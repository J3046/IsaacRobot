################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10778 steps/s (collection: 8.846s, learning 0.275s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0020
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.2435
                       Mean reward: 0.00
               Mean episode length: 21.93
    Episode_Reward/reaching_object: 0.0006
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0003
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.12s
                      Time elapsed: 00:00:09
                               ETA: 03:48:01

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 15076 steps/s (collection: 6.382s, learning 0.139s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.3114
                       Mean reward: 0.00
               Mean episode length: 45.42
    Episode_Reward/reaching_object: 0.0018
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0006
          Episode_Reward/joint_vel: -0.0008
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.52s
                      Time elapsed: 00:00:15
                               ETA: 03:15:23

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14405 steps/s (collection: 6.700s, learning 0.124s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.3850
                       Mean reward: 0.00
               Mean episode length: 69.07
    Episode_Reward/reaching_object: 0.0031
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0011
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.82s
                      Time elapsed: 00:00:22
                               ETA: 03:06:57

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 15370 steps/s (collection: 6.271s, learning 0.125s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 31.4295
                       Mean reward: 0.00
               Mean episode length: 93.12
    Episode_Reward/reaching_object: 0.0042
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0019
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.40s
                      Time elapsed: 00:00:28
                               ETA: 03:00:01

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 15205 steps/s (collection: 6.322s, learning 0.143s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 31.4831
                       Mean reward: 0.01
               Mean episode length: 117.84
    Episode_Reward/reaching_object: 0.0059
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.46s
                      Time elapsed: 00:00:35
                               ETA: 02:56:09

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 15208 steps/s (collection: 6.334s, learning 0.130s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 31.5444
                       Mean reward: 0.01
               Mean episode length: 141.19
    Episode_Reward/reaching_object: 0.0072
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0024
          Episode_Reward/joint_vel: -0.0030
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.46s
                      Time elapsed: 00:00:41
                               ETA: 02:53:32

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 15185 steps/s (collection: 6.341s, learning 0.132s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.5870
                       Mean reward: 0.01
               Mean episode length: 165.18
    Episode_Reward/reaching_object: 0.0090
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0036
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.47s
                      Time elapsed: 00:00:48
                               ETA: 02:51:40

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 15156 steps/s (collection: 6.353s, learning 0.133s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 31.6247
                       Mean reward: 0.02
               Mean episode length: 189.88
    Episode_Reward/reaching_object: 0.0114
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0032
          Episode_Reward/joint_vel: -0.0041
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.49s
                      Time elapsed: 00:00:54
                               ETA: 02:50:17

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 18360 steps/s (collection: 5.251s, learning 0.104s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 31.6614
                       Mean reward: 0.03
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 0.0131
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.35s
                      Time elapsed: 00:01:00
                               ETA: 02:46:03

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 60778 steps/s (collection: 1.528s, learning 0.090s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 31.7006
                       Mean reward: 0.03
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 0.0156
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.62s
                      Time elapsed: 00:01:01
                               ETA: 02:33:22

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 64633 steps/s (collection: 1.405s, learning 0.116s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.7139
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0191
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.52s
                      Time elapsed: 00:01:03
                               ETA: 02:22:46

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 64925 steps/s (collection: 1.424s, learning 0.090s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 31.7537
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0208
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.51s
                      Time elapsed: 00:01:04
                               ETA: 02:13:55

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 62413 steps/s (collection: 1.468s, learning 0.107s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 31.7744
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0253
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.58s
                      Time elapsed: 00:01:06
                               ETA: 02:06:32

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 59818 steps/s (collection: 1.535s, learning 0.108s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 31.7819
                       Mean reward: 0.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0304
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.64s
                      Time elapsed: 00:01:07
                               ETA: 02:00:19

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 64042 steps/s (collection: 1.429s, learning 0.106s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 31.8074
                       Mean reward: 0.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0370
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.53s
                      Time elapsed: 00:01:09
                               ETA: 01:54:46

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 61258 steps/s (collection: 1.487s, learning 0.118s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 31.8453
                       Mean reward: 0.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0475
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.60s
                      Time elapsed: 00:01:11
                               ETA: 01:50:00

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 62354 steps/s (collection: 1.465s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 31.8918
                       Mean reward: 0.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0664
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.58s
                      Time elapsed: 00:01:12
                               ETA: 01:45:45

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 59280 steps/s (collection: 1.523s, learning 0.135s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0010
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 31.9372
                       Mean reward: 0.46
               Mean episode length: 249.58
    Episode_Reward/reaching_object: 0.0790
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.66s
                      Time elapsed: 00:01:14
                               ETA: 01:42:05

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 58589 steps/s (collection: 1.587s, learning 0.091s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0022
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 31.9801
                       Mean reward: 0.48
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.1056
    Episode_Reward/rotating_object: 0.0005
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.68s
                      Time elapsed: 00:01:16
                               ETA: 01:38:50

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 56695 steps/s (collection: 1.645s, learning 0.089s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0049
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 32.0066
                       Mean reward: 0.74
               Mean episode length: 245.23
    Episode_Reward/reaching_object: 0.1470
    Episode_Reward/rotating_object: 0.0023
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.73s
                      Time elapsed: 00:01:17
                               ETA: 01:35:58

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 56110 steps/s (collection: 1.657s, learning 0.095s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0031
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 32.0927
                       Mean reward: 0.97
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.1843
    Episode_Reward/rotating_object: 0.0025
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.75s
                      Time elapsed: 00:01:19
                               ETA: 01:33:23

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 54541 steps/s (collection: 1.692s, learning 0.111s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0048
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 32.1306
                       Mean reward: 1.08
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 0.2088
    Episode_Reward/rotating_object: 0.0070
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.80s
                      Time elapsed: 00:01:21
                               ETA: 01:31:06

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 55758 steps/s (collection: 1.674s, learning 0.089s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0109
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 32.1785
                       Mean reward: 1.15
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 0.2348
    Episode_Reward/rotating_object: 0.0080
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 10.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.76s
                      Time elapsed: 00:01:23
                               ETA: 01:28:58

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 53830 steps/s (collection: 1.737s, learning 0.089s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0145
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.1975
                       Mean reward: 1.31
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 0.2588
    Episode_Reward/rotating_object: 0.0100
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 9.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.83s
                      Time elapsed: 00:01:24
                               ETA: 01:27:05

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 54020 steps/s (collection: 1.729s, learning 0.091s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0126
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 32.2530
                       Mean reward: 1.51
               Mean episode length: 222.89
    Episode_Reward/reaching_object: 0.2803
    Episode_Reward/rotating_object: 0.0080
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 7.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.82s
                      Time elapsed: 00:01:26
                               ETA: 01:25:20

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 52744 steps/s (collection: 1.770s, learning 0.094s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 32.3154
                       Mean reward: 1.44
               Mean episode length: 216.27
    Episode_Reward/reaching_object: 0.2991
    Episode_Reward/rotating_object: 0.0157
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 5.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.86s
                      Time elapsed: 00:01:28
                               ETA: 01:23:45

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 52637 steps/s (collection: 1.769s, learning 0.099s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0180
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 32.3589
                       Mean reward: 1.65
               Mean episode length: 210.72
    Episode_Reward/reaching_object: 0.3045
    Episode_Reward/rotating_object: 0.0145
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 4.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.87s
                      Time elapsed: 00:01:30
                               ETA: 01:22:18

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 53074 steps/s (collection: 1.747s, learning 0.105s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0421
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 32.4769
                       Mean reward: 1.87
               Mean episode length: 211.70
    Episode_Reward/reaching_object: 0.3342
    Episode_Reward/rotating_object: 0.0309
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 4.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.8750
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.85s
                      Time elapsed: 00:01:32
                               ETA: 01:20:56

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 53184 steps/s (collection: 1.759s, learning 0.090s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.4008
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.5812
                       Mean reward: 2.12
               Mean episode length: 205.90
    Episode_Reward/reaching_object: 0.3589
    Episode_Reward/rotating_object: 0.0496
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 5.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.85s
                      Time elapsed: 00:01:34
                               ETA: 01:19:39

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 52952 steps/s (collection: 1.766s, learning 0.091s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.2279
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.6316
                       Mean reward: 2.07
               Mean episode length: 203.61
    Episode_Reward/reaching_object: 0.3732
    Episode_Reward/rotating_object: 0.1444
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 5.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.86s
                      Time elapsed: 00:01:36
                               ETA: 01:18:27

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 52030 steps/s (collection: 1.791s, learning 0.098s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.2457
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.7311
                       Mean reward: 2.90
               Mean episode length: 204.35
    Episode_Reward/reaching_object: 0.3749
    Episode_Reward/rotating_object: 0.0742
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 5.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.89s
                      Time elapsed: 00:01:37
                               ETA: 01:17:22

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 52220 steps/s (collection: 1.774s, learning 0.108s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1437
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.8965
                       Mean reward: 2.17
               Mean episode length: 194.90
    Episode_Reward/reaching_object: 0.4184
    Episode_Reward/rotating_object: 0.1388
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 7.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.88s
                      Time elapsed: 00:01:39
                               ETA: 01:16:20

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 51302 steps/s (collection: 1.804s, learning 0.113s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.1533
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 33.0107
                       Mean reward: 3.07
               Mean episode length: 211.35
    Episode_Reward/reaching_object: 0.4680
    Episode_Reward/rotating_object: 0.1805
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 8.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.92s
                      Time elapsed: 00:01:41
                               ETA: 01:15:24

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 50983 steps/s (collection: 1.813s, learning 0.115s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3406
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.1530
                       Mean reward: 3.36
               Mean episode length: 209.59
    Episode_Reward/reaching_object: 0.4905
    Episode_Reward/rotating_object: 0.1160
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 8.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.93s
                      Time elapsed: 00:01:43
                               ETA: 01:14:31

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 51443 steps/s (collection: 1.817s, learning 0.094s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.4372
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.2572
                       Mean reward: 2.85
               Mean episode length: 207.99
    Episode_Reward/reaching_object: 0.5209
    Episode_Reward/rotating_object: 0.1809
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 9.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.91s
                      Time elapsed: 00:01:45
                               ETA: 01:13:40

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 51414 steps/s (collection: 1.807s, learning 0.105s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4159
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.3482
                       Mean reward: 4.15
               Mean episode length: 208.26
    Episode_Reward/reaching_object: 0.5449
    Episode_Reward/rotating_object: 0.3038
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 9.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.5000
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.91s
                      Time elapsed: 00:01:47
                               ETA: 01:12:52

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 50679 steps/s (collection: 1.832s, learning 0.108s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.7398
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.4968
                       Mean reward: 5.99
               Mean episode length: 211.99
    Episode_Reward/reaching_object: 0.5817
    Episode_Reward/rotating_object: 0.4411
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 9.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.94s
                      Time elapsed: 00:01:49
                               ETA: 01:12:08

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 52504 steps/s (collection: 1.780s, learning 0.092s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.8750
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 33.6248
                       Mean reward: 4.17
               Mean episode length: 210.81
    Episode_Reward/reaching_object: 0.5932
    Episode_Reward/rotating_object: 0.3152
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 9.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.87s
                      Time elapsed: 00:01:51
                               ETA: 01:11:23

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 51203 steps/s (collection: 1.830s, learning 0.090s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.3434
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 33.7332
                       Mean reward: 5.81
               Mean episode length: 218.48
    Episode_Reward/reaching_object: 0.6108
    Episode_Reward/rotating_object: 0.3618
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 9.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.92s
                      Time elapsed: 00:01:53
                               ETA: 01:10:42

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 51472 steps/s (collection: 1.813s, learning 0.097s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.8779
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.7739
                       Mean reward: 8.50
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 0.6661
    Episode_Reward/rotating_object: 0.7184
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.91s
                      Time elapsed: 00:01:55
                               ETA: 01:10:03

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 51007 steps/s (collection: 1.823s, learning 0.105s)
             Mean action noise std: 1.13
          Mean value_function loss: 2.0407
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.8664
                       Mean reward: 8.93
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 0.6851
    Episode_Reward/rotating_object: 1.0475
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.93s
                      Time elapsed: 00:01:57
                               ETA: 01:09:27

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 50567 steps/s (collection: 1.851s, learning 0.093s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.9394
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.9436
                       Mean reward: 5.27
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 0.9892
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.94s
                      Time elapsed: 00:01:58
                               ETA: 01:08:52

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 51820 steps/s (collection: 1.806s, learning 0.091s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.6333
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 34.0132
                       Mean reward: 8.02
               Mean episode length: 229.78
    Episode_Reward/reaching_object: 0.7122
    Episode_Reward/rotating_object: 1.1527
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.90s
                      Time elapsed: 00:02:00
                               ETA: 01:08:18

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 50402 steps/s (collection: 1.861s, learning 0.089s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.4097
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 34.0610
                       Mean reward: 11.23
               Mean episode length: 229.87
    Episode_Reward/reaching_object: 0.7364
    Episode_Reward/rotating_object: 1.1835
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.95s
                      Time elapsed: 00:02:02
                               ETA: 01:07:46

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 51655 steps/s (collection: 1.803s, learning 0.100s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.8089
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.1239
                       Mean reward: 10.24
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.7534
    Episode_Reward/rotating_object: 1.4044
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.90s
                      Time elapsed: 00:02:04
                               ETA: 01:07:15

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 51641 steps/s (collection: 1.808s, learning 0.096s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.9984
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 34.1819
                       Mean reward: 10.51
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 0.7360
    Episode_Reward/rotating_object: 1.3881
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.90s
                      Time elapsed: 00:02:06
                               ETA: 01:06:44

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 51206 steps/s (collection: 1.825s, learning 0.095s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.9982
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.2656
                       Mean reward: 6.50
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 0.8420
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.92s
                      Time elapsed: 00:02:08
                               ETA: 01:06:16

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 50943 steps/s (collection: 1.813s, learning 0.117s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.4851
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.3577
                       Mean reward: 8.69
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 0.7219
    Episode_Reward/rotating_object: 0.8200
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.93s
                      Time elapsed: 00:02:10
                               ETA: 01:05:49

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 50745 steps/s (collection: 1.825s, learning 0.112s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.5606
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.4005
                       Mean reward: 14.30
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 0.7206
    Episode_Reward/rotating_object: 1.6821
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.94s
                      Time elapsed: 00:02:12
                               ETA: 01:05:23

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 50300 steps/s (collection: 1.851s, learning 0.103s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.3426
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.4806
                       Mean reward: 11.87
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 1.6851
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.95s
                      Time elapsed: 00:02:14
                               ETA: 01:04:59

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 50243 steps/s (collection: 1.865s, learning 0.092s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.3370
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.6007
                       Mean reward: 9.09
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 1.3255
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.96s
                      Time elapsed: 00:02:16
                               ETA: 01:04:35

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 50817 steps/s (collection: 1.841s, learning 0.093s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.3646
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 34.6567
                       Mean reward: 11.01
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 1.4280
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 1.93s
                      Time elapsed: 00:02:18
                               ETA: 01:04:12

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 49705 steps/s (collection: 1.886s, learning 0.092s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.0135
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 34.6843
                       Mean reward: 12.72
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 1.8514
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.98s
                      Time elapsed: 00:02:20
                               ETA: 01:03:51

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 50495 steps/s (collection: 1.850s, learning 0.097s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.8451
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 34.7290
                       Mean reward: 9.29
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.7106
    Episode_Reward/rotating_object: 1.3759
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.95s
                      Time elapsed: 00:02:22
                               ETA: 01:03:29

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 50811 steps/s (collection: 1.846s, learning 0.089s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.3176
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 34.7595
                       Mean reward: 14.38
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 0.7335
    Episode_Reward/rotating_object: 1.8247
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.93s
                      Time elapsed: 00:02:24
                               ETA: 01:03:08

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 51381 steps/s (collection: 1.823s, learning 0.090s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.4785
               Mean surrogate loss: 0.0045
                 Mean entropy loss: 34.7813
                       Mean reward: 7.24
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.7070
    Episode_Reward/rotating_object: 1.7239
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.91s
                      Time elapsed: 00:02:26
                               ETA: 01:02:47

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 49606 steps/s (collection: 1.884s, learning 0.098s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.6007
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 34.7930
                       Mean reward: 14.23
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 0.7115
    Episode_Reward/rotating_object: 2.0128
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.98s
                      Time elapsed: 00:02:28
                               ETA: 01:02:29

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 51320 steps/s (collection: 1.813s, learning 0.103s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.6290
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 34.8050
                       Mean reward: 13.25
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 0.7149
    Episode_Reward/rotating_object: 2.4784
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.92s
                      Time elapsed: 00:02:29
                               ETA: 01:02:09

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 50324 steps/s (collection: 1.855s, learning 0.098s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.5560
               Mean surrogate loss: 0.0046
                 Mean entropy loss: 34.8377
                       Mean reward: 16.67
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 2.2477
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.95s
                      Time elapsed: 00:02:31
                               ETA: 01:01:51

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 49412 steps/s (collection: 1.892s, learning 0.098s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.6636
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 34.8507
                       Mean reward: 13.10
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 2.5912
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.99s
                      Time elapsed: 00:02:33
                               ETA: 01:01:35

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 45613 steps/s (collection: 2.048s, learning 0.107s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.9025
               Mean surrogate loss: 0.0048
                 Mean entropy loss: 34.8844
                       Mean reward: 14.81
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 0.7038
    Episode_Reward/rotating_object: 2.0751
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.16s
                      Time elapsed: 00:02:36
                               ETA: 01:01:23

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 47925 steps/s (collection: 1.945s, learning 0.106s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.0711
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 34.8934
                       Mean reward: 19.12
               Mean episode length: 227.38
    Episode_Reward/reaching_object: 0.7008
    Episode_Reward/rotating_object: 2.2384
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.05s
                      Time elapsed: 00:02:38
                               ETA: 01:01:08

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 49593 steps/s (collection: 1.887s, learning 0.095s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.9938
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 34.8995
                       Mean reward: 12.71
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 0.7355
    Episode_Reward/rotating_object: 2.1885
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.98s
                      Time elapsed: 00:02:40
                               ETA: 01:00:53

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 49452 steps/s (collection: 1.882s, learning 0.106s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.2280
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 34.9142
                       Mean reward: 14.09
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 0.7134
    Episode_Reward/rotating_object: 2.3386
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.99s
                      Time elapsed: 00:02:42
                               ETA: 01:00:38

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 49145 steps/s (collection: 1.892s, learning 0.109s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.2008
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 34.9212
                       Mean reward: 11.72
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 0.7061
    Episode_Reward/rotating_object: 2.2188
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.00s
                      Time elapsed: 00:02:44
                               ETA: 01:00:24

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 50670 steps/s (collection: 1.836s, learning 0.104s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.6651
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.9462
                       Mean reward: 22.74
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 2.9014
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.94s
                      Time elapsed: 00:02:45
                               ETA: 01:00:08

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 49850 steps/s (collection: 1.872s, learning 0.100s)
             Mean action noise std: 1.19
          Mean value_function loss: 4.1549
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 34.9943
                       Mean reward: 13.25
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 0.6939
    Episode_Reward/rotating_object: 2.7300
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.97s
                      Time elapsed: 00:02:47
                               ETA: 00:59:54

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 49591 steps/s (collection: 1.892s, learning 0.090s)
             Mean action noise std: 1.19
          Mean value_function loss: 4.3471
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.0113
                       Mean reward: 24.79
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 0.7110
    Episode_Reward/rotating_object: 2.8518
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.98s
                      Time elapsed: 00:02:49
                               ETA: 00:59:41

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 46744 steps/s (collection: 1.995s, learning 0.108s)
             Mean action noise std: 1.19
          Mean value_function loss: 4.6595
               Mean surrogate loss: 0.0029
                 Mean entropy loss: 35.0710
                       Mean reward: 12.95
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 0.6835
    Episode_Reward/rotating_object: 2.3170
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.10s
                      Time elapsed: 00:02:52
                               ETA: 00:59:30

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 47563 steps/s (collection: 1.973s, learning 0.094s)
             Mean action noise std: 1.19
          Mean value_function loss: 4.9005
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 35.0948
                       Mean reward: 26.09
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 0.6651
    Episode_Reward/rotating_object: 2.7501
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.07s
                      Time elapsed: 00:02:54
                               ETA: 00:59:19

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 50445 steps/s (collection: 1.855s, learning 0.094s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.8083
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 35.1562
                       Mean reward: 17.25
               Mean episode length: 232.60
    Episode_Reward/reaching_object: 0.6825
    Episode_Reward/rotating_object: 2.9236
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.95s
                      Time elapsed: 00:02:56
                               ETA: 00:59:05

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 50674 steps/s (collection: 1.842s, learning 0.098s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.6999
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 35.1994
                       Mean reward: 18.21
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 0.6861
    Episode_Reward/rotating_object: 2.9616
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.94s
                      Time elapsed: 00:02:57
                               ETA: 00:58:52

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 51282 steps/s (collection: 1.824s, learning 0.093s)
             Mean action noise std: 1.20
          Mean value_function loss: 6.0913
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 35.2605
                       Mean reward: 18.76
               Mean episode length: 220.63
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 2.5673
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.92s
                      Time elapsed: 00:02:59
                               ETA: 00:58:39

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 50835 steps/s (collection: 1.838s, learning 0.096s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.3410
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 35.2915
                       Mean reward: 17.48
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 0.6402
    Episode_Reward/rotating_object: 3.0230
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 10.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.93s
                      Time elapsed: 00:03:01
                               ETA: 00:58:26

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 50186 steps/s (collection: 1.852s, learning 0.107s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.5435
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.3416
                       Mean reward: 18.25
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 3.1406
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 10.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.96s
                      Time elapsed: 00:03:03
                               ETA: 00:58:14

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 50412 steps/s (collection: 1.853s, learning 0.097s)
             Mean action noise std: 1.21
          Mean value_function loss: 6.8007
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.4115
                       Mean reward: 20.87
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 0.6456
    Episode_Reward/rotating_object: 3.2167
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 10.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.95s
                      Time elapsed: 00:03:05
                               ETA: 00:58:02

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 49380 steps/s (collection: 1.873s, learning 0.118s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.1303
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.4830
                       Mean reward: 15.40
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.6846
    Episode_Reward/rotating_object: 3.4047
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.99s
                      Time elapsed: 00:03:07
                               ETA: 00:57:52

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 50475 steps/s (collection: 1.851s, learning 0.097s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.6926
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.5380
                       Mean reward: 21.61
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 0.7090
    Episode_Reward/rotating_object: 4.4387
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.95s
                      Time elapsed: 00:03:09
                               ETA: 00:57:40

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 51095 steps/s (collection: 1.823s, learning 0.101s)
             Mean action noise std: 1.22
          Mean value_function loss: 9.0553
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.5912
                       Mean reward: 22.02
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 0.7172
    Episode_Reward/rotating_object: 4.3891
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.92s
                      Time elapsed: 00:03:11
                               ETA: 00:57:29

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 51276 steps/s (collection: 1.808s, learning 0.110s)
             Mean action noise std: 1.22
          Mean value_function loss: 12.9324
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 35.6526
                       Mean reward: 20.24
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.6608
    Episode_Reward/rotating_object: 3.1325
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.92s
                      Time elapsed: 00:03:13
                               ETA: 00:57:17

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 51292 steps/s (collection: 1.812s, learning 0.105s)
             Mean action noise std: 1.23
          Mean value_function loss: 10.2375
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.6725
                       Mean reward: 20.45
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 0.6941
    Episode_Reward/rotating_object: 3.7956
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.92s
                      Time elapsed: 00:03:15
                               ETA: 00:57:06

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 51176 steps/s (collection: 1.823s, learning 0.098s)
             Mean action noise std: 1.23
          Mean value_function loss: 9.1852
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.7216
                       Mean reward: 28.82
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 0.6930
    Episode_Reward/rotating_object: 4.6130
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.92s
                      Time elapsed: 00:03:17
                               ETA: 00:56:55

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 51140 steps/s (collection: 1.827s, learning 0.095s)
             Mean action noise std: 1.23
          Mean value_function loss: 8.3504
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.7766
                       Mean reward: 21.39
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 0.6540
    Episode_Reward/rotating_object: 3.8210
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.92s
                      Time elapsed: 00:03:19
                               ETA: 00:56:44

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 51311 steps/s (collection: 1.804s, learning 0.112s)
             Mean action noise std: 1.24
          Mean value_function loss: 8.5510
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.8548
                       Mean reward: 27.37
               Mean episode length: 242.39
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 4.6798
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.92s
                      Time elapsed: 00:03:21
                               ETA: 00:56:34

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 51551 steps/s (collection: 1.812s, learning 0.095s)
             Mean action noise std: 1.24
          Mean value_function loss: 13.7985
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.9132
                       Mean reward: 22.73
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 3.9925
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.91s
                      Time elapsed: 00:03:23
                               ETA: 00:56:23

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 51998 steps/s (collection: 1.793s, learning 0.097s)
             Mean action noise std: 1.24
          Mean value_function loss: 11.4964
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 35.9523
                       Mean reward: 25.33
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 4.0974
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.89s
                      Time elapsed: 00:03:25
                               ETA: 00:56:13

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 52649 steps/s (collection: 1.773s, learning 0.094s)
             Mean action noise std: 1.25
          Mean value_function loss: 12.6172
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.0007
                       Mean reward: 19.34
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 0.6592
    Episode_Reward/rotating_object: 3.8544
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.87s
                      Time elapsed: 00:03:26
                               ETA: 00:56:02

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 52757 steps/s (collection: 1.759s, learning 0.104s)
             Mean action noise std: 1.25
          Mean value_function loss: 12.5567
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 36.0561
                       Mean reward: 30.22
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 0.6471
    Episode_Reward/rotating_object: 3.8952
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.86s
                      Time elapsed: 00:03:28
                               ETA: 00:55:51

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 52313 steps/s (collection: 1.791s, learning 0.089s)
             Mean action noise std: 1.25
          Mean value_function loss: 15.3462
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.0984
                       Mean reward: 29.95
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 0.6260
    Episode_Reward/rotating_object: 4.1549
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.88s
                      Time elapsed: 00:03:30
                               ETA: 00:55:41

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 50044 steps/s (collection: 1.868s, learning 0.096s)
             Mean action noise std: 1.25
          Mean value_function loss: 14.3879
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.1331
                       Mean reward: 36.30
               Mean episode length: 244.91
    Episode_Reward/reaching_object: 0.6446
    Episode_Reward/rotating_object: 5.3430
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.96s
                      Time elapsed: 00:03:32
                               ETA: 00:55:32

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 52237 steps/s (collection: 1.789s, learning 0.093s)
             Mean action noise std: 1.26
          Mean value_function loss: 13.2293
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 36.1933
                       Mean reward: 17.18
               Mean episode length: 248.44
    Episode_Reward/reaching_object: 0.6496
    Episode_Reward/rotating_object: 4.8135
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.88s
                      Time elapsed: 00:03:34
                               ETA: 00:55:22

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 52626 steps/s (collection: 1.779s, learning 0.089s)
             Mean action noise std: 1.26
          Mean value_function loss: 12.4337
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 36.2644
                       Mean reward: 32.09
               Mean episode length: 246.88
    Episode_Reward/reaching_object: 0.6441
    Episode_Reward/rotating_object: 5.2652
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.87s
                      Time elapsed: 00:03:36
                               ETA: 00:55:13

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 48959 steps/s (collection: 1.911s, learning 0.097s)
             Mean action noise std: 1.26
          Mean value_function loss: 12.8687
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.3299
                       Mean reward: 24.17
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 0.6313
    Episode_Reward/rotating_object: 4.3837
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.01s
                      Time elapsed: 00:03:38
                               ETA: 00:55:05

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 52173 steps/s (collection: 1.793s, learning 0.091s)
             Mean action noise std: 1.27
          Mean value_function loss: 11.8009
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.3660
                       Mean reward: 26.75
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 0.5965
    Episode_Reward/rotating_object: 4.3636
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.88s
                      Time elapsed: 00:03:40
                               ETA: 00:54:56

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 51860 steps/s (collection: 1.786s, learning 0.110s)
             Mean action noise std: 1.27
          Mean value_function loss: 12.7568
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 36.4316
                       Mean reward: 23.21
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 0.5949
    Episode_Reward/rotating_object: 4.7726
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.90s
                      Time elapsed: 00:03:42
                               ETA: 00:54:47

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 50471 steps/s (collection: 1.831s, learning 0.117s)
             Mean action noise std: 1.28
          Mean value_function loss: 12.3092
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 36.5072
                       Mean reward: 36.62
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 0.6014
    Episode_Reward/rotating_object: 6.1211
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.95s
                      Time elapsed: 00:03:44
                               ETA: 00:54:39

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 50675 steps/s (collection: 1.844s, learning 0.096s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.4454
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.5779
                       Mean reward: 24.40
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 0.6133
    Episode_Reward/rotating_object: 5.0141
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.94s
                      Time elapsed: 00:03:46
                               ETA: 00:54:31

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 51634 steps/s (collection: 1.805s, learning 0.099s)
             Mean action noise std: 1.28
          Mean value_function loss: 13.3388
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 36.6339
                       Mean reward: 44.48
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 0.5860
    Episode_Reward/rotating_object: 5.3100
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.90s
                      Time elapsed: 00:03:47
                               ETA: 00:54:22

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 52608 steps/s (collection: 1.778s, learning 0.091s)
             Mean action noise std: 1.28
          Mean value_function loss: 15.5575
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.6812
                       Mean reward: 25.16
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.5495
    Episode_Reward/rotating_object: 4.1701
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.87s
                      Time elapsed: 00:03:49
                               ETA: 00:54:13

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 52533 steps/s (collection: 1.780s, learning 0.092s)
             Mean action noise std: 1.29
          Mean value_function loss: 12.7673
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.7327
                       Mean reward: 27.67
               Mean episode length: 228.18
    Episode_Reward/reaching_object: 0.5681
    Episode_Reward/rotating_object: 5.6197
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.87s
                      Time elapsed: 00:03:51
                               ETA: 00:54:05

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 52460 steps/s (collection: 1.783s, learning 0.091s)
             Mean action noise std: 1.29
          Mean value_function loss: 12.9563
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.7779
                       Mean reward: 26.24
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 0.5814
    Episode_Reward/rotating_object: 5.1264
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.87s
                      Time elapsed: 00:03:53
                               ETA: 00:53:56

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 52281 steps/s (collection: 1.792s, learning 0.089s)
             Mean action noise std: 1.29
          Mean value_function loss: 12.3955
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 36.8382
                       Mean reward: 21.44
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 0.5916
    Episode_Reward/rotating_object: 6.0292
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.88s
                      Time elapsed: 00:03:55
                               ETA: 00:53:48

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 52402 steps/s (collection: 1.785s, learning 0.091s)
             Mean action noise std: 1.30
          Mean value_function loss: 11.0089
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 36.8799
                       Mean reward: 48.18
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 0.5724
    Episode_Reward/rotating_object: 7.5863
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.88s
                      Time elapsed: 00:03:57
                               ETA: 00:53:40

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 51350 steps/s (collection: 1.813s, learning 0.102s)
             Mean action noise std: 1.30
          Mean value_function loss: 12.1691
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.9229
                       Mean reward: 29.15
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 0.5618
    Episode_Reward/rotating_object: 5.6095
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.91s
                      Time elapsed: 00:03:59
                               ETA: 00:53:32

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 51941 steps/s (collection: 1.777s, learning 0.116s)
             Mean action noise std: 1.30
          Mean value_function loss: 11.9066
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 36.9819
                       Mean reward: 31.67
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 0.5520
    Episode_Reward/rotating_object: 5.3740
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.89s
                      Time elapsed: 00:04:01
                               ETA: 00:53:25

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 52360 steps/s (collection: 1.778s, learning 0.100s)
             Mean action noise std: 1.31
          Mean value_function loss: 12.9081
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.0177
                       Mean reward: 21.15
               Mean episode length: 220.22
    Episode_Reward/reaching_object: 0.5515
    Episode_Reward/rotating_object: 4.0665
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.88s
                      Time elapsed: 00:04:02
                               ETA: 00:53:17

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 53262 steps/s (collection: 1.754s, learning 0.092s)
             Mean action noise std: 1.31
          Mean value_function loss: 13.6577
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.0767
                       Mean reward: 23.29
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 0.5763
    Episode_Reward/rotating_object: 5.2511
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.85s
                      Time elapsed: 00:04:04
                               ETA: 00:53:09

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 52516 steps/s (collection: 1.780s, learning 0.092s)
             Mean action noise std: 1.31
          Mean value_function loss: 12.5144
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.1332
                       Mean reward: 37.74
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 0.5694
    Episode_Reward/rotating_object: 6.5960
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.87s
                      Time elapsed: 00:04:06
                               ETA: 00:53:01

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 52447 steps/s (collection: 1.778s, learning 0.096s)
             Mean action noise std: 1.32
          Mean value_function loss: 16.0051
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 37.1876
                       Mean reward: 44.58
               Mean episode length: 231.54
    Episode_Reward/reaching_object: 0.6055
    Episode_Reward/rotating_object: 6.3085
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.87s
                      Time elapsed: 00:04:08
                               ETA: 00:52:54

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 53302 steps/s (collection: 1.752s, learning 0.092s)
             Mean action noise std: 1.32
          Mean value_function loss: 15.4353
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.2364
                       Mean reward: 34.00
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 0.6330
    Episode_Reward/rotating_object: 5.8615
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.84s
                      Time elapsed: 00:04:10
                               ETA: 00:52:46

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 53044 steps/s (collection: 1.750s, learning 0.104s)
             Mean action noise std: 1.32
          Mean value_function loss: 15.5905
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.2821
                       Mean reward: 42.10
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 0.6038
    Episode_Reward/rotating_object: 6.1967
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.85s
                      Time elapsed: 00:04:12
                               ETA: 00:52:38

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 53177 steps/s (collection: 1.736s, learning 0.113s)
             Mean action noise std: 1.32
          Mean value_function loss: 14.4309
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.3190
                       Mean reward: 38.46
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 0.6020
    Episode_Reward/rotating_object: 6.5047
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.85s
                      Time elapsed: 00:04:14
                               ETA: 00:52:31

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 52113 steps/s (collection: 1.769s, learning 0.117s)
             Mean action noise std: 1.33
          Mean value_function loss: 14.5089
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.3637
                       Mean reward: 26.46
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 0.5826
    Episode_Reward/rotating_object: 5.7567
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.89s
                      Time elapsed: 00:04:15
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 54066 steps/s (collection: 1.729s, learning 0.090s)
             Mean action noise std: 1.33
          Mean value_function loss: 15.1534
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.4068
                       Mean reward: 28.14
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 0.6080
    Episode_Reward/rotating_object: 5.9486
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.82s
                      Time elapsed: 00:04:17
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 51095 steps/s (collection: 1.819s, learning 0.105s)
             Mean action noise std: 1.33
          Mean value_function loss: 15.9729
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.4472
                       Mean reward: 49.05
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 0.6260
    Episode_Reward/rotating_object: 6.7891
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.92s
                      Time elapsed: 00:04:19
                               ETA: 00:52:10

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 48455 steps/s (collection: 1.932s, learning 0.097s)
             Mean action noise std: 1.34
          Mean value_function loss: 17.5450
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 37.5004
                       Mean reward: 42.91
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 0.6293
    Episode_Reward/rotating_object: 8.2630
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.03s
                      Time elapsed: 00:04:21
                               ETA: 00:52:05

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 53649 steps/s (collection: 1.737s, learning 0.095s)
             Mean action noise std: 1.34
          Mean value_function loss: 17.0521
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.5666
                       Mean reward: 37.15
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 0.6045
    Episode_Reward/rotating_object: 7.1129
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.83s
                      Time elapsed: 00:04:23
                               ETA: 00:51:58

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 52944 steps/s (collection: 1.768s, learning 0.089s)
             Mean action noise std: 1.34
          Mean value_function loss: 16.6448
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 37.6114
                       Mean reward: 43.23
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 0.6223
    Episode_Reward/rotating_object: 7.8368
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.86s
                      Time elapsed: 00:04:25
                               ETA: 00:51:51

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 53252 steps/s (collection: 1.755s, learning 0.091s)
             Mean action noise std: 1.34
          Mean value_function loss: 16.1327
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.6615
                       Mean reward: 44.03
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 7.5426
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.85s
                      Time elapsed: 00:04:27
                               ETA: 00:51:44

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 53346 steps/s (collection: 1.751s, learning 0.092s)
             Mean action noise std: 1.35
          Mean value_function loss: 17.7654
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.7160
                       Mean reward: 38.26
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 0.6304
    Episode_Reward/rotating_object: 5.9975
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.84s
                      Time elapsed: 00:04:29
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 53835 steps/s (collection: 1.730s, learning 0.096s)
             Mean action noise std: 1.35
          Mean value_function loss: 17.4166
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.7699
                       Mean reward: 39.56
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 0.6139
    Episode_Reward/rotating_object: 6.1939
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.83s
                      Time elapsed: 00:04:30
                               ETA: 00:51:30

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 51885 steps/s (collection: 1.799s, learning 0.096s)
             Mean action noise std: 1.35
          Mean value_function loss: 19.2746
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 37.7998
                       Mean reward: 48.53
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 0.6499
    Episode_Reward/rotating_object: 8.2530
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.89s
                      Time elapsed: 00:04:32
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 53040 steps/s (collection: 1.761s, learning 0.092s)
             Mean action noise std: 1.36
          Mean value_function loss: 20.7372
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 37.8425
                       Mean reward: 50.90
               Mean episode length: 234.86
    Episode_Reward/reaching_object: 0.6548
    Episode_Reward/rotating_object: 7.8788
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.85s
                      Time elapsed: 00:04:34
                               ETA: 00:51:17

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 53675 steps/s (collection: 1.740s, learning 0.091s)
             Mean action noise std: 1.36
          Mean value_function loss: 18.1655
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 37.8987
                       Mean reward: 48.43
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 0.6781
    Episode_Reward/rotating_object: 9.7572
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.83s
                      Time elapsed: 00:04:36
                               ETA: 00:51:10

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 53144 steps/s (collection: 1.761s, learning 0.089s)
             Mean action noise std: 1.36
          Mean value_function loss: 19.4599
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.9548
                       Mean reward: 43.98
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 0.6321
    Episode_Reward/rotating_object: 8.5639
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.85s
                      Time elapsed: 00:04:38
                               ETA: 00:51:04

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 51199 steps/s (collection: 1.826s, learning 0.095s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.1845
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.0086
                       Mean reward: 22.08
               Mean episode length: 220.02
    Episode_Reward/reaching_object: 0.6091
    Episode_Reward/rotating_object: 7.2570
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.92s
                      Time elapsed: 00:04:40
                               ETA: 00:50:58

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 52947 steps/s (collection: 1.766s, learning 0.090s)
             Mean action noise std: 1.37
          Mean value_function loss: 16.2195
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.0445
                       Mean reward: 49.46
               Mean episode length: 224.26
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 7.9833
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.86s
                      Time elapsed: 00:04:42
                               ETA: 00:50:52

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 53303 steps/s (collection: 1.729s, learning 0.115s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.6134
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 38.0821
                       Mean reward: 47.09
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 0.5810
    Episode_Reward/rotating_object: 7.6922
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.84s
                      Time elapsed: 00:04:44
                               ETA: 00:50:46

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 51932 steps/s (collection: 1.791s, learning 0.102s)
             Mean action noise std: 1.37
          Mean value_function loss: 19.1957
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 38.1243
                       Mean reward: 29.46
               Mean episode length: 221.69
    Episode_Reward/reaching_object: 0.6415
    Episode_Reward/rotating_object: 9.5638
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.89s
                      Time elapsed: 00:04:45
                               ETA: 00:50:40

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 52908 steps/s (collection: 1.767s, learning 0.091s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.8177
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 38.1620
                       Mean reward: 32.06
               Mean episode length: 209.61
    Episode_Reward/reaching_object: 0.6333
    Episode_Reward/rotating_object: 7.7465
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.86s
                      Time elapsed: 00:04:47
                               ETA: 00:50:34

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 53233 steps/s (collection: 1.755s, learning 0.092s)
             Mean action noise std: 1.38
          Mean value_function loss: 17.3074
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.1975
                       Mean reward: 52.90
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 0.6175
    Episode_Reward/rotating_object: 8.5459
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.85s
                      Time elapsed: 00:04:49
                               ETA: 00:50:28

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 53173 steps/s (collection: 1.749s, learning 0.100s)
             Mean action noise std: 1.38
          Mean value_function loss: 19.3615
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.2510
                       Mean reward: 65.30
               Mean episode length: 220.86
    Episode_Reward/reaching_object: 0.6546
    Episode_Reward/rotating_object: 10.6869
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.85s
                      Time elapsed: 00:04:51
                               ETA: 00:50:22

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 53229 steps/s (collection: 1.753s, learning 0.094s)
             Mean action noise std: 1.38
          Mean value_function loss: 20.9803
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 38.2739
                       Mean reward: 45.86
               Mean episode length: 226.55
    Episode_Reward/reaching_object: 0.6233
    Episode_Reward/rotating_object: 8.9514
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.85s
                      Time elapsed: 00:04:53
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 53524 steps/s (collection: 1.730s, learning 0.107s)
             Mean action noise std: 1.38
          Mean value_function loss: 20.7521
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.3137
                       Mean reward: 41.76
               Mean episode length: 219.42
    Episode_Reward/reaching_object: 0.6241
    Episode_Reward/rotating_object: 9.0231
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.84s
                      Time elapsed: 00:04:55
                               ETA: 00:50:10

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 52962 steps/s (collection: 1.762s, learning 0.094s)
             Mean action noise std: 1.39
          Mean value_function loss: 22.1768
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 38.3513
                       Mean reward: 65.58
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 0.6351
    Episode_Reward/rotating_object: 9.7772
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.86s
                      Time elapsed: 00:04:56
                               ETA: 00:50:05

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 53270 steps/s (collection: 1.755s, learning 0.091s)
             Mean action noise std: 1.39
          Mean value_function loss: 25.0253
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 38.4004
                       Mean reward: 63.91
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 0.6342
    Episode_Reward/rotating_object: 10.2656
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.85s
                      Time elapsed: 00:04:58
                               ETA: 00:49:59

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 52858 steps/s (collection: 1.765s, learning 0.095s)
             Mean action noise std: 1.39
          Mean value_function loss: 21.9501
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.4246
                       Mean reward: 59.74
               Mean episode length: 215.81
    Episode_Reward/reaching_object: 0.6267
    Episode_Reward/rotating_object: 10.5241
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.86s
                      Time elapsed: 00:05:00
                               ETA: 00:49:53

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 53908 steps/s (collection: 1.729s, learning 0.095s)
             Mean action noise std: 1.39
          Mean value_function loss: 20.3505
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.4534
                       Mean reward: 59.24
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 0.6487
    Episode_Reward/rotating_object: 10.8519
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.82s
                      Time elapsed: 00:05:02
                               ETA: 00:49:47

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 53429 steps/s (collection: 1.742s, learning 0.098s)
             Mean action noise std: 1.40
          Mean value_function loss: 25.6857
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 38.4896
                       Mean reward: 75.03
               Mean episode length: 234.15
    Episode_Reward/reaching_object: 0.6441
    Episode_Reward/rotating_object: 12.0849
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.84s
                      Time elapsed: 00:05:04
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 53167 steps/s (collection: 1.756s, learning 0.093s)
             Mean action noise std: 1.40
          Mean value_function loss: 22.6555
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.5124
                       Mean reward: 53.49
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 0.6314
    Episode_Reward/rotating_object: 11.1749
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.85s
                      Time elapsed: 00:05:06
                               ETA: 00:49:36

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 54606 steps/s (collection: 1.711s, learning 0.090s)
             Mean action noise std: 1.40
          Mean value_function loss: 22.4414
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.5334
                       Mean reward: 71.33
               Mean episode length: 229.62
    Episode_Reward/reaching_object: 0.6474
    Episode_Reward/rotating_object: 10.4076
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.80s
                      Time elapsed: 00:05:08
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 53667 steps/s (collection: 1.739s, learning 0.093s)
             Mean action noise std: 1.40
          Mean value_function loss: 25.3786
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.5487
                       Mean reward: 63.28
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.6446
    Episode_Reward/rotating_object: 9.7632
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.83s
                      Time elapsed: 00:05:09
                               ETA: 00:49:25

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 53388 steps/s (collection: 1.741s, learning 0.100s)
             Mean action noise std: 1.40
          Mean value_function loss: 25.8551
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.5857
                       Mean reward: 82.34
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 0.6510
    Episode_Reward/rotating_object: 12.9417
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.84s
                      Time elapsed: 00:05:11
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 52599 steps/s (collection: 1.754s, learning 0.115s)
             Mean action noise std: 1.41
          Mean value_function loss: 26.1693
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 38.6332
                       Mean reward: 55.69
               Mean episode length: 224.94
    Episode_Reward/reaching_object: 0.6260
    Episode_Reward/rotating_object: 12.4856
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.87s
                      Time elapsed: 00:05:13
                               ETA: 00:49:14

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 52477 steps/s (collection: 1.764s, learning 0.109s)
             Mean action noise std: 1.41
          Mean value_function loss: 28.7873
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 38.6666
                       Mean reward: 56.18
               Mean episode length: 224.77
    Episode_Reward/reaching_object: 0.6294
    Episode_Reward/rotating_object: 11.4938
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.87s
                      Time elapsed: 00:05:15
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 53285 steps/s (collection: 1.750s, learning 0.095s)
             Mean action noise std: 1.41
          Mean value_function loss: 26.2951
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.6985
                       Mean reward: 60.69
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 0.6043
    Episode_Reward/rotating_object: 11.8606
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.84s
                      Time elapsed: 00:05:17
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 53685 steps/s (collection: 1.737s, learning 0.094s)
             Mean action noise std: 1.41
          Mean value_function loss: 24.4551
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 38.7407
                       Mean reward: 58.10
               Mean episode length: 222.99
    Episode_Reward/reaching_object: 0.6268
    Episode_Reward/rotating_object: 11.3129
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.83s
                      Time elapsed: 00:05:19
                               ETA: 00:48:59

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 52339 steps/s (collection: 1.784s, learning 0.095s)
             Mean action noise std: 1.41
          Mean value_function loss: 26.6857
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 38.7801
                       Mean reward: 47.05
               Mean episode length: 216.49
    Episode_Reward/reaching_object: 0.5601
    Episode_Reward/rotating_object: 8.6635
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.88s
                      Time elapsed: 00:05:20
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 52272 steps/s (collection: 1.791s, learning 0.090s)
             Mean action noise std: 1.42
          Mean value_function loss: 27.0113
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.8252
                       Mean reward: 57.12
               Mean episode length: 223.07
    Episode_Reward/reaching_object: 0.5817
    Episode_Reward/rotating_object: 12.0009
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.88s
                      Time elapsed: 00:05:22
                               ETA: 00:48:49

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 52643 steps/s (collection: 1.774s, learning 0.093s)
             Mean action noise std: 1.42
          Mean value_function loss: 25.7338
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.8575
                       Mean reward: 52.65
               Mean episode length: 219.31
    Episode_Reward/reaching_object: 0.5982
    Episode_Reward/rotating_object: 11.8218
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.87s
                      Time elapsed: 00:05:24
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 52250 steps/s (collection: 1.793s, learning 0.089s)
             Mean action noise std: 1.42
          Mean value_function loss: 27.5465
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.8860
                       Mean reward: 68.96
               Mean episode length: 215.83
    Episode_Reward/reaching_object: 0.6391
    Episode_Reward/rotating_object: 15.3563
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.88s
                      Time elapsed: 00:05:26
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 51920 steps/s (collection: 1.803s, learning 0.091s)
             Mean action noise std: 1.42
          Mean value_function loss: 28.1832
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 38.9275
                       Mean reward: 62.85
               Mean episode length: 229.63
    Episode_Reward/reaching_object: 0.6233
    Episode_Reward/rotating_object: 11.8072
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.89s
                      Time elapsed: 00:05:28
                               ETA: 00:48:35

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 50986 steps/s (collection: 1.836s, learning 0.092s)
             Mean action noise std: 1.43
          Mean value_function loss: 29.2384
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.9668
                       Mean reward: 82.45
               Mean episode length: 221.68
    Episode_Reward/reaching_object: 0.6283
    Episode_Reward/rotating_object: 13.3168
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.93s
                      Time elapsed: 00:05:30
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 50982 steps/s (collection: 1.833s, learning 0.096s)
             Mean action noise std: 1.43
          Mean value_function loss: 27.5854
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.0024
                       Mean reward: 62.73
               Mean episode length: 219.81
    Episode_Reward/reaching_object: 0.6181
    Episode_Reward/rotating_object: 12.5273
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.93s
                      Time elapsed: 00:05:32
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 50143 steps/s (collection: 1.856s, learning 0.104s)
             Mean action noise std: 1.43
          Mean value_function loss: 31.6459
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.0378
                       Mean reward: 73.28
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 0.6456
    Episode_Reward/rotating_object: 13.8030
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.96s
                      Time elapsed: 00:05:34
                               ETA: 00:48:23

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 50949 steps/s (collection: 1.820s, learning 0.110s)
             Mean action noise std: 1.43
          Mean value_function loss: 32.0074
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.0764
                       Mean reward: 53.68
               Mean episode length: 225.16
    Episode_Reward/reaching_object: 0.6479
    Episode_Reward/rotating_object: 13.1481
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.93s
                      Time elapsed: 00:05:36
                               ETA: 00:48:19

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 46367 steps/s (collection: 1.952s, learning 0.168s)
             Mean action noise std: 1.44
          Mean value_function loss: 32.2239
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 39.1057
                       Mean reward: 78.16
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 15.3647
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.12s
                      Time elapsed: 00:05:38
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 49035 steps/s (collection: 1.806s, learning 0.199s)
             Mean action noise std: 1.44
          Mean value_function loss: 28.7936
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.1436
                       Mean reward: 83.37
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 0.6671
    Episode_Reward/rotating_object: 12.1412
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.00s
                      Time elapsed: 00:05:40
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 47147 steps/s (collection: 1.882s, learning 0.204s)
             Mean action noise std: 1.44
          Mean value_function loss: 27.8438
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.1817
                       Mean reward: 73.28
               Mean episode length: 224.05
    Episode_Reward/reaching_object: 0.6771
    Episode_Reward/rotating_object: 14.8139
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.09s
                      Time elapsed: 00:05:42
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 43355 steps/s (collection: 2.170s, learning 0.097s)
             Mean action noise std: 1.44
          Mean value_function loss: 28.3665
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.2240
                       Mean reward: 72.65
               Mean episode length: 226.66
    Episode_Reward/reaching_object: 0.6713
    Episode_Reward/rotating_object: 13.7467
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.27s
                      Time elapsed: 00:05:44
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 49652 steps/s (collection: 1.876s, learning 0.104s)
             Mean action noise std: 1.45
          Mean value_function loss: 28.1699
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 39.2596
                       Mean reward: 76.78
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 0.6780
    Episode_Reward/rotating_object: 13.6518
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.98s
                      Time elapsed: 00:05:46
                               ETA: 00:48:05

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 49901 steps/s (collection: 1.867s, learning 0.103s)
             Mean action noise std: 1.45
          Mean value_function loss: 33.2517
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.2862
                       Mean reward: 55.30
               Mean episode length: 218.20
    Episode_Reward/reaching_object: 0.6344
    Episode_Reward/rotating_object: 12.7128
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.97s
                      Time elapsed: 00:05:48
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 48412 steps/s (collection: 1.850s, learning 0.180s)
             Mean action noise std: 1.45
          Mean value_function loss: 33.6510
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 39.3183
                       Mean reward: 74.91
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 0.6526
    Episode_Reward/rotating_object: 13.6431
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.03s
                      Time elapsed: 00:05:50
                               ETA: 00:47:58

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 48997 steps/s (collection: 1.901s, learning 0.106s)
             Mean action noise std: 1.45
          Mean value_function loss: 35.2450
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 39.3515
                       Mean reward: 54.27
               Mean episode length: 217.03
    Episode_Reward/reaching_object: 0.6309
    Episode_Reward/rotating_object: 12.3018
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.01s
                      Time elapsed: 00:05:52
                               ETA: 00:47:55

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 45948 steps/s (collection: 1.992s, learning 0.147s)
             Mean action noise std: 1.45
          Mean value_function loss: 36.0100
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.3850
                       Mean reward: 65.45
               Mean episode length: 222.16
    Episode_Reward/reaching_object: 0.6329
    Episode_Reward/rotating_object: 12.2314
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.14s
                      Time elapsed: 00:05:54
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 49166 steps/s (collection: 1.885s, learning 0.115s)
             Mean action noise std: 1.46
          Mean value_function loss: 40.4731
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 39.4146
                       Mean reward: 72.17
               Mean episode length: 224.74
    Episode_Reward/reaching_object: 0.6430
    Episode_Reward/rotating_object: 13.2252
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.00s
                      Time elapsed: 00:05:56
                               ETA: 00:47:49

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 46735 steps/s (collection: 1.952s, learning 0.151s)
             Mean action noise std: 1.46
          Mean value_function loss: 41.9986
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 39.4439
                       Mean reward: 68.47
               Mean episode length: 215.24
    Episode_Reward/reaching_object: 0.6247
    Episode_Reward/rotating_object: 12.1386
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.10s
                      Time elapsed: 00:05:58
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 45561 steps/s (collection: 1.948s, learning 0.210s)
             Mean action noise std: 1.46
          Mean value_function loss: 39.7696
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.4773
                       Mean reward: 77.57
               Mean episode length: 217.19
    Episode_Reward/reaching_object: 0.6333
    Episode_Reward/rotating_object: 13.9860
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.16s
                      Time elapsed: 00:06:01
                               ETA: 00:47:45

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 47644 steps/s (collection: 1.972s, learning 0.092s)
             Mean action noise std: 1.46
          Mean value_function loss: 40.5212
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.4925
                       Mean reward: 63.27
               Mean episode length: 213.75
    Episode_Reward/reaching_object: 0.6216
    Episode_Reward/rotating_object: 12.9030
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.06s
                      Time elapsed: 00:06:03
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 48469 steps/s (collection: 1.939s, learning 0.089s)
             Mean action noise std: 1.46
          Mean value_function loss: 40.8011
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.5208
                       Mean reward: 104.26
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 0.6620
    Episode_Reward/rotating_object: 16.6269
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.03s
                      Time elapsed: 00:06:05
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 46362 steps/s (collection: 1.970s, learning 0.150s)
             Mean action noise std: 1.47
          Mean value_function loss: 43.8474
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.5578
                       Mean reward: 79.16
               Mean episode length: 213.25
    Episode_Reward/reaching_object: 0.6283
    Episode_Reward/rotating_object: 14.6421
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.12s
                      Time elapsed: 00:06:07
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 51301 steps/s (collection: 1.816s, learning 0.100s)
             Mean action noise std: 1.47
          Mean value_function loss: 45.9416
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.5924
                       Mean reward: 85.85
               Mean episode length: 215.01
    Episode_Reward/reaching_object: 0.6392
    Episode_Reward/rotating_object: 14.4591
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.92s
                      Time elapsed: 00:06:09
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 51203 steps/s (collection: 1.827s, learning 0.093s)
             Mean action noise std: 1.47
          Mean value_function loss: 49.5614
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.6228
                       Mean reward: 67.69
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 0.6577
    Episode_Reward/rotating_object: 13.6183
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.92s
                      Time elapsed: 00:06:11
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 48550 steps/s (collection: 1.930s, learning 0.095s)
             Mean action noise std: 1.47
          Mean value_function loss: 40.9304
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 39.6571
                       Mean reward: 66.87
               Mean episode length: 213.61
    Episode_Reward/reaching_object: 0.6312
    Episode_Reward/rotating_object: 13.6743
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.02s
                      Time elapsed: 00:06:13
                               ETA: 00:47:26

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 50638 steps/s (collection: 1.847s, learning 0.095s)
             Mean action noise std: 1.48
          Mean value_function loss: 41.9059
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 39.6943
                       Mean reward: 76.41
               Mean episode length: 212.43
    Episode_Reward/reaching_object: 0.6303
    Episode_Reward/rotating_object: 15.7966
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.94s
                      Time elapsed: 00:06:15
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 50006 steps/s (collection: 1.858s, learning 0.108s)
             Mean action noise std: 1.48
          Mean value_function loss: 41.8075
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.7342
                       Mean reward: 67.50
               Mean episode length: 216.70
    Episode_Reward/reaching_object: 0.6357
    Episode_Reward/rotating_object: 15.0422
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 11.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.97s
                      Time elapsed: 00:06:17
                               ETA: 00:47:18

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 44090 steps/s (collection: 2.118s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 35.8741
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.7662
                       Mean reward: 98.02
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 0.6727
    Episode_Reward/rotating_object: 17.5709
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.23s
                      Time elapsed: 00:06:19
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 45470 steps/s (collection: 1.981s, learning 0.181s)
             Mean action noise std: 1.48
          Mean value_function loss: 43.4280
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 39.8079
                       Mean reward: 80.13
               Mean episode length: 226.73
    Episode_Reward/reaching_object: 0.6294
    Episode_Reward/rotating_object: 16.1546
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.16s
                      Time elapsed: 00:06:21
                               ETA: 00:47:15

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 47074 steps/s (collection: 1.943s, learning 0.146s)
             Mean action noise std: 1.49
          Mean value_function loss: 42.0802
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.8465
                       Mean reward: 74.18
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 0.7008
    Episode_Reward/rotating_object: 20.2202
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.09s
                      Time elapsed: 00:06:23
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 47173 steps/s (collection: 1.980s, learning 0.104s)
             Mean action noise std: 1.49
          Mean value_function loss: 44.6902
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.8696
                       Mean reward: 97.39
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 0.6821
    Episode_Reward/rotating_object: 19.0170
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.08s
                      Time elapsed: 00:06:25
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 49532 steps/s (collection: 1.882s, learning 0.103s)
             Mean action noise std: 1.49
          Mean value_function loss: 46.4061
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.8778
                       Mean reward: 76.16
               Mean episode length: 221.42
    Episode_Reward/reaching_object: 0.6609
    Episode_Reward/rotating_object: 15.7363
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.98s
                      Time elapsed: 00:06:27
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 49424 steps/s (collection: 1.875s, learning 0.114s)
             Mean action noise std: 1.49
          Mean value_function loss: 45.6685
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 39.8844
                       Mean reward: 78.12
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 17.8507
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.99s
                      Time elapsed: 00:06:29
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 47909 steps/s (collection: 1.955s, learning 0.097s)
             Mean action noise std: 1.49
          Mean value_function loss: 48.2269
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.9063
                       Mean reward: 81.44
               Mean episode length: 220.89
    Episode_Reward/reaching_object: 0.6900
    Episode_Reward/rotating_object: 17.3767
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.05s
                      Time elapsed: 00:06:31
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 44904 steps/s (collection: 2.052s, learning 0.137s)
             Mean action noise std: 1.49
          Mean value_function loss: 44.6974
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.9369
                       Mean reward: 85.24
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 20.4088
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.19s
                      Time elapsed: 00:06:33
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 49524 steps/s (collection: 1.882s, learning 0.103s)
             Mean action noise std: 1.49
          Mean value_function loss: 46.3065
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 39.9736
                       Mean reward: 99.78
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 18.8326
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.98s
                      Time elapsed: 00:06:35
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 48871 steps/s (collection: 1.903s, learning 0.108s)
             Mean action noise std: 1.50
          Mean value_function loss: 39.4859
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.9932
                       Mean reward: 91.17
               Mean episode length: 218.52
    Episode_Reward/reaching_object: 0.6646
    Episode_Reward/rotating_object: 17.7638
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.01s
                      Time elapsed: 00:06:37
                               ETA: 00:46:52

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 51065 steps/s (collection: 1.829s, learning 0.096s)
             Mean action noise std: 1.50
          Mean value_function loss: 45.1351
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.0308
                       Mean reward: 99.23
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 0.6795
    Episode_Reward/rotating_object: 20.9282
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.93s
                      Time elapsed: 00:06:39
                               ETA: 00:46:49

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 51120 steps/s (collection: 1.832s, learning 0.091s)
             Mean action noise std: 1.50
          Mean value_function loss: 40.4946
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.0574
                       Mean reward: 92.71
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 0.6802
    Episode_Reward/rotating_object: 19.5984
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.92s
                      Time elapsed: 00:06:41
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 51737 steps/s (collection: 1.791s, learning 0.109s)
             Mean action noise std: 1.50
          Mean value_function loss: 38.8020
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.0818
                       Mean reward: 87.61
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 0.6597
    Episode_Reward/rotating_object: 18.9148
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.90s
                      Time elapsed: 00:06:43
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 50598 steps/s (collection: 1.834s, learning 0.109s)
             Mean action noise std: 1.50
          Mean value_function loss: 41.8338
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 40.1122
                       Mean reward: 89.57
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 0.6510
    Episode_Reward/rotating_object: 17.1892
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.94s
                      Time elapsed: 00:06:45
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 50115 steps/s (collection: 1.839s, learning 0.122s)
             Mean action noise std: 1.51
          Mean value_function loss: 43.3917
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.1502
                       Mean reward: 116.09
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 0.6354
    Episode_Reward/rotating_object: 17.9418
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.96s
                      Time elapsed: 00:06:47
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 51131 steps/s (collection: 1.830s, learning 0.092s)
             Mean action noise std: 1.51
          Mean value_function loss: 42.1448
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 40.1768
                       Mean reward: 107.09
               Mean episode length: 230.00
    Episode_Reward/reaching_object: 0.6859
    Episode_Reward/rotating_object: 22.7472
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.92s
                      Time elapsed: 00:06:49
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 50633 steps/s (collection: 1.851s, learning 0.090s)
             Mean action noise std: 1.51
          Mean value_function loss: 45.9804
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.2059
                       Mean reward: 101.57
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 20.2237
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.94s
                      Time elapsed: 00:06:51
                               ETA: 00:46:28

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 51195 steps/s (collection: 1.828s, learning 0.092s)
             Mean action noise std: 1.51
          Mean value_function loss: 47.4835
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 40.2284
                       Mean reward: 110.54
               Mean episode length: 228.32
    Episode_Reward/reaching_object: 0.6640
    Episode_Reward/rotating_object: 20.7313
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.92s
                      Time elapsed: 00:06:53
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 50795 steps/s (collection: 1.823s, learning 0.112s)
             Mean action noise std: 1.51
          Mean value_function loss: 45.2897
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 40.2564
                       Mean reward: 113.51
               Mean episode length: 220.17
    Episode_Reward/reaching_object: 0.6558
    Episode_Reward/rotating_object: 19.4659
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.94s
                      Time elapsed: 00:06:55
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 50557 steps/s (collection: 1.829s, learning 0.116s)
             Mean action noise std: 1.52
          Mean value_function loss: 51.3355
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 40.2899
                       Mean reward: 97.10
               Mean episode length: 209.24
    Episode_Reward/reaching_object: 0.6385
    Episode_Reward/rotating_object: 20.2903
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.94s
                      Time elapsed: 00:06:57
                               ETA: 00:46:17

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 50872 steps/s (collection: 1.830s, learning 0.102s)
             Mean action noise std: 1.52
          Mean value_function loss: 58.7140
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.3149
                       Mean reward: 94.36
               Mean episode length: 219.65
    Episode_Reward/reaching_object: 0.6418
    Episode_Reward/rotating_object: 18.4430
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.93s
                      Time elapsed: 00:06:59
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 51440 steps/s (collection: 1.819s, learning 0.092s)
             Mean action noise std: 1.52
          Mean value_function loss: 58.4639
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 40.3372
                       Mean reward: 85.64
               Mean episode length: 218.66
    Episode_Reward/reaching_object: 0.6444
    Episode_Reward/rotating_object: 19.0640
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.91s
                      Time elapsed: 00:07:01
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 51225 steps/s (collection: 1.829s, learning 0.090s)
             Mean action noise std: 1.52
          Mean value_function loss: 66.3206
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.3727
                       Mean reward: 109.76
               Mean episode length: 214.04
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 22.1957
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.92s
                      Time elapsed: 00:07:02
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 50501 steps/s (collection: 1.852s, learning 0.095s)
             Mean action noise std: 1.52
          Mean value_function loss: 66.4516
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 40.3995
                       Mean reward: 95.65
               Mean episode length: 224.72
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 18.9931
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.95s
                      Time elapsed: 00:07:04
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 50316 steps/s (collection: 1.862s, learning 0.092s)
             Mean action noise std: 1.53
          Mean value_function loss: 60.2784
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 40.4255
                       Mean reward: 94.36
               Mean episode length: 224.88
    Episode_Reward/reaching_object: 0.6745
    Episode_Reward/rotating_object: 19.5691
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.95s
                      Time elapsed: 00:07:06
                               ETA: 00:46:00

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 50463 steps/s (collection: 1.850s, learning 0.098s)
             Mean action noise std: 1.53
          Mean value_function loss: 55.8810
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.4569
                       Mean reward: 111.57
               Mean episode length: 218.99
    Episode_Reward/reaching_object: 0.6549
    Episode_Reward/rotating_object: 18.7156
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.95s
                      Time elapsed: 00:07:08
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 50672 steps/s (collection: 1.839s, learning 0.101s)
             Mean action noise std: 1.53
          Mean value_function loss: 55.1622
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 40.4805
                       Mean reward: 121.97
               Mean episode length: 223.96
    Episode_Reward/reaching_object: 0.6953
    Episode_Reward/rotating_object: 23.7304
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.94s
                      Time elapsed: 00:07:10
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 49438 steps/s (collection: 1.859s, learning 0.129s)
             Mean action noise std: 1.53
          Mean value_function loss: 58.0865
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 40.5040
                       Mean reward: 119.89
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 0.6900
    Episode_Reward/rotating_object: 22.5370
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.99s
                      Time elapsed: 00:07:12
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 49835 steps/s (collection: 1.859s, learning 0.114s)
             Mean action noise std: 1.53
          Mean value_function loss: 56.3695
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 40.5283
                       Mean reward: 128.22
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 0.7028
    Episode_Reward/rotating_object: 21.4031
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.97s
                      Time elapsed: 00:07:14
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 48883 steps/s (collection: 1.903s, learning 0.108s)
             Mean action noise std: 1.54
          Mean value_function loss: 53.1412
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 40.5516
                       Mean reward: 112.65
               Mean episode length: 221.03
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 21.5351
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.01s
                      Time elapsed: 00:07:16
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 49703 steps/s (collection: 1.857s, learning 0.121s)
             Mean action noise std: 1.54
          Mean value_function loss: 53.6871
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.5735
                       Mean reward: 115.56
               Mean episode length: 220.56
    Episode_Reward/reaching_object: 0.6762
    Episode_Reward/rotating_object: 21.5220
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.98s
                      Time elapsed: 00:07:18
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 50186 steps/s (collection: 1.859s, learning 0.100s)
             Mean action noise std: 1.54
          Mean value_function loss: 53.9696
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 40.5952
                       Mean reward: 105.63
               Mean episode length: 213.57
    Episode_Reward/reaching_object: 0.6885
    Episode_Reward/rotating_object: 22.1914
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.96s
                      Time elapsed: 00:07:20
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 50510 steps/s (collection: 1.852s, learning 0.094s)
             Mean action noise std: 1.54
          Mean value_function loss: 53.4453
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.6328
                       Mean reward: 106.32
               Mean episode length: 213.09
    Episode_Reward/reaching_object: 0.7012
    Episode_Reward/rotating_object: 22.8744
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.95s
                      Time elapsed: 00:07:22
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 50073 steps/s (collection: 1.862s, learning 0.102s)
             Mean action noise std: 1.54
          Mean value_function loss: 64.0499
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 40.6770
                       Mean reward: 136.75
               Mean episode length: 218.96
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 22.1127
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 6.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.96s
                      Time elapsed: 00:07:24
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 50505 steps/s (collection: 1.850s, learning 0.096s)
             Mean action noise std: 1.55
          Mean value_function loss: 62.6663
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.7070
                       Mean reward: 112.92
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 0.6830
    Episode_Reward/rotating_object: 22.7052
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.95s
                      Time elapsed: 00:07:26
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 48506 steps/s (collection: 1.936s, learning 0.091s)
             Mean action noise std: 1.55
          Mean value_function loss: 62.0692
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 40.7410
                       Mean reward: 115.88
               Mean episode length: 215.87
    Episode_Reward/reaching_object: 0.6957
    Episode_Reward/rotating_object: 22.8170
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.03s
                      Time elapsed: 00:07:28
                               ETA: 00:45:27

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 49231 steps/s (collection: 1.886s, learning 0.111s)
             Mean action noise std: 1.55
          Mean value_function loss: 57.0761
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 40.7691
                       Mean reward: 115.44
               Mean episode length: 207.44
    Episode_Reward/reaching_object: 0.6709
    Episode_Reward/rotating_object: 24.9161
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.00s
                      Time elapsed: 00:07:30
                               ETA: 00:45:24

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 46286 steps/s (collection: 2.020s, learning 0.104s)
             Mean action noise std: 1.55
          Mean value_function loss: 58.6653
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.7934
                       Mean reward: 107.16
               Mean episode length: 205.07
    Episode_Reward/reaching_object: 0.6475
    Episode_Reward/rotating_object: 19.3878
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.12s
                      Time elapsed: 00:07:32
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 50123 steps/s (collection: 1.864s, learning 0.097s)
             Mean action noise std: 1.56
          Mean value_function loss: 59.1330
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.8187
                       Mean reward: 120.20
               Mean episode length: 218.26
    Episode_Reward/reaching_object: 0.6911
    Episode_Reward/rotating_object: 23.5375
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.96s
                      Time elapsed: 00:07:34
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 50202 steps/s (collection: 1.862s, learning 0.097s)
             Mean action noise std: 1.56
          Mean value_function loss: 56.8055
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 40.8481
                       Mean reward: 114.60
               Mean episode length: 221.92
    Episode_Reward/reaching_object: 0.7107
    Episode_Reward/rotating_object: 25.2069
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.96s
                      Time elapsed: 00:07:36
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 48674 steps/s (collection: 1.921s, learning 0.098s)
             Mean action noise std: 1.56
          Mean value_function loss: 54.8865
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.8673
                       Mean reward: 159.29
               Mean episode length: 224.44
    Episode_Reward/reaching_object: 0.6989
    Episode_Reward/rotating_object: 24.5727
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.02s
                      Time elapsed: 00:07:38
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 49688 steps/s (collection: 1.886s, learning 0.092s)
             Mean action noise std: 1.56
          Mean value_function loss: 52.1251
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.8867
                       Mean reward: 109.36
               Mean episode length: 221.57
    Episode_Reward/reaching_object: 0.7028
    Episode_Reward/rotating_object: 24.3380
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.98s
                      Time elapsed: 00:07:40
                               ETA: 00:45:10

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 48513 steps/s (collection: 1.929s, learning 0.097s)
             Mean action noise std: 1.56
          Mean value_function loss: 58.3125
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.9162
                       Mean reward: 120.62
               Mean episode length: 204.98
    Episode_Reward/reaching_object: 0.6749
    Episode_Reward/rotating_object: 22.7005
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.03s
                      Time elapsed: 00:07:42
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 46300 steps/s (collection: 2.000s, learning 0.123s)
             Mean action noise std: 1.56
          Mean value_function loss: 60.2659
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.9511
                       Mean reward: 147.51
               Mean episode length: 217.45
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 24.5024
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.12s
                      Time elapsed: 00:07:44
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 47142 steps/s (collection: 1.981s, learning 0.105s)
             Mean action noise std: 1.57
          Mean value_function loss: 60.0759
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.9699
                       Mean reward: 96.55
               Mean episode length: 208.29
    Episode_Reward/reaching_object: 0.7212
    Episode_Reward/rotating_object: 26.2251
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.09s
                      Time elapsed: 00:07:46
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 48927 steps/s (collection: 1.894s, learning 0.115s)
             Mean action noise std: 1.57
          Mean value_function loss: 65.8056
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.9922
                       Mean reward: 162.75
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 26.3828
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.01s
                      Time elapsed: 00:07:48
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 40531 steps/s (collection: 2.307s, learning 0.119s)
             Mean action noise std: 1.57
          Mean value_function loss: 66.5413
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.0180
                       Mean reward: 100.59
               Mean episode length: 198.87
    Episode_Reward/reaching_object: 0.6796
    Episode_Reward/rotating_object: 24.7203
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.43s
                      Time elapsed: 00:07:51
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 33982 steps/s (collection: 2.758s, learning 0.135s)
             Mean action noise std: 1.57
          Mean value_function loss: 66.1319
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 41.0515
                       Mean reward: 132.30
               Mean episode length: 221.37
    Episode_Reward/reaching_object: 0.7176
    Episode_Reward/rotating_object: 29.7973
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.89s
                      Time elapsed: 00:07:54
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 45975 steps/s (collection: 2.037s, learning 0.101s)
             Mean action noise std: 1.57
          Mean value_function loss: 65.3364
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 41.0815
                       Mean reward: 170.52
               Mean episode length: 212.67
    Episode_Reward/reaching_object: 0.7023
    Episode_Reward/rotating_object: 27.1355
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.14s
                      Time elapsed: 00:07:56
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 46501 steps/s (collection: 2.019s, learning 0.095s)
             Mean action noise std: 1.58
          Mean value_function loss: 63.8756
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 41.1069
                       Mean reward: 126.38
               Mean episode length: 206.60
    Episode_Reward/reaching_object: 0.6642
    Episode_Reward/rotating_object: 24.6328
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.11s
                      Time elapsed: 00:07:58
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 48954 steps/s (collection: 1.913s, learning 0.095s)
             Mean action noise std: 1.58
          Mean value_function loss: 65.3071
               Mean surrogate loss: 0.0023
                 Mean entropy loss: 41.1249
                       Mean reward: 136.56
               Mean episode length: 203.35
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 28.2856
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 11.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.01s
                      Time elapsed: 00:08:00
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 49403 steps/s (collection: 1.900s, learning 0.089s)
             Mean action noise std: 1.58
          Mean value_function loss: 57.0376
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 41.1286
                       Mean reward: 124.84
               Mean episode length: 198.29
    Episode_Reward/reaching_object: 0.6956
    Episode_Reward/rotating_object: 27.4198
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 11.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.99s
                      Time elapsed: 00:08:02
                               ETA: 00:44:53

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 49719 steps/s (collection: 1.887s, learning 0.090s)
             Mean action noise std: 1.58
          Mean value_function loss: 53.5595
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.1321
                       Mean reward: 158.30
               Mean episode length: 220.47
    Episode_Reward/reaching_object: 0.6921
    Episode_Reward/rotating_object: 27.2367
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.98s
                      Time elapsed: 00:08:04
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 49785 steps/s (collection: 1.886s, learning 0.089s)
             Mean action noise std: 1.58
          Mean value_function loss: 57.2345
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 41.1413
                       Mean reward: 147.35
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 28.3400
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.97s
                      Time elapsed: 00:08:06
                               ETA: 00:44:47

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 49366 steps/s (collection: 1.885s, learning 0.106s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.4992
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.1618
                       Mean reward: 138.57
               Mean episode length: 206.94
    Episode_Reward/reaching_object: 0.6846
    Episode_Reward/rotating_object: 28.7271
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.99s
                      Time elapsed: 00:08:08
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 47337 steps/s (collection: 1.976s, learning 0.101s)
             Mean action noise std: 1.58
          Mean value_function loss: 65.2143
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.1918
                       Mean reward: 135.06
               Mean episode length: 213.37
    Episode_Reward/reaching_object: 0.6740
    Episode_Reward/rotating_object: 27.3721
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.08s
                      Time elapsed: 00:08:10
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 48718 steps/s (collection: 1.911s, learning 0.107s)
             Mean action noise std: 1.58
          Mean value_function loss: 67.0742
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 41.2221
                       Mean reward: 121.11
               Mean episode length: 207.72
    Episode_Reward/reaching_object: 0.6777
    Episode_Reward/rotating_object: 27.7202
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.02s
                      Time elapsed: 00:08:12
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 48199 steps/s (collection: 1.934s, learning 0.105s)
             Mean action noise std: 1.59
          Mean value_function loss: 68.0915
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.2551
                       Mean reward: 156.66
               Mean episode length: 221.82
    Episode_Reward/reaching_object: 0.6821
    Episode_Reward/rotating_object: 28.7226
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.04s
                      Time elapsed: 00:08:14
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 47616 steps/s (collection: 1.950s, learning 0.115s)
             Mean action noise std: 1.59
          Mean value_function loss: 78.9629
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.2835
                       Mean reward: 169.26
               Mean episode length: 212.92
    Episode_Reward/reaching_object: 0.6674
    Episode_Reward/rotating_object: 28.4341
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.06s
                      Time elapsed: 00:08:16
                               ETA: 00:44:34

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 47737 steps/s (collection: 1.946s, learning 0.114s)
             Mean action noise std: 1.59
          Mean value_function loss: 75.1316
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 41.3074
                       Mean reward: 152.39
               Mean episode length: 216.12
    Episode_Reward/reaching_object: 0.6805
    Episode_Reward/rotating_object: 28.7944
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.06s
                      Time elapsed: 00:08:18
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 47511 steps/s (collection: 1.966s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 74.2706
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 41.3361
                       Mean reward: 154.38
               Mean episode length: 201.64
    Episode_Reward/reaching_object: 0.6988
    Episode_Reward/rotating_object: 32.1794
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.07s
                      Time elapsed: 00:08:20
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 47006 steps/s (collection: 1.995s, learning 0.097s)
             Mean action noise std: 1.59
          Mean value_function loss: 75.8784
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 41.3680
                       Mean reward: 113.94
               Mean episode length: 198.78
    Episode_Reward/reaching_object: 0.6574
    Episode_Reward/rotating_object: 28.1411
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.09s
                      Time elapsed: 00:08:22
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 47763 steps/s (collection: 1.958s, learning 0.101s)
             Mean action noise std: 1.60
          Mean value_function loss: 71.3864
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.3875
                       Mean reward: 170.22
               Mean episode length: 212.53
    Episode_Reward/reaching_object: 0.7027
    Episode_Reward/rotating_object: 35.7713
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.06s
                      Time elapsed: 00:08:24
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 41763 steps/s (collection: 2.048s, learning 0.306s)
             Mean action noise std: 1.60
          Mean value_function loss: 74.2276
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.4109
                       Mean reward: 165.48
               Mean episode length: 218.72
    Episode_Reward/reaching_object: 0.7059
    Episode_Reward/rotating_object: 29.5445
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.35s
                      Time elapsed: 00:08:27
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 35400 steps/s (collection: 2.598s, learning 0.179s)
             Mean action noise std: 1.60
          Mean value_function loss: 78.5781
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 41.4342
                       Mean reward: 184.03
               Mean episode length: 210.31
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 33.2381
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.78s
                      Time elapsed: 00:08:29
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 43456 steps/s (collection: 2.159s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 75.9094
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.4526
                       Mean reward: 134.98
               Mean episode length: 197.59
    Episode_Reward/reaching_object: 0.6951
    Episode_Reward/rotating_object: 33.1563
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.26s
                      Time elapsed: 00:08:32
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 48033 steps/s (collection: 1.952s, learning 0.095s)
             Mean action noise std: 1.60
          Mean value_function loss: 79.3347
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.4671
                       Mean reward: 135.36
               Mean episode length: 212.89
    Episode_Reward/reaching_object: 0.6952
    Episode_Reward/rotating_object: 32.4586
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.05s
                      Time elapsed: 00:08:34
                               ETA: 00:44:22

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 47743 steps/s (collection: 1.958s, learning 0.101s)
             Mean action noise std: 1.60
          Mean value_function loss: 76.4127
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.4822
                       Mean reward: 164.11
               Mean episode length: 204.76
    Episode_Reward/reaching_object: 0.7025
    Episode_Reward/rotating_object: 34.0743
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.06s
                      Time elapsed: 00:08:36
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 49409 steps/s (collection: 1.899s, learning 0.091s)
             Mean action noise std: 1.61
          Mean value_function loss: 82.0153
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.5099
                       Mean reward: 179.11
               Mean episode length: 216.59
    Episode_Reward/reaching_object: 0.6945
    Episode_Reward/rotating_object: 33.0490
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.99s
                      Time elapsed: 00:08:38
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 49639 steps/s (collection: 1.889s, learning 0.092s)
             Mean action noise std: 1.61
          Mean value_function loss: 83.1662
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 41.5349
                       Mean reward: 206.10
               Mean episode length: 213.83
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 37.2643
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.98s
                      Time elapsed: 00:08:40
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 49049 steps/s (collection: 1.912s, learning 0.093s)
             Mean action noise std: 1.61
          Mean value_function loss: 83.0327
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 41.5572
                       Mean reward: 163.92
               Mean episode length: 212.35
    Episode_Reward/reaching_object: 0.7238
    Episode_Reward/rotating_object: 33.1703
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.00s
                      Time elapsed: 00:08:42
                               ETA: 00:44:11

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 48551 steps/s (collection: 1.908s, learning 0.117s)
             Mean action noise std: 1.61
          Mean value_function loss: 79.8341
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 41.5840
                       Mean reward: 176.49
               Mean episode length: 213.16
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 35.6556
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.02s
                      Time elapsed: 00:08:44
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 47539 steps/s (collection: 1.964s, learning 0.104s)
             Mean action noise std: 1.61
          Mean value_function loss: 83.4902
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 41.6069
                       Mean reward: 169.90
               Mean episode length: 215.74
    Episode_Reward/reaching_object: 0.7077
    Episode_Reward/rotating_object: 33.7654
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.07s
                      Time elapsed: 00:08:46
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 48026 steps/s (collection: 1.946s, learning 0.101s)
             Mean action noise std: 1.61
          Mean value_function loss: 89.3373
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 41.6241
                       Mean reward: 178.62
               Mean episode length: 208.42
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 37.2442
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.05s
                      Time elapsed: 00:08:48
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 47152 steps/s (collection: 1.995s, learning 0.090s)
             Mean action noise std: 1.62
          Mean value_function loss: 102.0292
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 41.6451
                       Mean reward: 195.80
               Mean episode length: 218.44
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 37.2340
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.08s
                      Time elapsed: 00:08:50
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 47678 steps/s (collection: 1.965s, learning 0.097s)
             Mean action noise std: 1.62
          Mean value_function loss: 100.4670
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.6695
                       Mean reward: 182.57
               Mean episode length: 218.37
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 37.2155
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.06s
                      Time elapsed: 00:08:52
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 48046 steps/s (collection: 1.940s, learning 0.106s)
             Mean action noise std: 1.62
          Mean value_function loss: 97.2019
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 41.6896
                       Mean reward: 182.41
               Mean episode length: 217.50
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 34.0723
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.05s
                      Time elapsed: 00:08:54
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 45010 steps/s (collection: 2.088s, learning 0.097s)
             Mean action noise std: 1.62
          Mean value_function loss: 89.0601
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 41.7072
                       Mean reward: 185.96
               Mean episode length: 218.17
    Episode_Reward/reaching_object: 0.7543
    Episode_Reward/rotating_object: 37.6242
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.18s
                      Time elapsed: 00:08:56
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 46811 steps/s (collection: 2.002s, learning 0.098s)
             Mean action noise std: 1.62
          Mean value_function loss: 88.1244
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.7326
                       Mean reward: 169.44
               Mean episode length: 211.16
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 37.9989
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.10s
                      Time elapsed: 00:08:58
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 44854 steps/s (collection: 2.089s, learning 0.103s)
             Mean action noise std: 1.62
          Mean value_function loss: 88.2442
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.7601
                       Mean reward: 209.95
               Mean episode length: 224.26
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 35.4229
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.19s
                      Time elapsed: 00:09:01
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 48901 steps/s (collection: 1.910s, learning 0.101s)
             Mean action noise std: 1.63
          Mean value_function loss: 77.2554
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.7767
                       Mean reward: 202.22
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 0.7884
    Episode_Reward/rotating_object: 40.7618
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.01s
                      Time elapsed: 00:09:03
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 46567 steps/s (collection: 2.008s, learning 0.103s)
             Mean action noise std: 1.63
          Mean value_function loss: 87.5735
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 41.8049
                       Mean reward: 201.49
               Mean episode length: 227.81
    Episode_Reward/reaching_object: 0.7619
    Episode_Reward/rotating_object: 38.0915
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.11s
                      Time elapsed: 00:09:05
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 48341 steps/s (collection: 1.930s, learning 0.103s)
             Mean action noise std: 1.63
          Mean value_function loss: 84.5366
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.8290
                       Mean reward: 182.96
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 36.4272
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.03s
                      Time elapsed: 00:09:07
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 48469 steps/s (collection: 1.927s, learning 0.102s)
             Mean action noise std: 1.63
          Mean value_function loss: 81.6312
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 41.8489
                       Mean reward: 170.58
               Mean episode length: 209.65
    Episode_Reward/reaching_object: 0.7688
    Episode_Reward/rotating_object: 39.4373
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.03s
                      Time elapsed: 00:09:09
                               ETA: 00:43:41

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 48681 steps/s (collection: 1.926s, learning 0.094s)
             Mean action noise std: 1.63
          Mean value_function loss: 86.2162
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 41.8650
                       Mean reward: 176.24
               Mean episode length: 222.96
    Episode_Reward/reaching_object: 0.7483
    Episode_Reward/rotating_object: 39.3066
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.02s
                      Time elapsed: 00:09:11
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 49205 steps/s (collection: 1.900s, learning 0.097s)
             Mean action noise std: 1.63
          Mean value_function loss: 100.0159
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.8813
                       Mean reward: 202.23
               Mean episode length: 220.17
    Episode_Reward/reaching_object: 0.7605
    Episode_Reward/rotating_object: 38.0113
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.00s
                      Time elapsed: 00:09:13
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 46593 steps/s (collection: 1.969s, learning 0.141s)
             Mean action noise std: 1.63
          Mean value_function loss: 105.1265
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 41.8961
                       Mean reward: 188.97
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 0.7550
    Episode_Reward/rotating_object: 43.2340
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.11s
                      Time elapsed: 00:09:15
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 45053 steps/s (collection: 2.077s, learning 0.105s)
             Mean action noise std: 1.64
          Mean value_function loss: 100.9663
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 41.9129
                       Mean reward: 187.34
               Mean episode length: 221.88
    Episode_Reward/reaching_object: 0.7593
    Episode_Reward/rotating_object: 41.0792
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.18s
                      Time elapsed: 00:09:17
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 48396 steps/s (collection: 1.927s, learning 0.104s)
             Mean action noise std: 1.64
          Mean value_function loss: 98.8359
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.9362
                       Mean reward: 209.47
               Mean episode length: 216.52
    Episode_Reward/reaching_object: 0.7702
    Episode_Reward/rotating_object: 40.3118
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.03s
                      Time elapsed: 00:09:19
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 46485 steps/s (collection: 1.982s, learning 0.132s)
             Mean action noise std: 1.64
          Mean value_function loss: 104.6910
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.9602
                       Mean reward: 200.84
               Mean episode length: 223.46
    Episode_Reward/reaching_object: 0.7865
    Episode_Reward/rotating_object: 43.7454
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.11s
                      Time elapsed: 00:09:21
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 40103 steps/s (collection: 2.313s, learning 0.139s)
             Mean action noise std: 1.64
          Mean value_function loss: 99.7783
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 41.9772
                       Mean reward: 216.63
               Mean episode length: 226.59
    Episode_Reward/reaching_object: 0.7979
    Episode_Reward/rotating_object: 42.3975
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.45s
                      Time elapsed: 00:09:24
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 42935 steps/s (collection: 2.045s, learning 0.245s)
             Mean action noise std: 1.64
          Mean value_function loss: 111.6577
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.9966
                       Mean reward: 209.07
               Mean episode length: 212.95
    Episode_Reward/reaching_object: 0.7798
    Episode_Reward/rotating_object: 39.9809
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.29s
                      Time elapsed: 00:09:26
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 43823 steps/s (collection: 2.110s, learning 0.133s)
             Mean action noise std: 1.64
          Mean value_function loss: 105.4455
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.0100
                       Mean reward: 222.20
               Mean episode length: 221.60
    Episode_Reward/reaching_object: 0.7903
    Episode_Reward/rotating_object: 40.7293
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.24s
                      Time elapsed: 00:09:28
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 40799 steps/s (collection: 2.291s, learning 0.118s)
             Mean action noise std: 1.65
          Mean value_function loss: 100.0780
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 42.0266
                       Mean reward: 264.18
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 0.7889
    Episode_Reward/rotating_object: 41.8056
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.41s
                      Time elapsed: 00:09:31
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 44872 steps/s (collection: 2.081s, learning 0.110s)
             Mean action noise std: 1.65
          Mean value_function loss: 90.6122
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.0430
                       Mean reward: 233.84
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 0.8069
    Episode_Reward/rotating_object: 46.5554
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.19s
                      Time elapsed: 00:09:33
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 43372 steps/s (collection: 2.046s, learning 0.220s)
             Mean action noise std: 1.65
          Mean value_function loss: 88.3475
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 42.0599
                       Mean reward: 256.70
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 0.8241
    Episode_Reward/rotating_object: 50.0136
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.27s
                      Time elapsed: 00:09:35
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 46826 steps/s (collection: 2.002s, learning 0.098s)
             Mean action noise std: 1.65
          Mean value_function loss: 89.1572
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 42.0783
                       Mean reward: 194.31
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 0.7921
    Episode_Reward/rotating_object: 44.5109
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.10s
                      Time elapsed: 00:09:37
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 44500 steps/s (collection: 2.116s, learning 0.093s)
             Mean action noise std: 1.65
          Mean value_function loss: 77.8031
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 42.0956
                       Mean reward: 231.32
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 0.8043
    Episode_Reward/rotating_object: 46.1066
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.21s
                      Time elapsed: 00:09:39
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 46358 steps/s (collection: 2.021s, learning 0.100s)
             Mean action noise std: 1.65
          Mean value_function loss: 88.7229
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 42.1264
                       Mean reward: 215.11
               Mean episode length: 219.42
    Episode_Reward/reaching_object: 0.7663
    Episode_Reward/rotating_object: 43.1634
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.12s
                      Time elapsed: 00:09:41
                               ETA: 00:43:14

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 46261 steps/s (collection: 2.030s, learning 0.095s)
             Mean action noise std: 1.65
          Mean value_function loss: 81.3955
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.1517
                       Mean reward: 255.01
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 0.7904
    Episode_Reward/rotating_object: 47.2420
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.12s
                      Time elapsed: 00:09:44
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 45922 steps/s (collection: 2.039s, learning 0.102s)
             Mean action noise std: 1.66
          Mean value_function loss: 93.8301
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.1665
                       Mean reward: 256.39
               Mean episode length: 212.59
    Episode_Reward/reaching_object: 0.7722
    Episode_Reward/rotating_object: 48.6037
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.14s
                      Time elapsed: 00:09:46
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 46622 steps/s (collection: 1.988s, learning 0.121s)
             Mean action noise std: 1.66
          Mean value_function loss: 99.0969
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.1812
                       Mean reward: 236.70
               Mean episode length: 216.91
    Episode_Reward/reaching_object: 0.7980
    Episode_Reward/rotating_object: 49.4546
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.11s
                      Time elapsed: 00:09:48
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 44553 steps/s (collection: 2.092s, learning 0.114s)
             Mean action noise std: 1.66
          Mean value_function loss: 95.1797
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 42.1944
                       Mean reward: 244.90
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 0.7644
    Episode_Reward/rotating_object: 46.7649
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.21s
                      Time elapsed: 00:09:50
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 46257 steps/s (collection: 2.027s, learning 0.099s)
             Mean action noise std: 1.66
          Mean value_function loss: 106.8352
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 42.2130
                       Mean reward: 250.74
               Mean episode length: 224.23
    Episode_Reward/reaching_object: 0.7841
    Episode_Reward/rotating_object: 47.4575
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.13s
                      Time elapsed: 00:09:52
                               ETA: 00:43:04

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 45768 steps/s (collection: 2.052s, learning 0.096s)
             Mean action noise std: 1.66
          Mean value_function loss: 111.6850
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 42.2343
                       Mean reward: 254.07
               Mean episode length: 218.00
    Episode_Reward/reaching_object: 0.7722
    Episode_Reward/rotating_object: 45.7365
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.15s
                      Time elapsed: 00:09:54
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 45318 steps/s (collection: 2.072s, learning 0.097s)
             Mean action noise std: 1.66
          Mean value_function loss: 118.3807
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 42.2457
                       Mean reward: 232.74
               Mean episode length: 217.30
    Episode_Reward/reaching_object: 0.7717
    Episode_Reward/rotating_object: 46.7929
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.17s
                      Time elapsed: 00:09:57
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 47817 steps/s (collection: 1.964s, learning 0.092s)
             Mean action noise std: 1.66
          Mean value_function loss: 116.6151
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 42.2622
                       Mean reward: 285.98
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 0.8167
    Episode_Reward/rotating_object: 51.4002
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.06s
                      Time elapsed: 00:09:59
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 46557 steps/s (collection: 2.009s, learning 0.102s)
             Mean action noise std: 1.66
          Mean value_function loss: 117.8213
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.2814
                       Mean reward: 246.47
               Mean episode length: 212.00
    Episode_Reward/reaching_object: 0.8093
    Episode_Reward/rotating_object: 51.2325
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.11s
                      Time elapsed: 00:10:01
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 44486 steps/s (collection: 2.108s, learning 0.102s)
             Mean action noise std: 1.67
          Mean value_function loss: 109.2492
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 42.2961
                       Mean reward: 260.16
               Mean episode length: 225.18
    Episode_Reward/reaching_object: 0.8142
    Episode_Reward/rotating_object: 49.6485
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.21s
                      Time elapsed: 00:10:03
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 46837 steps/s (collection: 1.999s, learning 0.100s)
             Mean action noise std: 1.67
          Mean value_function loss: 94.2617
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.3203
                       Mean reward: 274.87
               Mean episode length: 224.35
    Episode_Reward/reaching_object: 0.8233
    Episode_Reward/rotating_object: 51.6884
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.10s
                      Time elapsed: 00:10:05
                               ETA: 00:42:52

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 48271 steps/s (collection: 1.936s, learning 0.100s)
             Mean action noise std: 1.67
          Mean value_function loss: 109.6264
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.3447
                       Mean reward: 227.37
               Mean episode length: 205.18
    Episode_Reward/reaching_object: 0.8003
    Episode_Reward/rotating_object: 52.1107
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.04s
                      Time elapsed: 00:10:07
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 48060 steps/s (collection: 1.944s, learning 0.102s)
             Mean action noise std: 1.67
          Mean value_function loss: 113.5295
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.3594
                       Mean reward: 277.31
               Mean episode length: 221.16
    Episode_Reward/reaching_object: 0.8056
    Episode_Reward/rotating_object: 52.4731
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.05s
                      Time elapsed: 00:10:09
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 47331 steps/s (collection: 1.966s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 117.5676
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 42.3751
                       Mean reward: 270.64
               Mean episode length: 216.03
    Episode_Reward/reaching_object: 0.8052
    Episode_Reward/rotating_object: 51.4978
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.08s
                      Time elapsed: 00:10:11
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 48393 steps/s (collection: 1.934s, learning 0.098s)
             Mean action noise std: 1.67
          Mean value_function loss: 121.3221
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.3937
                       Mean reward: 220.52
               Mean episode length: 213.17
    Episode_Reward/reaching_object: 0.8052
    Episode_Reward/rotating_object: 49.6153
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.03s
                      Time elapsed: 00:10:13
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 47105 steps/s (collection: 1.971s, learning 0.116s)
             Mean action noise std: 1.68
          Mean value_function loss: 103.2025
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.4093
                       Mean reward: 283.96
               Mean episode length: 218.23
    Episode_Reward/reaching_object: 0.8510
    Episode_Reward/rotating_object: 59.4929
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.09s
                      Time elapsed: 00:10:15
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 46754 steps/s (collection: 1.994s, learning 0.109s)
             Mean action noise std: 1.68
          Mean value_function loss: 94.5871
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 42.4244
                       Mean reward: 240.72
               Mean episode length: 215.15
    Episode_Reward/reaching_object: 0.7838
    Episode_Reward/rotating_object: 48.4874
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.10s
                      Time elapsed: 00:10:17
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 48333 steps/s (collection: 1.927s, learning 0.107s)
             Mean action noise std: 1.68
          Mean value_function loss: 83.5816
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 42.4364
                       Mean reward: 271.06
               Mean episode length: 218.03
    Episode_Reward/reaching_object: 0.8240
    Episode_Reward/rotating_object: 54.1796
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.03s
                      Time elapsed: 00:10:19
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 47106 steps/s (collection: 1.986s, learning 0.101s)
             Mean action noise std: 1.68
          Mean value_function loss: 86.8615
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.4569
                       Mean reward: 288.05
               Mean episode length: 214.75
    Episode_Reward/reaching_object: 0.7921
    Episode_Reward/rotating_object: 52.0868
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.09s
                      Time elapsed: 00:10:21
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 47341 steps/s (collection: 1.970s, learning 0.106s)
             Mean action noise std: 1.68
          Mean value_function loss: 83.0887
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.4715
                       Mean reward: 279.21
               Mean episode length: 215.27
    Episode_Reward/reaching_object: 0.7835
    Episode_Reward/rotating_object: 49.8390
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.08s
                      Time elapsed: 00:10:24
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 46702 steps/s (collection: 2.007s, learning 0.098s)
             Mean action noise std: 1.68
          Mean value_function loss: 104.5546
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.4781
                       Mean reward: 242.64
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 0.8169
    Episode_Reward/rotating_object: 49.5542
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.10s
                      Time elapsed: 00:10:26
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 47430 steps/s (collection: 1.975s, learning 0.098s)
             Mean action noise std: 1.68
          Mean value_function loss: 109.5637
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.4933
                       Mean reward: 293.07
               Mean episode length: 226.71
    Episode_Reward/reaching_object: 0.8119
    Episode_Reward/rotating_object: 55.7361
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.07s
                      Time elapsed: 00:10:28
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 46024 steps/s (collection: 2.035s, learning 0.101s)
             Mean action noise std: 1.68
          Mean value_function loss: 112.4929
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.5076
                       Mean reward: 273.96
               Mean episode length: 220.68
    Episode_Reward/reaching_object: 0.8120
    Episode_Reward/rotating_object: 53.6246
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.14s
                      Time elapsed: 00:10:30
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 45585 steps/s (collection: 2.054s, learning 0.103s)
             Mean action noise std: 1.68
          Mean value_function loss: 109.5908
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 42.5168
                       Mean reward: 299.47
               Mean episode length: 217.69
    Episode_Reward/reaching_object: 0.8144
    Episode_Reward/rotating_object: 59.3432
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.16s
                      Time elapsed: 00:10:32
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 43068 steps/s (collection: 2.142s, learning 0.140s)
             Mean action noise std: 1.69
          Mean value_function loss: 109.6648
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.5338
                       Mean reward: 305.08
               Mean episode length: 219.66
    Episode_Reward/reaching_object: 0.8256
    Episode_Reward/rotating_object: 54.3923
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.28s
                      Time elapsed: 00:10:34
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 41843 steps/s (collection: 2.189s, learning 0.161s)
             Mean action noise std: 1.69
          Mean value_function loss: 99.7056
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 42.5495
                       Mean reward: 288.00
               Mean episode length: 218.41
    Episode_Reward/reaching_object: 0.8114
    Episode_Reward/rotating_object: 56.2677
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.35s
                      Time elapsed: 00:10:37
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 42394 steps/s (collection: 2.215s, learning 0.104s)
             Mean action noise std: 1.69
          Mean value_function loss: 93.7019
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 42.5653
                       Mean reward: 283.88
               Mean episode length: 220.33
    Episode_Reward/reaching_object: 0.8472
    Episode_Reward/rotating_object: 60.5914
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.32s
                      Time elapsed: 00:10:39
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 42228 steps/s (collection: 2.172s, learning 0.156s)
             Mean action noise std: 1.69
          Mean value_function loss: 82.2077
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 42.5743
                       Mean reward: 316.35
               Mean episode length: 221.99
    Episode_Reward/reaching_object: 0.8362
    Episode_Reward/rotating_object: 57.5485
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.33s
                      Time elapsed: 00:10:41
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 43539 steps/s (collection: 2.119s, learning 0.139s)
             Mean action noise std: 1.69
          Mean value_function loss: 80.2692
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.5931
                       Mean reward: 243.79
               Mean episode length: 205.30
    Episode_Reward/reaching_object: 0.8310
    Episode_Reward/rotating_object: 53.1586
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.26s
                      Time elapsed: 00:10:44
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 42477 steps/s (collection: 2.176s, learning 0.138s)
             Mean action noise std: 1.69
          Mean value_function loss: 86.4972
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.6085
                       Mean reward: 297.36
               Mean episode length: 214.67
    Episode_Reward/reaching_object: 0.8244
    Episode_Reward/rotating_object: 59.1954
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.31s
                      Time elapsed: 00:10:46
                               ETA: 00:42:14

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 43634 steps/s (collection: 2.144s, learning 0.109s)
             Mean action noise std: 1.69
          Mean value_function loss: 82.0791
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.6166
                       Mean reward: 314.14
               Mean episode length: 221.49
    Episode_Reward/reaching_object: 0.8188
    Episode_Reward/rotating_object: 57.6646
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.25s
                      Time elapsed: 00:10:48
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 45438 steps/s (collection: 2.060s, learning 0.103s)
             Mean action noise std: 1.69
          Mean value_function loss: 86.0710
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 42.6243
                       Mean reward: 293.87
               Mean episode length: 216.00
    Episode_Reward/reaching_object: 0.8117
    Episode_Reward/rotating_object: 55.6340
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.16s
                      Time elapsed: 00:10:50
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 47446 steps/s (collection: 1.973s, learning 0.099s)
             Mean action noise std: 1.69
          Mean value_function loss: 92.9071
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.6370
                       Mean reward: 309.51
               Mean episode length: 214.54
    Episode_Reward/reaching_object: 0.8177
    Episode_Reward/rotating_object: 57.3273
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.07s
                      Time elapsed: 00:10:52
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 47459 steps/s (collection: 1.971s, learning 0.101s)
             Mean action noise std: 1.69
          Mean value_function loss: 93.2054
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 42.6493
                       Mean reward: 301.89
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 0.8229
    Episode_Reward/rotating_object: 61.0473
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.07s
                      Time elapsed: 00:10:54
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 47631 steps/s (collection: 1.964s, learning 0.100s)
             Mean action noise std: 1.70
          Mean value_function loss: 96.3192
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.6656
                       Mean reward: 343.72
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 0.8287
    Episode_Reward/rotating_object: 61.5192
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.06s
                      Time elapsed: 00:10:57
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 48286 steps/s (collection: 1.940s, learning 0.096s)
             Mean action noise std: 1.70
          Mean value_function loss: 87.8756
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 42.6769
                       Mean reward: 344.64
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 0.8510
    Episode_Reward/rotating_object: 63.7934
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.04s
                      Time elapsed: 00:10:59
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 49198 steps/s (collection: 1.903s, learning 0.095s)
             Mean action noise std: 1.70
          Mean value_function loss: 90.9475
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.6817
                       Mean reward: 262.38
               Mean episode length: 215.94
    Episode_Reward/reaching_object: 0.8239
    Episode_Reward/rotating_object: 60.1130
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.00s
                      Time elapsed: 00:11:01
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 48146 steps/s (collection: 1.946s, learning 0.096s)
             Mean action noise std: 1.70
          Mean value_function loss: 97.6324
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.6844
                       Mean reward: 334.34
               Mean episode length: 226.93
    Episode_Reward/reaching_object: 0.8359
    Episode_Reward/rotating_object: 61.2520
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.04s
                      Time elapsed: 00:11:03
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 47628 steps/s (collection: 1.971s, learning 0.093s)
             Mean action noise std: 1.70
          Mean value_function loss: 98.7171
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.6907
                       Mean reward: 334.57
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 0.8555
    Episode_Reward/rotating_object: 63.3218
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.06s
                      Time elapsed: 00:11:05
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 46474 steps/s (collection: 2.013s, learning 0.102s)
             Mean action noise std: 1.70
          Mean value_function loss: 101.0970
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 42.7040
                       Mean reward: 352.50
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 0.8693
    Episode_Reward/rotating_object: 65.6922
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.12s
                      Time elapsed: 00:11:07
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 48316 steps/s (collection: 1.936s, learning 0.099s)
             Mean action noise std: 1.70
          Mean value_function loss: 87.4100
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.7142
                       Mean reward: 326.84
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 0.8638
    Episode_Reward/rotating_object: 62.0639
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.03s
                      Time elapsed: 00:11:09
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 46428 steps/s (collection: 2.026s, learning 0.092s)
             Mean action noise std: 1.70
          Mean value_function loss: 86.1968
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.7275
                       Mean reward: 321.87
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 0.8580
    Episode_Reward/rotating_object: 64.8221
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.12s
                      Time elapsed: 00:11:11
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 48648 steps/s (collection: 1.930s, learning 0.091s)
             Mean action noise std: 1.70
          Mean value_function loss: 92.5659
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.7341
                       Mean reward: 351.61
               Mean episode length: 223.03
    Episode_Reward/reaching_object: 0.8566
    Episode_Reward/rotating_object: 65.9462
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.02s
                      Time elapsed: 00:11:13
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 47463 steps/s (collection: 1.961s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 92.4461
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.7430
                       Mean reward: 322.71
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 0.8487
    Episode_Reward/rotating_object: 63.5097
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.07s
                      Time elapsed: 00:11:15
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 47381 steps/s (collection: 1.961s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 96.5233
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.7573
                       Mean reward: 290.80
               Mean episode length: 222.43
    Episode_Reward/reaching_object: 0.8544
    Episode_Reward/rotating_object: 62.5881
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.07s
                      Time elapsed: 00:11:17
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 47630 steps/s (collection: 1.953s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 93.8400
               Mean surrogate loss: 0.0023
                 Mean entropy loss: 42.7693
                       Mean reward: 324.08
               Mean episode length: 223.73
    Episode_Reward/reaching_object: 0.8456
    Episode_Reward/rotating_object: 64.7021
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.06s
                      Time elapsed: 00:11:19
                               ETA: 00:41:38

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 47355 steps/s (collection: 1.970s, learning 0.106s)
             Mean action noise std: 1.70
          Mean value_function loss: 87.0186
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 42.7743
                       Mean reward: 328.11
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 0.8606
    Episode_Reward/rotating_object: 67.5226
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.08s
                      Time elapsed: 00:11:21
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 46828 steps/s (collection: 2.001s, learning 0.099s)
             Mean action noise std: 1.71
          Mean value_function loss: 88.1302
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 42.7880
                       Mean reward: 310.50
               Mean episode length: 227.73
    Episode_Reward/reaching_object: 0.8551
    Episode_Reward/rotating_object: 66.3423
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.10s
                      Time elapsed: 00:11:23
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 47129 steps/s (collection: 1.990s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 102.2747
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.8058
                       Mean reward: 317.80
               Mean episode length: 224.39
    Episode_Reward/reaching_object: 0.8580
    Episode_Reward/rotating_object: 68.2264
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.09s
                      Time elapsed: 00:11:25
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 47954 steps/s (collection: 1.957s, learning 0.093s)
             Mean action noise std: 1.71
          Mean value_function loss: 97.4469
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.8148
                       Mean reward: 335.40
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 0.8598
    Episode_Reward/rotating_object: 67.3778
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.05s
                      Time elapsed: 00:11:27
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 47512 steps/s (collection: 1.971s, learning 0.098s)
             Mean action noise std: 1.71
          Mean value_function loss: 89.4643
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 42.8255
                       Mean reward: 304.33
               Mean episode length: 216.25
    Episode_Reward/reaching_object: 0.8698
    Episode_Reward/rotating_object: 64.3411
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.07s
                      Time elapsed: 00:11:30
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 47495 steps/s (collection: 1.976s, learning 0.094s)
             Mean action noise std: 1.71
          Mean value_function loss: 106.2308
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.8437
                       Mean reward: 366.68
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.8846
    Episode_Reward/rotating_object: 69.2378
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.07s
                      Time elapsed: 00:11:32
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 46721 steps/s (collection: 2.010s, learning 0.094s)
             Mean action noise std: 1.71
          Mean value_function loss: 96.6626
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.8621
                       Mean reward: 371.01
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 0.8791
    Episode_Reward/rotating_object: 69.1333
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.10s
                      Time elapsed: 00:11:34
                               ETA: 00:41:22

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 47974 steps/s (collection: 1.954s, learning 0.095s)
             Mean action noise std: 1.71
          Mean value_function loss: 96.3040
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.8784
                       Mean reward: 374.91
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 0.8855
    Episode_Reward/rotating_object: 68.4825
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.05s
                      Time elapsed: 00:11:36
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 47518 steps/s (collection: 1.972s, learning 0.097s)
             Mean action noise std: 1.71
          Mean value_function loss: 93.9379
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.8862
                       Mean reward: 380.65
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 0.8739
    Episode_Reward/rotating_object: 68.3950
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.07s
                      Time elapsed: 00:11:38
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 47073 steps/s (collection: 1.992s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 79.8519
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.8943
                       Mean reward: 353.27
               Mean episode length: 226.30
    Episode_Reward/reaching_object: 0.8758
    Episode_Reward/rotating_object: 68.0779
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.09s
                      Time elapsed: 00:11:40
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 47491 steps/s (collection: 1.970s, learning 0.100s)
             Mean action noise std: 1.72
          Mean value_function loss: 88.5107
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.9104
                       Mean reward: 369.42
               Mean episode length: 223.51
    Episode_Reward/reaching_object: 0.8916
    Episode_Reward/rotating_object: 69.9290
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.07s
                      Time elapsed: 00:11:42
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 46751 steps/s (collection: 2.000s, learning 0.102s)
             Mean action noise std: 1.72
          Mean value_function loss: 101.2751
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.9295
                       Mean reward: 365.62
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 0.8653
    Episode_Reward/rotating_object: 68.5745
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.10s
                      Time elapsed: 00:11:44
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19796 steps/s (collection: 4.839s, learning 0.127s)
             Mean action noise std: 1.72
          Mean value_function loss: 97.6795
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 42.9465
                       Mean reward: 378.68
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.8615
    Episode_Reward/rotating_object: 67.1023
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 4.97s
                      Time elapsed: 00:11:49
                               ETA: 00:41:19

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14609 steps/s (collection: 6.594s, learning 0.135s)
             Mean action noise std: 1.72
          Mean value_function loss: 93.0641
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.9662
                       Mean reward: 320.98
               Mean episode length: 215.42
    Episode_Reward/reaching_object: 0.8534
    Episode_Reward/rotating_object: 66.0700
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.73s
                      Time elapsed: 00:11:56
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14368 steps/s (collection: 6.718s, learning 0.123s)
             Mean action noise std: 1.72
          Mean value_function loss: 102.7226
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 42.9825
                       Mean reward: 327.23
               Mean episode length: 219.93
    Episode_Reward/reaching_object: 0.8771
    Episode_Reward/rotating_object: 69.3748
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.84s
                      Time elapsed: 00:12:03
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14603 steps/s (collection: 6.591s, learning 0.140s)
             Mean action noise std: 1.72
          Mean value_function loss: 87.2179
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 42.9971
                       Mean reward: 378.87
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 0.8495
    Episode_Reward/rotating_object: 69.1330
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.73s
                      Time elapsed: 00:12:09
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14781 steps/s (collection: 6.530s, learning 0.120s)
             Mean action noise std: 1.72
          Mean value_function loss: 86.5033
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.0125
                       Mean reward: 344.44
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 0.8624
    Episode_Reward/rotating_object: 67.2906
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.65s
                      Time elapsed: 00:12:16
                               ETA: 00:42:14

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14644 steps/s (collection: 6.573s, learning 0.140s)
             Mean action noise std: 1.72
          Mean value_function loss: 93.8116
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.0266
                       Mean reward: 346.17
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 0.8388
    Episode_Reward/rotating_object: 66.3873
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.71s
                      Time elapsed: 00:12:23
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14987 steps/s (collection: 6.440s, learning 0.119s)
             Mean action noise std: 1.73
          Mean value_function loss: 90.4889
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.0355
                       Mean reward: 380.13
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 0.8505
    Episode_Reward/rotating_object: 67.0359
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.56s
                      Time elapsed: 00:12:29
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14835 steps/s (collection: 6.508s, learning 0.119s)
             Mean action noise std: 1.73
          Mean value_function loss: 106.2191
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.0493
                       Mean reward: 349.90
               Mean episode length: 219.77
    Episode_Reward/reaching_object: 0.8635
    Episode_Reward/rotating_object: 70.2785
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.63s
                      Time elapsed: 00:12:36
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13566 steps/s (collection: 7.142s, learning 0.104s)
             Mean action noise std: 1.73
          Mean value_function loss: 98.1408
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 43.0662
                       Mean reward: 346.87
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 0.8854
    Episode_Reward/rotating_object: 70.1010
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.25s
                      Time elapsed: 00:12:43
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 48073 steps/s (collection: 1.952s, learning 0.093s)
             Mean action noise std: 1.73
          Mean value_function loss: 94.6360
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.0767
                       Mean reward: 326.83
               Mean episode length: 212.75
    Episode_Reward/reaching_object: 0.8466
    Episode_Reward/rotating_object: 68.9220
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.04s
                      Time elapsed: 00:12:45
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 48512 steps/s (collection: 1.928s, learning 0.098s)
             Mean action noise std: 1.73
          Mean value_function loss: 102.3232
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.0840
                       Mean reward: 359.72
               Mean episode length: 224.62
    Episode_Reward/reaching_object: 0.8632
    Episode_Reward/rotating_object: 72.9196
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.03s
                      Time elapsed: 00:12:47
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 46876 steps/s (collection: 2.000s, learning 0.097s)
             Mean action noise std: 1.73
          Mean value_function loss: 103.3848
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.0947
                       Mean reward: 355.10
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 0.8732
    Episode_Reward/rotating_object: 69.1393
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.10s
                      Time elapsed: 00:12:49
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 44899 steps/s (collection: 2.083s, learning 0.107s)
             Mean action noise std: 1.73
          Mean value_function loss: 115.7292
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.1074
                       Mean reward: 392.67
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 0.8661
    Episode_Reward/rotating_object: 70.2496
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.19s
                      Time elapsed: 00:12:52
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 47385 steps/s (collection: 1.983s, learning 0.092s)
             Mean action noise std: 1.73
          Mean value_function loss: 108.2541
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 43.1146
                       Mean reward: 319.53
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 0.8777
    Episode_Reward/rotating_object: 71.7813
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.07s
                      Time elapsed: 00:12:54
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 48132 steps/s (collection: 1.950s, learning 0.092s)
             Mean action noise std: 1.73
          Mean value_function loss: 108.9624
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 43.1285
                       Mean reward: 399.84
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 0.8802
    Episode_Reward/rotating_object: 74.0864
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.04s
                      Time elapsed: 00:12:56
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 48292 steps/s (collection: 1.943s, learning 0.093s)
             Mean action noise std: 1.73
          Mean value_function loss: 115.8783
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.1436
                       Mean reward: 346.47
               Mean episode length: 215.02
    Episode_Reward/reaching_object: 0.8811
    Episode_Reward/rotating_object: 74.8698
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.04s
                      Time elapsed: 00:12:58
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 46546 steps/s (collection: 2.005s, learning 0.107s)
             Mean action noise std: 1.74
          Mean value_function loss: 107.7561
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.1549
                       Mean reward: 316.73
               Mean episode length: 218.24
    Episode_Reward/reaching_object: 0.8669
    Episode_Reward/rotating_object: 69.8681
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.11s
                      Time elapsed: 00:13:00
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 47717 steps/s (collection: 1.950s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 113.3670
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.1647
                       Mean reward: 373.30
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 0.8921
    Episode_Reward/rotating_object: 73.3381
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.06s
                      Time elapsed: 00:13:02
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 45209 steps/s (collection: 2.038s, learning 0.136s)
             Mean action noise std: 1.74
          Mean value_function loss: 109.4394
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 43.1714
                       Mean reward: 391.19
               Mean episode length: 225.28
    Episode_Reward/reaching_object: 0.8841
    Episode_Reward/rotating_object: 73.7713
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.17s
                      Time elapsed: 00:13:04
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 48167 steps/s (collection: 1.947s, learning 0.094s)
             Mean action noise std: 1.74
          Mean value_function loss: 115.6781
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.1820
                       Mean reward: 310.35
               Mean episode length: 213.71
    Episode_Reward/reaching_object: 0.8848
    Episode_Reward/rotating_object: 73.5422
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.04s
                      Time elapsed: 00:13:06
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 48908 steps/s (collection: 1.898s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 118.6746
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.1920
                       Mean reward: 363.24
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 0.8958
    Episode_Reward/rotating_object: 71.9270
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.01s
                      Time elapsed: 00:13:08
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 45720 steps/s (collection: 2.028s, learning 0.122s)
             Mean action noise std: 1.74
          Mean value_function loss: 112.1926
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.2014
                       Mean reward: 394.47
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 0.8977
    Episode_Reward/rotating_object: 74.5460
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.15s
                      Time elapsed: 00:13:10
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 48038 steps/s (collection: 1.939s, learning 0.107s)
             Mean action noise std: 1.74
          Mean value_function loss: 112.8140
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.2113
                       Mean reward: 412.98
               Mean episode length: 231.14
    Episode_Reward/reaching_object: 0.8995
    Episode_Reward/rotating_object: 78.8990
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.05s
                      Time elapsed: 00:13:12
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 46453 steps/s (collection: 2.015s, learning 0.102s)
             Mean action noise std: 1.74
          Mean value_function loss: 103.7377
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.2227
                       Mean reward: 404.61
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 0.8983
    Episode_Reward/rotating_object: 77.2142
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.12s
                      Time elapsed: 00:13:14
                               ETA: 00:42:27

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 48446 steps/s (collection: 1.920s, learning 0.109s)
             Mean action noise std: 1.74
          Mean value_function loss: 107.3034
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.2325
                       Mean reward: 438.07
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 0.9006
    Episode_Reward/rotating_object: 79.1310
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.03s
                      Time elapsed: 00:13:16
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 47968 steps/s (collection: 1.940s, learning 0.109s)
             Mean action noise std: 1.74
          Mean value_function loss: 109.9307
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.2508
                       Mean reward: 369.52
               Mean episode length: 222.79
    Episode_Reward/reaching_object: 0.8990
    Episode_Reward/rotating_object: 72.6529
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.05s
                      Time elapsed: 00:13:18
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 47417 steps/s (collection: 1.964s, learning 0.109s)
             Mean action noise std: 1.74
          Mean value_function loss: 112.4515
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.2652
                       Mean reward: 424.32
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 0.9069
    Episode_Reward/rotating_object: 82.0661
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.07s
                      Time elapsed: 00:13:21
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 48626 steps/s (collection: 1.930s, learning 0.092s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.4107
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 43.2754
                       Mean reward: 413.69
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 0.9206
    Episode_Reward/rotating_object: 82.5388
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.02s
                      Time elapsed: 00:13:23
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 47530 steps/s (collection: 1.974s, learning 0.094s)
             Mean action noise std: 1.75
          Mean value_function loss: 111.7661
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.2881
                       Mean reward: 392.58
               Mean episode length: 214.64
    Episode_Reward/reaching_object: 0.8702
    Episode_Reward/rotating_object: 76.4806
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.07s
                      Time elapsed: 00:13:25
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 48768 steps/s (collection: 1.926s, learning 0.090s)
             Mean action noise std: 1.75
          Mean value_function loss: 105.1814
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.2936
                       Mean reward: 429.96
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 0.9221
    Episode_Reward/rotating_object: 81.3206
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.02s
                      Time elapsed: 00:13:27
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 48356 steps/s (collection: 1.932s, learning 0.101s)
             Mean action noise std: 1.75
          Mean value_function loss: 117.1018
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.2982
                       Mean reward: 373.91
               Mean episode length: 218.54
    Episode_Reward/reaching_object: 0.8772
    Episode_Reward/rotating_object: 76.0408
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.03s
                      Time elapsed: 00:13:29
                               ETA: 00:42:07

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 47593 steps/s (collection: 1.968s, learning 0.097s)
             Mean action noise std: 1.75
          Mean value_function loss: 116.2054
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.3056
                       Mean reward: 387.13
               Mean episode length: 223.48
    Episode_Reward/reaching_object: 0.8819
    Episode_Reward/rotating_object: 77.3294
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.07s
                      Time elapsed: 00:13:31
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 49456 steps/s (collection: 1.898s, learning 0.090s)
             Mean action noise std: 1.75
          Mean value_function loss: 114.6818
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.3187
                       Mean reward: 391.44
               Mean episode length: 219.26
    Episode_Reward/reaching_object: 0.9078
    Episode_Reward/rotating_object: 82.3766
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.99s
                      Time elapsed: 00:13:33
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 48095 steps/s (collection: 1.941s, learning 0.103s)
             Mean action noise std: 1.75
          Mean value_function loss: 124.6767
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.3286
                       Mean reward: 423.64
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 0.9429
    Episode_Reward/rotating_object: 84.9483
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.04s
                      Time elapsed: 00:13:35
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 48051 steps/s (collection: 1.940s, learning 0.106s)
             Mean action noise std: 1.75
          Mean value_function loss: 125.8401
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.3335
                       Mean reward: 391.50
               Mean episode length: 213.29
    Episode_Reward/reaching_object: 0.9017
    Episode_Reward/rotating_object: 81.8303
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.05s
                      Time elapsed: 00:13:37
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 48175 steps/s (collection: 1.941s, learning 0.099s)
             Mean action noise std: 1.75
          Mean value_function loss: 115.5136
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.3433
                       Mean reward: 409.99
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 0.9049
    Episode_Reward/rotating_object: 81.7314
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.04s
                      Time elapsed: 00:13:39
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 49231 steps/s (collection: 1.895s, learning 0.102s)
             Mean action noise std: 1.75
          Mean value_function loss: 109.4173
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 43.3556
                       Mean reward: 448.52
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 0.9246
    Episode_Reward/rotating_object: 83.0805
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.00s
                      Time elapsed: 00:13:41
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 48951 steps/s (collection: 1.908s, learning 0.101s)
             Mean action noise std: 1.75
          Mean value_function loss: 97.4899
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.3708
                       Mean reward: 416.12
               Mean episode length: 220.07
    Episode_Reward/reaching_object: 0.9324
    Episode_Reward/rotating_object: 85.9943
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.01s
                      Time elapsed: 00:13:43
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 48107 steps/s (collection: 1.941s, learning 0.103s)
             Mean action noise std: 1.75
          Mean value_function loss: 104.6688
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.3789
                       Mean reward: 473.16
               Mean episode length: 225.42
    Episode_Reward/reaching_object: 0.9353
    Episode_Reward/rotating_object: 87.0929
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.04s
                      Time elapsed: 00:13:45
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 48689 steps/s (collection: 1.922s, learning 0.097s)
             Mean action noise std: 1.76
          Mean value_function loss: 106.8458
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.3878
                       Mean reward: 432.71
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 0.9228
    Episode_Reward/rotating_object: 84.7130
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.02s
                      Time elapsed: 00:13:47
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 48588 steps/s (collection: 1.921s, learning 0.102s)
             Mean action noise std: 1.76
          Mean value_function loss: 111.1363
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.3964
                       Mean reward: 403.77
               Mean episode length: 227.24
    Episode_Reward/reaching_object: 0.9303
    Episode_Reward/rotating_object: 84.5806
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.02s
                      Time elapsed: 00:13:49
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 48512 steps/s (collection: 1.919s, learning 0.108s)
             Mean action noise std: 1.76
          Mean value_function loss: 99.6579
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.4051
                       Mean reward: 417.56
               Mean episode length: 226.74
    Episode_Reward/reaching_object: 0.9164
    Episode_Reward/rotating_object: 86.2343
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.03s
                      Time elapsed: 00:13:51
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 46459 steps/s (collection: 2.008s, learning 0.108s)
             Mean action noise std: 1.76
          Mean value_function loss: 104.0782
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 43.4192
                       Mean reward: 429.02
               Mean episode length: 221.69
    Episode_Reward/reaching_object: 0.8777
    Episode_Reward/rotating_object: 80.5833
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.12s
                      Time elapsed: 00:13:53
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 47882 steps/s (collection: 1.938s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 112.0297
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.4307
                       Mean reward: 371.87
               Mean episode length: 217.59
    Episode_Reward/reaching_object: 0.8962
    Episode_Reward/rotating_object: 82.7655
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.05s
                      Time elapsed: 00:13:55
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 48159 steps/s (collection: 1.938s, learning 0.103s)
             Mean action noise std: 1.76
          Mean value_function loss: 125.9016
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 43.4381
                       Mean reward: 438.95
               Mean episode length: 212.66
    Episode_Reward/reaching_object: 0.8966
    Episode_Reward/rotating_object: 87.6190
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.04s
                      Time elapsed: 00:13:57
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 47188 steps/s (collection: 1.968s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 114.4894
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.4485
                       Mean reward: 443.83
               Mean episode length: 227.78
    Episode_Reward/reaching_object: 0.8813
    Episode_Reward/rotating_object: 85.3656
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.08s
                      Time elapsed: 00:13:59
                               ETA: 00:41:26

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 47135 steps/s (collection: 1.973s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 113.2536
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.4607
                       Mean reward: 443.86
               Mean episode length: 224.33
    Episode_Reward/reaching_object: 0.9089
    Episode_Reward/rotating_object: 86.1812
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.09s
                      Time elapsed: 00:14:01
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 47967 steps/s (collection: 1.953s, learning 0.096s)
             Mean action noise std: 1.76
          Mean value_function loss: 118.1705
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.4714
                       Mean reward: 435.73
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 0.9097
    Episode_Reward/rotating_object: 86.3427
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.05s
                      Time elapsed: 00:14:03
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 46923 steps/s (collection: 2.000s, learning 0.095s)
             Mean action noise std: 1.76
          Mean value_function loss: 118.2740
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 43.4755
                       Mean reward: 429.26
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 0.9271
    Episode_Reward/rotating_object: 88.8348
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.09s
                      Time elapsed: 00:14:05
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 47820 steps/s (collection: 1.961s, learning 0.095s)
             Mean action noise std: 1.76
          Mean value_function loss: 118.2525
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.4814
                       Mean reward: 449.15
               Mean episode length: 224.14
    Episode_Reward/reaching_object: 0.9270
    Episode_Reward/rotating_object: 89.9045
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.06s
                      Time elapsed: 00:14:08
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 47353 steps/s (collection: 1.985s, learning 0.091s)
             Mean action noise std: 1.76
          Mean value_function loss: 121.3504
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.4891
                       Mean reward: 442.90
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 0.9496
    Episode_Reward/rotating_object: 90.2711
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.08s
                      Time elapsed: 00:14:10
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 47400 steps/s (collection: 1.977s, learning 0.097s)
             Mean action noise std: 1.76
          Mean value_function loss: 116.4223
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.4945
                       Mean reward: 433.88
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 0.9276
    Episode_Reward/rotating_object: 88.5783
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.07s
                      Time elapsed: 00:14:12
                               ETA: 00:41:10

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 46553 steps/s (collection: 2.016s, learning 0.095s)
             Mean action noise std: 1.77
          Mean value_function loss: 115.7404
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.5008
                       Mean reward: 426.22
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 0.9511
    Episode_Reward/rotating_object: 92.1492
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.11s
                      Time elapsed: 00:14:14
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 46645 steps/s (collection: 2.013s, learning 0.095s)
             Mean action noise std: 1.77
          Mean value_function loss: 129.6507
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.5113
                       Mean reward: 424.46
               Mean episode length: 225.15
    Episode_Reward/reaching_object: 0.9408
    Episode_Reward/rotating_object: 90.0022
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.11s
                      Time elapsed: 00:14:16
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 45897 steps/s (collection: 2.042s, learning 0.100s)
             Mean action noise std: 1.77
          Mean value_function loss: 126.2580
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.5196
                       Mean reward: 382.84
               Mean episode length: 215.87
    Episode_Reward/reaching_object: 0.9030
    Episode_Reward/rotating_object: 80.7693
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.14s
                      Time elapsed: 00:14:18
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 48129 steps/s (collection: 1.950s, learning 0.092s)
             Mean action noise std: 1.77
          Mean value_function loss: 126.1241
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.5271
                       Mean reward: 424.26
               Mean episode length: 227.06
    Episode_Reward/reaching_object: 0.9474
    Episode_Reward/rotating_object: 86.4348
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.04s
                      Time elapsed: 00:14:20
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 47268 steps/s (collection: 1.978s, learning 0.102s)
             Mean action noise std: 1.77
          Mean value_function loss: 119.1949
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.5355
                       Mean reward: 401.30
               Mean episode length: 212.03
    Episode_Reward/reaching_object: 0.9159
    Episode_Reward/rotating_object: 84.1023
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.08s
                      Time elapsed: 00:14:22
                               ETA: 00:40:57

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 46432 steps/s (collection: 2.005s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 109.6327
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.5436
                       Mean reward: 448.73
               Mean episode length: 222.75
    Episode_Reward/reaching_object: 0.9658
    Episode_Reward/rotating_object: 91.5121
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.12s
                      Time elapsed: 00:14:24
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 45825 steps/s (collection: 2.047s, learning 0.099s)
             Mean action noise std: 1.77
          Mean value_function loss: 118.8636
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 43.5512
                       Mean reward: 424.87
               Mean episode length: 213.18
    Episode_Reward/reaching_object: 0.9345
    Episode_Reward/rotating_object: 87.8330
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.15s
                      Time elapsed: 00:14:26
                               ETA: 00:40:52

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 48301 steps/s (collection: 1.934s, learning 0.102s)
             Mean action noise std: 1.77
          Mean value_function loss: 108.4225
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.5640
                       Mean reward: 443.41
               Mean episode length: 212.62
    Episode_Reward/reaching_object: 0.9405
    Episode_Reward/rotating_object: 91.8489
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.04s
                      Time elapsed: 00:14:28
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 48252 steps/s (collection: 1.934s, learning 0.103s)
             Mean action noise std: 1.77
          Mean value_function loss: 110.3718
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.5723
                       Mean reward: 427.72
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 0.9733
    Episode_Reward/rotating_object: 94.5393
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.04s
                      Time elapsed: 00:14:31
                               ETA: 00:40:47

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 48406 steps/s (collection: 1.924s, learning 0.107s)
             Mean action noise std: 1.77
          Mean value_function loss: 114.5762
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.5789
                       Mean reward: 482.33
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 91.0275
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.03s
                      Time elapsed: 00:14:33
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 48517 steps/s (collection: 1.932s, learning 0.094s)
             Mean action noise std: 1.77
          Mean value_function loss: 105.5838
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.5855
                       Mean reward: 435.77
               Mean episode length: 214.56
    Episode_Reward/reaching_object: 0.9379
    Episode_Reward/rotating_object: 92.4554
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.03s
                      Time elapsed: 00:14:35
                               ETA: 00:40:41

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 48279 steps/s (collection: 1.947s, learning 0.089s)
             Mean action noise std: 1.77
          Mean value_function loss: 109.0881
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.5927
                       Mean reward: 495.09
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 0.9468
    Episode_Reward/rotating_object: 96.4925
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.04s
                      Time elapsed: 00:14:37
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 47460 steps/s (collection: 1.979s, learning 0.093s)
             Mean action noise std: 1.77
          Mean value_function loss: 114.4550
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.6038
                       Mean reward: 462.08
               Mean episode length: 213.75
    Episode_Reward/reaching_object: 0.9221
    Episode_Reward/rotating_object: 89.4576
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.07s
                      Time elapsed: 00:14:39
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 45707 steps/s (collection: 2.055s, learning 0.096s)
             Mean action noise std: 1.78
          Mean value_function loss: 106.5895
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 43.6166
                       Mean reward: 465.35
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 0.9660
    Episode_Reward/rotating_object: 97.8736
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.15s
                      Time elapsed: 00:14:41
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 46698 steps/s (collection: 2.014s, learning 0.092s)
             Mean action noise std: 1.78
          Mean value_function loss: 114.3580
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.6304
                       Mean reward: 463.82
               Mean episode length: 229.68
    Episode_Reward/reaching_object: 0.9399
    Episode_Reward/rotating_object: 90.0939
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.11s
                      Time elapsed: 00:14:43
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 47696 steps/s (collection: 1.970s, learning 0.091s)
             Mean action noise std: 1.78
          Mean value_function loss: 127.1293
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 43.6409
                       Mean reward: 484.46
               Mean episode length: 222.33
    Episode_Reward/reaching_object: 0.9381
    Episode_Reward/rotating_object: 93.6494
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.06s
                      Time elapsed: 00:14:45
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 46759 steps/s (collection: 2.001s, learning 0.101s)
             Mean action noise std: 1.78
          Mean value_function loss: 98.1075
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.6466
                       Mean reward: 509.67
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 0.9712
    Episode_Reward/rotating_object: 97.7214
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.10s
                      Time elapsed: 00:14:47
                               ETA: 00:40:26

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 46235 steps/s (collection: 2.013s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 97.3904
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.6533
                       Mean reward: 459.55
               Mean episode length: 222.53
    Episode_Reward/reaching_object: 0.9424
    Episode_Reward/rotating_object: 92.8454
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.13s
                      Time elapsed: 00:14:49
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 43005 steps/s (collection: 2.173s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 106.9313
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.6596
                       Mean reward: 457.15
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 0.9194
    Episode_Reward/rotating_object: 91.7027
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.29s
                      Time elapsed: 00:14:52
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 43943 steps/s (collection: 2.062s, learning 0.175s)
             Mean action noise std: 1.78
          Mean value_function loss: 102.9879
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.6675
                       Mean reward: 511.74
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 0.9369
    Episode_Reward/rotating_object: 94.5892
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.24s
                      Time elapsed: 00:14:54
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 43447 steps/s (collection: 2.169s, learning 0.094s)
             Mean action noise std: 1.78
          Mean value_function loss: 111.1151
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.6732
                       Mean reward: 480.95
               Mean episode length: 222.79
    Episode_Reward/reaching_object: 0.9306
    Episode_Reward/rotating_object: 94.7565
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.26s
                      Time elapsed: 00:14:56
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 47450 steps/s (collection: 1.976s, learning 0.096s)
             Mean action noise std: 1.78
          Mean value_function loss: 105.8361
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.6856
                       Mean reward: 520.47
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 0.9752
    Episode_Reward/rotating_object: 99.9818
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.07s
                      Time elapsed: 00:14:58
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 46431 steps/s (collection: 1.973s, learning 0.144s)
             Mean action noise std: 1.78
          Mean value_function loss: 107.6852
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.7009
                       Mean reward: 472.98
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 0.9572
    Episode_Reward/rotating_object: 98.1645
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.12s
                      Time elapsed: 00:15:00
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 46844 steps/s (collection: 1.982s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 102.2211
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.7121
                       Mean reward: 483.54
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 0.9783
    Episode_Reward/rotating_object: 100.4711
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.10s
                      Time elapsed: 00:15:02
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 47253 steps/s (collection: 1.955s, learning 0.126s)
             Mean action noise std: 1.78
          Mean value_function loss: 102.2699
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.7184
                       Mean reward: 524.29
               Mean episode length: 230.22
    Episode_Reward/reaching_object: 0.9662
    Episode_Reward/rotating_object: 101.1804
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.08s
                      Time elapsed: 00:15:04
                               ETA: 00:40:07

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 44306 steps/s (collection: 2.072s, learning 0.147s)
             Mean action noise std: 1.78
          Mean value_function loss: 102.7547
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.7298
                       Mean reward: 508.03
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 0.9647
    Episode_Reward/rotating_object: 101.5677
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.22s
                      Time elapsed: 00:15:07
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 45938 steps/s (collection: 2.048s, learning 0.092s)
             Mean action noise std: 1.79
          Mean value_function loss: 98.3687
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 43.7425
                       Mean reward: 534.22
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 0.9657
    Episode_Reward/rotating_object: 100.6076
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.14s
                      Time elapsed: 00:15:09
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 46305 steps/s (collection: 2.018s, learning 0.105s)
             Mean action noise std: 1.79
          Mean value_function loss: 99.7526
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.7534
                       Mean reward: 516.42
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 0.9640
    Episode_Reward/rotating_object: 102.0790
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.12s
                      Time elapsed: 00:15:11
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 47169 steps/s (collection: 1.974s, learning 0.110s)
             Mean action noise std: 1.79
          Mean value_function loss: 105.5034
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.7611
                       Mean reward: 476.77
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 0.9737
    Episode_Reward/rotating_object: 102.0366
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.08s
                      Time elapsed: 00:15:13
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 42417 steps/s (collection: 2.191s, learning 0.126s)
             Mean action noise std: 1.79
          Mean value_function loss: 118.1504
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.7694
                       Mean reward: 504.56
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 0.9564
    Episode_Reward/rotating_object: 101.3321
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.32s
                      Time elapsed: 00:15:15
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 47048 steps/s (collection: 1.966s, learning 0.124s)
             Mean action noise std: 1.79
          Mean value_function loss: 110.0957
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.7783
                       Mean reward: 544.03
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 0.9728
    Episode_Reward/rotating_object: 101.3940
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.09s
                      Time elapsed: 00:15:17
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 46629 steps/s (collection: 2.008s, learning 0.100s)
             Mean action noise std: 1.79
          Mean value_function loss: 115.0896
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.7894
                       Mean reward: 495.37
               Mean episode length: 221.55
    Episode_Reward/reaching_object: 0.9709
    Episode_Reward/rotating_object: 102.1788
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.11s
                      Time elapsed: 00:15:19
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 42405 steps/s (collection: 2.138s, learning 0.180s)
             Mean action noise std: 1.79
          Mean value_function loss: 102.8493
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.8011
                       Mean reward: 514.54
               Mean episode length: 224.77
    Episode_Reward/reaching_object: 0.9817
    Episode_Reward/rotating_object: 104.1465
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.32s
                      Time elapsed: 00:15:22
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 44605 steps/s (collection: 2.077s, learning 0.127s)
             Mean action noise std: 1.79
          Mean value_function loss: 105.8167
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.8076
                       Mean reward: 521.67
               Mean episode length: 224.01
    Episode_Reward/reaching_object: 0.9654
    Episode_Reward/rotating_object: 103.0319
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.20s
                      Time elapsed: 00:15:24
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 44434 steps/s (collection: 2.062s, learning 0.150s)
             Mean action noise std: 1.79
          Mean value_function loss: 115.6488
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.8130
                       Mean reward: 535.28
               Mean episode length: 231.26
    Episode_Reward/reaching_object: 0.9772
    Episode_Reward/rotating_object: 102.6878
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.21s
                      Time elapsed: 00:15:26
                               ETA: 00:39:45

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 43089 steps/s (collection: 2.116s, learning 0.166s)
             Mean action noise std: 1.79
          Mean value_function loss: 107.2451
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.8227
                       Mean reward: 517.50
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 0.9970
    Episode_Reward/rotating_object: 105.5875
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.28s
                      Time elapsed: 00:15:28
                               ETA: 00:39:43

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 46180 steps/s (collection: 1.975s, learning 0.154s)
             Mean action noise std: 1.79
          Mean value_function loss: 121.2446
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.8396
                       Mean reward: 519.59
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 0.9661
    Episode_Reward/rotating_object: 101.0134
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.13s
                      Time elapsed: 00:15:31
                               ETA: 00:39:40

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 45668 steps/s (collection: 2.056s, learning 0.097s)
             Mean action noise std: 1.80
          Mean value_function loss: 102.6129
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.8510
                       Mean reward: 491.53
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 0.9772
    Episode_Reward/rotating_object: 101.9912
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.15s
                      Time elapsed: 00:15:33
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 45635 steps/s (collection: 2.048s, learning 0.107s)
             Mean action noise std: 1.80
          Mean value_function loss: 96.0633
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.8591
                       Mean reward: 533.64
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 106.9640
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.15s
                      Time elapsed: 00:15:35
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 45870 steps/s (collection: 2.025s, learning 0.118s)
             Mean action noise std: 1.80
          Mean value_function loss: 109.1154
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.8666
                       Mean reward: 500.68
               Mean episode length: 222.67
    Episode_Reward/reaching_object: 0.9608
    Episode_Reward/rotating_object: 101.0934
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.14s
                      Time elapsed: 00:15:37
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 45864 steps/s (collection: 2.047s, learning 0.096s)
             Mean action noise std: 1.80
          Mean value_function loss: 105.1524
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.8788
                       Mean reward: 539.59
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 0.9741
    Episode_Reward/rotating_object: 101.5192
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.14s
                      Time elapsed: 00:15:39
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 44429 steps/s (collection: 2.057s, learning 0.155s)
             Mean action noise std: 1.80
          Mean value_function loss: 98.0234
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.8890
                       Mean reward: 539.04
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.0020
    Episode_Reward/rotating_object: 106.1227
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.21s
                      Time elapsed: 00:15:41
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 46157 steps/s (collection: 1.963s, learning 0.167s)
             Mean action noise std: 1.80
          Mean value_function loss: 94.6741
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.8973
                       Mean reward: 489.07
               Mean episode length: 224.22
    Episode_Reward/reaching_object: 0.9770
    Episode_Reward/rotating_object: 104.2972
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.13s
                      Time elapsed: 00:15:44
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 45629 steps/s (collection: 2.035s, learning 0.119s)
             Mean action noise std: 1.80
          Mean value_function loss: 98.5101
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.9088
                       Mean reward: 573.12
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 0.9882
    Episode_Reward/rotating_object: 107.7979
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.15s
                      Time elapsed: 00:15:46
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 47157 steps/s (collection: 1.996s, learning 0.088s)
             Mean action noise std: 1.80
          Mean value_function loss: 90.7763
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.9218
                       Mean reward: 528.83
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 108.9826
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.08s
                      Time elapsed: 00:15:48
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 47341 steps/s (collection: 1.978s, learning 0.098s)
             Mean action noise std: 1.80
          Mean value_function loss: 107.7771
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.9296
                       Mean reward: 590.22
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 0.9821
    Episode_Reward/rotating_object: 107.7779
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.08s
                      Time elapsed: 00:15:50
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 47698 steps/s (collection: 1.972s, learning 0.089s)
             Mean action noise std: 1.80
          Mean value_function loss: 114.9887
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.9410
                       Mean reward: 551.17
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 0.9984
    Episode_Reward/rotating_object: 108.4271
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.06s
                      Time elapsed: 00:15:52
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 46991 steps/s (collection: 1.976s, learning 0.116s)
             Mean action noise std: 1.80
          Mean value_function loss: 108.6449
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.9506
                       Mean reward: 569.17
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 0.9914
    Episode_Reward/rotating_object: 107.2795
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.09s
                      Time elapsed: 00:15:54
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 46934 steps/s (collection: 2.001s, learning 0.094s)
             Mean action noise std: 1.80
          Mean value_function loss: 101.9914
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 43.9532
                       Mean reward: 557.91
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 0.9862
    Episode_Reward/rotating_object: 105.4361
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.09s
                      Time elapsed: 00:15:56
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 48278 steps/s (collection: 1.946s, learning 0.091s)
             Mean action noise std: 1.80
          Mean value_function loss: 102.3400
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.9553
                       Mean reward: 590.09
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.0150
    Episode_Reward/rotating_object: 113.9891
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.04s
                      Time elapsed: 00:15:58
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 46369 steps/s (collection: 2.011s, learning 0.109s)
             Mean action noise std: 1.81
          Mean value_function loss: 107.5142
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.9613
                       Mean reward: 567.46
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.0073
    Episode_Reward/rotating_object: 112.1059
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.12s
                      Time elapsed: 00:16:00
                               ETA: 00:39:06

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 44777 steps/s (collection: 2.030s, learning 0.166s)
             Mean action noise std: 1.81
          Mean value_function loss: 96.7177
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.9727
                       Mean reward: 538.21
               Mean episode length: 223.34
    Episode_Reward/reaching_object: 0.9803
    Episode_Reward/rotating_object: 105.8609
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.20s
                      Time elapsed: 00:16:02
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 44025 steps/s (collection: 2.124s, learning 0.109s)
             Mean action noise std: 1.81
          Mean value_function loss: 101.8122
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 43.9805
                       Mean reward: 538.11
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 0.9789
    Episode_Reward/rotating_object: 108.8571
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.23s
                      Time elapsed: 00:16:05
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 47474 steps/s (collection: 1.978s, learning 0.093s)
             Mean action noise std: 1.81
          Mean value_function loss: 99.9888
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.9936
                       Mean reward: 557.50
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 0.9958
    Episode_Reward/rotating_object: 109.6115
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.07s
                      Time elapsed: 00:16:07
                               ETA: 00:38:59

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 41884 steps/s (collection: 2.239s, learning 0.109s)
             Mean action noise std: 1.81
          Mean value_function loss: 97.3996
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.0067
                       Mean reward: 601.62
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 0.9925
    Episode_Reward/rotating_object: 111.2852
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.35s
                      Time elapsed: 00:16:09
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 46937 steps/s (collection: 1.995s, learning 0.100s)
             Mean action noise std: 1.81
          Mean value_function loss: 99.6184
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.0174
                       Mean reward: 578.15
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 0.9950
    Episode_Reward/rotating_object: 111.0081
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.09s
                      Time elapsed: 00:16:11
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 47476 steps/s (collection: 1.965s, learning 0.106s)
             Mean action noise std: 1.81
          Mean value_function loss: 99.5290
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.0286
                       Mean reward: 574.11
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 0.9795
    Episode_Reward/rotating_object: 109.0955
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.07s
                      Time elapsed: 00:16:13
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 46864 steps/s (collection: 2.004s, learning 0.094s)
             Mean action noise std: 1.81
          Mean value_function loss: 96.0442
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.0395
                       Mean reward: 551.06
               Mean episode length: 229.59
    Episode_Reward/reaching_object: 0.9869
    Episode_Reward/rotating_object: 108.9701
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.10s
                      Time elapsed: 00:16:15
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 46980 steps/s (collection: 1.985s, learning 0.108s)
             Mean action noise std: 1.81
          Mean value_function loss: 96.0523
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.0501
                       Mean reward: 579.92
               Mean episode length: 229.03
    Episode_Reward/reaching_object: 0.9990
    Episode_Reward/rotating_object: 111.5671
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.09s
                      Time elapsed: 00:16:17
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 47346 steps/s (collection: 1.948s, learning 0.129s)
             Mean action noise std: 1.81
          Mean value_function loss: 106.9453
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.0579
                       Mean reward: 604.50
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 0.9843
    Episode_Reward/rotating_object: 110.8134
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.08s
                      Time elapsed: 00:16:20
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 46992 steps/s (collection: 1.998s, learning 0.094s)
             Mean action noise std: 1.82
          Mean value_function loss: 101.6298
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.0696
                       Mean reward: 587.22
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 0.9989
    Episode_Reward/rotating_object: 114.5704
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.09s
                      Time elapsed: 00:16:22
                               ETA: 00:38:43

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 43481 steps/s (collection: 2.120s, learning 0.141s)
             Mean action noise std: 1.82
          Mean value_function loss: 96.7054
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.0826
                       Mean reward: 534.66
               Mean episode length: 217.05
    Episode_Reward/reaching_object: 0.9742
    Episode_Reward/rotating_object: 109.5645
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.26s
                      Time elapsed: 00:16:24
                               ETA: 00:38:41

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 47031 steps/s (collection: 1.997s, learning 0.093s)
             Mean action noise std: 1.82
          Mean value_function loss: 95.6093
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.0982
                       Mean reward: 570.68
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.0024
    Episode_Reward/rotating_object: 116.5382
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.09s
                      Time elapsed: 00:16:26
                               ETA: 00:38:38

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 47743 steps/s (collection: 1.960s, learning 0.099s)
             Mean action noise std: 1.82
          Mean value_function loss: 88.9896
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.1157
                       Mean reward: 614.68
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 0.9730
    Episode_Reward/rotating_object: 108.4827
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.06s
                      Time elapsed: 00:16:28
                               ETA: 00:38:36

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 47481 steps/s (collection: 1.975s, learning 0.095s)
             Mean action noise std: 1.82
          Mean value_function loss: 91.6722
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.1226
                       Mean reward: 538.05
               Mean episode length: 216.53
    Episode_Reward/reaching_object: 0.9957
    Episode_Reward/rotating_object: 111.8723
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.07s
                      Time elapsed: 00:16:30
                               ETA: 00:38:33

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 47813 steps/s (collection: 1.960s, learning 0.096s)
             Mean action noise std: 1.82
          Mean value_function loss: 88.7951
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.1296
                       Mean reward: 578.23
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 1.0105
    Episode_Reward/rotating_object: 116.2775
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.06s
                      Time elapsed: 00:16:32
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 44115 steps/s (collection: 2.138s, learning 0.090s)
             Mean action noise std: 1.82
          Mean value_function loss: 91.2105
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.1396
                       Mean reward: 591.87
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 119.1357
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.23s
                      Time elapsed: 00:16:34
                               ETA: 00:38:28

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 47531 steps/s (collection: 1.972s, learning 0.097s)
             Mean action noise std: 1.82
          Mean value_function loss: 96.3527
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.1508
                       Mean reward: 554.25
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 0.9782
    Episode_Reward/rotating_object: 113.2941
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.07s
                      Time elapsed: 00:16:36
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 44527 steps/s (collection: 2.029s, learning 0.179s)
             Mean action noise std: 1.82
          Mean value_function loss: 92.9872
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.1662
                       Mean reward: 545.63
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 0.9743
    Episode_Reward/rotating_object: 109.8970
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.21s
                      Time elapsed: 00:16:39
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 45382 steps/s (collection: 2.008s, learning 0.158s)
             Mean action noise std: 1.82
          Mean value_function loss: 94.6566
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.1768
                       Mean reward: 621.85
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.9878
    Episode_Reward/rotating_object: 118.9474
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.17s
                      Time elapsed: 00:16:41
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 47361 steps/s (collection: 1.961s, learning 0.115s)
             Mean action noise std: 1.83
          Mean value_function loss: 87.0983
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.1876
                       Mean reward: 602.66
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.0010
    Episode_Reward/rotating_object: 117.0520
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.08s
                      Time elapsed: 00:16:43
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 44409 steps/s (collection: 2.104s, learning 0.109s)
             Mean action noise std: 1.83
          Mean value_function loss: 81.8649
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 44.2015
                       Mean reward: 561.06
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 0.9990
    Episode_Reward/rotating_object: 115.2571
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.21s
                      Time elapsed: 00:16:45
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 45251 steps/s (collection: 2.026s, learning 0.147s)
             Mean action noise std: 1.83
          Mean value_function loss: 87.9074
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.2102
                       Mean reward: 604.66
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 0.9993
    Episode_Reward/rotating_object: 116.2075
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.17s
                      Time elapsed: 00:16:47
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 46418 steps/s (collection: 2.006s, learning 0.112s)
             Mean action noise std: 1.83
          Mean value_function loss: 90.8083
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.2260
                       Mean reward: 549.05
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 0.9866
    Episode_Reward/rotating_object: 114.7831
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.12s
                      Time elapsed: 00:16:49
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 45658 steps/s (collection: 2.056s, learning 0.097s)
             Mean action noise std: 1.83
          Mean value_function loss: 95.7825
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.2439
                       Mean reward: 527.13
               Mean episode length: 223.21
    Episode_Reward/reaching_object: 0.9901
    Episode_Reward/rotating_object: 115.3754
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.15s
                      Time elapsed: 00:16:52
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 45906 steps/s (collection: 1.978s, learning 0.163s)
             Mean action noise std: 1.83
          Mean value_function loss: 85.1107
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.2570
                       Mean reward: 575.35
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 116.3430
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.14s
                      Time elapsed: 00:16:54
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 44159 steps/s (collection: 2.086s, learning 0.140s)
             Mean action noise std: 1.83
          Mean value_function loss: 93.6167
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.2737
                       Mean reward: 597.64
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 0.9923
    Episode_Reward/rotating_object: 116.3261
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.23s
                      Time elapsed: 00:16:56
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 45672 steps/s (collection: 2.032s, learning 0.121s)
             Mean action noise std: 1.83
          Mean value_function loss: 88.5819
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.2930
                       Mean reward: 601.84
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 0.9827
    Episode_Reward/rotating_object: 115.7311
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.15s
                      Time elapsed: 00:16:58
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 44629 steps/s (collection: 2.081s, learning 0.122s)
             Mean action noise std: 1.84
          Mean value_function loss: 87.1107
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.3101
                       Mean reward: 596.49
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.0075
    Episode_Reward/rotating_object: 117.5747
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.20s
                      Time elapsed: 00:17:00
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 45973 steps/s (collection: 2.042s, learning 0.097s)
             Mean action noise std: 1.84
          Mean value_function loss: 91.9410
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3260
                       Mean reward: 604.70
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 1.0131
    Episode_Reward/rotating_object: 120.1916
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.14s
                      Time elapsed: 00:17:02
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 43809 steps/s (collection: 2.124s, learning 0.120s)
             Mean action noise std: 1.84
          Mean value_function loss: 90.9910
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.3414
                       Mean reward: 570.87
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 0.9973
    Episode_Reward/rotating_object: 116.4247
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.24s
                      Time elapsed: 00:17:05
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 44184 steps/s (collection: 2.049s, learning 0.176s)
             Mean action noise std: 1.84
          Mean value_function loss: 99.5077
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.3552
                       Mean reward: 588.29
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 0.9955
    Episode_Reward/rotating_object: 115.7884
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.22s
                      Time elapsed: 00:17:07
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 46823 steps/s (collection: 1.987s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 90.6736
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.3697
                       Mean reward: 638.44
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.0117
    Episode_Reward/rotating_object: 121.9196
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.10s
                      Time elapsed: 00:17:09
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 46927 steps/s (collection: 2.003s, learning 0.092s)
             Mean action noise std: 1.84
          Mean value_function loss: 97.4939
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.3842
                       Mean reward: 604.83
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.0181
    Episode_Reward/rotating_object: 121.4601
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.09s
                      Time elapsed: 00:17:11
                               ETA: 00:37:49

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 46253 steps/s (collection: 2.026s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 93.8345
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.3931
                       Mean reward: 617.13
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.0051
    Episode_Reward/rotating_object: 115.2067
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.13s
                      Time elapsed: 00:17:13
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 43679 steps/s (collection: 2.142s, learning 0.109s)
             Mean action noise std: 1.84
          Mean value_function loss: 89.6652
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.4030
                       Mean reward: 602.19
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 1.0167
    Episode_Reward/rotating_object: 120.2999
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.25s
                      Time elapsed: 00:17:15
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 46090 steps/s (collection: 2.033s, learning 0.100s)
             Mean action noise std: 1.85
          Mean value_function loss: 82.9062
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.4178
                       Mean reward: 608.88
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.0371
    Episode_Reward/rotating_object: 122.8377
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.13s
                      Time elapsed: 00:17:18
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 45342 steps/s (collection: 2.002s, learning 0.166s)
             Mean action noise std: 1.85
          Mean value_function loss: 92.9810
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.4334
                       Mean reward: 647.00
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 124.3998
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.17s
                      Time elapsed: 00:17:20
                               ETA: 00:37:40

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 45595 steps/s (collection: 2.022s, learning 0.134s)
             Mean action noise std: 1.85
          Mean value_function loss: 86.3181
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.4429
                       Mean reward: 649.62
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 1.0009
    Episode_Reward/rotating_object: 116.7623
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.16s
                      Time elapsed: 00:17:22
                               ETA: 00:37:38

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 46723 steps/s (collection: 2.001s, learning 0.103s)
             Mean action noise std: 1.85
          Mean value_function loss: 90.5113
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.4497
                       Mean reward: 589.34
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 120.4968
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.10s
                      Time elapsed: 00:17:24
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 45554 steps/s (collection: 2.052s, learning 0.106s)
             Mean action noise std: 1.85
          Mean value_function loss: 83.7137
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.4549
                       Mean reward: 605.15
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.0035
    Episode_Reward/rotating_object: 118.5234
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.16s
                      Time elapsed: 00:17:26
                               ETA: 00:37:33

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 43686 steps/s (collection: 2.130s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 88.9203
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.4648
                       Mean reward: 640.19
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.0315
    Episode_Reward/rotating_object: 124.1008
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.25s
                      Time elapsed: 00:17:28
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 46255 steps/s (collection: 2.027s, learning 0.098s)
             Mean action noise std: 1.85
          Mean value_function loss: 93.8898
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.4784
                       Mean reward: 556.72
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.0013
    Episode_Reward/rotating_object: 117.9153
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.13s
                      Time elapsed: 00:17:31
                               ETA: 00:37:29

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 44994 steps/s (collection: 2.042s, learning 0.143s)
             Mean action noise std: 1.85
          Mean value_function loss: 88.6130
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.4873
                       Mean reward: 630.74
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.0240
    Episode_Reward/rotating_object: 125.2282
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.18s
                      Time elapsed: 00:17:33
                               ETA: 00:37:27

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 45044 steps/s (collection: 2.081s, learning 0.102s)
             Mean action noise std: 1.85
          Mean value_function loss: 91.4383
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.4968
                       Mean reward: 609.13
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.0192
    Episode_Reward/rotating_object: 122.9614
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.18s
                      Time elapsed: 00:17:35
                               ETA: 00:37:24

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 44664 steps/s (collection: 2.088s, learning 0.113s)
             Mean action noise std: 1.85
          Mean value_function loss: 86.5426
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.5089
                       Mean reward: 624.41
               Mean episode length: 232.82
    Episode_Reward/reaching_object: 1.0102
    Episode_Reward/rotating_object: 122.5772
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.20s
                      Time elapsed: 00:17:37
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 44613 steps/s (collection: 2.104s, learning 0.100s)
             Mean action noise std: 1.85
          Mean value_function loss: 89.9025
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.5178
                       Mean reward: 562.68
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.0383
    Episode_Reward/rotating_object: 121.9342
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.20s
                      Time elapsed: 00:17:39
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 45795 steps/s (collection: 2.043s, learning 0.104s)
             Mean action noise std: 1.86
          Mean value_function loss: 79.6719
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.5274
                       Mean reward: 580.52
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.0334
    Episode_Reward/rotating_object: 122.5427
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.15s
                      Time elapsed: 00:17:41
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 45549 steps/s (collection: 2.047s, learning 0.112s)
             Mean action noise std: 1.86
          Mean value_function loss: 91.0427
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.5405
                       Mean reward: 611.65
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.0099
    Episode_Reward/rotating_object: 118.1760
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.16s
                      Time elapsed: 00:17:44
                               ETA: 00:37:15

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 46360 steps/s (collection: 2.016s, learning 0.105s)
             Mean action noise std: 1.86
          Mean value_function loss: 85.3574
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.5531
                       Mean reward: 618.92
               Mean episode length: 230.48
    Episode_Reward/reaching_object: 1.0185
    Episode_Reward/rotating_object: 122.2660
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.12s
                      Time elapsed: 00:17:46
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 45068 steps/s (collection: 2.044s, learning 0.138s)
             Mean action noise std: 1.86
          Mean value_function loss: 94.1352
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 44.5629
                       Mean reward: 657.49
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.0340
    Episode_Reward/rotating_object: 124.2466
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.18s
                      Time elapsed: 00:17:48
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 45466 steps/s (collection: 2.051s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 89.1273
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.5720
                       Mean reward: 644.16
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 125.2620
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.16s
                      Time elapsed: 00:17:50
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 45080 steps/s (collection: 2.069s, learning 0.112s)
             Mean action noise std: 1.86
          Mean value_function loss: 90.3524
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.5835
                       Mean reward: 626.23
               Mean episode length: 230.26
    Episode_Reward/reaching_object: 1.0263
    Episode_Reward/rotating_object: 122.8474
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.18s
                      Time elapsed: 00:17:52
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 42934 steps/s (collection: 2.180s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 97.0950
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.5918
                       Mean reward: 565.46
               Mean episode length: 222.47
    Episode_Reward/reaching_object: 1.0409
    Episode_Reward/rotating_object: 123.0271
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.29s
                      Time elapsed: 00:17:55
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 43183 steps/s (collection: 2.142s, learning 0.134s)
             Mean action noise std: 1.86
          Mean value_function loss: 92.7103
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.6030
                       Mean reward: 650.77
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0486
    Episode_Reward/rotating_object: 125.2493
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.28s
                      Time elapsed: 00:17:57
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 44880 steps/s (collection: 2.055s, learning 0.136s)
             Mean action noise std: 1.86
          Mean value_function loss: 91.1140
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.6099
                       Mean reward: 604.29
               Mean episode length: 229.62
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 125.6575
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.19s
                      Time elapsed: 00:17:59
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 45616 steps/s (collection: 2.046s, learning 0.109s)
             Mean action noise std: 1.86
          Mean value_function loss: 88.0605
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.6234
                       Mean reward: 625.52
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.0358
    Episode_Reward/rotating_object: 122.2275
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.16s
                      Time elapsed: 00:18:01
                               ETA: 00:36:58

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 45092 steps/s (collection: 2.090s, learning 0.091s)
             Mean action noise std: 1.87
          Mean value_function loss: 83.2894
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.6350
                       Mean reward: 640.55
               Mean episode length: 245.01
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 125.2405
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.18s
                      Time elapsed: 00:18:03
                               ETA: 00:36:56

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 45574 steps/s (collection: 2.066s, learning 0.091s)
             Mean action noise std: 1.87
          Mean value_function loss: 87.7719
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.6442
                       Mean reward: 629.88
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 1.0578
    Episode_Reward/rotating_object: 125.9454
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.16s
                      Time elapsed: 00:18:06
                               ETA: 00:36:53

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 43168 steps/s (collection: 2.080s, learning 0.197s)
             Mean action noise std: 1.87
          Mean value_function loss: 84.7206
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.6574
                       Mean reward: 622.38
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.0656
    Episode_Reward/rotating_object: 127.2239
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.28s
                      Time elapsed: 00:18:08
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 40608 steps/s (collection: 2.219s, learning 0.202s)
             Mean action noise std: 1.87
          Mean value_function loss: 81.6535
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.6726
                       Mean reward: 674.71
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 1.0546
    Episode_Reward/rotating_object: 127.1486
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.42s
                      Time elapsed: 00:18:10
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 42120 steps/s (collection: 2.195s, learning 0.139s)
             Mean action noise std: 1.87
          Mean value_function loss: 86.2867
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.6846
                       Mean reward: 625.13
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.0479
    Episode_Reward/rotating_object: 126.6169
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.33s
                      Time elapsed: 00:18:13
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 41822 steps/s (collection: 2.210s, learning 0.141s)
             Mean action noise std: 1.87
          Mean value_function loss: 88.7453
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.6995
                       Mean reward: 660.29
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.0555
    Episode_Reward/rotating_object: 128.8525
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.35s
                      Time elapsed: 00:18:15
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 41218 steps/s (collection: 2.167s, learning 0.218s)
             Mean action noise std: 1.87
          Mean value_function loss: 87.8986
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.7091
                       Mean reward: 671.84
               Mean episode length: 242.90
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 128.7691
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.38s
                      Time elapsed: 00:18:17
                               ETA: 00:36:44

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 44016 steps/s (collection: 2.138s, learning 0.095s)
             Mean action noise std: 1.87
          Mean value_function loss: 94.3677
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.7209
                       Mean reward: 644.01
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.0627
    Episode_Reward/rotating_object: 127.1971
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.23s
                      Time elapsed: 00:18:20
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 43204 steps/s (collection: 2.142s, learning 0.133s)
             Mean action noise std: 1.87
          Mean value_function loss: 77.2087
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.7354
                       Mean reward: 632.12
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 1.0645
    Episode_Reward/rotating_object: 128.6979
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.28s
                      Time elapsed: 00:18:22
                               ETA: 00:36:40

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 42913 steps/s (collection: 2.118s, learning 0.173s)
             Mean action noise std: 1.88
          Mean value_function loss: 74.8821
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 44.7463
                       Mean reward: 620.11
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.0376
    Episode_Reward/rotating_object: 123.8140
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.29s
                      Time elapsed: 00:18:24
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 45863 steps/s (collection: 2.017s, learning 0.126s)
             Mean action noise std: 1.88
          Mean value_function loss: 71.0660
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.7613
                       Mean reward: 634.35
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 125.8105
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.14s
                      Time elapsed: 00:18:26
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 40761 steps/s (collection: 2.245s, learning 0.167s)
             Mean action noise std: 1.88
          Mean value_function loss: 76.1953
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.7699
                       Mean reward: 631.21
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 128.1126
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.41s
                      Time elapsed: 00:18:29
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 43605 steps/s (collection: 2.119s, learning 0.135s)
             Mean action noise std: 1.88
          Mean value_function loss: 77.0339
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.7824
                       Mean reward: 654.64
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.0413
    Episode_Reward/rotating_object: 125.9866
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.25s
                      Time elapsed: 00:18:31
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 44075 steps/s (collection: 2.056s, learning 0.175s)
             Mean action noise std: 1.88
          Mean value_function loss: 80.8307
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.7944
                       Mean reward: 681.65
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 1.0582
    Episode_Reward/rotating_object: 128.6892
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.23s
                      Time elapsed: 00:18:33
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 45431 steps/s (collection: 2.050s, learning 0.113s)
             Mean action noise std: 1.88
          Mean value_function loss: 92.3560
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.8044
                       Mean reward: 646.19
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 1.0406
    Episode_Reward/rotating_object: 125.3398
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.16s
                      Time elapsed: 00:18:35
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 46549 steps/s (collection: 2.013s, learning 0.099s)
             Mean action noise std: 1.88
          Mean value_function loss: 78.7204
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 44.8157
                       Mean reward: 600.97
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.0394
    Episode_Reward/rotating_object: 125.1376
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.11s
                      Time elapsed: 00:18:37
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 45644 steps/s (collection: 2.042s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 82.0004
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 44.8283
                       Mean reward: 662.39
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 1.0346
    Episode_Reward/rotating_object: 127.0041
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.15s
                      Time elapsed: 00:18:40
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 46318 steps/s (collection: 2.017s, learning 0.105s)
             Mean action noise std: 1.89
          Mean value_function loss: 91.1391
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.8483
                       Mean reward: 592.92
               Mean episode length: 228.78
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 127.8987
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.12s
                      Time elapsed: 00:18:42
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 46351 steps/s (collection: 2.013s, learning 0.108s)
             Mean action noise std: 1.89
          Mean value_function loss: 93.4559
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 44.8569
                       Mean reward: 647.19
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 130.9144
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.12s
                      Time elapsed: 00:18:44
                               ETA: 00:36:18

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 45953 steps/s (collection: 2.044s, learning 0.096s)
             Mean action noise std: 1.89
          Mean value_function loss: 94.0945
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.8711
                       Mean reward: 616.12
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.0133
    Episode_Reward/rotating_object: 123.4286
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.14s
                      Time elapsed: 00:18:46
                               ETA: 00:36:15

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 44479 steps/s (collection: 2.097s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 89.3076
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.8883
                       Mean reward: 631.17
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 127.6453
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.21s
                      Time elapsed: 00:18:48
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 42540 steps/s (collection: 2.131s, learning 0.180s)
             Mean action noise std: 1.89
          Mean value_function loss: 88.9790
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.9002
                       Mean reward: 654.83
               Mean episode length: 234.42
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 128.5072
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.31s
                      Time elapsed: 00:18:50
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 40838 steps/s (collection: 2.235s, learning 0.172s)
             Mean action noise std: 1.89
          Mean value_function loss: 84.2626
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.9179
                       Mean reward: 644.82
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.0645
    Episode_Reward/rotating_object: 129.7492
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.41s
                      Time elapsed: 00:18:53
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 39712 steps/s (collection: 2.296s, learning 0.179s)
             Mean action noise std: 1.89
          Mean value_function loss: 83.4053
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.9347
                       Mean reward: 646.96
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 130.4418
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.48s
                      Time elapsed: 00:18:55
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 44045 steps/s (collection: 2.103s, learning 0.129s)
             Mean action noise std: 1.90
          Mean value_function loss: 83.5335
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.9455
                       Mean reward: 649.92
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.0416
    Episode_Reward/rotating_object: 125.6116
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.23s
                      Time elapsed: 00:18:58
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 41758 steps/s (collection: 2.205s, learning 0.149s)
             Mean action noise std: 1.90
          Mean value_function loss: 80.2618
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.9626
                       Mean reward: 650.36
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.0436
    Episode_Reward/rotating_object: 126.3234
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.35s
                      Time elapsed: 00:19:00
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 43634 steps/s (collection: 2.110s, learning 0.143s)
             Mean action noise std: 1.90
          Mean value_function loss: 93.6026
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.9818
                       Mean reward: 602.61
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.0415
    Episode_Reward/rotating_object: 126.2559
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.25s
                      Time elapsed: 00:19:02
                               ETA: 00:36:02

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 44568 steps/s (collection: 2.091s, learning 0.115s)
             Mean action noise std: 1.90
          Mean value_function loss: 93.8804
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.9918
                       Mean reward: 644.73
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.0399
    Episode_Reward/rotating_object: 125.4548
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.21s
                      Time elapsed: 00:19:04
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 40419 steps/s (collection: 2.258s, learning 0.174s)
             Mean action noise std: 1.90
          Mean value_function loss: 78.6090
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.9981
                       Mean reward: 660.01
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.0627
    Episode_Reward/rotating_object: 128.6049
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.43s
                      Time elapsed: 00:19:07
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 42892 steps/s (collection: 2.133s, learning 0.159s)
             Mean action noise std: 1.90
          Mean value_function loss: 95.3708
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.0118
                       Mean reward: 628.08
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 1.0259
    Episode_Reward/rotating_object: 124.9351
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.29s
                      Time elapsed: 00:19:09
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 41628 steps/s (collection: 2.248s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 92.7860
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.0276
                       Mean reward: 622.63
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 129.3480
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.36s
                      Time elapsed: 00:19:11
                               ETA: 00:35:54

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 45839 steps/s (collection: 2.050s, learning 0.095s)
             Mean action noise std: 1.90
          Mean value_function loss: 95.9486
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.0446
                       Mean reward: 640.61
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.0537
    Episode_Reward/rotating_object: 127.5259
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.14s
                      Time elapsed: 00:19:14
                               ETA: 00:35:51

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 45628 steps/s (collection: 2.052s, learning 0.102s)
             Mean action noise std: 1.91
          Mean value_function loss: 75.6816
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.0560
                       Mean reward: 664.76
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.0617
    Episode_Reward/rotating_object: 126.2882
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.15s
                      Time elapsed: 00:19:16
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 39560 steps/s (collection: 2.283s, learning 0.202s)
             Mean action noise std: 1.91
          Mean value_function loss: 84.4038
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.0677
                       Mean reward: 690.84
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 131.2420
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.48s
                      Time elapsed: 00:19:18
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 41267 steps/s (collection: 2.204s, learning 0.178s)
             Mean action noise std: 1.91
          Mean value_function loss: 65.1076
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.0795
                       Mean reward: 671.45
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 130.7883
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.38s
                      Time elapsed: 00:19:21
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 42600 steps/s (collection: 2.190s, learning 0.118s)
             Mean action noise std: 1.91
          Mean value_function loss: 75.7789
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.0970
                       Mean reward: 657.73
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 130.5337
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.31s
                      Time elapsed: 00:19:23
                               ETA: 00:35:43

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 42824 steps/s (collection: 2.088s, learning 0.208s)
             Mean action noise std: 1.91
          Mean value_function loss: 69.1281
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.1083
                       Mean reward: 666.60
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 130.4366
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.30s
                      Time elapsed: 00:19:25
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 41219 steps/s (collection: 2.214s, learning 0.171s)
             Mean action noise std: 1.91
          Mean value_function loss: 71.6813
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.1174
                       Mean reward: 692.96
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 131.4642
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.38s
                      Time elapsed: 00:19:28
                               ETA: 00:35:40

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 44867 steps/s (collection: 2.066s, learning 0.125s)
             Mean action noise std: 1.91
          Mean value_function loss: 75.2091
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.1298
                       Mean reward: 653.08
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0515
    Episode_Reward/rotating_object: 127.6519
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.19s
                      Time elapsed: 00:19:30
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 42421 steps/s (collection: 2.144s, learning 0.173s)
             Mean action noise std: 1.91
          Mean value_function loss: 76.2975
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.1401
                       Mean reward: 629.59
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.0473
    Episode_Reward/rotating_object: 127.1174
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.32s
                      Time elapsed: 00:19:32
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 41113 steps/s (collection: 2.195s, learning 0.196s)
             Mean action noise std: 1.92
          Mean value_function loss: 67.8215
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.1534
                       Mean reward: 677.25
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.0498
    Episode_Reward/rotating_object: 129.3353
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.39s
                      Time elapsed: 00:19:35
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 41886 steps/s (collection: 2.199s, learning 0.148s)
             Mean action noise std: 1.92
          Mean value_function loss: 81.6181
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.1711
                       Mean reward: 656.92
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.0458
    Episode_Reward/rotating_object: 129.9149
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.35s
                      Time elapsed: 00:19:37
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 40989 steps/s (collection: 2.244s, learning 0.155s)
             Mean action noise std: 1.92
          Mean value_function loss: 82.0571
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.1857
                       Mean reward: 646.25
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.0720
    Episode_Reward/rotating_object: 131.6435
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.40s
                      Time elapsed: 00:19:39
                               ETA: 00:35:30

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 37476 steps/s (collection: 2.422s, learning 0.201s)
             Mean action noise std: 1.92
          Mean value_function loss: 85.6736
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 45.2018
                       Mean reward: 585.08
               Mean episode length: 220.52
    Episode_Reward/reaching_object: 1.0342
    Episode_Reward/rotating_object: 126.6327
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.62s
                      Time elapsed: 00:19:42
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 38108 steps/s (collection: 2.470s, learning 0.110s)
             Mean action noise std: 1.92
          Mean value_function loss: 78.1382
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.2231
                       Mean reward: 655.27
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 130.6788
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.58s
                      Time elapsed: 00:19:44
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 42234 steps/s (collection: 2.219s, learning 0.109s)
             Mean action noise std: 1.92
          Mean value_function loss: 72.7295
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.2491
                       Mean reward: 640.33
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 131.5263
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.33s
                      Time elapsed: 00:19:47
                               ETA: 00:35:25

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 41671 steps/s (collection: 2.225s, learning 0.134s)
             Mean action noise std: 1.93
          Mean value_function loss: 79.2907
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.2706
                       Mean reward: 664.30
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.0894
    Episode_Reward/rotating_object: 133.4444
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.36s
                      Time elapsed: 00:19:49
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 41220 steps/s (collection: 2.264s, learning 0.121s)
             Mean action noise std: 1.93
          Mean value_function loss: 71.6406
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.2862
                       Mean reward: 649.58
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 132.0838
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.38s
                      Time elapsed: 00:19:52
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 40294 steps/s (collection: 2.314s, learning 0.126s)
             Mean action noise std: 1.93
          Mean value_function loss: 70.1032
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.3013
                       Mean reward: 673.67
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.0788
    Episode_Reward/rotating_object: 130.7272
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.44s
                      Time elapsed: 00:19:54
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 41336 steps/s (collection: 2.244s, learning 0.134s)
             Mean action noise std: 1.93
          Mean value_function loss: 89.7151
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.3205
                       Mean reward: 695.21
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.0672
    Episode_Reward/rotating_object: 131.3989
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.38s
                      Time elapsed: 00:19:56
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 45231 steps/s (collection: 2.042s, learning 0.132s)
             Mean action noise std: 1.93
          Mean value_function loss: 76.4183
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.3326
                       Mean reward: 673.59
               Mean episode length: 234.89
    Episode_Reward/reaching_object: 1.0834
    Episode_Reward/rotating_object: 134.5292
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.17s
                      Time elapsed: 00:19:59
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 45319 steps/s (collection: 2.075s, learning 0.094s)
             Mean action noise std: 1.93
          Mean value_function loss: 66.1831
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.3488
                       Mean reward: 676.28
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 130.7397
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.17s
                      Time elapsed: 00:20:01
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 46096 steps/s (collection: 2.031s, learning 0.101s)
             Mean action noise std: 1.93
          Mean value_function loss: 70.7821
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.3678
                       Mean reward: 622.61
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 132.1685
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.13s
                      Time elapsed: 00:20:03
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 46220 steps/s (collection: 2.030s, learning 0.097s)
             Mean action noise std: 1.94
          Mean value_function loss: 68.9203
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.3867
                       Mean reward: 625.87
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.0884
    Episode_Reward/rotating_object: 133.6635
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.13s
                      Time elapsed: 00:20:05
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 46373 steps/s (collection: 2.018s, learning 0.101s)
             Mean action noise std: 1.94
          Mean value_function loss: 66.6969
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.4076
                       Mean reward: 702.96
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.0764
    Episode_Reward/rotating_object: 133.5795
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.12s
                      Time elapsed: 00:20:07
                               ETA: 00:35:06

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 44703 steps/s (collection: 2.066s, learning 0.133s)
             Mean action noise std: 1.94
          Mean value_function loss: 79.3816
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.4263
                       Mean reward: 602.96
               Mean episode length: 216.02
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 128.6583
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.20s
                      Time elapsed: 00:20:09
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 44355 steps/s (collection: 2.059s, learning 0.157s)
             Mean action noise std: 1.94
          Mean value_function loss: 78.3249
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.4387
                       Mean reward: 693.73
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.0635
    Episode_Reward/rotating_object: 131.8403
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.22s
                      Time elapsed: 00:20:11
                               ETA: 00:35:01

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 45302 steps/s (collection: 2.066s, learning 0.104s)
             Mean action noise std: 1.94
          Mean value_function loss: 75.3341
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.4522
                       Mean reward: 632.36
               Mean episode length: 220.05
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 128.4670
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.17s
                      Time elapsed: 00:20:14
                               ETA: 00:34:59

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 44941 steps/s (collection: 2.076s, learning 0.111s)
             Mean action noise std: 1.94
          Mean value_function loss: 74.2930
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.4743
                       Mean reward: 665.78
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.0819
    Episode_Reward/rotating_object: 131.7173
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.19s
                      Time elapsed: 00:20:16
                               ETA: 00:34:57

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 44218 steps/s (collection: 2.113s, learning 0.110s)
             Mean action noise std: 1.95
          Mean value_function loss: 75.0282
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.4908
                       Mean reward: 682.07
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 1.0970
    Episode_Reward/rotating_object: 133.1912
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.22s
                      Time elapsed: 00:20:18
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 45793 steps/s (collection: 2.044s, learning 0.103s)
             Mean action noise std: 1.95
          Mean value_function loss: 64.3205
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.5088
                       Mean reward: 677.52
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.0876
    Episode_Reward/rotating_object: 132.8864
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.15s
                      Time elapsed: 00:20:20
                               ETA: 00:34:52

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 43742 steps/s (collection: 2.054s, learning 0.193s)
             Mean action noise std: 1.95
          Mean value_function loss: 62.2061
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.5243
                       Mean reward: 718.26
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 1.0938
    Episode_Reward/rotating_object: 135.8801
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.25s
                      Time elapsed: 00:20:22
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 46140 steps/s (collection: 2.027s, learning 0.104s)
             Mean action noise std: 1.95
          Mean value_function loss: 60.7228
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.5399
                       Mean reward: 706.05
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 138.9100
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.13s
                      Time elapsed: 00:20:25
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 45755 steps/s (collection: 2.047s, learning 0.101s)
             Mean action noise std: 1.95
          Mean value_function loss: 64.9705
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.5526
                       Mean reward: 676.19
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 131.0041
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.15s
                      Time elapsed: 00:20:27
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 43890 steps/s (collection: 2.142s, learning 0.098s)
             Mean action noise std: 1.95
          Mean value_function loss: 73.5564
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.5670
                       Mean reward: 601.74
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 1.0583
    Episode_Reward/rotating_object: 131.5239
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.24s
                      Time elapsed: 00:20:29
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 45903 steps/s (collection: 2.042s, learning 0.100s)
             Mean action noise std: 1.96
          Mean value_function loss: 76.0505
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.5844
                       Mean reward: 671.57
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.0860
    Episode_Reward/rotating_object: 135.7612
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.14s
                      Time elapsed: 00:20:31
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 46082 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 1.96
          Mean value_function loss: 64.8904
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.6018
                       Mean reward: 694.75
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 135.8992
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.13s
                      Time elapsed: 00:20:33
                               ETA: 00:34:39

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 44752 steps/s (collection: 2.065s, learning 0.132s)
             Mean action noise std: 1.96
          Mean value_function loss: 71.6254
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.6213
                       Mean reward: 701.78
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.0430
    Episode_Reward/rotating_object: 128.8030
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.20s
                      Time elapsed: 00:20:35
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 44929 steps/s (collection: 2.061s, learning 0.127s)
             Mean action noise std: 1.96
          Mean value_function loss: 58.6902
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.6407
                       Mean reward: 680.27
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.0778
    Episode_Reward/rotating_object: 134.5386
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.19s
                      Time elapsed: 00:20:38
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 45280 steps/s (collection: 2.079s, learning 0.092s)
             Mean action noise std: 1.96
          Mean value_function loss: 75.6601
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.6548
                       Mean reward: 701.70
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 1.0820
    Episode_Reward/rotating_object: 133.8010
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.17s
                      Time elapsed: 00:20:40
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 45129 steps/s (collection: 2.050s, learning 0.129s)
             Mean action noise std: 1.96
          Mean value_function loss: 75.1576
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.6739
                       Mean reward: 663.20
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 129.1654
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.18s
                      Time elapsed: 00:20:42
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 44673 steps/s (collection: 2.089s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 65.1212
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 45.6947
                       Mean reward: 716.25
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.1022
    Episode_Reward/rotating_object: 141.1372
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.20s
                      Time elapsed: 00:20:44
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 45952 steps/s (collection: 2.018s, learning 0.122s)
             Mean action noise std: 1.97
          Mean value_function loss: 67.2835
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.7206
                       Mean reward: 721.22
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 135.4787
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.14s
                      Time elapsed: 00:20:46
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 43301 steps/s (collection: 2.117s, learning 0.153s)
             Mean action noise std: 1.97
          Mean value_function loss: 68.2197
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.7372
                       Mean reward: 685.37
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.0888
    Episode_Reward/rotating_object: 136.9035
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.27s
                      Time elapsed: 00:20:49
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 46312 steps/s (collection: 2.030s, learning 0.093s)
             Mean action noise std: 1.97
          Mean value_function loss: 72.4416
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.7514
                       Mean reward: 662.11
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 134.7053
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.12s
                      Time elapsed: 00:20:51
                               ETA: 00:34:21

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 44569 steps/s (collection: 2.083s, learning 0.123s)
             Mean action noise std: 1.97
          Mean value_function loss: 70.3968
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.7704
                       Mean reward: 688.17
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 134.1342
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.21s
                      Time elapsed: 00:20:53
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 43869 steps/s (collection: 2.140s, learning 0.101s)
             Mean action noise std: 1.98
          Mean value_function loss: 70.9799
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.7893
                       Mean reward: 694.24
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 135.6897
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.24s
                      Time elapsed: 00:20:55
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 43200 steps/s (collection: 2.078s, learning 0.197s)
             Mean action noise std: 1.98
          Mean value_function loss: 61.1963
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.8070
                       Mean reward: 712.73
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 1.0885
    Episode_Reward/rotating_object: 136.8501
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.28s
                      Time elapsed: 00:20:57
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 45350 steps/s (collection: 1.997s, learning 0.171s)
             Mean action noise std: 1.98
          Mean value_function loss: 64.4367
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.8237
                       Mean reward: 694.62
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 133.7366
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.17s
                      Time elapsed: 00:21:00
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 46159 steps/s (collection: 2.026s, learning 0.104s)
             Mean action noise std: 1.98
          Mean value_function loss: 71.0402
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.8356
                       Mean reward: 671.03
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 131.9184
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.13s
                      Time elapsed: 00:21:02
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 46036 steps/s (collection: 2.035s, learning 0.101s)
             Mean action noise std: 1.98
          Mean value_function loss: 62.4042
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.8563
                       Mean reward: 675.49
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 133.8576
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.14s
                      Time elapsed: 00:21:04
                               ETA: 00:34:07

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 46466 steps/s (collection: 2.022s, learning 0.094s)
             Mean action noise std: 1.98
          Mean value_function loss: 66.1240
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.8760
                       Mean reward: 639.57
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 134.4533
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.12s
                      Time elapsed: 00:21:06
                               ETA: 00:34:05

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 44187 steps/s (collection: 2.117s, learning 0.108s)
             Mean action noise std: 1.99
          Mean value_function loss: 62.6620
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.8952
                       Mean reward: 704.42
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 134.9226
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.22s
                      Time elapsed: 00:21:08
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 45693 steps/s (collection: 2.027s, learning 0.125s)
             Mean action noise std: 1.99
          Mean value_function loss: 61.2781
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.9248
                       Mean reward: 694.42
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.0977
    Episode_Reward/rotating_object: 136.7796
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.15s
                      Time elapsed: 00:21:10
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 42573 steps/s (collection: 2.108s, learning 0.201s)
             Mean action noise std: 1.99
          Mean value_function loss: 78.8819
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.9468
                       Mean reward: 671.94
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.0848
    Episode_Reward/rotating_object: 134.0572
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.31s
                      Time elapsed: 00:21:13
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 45982 steps/s (collection: 2.037s, learning 0.101s)
             Mean action noise std: 1.99
          Mean value_function loss: 58.9565
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.9622
                       Mean reward: 689.86
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 135.6163
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.14s
                      Time elapsed: 00:21:15
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 43936 steps/s (collection: 2.073s, learning 0.165s)
             Mean action noise std: 1.99
          Mean value_function loss: 56.0899
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.9769
                       Mean reward: 711.37
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 1.1042
    Episode_Reward/rotating_object: 138.4165
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.24s
                      Time elapsed: 00:21:17
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 44439 steps/s (collection: 2.095s, learning 0.117s)
             Mean action noise std: 1.99
          Mean value_function loss: 60.1166
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.9926
                       Mean reward: 697.91
               Mean episode length: 247.14
    Episode_Reward/reaching_object: 1.1157
    Episode_Reward/rotating_object: 136.6053
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.21s
                      Time elapsed: 00:21:19
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 44383 steps/s (collection: 2.069s, learning 0.146s)
             Mean action noise std: 2.00
          Mean value_function loss: 59.8833
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.0056
                       Mean reward: 697.51
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.1003
    Episode_Reward/rotating_object: 139.8814
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.21s
                      Time elapsed: 00:21:21
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 44051 steps/s (collection: 2.091s, learning 0.141s)
             Mean action noise std: 2.00
          Mean value_function loss: 68.2125
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.0271
                       Mean reward: 653.76
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.1043
    Episode_Reward/rotating_object: 136.9525
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.23s
                      Time elapsed: 00:21:24
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 45251 steps/s (collection: 2.063s, learning 0.110s)
             Mean action noise std: 2.00
          Mean value_function loss: 73.6363
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.0567
                       Mean reward: 664.11
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 132.7810
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.17s
                      Time elapsed: 00:21:26
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 45760 steps/s (collection: 2.040s, learning 0.108s)
             Mean action noise std: 2.00
          Mean value_function loss: 77.8413
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.0815
                       Mean reward: 665.41
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 1.1087
    Episode_Reward/rotating_object: 137.7501
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.15s
                      Time elapsed: 00:21:28
                               ETA: 00:33:43

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 45582 steps/s (collection: 2.046s, learning 0.111s)
             Mean action noise std: 2.01
          Mean value_function loss: 68.5054
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.1022
                       Mean reward: 652.64
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 131.5102
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.16s
                      Time elapsed: 00:21:30
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 44116 steps/s (collection: 2.131s, learning 0.098s)
             Mean action noise std: 2.01
          Mean value_function loss: 65.2322
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.1176
                       Mean reward: 679.64
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.1125
    Episode_Reward/rotating_object: 138.6808
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.23s
                      Time elapsed: 00:21:32
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 45435 steps/s (collection: 2.026s, learning 0.137s)
             Mean action noise std: 2.01
          Mean value_function loss: 76.8362
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.1322
                       Mean reward: 644.48
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 1.1013
    Episode_Reward/rotating_object: 135.0941
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.16s
                      Time elapsed: 00:21:35
                               ETA: 00:33:36

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 43804 steps/s (collection: 2.063s, learning 0.182s)
             Mean action noise std: 2.01
          Mean value_function loss: 73.8789
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.1491
                       Mean reward: 672.94
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.0798
    Episode_Reward/rotating_object: 133.3587
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.24s
                      Time elapsed: 00:21:37
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 42445 steps/s (collection: 2.148s, learning 0.168s)
             Mean action noise std: 2.01
          Mean value_function loss: 71.5098
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.1749
                       Mean reward: 680.67
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.1034
    Episode_Reward/rotating_object: 137.1055
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.32s
                      Time elapsed: 00:21:39
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 38969 steps/s (collection: 2.319s, learning 0.204s)
             Mean action noise std: 2.01
          Mean value_function loss: 74.5847
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.1940
                       Mean reward: 694.91
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.0876
    Episode_Reward/rotating_object: 135.1644
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.52s
                      Time elapsed: 00:21:42
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 41532 steps/s (collection: 2.215s, learning 0.152s)
             Mean action noise std: 2.02
          Mean value_function loss: 64.2185
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.2087
                       Mean reward: 706.28
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.1009
    Episode_Reward/rotating_object: 138.9929
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.37s
                      Time elapsed: 00:21:44
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 44674 steps/s (collection: 2.063s, learning 0.138s)
             Mean action noise std: 2.02
          Mean value_function loss: 58.4939
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.2234
                       Mean reward: 711.49
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 1.0792
    Episode_Reward/rotating_object: 132.7340
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.20s
                      Time elapsed: 00:21:46
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 45814 steps/s (collection: 2.050s, learning 0.096s)
             Mean action noise std: 2.02
          Mean value_function loss: 65.1354
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.2383
                       Mean reward: 738.27
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 1.1029
    Episode_Reward/rotating_object: 139.4935
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.15s
                      Time elapsed: 00:21:48
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 41368 steps/s (collection: 2.151s, learning 0.225s)
             Mean action noise std: 2.02
          Mean value_function loss: 74.4046
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.2636
                       Mean reward: 650.56
               Mean episode length: 227.62
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 134.2618
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.38s
                      Time elapsed: 00:21:51
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 42992 steps/s (collection: 2.125s, learning 0.161s)
             Mean action noise std: 2.02
          Mean value_function loss: 70.2450
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.2868
                       Mean reward: 672.53
               Mean episode length: 235.32
    Episode_Reward/reaching_object: 1.0670
    Episode_Reward/rotating_object: 131.8600
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.29s
                      Time elapsed: 00:21:53
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 42591 steps/s (collection: 2.188s, learning 0.120s)
             Mean action noise std: 2.03
          Mean value_function loss: 62.5814
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.3193
                       Mean reward: 728.68
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 1.1024
    Episode_Reward/rotating_object: 136.7615
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.31s
                      Time elapsed: 00:21:55
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 44636 steps/s (collection: 2.086s, learning 0.116s)
             Mean action noise std: 2.03
          Mean value_function loss: 76.0717
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.3402
                       Mean reward: 652.61
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 134.6178
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.20s
                      Time elapsed: 00:21:58
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 43888 steps/s (collection: 2.055s, learning 0.185s)
             Mean action noise std: 2.03
          Mean value_function loss: 78.3546
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.3576
                       Mean reward: 622.89
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 130.0834
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.24s
                      Time elapsed: 00:22:00
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 45351 steps/s (collection: 2.002s, learning 0.166s)
             Mean action noise std: 2.03
          Mean value_function loss: 65.2887
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.3771
                       Mean reward: 666.49
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 134.7344
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.17s
                      Time elapsed: 00:22:02
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 45756 steps/s (collection: 2.045s, learning 0.104s)
             Mean action noise std: 2.03
          Mean value_function loss: 66.4526
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.3994
                       Mean reward: 687.96
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.0842
    Episode_Reward/rotating_object: 136.6833
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.15s
                      Time elapsed: 00:22:04
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 43634 steps/s (collection: 2.137s, learning 0.116s)
             Mean action noise std: 2.04
          Mean value_function loss: 85.9985
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.4143
                       Mean reward: 664.70
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.0726
    Episode_Reward/rotating_object: 134.7808
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.25s
                      Time elapsed: 00:22:06
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 44264 steps/s (collection: 2.101s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 67.4134
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.4330
                       Mean reward: 703.47
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.0923
    Episode_Reward/rotating_object: 136.1369
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.22s
                      Time elapsed: 00:22:09
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 45059 steps/s (collection: 2.057s, learning 0.124s)
             Mean action noise std: 2.04
          Mean value_function loss: 61.7497
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.4524
                       Mean reward: 677.96
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 134.8768
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.18s
                      Time elapsed: 00:22:11
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 44169 steps/s (collection: 2.087s, learning 0.138s)
             Mean action noise std: 2.04
          Mean value_function loss: 58.8742
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.4684
                       Mean reward: 698.37
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 134.7558
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.23s
                      Time elapsed: 00:22:13
                               ETA: 00:33:00

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 46154 steps/s (collection: 2.009s, learning 0.121s)
             Mean action noise std: 2.04
          Mean value_function loss: 59.2752
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.4818
                       Mean reward: 689.12
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 138.1171
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.13s
                      Time elapsed: 00:22:15
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 44323 steps/s (collection: 2.118s, learning 0.100s)
             Mean action noise std: 2.05
          Mean value_function loss: 71.0950
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.5004
                       Mean reward: 654.77
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 1.0810
    Episode_Reward/rotating_object: 133.4789
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.22s
                      Time elapsed: 00:22:17
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 45715 steps/s (collection: 2.055s, learning 0.095s)
             Mean action noise std: 2.05
          Mean value_function loss: 75.3871
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.5196
                       Mean reward: 717.62
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.0878
    Episode_Reward/rotating_object: 138.1333
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.15s
                      Time elapsed: 00:22:19
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 43049 steps/s (collection: 2.065s, learning 0.218s)
             Mean action noise std: 2.05
          Mean value_function loss: 52.0524
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.5401
                       Mean reward: 687.51
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 133.2728
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.28s
                      Time elapsed: 00:22:22
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 43951 steps/s (collection: 2.110s, learning 0.127s)
             Mean action noise std: 2.05
          Mean value_function loss: 67.3711
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.5514
                       Mean reward: 677.45
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.1002
    Episode_Reward/rotating_object: 137.8505
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.24s
                      Time elapsed: 00:22:24
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 46221 steps/s (collection: 2.020s, learning 0.107s)
             Mean action noise std: 2.05
          Mean value_function loss: 65.0562
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.5695
                       Mean reward: 658.37
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 1.1000
    Episode_Reward/rotating_object: 132.9434
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.13s
                      Time elapsed: 00:22:26
                               ETA: 00:32:46

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 44151 steps/s (collection: 2.121s, learning 0.106s)
             Mean action noise std: 2.05
          Mean value_function loss: 64.1073
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.5927
                       Mean reward: 737.70
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 140.3780
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.23s
                      Time elapsed: 00:22:28
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 45271 steps/s (collection: 2.068s, learning 0.103s)
             Mean action noise std: 2.06
          Mean value_function loss: 60.2276
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 46.6120
                       Mean reward: 693.17
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.0641
    Episode_Reward/rotating_object: 133.9086
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.17s
                      Time elapsed: 00:22:31
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 44144 steps/s (collection: 2.080s, learning 0.147s)
             Mean action noise std: 2.06
          Mean value_function loss: 72.4276
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.6388
                       Mean reward: 691.41
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.1019
    Episode_Reward/rotating_object: 139.8717
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.23s
                      Time elapsed: 00:22:33
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 44863 steps/s (collection: 2.024s, learning 0.167s)
             Mean action noise std: 2.06
          Mean value_function loss: 58.4111
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.6651
                       Mean reward: 669.68
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 1.0920
    Episode_Reward/rotating_object: 137.1162
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.19s
                      Time elapsed: 00:22:35
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 46355 steps/s (collection: 2.010s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 69.7800
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.6872
                       Mean reward: 696.31
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.1028
    Episode_Reward/rotating_object: 139.4080
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.12s
                      Time elapsed: 00:22:37
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 44196 steps/s (collection: 2.075s, learning 0.149s)
             Mean action noise std: 2.07
          Mean value_function loss: 60.7286
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.7086
                       Mean reward: 679.19
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.0912
    Episode_Reward/rotating_object: 137.3582
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.22s
                      Time elapsed: 00:22:39
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 46210 steps/s (collection: 2.017s, learning 0.110s)
             Mean action noise std: 2.07
          Mean value_function loss: 58.3003
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.7259
                       Mean reward: 709.75
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 1.1195
    Episode_Reward/rotating_object: 141.8425
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.13s
                      Time elapsed: 00:22:41
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 45637 steps/s (collection: 2.046s, learning 0.108s)
             Mean action noise std: 2.07
          Mean value_function loss: 61.9626
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.7421
                       Mean reward: 679.67
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 136.9988
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.15s
                      Time elapsed: 00:22:44
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 43640 steps/s (collection: 2.082s, learning 0.171s)
             Mean action noise std: 2.07
          Mean value_function loss: 53.7751
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.7672
                       Mean reward: 672.24
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.1052
    Episode_Reward/rotating_object: 138.7482
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.25s
                      Time elapsed: 00:22:46
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 45404 steps/s (collection: 2.013s, learning 0.153s)
             Mean action noise std: 2.08
          Mean value_function loss: 50.8512
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.7948
                       Mean reward: 700.36
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.1142
    Episode_Reward/rotating_object: 142.6698
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.17s
                      Time elapsed: 00:22:48
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 45366 steps/s (collection: 2.057s, learning 0.110s)
             Mean action noise std: 2.08
          Mean value_function loss: 68.6113
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.8186
                       Mean reward: 672.60
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 1.0829
    Episode_Reward/rotating_object: 137.5155
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.17s
                      Time elapsed: 00:22:50
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 45749 steps/s (collection: 2.014s, learning 0.135s)
             Mean action noise std: 2.08
          Mean value_function loss: 49.1569
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.8421
                       Mean reward: 717.47
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 1.1123
    Episode_Reward/rotating_object: 141.5153
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.15s
                      Time elapsed: 00:22:52
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 44185 steps/s (collection: 2.124s, learning 0.101s)
             Mean action noise std: 2.08
          Mean value_function loss: 65.6957
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.8580
                       Mean reward: 729.10
               Mean episode length: 246.60
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 137.1108
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.22s
                      Time elapsed: 00:22:55
                               ETA: 00:32:17

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 47544 steps/s (collection: 1.966s, learning 0.102s)
             Mean action noise std: 2.08
          Mean value_function loss: 52.0609
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.8823
                       Mean reward: 668.92
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.0883
    Episode_Reward/rotating_object: 135.2358
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.07s
                      Time elapsed: 00:22:57
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 45836 steps/s (collection: 2.040s, learning 0.104s)
             Mean action noise std: 2.09
          Mean value_function loss: 58.6064
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.9095
                       Mean reward: 722.70
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.1050
    Episode_Reward/rotating_object: 139.7782
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.14s
                      Time elapsed: 00:22:59
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 44282 steps/s (collection: 2.043s, learning 0.177s)
             Mean action noise std: 2.09
          Mean value_function loss: 57.6746
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.9270
                       Mean reward: 708.76
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 1.1035
    Episode_Reward/rotating_object: 137.5384
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.22s
                      Time elapsed: 00:23:01
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 45751 steps/s (collection: 1.986s, learning 0.163s)
             Mean action noise std: 2.09
          Mean value_function loss: 64.5369
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.9488
                       Mean reward: 698.45
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.1001
    Episode_Reward/rotating_object: 139.1995
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.15s
                      Time elapsed: 00:23:03
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 46537 steps/s (collection: 1.988s, learning 0.124s)
             Mean action noise std: 2.09
          Mean value_function loss: 56.5937
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.9624
                       Mean reward: 726.20
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 1.0998
    Episode_Reward/rotating_object: 140.5445
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.11s
                      Time elapsed: 00:23:05
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 45860 steps/s (collection: 2.054s, learning 0.090s)
             Mean action noise std: 2.09
          Mean value_function loss: 66.8690
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.9738
                       Mean reward: 702.92
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 1.0859
    Episode_Reward/rotating_object: 136.7373
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.14s
                      Time elapsed: 00:23:07
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 45851 steps/s (collection: 2.034s, learning 0.110s)
             Mean action noise std: 2.10
          Mean value_function loss: 77.3370
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.9976
                       Mean reward: 634.66
               Mean episode length: 224.79
    Episode_Reward/reaching_object: 1.0890
    Episode_Reward/rotating_object: 137.9618
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.14s
                      Time elapsed: 00:23:10
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 46502 steps/s (collection: 2.016s, learning 0.098s)
             Mean action noise std: 2.10
          Mean value_function loss: 68.8251
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.0256
                       Mean reward: 735.90
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.0934
    Episode_Reward/rotating_object: 138.1688
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.11s
                      Time elapsed: 00:23:12
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 46618 steps/s (collection: 2.007s, learning 0.102s)
             Mean action noise std: 2.10
          Mean value_function loss: 56.4544
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.0442
                       Mean reward: 685.13
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 1.1042
    Episode_Reward/rotating_object: 139.6363
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.11s
                      Time elapsed: 00:23:14
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 46134 steps/s (collection: 2.003s, learning 0.128s)
             Mean action noise std: 2.10
          Mean value_function loss: 66.2109
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 47.0665
                       Mean reward: 724.08
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.1107
    Episode_Reward/rotating_object: 140.6859
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.13s
                      Time elapsed: 00:23:16
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 45545 steps/s (collection: 2.023s, learning 0.136s)
             Mean action noise std: 2.11
          Mean value_function loss: 64.6824
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.1019
                       Mean reward: 691.57
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 1.0818
    Episode_Reward/rotating_object: 134.5321
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.16s
                      Time elapsed: 00:23:18
                               ETA: 00:31:52

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 45365 steps/s (collection: 2.072s, learning 0.095s)
             Mean action noise std: 2.11
          Mean value_function loss: 60.6164
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.1294
                       Mean reward: 689.03
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.1020
    Episode_Reward/rotating_object: 136.8475
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.17s
                      Time elapsed: 00:23:20
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 46226 steps/s (collection: 2.030s, learning 0.097s)
             Mean action noise std: 2.12
          Mean value_function loss: 55.1827
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.1748
                       Mean reward: 734.55
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 1.1224
    Episode_Reward/rotating_object: 142.0334
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.13s
                      Time elapsed: 00:23:22
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 46547 steps/s (collection: 2.018s, learning 0.094s)
             Mean action noise std: 2.12
          Mean value_function loss: 57.6632
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.2100
                       Mean reward: 723.82
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 1.1080
    Episode_Reward/rotating_object: 141.9426
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.11s
                      Time elapsed: 00:23:24
                               ETA: 00:31:45

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 44978 steps/s (collection: 2.073s, learning 0.113s)
             Mean action noise std: 2.12
          Mean value_function loss: 53.2031
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.2303
                       Mean reward: 649.14
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.1115
    Episode_Reward/rotating_object: 140.3360
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.19s
                      Time elapsed: 00:23:27
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 45716 steps/s (collection: 2.048s, learning 0.102s)
             Mean action noise std: 2.12
          Mean value_function loss: 59.3180
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.2535
                       Mean reward: 694.09
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.1149
    Episode_Reward/rotating_object: 139.8433
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 19.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.15s
                      Time elapsed: 00:23:29
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 46319 steps/s (collection: 2.016s, learning 0.106s)
             Mean action noise std: 2.12
          Mean value_function loss: 56.0359
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.2780
                       Mean reward: 694.81
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 1.1042
    Episode_Reward/rotating_object: 140.8337
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.12s
                      Time elapsed: 00:23:31
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 46327 steps/s (collection: 2.031s, learning 0.091s)
             Mean action noise std: 2.13
          Mean value_function loss: 57.6904
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.3032
                       Mean reward: 704.75
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 1.1235
    Episode_Reward/rotating_object: 142.2312
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.12s
                      Time elapsed: 00:23:33
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 45274 steps/s (collection: 2.014s, learning 0.158s)
             Mean action noise std: 2.13
          Mean value_function loss: 50.6037
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.3262
                       Mean reward: 694.65
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.1121
    Episode_Reward/rotating_object: 139.5648
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.17s
                      Time elapsed: 00:23:35
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 46146 steps/s (collection: 2.035s, learning 0.095s)
             Mean action noise std: 2.13
          Mean value_function loss: 43.6745
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.3460
                       Mean reward: 744.33
               Mean episode length: 247.22
    Episode_Reward/reaching_object: 1.1147
    Episode_Reward/rotating_object: 141.4244
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.13s
                      Time elapsed: 00:23:37
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 46026 steps/s (collection: 2.029s, learning 0.107s)
             Mean action noise std: 2.13
          Mean value_function loss: 62.9869
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.3674
                       Mean reward: 687.91
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.1067
    Episode_Reward/rotating_object: 140.1573
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.14s
                      Time elapsed: 00:23:39
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 41613 steps/s (collection: 2.219s, learning 0.144s)
             Mean action noise std: 2.14
          Mean value_function loss: 57.8542
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.3917
                       Mean reward: 689.56
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.0958
    Episode_Reward/rotating_object: 138.2227
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.36s
                      Time elapsed: 00:23:42
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 44115 steps/s (collection: 2.052s, learning 0.177s)
             Mean action noise std: 2.14
          Mean value_function loss: 57.3564
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.4131
                       Mean reward: 695.34
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.1089
    Episode_Reward/rotating_object: 140.1668
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.23s
                      Time elapsed: 00:23:44
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 43983 steps/s (collection: 2.101s, learning 0.134s)
             Mean action noise std: 2.14
          Mean value_function loss: 66.2714
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.4344
                       Mean reward: 717.12
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 1.1107
    Episode_Reward/rotating_object: 143.6287
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.24s
                      Time elapsed: 00:23:46
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 45973 steps/s (collection: 2.018s, learning 0.120s)
             Mean action noise std: 2.14
          Mean value_function loss: 58.2775
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.4588
                       Mean reward: 725.64
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.1087
    Episode_Reward/rotating_object: 141.3125
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.14s
                      Time elapsed: 00:23:48
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.016s, learning 0.118s)
             Mean action noise std: 2.15
          Mean value_function loss: 54.8419
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.4822
                       Mean reward: 669.26
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 141.9456
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 18.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.13s
                      Time elapsed: 00:23:51
                               ETA: 00:31:18

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 42743 steps/s (collection: 2.187s, learning 0.113s)
             Mean action noise std: 2.15
          Mean value_function loss: 62.4134
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.4991
                       Mean reward: 706.20
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.0984
    Episode_Reward/rotating_object: 140.4398
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.30s
                      Time elapsed: 00:23:53
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 43848 steps/s (collection: 2.137s, learning 0.105s)
             Mean action noise std: 2.15
          Mean value_function loss: 67.3552
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.5130
                       Mean reward: 698.58
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 135.8775
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.24s
                      Time elapsed: 00:23:55
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 43029 steps/s (collection: 2.165s, learning 0.120s)
             Mean action noise std: 2.15
          Mean value_function loss: 55.3743
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.5357
                       Mean reward: 734.66
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.1147
    Episode_Reward/rotating_object: 143.6220
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.28s
                      Time elapsed: 00:23:57
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 44322 steps/s (collection: 2.097s, learning 0.121s)
             Mean action noise std: 2.15
          Mean value_function loss: 68.2037
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.5573
                       Mean reward: 690.95
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.1007
    Episode_Reward/rotating_object: 142.0042
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.22s
                      Time elapsed: 00:24:00
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 43308 steps/s (collection: 2.178s, learning 0.092s)
             Mean action noise std: 2.16
          Mean value_function loss: 45.6684
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.5756
                       Mean reward: 717.60
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.1039
    Episode_Reward/rotating_object: 140.6217
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.27s
                      Time elapsed: 00:24:02
                               ETA: 00:31:08

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 43987 steps/s (collection: 2.117s, learning 0.118s)
             Mean action noise std: 2.16
          Mean value_function loss: 53.2126
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.5946
                       Mean reward: 734.04
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.0939
    Episode_Reward/rotating_object: 137.7300
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.23s
                      Time elapsed: 00:24:04
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 44807 steps/s (collection: 2.090s, learning 0.104s)
             Mean action noise std: 2.16
          Mean value_function loss: 50.2439
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.6179
                       Mean reward: 697.50
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.1198
    Episode_Reward/rotating_object: 140.4809
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.19s
                      Time elapsed: 00:24:06
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 45614 steps/s (collection: 2.057s, learning 0.099s)
             Mean action noise std: 2.16
          Mean value_function loss: 52.9849
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.6473
                       Mean reward: 728.88
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.1152
    Episode_Reward/rotating_object: 142.4057
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.16s
                      Time elapsed: 00:24:08
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 44637 steps/s (collection: 2.089s, learning 0.113s)
             Mean action noise std: 2.17
          Mean value_function loss: 53.7261
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.6644
                       Mean reward: 679.43
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.0883
    Episode_Reward/rotating_object: 137.6125
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.20s
                      Time elapsed: 00:24:11
                               ETA: 00:30:59

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 44866 steps/s (collection: 2.079s, learning 0.113s)
             Mean action noise std: 2.17
          Mean value_function loss: 54.6210
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.6770
                       Mean reward: 706.55
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.1099
    Episode_Reward/rotating_object: 141.9896
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.19s
                      Time elapsed: 00:24:13
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 44511 steps/s (collection: 2.091s, learning 0.118s)
             Mean action noise std: 2.17
          Mean value_function loss: 52.6473
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.6984
                       Mean reward: 684.36
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.1126
    Episode_Reward/rotating_object: 142.8907
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.21s
                      Time elapsed: 00:24:15
                               ETA: 00:30:54

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 44203 steps/s (collection: 2.119s, learning 0.105s)
             Mean action noise std: 2.17
          Mean value_function loss: 58.5345
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.7371
                       Mean reward: 713.98
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.1138
    Episode_Reward/rotating_object: 141.8790
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.22s
                      Time elapsed: 00:24:17
                               ETA: 00:30:52

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 44035 steps/s (collection: 2.129s, learning 0.103s)
             Mean action noise std: 2.18
          Mean value_function loss: 62.6587
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.7669
                       Mean reward: 724.09
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 1.1132
    Episode_Reward/rotating_object: 140.7623
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.23s
                      Time elapsed: 00:24:20
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 45695 steps/s (collection: 2.018s, learning 0.134s)
             Mean action noise std: 2.18
          Mean value_function loss: 53.3676
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.7964
                       Mean reward: 699.61
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.1171
    Episode_Reward/rotating_object: 142.0049
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.15s
                      Time elapsed: 00:24:22
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 45105 steps/s (collection: 2.070s, learning 0.109s)
             Mean action noise std: 2.18
          Mean value_function loss: 58.8296
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.8222
                       Mean reward: 712.24
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 1.1275
    Episode_Reward/rotating_object: 143.5103
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.18s
                      Time elapsed: 00:24:24
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 45425 steps/s (collection: 2.056s, learning 0.108s)
             Mean action noise std: 2.19
          Mean value_function loss: 46.3020
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.8512
                       Mean reward: 717.69
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 1.1142
    Episode_Reward/rotating_object: 140.9944
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.16s
                      Time elapsed: 00:24:26
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 45875 steps/s (collection: 2.025s, learning 0.118s)
             Mean action noise std: 2.19
          Mean value_function loss: 45.2065
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.8717
                       Mean reward: 728.05
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 1.1342
    Episode_Reward/rotating_object: 144.7523
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.14s
                      Time elapsed: 00:24:28
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 27366 steps/s (collection: 3.474s, learning 0.119s)
             Mean action noise std: 2.19
          Mean value_function loss: 59.7227
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.8880
                       Mean reward: 692.09
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 1.1031
    Episode_Reward/rotating_object: 139.8978
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.59s
                      Time elapsed: 00:24:32
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14235 steps/s (collection: 6.788s, learning 0.118s)
             Mean action noise std: 2.19
          Mean value_function loss: 57.7673
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.9096
                       Mean reward: 692.97
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 1.1150
    Episode_Reward/rotating_object: 142.0743
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.91s
                      Time elapsed: 00:24:39
                               ETA: 00:30:44

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14462 steps/s (collection: 6.656s, learning 0.142s)
             Mean action noise std: 2.19
          Mean value_function loss: 51.3994
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 47.9318
                       Mean reward: 730.87
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 1.1211
    Episode_Reward/rotating_object: 141.4346
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.80s
                      Time elapsed: 00:24:45
                               ETA: 00:30:47

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 13879 steps/s (collection: 6.930s, learning 0.152s)
             Mean action noise std: 2.20
          Mean value_function loss: 57.4053
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.9502
                       Mean reward: 724.63
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 1.1272
    Episode_Reward/rotating_object: 143.6396
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 7.08s
                      Time elapsed: 00:24:53
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14470 steps/s (collection: 6.662s, learning 0.131s)
             Mean action noise std: 2.20
          Mean value_function loss: 57.7208
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.9700
                       Mean reward: 726.05
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.1293
    Episode_Reward/rotating_object: 142.5216
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.79s
                      Time elapsed: 00:24:59
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14046 steps/s (collection: 6.881s, learning 0.118s)
             Mean action noise std: 2.20
          Mean value_function loss: 55.4755
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.9993
                       Mean reward: 686.84
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.1049
    Episode_Reward/rotating_object: 140.2536
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 7.00s
                      Time elapsed: 00:25:06
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14025 steps/s (collection: 6.878s, learning 0.131s)
             Mean action noise std: 2.20
          Mean value_function loss: 44.3382
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.0269
                       Mean reward: 716.10
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 1.1134
    Episode_Reward/rotating_object: 141.9787
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 7.01s
                      Time elapsed: 00:25:13
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14243 steps/s (collection: 6.778s, learning 0.124s)
             Mean action noise std: 2.21
          Mean value_function loss: 49.8789
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.0436
                       Mean reward: 741.94
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 1.1196
    Episode_Reward/rotating_object: 144.0429
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.90s
                      Time elapsed: 00:25:20
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14588 steps/s (collection: 6.588s, learning 0.151s)
             Mean action noise std: 2.21
          Mean value_function loss: 57.8717
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 48.0687
                       Mean reward: 753.98
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 1.1092
    Episode_Reward/rotating_object: 141.7524
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.74s
                      Time elapsed: 00:25:27
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 18418 steps/s (collection: 5.233s, learning 0.105s)
             Mean action noise std: 2.21
          Mean value_function loss: 59.0990
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 48.0990
                       Mean reward: 708.83
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.1069
    Episode_Reward/rotating_object: 141.3966
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 5.34s
                      Time elapsed: 00:25:32
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 47286 steps/s (collection: 1.990s, learning 0.089s)
             Mean action noise std: 2.22
          Mean value_function loss: 62.3088
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 48.1235
                       Mean reward: 723.80
               Mean episode length: 242.48
    Episode_Reward/reaching_object: 1.1243
    Episode_Reward/rotating_object: 140.5776
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.08s
                      Time elapsed: 00:25:34
                               ETA: 00:31:08

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 43828 steps/s (collection: 2.046s, learning 0.197s)
             Mean action noise std: 2.22
          Mean value_function loss: 61.8442
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 48.1396
                       Mean reward: 720.69
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 1.1160
    Episode_Reward/rotating_object: 145.3015
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.24s
                      Time elapsed: 00:25:37
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 44337 steps/s (collection: 2.108s, learning 0.109s)
             Mean action noise std: 2.22
          Mean value_function loss: 55.6523
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.1486
                       Mean reward: 710.60
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.1049
    Episode_Reward/rotating_object: 141.4473
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.22s
                      Time elapsed: 00:25:39
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 48370 steps/s (collection: 1.942s, learning 0.091s)
             Mean action noise std: 2.22
          Mean value_function loss: 59.5915
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.1666
                       Mean reward: 718.22
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 1.1113
    Episode_Reward/rotating_object: 140.4836
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.03s
                      Time elapsed: 00:25:41
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 47284 steps/s (collection: 1.957s, learning 0.122s)
             Mean action noise std: 2.22
          Mean value_function loss: 55.1687
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.1982
                       Mean reward: 743.56
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 1.1349
    Episode_Reward/rotating_object: 143.6340
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.08s
                      Time elapsed: 00:25:43
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 46239 steps/s (collection: 1.995s, learning 0.131s)
             Mean action noise std: 2.23
          Mean value_function loss: 58.0563
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.2294
                       Mean reward: 726.23
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 142.8900
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.13s
                      Time elapsed: 00:25:45
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 43575 steps/s (collection: 2.124s, learning 0.132s)
             Mean action noise std: 2.23
          Mean value_function loss: 59.3966
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.2533
                       Mean reward: 728.77
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.1216
    Episode_Reward/rotating_object: 143.3887
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.26s
                      Time elapsed: 00:25:47
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 49015 steps/s (collection: 1.906s, learning 0.100s)
             Mean action noise std: 2.23
          Mean value_function loss: 55.3902
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.2754
                       Mean reward: 703.21
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.1070
    Episode_Reward/rotating_object: 139.5308
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.01s
                      Time elapsed: 00:25:49
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 43684 steps/s (collection: 2.090s, learning 0.161s)
             Mean action noise std: 2.23
          Mean value_function loss: 56.1546
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.3005
                       Mean reward: 744.84
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.1117
    Episode_Reward/rotating_object: 143.7856
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.25s
                      Time elapsed: 00:25:52
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 46745 steps/s (collection: 1.970s, learning 0.133s)
             Mean action noise std: 2.24
          Mean value_function loss: 60.4777
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.3226
                       Mean reward: 737.71
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 1.1056
    Episode_Reward/rotating_object: 141.4376
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.10s
                      Time elapsed: 00:25:54
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 48515 steps/s (collection: 1.938s, learning 0.089s)
             Mean action noise std: 2.24
          Mean value_function loss: 64.8526
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.3459
                       Mean reward: 690.68
               Mean episode length: 233.10
    Episode_Reward/reaching_object: 1.0774
    Episode_Reward/rotating_object: 134.2640
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.03s
                      Time elapsed: 00:25:56
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 48130 steps/s (collection: 1.925s, learning 0.117s)
             Mean action noise std: 2.24
          Mean value_function loss: 54.2979
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.3685
                       Mean reward: 739.32
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.1040
    Episode_Reward/rotating_object: 140.0573
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.04s
                      Time elapsed: 00:25:58
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 44990 steps/s (collection: 2.080s, learning 0.105s)
             Mean action noise std: 2.24
          Mean value_function loss: 48.9399
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.3956
                       Mean reward: 714.16
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 1.1249
    Episode_Reward/rotating_object: 142.7534
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.18s
                      Time elapsed: 00:26:00
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 42997 steps/s (collection: 2.163s, learning 0.123s)
             Mean action noise std: 2.25
          Mean value_function loss: 60.6861
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.4162
                       Mean reward: 711.12
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 1.1102
    Episode_Reward/rotating_object: 142.1312
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.29s
                      Time elapsed: 00:26:02
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 48350 steps/s (collection: 1.940s, learning 0.093s)
             Mean action noise std: 2.25
          Mean value_function loss: 58.0572
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.4387
                       Mean reward: 721.88
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.1072
    Episode_Reward/rotating_object: 141.5937
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.03s
                      Time elapsed: 00:26:04
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 46045 steps/s (collection: 2.009s, learning 0.126s)
             Mean action noise std: 2.25
          Mean value_function loss: 51.4535
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.4593
                       Mean reward: 690.85
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 1.1098
    Episode_Reward/rotating_object: 140.3158
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.13s
                      Time elapsed: 00:26:06
                               ETA: 00:30:31

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 47195 steps/s (collection: 1.988s, learning 0.095s)
             Mean action noise std: 2.25
          Mean value_function loss: 57.7658
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.4724
                       Mean reward: 741.11
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 1.1154
    Episode_Reward/rotating_object: 142.4853
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.08s
                      Time elapsed: 00:26:08
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 48480 steps/s (collection: 1.932s, learning 0.096s)
             Mean action noise std: 2.26
          Mean value_function loss: 59.2769
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.4888
                       Mean reward: 709.41
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 1.1035
    Episode_Reward/rotating_object: 138.7892
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.03s
                      Time elapsed: 00:26:11
                               ETA: 00:30:26

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 49269 steps/s (collection: 1.907s, learning 0.088s)
             Mean action noise std: 2.26
          Mean value_function loss: 57.4605
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.5089
                       Mean reward: 694.90
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.1229
    Episode_Reward/rotating_object: 140.7805
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.00s
                      Time elapsed: 00:26:13
                               ETA: 00:30:24

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 48373 steps/s (collection: 1.942s, learning 0.091s)
             Mean action noise std: 2.26
          Mean value_function loss: 63.2562
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.5308
                       Mean reward: 717.27
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 139.7801
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.03s
                      Time elapsed: 00:26:15
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 43661 steps/s (collection: 2.099s, learning 0.153s)
             Mean action noise std: 2.26
          Mean value_function loss: 60.9158
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.5547
                       Mean reward: 693.18
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 1.1031
    Episode_Reward/rotating_object: 138.6372
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.25s
                      Time elapsed: 00:26:17
                               ETA: 00:30:19

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 48532 steps/s (collection: 1.928s, learning 0.098s)
             Mean action noise std: 2.26
          Mean value_function loss: 60.2248
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.5757
                       Mean reward: 704.31
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.1109
    Episode_Reward/rotating_object: 141.0584
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 18.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.03s
                      Time elapsed: 00:26:19
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 43172 steps/s (collection: 2.134s, learning 0.143s)
             Mean action noise std: 2.27
          Mean value_function loss: 56.4238
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.6010
                       Mean reward: 716.43
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.1287
    Episode_Reward/rotating_object: 145.1787
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.28s
                      Time elapsed: 00:26:21
                               ETA: 00:30:14

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 47507 steps/s (collection: 1.954s, learning 0.116s)
             Mean action noise std: 2.27
          Mean value_function loss: 65.7791
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.6250
                       Mean reward: 669.93
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.0651
    Episode_Reward/rotating_object: 133.9717
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.07s
                      Time elapsed: 00:26:23
                               ETA: 00:30:12

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 44584 steps/s (collection: 2.065s, learning 0.140s)
             Mean action noise std: 2.27
          Mean value_function loss: 47.8930
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.6436
                       Mean reward: 751.82
               Mean episode length: 246.49
    Episode_Reward/reaching_object: 1.1289
    Episode_Reward/rotating_object: 145.1194
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.20s
                      Time elapsed: 00:26:25
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 46943 steps/s (collection: 1.988s, learning 0.107s)
             Mean action noise std: 2.28
          Mean value_function loss: 58.4527
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.6690
                       Mean reward: 714.15
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.1083
    Episode_Reward/rotating_object: 143.2258
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.09s
                      Time elapsed: 00:26:27
                               ETA: 00:30:07

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 47077 steps/s (collection: 1.985s, learning 0.104s)
             Mean action noise std: 2.28
          Mean value_function loss: 62.6470
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.6997
                       Mean reward: 746.47
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 1.1081
    Episode_Reward/rotating_object: 143.7680
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.09s
                      Time elapsed: 00:26:30
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 45198 steps/s (collection: 2.061s, learning 0.114s)
             Mean action noise std: 2.28
          Mean value_function loss: 56.9039
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.7288
                       Mean reward: 665.71
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.1017
    Episode_Reward/rotating_object: 140.9078
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.17s
                      Time elapsed: 00:26:32
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 47300 steps/s (collection: 1.958s, learning 0.120s)
             Mean action noise std: 2.28
          Mean value_function loss: 65.9212
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.7532
                       Mean reward: 708.92
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.0894
    Episode_Reward/rotating_object: 139.0549
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.08s
                      Time elapsed: 00:26:34
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 45585 steps/s (collection: 2.065s, learning 0.091s)
             Mean action noise std: 2.29
          Mean value_function loss: 59.7012
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.7797
                       Mean reward: 721.08
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.1065
    Episode_Reward/rotating_object: 143.7989
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.16s
                      Time elapsed: 00:26:36
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 47584 steps/s (collection: 1.948s, learning 0.118s)
             Mean action noise std: 2.29
          Mean value_function loss: 64.0225
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 48.8008
                       Mean reward: 702.73
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0940
    Episode_Reward/rotating_object: 139.5222
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.07s
                      Time elapsed: 00:26:38
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 49345 steps/s (collection: 1.890s, learning 0.102s)
             Mean action noise std: 2.29
          Mean value_function loss: 62.4286
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.8279
                       Mean reward: 707.96
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.1122
    Episode_Reward/rotating_object: 142.7204
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.99s
                      Time elapsed: 00:26:40
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 47493 steps/s (collection: 1.933s, learning 0.137s)
             Mean action noise std: 2.30
          Mean value_function loss: 60.2832
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.8537
                       Mean reward: 723.11
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.1163
    Episode_Reward/rotating_object: 141.4977
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.07s
                      Time elapsed: 00:26:42
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 47290 steps/s (collection: 1.958s, learning 0.120s)
             Mean action noise std: 2.30
          Mean value_function loss: 57.5419
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 48.8734
                       Mean reward: 708.54
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.1057
    Episode_Reward/rotating_object: 141.8064
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.08s
                      Time elapsed: 00:26:44
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 45609 steps/s (collection: 2.051s, learning 0.105s)
             Mean action noise std: 2.30
          Mean value_function loss: 47.5598
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.8837
                       Mean reward: 729.35
               Mean episode length: 245.12
    Episode_Reward/reaching_object: 1.1000
    Episode_Reward/rotating_object: 139.1758
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.16s
                      Time elapsed: 00:26:46
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 48892 steps/s (collection: 1.906s, learning 0.105s)
             Mean action noise std: 2.30
          Mean value_function loss: 64.5221
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.9002
                       Mean reward: 753.13
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 1.1153
    Episode_Reward/rotating_object: 143.3045
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.01s
                      Time elapsed: 00:26:48
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 45722 steps/s (collection: 1.995s, learning 0.155s)
             Mean action noise std: 2.30
          Mean value_function loss: 67.3900
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.9197
                       Mean reward: 686.65
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.1080
    Episode_Reward/rotating_object: 143.1451
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.15s
                      Time elapsed: 00:26:50
                               ETA: 00:29:40

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 47126 steps/s (collection: 1.994s, learning 0.092s)
             Mean action noise std: 2.31
          Mean value_function loss: 73.3057
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.9469
                       Mean reward: 667.76
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 137.2286
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.09s
                      Time elapsed: 00:26:53
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 47974 steps/s (collection: 1.960s, learning 0.089s)
             Mean action noise std: 2.31
          Mean value_function loss: 51.3898
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.9774
                       Mean reward: 736.85
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 1.0853
    Episode_Reward/rotating_object: 141.2383
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.05s
                      Time elapsed: 00:26:55
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 48416 steps/s (collection: 1.933s, learning 0.098s)
             Mean action noise std: 2.31
          Mean value_function loss: 59.2775
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.0041
                       Mean reward: 695.08
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 1.0889
    Episode_Reward/rotating_object: 138.3071
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.03s
                      Time elapsed: 00:26:57
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 48519 steps/s (collection: 1.935s, learning 0.092s)
             Mean action noise std: 2.31
          Mean value_function loss: 61.5849
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.0254
                       Mean reward: 704.07
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.0910
    Episode_Reward/rotating_object: 137.6871
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.03s
                      Time elapsed: 00:26:59
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 48667 steps/s (collection: 1.929s, learning 0.091s)
             Mean action noise std: 2.32
          Mean value_function loss: 46.8561
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.0516
                       Mean reward: 696.69
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 1.0885
    Episode_Reward/rotating_object: 137.4446
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.02s
                      Time elapsed: 00:27:01
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 48697 steps/s (collection: 1.924s, learning 0.094s)
             Mean action noise std: 2.32
          Mean value_function loss: 62.0561
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.0823
                       Mean reward: 722.75
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.1092
    Episode_Reward/rotating_object: 140.6406
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.02s
                      Time elapsed: 00:27:03
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 48155 steps/s (collection: 1.952s, learning 0.090s)
             Mean action noise std: 2.32
          Mean value_function loss: 65.5034
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.1087
                       Mean reward: 671.13
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.0938
    Episode_Reward/rotating_object: 139.5603
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.04s
                      Time elapsed: 00:27:05
                               ETA: 00:29:22

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 48968 steps/s (collection: 1.917s, learning 0.091s)
             Mean action noise std: 2.33
          Mean value_function loss: 61.3466
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.1374
                       Mean reward: 680.68
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 1.1049
    Episode_Reward/rotating_object: 140.2964
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.01s
                      Time elapsed: 00:27:07
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 48650 steps/s (collection: 1.911s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 63.9778
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.1582
                       Mean reward: 667.17
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.0958
    Episode_Reward/rotating_object: 139.8343
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.02s
                      Time elapsed: 00:27:09
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 44750 steps/s (collection: 2.052s, learning 0.145s)
             Mean action noise std: 2.33
          Mean value_function loss: 69.1381
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.1751
                       Mean reward: 732.69
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.1027
    Episode_Reward/rotating_object: 140.8573
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.20s
                      Time elapsed: 00:27:11
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 47541 steps/s (collection: 1.954s, learning 0.114s)
             Mean action noise std: 2.33
          Mean value_function loss: 47.5580
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.2046
                       Mean reward: 727.64
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 1.0938
    Episode_Reward/rotating_object: 139.5040
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.07s
                      Time elapsed: 00:27:13
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 47246 steps/s (collection: 1.916s, learning 0.165s)
             Mean action noise std: 2.34
          Mean value_function loss: 53.8967
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.2256
                       Mean reward: 721.12
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 1.1116
    Episode_Reward/rotating_object: 141.2290
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.08s
                      Time elapsed: 00:27:15
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 48387 steps/s (collection: 1.908s, learning 0.124s)
             Mean action noise std: 2.34
          Mean value_function loss: 54.1856
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.2471
                       Mean reward: 717.21
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 1.1120
    Episode_Reward/rotating_object: 144.0012
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.03s
                      Time elapsed: 00:27:17
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 48803 steps/s (collection: 1.918s, learning 0.096s)
             Mean action noise std: 2.34
          Mean value_function loss: 58.3385
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.2709
                       Mean reward: 725.08
               Mean episode length: 235.49
    Episode_Reward/reaching_object: 1.1035
    Episode_Reward/rotating_object: 141.1015
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.01s
                      Time elapsed: 00:27:19
                               ETA: 00:29:05

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 47894 steps/s (collection: 1.959s, learning 0.094s)
             Mean action noise std: 2.34
          Mean value_function loss: 50.2896
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.2891
                       Mean reward: 716.69
               Mean episode length: 241.96
    Episode_Reward/reaching_object: 1.1223
    Episode_Reward/rotating_object: 143.6644
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.05s
                      Time elapsed: 00:27:21
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 48312 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 2.35
          Mean value_function loss: 57.3593
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.3078
                       Mean reward: 713.05
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.0851
    Episode_Reward/rotating_object: 136.6879
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.03s
                      Time elapsed: 00:27:23
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 48813 steps/s (collection: 1.897s, learning 0.116s)
             Mean action noise std: 2.35
          Mean value_function loss: 66.1720
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.3292
                       Mean reward: 748.82
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 1.1383
    Episode_Reward/rotating_object: 146.3039
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.01s
                      Time elapsed: 00:27:25
                               ETA: 00:28:58

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 48557 steps/s (collection: 1.906s, learning 0.118s)
             Mean action noise std: 2.35
          Mean value_function loss: 61.0159
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.3538
                       Mean reward: 716.37
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 1.1012
    Episode_Reward/rotating_object: 141.7311
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.02s
                      Time elapsed: 00:27:27
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 49040 steps/s (collection: 1.914s, learning 0.091s)
             Mean action noise std: 2.35
          Mean value_function loss: 51.4444
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.3711
                       Mean reward: 712.88
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.1125
    Episode_Reward/rotating_object: 139.1834
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.00s
                      Time elapsed: 00:27:29
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 48516 steps/s (collection: 1.930s, learning 0.096s)
             Mean action noise std: 2.36
          Mean value_function loss: 61.6835
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.3970
                       Mean reward: 708.48
               Mean episode length: 236.10
    Episode_Reward/reaching_object: 1.1136
    Episode_Reward/rotating_object: 142.5687
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.03s
                      Time elapsed: 00:27:31
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 48662 steps/s (collection: 1.914s, learning 0.106s)
             Mean action noise std: 2.36
          Mean value_function loss: 58.5985
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.4214
                       Mean reward: 723.27
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.1168
    Episode_Reward/rotating_object: 143.0981
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.02s
                      Time elapsed: 00:27:33
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 46113 steps/s (collection: 1.990s, learning 0.142s)
             Mean action noise std: 2.36
          Mean value_function loss: 58.6470
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.4566
                       Mean reward: 688.80
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 1.0891
    Episode_Reward/rotating_object: 135.6629
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.13s
                      Time elapsed: 00:27:35
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 45360 steps/s (collection: 2.012s, learning 0.156s)
             Mean action noise std: 2.37
          Mean value_function loss: 62.7666
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.4924
                       Mean reward: 722.00
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.1147
    Episode_Reward/rotating_object: 143.4081
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.17s
                      Time elapsed: 00:27:38
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 45580 steps/s (collection: 2.040s, learning 0.117s)
             Mean action noise std: 2.37
          Mean value_function loss: 62.0288
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.5182
                       Mean reward: 742.07
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 1.1150
    Episode_Reward/rotating_object: 141.8939
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.16s
                      Time elapsed: 00:27:40
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 46221 steps/s (collection: 2.019s, learning 0.108s)
             Mean action noise std: 2.37
          Mean value_function loss: 50.7459
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.5457
                       Mean reward: 717.29
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.0958
    Episode_Reward/rotating_object: 140.1999
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.13s
                      Time elapsed: 00:27:42
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 46217 steps/s (collection: 2.018s, learning 0.109s)
             Mean action noise std: 2.38
          Mean value_function loss: 52.0363
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.5716
                       Mean reward: 754.01
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.1150
    Episode_Reward/rotating_object: 140.5281
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.13s
                      Time elapsed: 00:27:44
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 45662 steps/s (collection: 2.026s, learning 0.127s)
             Mean action noise std: 2.38
          Mean value_function loss: 66.1282
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.6017
                       Mean reward: 656.33
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.1005
    Episode_Reward/rotating_object: 139.8794
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.15s
                      Time elapsed: 00:27:46
                               ETA: 00:28:34

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 47440 steps/s (collection: 1.963s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 68.8885
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.6214
                       Mean reward: 689.33
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.0871
    Episode_Reward/rotating_object: 135.7181
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.07s
                      Time elapsed: 00:27:48
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 47118 steps/s (collection: 1.941s, learning 0.145s)
             Mean action noise std: 2.38
          Mean value_function loss: 64.3269
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.6393
                       Mean reward: 691.00
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.0723
    Episode_Reward/rotating_object: 134.1704
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.09s
                      Time elapsed: 00:27:50
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 47482 steps/s (collection: 1.962s, learning 0.108s)
             Mean action noise std: 2.38
          Mean value_function loss: 65.5529
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.6556
                       Mean reward: 685.18
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.1006
    Episode_Reward/rotating_object: 140.8680
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.07s
                      Time elapsed: 00:27:52
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 48050 steps/s (collection: 1.949s, learning 0.097s)
             Mean action noise std: 2.39
          Mean value_function loss: 53.2941
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.6736
                       Mean reward: 677.02
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.0996
    Episode_Reward/rotating_object: 139.7994
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.05s
                      Time elapsed: 00:27:54
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 48669 steps/s (collection: 1.912s, learning 0.108s)
             Mean action noise std: 2.39
          Mean value_function loss: 56.9245
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.6927
                       Mean reward: 680.26
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.1117
    Episode_Reward/rotating_object: 142.0312
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.02s
                      Time elapsed: 00:27:57
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 46803 steps/s (collection: 1.986s, learning 0.114s)
             Mean action noise std: 2.39
          Mean value_function loss: 70.3128
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.7145
                       Mean reward: 671.83
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 141.9890
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.10s
                      Time elapsed: 00:27:59
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 41550 steps/s (collection: 2.253s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 54.9742
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.7332
                       Mean reward: 744.20
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.1174
    Episode_Reward/rotating_object: 142.7106
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.37s
                      Time elapsed: 00:28:01
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 47988 steps/s (collection: 1.957s, learning 0.091s)
             Mean action noise std: 2.39
          Mean value_function loss: 59.6068
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.7503
                       Mean reward: 706.33
               Mean episode length: 232.99
    Episode_Reward/reaching_object: 1.0997
    Episode_Reward/rotating_object: 140.9413
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.05s
                      Time elapsed: 00:28:03
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 46434 steps/s (collection: 1.940s, learning 0.177s)
             Mean action noise std: 2.40
          Mean value_function loss: 50.7865
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.7728
                       Mean reward: 715.52
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 1.1241
    Episode_Reward/rotating_object: 145.3083
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.12s
                      Time elapsed: 00:28:05
                               ETA: 00:28:12

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 44541 steps/s (collection: 2.027s, learning 0.180s)
             Mean action noise std: 2.40
          Mean value_function loss: 62.6164
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.7992
                       Mean reward: 720.70
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.1026
    Episode_Reward/rotating_object: 140.7699
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.21s
                      Time elapsed: 00:28:07
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 46881 steps/s (collection: 1.952s, learning 0.145s)
             Mean action noise std: 2.40
          Mean value_function loss: 57.0387
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.8286
                       Mean reward: 702.47
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.0941
    Episode_Reward/rotating_object: 140.6800
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.10s
                      Time elapsed: 00:28:09
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 45366 steps/s (collection: 2.052s, learning 0.115s)
             Mean action noise std: 2.41
          Mean value_function loss: 72.8162
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 49.8540
                       Mean reward: 713.06
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 141.4131
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.17s
                      Time elapsed: 00:28:12
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 47517 steps/s (collection: 1.977s, learning 0.092s)
             Mean action noise std: 2.41
          Mean value_function loss: 68.9163
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.8686
                       Mean reward: 698.86
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.0852
    Episode_Reward/rotating_object: 138.0271
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.07s
                      Time elapsed: 00:28:14
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 47958 steps/s (collection: 1.961s, learning 0.089s)
             Mean action noise std: 2.41
          Mean value_function loss: 66.4257
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.8933
                       Mean reward: 665.81
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.0859
    Episode_Reward/rotating_object: 137.9378
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.05s
                      Time elapsed: 00:28:16
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 48508 steps/s (collection: 1.930s, learning 0.097s)
             Mean action noise std: 2.41
          Mean value_function loss: 61.4289
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.9210
                       Mean reward: 695.24
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.0892
    Episode_Reward/rotating_object: 138.6169
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.03s
                      Time elapsed: 00:28:18
                               ETA: 00:27:58

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 47431 steps/s (collection: 1.977s, learning 0.096s)
             Mean action noise std: 2.42
          Mean value_function loss: 54.4435
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.9457
                       Mean reward: 734.43
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 1.1163
    Episode_Reward/rotating_object: 142.2424
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.07s
                      Time elapsed: 00:28:20
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 44328 steps/s (collection: 2.104s, learning 0.114s)
             Mean action noise std: 2.42
          Mean value_function loss: 63.0057
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.9613
                       Mean reward: 708.77
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 137.5072
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.22s
                      Time elapsed: 00:28:22
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 47132 steps/s (collection: 1.968s, learning 0.118s)
             Mean action noise std: 2.42
          Mean value_function loss: 67.8847
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.9791
                       Mean reward: 688.94
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.0935
    Episode_Reward/rotating_object: 139.6519
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.09s
                      Time elapsed: 00:28:24
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 45771 steps/s (collection: 2.014s, learning 0.134s)
             Mean action noise std: 2.42
          Mean value_function loss: 60.5011
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 49.9966
                       Mean reward: 722.79
               Mean episode length: 234.10
    Episode_Reward/reaching_object: 1.0860
    Episode_Reward/rotating_object: 139.9890
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.15s
                      Time elapsed: 00:28:26
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 47666 steps/s (collection: 1.967s, learning 0.095s)
             Mean action noise std: 2.43
          Mean value_function loss: 57.5049
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.0182
                       Mean reward: 715.36
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 139.0184
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.06s
                      Time elapsed: 00:28:28
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 48203 steps/s (collection: 1.926s, learning 0.114s)
             Mean action noise std: 2.43
          Mean value_function loss: 67.5466
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.0413
                       Mean reward: 700.10
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.0940
    Episode_Reward/rotating_object: 140.3335
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.04s
                      Time elapsed: 00:28:30
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 47636 steps/s (collection: 1.942s, learning 0.122s)
             Mean action noise std: 2.43
          Mean value_function loss: 55.0619
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.0599
                       Mean reward: 720.54
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 1.1022
    Episode_Reward/rotating_object: 144.3320
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.06s
                      Time elapsed: 00:28:32
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 47415 steps/s (collection: 1.964s, learning 0.109s)
             Mean action noise std: 2.43
          Mean value_function loss: 58.4974
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.0735
                       Mean reward: 705.60
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 1.0909
    Episode_Reward/rotating_object: 139.7563
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.07s
                      Time elapsed: 00:28:35
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 47308 steps/s (collection: 1.974s, learning 0.104s)
             Mean action noise std: 2.43
          Mean value_function loss: 58.8444
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.0911
                       Mean reward: 725.42
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.0938
    Episode_Reward/rotating_object: 141.2377
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.08s
                      Time elapsed: 00:28:37
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 48656 steps/s (collection: 1.925s, learning 0.095s)
             Mean action noise std: 2.44
          Mean value_function loss: 61.7855
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.1168
                       Mean reward: 697.01
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 1.1007
    Episode_Reward/rotating_object: 142.9212
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.02s
                      Time elapsed: 00:28:39
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 48965 steps/s (collection: 1.911s, learning 0.096s)
             Mean action noise std: 2.44
          Mean value_function loss: 57.7411
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.1425
                       Mean reward: 754.72
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 142.5181
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.01s
                      Time elapsed: 00:28:41
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 43886 steps/s (collection: 2.116s, learning 0.124s)
             Mean action noise std: 2.44
          Mean value_function loss: 66.1806
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.1625
                       Mean reward: 727.92
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 141.1945
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.24s
                      Time elapsed: 00:28:43
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 44336 steps/s (collection: 2.126s, learning 0.091s)
             Mean action noise std: 2.45
          Mean value_function loss: 54.7501
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.1838
                       Mean reward: 718.04
               Mean episode length: 242.62
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 139.9722
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.22s
                      Time elapsed: 00:28:45
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 46999 steps/s (collection: 1.984s, learning 0.108s)
             Mean action noise std: 2.45
          Mean value_function loss: 59.1851
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.2024
                       Mean reward: 714.28
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.0896
    Episode_Reward/rotating_object: 143.2763
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.09s
                      Time elapsed: 00:28:47
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 47802 steps/s (collection: 1.960s, learning 0.096s)
             Mean action noise std: 2.45
          Mean value_function loss: 65.3906
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.2289
                       Mean reward: 730.28
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 139.3629
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.06s
                      Time elapsed: 00:28:49
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 42674 steps/s (collection: 2.129s, learning 0.175s)
             Mean action noise std: 2.45
          Mean value_function loss: 64.6704
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.2543
                       Mean reward: 725.96
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.0924
    Episode_Reward/rotating_object: 143.5048
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.30s
                      Time elapsed: 00:28:52
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 45566 steps/s (collection: 2.059s, learning 0.098s)
             Mean action noise std: 2.46
          Mean value_function loss: 55.0025
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.2785
                       Mean reward: 718.22
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 139.3482
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.16s
                      Time elapsed: 00:28:54
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 48066 steps/s (collection: 1.958s, learning 0.087s)
             Mean action noise std: 2.46
          Mean value_function loss: 64.6139
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.2969
                       Mean reward: 717.74
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 139.8807
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.05s
                      Time elapsed: 00:28:56
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 44249 steps/s (collection: 2.077s, learning 0.145s)
             Mean action noise std: 2.46
          Mean value_function loss: 51.5043
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.3177
                       Mean reward: 731.13
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 1.1008
    Episode_Reward/rotating_object: 145.0377
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.22s
                      Time elapsed: 00:28:58
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 47262 steps/s (collection: 1.987s, learning 0.093s)
             Mean action noise std: 2.46
          Mean value_function loss: 64.6970
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.3406
                       Mean reward: 738.10
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 140.1687
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.08s
                      Time elapsed: 00:29:00
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 48263 steps/s (collection: 1.943s, learning 0.094s)
             Mean action noise std: 2.47
          Mean value_function loss: 58.2121
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.3612
                       Mean reward: 721.28
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.0816
    Episode_Reward/rotating_object: 139.5080
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.04s
                      Time elapsed: 00:29:02
                               ETA: 00:27:08

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 47655 steps/s (collection: 1.967s, learning 0.096s)
             Mean action noise std: 2.47
          Mean value_function loss: 64.1118
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.3799
                       Mean reward: 721.20
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.1081
    Episode_Reward/rotating_object: 145.2615
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.06s
                      Time elapsed: 00:29:04
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 44887 steps/s (collection: 2.050s, learning 0.140s)
             Mean action noise std: 2.47
          Mean value_function loss: 60.4712
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.3906
                       Mean reward: 686.31
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.0823
    Episode_Reward/rotating_object: 139.3984
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.19s
                      Time elapsed: 00:29:06
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 46996 steps/s (collection: 1.969s, learning 0.123s)
             Mean action noise std: 2.47
          Mean value_function loss: 63.0143
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.3983
                       Mean reward: 726.72
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 1.1004
    Episode_Reward/rotating_object: 140.8900
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.09s
                      Time elapsed: 00:29:08
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 46610 steps/s (collection: 1.976s, learning 0.133s)
             Mean action noise std: 2.47
          Mean value_function loss: 64.4677
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.4106
                       Mean reward: 720.64
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 138.6153
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.11s
                      Time elapsed: 00:29:11
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 48723 steps/s (collection: 1.919s, learning 0.099s)
             Mean action noise std: 2.48
          Mean value_function loss: 62.9422
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.4337
                       Mean reward: 733.28
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.1021
    Episode_Reward/rotating_object: 143.2896
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.02s
                      Time elapsed: 00:29:13
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 45967 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 59.1402
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.4620
                       Mean reward: 732.87
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 1.0940
    Episode_Reward/rotating_object: 141.0251
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.14s
                      Time elapsed: 00:29:15
                               ETA: 00:26:53

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 46305 steps/s (collection: 2.020s, learning 0.103s)
             Mean action noise std: 2.48
          Mean value_function loss: 70.2801
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.4812
                       Mean reward: 688.72
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 137.4684
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.12s
                      Time elapsed: 00:29:17
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 46373 steps/s (collection: 2.020s, learning 0.100s)
             Mean action noise std: 2.48
          Mean value_function loss: 69.3486
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.5023
                       Mean reward: 678.27
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 1.0703
    Episode_Reward/rotating_object: 136.6927
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.12s
                      Time elapsed: 00:29:19
                               ETA: 00:26:49

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 46048 steps/s (collection: 2.026s, learning 0.109s)
             Mean action noise std: 2.49
          Mean value_function loss: 59.3835
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.5294
                       Mean reward: 736.71
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 1.1069
    Episode_Reward/rotating_object: 143.4229
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.13s
                      Time elapsed: 00:29:21
                               ETA: 00:26:46

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 46360 steps/s (collection: 2.004s, learning 0.117s)
             Mean action noise std: 2.49
          Mean value_function loss: 77.1492
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.5537
                       Mean reward: 680.95
               Mean episode length: 231.34
    Episode_Reward/reaching_object: 1.0869
    Episode_Reward/rotating_object: 138.5018
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.12s
                      Time elapsed: 00:29:23
                               ETA: 00:26:44

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 46062 steps/s (collection: 2.040s, learning 0.094s)
             Mean action noise std: 2.49
          Mean value_function loss: 48.1701
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.5755
                       Mean reward: 716.52
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 1.0882
    Episode_Reward/rotating_object: 139.1697
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.13s
                      Time elapsed: 00:29:25
                               ETA: 00:26:42

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 45924 steps/s (collection: 1.988s, learning 0.152s)
             Mean action noise std: 2.50
          Mean value_function loss: 56.3885
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.6041
                       Mean reward: 696.77
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.0954
    Episode_Reward/rotating_object: 141.4961
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.14s
                      Time elapsed: 00:29:27
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 46217 steps/s (collection: 2.010s, learning 0.117s)
             Mean action noise std: 2.50
          Mean value_function loss: 75.8893
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.6266
                       Mean reward: 645.84
               Mean episode length: 224.63
    Episode_Reward/reaching_object: 1.0983
    Episode_Reward/rotating_object: 140.8238
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.13s
                      Time elapsed: 00:29:30
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 47674 steps/s (collection: 1.962s, learning 0.100s)
             Mean action noise std: 2.50
          Mean value_function loss: 68.3705
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.6416
                       Mean reward: 706.99
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 139.3644
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.06s
                      Time elapsed: 00:29:32
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 46301 steps/s (collection: 1.991s, learning 0.132s)
             Mean action noise std: 2.50
          Mean value_function loss: 71.4967
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.6594
                       Mean reward: 680.28
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 139.0510
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.12s
                      Time elapsed: 00:29:34
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 45017 steps/s (collection: 2.062s, learning 0.122s)
             Mean action noise std: 2.51
          Mean value_function loss: 67.0812
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.6833
                       Mean reward: 685.63
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 139.1444
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.18s
                      Time elapsed: 00:29:36
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 47930 steps/s (collection: 1.953s, learning 0.098s)
             Mean action noise std: 2.51
          Mean value_function loss: 50.9157
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.7033
                       Mean reward: 728.46
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.1110
    Episode_Reward/rotating_object: 141.9521
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.05s
                      Time elapsed: 00:29:38
                               ETA: 00:26:27

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 47589 steps/s (collection: 1.970s, learning 0.096s)
             Mean action noise std: 2.51
          Mean value_function loss: 65.0674
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.7275
                       Mean reward: 701.28
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 138.4541
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.07s
                      Time elapsed: 00:29:40
                               ETA: 00:26:25

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 47398 steps/s (collection: 1.967s, learning 0.107s)
             Mean action noise std: 2.51
          Mean value_function loss: 53.3564
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.7475
                       Mean reward: 679.29
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 1.1102
    Episode_Reward/rotating_object: 140.7946
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.07s
                      Time elapsed: 00:29:42
                               ETA: 00:26:23

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 45107 steps/s (collection: 2.058s, learning 0.121s)
             Mean action noise std: 2.52
          Mean value_function loss: 52.6917
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.7704
                       Mean reward: 735.20
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 1.1182
    Episode_Reward/rotating_object: 145.1193
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.18s
                      Time elapsed: 00:29:44
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 42919 steps/s (collection: 2.137s, learning 0.154s)
             Mean action noise std: 2.52
          Mean value_function loss: 58.2388
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.7879
                       Mean reward: 746.26
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.1093
    Episode_Reward/rotating_object: 143.8887
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.29s
                      Time elapsed: 00:29:47
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 43480 steps/s (collection: 2.125s, learning 0.136s)
             Mean action noise std: 2.52
          Mean value_function loss: 58.4121
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.8064
                       Mean reward: 721.31
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.0923
    Episode_Reward/rotating_object: 142.3947
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.26s
                      Time elapsed: 00:29:49
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 43164 steps/s (collection: 2.125s, learning 0.153s)
             Mean action noise std: 2.52
          Mean value_function loss: 57.3102
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.8389
                       Mean reward: 700.75
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 137.0726
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.28s
                      Time elapsed: 00:29:51
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 46135 steps/s (collection: 2.011s, learning 0.120s)
             Mean action noise std: 2.53
          Mean value_function loss: 61.2106
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 50.8585
                       Mean reward: 716.36
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.0735
    Episode_Reward/rotating_object: 136.8638
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.13s
                      Time elapsed: 00:29:53
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 41619 steps/s (collection: 2.231s, learning 0.131s)
             Mean action noise std: 2.53
          Mean value_function loss: 77.5535
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.8813
                       Mean reward: 714.54
               Mean episode length: 238.41
    Episode_Reward/reaching_object: 1.1080
    Episode_Reward/rotating_object: 141.7878
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.36s
                      Time elapsed: 00:29:56
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 45585 steps/s (collection: 2.039s, learning 0.118s)
             Mean action noise std: 2.53
          Mean value_function loss: 75.4658
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.9078
                       Mean reward: 670.12
               Mean episode length: 230.14
    Episode_Reward/reaching_object: 1.0860
    Episode_Reward/rotating_object: 140.2804
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.16s
                      Time elapsed: 00:29:58
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 47196 steps/s (collection: 1.969s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 78.1045
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.9309
                       Mean reward: 681.71
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 139.2672
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.08s
                      Time elapsed: 00:30:00
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 47011 steps/s (collection: 1.995s, learning 0.096s)
             Mean action noise std: 2.54
          Mean value_function loss: 68.7662
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.9517
                       Mean reward: 705.14
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 1.0792
    Episode_Reward/rotating_object: 139.6054
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.09s
                      Time elapsed: 00:30:02
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 46360 steps/s (collection: 1.989s, learning 0.131s)
             Mean action noise std: 2.54
          Mean value_function loss: 75.7752
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.9682
                       Mean reward: 682.62
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 138.5183
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.12s
                      Time elapsed: 00:30:04
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 45116 steps/s (collection: 2.089s, learning 0.090s)
             Mean action noise std: 2.54
          Mean value_function loss: 63.0851
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.9908
                       Mean reward: 705.13
               Mean episode length: 230.97
    Episode_Reward/reaching_object: 1.0946
    Episode_Reward/rotating_object: 142.1417
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.18s
                      Time elapsed: 00:30:06
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 47131 steps/s (collection: 1.983s, learning 0.103s)
             Mean action noise std: 2.54
          Mean value_function loss: 74.5542
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.0048
                       Mean reward: 656.71
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 1.0897
    Episode_Reward/rotating_object: 140.9109
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.09s
                      Time elapsed: 00:30:08
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 44150 steps/s (collection: 2.112s, learning 0.115s)
             Mean action noise std: 2.54
          Mean value_function loss: 77.6471
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.0200
                       Mean reward: 713.27
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 1.0897
    Episode_Reward/rotating_object: 140.2237
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.23s
                      Time elapsed: 00:30:11
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 46029 steps/s (collection: 2.008s, learning 0.128s)
             Mean action noise std: 2.55
          Mean value_function loss: 72.9552
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.0425
                       Mean reward: 702.21
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 137.0825
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.14s
                      Time elapsed: 00:30:13
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 45562 steps/s (collection: 2.007s, learning 0.151s)
             Mean action noise std: 2.55
          Mean value_function loss: 65.3309
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.0687
                       Mean reward: 710.29
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0954
    Episode_Reward/rotating_object: 139.9720
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.16s
                      Time elapsed: 00:30:15
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 46488 steps/s (collection: 2.000s, learning 0.114s)
             Mean action noise std: 2.55
          Mean value_function loss: 63.4731
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.0871
                       Mean reward: 709.54
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 136.9893
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.11s
                      Time elapsed: 00:30:17
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 47840 steps/s (collection: 1.966s, learning 0.088s)
             Mean action noise std: 2.56
          Mean value_function loss: 69.5346
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.1088
                       Mean reward: 735.87
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.0893
    Episode_Reward/rotating_object: 139.2480
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.05s
                      Time elapsed: 00:30:19
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 47040 steps/s (collection: 1.992s, learning 0.098s)
             Mean action noise std: 2.56
          Mean value_function loss: 79.7288
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.1309
                       Mean reward: 729.53
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 139.2059
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.09s
                      Time elapsed: 00:30:21
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 47797 steps/s (collection: 1.967s, learning 0.090s)
             Mean action noise std: 2.56
          Mean value_function loss: 61.8534
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.1487
                       Mean reward: 707.22
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 1.0920
    Episode_Reward/rotating_object: 140.1232
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.06s
                      Time elapsed: 00:30:23
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 43996 steps/s (collection: 2.120s, learning 0.114s)
             Mean action noise std: 2.56
          Mean value_function loss: 68.8207
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.1710
                       Mean reward: 705.29
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 1.0996
    Episode_Reward/rotating_object: 141.7945
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.23s
                      Time elapsed: 00:30:25
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 44732 steps/s (collection: 2.021s, learning 0.177s)
             Mean action noise std: 2.57
          Mean value_function loss: 68.3590
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.1958
                       Mean reward: 704.26
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.0955
    Episode_Reward/rotating_object: 140.4403
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.20s
                      Time elapsed: 00:30:28
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 42686 steps/s (collection: 2.189s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 70.2316
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.2173
                       Mean reward: 721.22
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 135.9760
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.30s
                      Time elapsed: 00:30:30
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 46060 steps/s (collection: 2.018s, learning 0.117s)
             Mean action noise std: 2.57
          Mean value_function loss: 60.9996
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.2310
                       Mean reward: 711.68
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 140.3580
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.13s
                      Time elapsed: 00:30:32
                               ETA: 00:25:30

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 46341 steps/s (collection: 2.013s, learning 0.108s)
             Mean action noise std: 2.57
          Mean value_function loss: 64.0317
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.2544
                       Mean reward: 700.43
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 140.7749
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.12s
                      Time elapsed: 00:30:34
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 47999 steps/s (collection: 1.945s, learning 0.103s)
             Mean action noise std: 2.58
          Mean value_function loss: 56.9457
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.2824
                       Mean reward: 729.29
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 138.2233
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.05s
                      Time elapsed: 00:30:36
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 46641 steps/s (collection: 1.986s, learning 0.122s)
             Mean action noise std: 2.58
          Mean value_function loss: 59.7175
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.3064
                       Mean reward: 711.18
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 139.6623
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.11s
                      Time elapsed: 00:30:38
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 47011 steps/s (collection: 2.000s, learning 0.091s)
             Mean action noise std: 2.58
          Mean value_function loss: 58.8886
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.3298
                       Mean reward: 707.89
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 1.1058
    Episode_Reward/rotating_object: 142.7462
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.09s
                      Time elapsed: 00:30:40
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 46774 steps/s (collection: 1.988s, learning 0.114s)
             Mean action noise std: 2.58
          Mean value_function loss: 67.4204
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.3455
                       Mean reward: 687.57
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.0942
    Episode_Reward/rotating_object: 141.7372
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.10s
                      Time elapsed: 00:30:43
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 45332 steps/s (collection: 2.075s, learning 0.093s)
             Mean action noise std: 2.59
          Mean value_function loss: 64.7314
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 51.3642
                       Mean reward: 734.15
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.0974
    Episode_Reward/rotating_object: 144.4806
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.17s
                      Time elapsed: 00:30:45
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 46207 steps/s (collection: 2.009s, learning 0.119s)
             Mean action noise std: 2.59
          Mean value_function loss: 68.3019
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.3817
                       Mean reward: 734.07
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 1.1141
    Episode_Reward/rotating_object: 145.3147
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.13s
                      Time elapsed: 00:30:47
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 45204 steps/s (collection: 2.065s, learning 0.110s)
             Mean action noise std: 2.59
          Mean value_function loss: 60.8520
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 51.4017
                       Mean reward: 709.50
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 139.1994
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.17s
                      Time elapsed: 00:30:49
                               ETA: 00:25:11

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 42038 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 54.1786
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.4297
                       Mean reward: 720.25
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.0763
    Episode_Reward/rotating_object: 139.5954
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.34s
                      Time elapsed: 00:30:51
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 47893 steps/s (collection: 1.956s, learning 0.097s)
             Mean action noise std: 2.60
          Mean value_function loss: 63.9610
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.4596
                       Mean reward: 721.13
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 137.1776
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.05s
                      Time elapsed: 00:30:53
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 47393 steps/s (collection: 1.977s, learning 0.097s)
             Mean action noise std: 2.60
          Mean value_function loss: 54.1404
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.4794
                       Mean reward: 712.39
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 1.0953
    Episode_Reward/rotating_object: 141.2823
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.07s
                      Time elapsed: 00:30:55
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 47889 steps/s (collection: 1.962s, learning 0.091s)
             Mean action noise std: 2.60
          Mean value_function loss: 58.9362
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.4986
                       Mean reward: 711.57
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.1021
    Episode_Reward/rotating_object: 143.9097
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.05s
                      Time elapsed: 00:30:58
                               ETA: 00:25:02

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 45793 steps/s (collection: 2.020s, learning 0.127s)
             Mean action noise std: 2.61
          Mean value_function loss: 59.0658
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.5213
                       Mean reward: 712.39
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 141.5027
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.15s
                      Time elapsed: 00:31:00
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 46492 steps/s (collection: 1.965s, learning 0.149s)
             Mean action noise std: 2.61
          Mean value_function loss: 64.6861
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.5444
                       Mean reward: 713.02
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 141.2643
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.11s
                      Time elapsed: 00:31:02
                               ETA: 00:24:57

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 45544 steps/s (collection: 2.004s, learning 0.155s)
             Mean action noise std: 2.61
          Mean value_function loss: 72.0569
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.5587
                       Mean reward: 718.60
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 1.0971
    Episode_Reward/rotating_object: 142.4654
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.16s
                      Time elapsed: 00:31:04
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 46862 steps/s (collection: 1.988s, learning 0.110s)
             Mean action noise std: 2.61
          Mean value_function loss: 79.3608
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.5797
                       Mean reward: 682.49
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.0586
    Episode_Reward/rotating_object: 136.5973
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.10s
                      Time elapsed: 00:31:06
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 47574 steps/s (collection: 1.970s, learning 0.096s)
             Mean action noise std: 2.62
          Mean value_function loss: 80.1866
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.6046
                       Mean reward: 686.68
               Mean episode length: 231.81
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 136.8918
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.07s
                      Time elapsed: 00:31:08
                               ETA: 00:24:50

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 48151 steps/s (collection: 1.949s, learning 0.092s)
             Mean action noise std: 2.62
          Mean value_function loss: 68.2312
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.6296
                       Mean reward: 677.07
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.0873
    Episode_Reward/rotating_object: 141.4435
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.04s
                      Time elapsed: 00:31:10
                               ETA: 00:24:48

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 46282 steps/s (collection: 2.014s, learning 0.110s)
             Mean action noise std: 2.62
          Mean value_function loss: 69.1023
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.6546
                       Mean reward: 674.37
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 140.5745
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.12s
                      Time elapsed: 00:31:12
                               ETA: 00:24:45

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 48198 steps/s (collection: 1.938s, learning 0.101s)
             Mean action noise std: 2.63
          Mean value_function loss: 67.0242
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.6785
                       Mean reward: 725.71
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 1.0653
    Episode_Reward/rotating_object: 134.4585
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.04s
                      Time elapsed: 00:31:14
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 47995 steps/s (collection: 1.961s, learning 0.088s)
             Mean action noise std: 2.63
          Mean value_function loss: 48.6670
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.6964
                       Mean reward: 706.99
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0899
    Episode_Reward/rotating_object: 141.0118
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.05s
                      Time elapsed: 00:31:16
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 48370 steps/s (collection: 1.941s, learning 0.092s)
             Mean action noise std: 2.63
          Mean value_function loss: 69.2547
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.7115
                       Mean reward: 675.70
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 139.7797
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.03s
                      Time elapsed: 00:31:18
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 47677 steps/s (collection: 1.973s, learning 0.089s)
             Mean action noise std: 2.63
          Mean value_function loss: 61.0135
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.7330
                       Mean reward: 743.29
               Mean episode length: 246.86
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 141.6446
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.06s
                      Time elapsed: 00:31:20
                               ETA: 00:24:36

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 48430 steps/s (collection: 1.935s, learning 0.095s)
             Mean action noise std: 2.64
          Mean value_function loss: 62.9009
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.7547
                       Mean reward: 713.19
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.0765
    Episode_Reward/rotating_object: 137.9241
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.03s
                      Time elapsed: 00:31:22
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 47527 steps/s (collection: 1.954s, learning 0.114s)
             Mean action noise std: 2.64
          Mean value_function loss: 63.8030
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.7806
                       Mean reward: 730.92
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.0863
    Episode_Reward/rotating_object: 139.1736
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.07s
                      Time elapsed: 00:31:25
                               ETA: 00:24:31

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 48405 steps/s (collection: 1.938s, learning 0.093s)
             Mean action noise std: 2.64
          Mean value_function loss: 67.4890
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.8004
                       Mean reward: 723.24
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 141.8536
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.03s
                      Time elapsed: 00:31:27
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 48146 steps/s (collection: 1.953s, learning 0.089s)
             Mean action noise std: 2.64
          Mean value_function loss: 70.8589
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.8151
                       Mean reward: 712.63
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 137.3446
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.04s
                      Time elapsed: 00:31:29
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 47948 steps/s (collection: 1.951s, learning 0.099s)
             Mean action noise std: 2.64
          Mean value_function loss: 78.3599
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.8265
                       Mean reward: 630.64
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 1.0676
    Episode_Reward/rotating_object: 136.4429
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.05s
                      Time elapsed: 00:31:31
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 48085 steps/s (collection: 1.952s, learning 0.092s)
             Mean action noise std: 2.65
          Mean value_function loss: 70.2660
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.8459
                       Mean reward: 717.83
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 140.6652
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.04s
                      Time elapsed: 00:31:33
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 45987 steps/s (collection: 2.038s, learning 0.100s)
             Mean action noise std: 2.65
          Mean value_function loss: 62.9270
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.8696
                       Mean reward: 728.47
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 141.5150
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.14s
                      Time elapsed: 00:31:35
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 46425 steps/s (collection: 2.010s, learning 0.108s)
             Mean action noise std: 2.65
          Mean value_function loss: 60.3254
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.8915
                       Mean reward: 697.42
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.0977
    Episode_Reward/rotating_object: 141.6081
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.12s
                      Time elapsed: 00:31:37
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 46194 steps/s (collection: 2.018s, learning 0.110s)
             Mean action noise std: 2.65
          Mean value_function loss: 67.5280
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.9083
                       Mean reward: 703.57
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 137.5863
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.13s
                      Time elapsed: 00:31:39
                               ETA: 00:24:14

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 47242 steps/s (collection: 1.982s, learning 0.099s)
             Mean action noise std: 2.66
          Mean value_function loss: 58.0875
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.9245
                       Mean reward: 700.42
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 1.1032
    Episode_Reward/rotating_object: 143.0249
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.08s
                      Time elapsed: 00:31:41
                               ETA: 00:24:12

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 45753 steps/s (collection: 2.026s, learning 0.123s)
             Mean action noise std: 2.66
          Mean value_function loss: 47.9516
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.9435
                       Mean reward: 755.44
               Mean episode length: 247.38
    Episode_Reward/reaching_object: 1.0999
    Episode_Reward/rotating_object: 144.9768
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.15s
                      Time elapsed: 00:31:43
                               ETA: 00:24:10

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 46572 steps/s (collection: 2.021s, learning 0.090s)
             Mean action noise std: 2.66
          Mean value_function loss: 52.4335
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.9644
                       Mean reward: 704.01
               Mean episode length: 234.86
    Episode_Reward/reaching_object: 1.0976
    Episode_Reward/rotating_object: 142.0468
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.11s
                      Time elapsed: 00:31:45
                               ETA: 00:24:07

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 48035 steps/s (collection: 1.935s, learning 0.111s)
             Mean action noise std: 2.66
          Mean value_function loss: 60.5632
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 51.9857
                       Mean reward: 722.79
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.0994
    Episode_Reward/rotating_object: 142.3273
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.05s
                      Time elapsed: 00:31:47
                               ETA: 00:24:05

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 47008 steps/s (collection: 1.976s, learning 0.116s)
             Mean action noise std: 2.67
          Mean value_function loss: 60.8897
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.9973
                       Mean reward: 706.61
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.0574
    Episode_Reward/rotating_object: 134.1870
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.09s
                      Time elapsed: 00:31:50
                               ETA: 00:24:03

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 46399 steps/s (collection: 2.009s, learning 0.109s)
             Mean action noise std: 2.67
          Mean value_function loss: 53.4338
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.0207
                       Mean reward: 733.04
               Mean episode length: 246.76
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 146.2546
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.12s
                      Time elapsed: 00:31:52
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 46451 steps/s (collection: 2.011s, learning 0.105s)
             Mean action noise std: 2.67
          Mean value_function loss: 65.9698
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.0467
                       Mean reward: 736.19
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 1.1103
    Episode_Reward/rotating_object: 146.1580
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.12s
                      Time elapsed: 00:31:54
                               ETA: 00:23:58

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 44582 steps/s (collection: 2.070s, learning 0.135s)
             Mean action noise std: 2.68
          Mean value_function loss: 79.1337
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.0680
                       Mean reward: 691.58
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.0503
    Episode_Reward/rotating_object: 135.1749
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.20s
                      Time elapsed: 00:31:56
                               ETA: 00:23:56

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 47136 steps/s (collection: 1.978s, learning 0.108s)
             Mean action noise std: 2.68
          Mean value_function loss: 70.0719
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.0859
                       Mean reward: 706.01
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 1.0791
    Episode_Reward/rotating_object: 140.3290
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.09s
                      Time elapsed: 00:31:58
                               ETA: 00:23:53

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 46020 steps/s (collection: 1.995s, learning 0.141s)
             Mean action noise std: 2.68
          Mean value_function loss: 86.8080
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 52.1033
                       Mean reward: 700.42
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 137.1207
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.14s
                      Time elapsed: 00:32:00
                               ETA: 00:23:51

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 46589 steps/s (collection: 1.977s, learning 0.133s)
             Mean action noise std: 2.68
          Mean value_function loss: 77.8437
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.1262
                       Mean reward: 700.66
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.0597
    Episode_Reward/rotating_object: 137.8130
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.11s
                      Time elapsed: 00:32:02
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 45449 steps/s (collection: 2.044s, learning 0.119s)
             Mean action noise std: 2.69
          Mean value_function loss: 65.2065
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.1501
                       Mean reward: 666.17
               Mean episode length: 228.27
    Episode_Reward/reaching_object: 1.0806
    Episode_Reward/rotating_object: 139.1319
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.16s
                      Time elapsed: 00:32:05
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 48030 steps/s (collection: 1.952s, learning 0.095s)
             Mean action noise std: 2.69
          Mean value_function loss: 58.0129
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.1641
                       Mean reward: 707.49
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.0604
    Episode_Reward/rotating_object: 136.9149
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.05s
                      Time elapsed: 00:32:07
                               ETA: 00:23:44

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 47719 steps/s (collection: 1.953s, learning 0.108s)
             Mean action noise std: 2.69
          Mean value_function loss: 63.1216
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.1763
                       Mean reward: 748.55
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.1060
    Episode_Reward/rotating_object: 143.9556
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.06s
                      Time elapsed: 00:32:09
                               ETA: 00:23:42

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 48561 steps/s (collection: 1.932s, learning 0.092s)
             Mean action noise std: 2.69
          Mean value_function loss: 54.5622
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.1911
                       Mean reward: 719.36
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 139.8970
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.02s
                      Time elapsed: 00:32:11
                               ETA: 00:23:39

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 47627 steps/s (collection: 1.975s, learning 0.089s)
             Mean action noise std: 2.69
          Mean value_function loss: 58.1988
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.2123
                       Mean reward: 728.43
               Mean episode length: 244.77
    Episode_Reward/reaching_object: 1.0951
    Episode_Reward/rotating_object: 142.0771
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.06s
                      Time elapsed: 00:32:13
                               ETA: 00:23:37

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 47091 steps/s (collection: 1.977s, learning 0.111s)
             Mean action noise std: 2.70
          Mean value_function loss: 58.7031
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 52.2284
                       Mean reward: 728.14
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 1.0939
    Episode_Reward/rotating_object: 144.9729
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.09s
                      Time elapsed: 00:32:15
                               ETA: 00:23:35

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 48280 steps/s (collection: 1.932s, learning 0.105s)
             Mean action noise std: 2.70
          Mean value_function loss: 80.8856
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.2431
                       Mean reward: 710.73
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 138.1842
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.04s
                      Time elapsed: 00:32:17
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 47508 steps/s (collection: 1.960s, learning 0.109s)
             Mean action noise std: 2.70
          Mean value_function loss: 66.9736
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.2631
                       Mean reward: 706.32
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.1117
    Episode_Reward/rotating_object: 144.4328
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.07s
                      Time elapsed: 00:32:19
                               ETA: 00:23:30

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 47168 steps/s (collection: 1.963s, learning 0.122s)
             Mean action noise std: 2.70
          Mean value_function loss: 70.6213
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.2874
                       Mean reward: 709.78
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.0966
    Episode_Reward/rotating_object: 141.2013
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.08s
                      Time elapsed: 00:32:21
                               ETA: 00:23:28

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 46906 steps/s (collection: 1.997s, learning 0.099s)
             Mean action noise std: 2.71
          Mean value_function loss: 61.8025
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.3137
                       Mean reward: 693.21
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 140.2296
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.10s
                      Time elapsed: 00:32:23
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 45974 steps/s (collection: 2.015s, learning 0.123s)
             Mean action noise std: 2.71
          Mean value_function loss: 70.5150
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.3387
                       Mean reward: 656.22
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 1.0745
    Episode_Reward/rotating_object: 139.8477
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.14s
                      Time elapsed: 00:32:25
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 44093 steps/s (collection: 2.090s, learning 0.139s)
             Mean action noise std: 2.71
          Mean value_function loss: 56.6335
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.3566
                       Mean reward: 716.88
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 1.0778
    Episode_Reward/rotating_object: 139.4729
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.23s
                      Time elapsed: 00:32:27
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 44793 steps/s (collection: 2.057s, learning 0.138s)
             Mean action noise std: 2.72
          Mean value_function loss: 76.9458
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.3770
                       Mean reward: 718.53
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.0849
    Episode_Reward/rotating_object: 143.0606
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.19s
                      Time elapsed: 00:32:30
                               ETA: 00:23:19

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 46571 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 2.72
          Mean value_function loss: 79.0375
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.3989
                       Mean reward: 740.40
               Mean episode length: 245.30
    Episode_Reward/reaching_object: 1.0888
    Episode_Reward/rotating_object: 143.7526
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.11s
                      Time elapsed: 00:32:32
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 48073 steps/s (collection: 1.952s, learning 0.093s)
             Mean action noise std: 2.72
          Mean value_function loss: 55.8289
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.4192
                       Mean reward: 722.64
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.0684
    Episode_Reward/rotating_object: 140.6752
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.04s
                      Time elapsed: 00:32:34
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 47562 steps/s (collection: 1.950s, learning 0.117s)
             Mean action noise std: 2.72
          Mean value_function loss: 67.6002
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.4333
                       Mean reward: 718.92
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.1021
    Episode_Reward/rotating_object: 143.4032
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.07s
                      Time elapsed: 00:32:36
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 46714 steps/s (collection: 1.989s, learning 0.116s)
             Mean action noise std: 2.73
          Mean value_function loss: 70.7284
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.4508
                       Mean reward: 741.83
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 139.4310
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.10s
                      Time elapsed: 00:32:38
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 45137 steps/s (collection: 2.059s, learning 0.119s)
             Mean action noise std: 2.73
          Mean value_function loss: 64.0405
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.4764
                       Mean reward: 681.67
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 140.4668
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.18s
                      Time elapsed: 00:32:40
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 45198 steps/s (collection: 2.039s, learning 0.136s)
             Mean action noise std: 2.73
          Mean value_function loss: 61.5952
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.5021
                       Mean reward: 706.27
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 136.9628
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.17s
                      Time elapsed: 00:32:42
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 47067 steps/s (collection: 1.982s, learning 0.107s)
             Mean action noise std: 2.73
          Mean value_function loss: 59.3624
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.5198
                       Mean reward: 709.58
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.0791
    Episode_Reward/rotating_object: 140.8873
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.09s
                      Time elapsed: 00:32:44
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 46678 steps/s (collection: 2.006s, learning 0.100s)
             Mean action noise std: 2.74
          Mean value_function loss: 68.0541
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.5378
                       Mean reward: 720.88
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.0869
    Episode_Reward/rotating_object: 140.9862
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.11s
                      Time elapsed: 00:32:47
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 45871 steps/s (collection: 2.043s, learning 0.100s)
             Mean action noise std: 2.74
          Mean value_function loss: 57.9742
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.5594
                       Mean reward: 712.44
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 143.1505
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.14s
                      Time elapsed: 00:32:49
                               ETA: 00:22:58

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 45989 steps/s (collection: 2.019s, learning 0.118s)
             Mean action noise std: 2.74
          Mean value_function loss: 69.5951
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.5816
                       Mean reward: 648.12
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.0631
    Episode_Reward/rotating_object: 135.5135
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.14s
                      Time elapsed: 00:32:51
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 45898 steps/s (collection: 2.018s, learning 0.124s)
             Mean action noise std: 2.74
          Mean value_function loss: 72.0326
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.6014
                       Mean reward: 750.28
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 140.3757
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.14s
                      Time elapsed: 00:32:53
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 43218 steps/s (collection: 2.125s, learning 0.150s)
             Mean action noise std: 2.75
          Mean value_function loss: 69.3536
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.6173
                       Mean reward: 751.86
               Mean episode length: 242.83
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 140.8155
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.27s
                      Time elapsed: 00:32:55
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 42787 steps/s (collection: 2.137s, learning 0.161s)
             Mean action noise std: 2.75
          Mean value_function loss: 63.6816
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.6348
                       Mean reward: 678.10
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.0768
    Episode_Reward/rotating_object: 138.9899
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.30s
                      Time elapsed: 00:32:58
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 44647 steps/s (collection: 2.104s, learning 0.098s)
             Mean action noise std: 2.75
          Mean value_function loss: 71.3941
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.6529
                       Mean reward: 728.09
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.0687
    Episode_Reward/rotating_object: 137.9969
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.20s
                      Time elapsed: 00:33:00
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 46647 steps/s (collection: 2.000s, learning 0.108s)
             Mean action noise std: 2.75
          Mean value_function loss: 66.5055
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.6741
                       Mean reward: 720.57
               Mean episode length: 238.34
    Episode_Reward/reaching_object: 1.0868
    Episode_Reward/rotating_object: 142.5429
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.11s
                      Time elapsed: 00:33:02
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 47524 steps/s (collection: 1.971s, learning 0.098s)
             Mean action noise std: 2.76
          Mean value_function loss: 72.6124
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.6875
                       Mean reward: 716.15
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 139.1149
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.07s
                      Time elapsed: 00:33:04
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 46198 steps/s (collection: 2.022s, learning 0.106s)
             Mean action noise std: 2.76
          Mean value_function loss: 72.4506
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.6977
                       Mean reward: 697.85
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 141.2925
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.13s
                      Time elapsed: 00:33:06
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 46266 steps/s (collection: 2.003s, learning 0.122s)
             Mean action noise std: 2.76
          Mean value_function loss: 67.7875
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.7179
                       Mean reward: 717.02
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.0587
    Episode_Reward/rotating_object: 137.5389
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.12s
                      Time elapsed: 00:33:08
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 45897 steps/s (collection: 2.005s, learning 0.137s)
             Mean action noise std: 2.76
          Mean value_function loss: 80.7381
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.7377
                       Mean reward: 687.16
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.0780
    Episode_Reward/rotating_object: 139.4743
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.14s
                      Time elapsed: 00:33:10
                               ETA: 00:22:35

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 45555 steps/s (collection: 2.048s, learning 0.110s)
             Mean action noise std: 2.77
          Mean value_function loss: 68.9454
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.7570
                       Mean reward: 733.19
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.0587
    Episode_Reward/rotating_object: 138.3520
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.16s
                      Time elapsed: 00:33:12
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 42791 steps/s (collection: 2.202s, learning 0.095s)
             Mean action noise std: 2.77
          Mean value_function loss: 64.2580
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.7716
                       Mean reward: 729.01
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.0754
    Episode_Reward/rotating_object: 139.2369
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.30s
                      Time elapsed: 00:33:15
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 46307 steps/s (collection: 2.030s, learning 0.093s)
             Mean action noise std: 2.77
          Mean value_function loss: 68.1589
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.7842
                       Mean reward: 706.19
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.0606
    Episode_Reward/rotating_object: 138.4361
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.12s
                      Time elapsed: 00:33:17
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 42304 steps/s (collection: 2.229s, learning 0.095s)
             Mean action noise std: 2.77
          Mean value_function loss: 78.4213
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.7983
                       Mean reward: 707.89
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.0841
    Episode_Reward/rotating_object: 141.2445
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.32s
                      Time elapsed: 00:33:19
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 43610 steps/s (collection: 2.046s, learning 0.208s)
             Mean action noise std: 2.77
          Mean value_function loss: 72.3659
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.8182
                       Mean reward: 711.33
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.0715
    Episode_Reward/rotating_object: 138.4378
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.25s
                      Time elapsed: 00:33:21
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 43734 steps/s (collection: 2.100s, learning 0.148s)
             Mean action noise std: 2.78
          Mean value_function loss: 72.2314
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.8433
                       Mean reward: 670.74
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.0602
    Episode_Reward/rotating_object: 135.4070
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.25s
                      Time elapsed: 00:33:24
                               ETA: 00:22:22

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 45252 steps/s (collection: 2.063s, learning 0.110s)
             Mean action noise std: 2.78
          Mean value_function loss: 61.9972
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.8650
                       Mean reward: 662.74
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 135.8561
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.17s
                      Time elapsed: 00:33:26
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 45559 steps/s (collection: 2.043s, learning 0.115s)
             Mean action noise std: 2.78
          Mean value_function loss: 72.5173
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.8774
                       Mean reward: 691.47
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 137.9400
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.16s
                      Time elapsed: 00:33:28
                               ETA: 00:22:17

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 42557 steps/s (collection: 2.151s, learning 0.159s)
             Mean action noise std: 2.78
          Mean value_function loss: 80.1823
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.8880
                       Mean reward: 660.49
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 138.9779
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.31s
                      Time elapsed: 00:33:30
                               ETA: 00:22:15

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 45781 steps/s (collection: 2.040s, learning 0.107s)
             Mean action noise std: 2.79
          Mean value_function loss: 61.1789
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.9066
                       Mean reward: 678.33
               Mean episode length: 230.22
    Episode_Reward/reaching_object: 1.0678
    Episode_Reward/rotating_object: 138.0513
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.15s
                      Time elapsed: 00:33:32
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 44105 steps/s (collection: 2.131s, learning 0.098s)
             Mean action noise std: 2.79
          Mean value_function loss: 70.8618
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.9229
                       Mean reward: 666.94
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.0651
    Episode_Reward/rotating_object: 137.5498
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.23s
                      Time elapsed: 00:33:35
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 45906 steps/s (collection: 2.021s, learning 0.121s)
             Mean action noise std: 2.79
          Mean value_function loss: 70.1198
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.9395
                       Mean reward: 694.29
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.0624
    Episode_Reward/rotating_object: 137.8497
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.14s
                      Time elapsed: 00:33:37
                               ETA: 00:22:08

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 45091 steps/s (collection: 2.077s, learning 0.103s)
             Mean action noise std: 2.79
          Mean value_function loss: 52.2308
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.9624
                       Mean reward: 730.41
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 1.1028
    Episode_Reward/rotating_object: 142.4885
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.18s
                      Time elapsed: 00:33:39
                               ETA: 00:22:06

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 45756 steps/s (collection: 2.049s, learning 0.099s)
             Mean action noise std: 2.80
          Mean value_function loss: 78.0098
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.9823
                       Mean reward: 738.39
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 1.0878
    Episode_Reward/rotating_object: 142.6550
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.15s
                      Time elapsed: 00:33:41
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 43219 steps/s (collection: 2.063s, learning 0.211s)
             Mean action noise std: 2.80
          Mean value_function loss: 62.5671
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.9992
                       Mean reward: 719.09
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.0651
    Episode_Reward/rotating_object: 138.2330
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.27s
                      Time elapsed: 00:33:43
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 44761 steps/s (collection: 2.031s, learning 0.165s)
             Mean action noise std: 2.80
          Mean value_function loss: 65.7633
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.0180
                       Mean reward: 673.58
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.0698
    Episode_Reward/rotating_object: 136.4460
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.20s
                      Time elapsed: 00:33:46
                               ETA: 00:21:59

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 46447 steps/s (collection: 2.020s, learning 0.097s)
             Mean action noise std: 2.80
          Mean value_function loss: 75.8855
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.0317
                       Mean reward: 703.20
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 142.3345
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.12s
                      Time elapsed: 00:33:48
                               ETA: 00:21:57

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 43429 steps/s (collection: 2.104s, learning 0.159s)
             Mean action noise std: 2.81
          Mean value_function loss: 72.3450
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.0523
                       Mean reward: 666.31
               Mean episode length: 229.99
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 138.5850
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.26s
                      Time elapsed: 00:33:50
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 43903 steps/s (collection: 2.099s, learning 0.140s)
             Mean action noise std: 2.81
          Mean value_function loss: 76.9287
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.0688
                       Mean reward: 685.52
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 135.6362
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.24s
                      Time elapsed: 00:33:52
                               ETA: 00:21:52

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 42559 steps/s (collection: 2.150s, learning 0.160s)
             Mean action noise std: 2.81
          Mean value_function loss: 66.4758
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.0835
                       Mean reward: 739.02
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.0890
    Episode_Reward/rotating_object: 142.9104
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.31s
                      Time elapsed: 00:33:55
                               ETA: 00:21:50

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 45353 steps/s (collection: 2.064s, learning 0.103s)
             Mean action noise std: 2.81
          Mean value_function loss: 63.9439
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.0962
                       Mean reward: 656.03
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.0893
    Episode_Reward/rotating_object: 138.3972
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.17s
                      Time elapsed: 00:33:57
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 45955 steps/s (collection: 2.036s, learning 0.103s)
             Mean action noise std: 2.81
          Mean value_function loss: 54.6130
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.1141
                       Mean reward: 769.96
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 141.8595
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.14s
                      Time elapsed: 00:33:59
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 46184 steps/s (collection: 2.032s, learning 0.097s)
             Mean action noise std: 2.82
          Mean value_function loss: 55.5691
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.1419
                       Mean reward: 689.89
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 137.6375
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.13s
                      Time elapsed: 00:34:01
                               ETA: 00:21:43

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 46248 steps/s (collection: 2.024s, learning 0.102s)
             Mean action noise std: 2.82
          Mean value_function loss: 49.4774
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.1673
                       Mean reward: 726.85
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 1.1052
    Episode_Reward/rotating_object: 144.4355
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.13s
                      Time elapsed: 00:34:03
                               ETA: 00:21:41

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 44929 steps/s (collection: 2.064s, learning 0.124s)
             Mean action noise std: 2.82
          Mean value_function loss: 65.1233
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.1836
                       Mean reward: 719.51
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.0945
    Episode_Reward/rotating_object: 141.9643
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.19s
                      Time elapsed: 00:34:05
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 45418 steps/s (collection: 2.029s, learning 0.135s)
             Mean action noise std: 2.82
          Mean value_function loss: 50.6240
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.2013
                       Mean reward: 727.69
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 140.5970
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.16s
                      Time elapsed: 00:34:07
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 43803 steps/s (collection: 2.081s, learning 0.164s)
             Mean action noise std: 2.83
          Mean value_function loss: 54.6411
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.2140
                       Mean reward: 762.12
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.1071
    Episode_Reward/rotating_object: 144.6516
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.24s
                      Time elapsed: 00:34:10
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 45068 steps/s (collection: 2.067s, learning 0.115s)
             Mean action noise std: 2.83
          Mean value_function loss: 72.1633
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.2331
                       Mean reward: 720.74
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.0590
    Episode_Reward/rotating_object: 136.4308
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.18s
                      Time elapsed: 00:34:12
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 42570 steps/s (collection: 2.173s, learning 0.136s)
             Mean action noise std: 2.83
          Mean value_function loss: 63.5840
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.2502
                       Mean reward: 727.42
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.0872
    Episode_Reward/rotating_object: 142.0673
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.31s
                      Time elapsed: 00:34:14
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 44580 steps/s (collection: 2.073s, learning 0.132s)
             Mean action noise std: 2.83
          Mean value_function loss: 57.4256
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.2662
                       Mean reward: 737.38
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 138.7343
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.21s
                      Time elapsed: 00:34:16
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 43810 steps/s (collection: 2.085s, learning 0.159s)
             Mean action noise std: 2.84
          Mean value_function loss: 66.5346
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.2830
                       Mean reward: 697.71
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 1.0800
    Episode_Reward/rotating_object: 140.3979
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.24s
                      Time elapsed: 00:34:19
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 45044 steps/s (collection: 2.059s, learning 0.123s)
             Mean action noise std: 2.84
          Mean value_function loss: 62.2348
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.3048
                       Mean reward: 743.47
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 143.9231
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.18s
                      Time elapsed: 00:34:21
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 46208 steps/s (collection: 2.020s, learning 0.107s)
             Mean action noise std: 2.84
          Mean value_function loss: 72.1746
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.3315
                       Mean reward: 702.49
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 138.6690
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.13s
                      Time elapsed: 00:34:23
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 43904 steps/s (collection: 2.129s, learning 0.111s)
             Mean action noise std: 2.85
          Mean value_function loss: 58.4726
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.3564
                       Mean reward: 689.55
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 140.1768
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.24s
                      Time elapsed: 00:34:25
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 46783 steps/s (collection: 1.991s, learning 0.111s)
             Mean action noise std: 2.85
          Mean value_function loss: 62.4868
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.3737
                       Mean reward: 756.81
               Mean episode length: 244.85
    Episode_Reward/reaching_object: 1.1001
    Episode_Reward/rotating_object: 145.1699
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.10s
                      Time elapsed: 00:34:27
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 42486 steps/s (collection: 2.143s, learning 0.171s)
             Mean action noise std: 2.85
          Mean value_function loss: 66.3057
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.3965
                       Mean reward: 712.22
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.1085
    Episode_Reward/rotating_object: 146.2864
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.31s
                      Time elapsed: 00:34:30
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 45169 steps/s (collection: 2.042s, learning 0.134s)
             Mean action noise std: 2.85
          Mean value_function loss: 66.8023
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.4163
                       Mean reward: 745.88
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 1.0902
    Episode_Reward/rotating_object: 142.3847
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.18s
                      Time elapsed: 00:34:32
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 43608 steps/s (collection: 2.100s, learning 0.154s)
             Mean action noise std: 2.86
          Mean value_function loss: 66.2770
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.4369
                       Mean reward: 694.55
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.0956
    Episode_Reward/rotating_object: 141.4208
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.25s
                      Time elapsed: 00:34:34
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 44523 steps/s (collection: 2.105s, learning 0.103s)
             Mean action noise std: 2.86
          Mean value_function loss: 73.6060
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.4525
                       Mean reward: 671.47
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 1.0714
    Episode_Reward/rotating_object: 138.0068
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.21s
                      Time elapsed: 00:34:36
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 43509 steps/s (collection: 2.122s, learning 0.138s)
             Mean action noise std: 2.86
          Mean value_function loss: 54.6709
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.4681
                       Mean reward: 720.18
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.0904
    Episode_Reward/rotating_object: 142.5809
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.26s
                      Time elapsed: 00:34:39
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 43996 steps/s (collection: 2.132s, learning 0.102s)
             Mean action noise std: 2.86
          Mean value_function loss: 58.8890
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.4824
                       Mean reward: 691.49
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.1084
    Episode_Reward/rotating_object: 142.5039
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.23s
                      Time elapsed: 00:34:41
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 45461 steps/s (collection: 2.048s, learning 0.115s)
             Mean action noise std: 2.87
          Mean value_function loss: 62.8826
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.5029
                       Mean reward: 731.29
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 1.1006
    Episode_Reward/rotating_object: 144.5367
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.16s
                      Time elapsed: 00:34:43
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 44212 steps/s (collection: 2.116s, learning 0.108s)
             Mean action noise std: 2.87
          Mean value_function loss: 80.6536
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.5223
                       Mean reward: 702.87
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.0810
    Episode_Reward/rotating_object: 140.4800
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.22s
                      Time elapsed: 00:34:45
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 46072 steps/s (collection: 2.038s, learning 0.096s)
             Mean action noise std: 2.87
          Mean value_function loss: 75.0278
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.5422
                       Mean reward: 761.29
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.0861
    Episode_Reward/rotating_object: 141.3056
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.13s
                      Time elapsed: 00:34:47
                               ETA: 00:20:56

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 40150 steps/s (collection: 2.292s, learning 0.156s)
             Mean action noise std: 2.87
          Mean value_function loss: 66.9718
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.5614
                       Mean reward: 690.01
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 140.0874
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.45s
                      Time elapsed: 00:34:50
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 43818 steps/s (collection: 2.137s, learning 0.106s)
             Mean action noise std: 2.88
          Mean value_function loss: 68.5519
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.5916
                       Mean reward: 688.95
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.0718
    Episode_Reward/rotating_object: 139.0374
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.24s
                      Time elapsed: 00:34:52
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 45292 steps/s (collection: 2.064s, learning 0.107s)
             Mean action noise std: 2.88
          Mean value_function loss: 67.4690
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.6183
                       Mean reward: 701.46
               Mean episode length: 233.49
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 139.2792
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.17s
                      Time elapsed: 00:34:54
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 45056 steps/s (collection: 2.059s, learning 0.123s)
             Mean action noise std: 2.88
          Mean value_function loss: 74.0483
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.6320
                       Mean reward: 699.82
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 1.0790
    Episode_Reward/rotating_object: 142.9780
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.18s
                      Time elapsed: 00:34:56
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 46044 steps/s (collection: 2.032s, learning 0.103s)
             Mean action noise std: 2.88
          Mean value_function loss: 84.4824
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.6460
                       Mean reward: 676.34
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.0675
    Episode_Reward/rotating_object: 138.8186
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.13s
                      Time elapsed: 00:34:58
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 44226 steps/s (collection: 2.094s, learning 0.129s)
             Mean action noise std: 2.89
          Mean value_function loss: 69.3442
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.6655
                       Mean reward: 723.15
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 141.7585
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.22s
                      Time elapsed: 00:35:01
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 45093 steps/s (collection: 2.081s, learning 0.099s)
             Mean action noise std: 2.89
          Mean value_function loss: 58.9153
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.6839
                       Mean reward: 738.41
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.0560
    Episode_Reward/rotating_object: 139.2309
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.18s
                      Time elapsed: 00:35:03
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 43193 steps/s (collection: 2.124s, learning 0.152s)
             Mean action noise std: 2.89
          Mean value_function loss: 68.0882
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.7048
                       Mean reward: 676.91
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 137.9443
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.28s
                      Time elapsed: 00:35:05
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 44949 steps/s (collection: 2.091s, learning 0.096s)
             Mean action noise std: 2.90
          Mean value_function loss: 56.7544
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.7313
                       Mean reward: 697.25
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.0672
    Episode_Reward/rotating_object: 140.2067
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.19s
                      Time elapsed: 00:35:07
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 40919 steps/s (collection: 2.189s, learning 0.213s)
             Mean action noise std: 2.90
          Mean value_function loss: 66.7425
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.7474
                       Mean reward: 712.04
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 1.0664
    Episode_Reward/rotating_object: 137.4075
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.40s
                      Time elapsed: 00:35:10
                               ETA: 00:20:34

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 43118 steps/s (collection: 2.170s, learning 0.110s)
             Mean action noise std: 2.90
          Mean value_function loss: 80.7543
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.7677
                       Mean reward: 660.34
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.0317
    Episode_Reward/rotating_object: 135.0873
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.28s
                      Time elapsed: 00:35:12
                               ETA: 00:20:32

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 44026 steps/s (collection: 2.101s, learning 0.132s)
             Mean action noise std: 2.90
          Mean value_function loss: 57.7132
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.7866
                       Mean reward: 734.57
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.0719
    Episode_Reward/rotating_object: 143.2815
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.23s
                      Time elapsed: 00:35:14
                               ETA: 00:20:30

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 44221 steps/s (collection: 2.097s, learning 0.126s)
             Mean action noise std: 2.91
          Mean value_function loss: 74.8894
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.8066
                       Mean reward: 643.51
               Mean episode length: 219.50
    Episode_Reward/reaching_object: 1.0242
    Episode_Reward/rotating_object: 134.3085
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.22s
                      Time elapsed: 00:35:16
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 43729 steps/s (collection: 2.146s, learning 0.102s)
             Mean action noise std: 2.91
          Mean value_function loss: 69.4061
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.8288
                       Mean reward: 698.99
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.0602
    Episode_Reward/rotating_object: 138.3313
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.25s
                      Time elapsed: 00:35:19
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 39779 steps/s (collection: 2.292s, learning 0.180s)
             Mean action noise std: 2.91
          Mean value_function loss: 80.1459
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.8435
                       Mean reward: 737.37
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 141.1541
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.47s
                      Time elapsed: 00:35:21
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 42915 steps/s (collection: 2.174s, learning 0.116s)
             Mean action noise std: 2.91
          Mean value_function loss: 82.4200
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.8572
                       Mean reward: 709.12
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.0584
    Episode_Reward/rotating_object: 141.0237
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.29s
                      Time elapsed: 00:35:23
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 45506 steps/s (collection: 2.058s, learning 0.102s)
             Mean action noise std: 2.92
          Mean value_function loss: 66.4702
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.8761
                       Mean reward: 682.95
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 139.3540
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.16s
                      Time elapsed: 00:35:26
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 45084 steps/s (collection: 2.065s, learning 0.116s)
             Mean action noise std: 2.92
          Mean value_function loss: 72.4841
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.8903
                       Mean reward: 711.24
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 138.6922
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.18s
                      Time elapsed: 00:35:28
                               ETA: 00:20:16

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 44020 steps/s (collection: 2.120s, learning 0.113s)
             Mean action noise std: 2.92
          Mean value_function loss: 56.8564
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.9040
                       Mean reward: 731.38
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 143.7648
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.23s
                      Time elapsed: 00:35:30
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 46639 steps/s (collection: 2.008s, learning 0.100s)
             Mean action noise std: 2.92
          Mean value_function loss: 75.6985
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.9214
                       Mean reward: 735.15
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.0502
    Episode_Reward/rotating_object: 138.4199
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.11s
                      Time elapsed: 00:35:32
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 45286 steps/s (collection: 2.064s, learning 0.107s)
             Mean action noise std: 2.92
          Mean value_function loss: 58.7853
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.9358
                       Mean reward: 745.39
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 1.0629
    Episode_Reward/rotating_object: 141.8545
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.17s
                      Time elapsed: 00:35:34
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 45849 steps/s (collection: 2.045s, learning 0.099s)
             Mean action noise std: 2.93
          Mean value_function loss: 72.1116
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.9556
                       Mean reward: 707.57
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.0531
    Episode_Reward/rotating_object: 138.0200
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.14s
                      Time elapsed: 00:35:36
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 46079 steps/s (collection: 2.031s, learning 0.102s)
             Mean action noise std: 2.93
          Mean value_function loss: 71.8316
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.9695
                       Mean reward: 684.27
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 140.6049
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.13s
                      Time elapsed: 00:35:39
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 46408 steps/s (collection: 2.014s, learning 0.104s)
             Mean action noise std: 2.93
          Mean value_function loss: 60.0640
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.9856
                       Mean reward: 714.97
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 1.0412
    Episode_Reward/rotating_object: 138.1284
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.12s
                      Time elapsed: 00:35:41
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 44725 steps/s (collection: 2.072s, learning 0.126s)
             Mean action noise std: 2.93
          Mean value_function loss: 72.6222
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.0012
                       Mean reward: 677.16
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 139.0734
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.20s
                      Time elapsed: 00:35:43
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 45379 steps/s (collection: 2.069s, learning 0.098s)
             Mean action noise std: 2.94
          Mean value_function loss: 71.0424
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.0237
                       Mean reward: 699.32
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.0765
    Episode_Reward/rotating_object: 141.3243
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.17s
                      Time elapsed: 00:35:45
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 46194 steps/s (collection: 2.018s, learning 0.110s)
             Mean action noise std: 2.94
          Mean value_function loss: 65.1815
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.0457
                       Mean reward: 681.61
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 143.0459
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.13s
                      Time elapsed: 00:35:47
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 45270 steps/s (collection: 2.065s, learning 0.106s)
             Mean action noise std: 2.94
          Mean value_function loss: 66.1828
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.0651
                       Mean reward: 730.25
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 1.0420
    Episode_Reward/rotating_object: 137.6754
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.17s
                      Time elapsed: 00:35:49
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 43138 steps/s (collection: 2.172s, learning 0.107s)
             Mean action noise std: 2.94
          Mean value_function loss: 57.6291
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 54.0717
                       Mean reward: 704.37
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 137.0771
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.28s
                      Time elapsed: 00:35:52
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 45408 steps/s (collection: 2.053s, learning 0.112s)
             Mean action noise std: 2.95
          Mean value_function loss: 67.9886
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.0850
                       Mean reward: 726.55
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 141.3939
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.16s
                      Time elapsed: 00:35:54
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 45728 steps/s (collection: 2.046s, learning 0.104s)
             Mean action noise std: 2.95
          Mean value_function loss: 61.8159
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.0990
                       Mean reward: 709.81
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.0525
    Episode_Reward/rotating_object: 141.2966
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.15s
                      Time elapsed: 00:35:56
                               ETA: 00:19:47

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 45496 steps/s (collection: 2.038s, learning 0.123s)
             Mean action noise std: 2.95
          Mean value_function loss: 79.7260
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.1106
                       Mean reward: 679.14
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.0646
    Episode_Reward/rotating_object: 142.1669
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.16s
                      Time elapsed: 00:35:58
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 44741 steps/s (collection: 2.098s, learning 0.100s)
             Mean action noise std: 2.95
          Mean value_function loss: 78.1360
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.1271
                       Mean reward: 701.02
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 1.0389
    Episode_Reward/rotating_object: 137.2663
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.20s
                      Time elapsed: 00:36:00
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 45451 steps/s (collection: 2.051s, learning 0.112s)
             Mean action noise std: 2.95
          Mean value_function loss: 84.3603
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.1423
                       Mean reward: 671.03
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 1.0434
    Episode_Reward/rotating_object: 135.5533
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.16s
                      Time elapsed: 00:36:03
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 45249 steps/s (collection: 2.057s, learning 0.116s)
             Mean action noise std: 2.96
          Mean value_function loss: 71.8455
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.1575
                       Mean reward: 658.06
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 139.2037
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.17s
                      Time elapsed: 00:36:05
                               ETA: 00:19:38

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 44263 steps/s (collection: 2.096s, learning 0.125s)
             Mean action noise std: 2.96
          Mean value_function loss: 76.3898
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.1728
                       Mean reward: 672.84
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 138.9528
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.22s
                      Time elapsed: 00:36:07
                               ETA: 00:19:36

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 44928 steps/s (collection: 2.073s, learning 0.115s)
             Mean action noise std: 2.96
          Mean value_function loss: 80.4930
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.1888
                       Mean reward: 697.99
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 140.9571
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.19s
                      Time elapsed: 00:36:09
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 45627 steps/s (collection: 2.033s, learning 0.121s)
             Mean action noise std: 2.96
          Mean value_function loss: 72.4112
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.2057
                       Mean reward: 697.56
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.0341
    Episode_Reward/rotating_object: 135.9309
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.15s
                      Time elapsed: 00:36:11
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45051 steps/s (collection: 2.074s, learning 0.108s)
             Mean action noise std: 2.96
          Mean value_function loss: 68.6656
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.2196
                       Mean reward: 696.84
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.0596
    Episode_Reward/rotating_object: 137.9723
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.18s
                      Time elapsed: 00:36:13
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 45568 steps/s (collection: 2.036s, learning 0.121s)
             Mean action noise std: 2.97
          Mean value_function loss: 63.6837
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.2317
                       Mean reward: 675.30
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 137.1993
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.16s
                      Time elapsed: 00:36:16
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 46438 steps/s (collection: 2.014s, learning 0.103s)
             Mean action noise std: 2.97
          Mean value_function loss: 70.1525
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.2534
                       Mean reward: 676.02
               Mean episode length: 228.18
    Episode_Reward/reaching_object: 1.0630
    Episode_Reward/rotating_object: 141.6651
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.12s
                      Time elapsed: 00:36:18
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 45966 steps/s (collection: 2.041s, learning 0.098s)
             Mean action noise std: 2.97
          Mean value_function loss: 83.0344
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.2766
                       Mean reward: 686.79
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 137.8967
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.14s
                      Time elapsed: 00:36:20
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 46223 steps/s (collection: 2.026s, learning 0.101s)
             Mean action noise std: 2.98
          Mean value_function loss: 79.5677
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.3035
                       Mean reward: 685.69
               Mean episode length: 228.83
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 139.2190
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.13s
                      Time elapsed: 00:36:22
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 44760 steps/s (collection: 2.096s, learning 0.101s)
             Mean action noise std: 2.98
          Mean value_function loss: 80.7010
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.3291
                       Mean reward: 691.02
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 1.0513
    Episode_Reward/rotating_object: 137.7649
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.20s
                      Time elapsed: 00:36:24
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 44935 steps/s (collection: 2.092s, learning 0.096s)
             Mean action noise std: 2.98
          Mean value_function loss: 85.6377
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.3509
                       Mean reward: 667.98
               Mean episode length: 223.86
    Episode_Reward/reaching_object: 1.0398
    Episode_Reward/rotating_object: 136.9398
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.19s
                      Time elapsed: 00:36:26
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 45374 steps/s (collection: 2.047s, learning 0.119s)
             Mean action noise std: 2.99
          Mean value_function loss: 74.4996
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.3655
                       Mean reward: 716.36
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.0382
    Episode_Reward/rotating_object: 138.7242
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.17s
                      Time elapsed: 00:36:29
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 43892 steps/s (collection: 2.128s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 82.9517
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.3828
                       Mean reward: 693.06
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.0517
    Episode_Reward/rotating_object: 139.4760
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.24s
                      Time elapsed: 00:36:31
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 45408 steps/s (collection: 2.051s, learning 0.114s)
             Mean action noise std: 2.99
          Mean value_function loss: 70.2308
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.4048
                       Mean reward: 691.46
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.0444
    Episode_Reward/rotating_object: 136.6192
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.16s
                      Time elapsed: 00:36:33
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 45577 steps/s (collection: 2.058s, learning 0.099s)
             Mean action noise std: 2.99
          Mean value_function loss: 66.0185
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.4176
                       Mean reward: 702.87
               Mean episode length: 232.82
    Episode_Reward/reaching_object: 1.0423
    Episode_Reward/rotating_object: 137.9532
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.16s
                      Time elapsed: 00:36:35
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 46236 steps/s (collection: 2.029s, learning 0.098s)
             Mean action noise std: 2.99
          Mean value_function loss: 71.9997
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.4291
                       Mean reward: 634.28
               Mean episode length: 220.74
    Episode_Reward/reaching_object: 1.0400
    Episode_Reward/rotating_object: 138.3558
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.13s
                      Time elapsed: 00:36:37
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 44699 steps/s (collection: 2.100s, learning 0.099s)
             Mean action noise std: 3.00
          Mean value_function loss: 74.1720
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.4416
                       Mean reward: 693.32
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 1.0503
    Episode_Reward/rotating_object: 138.9344
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.20s
                      Time elapsed: 00:36:39
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 45227 steps/s (collection: 2.075s, learning 0.099s)
             Mean action noise std: 3.00
          Mean value_function loss: 68.7795
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.4594
                       Mean reward: 687.12
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.0139
    Episode_Reward/rotating_object: 133.1713
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.17s
                      Time elapsed: 00:36:42
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 44035 steps/s (collection: 2.133s, learning 0.099s)
             Mean action noise std: 3.00
          Mean value_function loss: 65.4953
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.4756
                       Mean reward: 684.84
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 1.0409
    Episode_Reward/rotating_object: 137.4664
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.23s
                      Time elapsed: 00:36:44
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 45858 steps/s (collection: 2.031s, learning 0.113s)
             Mean action noise std: 3.00
          Mean value_function loss: 66.7946
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.4950
                       Mean reward: 711.89
               Mean episode length: 240.23
    Episode_Reward/reaching_object: 1.0451
    Episode_Reward/rotating_object: 136.4375
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.14s
                      Time elapsed: 00:36:46
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 46000 steps/s (collection: 2.020s, learning 0.117s)
             Mean action noise std: 3.01
          Mean value_function loss: 66.3876
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.5160
                       Mean reward: 726.20
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.0600
    Episode_Reward/rotating_object: 140.7262
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.14s
                      Time elapsed: 00:36:48
                               ETA: 00:18:53

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 43725 steps/s (collection: 2.108s, learning 0.140s)
             Mean action noise std: 3.01
          Mean value_function loss: 59.2315
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.5360
                       Mean reward: 688.55
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.0522
    Episode_Reward/rotating_object: 138.5796
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.25s
                      Time elapsed: 00:36:50
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 46181 steps/s (collection: 2.020s, learning 0.109s)
             Mean action noise std: 3.01
          Mean value_function loss: 69.0311
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 54.5585
                       Mean reward: 700.29
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.0550
    Episode_Reward/rotating_object: 138.9193
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.13s
                      Time elapsed: 00:36:52
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 45092 steps/s (collection: 2.079s, learning 0.101s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.2475
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.5682
                       Mean reward: 694.36
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.0388
    Episode_Reward/rotating_object: 139.5907
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.18s
                      Time elapsed: 00:36:55
                               ETA: 00:18:46

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 45729 steps/s (collection: 2.028s, learning 0.122s)
             Mean action noise std: 3.02
          Mean value_function loss: 92.2092
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.5841
                       Mean reward: 689.89
               Mean episode length: 227.53
    Episode_Reward/reaching_object: 1.0293
    Episode_Reward/rotating_object: 134.9889
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.15s
                      Time elapsed: 00:36:57
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 45024 steps/s (collection: 2.069s, learning 0.115s)
             Mean action noise std: 3.02
          Mean value_function loss: 81.5910
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.6030
                       Mean reward: 666.98
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 135.8601
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.18s
                      Time elapsed: 00:36:59
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 45430 steps/s (collection: 2.038s, learning 0.126s)
             Mean action noise std: 3.02
          Mean value_function loss: 68.0413
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.6222
                       Mean reward: 710.73
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 143.0827
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.16s
                      Time elapsed: 00:37:01
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 45139 steps/s (collection: 2.061s, learning 0.116s)
             Mean action noise std: 3.03
          Mean value_function loss: 65.7827
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.6457
                       Mean reward: 734.22
               Mean episode length: 240.82
    Episode_Reward/reaching_object: 1.0616
    Episode_Reward/rotating_object: 141.6313
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.18s
                      Time elapsed: 00:37:03
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 45965 steps/s (collection: 2.021s, learning 0.118s)
             Mean action noise std: 3.03
          Mean value_function loss: 68.2412
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.6608
                       Mean reward: 720.10
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 1.0503
    Episode_Reward/rotating_object: 140.1702
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.14s
                      Time elapsed: 00:37:05
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 15066 steps/s (collection: 6.399s, learning 0.126s)
             Mean action noise std: 3.03
          Mean value_function loss: 69.6772
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.6746
                       Mean reward: 719.65
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.0608
    Episode_Reward/rotating_object: 140.1435
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.52s
                      Time elapsed: 00:37:12
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14959 steps/s (collection: 6.448s, learning 0.123s)
             Mean action noise std: 3.03
          Mean value_function loss: 74.0015
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.6961
                       Mean reward: 705.04
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 1.0536
    Episode_Reward/rotating_object: 141.1146
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.57s
                      Time elapsed: 00:37:19
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14699 steps/s (collection: 6.548s, learning 0.139s)
             Mean action noise std: 3.04
          Mean value_function loss: 87.4145
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.7147
                       Mean reward: 677.44
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.0369
    Episode_Reward/rotating_object: 136.3435
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.69s
                      Time elapsed: 00:37:25
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14634 steps/s (collection: 6.606s, learning 0.112s)
             Mean action noise std: 3.04
          Mean value_function loss: 82.2081
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.7340
                       Mean reward: 655.84
               Mean episode length: 227.70
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 136.5722
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.72s
                      Time elapsed: 00:37:32
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14663 steps/s (collection: 6.583s, learning 0.121s)
             Mean action noise std: 3.04
          Mean value_function loss: 77.5759
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.7541
                       Mean reward: 690.88
               Mean episode length: 231.36
    Episode_Reward/reaching_object: 1.0497
    Episode_Reward/rotating_object: 138.6673
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.70s
                      Time elapsed: 00:37:39
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14540 steps/s (collection: 6.622s, learning 0.138s)
             Mean action noise std: 3.04
          Mean value_function loss: 83.0496
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.7691
                       Mean reward: 680.83
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 138.9954
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.76s
                      Time elapsed: 00:37:45
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14523 steps/s (collection: 6.640s, learning 0.129s)
             Mean action noise std: 3.05
          Mean value_function loss: 78.8911
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.7833
                       Mean reward: 694.84
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.0574
    Episode_Reward/rotating_object: 140.8212
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.77s
                      Time elapsed: 00:37:52
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14288 steps/s (collection: 6.764s, learning 0.116s)
             Mean action noise std: 3.05
          Mean value_function loss: 85.8076
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.7997
                       Mean reward: 672.03
               Mean episode length: 227.35
    Episode_Reward/reaching_object: 1.0213
    Episode_Reward/rotating_object: 134.8441
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.88s
                      Time elapsed: 00:37:59
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 16154 steps/s (collection: 5.952s, learning 0.134s)
             Mean action noise std: 3.05
          Mean value_function loss: 63.4242
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.8182
                       Mean reward: 706.48
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.0690
    Episode_Reward/rotating_object: 140.8328
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 6.09s
                      Time elapsed: 00:38:05
                               ETA: 00:18:34

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 41161 steps/s (collection: 2.240s, learning 0.148s)
             Mean action noise std: 3.05
          Mean value_function loss: 61.3713
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.8287
                       Mean reward: 687.58
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 1.0405
    Episode_Reward/rotating_object: 136.8611
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.39s
                      Time elapsed: 00:38:08
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 47266 steps/s (collection: 1.984s, learning 0.095s)
             Mean action noise std: 3.05
          Mean value_function loss: 80.1342
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.8416
                       Mean reward: 716.00
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.0523
    Episode_Reward/rotating_object: 134.7923
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.08s
                      Time elapsed: 00:38:10
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 46364 steps/s (collection: 1.990s, learning 0.130s)
             Mean action noise std: 3.06
          Mean value_function loss: 82.1047
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.8528
                       Mean reward: 704.51
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.0537
    Episode_Reward/rotating_object: 137.7840
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.12s
                      Time elapsed: 00:38:12
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 46501 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 3.06
          Mean value_function loss: 76.4194
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.8678
                       Mean reward: 696.57
               Mean episode length: 232.27
    Episode_Reward/reaching_object: 1.0369
    Episode_Reward/rotating_object: 135.3203
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.11s
                      Time elapsed: 00:38:14
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 46416 steps/s (collection: 2.003s, learning 0.114s)
             Mean action noise std: 3.06
          Mean value_function loss: 72.8986
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.8824
                       Mean reward: 714.04
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.0495
    Episode_Reward/rotating_object: 138.7243
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.12s
                      Time elapsed: 00:38:16
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 45378 steps/s (collection: 2.069s, learning 0.097s)
             Mean action noise std: 3.06
          Mean value_function loss: 84.7992
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.9001
                       Mean reward: 731.37
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 141.6474
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.17s
                      Time elapsed: 00:38:18
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 47288 steps/s (collection: 1.977s, learning 0.102s)
             Mean action noise std: 3.07
          Mean value_function loss: 71.5628
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.9215
                       Mean reward: 707.00
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.0669
    Episode_Reward/rotating_object: 140.8264
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.08s
                      Time elapsed: 00:38:20
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 40831 steps/s (collection: 2.268s, learning 0.140s)
             Mean action noise std: 3.07
          Mean value_function loss: 87.8624
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.9288
                       Mean reward: 747.50
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 137.7602
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.41s
                      Time elapsed: 00:38:23
                               ETA: 00:18:16

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 40137 steps/s (collection: 2.330s, learning 0.119s)
             Mean action noise std: 3.07
          Mean value_function loss: 79.5056
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.9386
                       Mean reward: 698.34
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 1.0496
    Episode_Reward/rotating_object: 139.0103
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.45s
                      Time elapsed: 00:38:25
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 38557 steps/s (collection: 2.441s, learning 0.108s)
             Mean action noise std: 3.07
          Mean value_function loss: 77.7507
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.9522
                       Mean reward: 691.40
               Mean episode length: 228.89
    Episode_Reward/reaching_object: 1.0348
    Episode_Reward/rotating_object: 136.6147
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.55s
                      Time elapsed: 00:38:28
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 43880 steps/s (collection: 2.112s, learning 0.129s)
             Mean action noise std: 3.07
          Mean value_function loss: 81.3172
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.9700
                       Mean reward: 659.91
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.0357
    Episode_Reward/rotating_object: 130.9406
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.24s
                      Time elapsed: 00:38:30
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 42376 steps/s (collection: 2.207s, learning 0.113s)
             Mean action noise std: 3.08
          Mean value_function loss: 73.6043
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.9936
                       Mean reward: 715.74
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.0697
    Episode_Reward/rotating_object: 139.6303
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.32s
                      Time elapsed: 00:38:32
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 43374 steps/s (collection: 2.169s, learning 0.097s)
             Mean action noise std: 3.08
          Mean value_function loss: 82.6277
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.0109
                       Mean reward: 640.31
               Mean episode length: 219.90
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 133.6340
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.27s
                      Time elapsed: 00:38:34
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 46680 steps/s (collection: 2.006s, learning 0.100s)
             Mean action noise std: 3.08
          Mean value_function loss: 71.8395
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.0296
                       Mean reward: 682.58
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 1.0722
    Episode_Reward/rotating_object: 139.0615
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.11s
                      Time elapsed: 00:38:37
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 44105 steps/s (collection: 2.107s, learning 0.122s)
             Mean action noise std: 3.08
          Mean value_function loss: 75.7948
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.0448
                       Mean reward: 668.00
               Mean episode length: 227.43
    Episode_Reward/reaching_object: 1.0353
    Episode_Reward/rotating_object: 132.8958
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.23s
                      Time elapsed: 00:38:39
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 41079 steps/s (collection: 2.270s, learning 0.123s)
             Mean action noise std: 3.09
          Mean value_function loss: 74.7142
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.0640
                       Mean reward: 707.40
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 1.0552
    Episode_Reward/rotating_object: 140.4778
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.39s
                      Time elapsed: 00:38:41
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 41447 steps/s (collection: 2.268s, learning 0.104s)
             Mean action noise std: 3.09
          Mean value_function loss: 59.9185
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.0836
                       Mean reward: 707.94
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.0665
    Episode_Reward/rotating_object: 139.6393
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.37s
                      Time elapsed: 00:38:44
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 41075 steps/s (collection: 2.270s, learning 0.124s)
             Mean action noise std: 3.09
          Mean value_function loss: 68.8842
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.0947
                       Mean reward: 678.24
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 139.9725
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.39s
                      Time elapsed: 00:38:46
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 42650 steps/s (collection: 2.201s, learning 0.103s)
             Mean action noise std: 3.09
          Mean value_function loss: 76.2034
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.1135
                       Mean reward: 751.05
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 1.0550
    Episode_Reward/rotating_object: 142.1097
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.30s
                      Time elapsed: 00:38:48
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 42162 steps/s (collection: 2.218s, learning 0.113s)
             Mean action noise std: 3.10
          Mean value_function loss: 66.3493
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.1264
                       Mean reward: 670.21
               Mean episode length: 229.65
    Episode_Reward/reaching_object: 1.0526
    Episode_Reward/rotating_object: 135.8641
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.33s
                      Time elapsed: 00:38:51
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 44979 steps/s (collection: 2.085s, learning 0.100s)
             Mean action noise std: 3.10
          Mean value_function loss: 65.6882
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.1393
                       Mean reward: 704.78
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 142.1865
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.19s
                      Time elapsed: 00:38:53
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 45377 steps/s (collection: 2.060s, learning 0.106s)
             Mean action noise std: 3.10
          Mean value_function loss: 72.2536
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.1506
                       Mean reward: 696.02
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.0493
    Episode_Reward/rotating_object: 137.5250
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.17s
                      Time elapsed: 00:38:55
                               ETA: 00:17:44

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 47018 steps/s (collection: 1.991s, learning 0.100s)
             Mean action noise std: 3.10
          Mean value_function loss: 57.9360
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.1682
                       Mean reward: 703.87
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.0675
    Episode_Reward/rotating_object: 141.8008
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.09s
                      Time elapsed: 00:38:57
                               ETA: 00:17:42

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 47314 steps/s (collection: 1.984s, learning 0.094s)
             Mean action noise std: 3.11
          Mean value_function loss: 81.9252
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.1893
                       Mean reward: 708.72
               Mean episode length: 231.64
    Episode_Reward/reaching_object: 1.0641
    Episode_Reward/rotating_object: 141.1924
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.08s
                      Time elapsed: 00:38:59
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 47032 steps/s (collection: 1.996s, learning 0.094s)
             Mean action noise std: 3.11
          Mean value_function loss: 70.4455
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.2109
                       Mean reward: 722.84
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 139.0285
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.09s
                      Time elapsed: 00:39:01
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 47841 steps/s (collection: 1.961s, learning 0.094s)
             Mean action noise std: 3.11
          Mean value_function loss: 73.8704
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.2311
                       Mean reward: 726.20
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.0556
    Episode_Reward/rotating_object: 142.4085
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.05s
                      Time elapsed: 00:39:03
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 47202 steps/s (collection: 1.986s, learning 0.097s)
             Mean action noise std: 3.11
          Mean value_function loss: 72.4277
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.2480
                       Mean reward: 711.36
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 139.0696
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.08s
                      Time elapsed: 00:39:05
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 46702 steps/s (collection: 2.010s, learning 0.095s)
             Mean action noise std: 3.12
          Mean value_function loss: 69.1059
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.2607
                       Mean reward: 725.36
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 142.4064
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.10s
                      Time elapsed: 00:39:07
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 47542 steps/s (collection: 1.976s, learning 0.092s)
             Mean action noise std: 3.12
          Mean value_function loss: 72.7750
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.2750
                       Mean reward: 681.02
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 1.0427
    Episode_Reward/rotating_object: 137.8184
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.07s
                      Time elapsed: 00:39:10
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 46754 steps/s (collection: 2.005s, learning 0.098s)
             Mean action noise std: 3.12
          Mean value_function loss: 69.8933
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.2901
                       Mean reward: 680.14
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.0408
    Episode_Reward/rotating_object: 137.6882
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.10s
                      Time elapsed: 00:39:12
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 46711 steps/s (collection: 2.008s, learning 0.096s)
             Mean action noise std: 3.12
          Mean value_function loss: 66.5464
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.3072
                       Mean reward: 704.18
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.0504
    Episode_Reward/rotating_object: 139.5620
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.10s
                      Time elapsed: 00:39:14
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 47507 steps/s (collection: 1.962s, learning 0.108s)
             Mean action noise std: 3.13
          Mean value_function loss: 74.0139
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.3222
                       Mean reward: 696.99
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 139.7954
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.07s
                      Time elapsed: 00:39:16
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 45101 steps/s (collection: 2.086s, learning 0.094s)
             Mean action noise std: 3.13
          Mean value_function loss: 71.9921
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.3387
                       Mean reward: 632.89
               Mean episode length: 216.84
    Episode_Reward/reaching_object: 1.0531
    Episode_Reward/rotating_object: 140.3860
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.18s
                      Time elapsed: 00:39:18
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 45177 steps/s (collection: 2.065s, learning 0.111s)
             Mean action noise std: 3.13
          Mean value_function loss: 80.9807
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.3614
                       Mean reward: 699.20
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.0408
    Episode_Reward/rotating_object: 139.4477
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.18s
                      Time elapsed: 00:39:20
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 45006 steps/s (collection: 2.078s, learning 0.106s)
             Mean action noise std: 3.13
          Mean value_function loss: 74.3507
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.3772
                       Mean reward: 744.51
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 143.9068
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.18s
                      Time elapsed: 00:39:22
                               ETA: 00:17:14

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 46649 steps/s (collection: 2.001s, learning 0.106s)
             Mean action noise std: 3.14
          Mean value_function loss: 68.8548
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.3912
                       Mean reward: 721.24
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 143.3360
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.11s
                      Time elapsed: 00:39:24
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 46620 steps/s (collection: 2.013s, learning 0.096s)
             Mean action noise std: 3.14
          Mean value_function loss: 75.9362
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.4066
                       Mean reward: 733.64
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.0577
    Episode_Reward/rotating_object: 142.6263
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.11s
                      Time elapsed: 00:39:27
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 46477 steps/s (collection: 2.016s, learning 0.100s)
             Mean action noise std: 3.14
          Mean value_function loss: 64.3795
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.4147
                       Mean reward: 683.95
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.0568
    Episode_Reward/rotating_object: 138.9123
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.12s
                      Time elapsed: 00:39:29
                               ETA: 00:17:07

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 46238 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 74.1989
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.4273
                       Mean reward: 707.22
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.0669
    Episode_Reward/rotating_object: 144.5778
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.13s
                      Time elapsed: 00:39:31
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 44947 steps/s (collection: 2.077s, learning 0.110s)
             Mean action noise std: 3.14
          Mean value_function loss: 78.2827
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.4435
                       Mean reward: 661.30
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 1.0285
    Episode_Reward/rotating_object: 134.5765
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.19s
                      Time elapsed: 00:39:33
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 43579 steps/s (collection: 2.158s, learning 0.098s)
             Mean action noise std: 3.15
          Mean value_function loss: 70.8281
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.4641
                       Mean reward: 699.33
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 142.6173
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.26s
                      Time elapsed: 00:39:35
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 46383 steps/s (collection: 2.010s, learning 0.109s)
             Mean action noise std: 3.15
          Mean value_function loss: 78.9839
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.4798
                       Mean reward: 677.10
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.0488
    Episode_Reward/rotating_object: 140.5761
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.12s
                      Time elapsed: 00:39:37
                               ETA: 00:16:58

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 44325 steps/s (collection: 2.106s, learning 0.112s)
             Mean action noise std: 3.15
          Mean value_function loss: 79.1603
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.4954
                       Mean reward: 677.11
               Mean episode length: 234.90
    Episode_Reward/reaching_object: 1.0341
    Episode_Reward/rotating_object: 134.3744
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.22s
                      Time elapsed: 00:39:40
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 45369 steps/s (collection: 2.058s, learning 0.109s)
             Mean action noise std: 3.15
          Mean value_function loss: 73.9544
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.5114
                       Mean reward: 709.91
               Mean episode length: 234.26
    Episode_Reward/reaching_object: 1.0611
    Episode_Reward/rotating_object: 140.3104
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.17s
                      Time elapsed: 00:39:42
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 46265 steps/s (collection: 2.008s, learning 0.117s)
             Mean action noise std: 3.16
          Mean value_function loss: 78.7006
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.5290
                       Mean reward: 689.24
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 139.7977
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.12s
                      Time elapsed: 00:39:44
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 45994 steps/s (collection: 2.014s, learning 0.123s)
             Mean action noise std: 3.16
          Mean value_function loss: 74.2011
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.5452
                       Mean reward: 697.18
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.0698
    Episode_Reward/rotating_object: 142.2613
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.14s
                      Time elapsed: 00:39:46
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 45536 steps/s (collection: 2.038s, learning 0.121s)
             Mean action noise std: 3.16
          Mean value_function loss: 93.1353
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.5604
                       Mean reward: 627.62
               Mean episode length: 215.74
    Episode_Reward/reaching_object: 1.0238
    Episode_Reward/rotating_object: 135.0423
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.16s
                      Time elapsed: 00:39:48
                               ETA: 00:16:46

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 45681 steps/s (collection: 2.045s, learning 0.107s)
             Mean action noise std: 3.16
          Mean value_function loss: 89.3097
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.5755
                       Mean reward: 686.96
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 132.6986
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.15s
                      Time elapsed: 00:39:50
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 46481 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 3.16
          Mean value_function loss: 82.7323
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.5881
                       Mean reward: 726.32
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 138.7858
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.11s
                      Time elapsed: 00:39:52
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 46338 steps/s (collection: 2.024s, learning 0.097s)
             Mean action noise std: 3.17
          Mean value_function loss: 75.5083
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.6050
                       Mean reward: 693.77
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.0356
    Episode_Reward/rotating_object: 135.9377
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.12s
                      Time elapsed: 00:39:55
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 46304 steps/s (collection: 2.025s, learning 0.098s)
             Mean action noise std: 3.17
          Mean value_function loss: 54.8679
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.6246
                       Mean reward: 688.18
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.0509
    Episode_Reward/rotating_object: 139.7255
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.12s
                      Time elapsed: 00:39:57
                               ETA: 00:16:37

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 46757 steps/s (collection: 2.007s, learning 0.095s)
             Mean action noise std: 3.17
          Mean value_function loss: 80.5036
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.6386
                       Mean reward: 731.40
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 142.1409
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.10s
                      Time elapsed: 00:39:59
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 46252 steps/s (collection: 2.030s, learning 0.096s)
             Mean action noise std: 3.17
          Mean value_function loss: 63.3596
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.6530
                       Mean reward: 631.68
               Mean episode length: 225.92
    Episode_Reward/reaching_object: 1.0419
    Episode_Reward/rotating_object: 135.6015
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.13s
                      Time elapsed: 00:40:01
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 45878 steps/s (collection: 2.028s, learning 0.115s)
             Mean action noise std: 3.18
          Mean value_function loss: 66.1664
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.6703
                       Mean reward: 734.69
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 1.0689
    Episode_Reward/rotating_object: 142.6188
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.14s
                      Time elapsed: 00:40:03
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 45999 steps/s (collection: 2.038s, learning 0.100s)
             Mean action noise std: 3.18
          Mean value_function loss: 63.0973
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.6836
                       Mean reward: 716.63
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 139.9895
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.14s
                      Time elapsed: 00:40:05
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 46020 steps/s (collection: 2.026s, learning 0.111s)
             Mean action noise std: 3.18
          Mean value_function loss: 73.4561
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.7053
                       Mean reward: 697.21
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.0388
    Episode_Reward/rotating_object: 137.7651
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.14s
                      Time elapsed: 00:40:07
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 45746 steps/s (collection: 2.043s, learning 0.106s)
             Mean action noise std: 3.18
          Mean value_function loss: 73.2638
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.7199
                       Mean reward: 642.30
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 1.0604
    Episode_Reward/rotating_object: 138.3020
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.15s
                      Time elapsed: 00:40:09
                               ETA: 00:16:23

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 46199 steps/s (collection: 2.014s, learning 0.114s)
             Mean action noise std: 3.19
          Mean value_function loss: 79.7135
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.7384
                       Mean reward: 665.04
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 1.0602
    Episode_Reward/rotating_object: 140.3387
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.13s
                      Time elapsed: 00:40:12
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 42485 steps/s (collection: 2.215s, learning 0.099s)
             Mean action noise std: 3.19
          Mean value_function loss: 69.0636
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.7592
                       Mean reward: 690.19
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 140.3202
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.31s
                      Time elapsed: 00:40:14
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 42061 steps/s (collection: 2.217s, learning 0.120s)
             Mean action noise std: 3.19
          Mean value_function loss: 80.1800
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.7710
                       Mean reward: 710.93
               Mean episode length: 234.10
    Episode_Reward/reaching_object: 1.0352
    Episode_Reward/rotating_object: 138.5545
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.34s
                      Time elapsed: 00:40:16
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 43131 steps/s (collection: 2.182s, learning 0.098s)
             Mean action noise std: 3.19
          Mean value_function loss: 75.8386
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.7825
                       Mean reward: 700.60
               Mean episode length: 239.25
    Episode_Reward/reaching_object: 1.0583
    Episode_Reward/rotating_object: 138.5987
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.28s
                      Time elapsed: 00:40:19
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 45846 steps/s (collection: 2.039s, learning 0.105s)
             Mean action noise std: 3.20
          Mean value_function loss: 75.8549
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.7954
                       Mean reward: 698.47
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 137.0000
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.14s
                      Time elapsed: 00:40:21
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 46140 steps/s (collection: 2.036s, learning 0.094s)
             Mean action noise std: 3.20
          Mean value_function loss: 67.1229
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.8092
                       Mean reward: 715.31
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 143.1270
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.13s
                      Time elapsed: 00:40:23
                               ETA: 00:16:09

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 44760 steps/s (collection: 2.090s, learning 0.106s)
             Mean action noise std: 3.20
          Mean value_function loss: 82.9168
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.8193
                       Mean reward: 663.58
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.0406
    Episode_Reward/rotating_object: 137.8385
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.20s
                      Time elapsed: 00:40:25
                               ETA: 00:16:07

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 45219 steps/s (collection: 2.060s, learning 0.114s)
             Mean action noise std: 3.20
          Mean value_function loss: 77.4736
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.8295
                       Mean reward: 728.31
               Mean episode length: 242.64
    Episode_Reward/reaching_object: 1.0468
    Episode_Reward/rotating_object: 139.7812
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.17s
                      Time elapsed: 00:40:27
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 43067 steps/s (collection: 2.169s, learning 0.114s)
             Mean action noise std: 3.20
          Mean value_function loss: 72.9548
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.8472
                       Mean reward: 640.64
               Mean episode length: 231.81
    Episode_Reward/reaching_object: 1.0342
    Episode_Reward/rotating_object: 136.1385
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.28s
                      Time elapsed: 00:40:29
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 46187 steps/s (collection: 2.039s, learning 0.089s)
             Mean action noise std: 3.21
          Mean value_function loss: 84.8840
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.8652
                       Mean reward: 695.11
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.0315
    Episode_Reward/rotating_object: 135.3954
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.13s
                      Time elapsed: 00:40:32
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 46868 steps/s (collection: 1.999s, learning 0.098s)
             Mean action noise std: 3.21
          Mean value_function loss: 63.6709
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.8775
                       Mean reward: 726.38
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 1.0516
    Episode_Reward/rotating_object: 138.9530
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.10s
                      Time elapsed: 00:40:34
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 45713 steps/s (collection: 2.055s, learning 0.095s)
             Mean action noise std: 3.21
          Mean value_function loss: 84.1347
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.8890
                       Mean reward: 758.71
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 143.1235
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.15s
                      Time elapsed: 00:40:36
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 45762 steps/s (collection: 2.053s, learning 0.095s)
             Mean action noise std: 3.21
          Mean value_function loss: 81.5866
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.9034
                       Mean reward: 715.40
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 1.0330
    Episode_Reward/rotating_object: 136.1058
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.15s
                      Time elapsed: 00:40:38
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 46787 steps/s (collection: 2.006s, learning 0.095s)
             Mean action noise std: 3.22
          Mean value_function loss: 84.7100
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.9234
                       Mean reward: 687.29
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.0427
    Episode_Reward/rotating_object: 137.2664
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.10s
                      Time elapsed: 00:40:40
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 45420 steps/s (collection: 2.047s, learning 0.118s)
             Mean action noise std: 3.22
          Mean value_function loss: 82.9564
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.9436
                       Mean reward: 692.14
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.0496
    Episode_Reward/rotating_object: 138.3724
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.16s
                      Time elapsed: 00:40:42
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 45010 steps/s (collection: 2.062s, learning 0.122s)
             Mean action noise std: 3.22
          Mean value_function loss: 81.2753
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.9594
                       Mean reward: 682.18
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.0501
    Episode_Reward/rotating_object: 138.0978
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.18s
                      Time elapsed: 00:40:44
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 46595 steps/s (collection: 2.012s, learning 0.098s)
             Mean action noise std: 3.22
          Mean value_function loss: 78.8749
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.9791
                       Mean reward: 658.18
               Mean episode length: 223.03
    Episode_Reward/reaching_object: 1.0290
    Episode_Reward/rotating_object: 137.0276
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.11s
                      Time elapsed: 00:40:47
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 46009 steps/s (collection: 2.039s, learning 0.098s)
             Mean action noise std: 3.23
          Mean value_function loss: 69.7305
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.0009
                       Mean reward: 708.82
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.0491
    Episode_Reward/rotating_object: 139.3274
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.14s
                      Time elapsed: 00:40:49
                               ETA: 00:15:42

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 45962 steps/s (collection: 2.038s, learning 0.101s)
             Mean action noise std: 3.23
          Mean value_function loss: 76.0404
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.0129
                       Mean reward: 672.85
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.0287
    Episode_Reward/rotating_object: 135.8594
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.14s
                      Time elapsed: 00:40:51
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 46549 steps/s (collection: 2.011s, learning 0.101s)
             Mean action noise std: 3.23
          Mean value_function loss: 77.1984
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.0261
                       Mean reward: 645.12
               Mean episode length: 226.30
    Episode_Reward/reaching_object: 1.0402
    Episode_Reward/rotating_object: 138.4391
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.11s
                      Time elapsed: 00:40:53
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 45011 steps/s (collection: 2.090s, learning 0.093s)
             Mean action noise std: 3.23
          Mean value_function loss: 83.8044
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.0455
                       Mean reward: 660.07
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.0401
    Episode_Reward/rotating_object: 136.7770
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.18s
                      Time elapsed: 00:40:55
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 45936 steps/s (collection: 2.037s, learning 0.103s)
             Mean action noise std: 3.24
          Mean value_function loss: 78.0108
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.0636
                       Mean reward: 718.45
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.0511
    Episode_Reward/rotating_object: 141.6955
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.14s
                      Time elapsed: 00:40:57
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 46949 steps/s (collection: 1.986s, learning 0.108s)
             Mean action noise std: 3.24
          Mean value_function loss: 73.6526
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.0798
                       Mean reward: 688.45
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.0500
    Episode_Reward/rotating_object: 137.5075
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.09s
                      Time elapsed: 00:40:59
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 45822 steps/s (collection: 2.046s, learning 0.099s)
             Mean action noise std: 3.24
          Mean value_function loss: 91.6072
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.1009
                       Mean reward: 688.38
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.0287
    Episode_Reward/rotating_object: 135.1889
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.15s
                      Time elapsed: 00:41:01
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 45490 steps/s (collection: 2.062s, learning 0.099s)
             Mean action noise std: 3.25
          Mean value_function loss: 71.7258
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.1230
                       Mean reward: 651.13
               Mean episode length: 226.01
    Episode_Reward/reaching_object: 1.0307
    Episode_Reward/rotating_object: 134.0914
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.16s
                      Time elapsed: 00:41:04
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 44200 steps/s (collection: 2.126s, learning 0.098s)
             Mean action noise std: 3.25
          Mean value_function loss: 83.6345
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.1467
                       Mean reward: 703.05
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.0421
    Episode_Reward/rotating_object: 139.3447
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.22s
                      Time elapsed: 00:41:06
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 42772 steps/s (collection: 2.191s, learning 0.107s)
             Mean action noise std: 3.25
          Mean value_function loss: 84.1124
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.1661
                       Mean reward: 691.04
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.0485
    Episode_Reward/rotating_object: 139.0691
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.30s
                      Time elapsed: 00:41:08
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 45367 steps/s (collection: 2.054s, learning 0.113s)
             Mean action noise std: 3.25
          Mean value_function loss: 69.9969
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.1829
                       Mean reward: 699.54
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.0383
    Episode_Reward/rotating_object: 137.9026
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.17s
                      Time elapsed: 00:41:10
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 45607 steps/s (collection: 2.045s, learning 0.110s)
             Mean action noise std: 3.26
          Mean value_function loss: 79.3173
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.1947
                       Mean reward: 727.77
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.0397
    Episode_Reward/rotating_object: 138.0570
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.16s
                      Time elapsed: 00:41:12
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 46773 steps/s (collection: 1.994s, learning 0.108s)
             Mean action noise std: 3.26
          Mean value_function loss: 68.6452
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.2079
                       Mean reward: 704.65
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.0420
    Episode_Reward/rotating_object: 138.0189
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.10s
                      Time elapsed: 00:41:15
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 45675 steps/s (collection: 2.048s, learning 0.104s)
             Mean action noise std: 3.26
          Mean value_function loss: 63.8045
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.2202
                       Mean reward: 730.26
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 141.9996
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.15s
                      Time elapsed: 00:41:17
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 42205 steps/s (collection: 2.229s, learning 0.101s)
             Mean action noise std: 3.26
          Mean value_function loss: 68.6394
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.2286
                       Mean reward: 715.59
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 143.1114
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.33s
                      Time elapsed: 00:41:19
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 45001 steps/s (collection: 2.084s, learning 0.100s)
             Mean action noise std: 3.26
          Mean value_function loss: 71.2016
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.2355
                       Mean reward: 729.33
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.0600
    Episode_Reward/rotating_object: 139.3204
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.18s
                      Time elapsed: 00:41:21
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 44509 steps/s (collection: 2.112s, learning 0.097s)
             Mean action noise std: 3.27
          Mean value_function loss: 60.5407
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.2498
                       Mean reward: 684.70
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0505
    Episode_Reward/rotating_object: 137.2720
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.21s
                      Time elapsed: 00:41:23
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 45432 steps/s (collection: 2.071s, learning 0.093s)
             Mean action noise std: 3.27
          Mean value_function loss: 80.8744
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.2618
                       Mean reward: 694.40
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0644
    Episode_Reward/rotating_object: 137.9467
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.16s
                      Time elapsed: 00:41:26
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 44130 steps/s (collection: 2.125s, learning 0.102s)
             Mean action noise std: 3.27
          Mean value_function loss: 62.7892
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.2740
                       Mean reward: 716.06
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.0606
    Episode_Reward/rotating_object: 137.7084
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.23s
                      Time elapsed: 00:41:28
                               ETA: 00:15:00

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 45614 steps/s (collection: 2.055s, learning 0.100s)
             Mean action noise std: 3.27
          Mean value_function loss: 72.9832
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.2926
                       Mean reward: 700.93
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.0540
    Episode_Reward/rotating_object: 141.0721
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.16s
                      Time elapsed: 00:41:30
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 45869 steps/s (collection: 2.036s, learning 0.107s)
             Mean action noise std: 3.28
          Mean value_function loss: 71.0209
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.3141
                       Mean reward: 712.48
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.0517
    Episode_Reward/rotating_object: 135.4655
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.14s
                      Time elapsed: 00:41:32
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 44194 steps/s (collection: 2.119s, learning 0.106s)
             Mean action noise std: 3.28
          Mean value_function loss: 72.8637
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.3336
                       Mean reward: 716.28
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 1.0650
    Episode_Reward/rotating_object: 139.1770
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.22s
                      Time elapsed: 00:41:34
                               ETA: 00:14:54

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 45521 steps/s (collection: 2.055s, learning 0.105s)
             Mean action noise std: 3.28
          Mean value_function loss: 92.3898
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.3469
                       Mean reward: 680.71
               Mean episode length: 225.87
    Episode_Reward/reaching_object: 1.0248
    Episode_Reward/rotating_object: 135.0855
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.16s
                      Time elapsed: 00:41:37
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 45187 steps/s (collection: 2.072s, learning 0.103s)
             Mean action noise std: 3.28
          Mean value_function loss: 91.3187
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.3592
                       Mean reward: 686.92
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 1.0735
    Episode_Reward/rotating_object: 135.5977
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.18s
                      Time elapsed: 00:41:39
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 45397 steps/s (collection: 2.069s, learning 0.096s)
             Mean action noise std: 3.29
          Mean value_function loss: 75.6754
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.3743
                       Mean reward: 681.23
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 134.7238
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.17s
                      Time elapsed: 00:41:41
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 46413 steps/s (collection: 2.028s, learning 0.090s)
             Mean action noise std: 3.29
          Mean value_function loss: 82.5227
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.3869
                       Mean reward: 673.03
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.0509
    Episode_Reward/rotating_object: 138.0027
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.12s
                      Time elapsed: 00:41:43
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 46670 steps/s (collection: 2.010s, learning 0.096s)
             Mean action noise std: 3.29
          Mean value_function loss: 79.9360
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.3981
                       Mean reward: 716.98
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 143.4019
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.11s
                      Time elapsed: 00:41:45
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 46907 steps/s (collection: 2.001s, learning 0.095s)
             Mean action noise std: 3.29
          Mean value_function loss: 77.1023
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.4139
                       Mean reward: 685.72
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.0440
    Episode_Reward/rotating_object: 134.7723
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.10s
                      Time elapsed: 00:41:47
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 46443 steps/s (collection: 2.011s, learning 0.106s)
             Mean action noise std: 3.29
          Mean value_function loss: 78.6117
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.4281
                       Mean reward: 692.05
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.0486
    Episode_Reward/rotating_object: 138.5832
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.12s
                      Time elapsed: 00:41:49
                               ETA: 00:14:37

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 46445 steps/s (collection: 2.002s, learning 0.115s)
             Mean action noise std: 3.30
          Mean value_function loss: 70.3852
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.4422
                       Mean reward: 646.90
               Mean episode length: 224.71
    Episode_Reward/reaching_object: 1.0425
    Episode_Reward/rotating_object: 136.1344
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.12s
                      Time elapsed: 00:41:51
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 46080 steps/s (collection: 2.028s, learning 0.105s)
             Mean action noise std: 3.30
          Mean value_function loss: 69.4432
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.4598
                       Mean reward: 731.06
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.0665
    Episode_Reward/rotating_object: 138.9778
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.13s
                      Time elapsed: 00:41:54
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 46595 steps/s (collection: 2.007s, learning 0.103s)
             Mean action noise std: 3.30
          Mean value_function loss: 77.1778
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.4780
                       Mean reward: 703.08
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.0565
    Episode_Reward/rotating_object: 139.5934
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.11s
                      Time elapsed: 00:41:56
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 46870 steps/s (collection: 1.997s, learning 0.100s)
             Mean action noise std: 3.31
          Mean value_function loss: 67.2927
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.4982
                       Mean reward: 710.59
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 1.0602
    Episode_Reward/rotating_object: 135.9365
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.10s
                      Time elapsed: 00:41:58
                               ETA: 00:14:28

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 45861 steps/s (collection: 2.040s, learning 0.103s)
             Mean action noise std: 3.31
          Mean value_function loss: 70.1256
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.5100
                       Mean reward: 690.83
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 139.9048
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.14s
                      Time elapsed: 00:42:00
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 45684 steps/s (collection: 2.053s, learning 0.099s)
             Mean action noise std: 3.31
          Mean value_function loss: 63.8613
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.5191
                       Mean reward: 741.64
               Mean episode length: 243.23
    Episode_Reward/reaching_object: 1.0930
    Episode_Reward/rotating_object: 146.4101
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.15s
                      Time elapsed: 00:42:02
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 47155 steps/s (collection: 1.989s, learning 0.096s)
             Mean action noise std: 3.31
          Mean value_function loss: 81.2153
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.5310
                       Mean reward: 671.69
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.0496
    Episode_Reward/rotating_object: 135.2291
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.08s
                      Time elapsed: 00:42:04
                               ETA: 00:14:21

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 46282 steps/s (collection: 2.028s, learning 0.096s)
             Mean action noise std: 3.31
          Mean value_function loss: 81.2846
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.5439
                       Mean reward: 700.46
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 140.5171
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.12s
                      Time elapsed: 00:42:06
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 46941 steps/s (collection: 1.994s, learning 0.100s)
             Mean action noise std: 3.32
          Mean value_function loss: 69.5426
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.5600
                       Mean reward: 683.92
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.0466
    Episode_Reward/rotating_object: 135.5173
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.09s
                      Time elapsed: 00:42:08
                               ETA: 00:14:17

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 46165 steps/s (collection: 2.029s, learning 0.101s)
             Mean action noise std: 3.32
          Mean value_function loss: 62.6733
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.5775
                       Mean reward: 707.13
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 139.5282
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.13s
                      Time elapsed: 00:42:10
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 44129 steps/s (collection: 2.123s, learning 0.105s)
             Mean action noise std: 3.32
          Mean value_function loss: 81.0333
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.5878
                       Mean reward: 710.91
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.0546
    Episode_Reward/rotating_object: 135.6693
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.23s
                      Time elapsed: 00:42:13
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 44092 steps/s (collection: 2.116s, learning 0.113s)
             Mean action noise std: 3.32
          Mean value_function loss: 60.2108
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.5980
                       Mean reward: 749.40
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 1.0723
    Episode_Reward/rotating_object: 143.8200
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.23s
                      Time elapsed: 00:42:15
                               ETA: 00:14:10

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 44484 steps/s (collection: 2.111s, learning 0.099s)
             Mean action noise std: 3.33
          Mean value_function loss: 74.6148
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.6128
                       Mean reward: 701.20
               Mean episode length: 245.06
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 137.9218
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.21s
                      Time elapsed: 00:42:17
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 46737 steps/s (collection: 2.005s, learning 0.099s)
             Mean action noise std: 3.33
          Mean value_function loss: 77.3717
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.6317
                       Mean reward: 689.04
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.0474
    Episode_Reward/rotating_object: 137.7084
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.10s
                      Time elapsed: 00:42:19
                               ETA: 00:14:05

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 46795 steps/s (collection: 1.997s, learning 0.104s)
             Mean action noise std: 3.33
          Mean value_function loss: 67.4930
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.6536
                       Mean reward: 688.93
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 139.6282
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.10s
                      Time elapsed: 00:42:21
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 45729 steps/s (collection: 2.046s, learning 0.103s)
             Mean action noise std: 3.33
          Mean value_function loss: 77.6840
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 56.6671
                       Mean reward: 704.29
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.0386
    Episode_Reward/rotating_object: 137.7765
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.15s
                      Time elapsed: 00:42:24
                               ETA: 00:14:01

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 47058 steps/s (collection: 1.988s, learning 0.101s)
             Mean action noise std: 3.33
          Mean value_function loss: 87.3411
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.6729
                       Mean reward: 671.02
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 1.0445
    Episode_Reward/rotating_object: 137.5742
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.09s
                      Time elapsed: 00:42:26
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 44692 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 3.34
          Mean value_function loss: 58.3933
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.6879
                       Mean reward: 728.00
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 1.0693
    Episode_Reward/rotating_object: 143.0261
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.20s
                      Time elapsed: 00:42:28
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 46599 steps/s (collection: 2.008s, learning 0.102s)
             Mean action noise std: 3.34
          Mean value_function loss: 86.4188
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.7059
                       Mean reward: 715.21
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.0554
    Episode_Reward/rotating_object: 138.1152
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.11s
                      Time elapsed: 00:42:30
                               ETA: 00:13:54

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 35078 steps/s (collection: 2.442s, learning 0.361s)
             Mean action noise std: 3.34
          Mean value_function loss: 84.6372
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.7219
                       Mean reward: 657.97
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 134.3991
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.80s
                      Time elapsed: 00:42:33
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 16961 steps/s (collection: 5.336s, learning 0.460s)
             Mean action noise std: 3.34
          Mean value_function loss: 67.5668
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.7387
                       Mean reward: 729.05
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.0309
    Episode_Reward/rotating_object: 134.7873
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0503
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 5.80s
                      Time elapsed: 00:42:38
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 16919 steps/s (collection: 5.369s, learning 0.442s)
             Mean action noise std: 3.35
          Mean value_function loss: 70.8615
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 56.7547
                       Mean reward: 670.90
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.0488
    Episode_Reward/rotating_object: 135.5326
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 5.81s
                      Time elapsed: 00:42:44
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 17104 steps/s (collection: 5.388s, learning 0.359s)
             Mean action noise std: 3.35
          Mean value_function loss: 82.9430
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.7659
                       Mean reward: 688.47
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 139.7375
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 5.75s
                      Time elapsed: 00:42:50
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 15819 steps/s (collection: 5.753s, learning 0.461s)
             Mean action noise std: 3.35
          Mean value_function loss: 84.2926
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.7777
                       Mean reward: 683.25
               Mean episode length: 231.91
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 141.3573
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 6.21s
                      Time elapsed: 00:42:56
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 17012 steps/s (collection: 5.471s, learning 0.308s)
             Mean action noise std: 3.35
          Mean value_function loss: 93.2266
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.7950
                       Mean reward: 648.88
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.0308
    Episode_Reward/rotating_object: 133.8512
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 5.78s
                      Time elapsed: 00:43:02
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 16924 steps/s (collection: 5.564s, learning 0.244s)
             Mean action noise std: 3.36
          Mean value_function loss: 78.2779
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.8156
                       Mean reward: 674.30
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 1.0384
    Episode_Reward/rotating_object: 135.3705
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 5.81s
                      Time elapsed: 00:43:08
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 15544 steps/s (collection: 5.811s, learning 0.513s)
             Mean action noise std: 3.36
          Mean value_function loss: 65.1564
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.8344
                       Mean reward: 675.63
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.0581
    Episode_Reward/rotating_object: 137.8188
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 6.32s
                      Time elapsed: 00:43:14
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 15181 steps/s (collection: 6.017s, learning 0.458s)
             Mean action noise std: 3.36
          Mean value_function loss: 66.6891
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.8480
                       Mean reward: 702.27
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 138.8622
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 6.48s
                      Time elapsed: 00:43:21
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 14982 steps/s (collection: 6.069s, learning 0.492s)
             Mean action noise std: 3.36
          Mean value_function loss: 76.4003
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.8599
                       Mean reward: 678.56
               Mean episode length: 222.49
    Episode_Reward/reaching_object: 1.0494
    Episode_Reward/rotating_object: 140.5230
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 6.56s
                      Time elapsed: 00:43:27
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 14367 steps/s (collection: 6.467s, learning 0.375s)
             Mean action noise std: 3.36
          Mean value_function loss: 86.2146
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.8718
                       Mean reward: 696.39
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.0505
    Episode_Reward/rotating_object: 137.2941
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 6.84s
                      Time elapsed: 00:43:34
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 15074 steps/s (collection: 6.151s, learning 0.370s)
             Mean action noise std: 3.37
          Mean value_function loss: 77.1083
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.8863
                       Mean reward: 668.11
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.0207
    Episode_Reward/rotating_object: 135.4010
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 6.52s
                      Time elapsed: 00:43:41
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 14972 steps/s (collection: 6.073s, learning 0.492s)
             Mean action noise std: 3.37
          Mean value_function loss: 75.0334
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.9012
                       Mean reward: 730.90
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 1.0544
    Episode_Reward/rotating_object: 141.2373
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 6.57s
                      Time elapsed: 00:43:47
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 16314 steps/s (collection: 5.464s, learning 0.562s)
             Mean action noise std: 3.37
          Mean value_function loss: 80.0541
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.9134
                       Mean reward: 643.65
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 1.0365
    Episode_Reward/rotating_object: 134.5240
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 6.03s
                      Time elapsed: 00:43:53
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 16112 steps/s (collection: 5.686s, learning 0.415s)
             Mean action noise std: 3.37
          Mean value_function loss: 81.9309
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.9321
                       Mean reward: 697.69
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.0418
    Episode_Reward/rotating_object: 139.3722
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 6.10s
                      Time elapsed: 00:43:59
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 15329 steps/s (collection: 5.976s, learning 0.437s)
             Mean action noise std: 3.38
          Mean value_function loss: 79.7833
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.9510
                       Mean reward: 734.91
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 138.1930
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 6.41s
                      Time elapsed: 00:44:06
                               ETA: 00:13:36

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 16751 steps/s (collection: 5.418s, learning 0.450s)
             Mean action noise std: 3.38
          Mean value_function loss: 76.1885
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.9714
                       Mean reward: 711.86
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.0295
    Episode_Reward/rotating_object: 134.6835
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 5.87s
                      Time elapsed: 00:44:12
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 16080 steps/s (collection: 5.658s, learning 0.456s)
             Mean action noise std: 3.38
          Mean value_function loss: 79.1005
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.9881
                       Mean reward: 627.50
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 1.0196
    Episode_Reward/rotating_object: 133.7191
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 6.11s
                      Time elapsed: 00:44:18
                               ETA: 00:13:34

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 16203 steps/s (collection: 5.645s, learning 0.422s)
             Mean action noise std: 3.39
          Mean value_function loss: 64.4244
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.0080
                       Mean reward: 691.61
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.0489
    Episode_Reward/rotating_object: 138.8801
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 6.07s
                      Time elapsed: 00:44:24
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 17184 steps/s (collection: 5.325s, learning 0.395s)
             Mean action noise std: 3.39
          Mean value_function loss: 60.3081
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.0185
                       Mean reward: 694.04
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 138.7252
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 5.72s
                      Time elapsed: 00:44:29
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 17052 steps/s (collection: 5.276s, learning 0.488s)
             Mean action noise std: 3.39
          Mean value_function loss: 71.2459
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.0238
                       Mean reward: 724.72
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 1.0403
    Episode_Reward/rotating_object: 135.5721
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 5.76s
                      Time elapsed: 00:44:35
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 17110 steps/s (collection: 5.273s, learning 0.473s)
             Mean action noise std: 3.39
          Mean value_function loss: 65.2038
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.0374
                       Mean reward: 703.42
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 141.4402
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 5.75s
                      Time elapsed: 00:44:41
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 16249 steps/s (collection: 5.733s, learning 0.316s)
             Mean action noise std: 3.39
          Mean value_function loss: 69.8545
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.0535
                       Mean reward: 704.44
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.0257
    Episode_Reward/rotating_object: 133.4294
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 6.05s
                      Time elapsed: 00:44:47
                               ETA: 00:13:28

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 19578 steps/s (collection: 4.608s, learning 0.413s)
             Mean action noise std: 3.40
          Mean value_function loss: 78.3002
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.0662
                       Mean reward: 696.61
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 1.0268
    Episode_Reward/rotating_object: 137.8795
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 5.02s
                      Time elapsed: 00:44:52
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 16125 steps/s (collection: 5.672s, learning 0.424s)
             Mean action noise std: 3.40
          Mean value_function loss: 72.6895
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.0883
                       Mean reward: 736.95
               Mean episode length: 242.07
    Episode_Reward/reaching_object: 1.0483
    Episode_Reward/rotating_object: 141.2497
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 6.10s
                      Time elapsed: 00:44:58
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 15312 steps/s (collection: 5.879s, learning 0.541s)
             Mean action noise std: 3.40
          Mean value_function loss: 73.5804
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 57.1090
                       Mean reward: 647.97
               Mean episode length: 221.40
    Episode_Reward/reaching_object: 1.0337
    Episode_Reward/rotating_object: 138.3125
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 6.42s
                      Time elapsed: 00:45:05
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 17378 steps/s (collection: 5.196s, learning 0.461s)
             Mean action noise std: 3.40
          Mean value_function loss: 78.1936
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.1197
                       Mean reward: 683.41
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 1.0385
    Episode_Reward/rotating_object: 140.6065
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 5.66s
                      Time elapsed: 00:45:10
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 16732 steps/s (collection: 5.596s, learning 0.279s)
             Mean action noise std: 3.41
          Mean value_function loss: 70.5916
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.1349
                       Mean reward: 758.36
               Mean episode length: 245.00
    Episode_Reward/reaching_object: 1.0411
    Episode_Reward/rotating_object: 142.0968
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 5.88s
                      Time elapsed: 00:45:16
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 17730 steps/s (collection: 5.102s, learning 0.442s)
             Mean action noise std: 3.41
          Mean value_function loss: 79.4750
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.1505
                       Mean reward: 690.06
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 1.0178
    Episode_Reward/rotating_object: 136.3606
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 5.54s
                      Time elapsed: 00:45:22
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 15524 steps/s (collection: 5.807s, learning 0.525s)
             Mean action noise std: 3.41
          Mean value_function loss: 75.3415
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.1638
                       Mean reward: 742.64
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 145.8175
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 6.33s
                      Time elapsed: 00:45:28
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 16162 steps/s (collection: 5.613s, learning 0.469s)
             Mean action noise std: 3.41
          Mean value_function loss: 72.5907
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.1810
                       Mean reward: 676.34
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.0479
    Episode_Reward/rotating_object: 140.5365
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 6.08s
                      Time elapsed: 00:45:34
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 17941 steps/s (collection: 4.997s, learning 0.482s)
             Mean action noise std: 3.42
          Mean value_function loss: 68.8829
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.1967
                       Mean reward: 698.16
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.0343
    Episode_Reward/rotating_object: 140.4909
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 5.48s
                      Time elapsed: 00:45:40
                               ETA: 00:13:16

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 15623 steps/s (collection: 5.840s, learning 0.452s)
             Mean action noise std: 3.42
          Mean value_function loss: 66.0051
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.2135
                       Mean reward: 667.47
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.0093
    Episode_Reward/rotating_object: 132.2880
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 6.29s
                      Time elapsed: 00:45:46
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 18636 steps/s (collection: 4.915s, learning 0.360s)
             Mean action noise std: 3.42
          Mean value_function loss: 65.4323
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.2281
                       Mean reward: 690.07
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.0502
    Episode_Reward/rotating_object: 140.5166
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 5.27s
                      Time elapsed: 00:45:51
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 17116 steps/s (collection: 5.258s, learning 0.485s)
             Mean action noise std: 3.42
          Mean value_function loss: 76.9894
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.2440
                       Mean reward: 694.42
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 1.0449
    Episode_Reward/rotating_object: 139.5992
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 5.74s
                      Time elapsed: 00:45:57
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 17303 steps/s (collection: 5.218s, learning 0.463s)
             Mean action noise std: 3.43
          Mean value_function loss: 78.3497
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.2627
                       Mean reward: 647.40
               Mean episode length: 226.53
    Episode_Reward/reaching_object: 1.0273
    Episode_Reward/rotating_object: 135.4060
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 5.68s
                      Time elapsed: 00:46:03
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 16530 steps/s (collection: 5.522s, learning 0.425s)
             Mean action noise std: 3.43
          Mean value_function loss: 69.5348
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.2820
                       Mean reward: 728.93
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.0660
    Episode_Reward/rotating_object: 143.8119
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 5.95s
                      Time elapsed: 00:46:08
                               ETA: 00:13:09

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 17795 steps/s (collection: 5.212s, learning 0.313s)
             Mean action noise std: 3.43
          Mean value_function loss: 80.8780
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.2978
                       Mean reward: 691.65
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.0363
    Episode_Reward/rotating_object: 137.9236
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 5.52s
                      Time elapsed: 00:46:14
                               ETA: 00:13:07

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 19657 steps/s (collection: 4.705s, learning 0.296s)
             Mean action noise std: 3.44
          Mean value_function loss: 64.3755
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.3104
                       Mean reward: 725.64
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 143.7725
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 5.00s
                      Time elapsed: 00:46:19
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 18182 steps/s (collection: 5.157s, learning 0.250s)
             Mean action noise std: 3.44
          Mean value_function loss: 69.0172
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.3280
                       Mean reward: 712.73
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 1.0492
    Episode_Reward/rotating_object: 142.0662
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 5.41s
                      Time elapsed: 00:46:24
                               ETA: 00:13:04

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 16008 steps/s (collection: 5.687s, learning 0.454s)
             Mean action noise std: 3.44
          Mean value_function loss: 75.0360
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.3396
                       Mean reward: 692.96
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.0240
    Episode_Reward/rotating_object: 138.1092
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 6.14s
                      Time elapsed: 00:46:31
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 15392 steps/s (collection: 5.957s, learning 0.429s)
             Mean action noise std: 3.44
          Mean value_function loss: 72.2312
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.3546
                       Mean reward: 725.04
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 139.7700
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 6.39s
                      Time elapsed: 00:46:37
                               ETA: 00:13:02

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 15023 steps/s (collection: 6.052s, learning 0.492s)
             Mean action noise std: 3.44
          Mean value_function loss: 82.8015
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.3689
                       Mean reward: 694.04
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.0343
    Episode_Reward/rotating_object: 138.5102
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0498
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 6.54s
                      Time elapsed: 00:46:43
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 16856 steps/s (collection: 5.346s, learning 0.485s)
             Mean action noise std: 3.45
          Mean value_function loss: 69.5031
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.3849
                       Mean reward: 721.61
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 1.0397
    Episode_Reward/rotating_object: 139.3899
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 5.83s
                      Time elapsed: 00:46:49
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 18411 steps/s (collection: 4.875s, learning 0.464s)
             Mean action noise std: 3.45
          Mean value_function loss: 64.3620
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.3989
                       Mean reward: 719.99
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.0404
    Episode_Reward/rotating_object: 139.9042
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 5.34s
                      Time elapsed: 00:46:55
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 16498 steps/s (collection: 5.362s, learning 0.596s)
             Mean action noise std: 3.45
          Mean value_function loss: 83.2949
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.4098
                       Mean reward: 721.63
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0276
    Episode_Reward/rotating_object: 138.9714
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 5.96s
                      Time elapsed: 00:47:01
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 15564 steps/s (collection: 5.918s, learning 0.398s)
             Mean action noise std: 3.45
          Mean value_function loss: 83.3127
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.4237
                       Mean reward: 702.72
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 1.0324
    Episode_Reward/rotating_object: 138.7513
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 6.32s
                      Time elapsed: 00:47:07
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 16664 steps/s (collection: 5.513s, learning 0.386s)
             Mean action noise std: 3.46
          Mean value_function loss: 79.9449
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.4385
                       Mean reward: 714.08
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 1.0329
    Episode_Reward/rotating_object: 139.5698
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 5.90s
                      Time elapsed: 00:47:13
                               ETA: 00:12:53

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 16199 steps/s (collection: 5.617s, learning 0.451s)
             Mean action noise std: 3.46
          Mean value_function loss: 80.4181
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.4529
                       Mean reward: 678.38
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.0293
    Episode_Reward/rotating_object: 137.1070
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 6.07s
                      Time elapsed: 00:47:19
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 14743 steps/s (collection: 6.234s, learning 0.434s)
             Mean action noise std: 3.46
          Mean value_function loss: 86.3772
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.4689
                       Mean reward: 706.70
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.0148
    Episode_Reward/rotating_object: 138.0716
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 6.67s
                      Time elapsed: 00:47:26
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 15205 steps/s (collection: 5.998s, learning 0.467s)
             Mean action noise std: 3.46
          Mean value_function loss: 76.0233
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.4900
                       Mean reward: 707.39
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.0393
    Episode_Reward/rotating_object: 140.3131
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 6.46s
                      Time elapsed: 00:47:32
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 15094 steps/s (collection: 6.091s, learning 0.422s)
             Mean action noise std: 3.47
          Mean value_function loss: 80.6028
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.5077
                       Mean reward: 628.96
               Mean episode length: 222.30
    Episode_Reward/reaching_object: 1.0303
    Episode_Reward/rotating_object: 136.8645
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 6.51s
                      Time elapsed: 00:47:39
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 16074 steps/s (collection: 5.843s, learning 0.273s)
             Mean action noise std: 3.47
          Mean value_function loss: 64.4732
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.5255
                       Mean reward: 674.74
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.0433
    Episode_Reward/rotating_object: 137.6111
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 6.12s
                      Time elapsed: 00:47:45
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 16380 steps/s (collection: 5.574s, learning 0.427s)
             Mean action noise std: 3.47
          Mean value_function loss: 79.8428
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.5429
                       Mean reward: 683.24
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.0373
    Episode_Reward/rotating_object: 138.7669
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 6.00s
                      Time elapsed: 00:47:51
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 16264 steps/s (collection: 5.573s, learning 0.471s)
             Mean action noise std: 3.47
          Mean value_function loss: 65.1913
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.5531
                       Mean reward: 728.61
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.0373
    Episode_Reward/rotating_object: 139.7203
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 6.04s
                      Time elapsed: 00:47:57
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 17191 steps/s (collection: 5.269s, learning 0.449s)
             Mean action noise std: 3.48
          Mean value_function loss: 61.0638
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.5651
                       Mean reward: 726.95
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 1.0435
    Episode_Reward/rotating_object: 140.0491
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 5.72s
                      Time elapsed: 00:48:02
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 16144 steps/s (collection: 5.597s, learning 0.492s)
             Mean action noise std: 3.48
          Mean value_function loss: 63.2652
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.5778
                       Mean reward: 712.49
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 142.6027
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 6.09s
                      Time elapsed: 00:48:08
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 17030 steps/s (collection: 5.326s, learning 0.447s)
             Mean action noise std: 3.48
          Mean value_function loss: 69.1126
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.5898
                       Mean reward: 689.11
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.0579
    Episode_Reward/rotating_object: 140.7672
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 5.77s
                      Time elapsed: 00:48:14
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 18187 steps/s (collection: 4.964s, learning 0.441s)
             Mean action noise std: 3.48
          Mean value_function loss: 70.7247
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.5996
                       Mean reward: 684.23
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.0328
    Episode_Reward/rotating_object: 135.1318
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 5.41s
                      Time elapsed: 00:48:20
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 15682 steps/s (collection: 5.824s, learning 0.444s)
             Mean action noise std: 3.48
          Mean value_function loss: 67.7823
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.6093
                       Mean reward: 708.96
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.0491
    Episode_Reward/rotating_object: 138.9768
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 6.27s
                      Time elapsed: 00:48:26
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 16326 steps/s (collection: 5.572s, learning 0.449s)
             Mean action noise std: 3.49
          Mean value_function loss: 67.4675
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.6200
                       Mean reward: 709.07
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.0419
    Episode_Reward/rotating_object: 138.0627
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 6.02s
                      Time elapsed: 00:48:32
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 16655 steps/s (collection: 5.477s, learning 0.425s)
             Mean action noise std: 3.49
          Mean value_function loss: 77.0130
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.6353
                       Mean reward: 682.19
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 144.6397
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 5.90s
                      Time elapsed: 00:48:38
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 17787 steps/s (collection: 5.054s, learning 0.473s)
             Mean action noise std: 3.49
          Mean value_function loss: 63.0537
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.6564
                       Mean reward: 676.42
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.0387
    Episode_Reward/rotating_object: 136.0758
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 5.53s
                      Time elapsed: 00:48:43
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 18496 steps/s (collection: 5.086s, learning 0.229s)
             Mean action noise std: 3.49
          Mean value_function loss: 80.4111
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.6667
                       Mean reward: 665.45
               Mean episode length: 221.78
    Episode_Reward/reaching_object: 1.0189
    Episode_Reward/rotating_object: 137.5361
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 5.31s
                      Time elapsed: 00:48:49
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 17794 steps/s (collection: 4.994s, learning 0.531s)
             Mean action noise std: 3.50
          Mean value_function loss: 59.8032
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.6770
                       Mean reward: 730.05
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 1.0414
    Episode_Reward/rotating_object: 139.3487
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 5.52s
                      Time elapsed: 00:48:54
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 16546 steps/s (collection: 5.537s, learning 0.404s)
             Mean action noise std: 3.50
          Mean value_function loss: 69.8008
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.6908
                       Mean reward: 685.38
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 1.0519
    Episode_Reward/rotating_object: 142.0518
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 5.94s
                      Time elapsed: 00:49:00
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 17114 steps/s (collection: 5.241s, learning 0.503s)
             Mean action noise std: 3.50
          Mean value_function loss: 73.7869
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.7050
                       Mean reward: 725.35
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 139.0529
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 5.74s
                      Time elapsed: 00:49:06
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 16295 steps/s (collection: 5.550s, learning 0.483s)
             Mean action noise std: 3.50
          Mean value_function loss: 71.9249
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.7157
                       Mean reward: 713.17
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 1.0180
    Episode_Reward/rotating_object: 137.0441
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 6.03s
                      Time elapsed: 00:49:12
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 16522 steps/s (collection: 5.584s, learning 0.366s)
             Mean action noise std: 3.50
          Mean value_function loss: 63.2842
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.7269
                       Mean reward: 740.19
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.0501
    Episode_Reward/rotating_object: 145.7824
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 5.95s
                      Time elapsed: 00:49:18
                               ETA: 00:12:22

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 15311 steps/s (collection: 5.968s, learning 0.452s)
             Mean action noise std: 3.51
          Mean value_function loss: 60.9128
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.7360
                       Mean reward: 749.04
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.0613
    Episode_Reward/rotating_object: 144.4755
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 6.42s
                      Time elapsed: 00:49:24
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 16289 steps/s (collection: 5.600s, learning 0.435s)
             Mean action noise std: 3.51
          Mean value_function loss: 62.6225
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.7446
                       Mean reward: 700.78
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.0329
    Episode_Reward/rotating_object: 140.3863
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 6.03s
                      Time elapsed: 00:49:30
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 15371 steps/s (collection: 5.828s, learning 0.567s)
             Mean action noise std: 3.51
          Mean value_function loss: 73.3649
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.7577
                       Mean reward: 671.94
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.0151
    Episode_Reward/rotating_object: 136.1946
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 6.40s
                      Time elapsed: 00:49:37
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 15587 steps/s (collection: 5.842s, learning 0.464s)
             Mean action noise std: 3.51
          Mean value_function loss: 70.8625
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.7725
                       Mean reward: 735.70
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 140.9657
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 6.31s
                      Time elapsed: 00:49:43
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 17700 steps/s (collection: 5.212s, learning 0.342s)
             Mean action noise std: 3.51
          Mean value_function loss: 92.2407
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.7822
                       Mean reward: 665.29
               Mean episode length: 225.66
    Episode_Reward/reaching_object: 1.0186
    Episode_Reward/rotating_object: 136.8056
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 5.55s
                      Time elapsed: 00:49:49
                               ETA: 00:12:14

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 16227 steps/s (collection: 5.691s, learning 0.367s)
             Mean action noise std: 3.51
          Mean value_function loss: 70.1390
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.7897
                       Mean reward: 672.02
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 1.0293
    Episode_Reward/rotating_object: 137.5987
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 6.06s
                      Time elapsed: 00:49:55
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 15821 steps/s (collection: 5.771s, learning 0.442s)
             Mean action noise std: 3.52
          Mean value_function loss: 65.1387
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.8030
                       Mean reward: 689.68
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.0406
    Episode_Reward/rotating_object: 138.9517
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 6.21s
                      Time elapsed: 00:50:01
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 17662 steps/s (collection: 5.149s, learning 0.416s)
             Mean action noise std: 3.52
          Mean value_function loss: 73.1379
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.8181
                       Mean reward: 724.50
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.0319
    Episode_Reward/rotating_object: 139.0539
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 5.57s
                      Time elapsed: 00:50:06
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 16455 steps/s (collection: 5.498s, learning 0.476s)
             Mean action noise std: 3.52
          Mean value_function loss: 74.5400
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.8313
                       Mean reward: 695.34
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 141.2744
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 5.97s
                      Time elapsed: 00:50:12
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 15145 steps/s (collection: 6.033s, learning 0.458s)
             Mean action noise std: 3.53
          Mean value_function loss: 69.4092
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.8463
                       Mean reward: 686.43
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.0428
    Episode_Reward/rotating_object: 140.7563
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 6.49s
                      Time elapsed: 00:50:19
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 17672 steps/s (collection: 5.209s, learning 0.354s)
             Mean action noise std: 3.53
          Mean value_function loss: 60.8754
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.8698
                       Mean reward: 699.13
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.0256
    Episode_Reward/rotating_object: 138.9519
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 5.56s
                      Time elapsed: 00:50:24
                               ETA: 00:12:04

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 19185 steps/s (collection: 4.730s, learning 0.394s)
             Mean action noise std: 3.53
          Mean value_function loss: 56.7079
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.8817
                       Mean reward: 717.44
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.0689
    Episode_Reward/rotating_object: 142.6555
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 5.12s
                      Time elapsed: 00:50:30
                               ETA: 00:12:02

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 18680 steps/s (collection: 4.913s, learning 0.349s)
             Mean action noise std: 3.53
          Mean value_function loss: 67.8806
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.8927
                       Mean reward: 698.64
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 1.0290
    Episode_Reward/rotating_object: 140.1063
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0493
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 5.26s
                      Time elapsed: 00:50:35
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 18403 steps/s (collection: 4.949s, learning 0.392s)
             Mean action noise std: 3.54
          Mean value_function loss: 76.7980
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.9083
                       Mean reward: 656.09
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.0350
    Episode_Reward/rotating_object: 137.5734
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 5.34s
                      Time elapsed: 00:50:40
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 19340 steps/s (collection: 4.769s, learning 0.314s)
             Mean action noise std: 3.54
          Mean value_function loss: 76.8529
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.9274
                       Mean reward: 712.53
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.0300
    Episode_Reward/rotating_object: 139.5504
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 5.08s
                      Time elapsed: 00:50:45
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 18610 steps/s (collection: 4.950s, learning 0.332s)
             Mean action noise std: 3.54
          Mean value_function loss: 68.7890
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.9425
                       Mean reward: 714.84
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 1.0134
    Episode_Reward/rotating_object: 135.7519
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 5.28s
                      Time elapsed: 00:50:51
                               ETA: 00:11:55

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 17143 steps/s (collection: 5.310s, learning 0.424s)
             Mean action noise std: 3.54
          Mean value_function loss: 50.0438
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.9579
                       Mean reward: 734.31
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.0407
    Episode_Reward/rotating_object: 142.3115
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 5.73s
                      Time elapsed: 00:50:56
                               ETA: 00:11:53

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 18701 steps/s (collection: 4.952s, learning 0.305s)
             Mean action noise std: 3.55
          Mean value_function loss: 63.4403
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.9712
                       Mean reward: 727.20
               Mean episode length: 244.66
    Episode_Reward/reaching_object: 1.0496
    Episode_Reward/rotating_object: 145.2684
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 5.26s
                      Time elapsed: 00:51:02
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 21128 steps/s (collection: 4.352s, learning 0.301s)
             Mean action noise std: 3.55
          Mean value_function loss: 65.9445
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 57.9831
                       Mean reward: 701.14
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.0350
    Episode_Reward/rotating_object: 141.3644
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 4.65s
                      Time elapsed: 00:51:06
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 17829 steps/s (collection: 5.114s, learning 0.400s)
             Mean action noise std: 3.55
          Mean value_function loss: 64.1014
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.9877
                       Mean reward: 695.34
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.0345
    Episode_Reward/rotating_object: 139.3530
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 5.51s
                      Time elapsed: 00:51:12
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 16581 steps/s (collection: 5.549s, learning 0.380s)
             Mean action noise std: 3.55
          Mean value_function loss: 85.6404
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.9949
                       Mean reward: 675.84
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.0158
    Episode_Reward/rotating_object: 139.1996
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 5.93s
                      Time elapsed: 00:51:18
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 18443 steps/s (collection: 4.990s, learning 0.340s)
             Mean action noise std: 3.55
          Mean value_function loss: 66.3137
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.0085
                       Mean reward: 722.04
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.0153
    Episode_Reward/rotating_object: 142.5046
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 5.33s
                      Time elapsed: 00:51:23
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 17419 steps/s (collection: 5.193s, learning 0.450s)
             Mean action noise std: 3.55
          Mean value_function loss: 70.2594
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.0215
                       Mean reward: 729.10
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 1.0374
    Episode_Reward/rotating_object: 141.7233
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 5.64s
                      Time elapsed: 00:51:29
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 16849 steps/s (collection: 5.432s, learning 0.403s)
             Mean action noise std: 3.56
          Mean value_function loss: 85.9941
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.0315
                       Mean reward: 650.56
               Mean episode length: 228.27
    Episode_Reward/reaching_object: 0.9980
    Episode_Reward/rotating_object: 137.0605
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 5.83s
                      Time elapsed: 00:51:34
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 16943 steps/s (collection: 5.485s, learning 0.317s)
             Mean action noise std: 3.56
          Mean value_function loss: 52.3175
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.0412
                       Mean reward: 717.66
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 1.0282
    Episode_Reward/rotating_object: 142.4165
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 5.80s
                      Time elapsed: 00:51:40
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 18890 steps/s (collection: 4.870s, learning 0.334s)
             Mean action noise std: 3.56
          Mean value_function loss: 71.9856
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.0563
                       Mean reward: 728.41
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.0253
    Episode_Reward/rotating_object: 139.9388
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 5.20s
                      Time elapsed: 00:51:45
                               ETA: 00:11:36

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 17702 steps/s (collection: 5.215s, learning 0.339s)
             Mean action noise std: 3.56
          Mean value_function loss: 70.2235
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.0743
                       Mean reward: 727.63
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 1.0167
    Episode_Reward/rotating_object: 140.6778
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0504
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 5.55s
                      Time elapsed: 00:51:51
                               ETA: 00:11:34

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 17540 steps/s (collection: 5.299s, learning 0.305s)
             Mean action noise std: 3.57
          Mean value_function loss: 74.9668
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 58.0873
                       Mean reward: 652.86
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 0.9984
    Episode_Reward/rotating_object: 137.9470
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 5.60s
                      Time elapsed: 00:51:57
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 19162 steps/s (collection: 4.776s, learning 0.354s)
             Mean action noise std: 3.57
          Mean value_function loss: 62.4970
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.1011
                       Mean reward: 678.11
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.0284
    Episode_Reward/rotating_object: 141.0843
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 5.13s
                      Time elapsed: 00:52:02
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 18323 steps/s (collection: 4.980s, learning 0.385s)
             Mean action noise std: 3.57
          Mean value_function loss: 61.2789
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.1125
                       Mean reward: 695.93
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.0323
    Episode_Reward/rotating_object: 138.2547
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 5.37s
                      Time elapsed: 00:52:07
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 17741 steps/s (collection: 5.238s, learning 0.303s)
             Mean action noise std: 3.57
          Mean value_function loss: 78.5912
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.1246
                       Mean reward: 731.12
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 1.0289
    Episode_Reward/rotating_object: 140.3704
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 5.54s
                      Time elapsed: 00:52:13
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 23980 steps/s (collection: 3.815s, learning 0.284s)
             Mean action noise std: 3.58
          Mean value_function loss: 78.1721
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.1392
                       Mean reward: 712.63
               Mean episode length: 236.63
    Episode_Reward/reaching_object: 1.0216
    Episode_Reward/rotating_object: 140.8372
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 4.10s
                      Time elapsed: 00:52:17
                               ETA: 00:11:24

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 25696 steps/s (collection: 3.534s, learning 0.291s)
             Mean action noise std: 3.58
          Mean value_function loss: 63.0933
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.1515
                       Mean reward: 728.29
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.0222
    Episode_Reward/rotating_object: 142.3205
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 3.83s
                      Time elapsed: 00:52:21
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 25539 steps/s (collection: 3.595s, learning 0.254s)
             Mean action noise std: 3.58
          Mean value_function loss: 69.6875
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 58.1636
                       Mean reward: 717.95
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 1.0119
    Episode_Reward/rotating_object: 137.0266
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 3.85s
                      Time elapsed: 00:52:24
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 24601 steps/s (collection: 3.702s, learning 0.294s)
             Mean action noise std: 3.58
          Mean value_function loss: 70.0311
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.1733
                       Mean reward: 687.77
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.0237
    Episode_Reward/rotating_object: 143.3417
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 4.00s
                      Time elapsed: 00:52:28
                               ETA: 00:11:18

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 21251 steps/s (collection: 4.286s, learning 0.340s)
             Mean action noise std: 3.58
          Mean value_function loss: 86.2005
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.1903
                       Mean reward: 717.93
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.0005
    Episode_Reward/rotating_object: 136.9878
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 4.63s
                      Time elapsed: 00:52:33
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 18871 steps/s (collection: 4.884s, learning 0.325s)
             Mean action noise std: 3.59
          Mean value_function loss: 64.3068
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.2051
                       Mean reward: 718.27
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.0219
    Episode_Reward/rotating_object: 142.9829
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 5.21s
                      Time elapsed: 00:52:38
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 18097 steps/s (collection: 5.005s, learning 0.427s)
             Mean action noise std: 3.59
          Mean value_function loss: 66.3693
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.2168
                       Mean reward: 752.48
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 1.0327
    Episode_Reward/rotating_object: 142.4367
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0532
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 5.43s
                      Time elapsed: 00:52:44
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 19585 steps/s (collection: 4.691s, learning 0.328s)
             Mean action noise std: 3.59
          Mean value_function loss: 68.9097
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.2271
                       Mean reward: 746.16
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 145.8452
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0520
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 5.02s
                      Time elapsed: 00:52:49
                               ETA: 00:11:10

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 18022 steps/s (collection: 5.087s, learning 0.368s)
             Mean action noise std: 3.59
          Mean value_function loss: 72.6264
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.2393
                       Mean reward: 722.51
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 1.0167
    Episode_Reward/rotating_object: 139.8162
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 5.45s
                      Time elapsed: 00:52:54
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 17242 steps/s (collection: 5.284s, learning 0.417s)
             Mean action noise std: 3.60
          Mean value_function loss: 82.9983
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.2571
                       Mean reward: 681.91
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.0060
    Episode_Reward/rotating_object: 135.7933
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 5.70s
                      Time elapsed: 00:53:00
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 18235 steps/s (collection: 5.002s, learning 0.389s)
             Mean action noise std: 3.60
          Mean value_function loss: 92.2593
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.2773
                       Mean reward: 708.25
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 0.9981
    Episode_Reward/rotating_object: 137.7546
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 5.39s
                      Time elapsed: 00:53:05
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 19254 steps/s (collection: 4.745s, learning 0.361s)
             Mean action noise std: 3.60
          Mean value_function loss: 67.4273
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.3015
                       Mean reward: 673.04
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0052
    Episode_Reward/rotating_object: 135.7420
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 5.11s
                      Time elapsed: 00:53:10
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 20618 steps/s (collection: 4.391s, learning 0.377s)
             Mean action noise std: 3.61
          Mean value_function loss: 65.5477
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.3234
                       Mean reward: 710.73
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.0242
    Episode_Reward/rotating_object: 140.9634
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0516
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 4.77s
                      Time elapsed: 00:53:15
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 20232 steps/s (collection: 4.538s, learning 0.320s)
             Mean action noise std: 3.61
          Mean value_function loss: 77.6299
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.3425
                       Mean reward: 718.17
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.0149
    Episode_Reward/rotating_object: 137.8939
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0514
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 4.86s
                      Time elapsed: 00:53:20
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 20437 steps/s (collection: 4.398s, learning 0.412s)
             Mean action noise std: 3.61
          Mean value_function loss: 74.6837
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.3630
                       Mean reward: 733.88
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 1.0208
    Episode_Reward/rotating_object: 140.0550
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 4.81s
                      Time elapsed: 00:53:25
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 18889 steps/s (collection: 4.883s, learning 0.321s)
             Mean action noise std: 3.61
          Mean value_function loss: 87.9690
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.3797
                       Mean reward: 696.97
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.0213
    Episode_Reward/rotating_object: 141.9406
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 5.20s
                      Time elapsed: 00:53:30
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 20674 steps/s (collection: 4.435s, learning 0.320s)
             Mean action noise std: 3.62
          Mean value_function loss: 74.0294
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.3894
                       Mean reward: 698.99
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.0057
    Episode_Reward/rotating_object: 137.5721
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0524
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 4.75s
                      Time elapsed: 00:53:35
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 18323 steps/s (collection: 5.058s, learning 0.307s)
             Mean action noise std: 3.62
          Mean value_function loss: 84.0330
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.4026
                       Mean reward: 715.76
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.0064
    Episode_Reward/rotating_object: 136.6705
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 5.36s
                      Time elapsed: 00:53:40
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 20789 steps/s (collection: 4.442s, learning 0.286s)
             Mean action noise std: 3.62
          Mean value_function loss: 63.4366
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.4171
                       Mean reward: 730.71
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 1.0217
    Episode_Reward/rotating_object: 138.9226
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0526
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 4.73s
                      Time elapsed: 00:53:45
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 19468 steps/s (collection: 4.638s, learning 0.412s)
             Mean action noise std: 3.62
          Mean value_function loss: 87.8108
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.4332
                       Mean reward: 712.53
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.0347
    Episode_Reward/rotating_object: 141.7906
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0534
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 5.05s
                      Time elapsed: 00:53:50
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 19084 steps/s (collection: 4.837s, learning 0.314s)
             Mean action noise std: 3.63
          Mean value_function loss: 81.2378
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.4537
                       Mean reward: 673.29
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.0057
    Episode_Reward/rotating_object: 131.9570
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 5.15s
                      Time elapsed: 00:53:55
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 20617 steps/s (collection: 4.423s, learning 0.345s)
             Mean action noise std: 3.63
          Mean value_function loss: 82.0886
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.4632
                       Mean reward: 756.25
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 1.0173
    Episode_Reward/rotating_object: 141.2430
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 4.77s
                      Time elapsed: 00:54:00
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 19252 steps/s (collection: 4.751s, learning 0.355s)
             Mean action noise std: 3.63
          Mean value_function loss: 83.2872
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.4726
                       Mean reward: 662.57
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.0141
    Episode_Reward/rotating_object: 134.2613
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 5.11s
                      Time elapsed: 00:54:05
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 20657 steps/s (collection: 4.419s, learning 0.340s)
             Mean action noise std: 3.63
          Mean value_function loss: 74.5858
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.4830
                       Mean reward: 692.27
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.0136
    Episode_Reward/rotating_object: 136.9026
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 4.76s
                      Time elapsed: 00:54:10
                               ETA: 00:10:37

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 20200 steps/s (collection: 4.489s, learning 0.377s)
             Mean action noise std: 3.64
          Mean value_function loss: 76.7239
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.4990
                       Mean reward: 719.84
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 1.0248
    Episode_Reward/rotating_object: 139.1752
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 4.87s
                      Time elapsed: 00:54:15
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 17982 steps/s (collection: 5.038s, learning 0.429s)
             Mean action noise std: 3.64
          Mean value_function loss: 71.0163
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.5104
                       Mean reward: 691.05
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.0286
    Episode_Reward/rotating_object: 141.3542
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0521
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 5.47s
                      Time elapsed: 00:54:20
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 19851 steps/s (collection: 4.572s, learning 0.380s)
             Mean action noise std: 3.64
          Mean value_function loss: 75.7168
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.5236
                       Mean reward: 671.43
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.0054
    Episode_Reward/rotating_object: 132.1925
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 4.95s
                      Time elapsed: 00:54:25
                               ETA: 00:10:30

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 19723 steps/s (collection: 4.610s, learning 0.374s)
             Mean action noise std: 3.64
          Mean value_function loss: 74.5600
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.5366
                       Mean reward: 644.12
               Mean episode length: 225.10
    Episode_Reward/reaching_object: 1.0101
    Episode_Reward/rotating_object: 134.9767
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 4.98s
                      Time elapsed: 00:54:30
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 18103 steps/s (collection: 5.047s, learning 0.383s)
             Mean action noise std: 3.65
          Mean value_function loss: 84.5818
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.5562
                       Mean reward: 730.76
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.0367
    Episode_Reward/rotating_object: 139.2469
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 5.43s
                      Time elapsed: 00:54:35
                               ETA: 00:10:26

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 19605 steps/s (collection: 4.755s, learning 0.259s)
             Mean action noise std: 3.65
          Mean value_function loss: 84.5793
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.5721
                       Mean reward: 693.63
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.0273
    Episode_Reward/rotating_object: 139.8344
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0527
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 5.01s
                      Time elapsed: 00:54:40
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 25557 steps/s (collection: 3.629s, learning 0.217s)
             Mean action noise std: 3.65
          Mean value_function loss: 76.8383
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.5837
                       Mean reward: 706.85
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.0398
    Episode_Reward/rotating_object: 140.2638
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0540
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 3.85s
                      Time elapsed: 00:54:44
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 24077 steps/s (collection: 3.739s, learning 0.344s)
             Mean action noise std: 3.65
          Mean value_function loss: 87.4613
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.5922
                       Mean reward: 636.97
               Mean episode length: 218.20
    Episode_Reward/reaching_object: 1.0142
    Episode_Reward/rotating_object: 134.7162
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0528
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 4.08s
                      Time elapsed: 00:54:48
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 17670 steps/s (collection: 5.264s, learning 0.299s)
             Mean action noise std: 3.65
          Mean value_function loss: 80.7347
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.5987
                       Mean reward: 692.55
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 1.0175
    Episode_Reward/rotating_object: 138.6221
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0530
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 5.56s
                      Time elapsed: 00:54:54
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 19257 steps/s (collection: 4.748s, learning 0.356s)
             Mean action noise std: 3.66
          Mean value_function loss: 82.8313
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.6137
                       Mean reward: 731.34
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 1.0016
    Episode_Reward/rotating_object: 137.6360
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 5.10s
                      Time elapsed: 00:54:59
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 19042 steps/s (collection: 4.872s, learning 0.291s)
             Mean action noise std: 3.66
          Mean value_function loss: 67.0908
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.6287
                       Mean reward: 726.70
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.0375
    Episode_Reward/rotating_object: 142.3381
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0529
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 5.16s
                      Time elapsed: 00:55:04
                               ETA: 00:10:13

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 20154 steps/s (collection: 4.594s, learning 0.284s)
             Mean action noise std: 3.66
          Mean value_function loss: 71.7930
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.6421
                       Mean reward: 711.06
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 1.0407
    Episode_Reward/rotating_object: 141.7157
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0540
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 4.88s
                      Time elapsed: 00:55:09
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 19699 steps/s (collection: 4.587s, learning 0.403s)
             Mean action noise std: 3.66
          Mean value_function loss: 76.3112
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.6531
                       Mean reward: 712.43
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 1.0299
    Episode_Reward/rotating_object: 140.0793
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 4.99s
                      Time elapsed: 00:55:14
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 16773 steps/s (collection: 5.519s, learning 0.341s)
             Mean action noise std: 3.66
          Mean value_function loss: 65.0142
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.6607
                       Mean reward: 710.62
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 1.0532
    Episode_Reward/rotating_object: 142.7270
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 5.86s
                      Time elapsed: 00:55:20
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 20680 steps/s (collection: 4.550s, learning 0.203s)
             Mean action noise std: 3.67
          Mean value_function loss: 76.0995
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.6755
                       Mean reward: 682.68
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.0325
    Episode_Reward/rotating_object: 138.9650
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 4.75s
                      Time elapsed: 00:55:25
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 19303 steps/s (collection: 4.647s, learning 0.445s)
             Mean action noise std: 3.67
          Mean value_function loss: 70.9247
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.6857
                       Mean reward: 733.59
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.0507
    Episode_Reward/rotating_object: 143.9415
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 5.09s
                      Time elapsed: 00:55:30
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 16326 steps/s (collection: 5.566s, learning 0.455s)
             Mean action noise std: 3.67
          Mean value_function loss: 75.8214
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.6985
                       Mean reward: 729.30
               Mean episode length: 239.14
    Episode_Reward/reaching_object: 1.0177
    Episode_Reward/rotating_object: 138.5530
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 6.02s
                      Time elapsed: 00:55:36
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 21207 steps/s (collection: 4.339s, learning 0.297s)
             Mean action noise std: 3.67
          Mean value_function loss: 79.3443
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.7097
                       Mean reward: 713.25
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.0187
    Episode_Reward/rotating_object: 139.7028
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 4.64s
                      Time elapsed: 00:55:40
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 20242 steps/s (collection: 4.546s, learning 0.310s)
             Mean action noise std: 3.68
          Mean value_function loss: 69.1058
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.7262
                       Mean reward: 670.51
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 1.0254
    Episode_Reward/rotating_object: 136.7020
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0558
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 4.86s
                      Time elapsed: 00:55:45
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 18681 steps/s (collection: 4.918s, learning 0.344s)
             Mean action noise std: 3.68
          Mean value_function loss: 71.7943
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.7418
                       Mean reward: 681.68
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 1.0065
    Episode_Reward/rotating_object: 136.9084
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 5.26s
                      Time elapsed: 00:55:51
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 17862 steps/s (collection: 5.218s, learning 0.285s)
             Mean action noise std: 3.68
          Mean value_function loss: 81.6914
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.7535
                       Mean reward: 712.95
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.0163
    Episode_Reward/rotating_object: 140.0511
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0544
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 5.50s
                      Time elapsed: 00:55:56
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 19580 steps/s (collection: 4.658s, learning 0.363s)
             Mean action noise std: 3.68
          Mean value_function loss: 93.2846
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.7660
                       Mean reward: 652.29
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.0239
    Episode_Reward/rotating_object: 139.6768
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0540
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 5.02s
                      Time elapsed: 00:56:01
                               ETA: 00:09:49

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 17420 steps/s (collection: 5.193s, learning 0.450s)
             Mean action noise std: 3.69
          Mean value_function loss: 86.4407
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.7811
                       Mean reward: 631.62
               Mean episode length: 223.53
    Episode_Reward/reaching_object: 0.9820
    Episode_Reward/rotating_object: 132.5740
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0537
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 5.64s
                      Time elapsed: 00:56:07
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 17819 steps/s (collection: 5.203s, learning 0.314s)
             Mean action noise std: 3.69
          Mean value_function loss: 65.8463
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.7898
                       Mean reward: 708.34
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.0244
    Episode_Reward/rotating_object: 139.5249
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 5.52s
                      Time elapsed: 00:56:12
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 18168 steps/s (collection: 5.039s, learning 0.371s)
             Mean action noise std: 3.69
          Mean value_function loss: 92.9995
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.8009
                       Mean reward: 657.89
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 0.9913
    Episode_Reward/rotating_object: 134.7571
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 5.41s
                      Time elapsed: 00:56:18
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 20893 steps/s (collection: 4.352s, learning 0.353s)
             Mean action noise std: 3.69
          Mean value_function loss: 73.3844
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.8133
                       Mean reward: 679.59
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.0078
    Episode_Reward/rotating_object: 137.1263
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0547
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 4.70s
                      Time elapsed: 00:56:22
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 18540 steps/s (collection: 5.026s, learning 0.276s)
             Mean action noise std: 3.69
          Mean value_function loss: 80.8884
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.8245
                       Mean reward: 691.49
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.0056
    Episode_Reward/rotating_object: 134.8456
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 5.30s
                      Time elapsed: 00:56:28
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 19153 steps/s (collection: 4.717s, learning 0.416s)
             Mean action noise std: 3.70
          Mean value_function loss: 80.2426
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.8402
                       Mean reward: 684.32
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.0251
    Episode_Reward/rotating_object: 140.5376
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 5.13s
                      Time elapsed: 00:56:33
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 20286 steps/s (collection: 4.488s, learning 0.357s)
             Mean action noise std: 3.70
          Mean value_function loss: 80.9117
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.8552
                       Mean reward: 692.89
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 1.0131
    Episode_Reward/rotating_object: 137.9008
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0536
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 4.85s
                      Time elapsed: 00:56:38
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 20910 steps/s (collection: 4.440s, learning 0.261s)
             Mean action noise std: 3.70
          Mean value_function loss: 85.5308
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.8686
                       Mean reward: 673.44
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 1.0229
    Episode_Reward/rotating_object: 140.2137
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0555
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 4.70s
                      Time elapsed: 00:56:42
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 21221 steps/s (collection: 4.329s, learning 0.304s)
             Mean action noise std: 3.70
          Mean value_function loss: 88.7052
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.8801
                       Mean reward: 649.63
               Mean episode length: 224.43
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 135.6989
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0545
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 4.63s
                      Time elapsed: 00:56:47
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 17763 steps/s (collection: 5.233s, learning 0.301s)
             Mean action noise std: 3.71
          Mean value_function loss: 85.5582
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.8930
                       Mean reward: 691.68
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0061
    Episode_Reward/rotating_object: 136.4452
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0549
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 5.53s
                      Time elapsed: 00:56:52
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 20142 steps/s (collection: 4.540s, learning 0.341s)
             Mean action noise std: 3.71
          Mean value_function loss: 91.4644
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.9060
                       Mean reward: 683.10
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 0.9911
    Episode_Reward/rotating_object: 135.7008
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0551
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 4.88s
                      Time elapsed: 00:56:57
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 18552 steps/s (collection: 4.983s, learning 0.315s)
             Mean action noise std: 3.71
          Mean value_function loss: 88.4588
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.9148
                       Mean reward: 685.34
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 0.9969
    Episode_Reward/rotating_object: 135.0530
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0542
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 5.30s
                      Time elapsed: 00:57:03
                               ETA: 00:09:22

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 20398 steps/s (collection: 4.524s, learning 0.295s)
             Mean action noise std: 3.71
          Mean value_function loss: 77.6421
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.9298
                       Mean reward: 702.45
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 0.9980
    Episode_Reward/rotating_object: 134.8881
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0541
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 4.82s
                      Time elapsed: 00:57:07
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 19076 steps/s (collection: 4.789s, learning 0.364s)
             Mean action noise std: 3.71
          Mean value_function loss: 66.8282
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.9403
                       Mean reward: 729.62
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.0318
    Episode_Reward/rotating_object: 141.7496
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0557
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 5.15s
                      Time elapsed: 00:57:13
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 20686 steps/s (collection: 4.374s, learning 0.378s)
             Mean action noise std: 3.72
          Mean value_function loss: 72.9541
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.9521
                       Mean reward: 726.15
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 141.3442
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0552
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 4.75s
                      Time elapsed: 00:57:17
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 19390 steps/s (collection: 4.761s, learning 0.308s)
             Mean action noise std: 3.72
          Mean value_function loss: 72.2138
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.9631
                       Mean reward: 647.03
               Mean episode length: 222.42
    Episode_Reward/reaching_object: 0.9994
    Episode_Reward/rotating_object: 136.7697
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0553
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 5.07s
                      Time elapsed: 00:57:22
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 19710 steps/s (collection: 4.683s, learning 0.305s)
             Mean action noise std: 3.72
          Mean value_function loss: 66.9143
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.9747
                       Mean reward: 651.10
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 133.8052
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0546
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 4.99s
                      Time elapsed: 00:57:27
                               ETA: 00:09:11

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 17528 steps/s (collection: 5.234s, learning 0.375s)
             Mean action noise std: 3.72
          Mean value_function loss: 66.4144
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.9899
                       Mean reward: 704.54
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.0194
    Episode_Reward/rotating_object: 138.0479
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0566
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 5.61s
                      Time elapsed: 00:57:33
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 19918 steps/s (collection: 4.634s, learning 0.301s)
             Mean action noise std: 3.73
          Mean value_function loss: 56.3765
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.0073
                       Mean reward: 692.16
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.0302
    Episode_Reward/rotating_object: 141.2216
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0556
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 4.94s
                      Time elapsed: 00:57:38
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 18233 steps/s (collection: 5.099s, learning 0.293s)
             Mean action noise std: 3.73
          Mean value_function loss: 75.9479
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.0212
                       Mean reward: 720.60
               Mean episode length: 240.58
    Episode_Reward/reaching_object: 1.0162
    Episode_Reward/rotating_object: 140.7789
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0550
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 5.39s
                      Time elapsed: 00:57:43
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 17984 steps/s (collection: 5.056s, learning 0.410s)
             Mean action noise std: 3.73
          Mean value_function loss: 67.9690
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.0369
                       Mean reward: 721.65
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 1.0228
    Episode_Reward/rotating_object: 142.4721
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0531
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 5.47s
                      Time elapsed: 00:57:49
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 16950 steps/s (collection: 5.414s, learning 0.385s)
             Mean action noise std: 3.73
          Mean value_function loss: 74.0516
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.0484
                       Mean reward: 700.83
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 0.9945
    Episode_Reward/rotating_object: 136.5785
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0538
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 5.80s
                      Time elapsed: 00:57:55
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 19545 steps/s (collection: 4.741s, learning 0.289s)
             Mean action noise std: 3.73
          Mean value_function loss: 66.3324
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.0591
                       Mean reward: 705.91
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 141.4182
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0535
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 5.03s
                      Time elapsed: 00:58:00
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 18994 steps/s (collection: 4.778s, learning 0.397s)
             Mean action noise std: 3.74
          Mean value_function loss: 87.4143
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.0714
                       Mean reward: 655.86
               Mean episode length: 229.07
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 138.8413
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0518
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 5.18s
                      Time elapsed: 00:58:05
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 18123 steps/s (collection: 5.096s, learning 0.328s)
             Mean action noise std: 3.74
          Mean value_function loss: 79.4708
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.0882
                       Mean reward: 723.99
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.0129
    Episode_Reward/rotating_object: 142.8012
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 5.42s
                      Time elapsed: 00:58:10
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 18380 steps/s (collection: 4.980s, learning 0.368s)
             Mean action noise std: 3.74
          Mean value_function loss: 94.1498
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.1014
                       Mean reward: 711.34
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 0.9913
    Episode_Reward/rotating_object: 138.1426
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 5.35s
                      Time elapsed: 00:58:16
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 18402 steps/s (collection: 4.973s, learning 0.369s)
             Mean action noise std: 3.74
          Mean value_function loss: 90.8714
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.1082
                       Mean reward: 637.99
               Mean episode length: 222.72
    Episode_Reward/reaching_object: 0.9849
    Episode_Reward/rotating_object: 134.3765
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 5.34s
                      Time elapsed: 00:58:21
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 19857 steps/s (collection: 4.570s, learning 0.381s)
             Mean action noise std: 3.75
          Mean value_function loss: 60.1335
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.1152
                       Mean reward: 690.79
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 0.9913
    Episode_Reward/rotating_object: 137.5424
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 4.95s
                      Time elapsed: 00:58:26
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 18104 steps/s (collection: 5.053s, learning 0.377s)
             Mean action noise std: 3.75
          Mean value_function loss: 69.8664
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.1281
                       Mean reward: 701.21
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 137.9893
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 5.43s
                      Time elapsed: 00:58:31
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 18518 steps/s (collection: 4.988s, learning 0.321s)
             Mean action noise std: 3.75
          Mean value_function loss: 80.9834
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.1425
                       Mean reward: 719.95
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 0.9760
    Episode_Reward/rotating_object: 132.5589
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0512
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 5.31s
                      Time elapsed: 00:58:37
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 16530 steps/s (collection: 5.531s, learning 0.415s)
             Mean action noise std: 3.75
          Mean value_function loss: 69.1361
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.1581
                       Mean reward: 640.31
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.0170
    Episode_Reward/rotating_object: 139.6936
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0519
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 5.95s
                      Time elapsed: 00:58:43
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 19422 steps/s (collection: 4.787s, learning 0.275s)
             Mean action noise std: 3.75
          Mean value_function loss: 95.0202
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.1705
                       Mean reward: 716.33
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 0.9702
    Episode_Reward/rotating_object: 135.8763
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0513
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 5.06s
                      Time elapsed: 00:58:48
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 17151 steps/s (collection: 5.419s, learning 0.313s)
             Mean action noise std: 3.76
          Mean value_function loss: 92.5281
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.1811
                       Mean reward: 649.26
               Mean episode length: 221.86
    Episode_Reward/reaching_object: 0.9707
    Episode_Reward/rotating_object: 135.7319
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 5.73s
                      Time elapsed: 00:58:53
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 21667 steps/s (collection: 4.212s, learning 0.325s)
             Mean action noise std: 3.76
          Mean value_function loss: 89.5321
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.1954
                       Mean reward: 678.71
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 0.9828
    Episode_Reward/rotating_object: 134.3099
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0507
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 4.54s
                      Time elapsed: 00:58:58
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 18929 steps/s (collection: 4.844s, learning 0.349s)
             Mean action noise std: 3.76
          Mean value_function loss: 96.3197
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.2097
                       Mean reward: 671.96
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.0042
    Episode_Reward/rotating_object: 138.6397
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0508
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 5.19s
                      Time elapsed: 00:59:03
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 18630 steps/s (collection: 4.929s, learning 0.347s)
             Mean action noise std: 3.76
          Mean value_function loss: 86.6705
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.2218
                       Mean reward: 711.30
               Mean episode length: 234.83
    Episode_Reward/reaching_object: 0.9858
    Episode_Reward/rotating_object: 137.7766
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 5.28s
                      Time elapsed: 00:59:08
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 17627 steps/s (collection: 5.184s, learning 0.393s)
             Mean action noise std: 3.77
          Mean value_function loss: 83.8095
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.2334
                       Mean reward: 714.11
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.0140
    Episode_Reward/rotating_object: 141.9748
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 5.58s
                      Time elapsed: 00:59:14
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 19810 steps/s (collection: 4.654s, learning 0.308s)
             Mean action noise std: 3.77
          Mean value_function loss: 82.0449
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.2468
                       Mean reward: 727.69
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.0008
    Episode_Reward/rotating_object: 138.3980
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 4.96s
                      Time elapsed: 00:59:19
                               ETA: 00:08:23

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 19831 steps/s (collection: 4.528s, learning 0.429s)
             Mean action noise std: 3.77
          Mean value_function loss: 73.5908
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.2585
                       Mean reward: 671.09
               Mean episode length: 224.50
    Episode_Reward/reaching_object: 0.9930
    Episode_Reward/rotating_object: 137.5514
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 4.96s
                      Time elapsed: 00:59:24
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 19002 steps/s (collection: 4.800s, learning 0.373s)
             Mean action noise std: 3.77
          Mean value_function loss: 79.5733
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.2732
                       Mean reward: 733.98
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 138.6871
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0511
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 5.17s
                      Time elapsed: 00:59:29
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 17553 steps/s (collection: 5.277s, learning 0.323s)
             Mean action noise std: 3.78
          Mean value_function loss: 86.1005
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.2914
                       Mean reward: 692.61
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 0.9855
    Episode_Reward/rotating_object: 135.0070
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 5.60s
                      Time elapsed: 00:59:35
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 19724 steps/s (collection: 4.635s, learning 0.349s)
             Mean action noise std: 3.78
          Mean value_function loss: 87.2775
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.3036
                       Mean reward: 691.80
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.0066
    Episode_Reward/rotating_object: 140.7016
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 4.98s
                      Time elapsed: 00:59:40
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 19553 steps/s (collection: 4.662s, learning 0.365s)
             Mean action noise std: 3.78
          Mean value_function loss: 73.1264
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.3136
                       Mean reward: 722.48
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 1.0020
    Episode_Reward/rotating_object: 140.7955
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 5.03s
                      Time elapsed: 00:59:45
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 18374 steps/s (collection: 4.988s, learning 0.362s)
             Mean action noise std: 3.78
          Mean value_function loss: 70.3870
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.3246
                       Mean reward: 689.23
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 0.9969
    Episode_Reward/rotating_object: 137.4541
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0522
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 5.35s
                      Time elapsed: 00:59:50
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 19594 steps/s (collection: 4.755s, learning 0.262s)
             Mean action noise std: 3.79
          Mean value_function loss: 68.5881
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.3384
                       Mean reward: 675.49
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.0074
    Episode_Reward/rotating_object: 138.6303
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0515
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 5.02s
                      Time elapsed: 00:59:55
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 19283 steps/s (collection: 4.642s, learning 0.456s)
             Mean action noise std: 3.79
          Mean value_function loss: 74.7577
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.3558
                       Mean reward: 691.95
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 0.9888
    Episode_Reward/rotating_object: 134.4294
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 5.10s
                      Time elapsed: 01:00:00
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 17393 steps/s (collection: 5.327s, learning 0.325s)
             Mean action noise std: 3.79
          Mean value_function loss: 80.7391
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.3697
                       Mean reward: 693.93
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 0.9797
    Episode_Reward/rotating_object: 136.0436
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0500
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 5.65s
                      Time elapsed: 01:00:06
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 17460 steps/s (collection: 5.253s, learning 0.377s)
             Mean action noise std: 3.79
          Mean value_function loss: 81.8731
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.3818
                       Mean reward: 718.04
               Mean episode length: 245.13
    Episode_Reward/reaching_object: 1.0102
    Episode_Reward/rotating_object: 139.7130
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0523
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 5.63s
                      Time elapsed: 01:00:11
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 20354 steps/s (collection: 4.582s, learning 0.248s)
             Mean action noise std: 3.79
          Mean value_function loss: 102.4084
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.3923
                       Mean reward: 677.10
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 0.9799
    Episode_Reward/rotating_object: 136.4622
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 4.83s
                      Time elapsed: 01:00:16
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 21718 steps/s (collection: 4.164s, learning 0.362s)
             Mean action noise std: 3.80
          Mean value_function loss: 72.8252
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.4022
                       Mean reward: 668.32
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 0.9868
    Episode_Reward/rotating_object: 135.1839
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 4.53s
                      Time elapsed: 01:00:21
                               ETA: 00:07:54

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 21763 steps/s (collection: 4.080s, learning 0.436s)
             Mean action noise std: 3.80
          Mean value_function loss: 68.8771
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.4133
                       Mean reward: 720.07
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.0116
    Episode_Reward/rotating_object: 139.8103
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0509
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 4.52s
                      Time elapsed: 01:00:25
                               ETA: 00:07:52

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 19145 steps/s (collection: 4.774s, learning 0.361s)
             Mean action noise std: 3.80
          Mean value_function loss: 75.2596
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.4220
                       Mean reward: 696.43
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.9972
    Episode_Reward/rotating_object: 136.0808
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0517
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 5.13s
                      Time elapsed: 01:00:30
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 19981 steps/s (collection: 4.652s, learning 0.268s)
             Mean action noise std: 3.80
          Mean value_function loss: 69.0156
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.4298
                       Mean reward: 703.04
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.0032
    Episode_Reward/rotating_object: 139.5848
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0505
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 4.92s
                      Time elapsed: 01:00:35
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 18817 steps/s (collection: 4.959s, learning 0.265s)
             Mean action noise std: 3.80
          Mean value_function loss: 64.8693
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.4415
                       Mean reward: 696.92
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.0047
    Episode_Reward/rotating_object: 142.6608
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0510
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 5.22s
                      Time elapsed: 01:00:41
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 25264 steps/s (collection: 3.634s, learning 0.257s)
             Mean action noise std: 3.81
          Mean value_function loss: 71.3290
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.4522
                       Mean reward: 704.56
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.0014
    Episode_Reward/rotating_object: 140.3302
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 3.89s
                      Time elapsed: 01:00:44
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 25126 steps/s (collection: 3.662s, learning 0.251s)
             Mean action noise std: 3.81
          Mean value_function loss: 74.6801
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.4621
                       Mean reward: 720.00
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.0087
    Episode_Reward/rotating_object: 139.5575
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 3.91s
                      Time elapsed: 01:00:48
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 8907 steps/s (collection: 10.745s, learning 0.291s)
             Mean action noise std: 3.81
          Mean value_function loss: 80.7247
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.4821
                       Mean reward: 694.18
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 0.9885
    Episode_Reward/rotating_object: 138.8907
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 11.04s
                      Time elapsed: 01:00:59
                               ETA: 00:07:38

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 5755 steps/s (collection: 16.776s, learning 0.303s)
             Mean action noise std: 3.82
          Mean value_function loss: 78.8681
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.5003
                       Mean reward: 707.16
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 135.8026
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0499
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 17.08s
                      Time elapsed: 01:01:16
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 5697 steps/s (collection: 16.998s, learning 0.257s)
             Mean action noise std: 3.82
          Mean value_function loss: 79.5018
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.5148
                       Mean reward: 713.22
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 0.9912
    Episode_Reward/rotating_object: 138.6013
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 17.25s
                      Time elapsed: 01:01:34
                               ETA: 00:07:36

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 5699 steps/s (collection: 16.853s, learning 0.394s)
             Mean action noise std: 3.82
          Mean value_function loss: 84.4699
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.5274
                       Mean reward: 670.02
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 0.9778
    Episode_Reward/rotating_object: 137.1617
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 17.25s
                      Time elapsed: 01:01:51
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 5637 steps/s (collection: 17.116s, learning 0.321s)
             Mean action noise std: 3.82
          Mean value_function loss: 95.3239
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.5370
                       Mean reward: 653.69
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 0.9762
    Episode_Reward/rotating_object: 134.9956
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 17.44s
                      Time elapsed: 01:02:08
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 5354 steps/s (collection: 17.949s, learning 0.412s)
             Mean action noise std: 3.82
          Mean value_function loss: 66.6711
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.5446
                       Mean reward: 674.31
               Mean episode length: 222.96
    Episode_Reward/reaching_object: 0.9805
    Episode_Reward/rotating_object: 135.5291
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 18.36s
                      Time elapsed: 01:02:27
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 5465 steps/s (collection: 17.593s, learning 0.394s)
             Mean action noise std: 3.82
          Mean value_function loss: 69.1186
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.5542
                       Mean reward: 692.57
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 1.0062
    Episode_Reward/rotating_object: 140.4796
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 17.99s
                      Time elapsed: 01:02:45
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 5757 steps/s (collection: 16.693s, learning 0.382s)
             Mean action noise std: 3.83
          Mean value_function loss: 62.0152
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.5685
                       Mean reward: 718.56
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 140.3200
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 17.07s
                      Time elapsed: 01:03:02
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 4625 steps/s (collection: 20.992s, learning 0.259s)
             Mean action noise std: 3.83
          Mean value_function loss: 62.2214
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.5778
                       Mean reward: 736.19
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.0207
    Episode_Reward/rotating_object: 143.6201
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 21.25s
                      Time elapsed: 01:03:23
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 18734 steps/s (collection: 4.912s, learning 0.336s)
             Mean action noise std: 3.83
          Mean value_function loss: 61.3172
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.5864
                       Mean reward: 647.36
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 0.9996
    Episode_Reward/rotating_object: 138.3582
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0501
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 5.25s
                      Time elapsed: 01:03:28
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 16058 steps/s (collection: 5.734s, learning 0.388s)
             Mean action noise std: 3.83
          Mean value_function loss: 71.5739
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.5978
                       Mean reward: 717.39
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.9981
    Episode_Reward/rotating_object: 140.5713
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 6.12s
                      Time elapsed: 01:03:34
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 16728 steps/s (collection: 5.564s, learning 0.313s)
             Mean action noise std: 3.83
          Mean value_function loss: 71.9569
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.6087
                       Mean reward: 695.07
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 1.0098
    Episode_Reward/rotating_object: 143.0927
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 5.88s
                      Time elapsed: 01:03:40
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 18711 steps/s (collection: 4.877s, learning 0.377s)
             Mean action noise std: 3.84
          Mean value_function loss: 75.3306
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.6223
                       Mean reward: 725.26
               Mean episode length: 233.13
    Episode_Reward/reaching_object: 0.9960
    Episode_Reward/rotating_object: 142.0469
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 5.25s
                      Time elapsed: 01:03:46
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 16829 steps/s (collection: 5.508s, learning 0.333s)
             Mean action noise std: 3.84
          Mean value_function loss: 65.4597
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.6361
                       Mean reward: 687.31
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.0015
    Episode_Reward/rotating_object: 139.8446
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0506
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 5.84s
                      Time elapsed: 01:03:51
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 18203 steps/s (collection: 4.999s, learning 0.401s)
             Mean action noise std: 3.84
          Mean value_function loss: 86.7491
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.6489
                       Mean reward: 732.70
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 0.9940
    Episode_Reward/rotating_object: 140.4188
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 5.40s
                      Time elapsed: 01:03:57
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 17837 steps/s (collection: 5.171s, learning 0.340s)
             Mean action noise std: 3.85
          Mean value_function loss: 71.4211
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.6613
                       Mean reward: 726.13
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 1.0127
    Episode_Reward/rotating_object: 143.9843
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 5.51s
                      Time elapsed: 01:04:02
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 17395 steps/s (collection: 5.299s, learning 0.352s)
             Mean action noise std: 3.85
          Mean value_function loss: 76.0460
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.6702
                       Mean reward: 714.78
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 0.9986
    Episode_Reward/rotating_object: 142.0623
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 5.65s
                      Time elapsed: 01:04:08
                               ETA: 00:07:10

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 18782 steps/s (collection: 4.910s, learning 0.324s)
             Mean action noise std: 3.85
          Mean value_function loss: 74.0378
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.6791
                       Mean reward: 746.92
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 0.9835
    Episode_Reward/rotating_object: 139.5196
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 5.23s
                      Time elapsed: 01:04:13
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 19049 steps/s (collection: 4.777s, learning 0.384s)
             Mean action noise std: 3.85
          Mean value_function loss: 63.0958
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 59.6871
                       Mean reward: 708.74
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 142.9647
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0494
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 5.16s
                      Time elapsed: 01:04:18
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 18219 steps/s (collection: 5.010s, learning 0.385s)
             Mean action noise std: 3.85
          Mean value_function loss: 68.5054
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.6906
                       Mean reward: 738.95
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 1.0137
    Episode_Reward/rotating_object: 145.0979
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 5.40s
                      Time elapsed: 01:04:24
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 18973 steps/s (collection: 4.814s, learning 0.367s)
             Mean action noise std: 3.85
          Mean value_function loss: 61.1701
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.6972
                       Mean reward: 740.95
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.0271
    Episode_Reward/rotating_object: 146.5139
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 5.18s
                      Time elapsed: 01:04:29
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 19472 steps/s (collection: 4.656s, learning 0.392s)
             Mean action noise std: 3.85
          Mean value_function loss: 61.1177
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.7082
                       Mean reward: 687.20
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0199
    Episode_Reward/rotating_object: 141.4363
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0495
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 5.05s
                      Time elapsed: 01:04:34
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 18432 steps/s (collection: 5.054s, learning 0.280s)
             Mean action noise std: 3.86
          Mean value_function loss: 71.1863
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.7209
                       Mean reward: 710.82
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.0114
    Episode_Reward/rotating_object: 140.3046
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 5.33s
                      Time elapsed: 01:04:39
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 19793 steps/s (collection: 4.637s, learning 0.329s)
             Mean action noise std: 3.86
          Mean value_function loss: 82.4297
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.7314
                       Mean reward: 703.62
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.0072
    Episode_Reward/rotating_object: 142.1418
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 4.97s
                      Time elapsed: 01:04:44
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 16232 steps/s (collection: 5.708s, learning 0.348s)
             Mean action noise std: 3.86
          Mean value_function loss: 82.6336
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.7409
                       Mean reward: 713.54
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 139.9035
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 6.06s
                      Time elapsed: 01:04:50
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 18127 steps/s (collection: 5.006s, learning 0.417s)
             Mean action noise std: 3.86
          Mean value_function loss: 60.0454
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.7519
                       Mean reward: 702.32
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 1.0019
    Episode_Reward/rotating_object: 137.3048
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0502
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 5.42s
                      Time elapsed: 01:04:56
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 16345 steps/s (collection: 5.648s, learning 0.366s)
             Mean action noise std: 3.87
          Mean value_function loss: 65.5954
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.7648
                       Mean reward: 693.63
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.0028
    Episode_Reward/rotating_object: 141.3475
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 6.01s
                      Time elapsed: 01:05:02
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 15907 steps/s (collection: 5.802s, learning 0.378s)
             Mean action noise std: 3.87
          Mean value_function loss: 61.9324
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.7771
                       Mean reward: 726.45
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.0024
    Episode_Reward/rotating_object: 141.9642
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 6.18s
                      Time elapsed: 01:05:08
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 18326 steps/s (collection: 4.932s, learning 0.432s)
             Mean action noise std: 3.87
          Mean value_function loss: 70.0596
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.7883
                       Mean reward: 716.52
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.0135
    Episode_Reward/rotating_object: 142.8131
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 5.36s
                      Time elapsed: 01:05:13
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 17959 steps/s (collection: 5.162s, learning 0.312s)
             Mean action noise std: 3.87
          Mean value_function loss: 78.5030
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.8059
                       Mean reward: 685.10
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 0.9909
    Episode_Reward/rotating_object: 140.1163
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 5.47s
                      Time elapsed: 01:05:19
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 18732 steps/s (collection: 4.884s, learning 0.364s)
             Mean action noise std: 3.88
          Mean value_function loss: 86.2132
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.8262
                       Mean reward: 685.82
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 0.9871
    Episode_Reward/rotating_object: 137.0111
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 5.25s
                      Time elapsed: 01:05:24
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 19632 steps/s (collection: 4.633s, learning 0.374s)
             Mean action noise std: 3.88
          Mean value_function loss: 80.1802
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.8427
                       Mean reward: 759.55
               Mean episode length: 244.72
    Episode_Reward/reaching_object: 0.9886
    Episode_Reward/rotating_object: 140.6175
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 5.01s
                      Time elapsed: 01:05:29
                               ETA: 00:06:31

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 17598 steps/s (collection: 5.223s, learning 0.362s)
             Mean action noise std: 3.88
          Mean value_function loss: 77.7737
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.8591
                       Mean reward: 720.52
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 0.9940
    Episode_Reward/rotating_object: 138.4849
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 5.59s
                      Time elapsed: 01:05:35
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 19154 steps/s (collection: 4.789s, learning 0.343s)
             Mean action noise std: 3.88
          Mean value_function loss: 69.5647
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.8686
                       Mean reward: 711.17
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 139.7253
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 5.13s
                      Time elapsed: 01:05:40
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 18890 steps/s (collection: 4.756s, learning 0.448s)
             Mean action noise std: 3.88
          Mean value_function loss: 88.1639
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.8805
                       Mean reward: 725.09
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.0033
    Episode_Reward/rotating_object: 139.4066
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 5.20s
                      Time elapsed: 01:05:45
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 20767 steps/s (collection: 4.397s, learning 0.337s)
             Mean action noise std: 3.89
          Mean value_function loss: 76.6052
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.8932
                       Mean reward: 727.09
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.0069
    Episode_Reward/rotating_object: 141.9277
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 4.73s
                      Time elapsed: 01:05:50
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 18599 steps/s (collection: 4.912s, learning 0.373s)
             Mean action noise std: 3.89
          Mean value_function loss: 77.9354
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.9087
                       Mean reward: 709.55
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 0.9793
    Episode_Reward/rotating_object: 136.9615
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 5.29s
                      Time elapsed: 01:05:55
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 18795 steps/s (collection: 4.864s, learning 0.367s)
             Mean action noise std: 3.89
          Mean value_function loss: 70.3396
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.9189
                       Mean reward: 721.53
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 0.9960
    Episode_Reward/rotating_object: 135.9465
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 5.23s
                      Time elapsed: 01:06:00
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 18403 steps/s (collection: 5.039s, learning 0.302s)
             Mean action noise std: 3.89
          Mean value_function loss: 73.0837
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.9275
                       Mean reward: 701.12
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 1.0082
    Episode_Reward/rotating_object: 142.2174
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 5.34s
                      Time elapsed: 01:06:06
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 18431 steps/s (collection: 4.926s, learning 0.408s)
             Mean action noise std: 3.90
          Mean value_function loss: 64.2925
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.9361
                       Mean reward: 694.10
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.0100
    Episode_Reward/rotating_object: 140.6110
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 5.33s
                      Time elapsed: 01:06:11
                               ETA: 00:06:10

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 17915 steps/s (collection: 5.131s, learning 0.356s)
             Mean action noise std: 3.90
          Mean value_function loss: 75.1833
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.9448
                       Mean reward: 685.43
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 0.9895
    Episode_Reward/rotating_object: 138.9939
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 5.49s
                      Time elapsed: 01:06:16
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 18223 steps/s (collection: 5.054s, learning 0.341s)
             Mean action noise std: 3.90
          Mean value_function loss: 71.3300
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.9540
                       Mean reward: 689.87
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.0009
    Episode_Reward/rotating_object: 139.6712
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0491
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 5.39s
                      Time elapsed: 01:06:22
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 19388 steps/s (collection: 4.793s, learning 0.278s)
             Mean action noise std: 3.90
          Mean value_function loss: 76.6494
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.9632
                       Mean reward: 702.99
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.0059
    Episode_Reward/rotating_object: 144.5171
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 5.07s
                      Time elapsed: 01:06:27
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 19098 steps/s (collection: 4.831s, learning 0.316s)
             Mean action noise std: 3.90
          Mean value_function loss: 78.1099
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.9783
                       Mean reward: 686.03
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 0.9909
    Episode_Reward/rotating_object: 139.3477
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 5.15s
                      Time elapsed: 01:06:32
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 19117 steps/s (collection: 4.809s, learning 0.333s)
             Mean action noise std: 3.91
          Mean value_function loss: 77.3108
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.9967
                       Mean reward: 722.18
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 0.9959
    Episode_Reward/rotating_object: 139.9226
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 5.14s
                      Time elapsed: 01:06:37
                               ETA: 00:05:56

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 18406 steps/s (collection: 4.988s, learning 0.353s)
             Mean action noise std: 3.91
          Mean value_function loss: 76.7131
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.0165
                       Mean reward: 663.25
               Mean episode length: 220.40
    Episode_Reward/reaching_object: 0.9852
    Episode_Reward/rotating_object: 139.6853
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 5.34s
                      Time elapsed: 01:06:42
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 19504 steps/s (collection: 4.754s, learning 0.286s)
             Mean action noise std: 3.91
          Mean value_function loss: 78.7449
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 60.0294
                       Mean reward: 696.22
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 0.9621
    Episode_Reward/rotating_object: 135.0909
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 5.04s
                      Time elapsed: 01:06:48
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 18088 steps/s (collection: 5.087s, learning 0.348s)
             Mean action noise std: 3.91
          Mean value_function loss: 82.7527
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.0364
                       Mean reward: 693.62
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 0.9929
    Episode_Reward/rotating_object: 138.8772
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 5.43s
                      Time elapsed: 01:06:53
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 18730 steps/s (collection: 4.835s, learning 0.413s)
             Mean action noise std: 3.92
          Mean value_function loss: 77.3436
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.0473
                       Mean reward: 691.41
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 0.9830
    Episode_Reward/rotating_object: 137.1398
        Episode_Reward/action_rate: -0.0808
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 5.25s
                      Time elapsed: 01:06:58
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 18944 steps/s (collection: 4.789s, learning 0.400s)
             Mean action noise std: 3.92
          Mean value_function loss: 82.6160
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.0590
                       Mean reward: 721.48
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 0.9891
    Episode_Reward/rotating_object: 138.5734
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 5.19s
                      Time elapsed: 01:07:03
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 18711 steps/s (collection: 4.951s, learning 0.303s)
             Mean action noise std: 3.92
          Mean value_function loss: 66.1014
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.0710
                       Mean reward: 701.53
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 0.9838
    Episode_Reward/rotating_object: 139.1275
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 5.25s
                      Time elapsed: 01:07:09
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 18142 steps/s (collection: 5.029s, learning 0.389s)
             Mean action noise std: 3.92
          Mean value_function loss: 84.0044
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.0824
                       Mean reward: 682.54
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 0.9774
    Episode_Reward/rotating_object: 136.5213
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 5.42s
                      Time elapsed: 01:07:14
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 17389 steps/s (collection: 5.357s, learning 0.296s)
             Mean action noise std: 3.92
          Mean value_function loss: 83.4276
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.0935
                       Mean reward: 661.64
               Mean episode length: 226.75
    Episode_Reward/reaching_object: 0.9744
    Episode_Reward/rotating_object: 135.1615
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 5.65s
                      Time elapsed: 01:07:20
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 17492 steps/s (collection: 5.307s, learning 0.313s)
             Mean action noise std: 3.93
          Mean value_function loss: 60.7425
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.1097
                       Mean reward: 737.92
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 1.0044
    Episode_Reward/rotating_object: 140.7168
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 5.62s
                      Time elapsed: 01:07:25
                               ETA: 00:05:32

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 16636 steps/s (collection: 5.537s, learning 0.372s)
             Mean action noise std: 3.93
          Mean value_function loss: 70.3366
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.1251
                       Mean reward: 735.37
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 0.9903
    Episode_Reward/rotating_object: 139.8141
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 5.91s
                      Time elapsed: 01:07:31
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 18669 steps/s (collection: 4.908s, learning 0.357s)
             Mean action noise std: 3.93
          Mean value_function loss: 60.0414
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.1359
                       Mean reward: 736.79
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.0278
    Episode_Reward/rotating_object: 147.9212
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 5.27s
                      Time elapsed: 01:07:37
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 18601 steps/s (collection: 4.950s, learning 0.334s)
             Mean action noise std: 3.94
          Mean value_function loss: 71.2112
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.1508
                       Mean reward: 718.45
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 0.9934
    Episode_Reward/rotating_object: 141.9706
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 5.28s
                      Time elapsed: 01:07:42
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 18599 steps/s (collection: 4.944s, learning 0.341s)
             Mean action noise std: 3.94
          Mean value_function loss: 73.6402
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.1690
                       Mean reward: 746.62
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 1.0095
    Episode_Reward/rotating_object: 141.3301
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 5.29s
                      Time elapsed: 01:07:47
                               ETA: 00:05:21

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 16783 steps/s (collection: 5.426s, learning 0.432s)
             Mean action noise std: 3.94
          Mean value_function loss: 64.4326
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.1843
                       Mean reward: 722.05
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.0038
    Episode_Reward/rotating_object: 140.8111
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 5.86s
                      Time elapsed: 01:07:53
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 17021 steps/s (collection: 5.397s, learning 0.378s)
             Mean action noise std: 3.94
          Mean value_function loss: 73.5867
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.1953
                       Mean reward: 717.54
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 1.0116
    Episode_Reward/rotating_object: 143.2837
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 5.78s
                      Time elapsed: 01:07:59
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 17555 steps/s (collection: 5.218s, learning 0.382s)
             Mean action noise std: 3.95
          Mean value_function loss: 71.6699
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.2099
                       Mean reward: 680.54
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 0.9966
    Episode_Reward/rotating_object: 139.3241
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 5.60s
                      Time elapsed: 01:08:04
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 17964 steps/s (collection: 5.147s, learning 0.325s)
             Mean action noise std: 3.95
          Mean value_function loss: 62.8947
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.2202
                       Mean reward: 712.98
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 1.0045
    Episode_Reward/rotating_object: 140.2959
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 5.47s
                      Time elapsed: 01:08:10
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 16662 steps/s (collection: 5.547s, learning 0.353s)
             Mean action noise std: 3.95
          Mean value_function loss: 79.8954
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.2283
                       Mean reward: 697.84
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 0.9846
    Episode_Reward/rotating_object: 140.9096
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 5.90s
                      Time elapsed: 01:08:16
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 22732 steps/s (collection: 4.095s, learning 0.230s)
             Mean action noise std: 3.95
          Mean value_function loss: 91.2560
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.2369
                       Mean reward: 707.55
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 0.9888
    Episode_Reward/rotating_object: 138.8177
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 4.32s
                      Time elapsed: 01:08:20
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 19231 steps/s (collection: 4.796s, learning 0.315s)
             Mean action noise std: 3.95
          Mean value_function loss: 60.3536
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.2457
                       Mean reward: 718.04
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.0008
    Episode_Reward/rotating_object: 140.8297
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 5.11s
                      Time elapsed: 01:08:25
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 17679 steps/s (collection: 5.147s, learning 0.413s)
             Mean action noise std: 3.96
          Mean value_function loss: 63.5055
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.2545
                       Mean reward: 699.30
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.0066
    Episode_Reward/rotating_object: 141.7302
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 5.56s
                      Time elapsed: 01:08:31
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 20664 steps/s (collection: 4.381s, learning 0.376s)
             Mean action noise std: 3.96
          Mean value_function loss: 65.5786
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.2654
                       Mean reward: 717.55
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.0091
    Episode_Reward/rotating_object: 142.9669
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 4.76s
                      Time elapsed: 01:08:35
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 18743 steps/s (collection: 4.885s, learning 0.360s)
             Mean action noise std: 3.96
          Mean value_function loss: 71.6579
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.2784
                       Mean reward: 688.01
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 1.0130
    Episode_Reward/rotating_object: 142.2530
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 5.24s
                      Time elapsed: 01:08:41
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 18045 steps/s (collection: 5.087s, learning 0.360s)
             Mean action noise std: 3.96
          Mean value_function loss: 73.8886
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.2898
                       Mean reward: 710.03
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 0.9994
    Episode_Reward/rotating_object: 139.5953
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 5.45s
                      Time elapsed: 01:08:46
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 17249 steps/s (collection: 5.301s, learning 0.398s)
             Mean action noise std: 3.97
          Mean value_function loss: 74.4092
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.3038
                       Mean reward: 721.46
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 1.0055
    Episode_Reward/rotating_object: 141.8404
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 5.70s
                      Time elapsed: 01:08:52
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 19469 steps/s (collection: 4.725s, learning 0.324s)
             Mean action noise std: 3.97
          Mean value_function loss: 66.2751
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.3154
                       Mean reward: 709.94
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 1.0080
    Episode_Reward/rotating_object: 137.2182
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 5.05s
                      Time elapsed: 01:08:57
                               ETA: 00:04:45

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 17413 steps/s (collection: 5.240s, learning 0.405s)
             Mean action noise std: 3.97
          Mean value_function loss: 76.9994
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.3272
                       Mean reward: 678.48
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 0.9984
    Episode_Reward/rotating_object: 137.5575
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 5.65s
                      Time elapsed: 01:09:03
                               ETA: 00:04:43

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 19487 steps/s (collection: 4.703s, learning 0.342s)
             Mean action noise std: 3.97
          Mean value_function loss: 70.2741
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.3385
                       Mean reward: 695.31
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 0.9964
    Episode_Reward/rotating_object: 139.7781
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 5.04s
                      Time elapsed: 01:09:08
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 19177 steps/s (collection: 4.798s, learning 0.328s)
             Mean action noise std: 3.98
          Mean value_function loss: 73.1706
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.3519
                       Mean reward: 719.36
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.0017
    Episode_Reward/rotating_object: 140.1169
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 5.13s
                      Time elapsed: 01:09:13
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 20180 steps/s (collection: 4.538s, learning 0.333s)
             Mean action noise std: 3.98
          Mean value_function loss: 75.8523
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.3667
                       Mean reward: 709.30
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.0030
    Episode_Reward/rotating_object: 140.3851
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 4.87s
                      Time elapsed: 01:09:18
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 20493 steps/s (collection: 4.437s, learning 0.360s)
             Mean action noise std: 3.98
          Mean value_function loss: 80.6894
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3799
                       Mean reward: 718.66
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.0094
    Episode_Reward/rotating_object: 140.2794
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 4.80s
                      Time elapsed: 01:09:22
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 19894 steps/s (collection: 4.567s, learning 0.374s)
             Mean action noise std: 3.98
          Mean value_function loss: 73.8139
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.3968
                       Mean reward: 697.14
               Mean episode length: 240.23
    Episode_Reward/reaching_object: 0.9844
    Episode_Reward/rotating_object: 136.1897
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 4.94s
                      Time elapsed: 01:09:27
                               ETA: 00:04:28

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 17990 steps/s (collection: 5.090s, learning 0.374s)
             Mean action noise std: 3.99
          Mean value_function loss: 86.0217
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.4080
                       Mean reward: 703.69
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 0.9837
    Episode_Reward/rotating_object: 137.0114
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 5.46s
                      Time elapsed: 01:09:33
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 18911 steps/s (collection: 4.852s, learning 0.346s)
             Mean action noise std: 3.99
          Mean value_function loss: 82.1418
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.4176
                       Mean reward: 687.05
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 0.9851
    Episode_Reward/rotating_object: 137.2271
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 5.20s
                      Time elapsed: 01:09:38
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 19556 steps/s (collection: 4.596s, learning 0.431s)
             Mean action noise std: 3.99
          Mean value_function loss: 66.8604
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.4322
                       Mean reward: 721.93
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 0.9940
    Episode_Reward/rotating_object: 139.4303
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 5.03s
                      Time elapsed: 01:09:43
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 17456 steps/s (collection: 5.265s, learning 0.366s)
             Mean action noise std: 3.99
          Mean value_function loss: 80.2694
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.4449
                       Mean reward: 689.77
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 0.9874
    Episode_Reward/rotating_object: 133.7406
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 5.63s
                      Time elapsed: 01:09:49
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 19827 steps/s (collection: 4.509s, learning 0.449s)
             Mean action noise std: 3.99
          Mean value_function loss: 77.3194
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.4530
                       Mean reward: 701.32
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 0.9897
    Episode_Reward/rotating_object: 138.5285
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 4.96s
                      Time elapsed: 01:09:54
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 17953 steps/s (collection: 5.109s, learning 0.367s)
             Mean action noise std: 4.00
          Mean value_function loss: 76.5271
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.4625
                       Mean reward: 687.33
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 0.9883
    Episode_Reward/rotating_object: 137.2263
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 5.48s
                      Time elapsed: 01:09:59
                               ETA: 00:04:12

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 18849 steps/s (collection: 4.979s, learning 0.236s)
             Mean action noise std: 4.00
          Mean value_function loss: 82.4713
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.4794
                       Mean reward: 700.44
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 141.3131
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 5.22s
                      Time elapsed: 01:10:04
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 20438 steps/s (collection: 4.431s, learning 0.378s)
             Mean action noise std: 4.00
          Mean value_function loss: 83.2512
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.4929
                       Mean reward: 695.52
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 0.9992
    Episode_Reward/rotating_object: 138.6490
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 4.81s
                      Time elapsed: 01:10:09
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 20406 steps/s (collection: 4.539s, learning 0.279s)
             Mean action noise std: 4.00
          Mean value_function loss: 91.4349
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.5016
                       Mean reward: 659.16
               Mean episode length: 225.30
    Episode_Reward/reaching_object: 0.9953
    Episode_Reward/rotating_object: 138.1893
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 4.82s
                      Time elapsed: 01:10:14
                               ETA: 00:04:03

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 19645 steps/s (collection: 4.674s, learning 0.329s)
             Mean action noise std: 4.01
          Mean value_function loss: 93.6567
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.5141
                       Mean reward: 723.07
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 0.9995
    Episode_Reward/rotating_object: 138.4960
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 5.00s
                      Time elapsed: 01:10:19
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 18517 steps/s (collection: 4.915s, learning 0.394s)
             Mean action noise std: 4.01
          Mean value_function loss: 77.5088
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.5254
                       Mean reward: 694.02
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 0.9923
    Episode_Reward/rotating_object: 136.9373
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 5.31s
                      Time elapsed: 01:10:24
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 17513 steps/s (collection: 5.366s, learning 0.247s)
             Mean action noise std: 4.01
          Mean value_function loss: 70.7932
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.5313
                       Mean reward: 738.37
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 1.0127
    Episode_Reward/rotating_object: 139.5296
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 5.61s
                      Time elapsed: 01:10:30
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 19209 steps/s (collection: 4.792s, learning 0.326s)
             Mean action noise std: 4.01
          Mean value_function loss: 75.5699
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.5434
                       Mean reward: 744.72
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 1.0185
    Episode_Reward/rotating_object: 143.2267
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 5.12s
                      Time elapsed: 01:10:35
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 18937 steps/s (collection: 4.912s, learning 0.279s)
             Mean action noise std: 4.01
          Mean value_function loss: 79.2549
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.5538
                       Mean reward: 750.83
               Mean episode length: 246.73
    Episode_Reward/reaching_object: 0.9999
    Episode_Reward/rotating_object: 136.9883
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 5.19s
                      Time elapsed: 01:10:40
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 20102 steps/s (collection: 4.569s, learning 0.321s)
             Mean action noise std: 4.02
          Mean value_function loss: 69.0666
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.5639
                       Mean reward: 709.54
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 0.9999
    Episode_Reward/rotating_object: 141.1132
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 4.89s
                      Time elapsed: 01:10:45
                               ETA: 00:03:46

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 18457 steps/s (collection: 4.950s, learning 0.376s)
             Mean action noise std: 4.02
          Mean value_function loss: 68.2868
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.5773
                       Mean reward: 719.32
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.0177
    Episode_Reward/rotating_object: 141.7729
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 5.33s
                      Time elapsed: 01:10:50
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 17464 steps/s (collection: 5.311s, learning 0.318s)
             Mean action noise std: 4.02
          Mean value_function loss: 73.0181
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 60.5865
                       Mean reward: 706.72
               Mean episode length: 233.20
    Episode_Reward/reaching_object: 1.0036
    Episode_Reward/rotating_object: 139.5049
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 5.63s
                      Time elapsed: 01:10:56
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 16918 steps/s (collection: 5.305s, learning 0.506s)
             Mean action noise std: 4.02
          Mean value_function loss: 78.9785
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.5912
                       Mean reward: 657.97
               Mean episode length: 230.40
    Episode_Reward/reaching_object: 1.0018
    Episode_Reward/rotating_object: 134.7796
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 5.81s
                      Time elapsed: 01:11:02
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 18494 steps/s (collection: 5.026s, learning 0.289s)
             Mean action noise std: 4.02
          Mean value_function loss: 75.5971
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.6029
                       Mean reward: 683.94
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 1.0071
    Episode_Reward/rotating_object: 140.0863
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 5.32s
                      Time elapsed: 01:11:07
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 16119 steps/s (collection: 5.657s, learning 0.441s)
             Mean action noise std: 4.03
          Mean value_function loss: 88.2220
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.6202
                       Mean reward: 687.00
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 0.9912
    Episode_Reward/rotating_object: 135.8141
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 6.10s
                      Time elapsed: 01:11:13
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 18184 steps/s (collection: 5.120s, learning 0.286s)
             Mean action noise std: 4.03
          Mean value_function loss: 77.0263
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.6361
                       Mean reward: 738.29
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 1.0185
    Episode_Reward/rotating_object: 142.6164
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 5.41s
                      Time elapsed: 01:11:19
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 15943 steps/s (collection: 5.719s, learning 0.447s)
             Mean action noise std: 4.03
          Mean value_function loss: 77.4083
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.6482
                       Mean reward: 699.32
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.0042
    Episode_Reward/rotating_object: 141.2922
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 6.17s
                      Time elapsed: 01:11:25
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 15903 steps/s (collection: 5.836s, learning 0.345s)
             Mean action noise std: 4.04
          Mean value_function loss: 73.9565
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.6611
                       Mean reward: 702.35
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 0.9920
    Episode_Reward/rotating_object: 138.2532
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 6.18s
                      Time elapsed: 01:11:31
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 15690 steps/s (collection: 5.865s, learning 0.401s)
             Mean action noise std: 4.04
          Mean value_function loss: 78.0927
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 60.6716
                       Mean reward: 708.44
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.0043
    Episode_Reward/rotating_object: 138.7243
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 6.27s
                      Time elapsed: 01:11:37
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 18168 steps/s (collection: 5.017s, learning 0.394s)
             Mean action noise std: 4.04
          Mean value_function loss: 80.1861
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.6827
                       Mean reward: 706.92
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 0.9950
    Episode_Reward/rotating_object: 137.5825
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 5.41s
                      Time elapsed: 01:11:43
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 17798 steps/s (collection: 5.116s, learning 0.407s)
             Mean action noise std: 4.04
          Mean value_function loss: 81.3811
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.6998
                       Mean reward: 725.18
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 0.9853
    Episode_Reward/rotating_object: 140.8654
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 5.52s
                      Time elapsed: 01:11:48
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 19827 steps/s (collection: 4.633s, learning 0.325s)
             Mean action noise std: 4.05
          Mean value_function loss: 77.0693
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.7134
                       Mean reward: 715.90
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 0.9968
    Episode_Reward/rotating_object: 139.0805
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 4.96s
                      Time elapsed: 01:11:53
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 18047 steps/s (collection: 5.067s, learning 0.379s)
             Mean action noise std: 4.05
          Mean value_function loss: 70.4456
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.7269
                       Mean reward: 725.24
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 1.0066
    Episode_Reward/rotating_object: 143.8873
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 5.45s
                      Time elapsed: 01:11:59
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 19217 steps/s (collection: 4.688s, learning 0.427s)
             Mean action noise std: 4.05
          Mean value_function loss: 53.1733
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 60.7373
                       Mean reward: 738.59
               Mean episode length: 243.07
    Episode_Reward/reaching_object: 1.0027
    Episode_Reward/rotating_object: 142.4331
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 5.12s
                      Time elapsed: 01:12:04
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 18693 steps/s (collection: 5.017s, learning 0.242s)
             Mean action noise std: 4.05
          Mean value_function loss: 82.1374
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.7419
                       Mean reward: 681.57
               Mean episode length: 225.40
    Episode_Reward/reaching_object: 0.9803
    Episode_Reward/rotating_object: 135.4613
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 5.26s
                      Time elapsed: 01:12:09
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 18402 steps/s (collection: 4.900s, learning 0.442s)
             Mean action noise std: 4.05
          Mean value_function loss: 76.5872
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.7501
                       Mean reward: 728.85
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 0.9923
    Episode_Reward/rotating_object: 142.1342
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 5.34s
                      Time elapsed: 01:12:14
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 19052 steps/s (collection: 4.737s, learning 0.422s)
             Mean action noise std: 4.05
          Mean value_function loss: 76.0765
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.7612
                       Mean reward: 701.34
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 140.7866
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 5.16s
                      Time elapsed: 01:12:19
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 16973 steps/s (collection: 5.335s, learning 0.456s)
             Mean action noise std: 4.06
          Mean value_function loss: 71.3304
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.7737
                       Mean reward: 726.56
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 0.9936
    Episode_Reward/rotating_object: 139.8890
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 5.79s
                      Time elapsed: 01:12:25
                               ETA: 00:02:54

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 16144 steps/s (collection: 5.764s, learning 0.325s)
             Mean action noise std: 4.06
          Mean value_function loss: 59.0760
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.7898
                       Mean reward: 731.51
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0094
    Episode_Reward/rotating_object: 144.4013
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 6.09s
                      Time elapsed: 01:12:31
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 18673 steps/s (collection: 4.825s, learning 0.440s)
             Mean action noise std: 4.06
          Mean value_function loss: 61.3752
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.8019
                       Mean reward: 734.33
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 141.6011
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 5.26s
                      Time elapsed: 01:12:37
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 20171 steps/s (collection: 4.546s, learning 0.327s)
             Mean action noise std: 4.06
          Mean value_function loss: 67.5459
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.8157
                       Mean reward: 722.73
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 0.9763
    Episode_Reward/rotating_object: 136.9387
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 4.87s
                      Time elapsed: 01:12:41
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 20490 steps/s (collection: 4.517s, learning 0.281s)
             Mean action noise std: 4.07
          Mean value_function loss: 67.6742
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.8272
                       Mean reward: 708.22
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.0057
    Episode_Reward/rotating_object: 142.1525
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 4.80s
                      Time elapsed: 01:12:46
                               ETA: 00:02:42

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 16373 steps/s (collection: 5.642s, learning 0.362s)
             Mean action noise std: 4.07
          Mean value_function loss: 62.8984
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.8356
                       Mean reward: 762.95
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 1.0077
    Episode_Reward/rotating_object: 144.9420
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 6.00s
                      Time elapsed: 01:12:52
                               ETA: 00:02:40

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 17839 steps/s (collection: 5.169s, learning 0.342s)
             Mean action noise std: 4.07
          Mean value_function loss: 77.0159
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.8468
                       Mean reward: 730.68
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.0115
    Episode_Reward/rotating_object: 143.3922
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 5.51s
                      Time elapsed: 01:12:58
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 17283 steps/s (collection: 5.286s, learning 0.402s)
             Mean action noise std: 4.07
          Mean value_function loss: 68.8216
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.8545
                       Mean reward: 733.16
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 0.9893
    Episode_Reward/rotating_object: 139.7238
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 5.69s
                      Time elapsed: 01:13:03
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 17430 steps/s (collection: 5.247s, learning 0.393s)
             Mean action noise std: 4.07
          Mean value_function loss: 90.2450
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.8626
                       Mean reward: 676.46
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 0.9820
    Episode_Reward/rotating_object: 138.8306
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 5.64s
                      Time elapsed: 01:13:09
                               ETA: 00:02:31

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 17996 steps/s (collection: 5.170s, learning 0.292s)
             Mean action noise std: 4.08
          Mean value_function loss: 79.7899
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.8736
                       Mean reward: 686.26
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 0.9667
    Episode_Reward/rotating_object: 133.6026
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 5.46s
                      Time elapsed: 01:13:15
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 20941 steps/s (collection: 4.421s, learning 0.274s)
             Mean action noise std: 4.08
          Mean value_function loss: 72.0454
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.8912
                       Mean reward: 719.46
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 0.9885
    Episode_Reward/rotating_object: 141.5334
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 4.69s
                      Time elapsed: 01:13:19
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 18548 steps/s (collection: 4.878s, learning 0.422s)
             Mean action noise std: 4.08
          Mean value_function loss: 74.5812
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.9109
                       Mean reward: 736.88
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 1.0003
    Episode_Reward/rotating_object: 139.5369
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 5.30s
                      Time elapsed: 01:13:25
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 19070 steps/s (collection: 4.796s, learning 0.358s)
             Mean action noise std: 4.09
          Mean value_function loss: 77.6207
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.9301
                       Mean reward: 724.83
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 0.9844
    Episode_Reward/rotating_object: 138.3497
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 5.15s
                      Time elapsed: 01:13:30
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 19088 steps/s (collection: 4.809s, learning 0.341s)
             Mean action noise std: 4.09
          Mean value_function loss: 73.4859
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.9479
                       Mean reward: 683.16
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.9918
    Episode_Reward/rotating_object: 138.2596
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 5.15s
                      Time elapsed: 01:13:35
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 18629 steps/s (collection: 4.882s, learning 0.395s)
             Mean action noise std: 4.09
          Mean value_function loss: 79.8436
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.9661
                       Mean reward: 704.63
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 0.9983
    Episode_Reward/rotating_object: 139.7645
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 5.28s
                      Time elapsed: 01:13:40
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 20924 steps/s (collection: 4.433s, learning 0.265s)
             Mean action noise std: 4.10
          Mean value_function loss: 82.2209
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.9864
                       Mean reward: 692.92
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 0.9921
    Episode_Reward/rotating_object: 139.5258
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 4.70s
                      Time elapsed: 01:13:45
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 18357 steps/s (collection: 5.069s, learning 0.287s)
             Mean action noise std: 4.10
          Mean value_function loss: 77.4249
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.0007
                       Mean reward: 696.37
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 0.9825
    Episode_Reward/rotating_object: 136.2070
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 5.36s
                      Time elapsed: 01:13:50
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 18970 steps/s (collection: 4.844s, learning 0.338s)
             Mean action noise std: 4.10
          Mean value_function loss: 67.6776
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.0144
                       Mean reward: 735.61
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.9936
    Episode_Reward/rotating_object: 139.5494
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 5.18s
                      Time elapsed: 01:13:55
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 19880 steps/s (collection: 4.628s, learning 0.317s)
             Mean action noise std: 4.10
          Mean value_function loss: 93.1572
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.0282
                       Mean reward: 689.81
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 141.2342
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 4.94s
                      Time elapsed: 01:14:00
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 19356 steps/s (collection: 4.596s, learning 0.482s)
             Mean action noise std: 4.11
          Mean value_function loss: 90.4542
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.0438
                       Mean reward: 690.95
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 0.9769
    Episode_Reward/rotating_object: 136.1534
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 5.08s
                      Time elapsed: 01:14:05
                               ETA: 00:01:58

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 18470 steps/s (collection: 5.030s, learning 0.292s)
             Mean action noise std: 4.11
          Mean value_function loss: 82.4214
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.0603
                       Mean reward: 721.57
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.9965
    Episode_Reward/rotating_object: 139.1234
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 5.32s
                      Time elapsed: 01:14:11
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 19043 steps/s (collection: 4.693s, learning 0.469s)
             Mean action noise std: 4.11
          Mean value_function loss: 69.3627
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 61.0717
                       Mean reward: 693.63
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 0.9751
    Episode_Reward/rotating_object: 139.1838
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 5.16s
                      Time elapsed: 01:14:16
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 17846 steps/s (collection: 5.150s, learning 0.359s)
             Mean action noise std: 4.11
          Mean value_function loss: 83.4837
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.0830
                       Mean reward: 706.13
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 137.8799
        Episode_Reward/action_rate: -0.0890
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 5.51s
                      Time elapsed: 01:14:21
                               ETA: 00:01:49

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 18127 steps/s (collection: 5.122s, learning 0.301s)
             Mean action noise std: 4.12
          Mean value_function loss: 74.4038
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.0972
                       Mean reward: 719.05
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 0.9894
    Episode_Reward/rotating_object: 137.3070
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 5.42s
                      Time elapsed: 01:14:27
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 18306 steps/s (collection: 4.981s, learning 0.389s)
             Mean action noise std: 4.12
          Mean value_function loss: 72.7233
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.1137
                       Mean reward: 666.51
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 0.9962
    Episode_Reward/rotating_object: 138.7958
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 5.37s
                      Time elapsed: 01:14:32
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 20047 steps/s (collection: 4.547s, learning 0.357s)
             Mean action noise std: 4.12
          Mean value_function loss: 82.9828
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.1263
                       Mean reward: 707.66
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 0.9794
    Episode_Reward/rotating_object: 137.2397
        Episode_Reward/action_rate: -0.0883
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 4.90s
                      Time elapsed: 01:14:37
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 20325 steps/s (collection: 4.508s, learning 0.328s)
             Mean action noise std: 4.12
          Mean value_function loss: 81.9415
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.1371
                       Mean reward: 666.83
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 0.9776
    Episode_Reward/rotating_object: 137.4743
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 4.84s
                      Time elapsed: 01:14:42
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 18497 steps/s (collection: 5.087s, learning 0.228s)
             Mean action noise std: 4.13
          Mean value_function loss: 68.3615
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.1441
                       Mean reward: 700.18
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 0.9819
    Episode_Reward/rotating_object: 138.9330
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 5.31s
                      Time elapsed: 01:14:47
                               ETA: 00:01:34

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 18672 steps/s (collection: 4.941s, learning 0.324s)
             Mean action noise std: 4.13
          Mean value_function loss: 58.1596
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.1511
                       Mean reward: 736.84
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 1.0058
    Episode_Reward/rotating_object: 140.6107
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 5.26s
                      Time elapsed: 01:14:53
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 17638 steps/s (collection: 5.263s, learning 0.310s)
             Mean action noise std: 4.13
          Mean value_function loss: 92.7286
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.1578
                       Mean reward: 684.06
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 140.7504
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 5.57s
                      Time elapsed: 01:14:58
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 17595 steps/s (collection: 5.214s, learning 0.373s)
             Mean action noise std: 4.13
          Mean value_function loss: 94.8964
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.1653
                       Mean reward: 685.24
               Mean episode length: 233.70
    Episode_Reward/reaching_object: 0.9960
    Episode_Reward/rotating_object: 140.2388
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 5.59s
                      Time elapsed: 01:15:04
                               ETA: 00:01:25

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 18413 steps/s (collection: 4.990s, learning 0.349s)
             Mean action noise std: 4.13
          Mean value_function loss: 84.1536
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.1775
                       Mean reward: 622.87
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 0.9686
    Episode_Reward/rotating_object: 133.4483
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 5.34s
                      Time elapsed: 01:15:09
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 17968 steps/s (collection: 5.114s, learning 0.357s)
             Mean action noise std: 4.13
          Mean value_function loss: 73.9562
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.1870
                       Mean reward: 669.13
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 0.9803
    Episode_Reward/rotating_object: 133.8586
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 5.47s
                      Time elapsed: 01:15:14
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 19488 steps/s (collection: 4.659s, learning 0.385s)
             Mean action noise std: 4.14
          Mean value_function loss: 76.7345
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.1967
                       Mean reward: 708.31
               Mean episode length: 232.34
    Episode_Reward/reaching_object: 0.9970
    Episode_Reward/rotating_object: 140.1024
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 5.04s
                      Time elapsed: 01:15:20
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 16801 steps/s (collection: 5.580s, learning 0.271s)
             Mean action noise std: 4.14
          Mean value_function loss: 59.7504
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.2096
                       Mean reward: 725.85
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 1.0056
    Episode_Reward/rotating_object: 141.9906
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 5.85s
                      Time elapsed: 01:15:25
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 17687 steps/s (collection: 5.187s, learning 0.371s)
             Mean action noise std: 4.14
          Mean value_function loss: 67.3470
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.2176
                       Mean reward: 725.76
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 1.0056
    Episode_Reward/rotating_object: 137.2542
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 5.56s
                      Time elapsed: 01:15:31
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 17902 steps/s (collection: 5.204s, learning 0.287s)
             Mean action noise std: 4.14
          Mean value_function loss: 65.8809
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.2310
                       Mean reward: 726.05
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 143.1232
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 5.49s
                      Time elapsed: 01:15:36
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 18122 steps/s (collection: 5.019s, learning 0.406s)
             Mean action noise std: 4.15
          Mean value_function loss: 79.1287
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.2432
                       Mean reward: 692.90
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 0.9892
    Episode_Reward/rotating_object: 137.3042
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 5.42s
                      Time elapsed: 01:15:42
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 17737 steps/s (collection: 5.197s, learning 0.345s)
             Mean action noise std: 4.15
          Mean value_function loss: 78.1884
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.2528
                       Mean reward: 694.86
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.0031
    Episode_Reward/rotating_object: 140.0553
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 5.54s
                      Time elapsed: 01:15:47
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 18976 steps/s (collection: 4.843s, learning 0.337s)
             Mean action noise std: 4.15
          Mean value_function loss: 68.9448
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.2641
                       Mean reward: 708.88
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.9973
    Episode_Reward/rotating_object: 137.5636
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 5.18s
                      Time elapsed: 01:15:53
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 22671 steps/s (collection: 4.078s, learning 0.258s)
             Mean action noise std: 4.15
          Mean value_function loss: 86.7844
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.2768
                       Mean reward: 671.87
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 0.9656
    Episode_Reward/rotating_object: 134.4522
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 4.34s
                      Time elapsed: 01:15:57
                               ETA: 00:00:55

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 25310 steps/s (collection: 3.638s, learning 0.246s)
             Mean action noise std: 4.16
          Mean value_function loss: 67.2279
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.2903
                       Mean reward: 721.33
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 0.9973
    Episode_Reward/rotating_object: 139.0583
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 3.88s
                      Time elapsed: 01:16:01
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 19871 steps/s (collection: 4.606s, learning 0.341s)
             Mean action noise std: 4.16
          Mean value_function loss: 82.6980
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.3049
                       Mean reward: 748.13
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 0.9964
    Episode_Reward/rotating_object: 142.8480
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 4.95s
                      Time elapsed: 01:16:06
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 18042 steps/s (collection: 5.045s, learning 0.403s)
             Mean action noise std: 4.16
          Mean value_function loss: 67.5925
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3104
                       Mean reward: 740.03
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 0.9921
    Episode_Reward/rotating_object: 139.0923
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 5.45s
                      Time elapsed: 01:16:11
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 18843 steps/s (collection: 4.928s, learning 0.289s)
             Mean action noise std: 4.16
          Mean value_function loss: 69.1552
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.3187
                       Mean reward: 686.82
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 0.9901
    Episode_Reward/rotating_object: 139.2192
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 5.22s
                      Time elapsed: 01:16:16
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 19602 steps/s (collection: 4.658s, learning 0.357s)
             Mean action noise std: 4.16
          Mean value_function loss: 63.1259
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.3345
                       Mean reward: 726.62
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 1.0111
    Episode_Reward/rotating_object: 144.3661
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 5.01s
                      Time elapsed: 01:16:21
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 18695 steps/s (collection: 4.883s, learning 0.375s)
             Mean action noise std: 4.17
          Mean value_function loss: 70.7502
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.3460
                       Mean reward: 707.87
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 0.9988
    Episode_Reward/rotating_object: 140.0845
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 5.26s
                      Time elapsed: 01:16:27
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 18490 steps/s (collection: 5.023s, learning 0.294s)
             Mean action noise std: 4.17
          Mean value_function loss: 72.2542
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.3547
                       Mean reward: 703.99
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0095
    Episode_Reward/rotating_object: 143.9144
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 5.32s
                      Time elapsed: 01:16:32
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 17880 steps/s (collection: 5.203s, learning 0.295s)
             Mean action noise std: 4.17
          Mean value_function loss: 98.8184
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 61.3660
                       Mean reward: 688.95
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 0.9874
    Episode_Reward/rotating_object: 137.1306
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 5.50s
                      Time elapsed: 01:16:37
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 19927 steps/s (collection: 4.604s, learning 0.329s)
             Mean action noise std: 4.17
          Mean value_function loss: 85.0765
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.3745
                       Mean reward: 716.77
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 0.9704
    Episode_Reward/rotating_object: 137.1102
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 4.93s
                      Time elapsed: 01:16:42
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 17541 steps/s (collection: 5.212s, learning 0.392s)
             Mean action noise std: 4.17
          Mean value_function loss: 76.1800
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3814
                       Mean reward: 712.04
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.0036
    Episode_Reward/rotating_object: 143.1440
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 5.60s
                      Time elapsed: 01:16:48
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 17541 steps/s (collection: 5.221s, learning 0.383s)
             Mean action noise std: 4.17
          Mean value_function loss: 73.3419
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.3873
                       Mean reward: 695.03
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 1.0040
    Episode_Reward/rotating_object: 143.2052
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 5.60s
                      Time elapsed: 01:16:54
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 16851 steps/s (collection: 5.394s, learning 0.440s)
             Mean action noise std: 4.18
          Mean value_function loss: 61.0390
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3982
                       Mean reward: 675.43
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 0.9732
    Episode_Reward/rotating_object: 138.5142
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 5.83s
                      Time elapsed: 01:16:59
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 17035 steps/s (collection: 5.337s, learning 0.434s)
             Mean action noise std: 4.18
          Mean value_function loss: 69.1791
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.4109
                       Mean reward: 720.06
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 0.9850
    Episode_Reward/rotating_object: 139.2859
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 5.77s
                      Time elapsed: 01:17:05
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 17335 steps/s (collection: 5.352s, learning 0.318s)
             Mean action noise std: 4.18
          Mean value_function loss: 64.3167
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.4233
                       Mean reward: 671.49
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 137.8711
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 5.67s
                      Time elapsed: 01:17:11
                               ETA: 00:00:12

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 19218 steps/s (collection: 4.912s, learning 0.203s)
             Mean action noise std: 4.18
          Mean value_function loss: 71.2149
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.4334
                       Mean reward: 734.66
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 0.9784
    Episode_Reward/rotating_object: 139.9369
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 5.12s
                      Time elapsed: 01:17:16
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 19110 steps/s (collection: 4.724s, learning 0.420s)
             Mean action noise std: 4.19
          Mean value_function loss: 78.3236
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.4442
                       Mean reward: 698.84
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 0.9764
    Episode_Reward/rotating_object: 138.0584
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 5.14s
                      Time elapsed: 01:17:21
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 19825 steps/s (collection: 4.583s, learning 0.376s)
             Mean action noise std: 4.19
          Mean value_function loss: 67.4657
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.4550
                       Mean reward: 688.39
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 0.9741
    Episode_Reward/rotating_object: 137.5276
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 4.96s
                      Time elapsed: 01:17:26
                               ETA: 00:00:03

