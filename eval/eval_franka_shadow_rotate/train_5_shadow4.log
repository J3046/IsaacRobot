################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 22031 steps/s (collection: 4.337s, learning 0.125s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0049
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 36.9316
                       Mean reward: 0.00
               Mean episode length: 21.40
    Episode_Reward/reaching_object: 0.0008
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 4.46s
                      Time elapsed: 00:00:04
                               ETA: 01:51:32

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 49158 steps/s (collection: 1.885s, learning 0.115s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.0430
                       Mean reward: 0.00
               Mean episode length: 45.09
    Episode_Reward/reaching_object: 0.0023
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0008
          Episode_Reward/joint_vel: -0.0011
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 2.00s
                      Time elapsed: 00:00:06
                               ETA: 01:20:43

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 48635 steps/s (collection: 1.908s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.1118
                       Mean reward: 0.00
               Mean episode length: 69.30
    Episode_Reward/reaching_object: 0.0039
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0013
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 2.02s
                      Time elapsed: 00:00:08
                               ETA: 01:10:35

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 49824 steps/s (collection: 1.861s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.1299
                       Mean reward: 0.01
               Mean episode length: 93.06
    Episode_Reward/reaching_object: 0.0056
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0018
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.97s
                      Time elapsed: 00:00:10
                               ETA: 01:05:13

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 49161 steps/s (collection: 1.885s, learning 0.115s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 37.2112
                       Mean reward: 0.01
               Mean episode length: 117.24
    Episode_Reward/reaching_object: 0.0076
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 2.00s
                      Time elapsed: 00:00:12
                               ETA: 01:02:06

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 49725 steps/s (collection: 1.864s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.2599
                       Mean reward: 0.01
               Mean episode length: 141.16
    Episode_Reward/reaching_object: 0.0093
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.98s
                      Time elapsed: 00:00:14
                               ETA: 00:59:56

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 49643 steps/s (collection: 1.868s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.2891
                       Mean reward: 0.02
               Mean episode length: 165.69
    Episode_Reward/reaching_object: 0.0117
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.98s
                      Time elapsed: 00:00:16
                               ETA: 00:58:22

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 50603 steps/s (collection: 1.828s, learning 0.114s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 37.2773
                       Mean reward: 0.03
               Mean episode length: 189.43
    Episode_Reward/reaching_object: 0.0145
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0039
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.94s
                      Time elapsed: 00:00:18
                               ETA: 00:57:05

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 49009 steps/s (collection: 1.883s, learning 0.123s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 37.2867
                       Mean reward: 0.04
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 0.0179
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 2.01s
                      Time elapsed: 00:00:20
                               ETA: 00:56:15

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 50153 steps/s (collection: 1.839s, learning 0.121s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 37.3005
                       Mean reward: 0.07
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 0.0228
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.96s
                      Time elapsed: 00:00:22
                               ETA: 00:55:28

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 49596 steps/s (collection: 1.869s, learning 0.113s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 37.2989
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0254
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.98s
                      Time elapsed: 00:00:24
                               ETA: 00:54:51

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 51463 steps/s (collection: 1.798s, learning 0.113s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 37.3200
                       Mean reward: 0.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0315
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.91s
                      Time elapsed: 00:00:26
                               ETA: 00:54:12

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 51046 steps/s (collection: 1.811s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 37.3392
                       Mean reward: 0.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0365
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.93s
                      Time elapsed: 00:00:28
                               ETA: 00:53:40

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 51298 steps/s (collection: 1.802s, learning 0.114s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 37.3535
                       Mean reward: 0.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0421
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.92s
                      Time elapsed: 00:00:30
                               ETA: 00:53:12

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 51260 steps/s (collection: 1.804s, learning 0.114s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 37.3872
                       Mean reward: 0.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0578
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.92s
                      Time elapsed: 00:00:31
                               ETA: 00:52:47

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 51173 steps/s (collection: 1.808s, learning 0.113s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 37.4219
                       Mean reward: 0.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0712
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.92s
                      Time elapsed: 00:00:33
                               ETA: 00:52:25

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 50217 steps/s (collection: 1.841s, learning 0.117s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0010
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 37.4694
                       Mean reward: 0.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0955
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.96s
                      Time elapsed: 00:00:35
                               ETA: 00:52:09

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 49535 steps/s (collection: 1.871s, learning 0.113s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0014
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 37.5568
                       Mean reward: 0.66
               Mean episode length: 249.97
    Episode_Reward/reaching_object: 0.1246
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.98s
                      Time elapsed: 00:00:37
                               ETA: 00:51:57

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 48065 steps/s (collection: 1.930s, learning 0.115s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0019
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 37.5965
                       Mean reward: 0.77
               Mean episode length: 249.22
    Episode_Reward/reaching_object: 0.1517
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 2.05s
                      Time elapsed: 00:00:39
                               ETA: 00:51:50

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 46184 steps/s (collection: 2.008s, learning 0.121s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 37.6549
                       Mean reward: 0.94
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 0.1930
    Episode_Reward/rotating_object: 0.0004
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 2.13s
                      Time elapsed: 00:00:42
                               ETA: 00:51:50

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 45380 steps/s (collection: 2.049s, learning 0.117s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0060
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 37.7314
                       Mean reward: 1.21
               Mean episode length: 245.21
    Episode_Reward/reaching_object: 0.2330
    Episode_Reward/rotating_object: 0.0007
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 2.17s
                      Time elapsed: 00:00:44
                               ETA: 00:51:53

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 44527 steps/s (collection: 2.092s, learning 0.115s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0050
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 37.7908
                       Mean reward: 1.53
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.2835
    Episode_Reward/rotating_object: 0.0022
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 2.21s
                      Time elapsed: 00:00:46
                               ETA: 00:51:58

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 43976 steps/s (collection: 2.120s, learning 0.116s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0069
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 37.8811
                       Mean reward: 1.52
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 0.3049
    Episode_Reward/rotating_object: 0.0024
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 9.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 2.24s
                      Time elapsed: 00:00:48
                               ETA: 00:52:04

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 43304 steps/s (collection: 2.155s, learning 0.115s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0083
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 37.9509
                       Mean reward: 1.79
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 0.3384
    Episode_Reward/rotating_object: 0.0109
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 8.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.27s
                      Time elapsed: 00:00:50
                               ETA: 00:52:11

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 43040 steps/s (collection: 2.170s, learning 0.114s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 38.0284
                       Mean reward: 1.93
               Mean episode length: 223.76
    Episode_Reward/reaching_object: 0.3603
    Episode_Reward/rotating_object: 0.0089
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 7.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.28s
                      Time elapsed: 00:00:53
                               ETA: 00:52:19

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 43058 steps/s (collection: 2.155s, learning 0.128s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0206
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 38.1812
                       Mean reward: 1.90
               Mean episode length: 217.51
    Episode_Reward/reaching_object: 0.3897
    Episode_Reward/rotating_object: 0.0181
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 4.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 19.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.28s
                      Time elapsed: 00:00:55
                               ETA: 00:52:26

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 43265 steps/s (collection: 2.158s, learning 0.114s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0694
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.2957
                       Mean reward: 1.97
               Mean episode length: 208.44
    Episode_Reward/reaching_object: 0.4050
    Episode_Reward/rotating_object: 0.0352
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 2.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.27s
                      Time elapsed: 00:00:57
                               ETA: 00:52:31

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 42739 steps/s (collection: 2.173s, learning 0.127s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0366
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 38.3782
                       Mean reward: 2.19
               Mean episode length: 206.71
    Episode_Reward/reaching_object: 0.4253
    Episode_Reward/rotating_object: 0.0423
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 2.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 17.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.30s
                      Time elapsed: 00:01:00
                               ETA: 00:52:37

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 41885 steps/s (collection: 2.226s, learning 0.121s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0787
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 38.5231
                       Mean reward: 2.28
               Mean episode length: 197.33
    Episode_Reward/reaching_object: 0.4570
    Episode_Reward/rotating_object: 0.0346
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 2.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.35s
                      Time elapsed: 00:01:02
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 42363 steps/s (collection: 2.207s, learning 0.113s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1842
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.6496
                       Mean reward: 3.11
               Mean episode length: 202.49
    Episode_Reward/reaching_object: 0.5024
    Episode_Reward/rotating_object: 0.0755
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 3.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.32s
                      Time elapsed: 00:01:04
                               ETA: 00:52:52

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 41330 steps/s (collection: 2.265s, learning 0.114s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.3076
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.7053
                       Mean reward: 3.68
               Mean episode length: 202.11
    Episode_Reward/reaching_object: 0.5404
    Episode_Reward/rotating_object: 0.1483
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 3.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.38s
                      Time elapsed: 00:01:07
                               ETA: 00:53:00

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 41591 steps/s (collection: 2.249s, learning 0.114s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3531
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.8730
                       Mean reward: 3.60
               Mean episode length: 214.96
    Episode_Reward/reaching_object: 0.5941
    Episode_Reward/rotating_object: 0.1174
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 5.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.36s
                      Time elapsed: 00:01:09
                               ETA: 00:53:07

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 41449 steps/s (collection: 2.257s, learning 0.114s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.5789
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.0359
                       Mean reward: 4.66
               Mean episode length: 214.72
    Episode_Reward/reaching_object: 0.6419
    Episode_Reward/rotating_object: 0.3189
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 6.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.37s
                      Time elapsed: 00:01:11
                               ETA: 00:53:14

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 41761 steps/s (collection: 2.240s, learning 0.114s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3182
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.1583
                       Mean reward: 4.01
               Mean episode length: 224.16
    Episode_Reward/reaching_object: 0.7131
    Episode_Reward/rotating_object: 0.1553
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 7.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.35s
                      Time elapsed: 00:01:14
                               ETA: 00:53:19

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 41291 steps/s (collection: 2.268s, learning 0.113s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.3653
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.3118
                       Mean reward: 4.60
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 0.7526
    Episode_Reward/rotating_object: 0.3672
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 10.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.38s
                      Time elapsed: 00:01:16
                               ETA: 00:53:26

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 41798 steps/s (collection: 2.239s, learning 0.112s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5814
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 39.4273
                       Mean reward: 5.18
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 0.7976
    Episode_Reward/rotating_object: 0.2239
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.35s
                      Time elapsed: 00:01:18
                               ETA: 00:53:30

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 41641 steps/s (collection: 2.248s, learning 0.113s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4363
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.4972
                       Mean reward: 7.80
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 0.8281
    Episode_Reward/rotating_object: 0.3704
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.36s
                      Time elapsed: 00:01:21
                               ETA: 00:53:35

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 41928 steps/s (collection: 2.233s, learning 0.112s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.7017
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.6474
                       Mean reward: 6.32
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 0.9151
    Episode_Reward/rotating_object: 0.3369
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.34s
                      Time elapsed: 00:01:23
                               ETA: 00:53:38

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 41682 steps/s (collection: 2.246s, learning 0.112s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.6212
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.7770
                       Mean reward: 5.72
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 0.9034
    Episode_Reward/rotating_object: 0.3993
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.36s
                      Time elapsed: 00:01:25
                               ETA: 00:53:42

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 41489 steps/s (collection: 2.254s, learning 0.115s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.8603
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.9034
                       Mean reward: 5.97
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 0.9114
    Episode_Reward/rotating_object: 0.6419
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.37s
                      Time elapsed: 00:01:28
                               ETA: 00:53:46

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 41248 steps/s (collection: 2.266s, learning 0.117s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.8188
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.0484
                       Mean reward: 5.28
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.8843
    Episode_Reward/rotating_object: 0.6791
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.38s
                      Time elapsed: 00:01:30
                               ETA: 00:53:50

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 40893 steps/s (collection: 2.289s, learning 0.114s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.2410
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 40.2098
                       Mean reward: 7.69
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 0.8999
    Episode_Reward/rotating_object: 0.4857
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.40s
                      Time elapsed: 00:01:33
                               ETA: 00:53:54

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 41228 steps/s (collection: 2.272s, learning 0.112s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.5123
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 40.3747
                       Mean reward: 5.86
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 0.9276
    Episode_Reward/rotating_object: 0.6609
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.38s
                      Time elapsed: 00:01:35
                               ETA: 00:53:58

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 40255 steps/s (collection: 2.327s, learning 0.115s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.2999
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.5154
                       Mean reward: 10.39
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 0.9025
    Episode_Reward/rotating_object: 0.9511
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.44s
                      Time elapsed: 00:01:37
                               ETA: 00:54:03

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 40183 steps/s (collection: 2.331s, learning 0.116s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.5440
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.6428
                       Mean reward: 9.12
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 0.9088
    Episode_Reward/rotating_object: 0.6890
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.45s
                      Time elapsed: 00:01:40
                               ETA: 00:54:08

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 40177 steps/s (collection: 2.329s, learning 0.117s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.5762
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.6839
                       Mean reward: 9.81
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.8962
    Episode_Reward/rotating_object: 0.7928
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.45s
                      Time elapsed: 00:01:42
                               ETA: 00:54:12

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 40454 steps/s (collection: 2.315s, learning 0.115s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.6116
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.8047
                       Mean reward: 12.43
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.9587
    Episode_Reward/rotating_object: 1.0141
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.43s
                      Time elapsed: 00:01:45
                               ETA: 00:54:16

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 40902 steps/s (collection: 2.291s, learning 0.112s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.1678
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.9195
                       Mean reward: 8.29
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 0.9177
    Episode_Reward/rotating_object: 0.9765
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.40s
                      Time elapsed: 00:01:47
                               ETA: 00:54:19

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 40815 steps/s (collection: 2.292s, learning 0.117s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.5760
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.9895
                       Mean reward: 7.15
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 0.9517
    Episode_Reward/rotating_object: 1.0396
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.41s
                      Time elapsed: 00:01:50
                               ETA: 00:54:21

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 40799 steps/s (collection: 2.290s, learning 0.119s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.9547
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 41.1314
                       Mean reward: 9.65
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 0.9540
    Episode_Reward/rotating_object: 0.9014
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.41s
                      Time elapsed: 00:01:52
                               ETA: 00:54:24

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 40669 steps/s (collection: 2.304s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.6562
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.1622
                       Mean reward: 11.09
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 0.9818
    Episode_Reward/rotating_object: 1.1263
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.42s
                      Time elapsed: 00:01:54
                               ETA: 00:54:26

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 41103 steps/s (collection: 2.276s, learning 0.116s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.8635
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.2447
                       Mean reward: 14.70
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 0.9907
    Episode_Reward/rotating_object: 1.3377
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.39s
                      Time elapsed: 00:01:57
                               ETA: 00:54:28

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 40970 steps/s (collection: 2.288s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.2227
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.3539
                       Mean reward: 9.53
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 0.9917
    Episode_Reward/rotating_object: 1.1059
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.40s
                      Time elapsed: 00:01:59
                               ETA: 00:54:30

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 40637 steps/s (collection: 2.306s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.6931
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 41.4802
                       Mean reward: 8.68
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.9488
    Episode_Reward/rotating_object: 1.4494
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.42s
                      Time elapsed: 00:02:02
                               ETA: 00:54:32

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 41353 steps/s (collection: 2.264s, learning 0.114s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.0760
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 41.5804
                       Mean reward: 19.07
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 0.9412
    Episode_Reward/rotating_object: 1.4527
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.38s
                      Time elapsed: 00:02:04
                               ETA: 00:54:32

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 41385 steps/s (collection: 2.259s, learning 0.116s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.0137
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 41.6086
                       Mean reward: 19.46
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.9399
    Episode_Reward/rotating_object: 1.5845
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.38s
                      Time elapsed: 00:02:06
                               ETA: 00:54:33

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 41257 steps/s (collection: 2.269s, learning 0.113s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.1675
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.6528
                       Mean reward: 11.69
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.9571
    Episode_Reward/rotating_object: 1.6416
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.38s
                      Time elapsed: 00:02:09
                               ETA: 00:54:34

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 41672 steps/s (collection: 2.245s, learning 0.114s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.3986
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.7288
                       Mean reward: 17.50
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.9713
    Episode_Reward/rotating_object: 2.1137
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.36s
                      Time elapsed: 00:02:11
                               ETA: 00:54:34

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 41701 steps/s (collection: 2.243s, learning 0.115s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.0081
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 41.7892
                       Mean reward: 12.45
               Mean episode length: 245.20
    Episode_Reward/reaching_object: 0.9506
    Episode_Reward/rotating_object: 1.7399
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.36s
                      Time elapsed: 00:02:13
                               ETA: 00:54:34

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 41247 steps/s (collection: 2.270s, learning 0.113s)
             Mean action noise std: 1.21
          Mean value_function loss: 4.2548
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.8214
                       Mean reward: 18.04
               Mean episode length: 248.79
    Episode_Reward/reaching_object: 0.9513
    Episode_Reward/rotating_object: 2.9112
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.38s
                      Time elapsed: 00:02:16
                               ETA: 00:54:34

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 41276 steps/s (collection: 2.266s, learning 0.115s)
             Mean action noise std: 1.21
          Mean value_function loss: 4.4256
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.8741
                       Mean reward: 19.48
               Mean episode length: 245.25
    Episode_Reward/reaching_object: 0.9440
    Episode_Reward/rotating_object: 2.5619
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.38s
                      Time elapsed: 00:02:18
                               ETA: 00:54:34

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 40582 steps/s (collection: 2.306s, learning 0.116s)
             Mean action noise std: 1.22
          Mean value_function loss: 4.4560
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 41.9454
                       Mean reward: 19.11
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 0.9416
    Episode_Reward/rotating_object: 2.8604
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.42s
                      Time elapsed: 00:02:21
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 40762 steps/s (collection: 2.297s, learning 0.115s)
             Mean action noise std: 1.22
          Mean value_function loss: 4.0712
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.9852
                       Mean reward: 18.23
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 0.9404
    Episode_Reward/rotating_object: 1.9602
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.41s
                      Time elapsed: 00:02:23
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 40675 steps/s (collection: 2.298s, learning 0.119s)
             Mean action noise std: 1.22
          Mean value_function loss: 3.4633
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.0718
                       Mean reward: 10.28
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.9530
    Episode_Reward/rotating_object: 2.6477
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.42s
                      Time elapsed: 00:02:25
                               ETA: 00:54:37

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 41321 steps/s (collection: 2.255s, learning 0.124s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.0367
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.1447
                       Mean reward: 18.99
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.9489
    Episode_Reward/rotating_object: 2.8991
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.38s
                      Time elapsed: 00:02:28
                               ETA: 00:54:37

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 40840 steps/s (collection: 2.278s, learning 0.129s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.8660
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.2106
                       Mean reward: 13.21
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.9508
    Episode_Reward/rotating_object: 2.4923
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.41s
                      Time elapsed: 00:02:30
                               ETA: 00:54:38

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 40846 steps/s (collection: 2.293s, learning 0.114s)
             Mean action noise std: 1.23
          Mean value_function loss: 4.2220
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.2986
                       Mean reward: 21.59
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.9916
    Episode_Reward/rotating_object: 3.3045
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.41s
                      Time elapsed: 00:02:33
                               ETA: 00:54:38

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 41610 steps/s (collection: 2.247s, learning 0.116s)
             Mean action noise std: 1.24
          Mean value_function loss: 4.3584
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.3786
                       Mean reward: 18.34
               Mean episode length: 248.64
    Episode_Reward/reaching_object: 0.9701
    Episode_Reward/rotating_object: 2.5277
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.36s
                      Time elapsed: 00:02:35
                               ETA: 00:54:37

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 41090 steps/s (collection: 2.276s, learning 0.117s)
             Mean action noise std: 1.24
          Mean value_function loss: 4.7108
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.4374
                       Mean reward: 18.23
               Mean episode length: 246.79
    Episode_Reward/reaching_object: 0.9857
    Episode_Reward/rotating_object: 2.3087
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.39s
                      Time elapsed: 00:02:37
                               ETA: 00:54:37

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 41486 steps/s (collection: 2.253s, learning 0.117s)
             Mean action noise std: 1.25
          Mean value_function loss: 5.0107
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.5383
                       Mean reward: 21.23
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 0.9909
    Episode_Reward/rotating_object: 2.9314
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.37s
                      Time elapsed: 00:02:40
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 41391 steps/s (collection: 2.248s, learning 0.127s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.9384
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.6317
                       Mean reward: 14.25
               Mean episode length: 244.79
    Episode_Reward/reaching_object: 0.9837
    Episode_Reward/rotating_object: 2.9451
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.38s
                      Time elapsed: 00:02:42
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 40932 steps/s (collection: 2.289s, learning 0.112s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.6431
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.6649
                       Mean reward: 13.09
               Mean episode length: 244.75
    Episode_Reward/reaching_object: 0.9806
    Episode_Reward/rotating_object: 3.0497
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.40s
                      Time elapsed: 00:02:45
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 40389 steps/s (collection: 2.305s, learning 0.129s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.1392
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.7303
                       Mean reward: 18.74
               Mean episode length: 242.30
    Episode_Reward/reaching_object: 0.9359
    Episode_Reward/rotating_object: 3.7439
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.43s
                      Time elapsed: 00:02:47
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 41140 steps/s (collection: 2.262s, learning 0.127s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.3755
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.7634
                       Mean reward: 14.04
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.9570
    Episode_Reward/rotating_object: 3.2319
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.39s
                      Time elapsed: 00:02:49
                               ETA: 00:54:36

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 41740 steps/s (collection: 2.244s, learning 0.111s)
             Mean action noise std: 1.26
          Mean value_function loss: 4.8613
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 42.7908
                       Mean reward: 17.74
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.9228
    Episode_Reward/rotating_object: 2.6745
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.36s
                      Time elapsed: 00:02:52
                               ETA: 00:54:35

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 41444 steps/s (collection: 2.247s, learning 0.125s)
             Mean action noise std: 1.26
          Mean value_function loss: 5.3103
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 42.7995
                       Mean reward: 29.27
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 0.9479
    Episode_Reward/rotating_object: 3.5305
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.37s
                      Time elapsed: 00:02:54
                               ETA: 00:54:34

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 41756 steps/s (collection: 2.227s, learning 0.127s)
             Mean action noise std: 1.26
          Mean value_function loss: 4.6138
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 42.8080
                       Mean reward: 18.71
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.9170
    Episode_Reward/rotating_object: 3.3728
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.35s
                      Time elapsed: 00:02:56
                               ETA: 00:54:32

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 42018 steps/s (collection: 2.227s, learning 0.112s)
             Mean action noise std: 1.26
          Mean value_function loss: 4.3296
               Mean surrogate loss: 0.0039
                 Mean entropy loss: 42.8340
                       Mean reward: 15.18
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.9167
    Episode_Reward/rotating_object: 2.5822
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.34s
                      Time elapsed: 00:02:59
                               ETA: 00:54:31

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 41010 steps/s (collection: 2.284s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 4.0243
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 42.8428
                       Mean reward: 27.46
               Mean episode length: 244.44
    Episode_Reward/reaching_object: 0.9169
    Episode_Reward/rotating_object: 2.9435
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.40s
                      Time elapsed: 00:03:01
                               ETA: 00:54:30

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 41782 steps/s (collection: 2.241s, learning 0.112s)
             Mean action noise std: 1.26
          Mean value_function loss: 3.7758
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 42.8594
                       Mean reward: 20.44
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.9451
    Episode_Reward/rotating_object: 3.0810
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.35s
                      Time elapsed: 00:03:04
                               ETA: 00:54:29

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 42003 steps/s (collection: 2.221s, learning 0.120s)
             Mean action noise std: 1.26
          Mean value_function loss: 4.0869
               Mean surrogate loss: 0.0053
                 Mean entropy loss: 42.8702
                       Mean reward: 24.73
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.9115
    Episode_Reward/rotating_object: 4.1193
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.34s
                      Time elapsed: 00:03:06
                               ETA: 00:54:27

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 41602 steps/s (collection: 2.245s, learning 0.117s)
             Mean action noise std: 1.26
          Mean value_function loss: 4.2738
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 42.8783
                       Mean reward: 18.27
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 0.9486
    Episode_Reward/rotating_object: 2.8946
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.36s
                      Time elapsed: 00:03:08
                               ETA: 00:54:26

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 40724 steps/s (collection: 2.297s, learning 0.117s)
             Mean action noise std: 1.26
          Mean value_function loss: 3.7609
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 42.9050
                       Mean reward: 15.93
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.9159
    Episode_Reward/rotating_object: 3.4332
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.41s
                      Time elapsed: 00:03:11
                               ETA: 00:54:26

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 41554 steps/s (collection: 2.247s, learning 0.118s)
             Mean action noise std: 1.26
          Mean value_function loss: 3.6284
               Mean surrogate loss: 0.0032
                 Mean entropy loss: 42.9238
                       Mean reward: 16.81
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 0.9159
    Episode_Reward/rotating_object: 2.4292
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.37s
                      Time elapsed: 00:03:13
                               ETA: 00:54:25

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 41572 steps/s (collection: 2.252s, learning 0.112s)
             Mean action noise std: 1.26
          Mean value_function loss: 3.5406
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 42.9343
                       Mean reward: 16.47
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 0.9512
    Episode_Reward/rotating_object: 2.7064
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.36s
                      Time elapsed: 00:03:15
                               ETA: 00:54:23

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 41509 steps/s (collection: 2.256s, learning 0.113s)
             Mean action noise std: 1.27
          Mean value_function loss: 4.2226
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.9686
                       Mean reward: 24.62
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 0.9555
    Episode_Reward/rotating_object: 2.9276
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.37s
                      Time elapsed: 00:03:18
                               ETA: 00:54:22

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 41404 steps/s (collection: 2.258s, learning 0.117s)
             Mean action noise std: 1.27
          Mean value_function loss: 4.3762
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.0046
                       Mean reward: 21.64
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 0.9154
    Episode_Reward/rotating_object: 3.3408
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.37s
                      Time elapsed: 00:03:20
                               ETA: 00:54:21

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 41233 steps/s (collection: 2.269s, learning 0.115s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.3272
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.0534
                       Mean reward: 16.68
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 0.9558
    Episode_Reward/rotating_object: 3.0340
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.38s
                      Time elapsed: 00:03:23
                               ETA: 00:54:20

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 41411 steps/s (collection: 2.262s, learning 0.112s)
             Mean action noise std: 1.27
          Mean value_function loss: 6.1145
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.1202
                       Mean reward: 15.96
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.9523
    Episode_Reward/rotating_object: 3.0064
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.37s
                      Time elapsed: 00:03:25
                               ETA: 00:54:18

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 41700 steps/s (collection: 2.242s, learning 0.115s)
             Mean action noise std: 1.28
          Mean value_function loss: 5.5535
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.1735
                       Mean reward: 24.25
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.9705
    Episode_Reward/rotating_object: 3.7423
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.36s
                      Time elapsed: 00:03:27
                               ETA: 00:54:17

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 41554 steps/s (collection: 2.252s, learning 0.113s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.0935
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.2628
                       Mean reward: 20.85
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.9522
    Episode_Reward/rotating_object: 3.2476
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.37s
                      Time elapsed: 00:03:30
                               ETA: 00:54:16

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 41509 steps/s (collection: 2.241s, learning 0.127s)
             Mean action noise std: 1.29
          Mean value_function loss: 6.1873
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.3420
                       Mean reward: 26.97
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 0.9210
    Episode_Reward/rotating_object: 3.0358
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.37s
                      Time elapsed: 00:03:32
                               ETA: 00:54:14

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 41788 steps/s (collection: 2.240s, learning 0.113s)
             Mean action noise std: 1.29
          Mean value_function loss: 6.7821
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.4287
                       Mean reward: 21.81
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 0.9396
    Episode_Reward/rotating_object: 2.9689
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.35s
                      Time elapsed: 00:03:34
                               ETA: 00:54:12

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 41772 steps/s (collection: 2.239s, learning 0.114s)
             Mean action noise std: 1.29
          Mean value_function loss: 5.9601
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.4913
                       Mean reward: 22.98
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.9684
    Episode_Reward/rotating_object: 4.1826
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.35s
                      Time elapsed: 00:03:37
                               ETA: 00:54:11

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 41643 steps/s (collection: 2.237s, learning 0.124s)
             Mean action noise std: 1.29
          Mean value_function loss: 6.4351
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 43.5421
                       Mean reward: 23.10
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 0.9597
    Episode_Reward/rotating_object: 3.6733
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.36s
                      Time elapsed: 00:03:39
                               ETA: 00:54:09

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 41996 steps/s (collection: 2.228s, learning 0.113s)
             Mean action noise std: 1.29
          Mean value_function loss: 5.6083
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 43.5616
                       Mean reward: 22.46
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 0.9622
    Episode_Reward/rotating_object: 3.6537
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.34s
                      Time elapsed: 00:03:41
                               ETA: 00:54:07

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 42020 steps/s (collection: 2.226s, learning 0.113s)
             Mean action noise std: 1.30
          Mean value_function loss: 5.7783
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.5921
                       Mean reward: 31.76
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 0.9744
    Episode_Reward/rotating_object: 4.3159
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.34s
                      Time elapsed: 00:03:44
                               ETA: 00:54:05

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 42186 steps/s (collection: 2.217s, learning 0.113s)
             Mean action noise std: 1.30
          Mean value_function loss: 5.7356
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.6283
                       Mean reward: 17.49
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 0.9705
    Episode_Reward/rotating_object: 4.4848
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.33s
                      Time elapsed: 00:03:46
                               ETA: 00:54:03

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 42284 steps/s (collection: 2.198s, learning 0.127s)
             Mean action noise std: 1.30
          Mean value_function loss: 6.2376
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.7017
                       Mean reward: 15.97
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 0.9677
    Episode_Reward/rotating_object: 3.2672
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.32s
                      Time elapsed: 00:03:48
                               ETA: 00:54:01

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 42339 steps/s (collection: 2.208s, learning 0.114s)
             Mean action noise std: 1.31
          Mean value_function loss: 6.6255
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.7872
                       Mean reward: 20.21
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.9747
    Episode_Reward/rotating_object: 3.9319
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.32s
                      Time elapsed: 00:03:51
                               ETA: 00:53:59

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 42415 steps/s (collection: 2.201s, learning 0.116s)
             Mean action noise std: 1.31
          Mean value_function loss: 7.1228
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.8703
                       Mean reward: 27.49
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.9667
    Episode_Reward/rotating_object: 3.8718
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.32s
                      Time elapsed: 00:03:53
                               ETA: 00:53:57

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.209s, learning 0.137s)
             Mean action noise std: 1.32
          Mean value_function loss: 6.6801
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 43.9446
                       Mean reward: 25.62
               Mean episode length: 247.26
    Episode_Reward/reaching_object: 0.9759
    Episode_Reward/rotating_object: 4.0949
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.35s
                      Time elapsed: 00:03:55
                               ETA: 00:53:55

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 42017 steps/s (collection: 2.214s, learning 0.125s)
             Mean action noise std: 1.32
          Mean value_function loss: 6.5302
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.0137
                       Mean reward: 23.85
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 0.9632
    Episode_Reward/rotating_object: 4.1473
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.34s
                      Time elapsed: 00:03:58
                               ETA: 00:53:53

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 41574 steps/s (collection: 2.248s, learning 0.117s)
             Mean action noise std: 1.32
          Mean value_function loss: 6.8170
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.0946
                       Mean reward: 23.16
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 0.9655
    Episode_Reward/rotating_object: 3.5786
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.36s
                      Time elapsed: 00:04:00
                               ETA: 00:53:51

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 41465 steps/s (collection: 2.256s, learning 0.115s)
             Mean action noise std: 1.33
          Mean value_function loss: 7.8190
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.1761
                       Mean reward: 27.17
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.9897
    Episode_Reward/rotating_object: 4.3804
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.37s
                      Time elapsed: 00:04:02
                               ETA: 00:53:50

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 41584 steps/s (collection: 2.243s, learning 0.121s)
             Mean action noise std: 1.33
          Mean value_function loss: 8.3069
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.2316
                       Mean reward: 17.96
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.9512
    Episode_Reward/rotating_object: 3.4082
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.36s
                      Time elapsed: 00:04:05
                               ETA: 00:53:48

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 41942 steps/s (collection: 2.229s, learning 0.115s)
             Mean action noise std: 1.33
          Mean value_function loss: 8.2617
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.2929
                       Mean reward: 30.83
               Mean episode length: 247.10
    Episode_Reward/reaching_object: 0.9764
    Episode_Reward/rotating_object: 4.7730
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.34s
                      Time elapsed: 00:04:07
                               ETA: 00:53:46

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 41918 steps/s (collection: 2.230s, learning 0.115s)
             Mean action noise std: 1.34
          Mean value_function loss: 9.0285
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.3688
                       Mean reward: 27.78
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.9633
    Episode_Reward/rotating_object: 4.1765
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.35s
                      Time elapsed: 00:04:10
                               ETA: 00:53:44

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 41613 steps/s (collection: 2.248s, learning 0.114s)
             Mean action noise std: 1.34
          Mean value_function loss: 8.1944
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.4365
                       Mean reward: 20.14
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.9579
    Episode_Reward/rotating_object: 3.0460
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.36s
                      Time elapsed: 00:04:12
                               ETA: 00:53:43

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 41754 steps/s (collection: 2.240s, learning 0.114s)
             Mean action noise std: 1.34
          Mean value_function loss: 8.5280
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.4915
                       Mean reward: 26.25
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 0.9715
    Episode_Reward/rotating_object: 4.7090
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.35s
                      Time elapsed: 00:04:14
                               ETA: 00:53:41

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 42159 steps/s (collection: 2.217s, learning 0.115s)
             Mean action noise std: 1.35
          Mean value_function loss: 8.9135
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.5421
                       Mean reward: 30.07
               Mean episode length: 249.04
    Episode_Reward/reaching_object: 0.9575
    Episode_Reward/rotating_object: 5.2769
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.33s
                      Time elapsed: 00:04:17
                               ETA: 00:53:39

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 42217 steps/s (collection: 2.211s, learning 0.118s)
             Mean action noise std: 1.35
          Mean value_function loss: 8.5475
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.6147
                       Mean reward: 25.51
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 0.9477
    Episode_Reward/rotating_object: 4.7407
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.33s
                      Time elapsed: 00:04:19
                               ETA: 00:53:37

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 42165 steps/s (collection: 2.216s, learning 0.116s)
             Mean action noise std: 1.35
          Mean value_function loss: 8.4574
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.6972
                       Mean reward: 28.25
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.9896
    Episode_Reward/rotating_object: 4.8503
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.33s
                      Time elapsed: 00:04:21
                               ETA: 00:53:34

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 41786 steps/s (collection: 2.239s, learning 0.113s)
             Mean action noise std: 1.36
          Mean value_function loss: 7.9940
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.7869
                       Mean reward: 31.24
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 0.9315
    Episode_Reward/rotating_object: 3.8035
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.35s
                      Time elapsed: 00:04:24
                               ETA: 00:53:33

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 41186 steps/s (collection: 2.274s, learning 0.113s)
             Mean action noise std: 1.36
          Mean value_function loss: 8.0543
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.8662
                       Mean reward: 25.00
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 0.9008
    Episode_Reward/rotating_object: 4.0281
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.39s
                      Time elapsed: 00:04:26
                               ETA: 00:53:31

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 41148 steps/s (collection: 2.267s, learning 0.122s)
             Mean action noise std: 1.37
          Mean value_function loss: 7.5061
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.9505
                       Mean reward: 23.22
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 0.9400
    Episode_Reward/rotating_object: 3.9605
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.39s
                      Time elapsed: 00:04:28
                               ETA: 00:53:30

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 41594 steps/s (collection: 2.248s, learning 0.115s)
             Mean action noise std: 1.37
          Mean value_function loss: 7.8405
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.0308
                       Mean reward: 27.51
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 0.9253
    Episode_Reward/rotating_object: 4.0634
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.36s
                      Time elapsed: 00:04:31
                               ETA: 00:53:28

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 41324 steps/s (collection: 2.262s, learning 0.116s)
             Mean action noise std: 1.38
          Mean value_function loss: 6.9420
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.1250
                       Mean reward: 17.64
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 0.8944
    Episode_Reward/rotating_object: 5.7361
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.38s
                      Time elapsed: 00:04:33
                               ETA: 00:53:26

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 41578 steps/s (collection: 2.252s, learning 0.112s)
             Mean action noise std: 1.38
          Mean value_function loss: 6.7080
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.2001
                       Mean reward: 25.96
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 0.8941
    Episode_Reward/rotating_object: 4.1783
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.36s
                      Time elapsed: 00:04:35
                               ETA: 00:53:24

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 41507 steps/s (collection: 2.256s, learning 0.113s)
             Mean action noise std: 1.38
          Mean value_function loss: 7.3767
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.2753
                       Mean reward: 26.09
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 0.9254
    Episode_Reward/rotating_object: 3.4146
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.37s
                      Time elapsed: 00:04:38
                               ETA: 00:53:23

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 41232 steps/s (collection: 2.270s, learning 0.115s)
             Mean action noise std: 1.39
          Mean value_function loss: 7.4249
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.3590
                       Mean reward: 18.62
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 0.9048
    Episode_Reward/rotating_object: 3.5148
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.38s
                      Time elapsed: 00:04:40
                               ETA: 00:53:21

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 41583 steps/s (collection: 2.251s, learning 0.113s)
             Mean action noise std: 1.39
          Mean value_function loss: 7.9953
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 45.4254
                       Mean reward: 23.48
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 0.9187
    Episode_Reward/rotating_object: 3.2656
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.36s
                      Time elapsed: 00:04:43
                               ETA: 00:53:19

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 41339 steps/s (collection: 2.265s, learning 0.113s)
             Mean action noise std: 1.39
          Mean value_function loss: 7.7989
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.4669
                       Mean reward: 15.55
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 0.9070
    Episode_Reward/rotating_object: 3.5617
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.38s
                      Time elapsed: 00:04:45
                               ETA: 00:53:18

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 41253 steps/s (collection: 2.256s, learning 0.127s)
             Mean action noise std: 1.40
          Mean value_function loss: 8.8931
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.5185
                       Mean reward: 21.04
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 0.9111
    Episode_Reward/rotating_object: 3.1650
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.38s
                      Time elapsed: 00:04:47
                               ETA: 00:53:16

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 41662 steps/s (collection: 2.245s, learning 0.115s)
             Mean action noise std: 1.40
          Mean value_function loss: 8.9354
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.5680
                       Mean reward: 21.16
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 0.9167
    Episode_Reward/rotating_object: 3.5817
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.36s
                      Time elapsed: 00:04:50
                               ETA: 00:53:14

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 41549 steps/s (collection: 2.254s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 8.3293
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.6099
                       Mean reward: 20.28
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 0.8906
    Episode_Reward/rotating_object: 3.3387
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.37s
                      Time elapsed: 00:04:52
                               ETA: 00:53:12

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 41872 steps/s (collection: 2.236s, learning 0.112s)
             Mean action noise std: 1.41
          Mean value_function loss: 8.5653
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.6732
                       Mean reward: 22.27
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 0.9073
    Episode_Reward/rotating_object: 3.1461
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.35s
                      Time elapsed: 00:04:54
                               ETA: 00:53:10

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 41358 steps/s (collection: 2.259s, learning 0.118s)
             Mean action noise std: 1.41
          Mean value_function loss: 8.5510
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.7205
                       Mean reward: 26.02
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.9084
    Episode_Reward/rotating_object: 4.3240
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.38s
                      Time elapsed: 00:04:57
                               ETA: 00:53:08

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 41758 steps/s (collection: 2.239s, learning 0.115s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.8662
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.7603
                       Mean reward: 26.91
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 0.9051
    Episode_Reward/rotating_object: 4.9385
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.35s
                      Time elapsed: 00:04:59
                               ETA: 00:53:06

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 41324 steps/s (collection: 2.255s, learning 0.124s)
             Mean action noise std: 1.41
          Mean value_function loss: 8.9505
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 45.8301
                       Mean reward: 34.87
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 0.9299
    Episode_Reward/rotating_object: 4.0194
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.38s
                      Time elapsed: 00:05:02
                               ETA: 00:53:05

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 42313 steps/s (collection: 2.208s, learning 0.115s)
             Mean action noise std: 1.42
          Mean value_function loss: 9.1162
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.8587
                       Mean reward: 24.40
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.9013
    Episode_Reward/rotating_object: 4.1465
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.32s
                      Time elapsed: 00:05:04
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 42248 steps/s (collection: 2.212s, learning 0.115s)
             Mean action noise std: 1.42
          Mean value_function loss: 9.0028
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.9120
                       Mean reward: 16.59
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 0.8879
    Episode_Reward/rotating_object: 3.1067
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.33s
                      Time elapsed: 00:05:06
                               ETA: 00:53:00

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 42350 steps/s (collection: 2.208s, learning 0.113s)
             Mean action noise std: 1.42
          Mean value_function loss: 8.8219
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.9480
                       Mean reward: 28.00
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 0.8855
    Episode_Reward/rotating_object: 4.7207
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.32s
                      Time elapsed: 00:05:08
                               ETA: 00:52:58

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 42216 steps/s (collection: 2.214s, learning 0.115s)
             Mean action noise std: 1.42
          Mean value_function loss: 10.2341
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.9958
                       Mean reward: 24.69
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 0.8848
    Episode_Reward/rotating_object: 4.8904
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.33s
                      Time elapsed: 00:05:11
                               ETA: 00:52:55

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 42322 steps/s (collection: 2.197s, learning 0.126s)
             Mean action noise std: 1.43
          Mean value_function loss: 13.2030
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.0676
                       Mean reward: 24.47
               Mean episode length: 236.26
    Episode_Reward/reaching_object: 0.9034
    Episode_Reward/rotating_object: 4.3402
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.32s
                      Time elapsed: 00:05:13
                               ETA: 00:52:53

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 42438 steps/s (collection: 2.204s, learning 0.112s)
             Mean action noise std: 1.43
          Mean value_function loss: 10.8336
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.1353
                       Mean reward: 35.16
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 0.9069
    Episode_Reward/rotating_object: 4.7559
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.32s
                      Time elapsed: 00:05:15
                               ETA: 00:52:51

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 41721 steps/s (collection: 2.219s, learning 0.138s)
             Mean action noise std: 1.43
          Mean value_function loss: 11.6222
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 46.1915
                       Mean reward: 22.65
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 0.9021
    Episode_Reward/rotating_object: 5.2518
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.36s
                      Time elapsed: 00:05:18
                               ETA: 00:52:49

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 42677 steps/s (collection: 2.190s, learning 0.113s)
             Mean action noise std: 1.44
          Mean value_function loss: 12.7838
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 46.2470
                       Mean reward: 22.86
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.8788
    Episode_Reward/rotating_object: 4.5930
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.30s
                      Time elapsed: 00:05:20
                               ETA: 00:52:46

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 42786 steps/s (collection: 2.185s, learning 0.112s)
             Mean action noise std: 1.44
          Mean value_function loss: 14.2482
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 46.3203
                       Mean reward: 22.51
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 0.8931
    Episode_Reward/rotating_object: 4.9482
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.30s
                      Time elapsed: 00:05:22
                               ETA: 00:52:44

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 42420 steps/s (collection: 2.194s, learning 0.123s)
             Mean action noise std: 1.44
          Mean value_function loss: 11.3216
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.3814
                       Mean reward: 34.69
               Mean episode length: 246.69
    Episode_Reward/reaching_object: 0.8922
    Episode_Reward/rotating_object: 5.6142
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.32s
                      Time elapsed: 00:05:25
                               ETA: 00:52:41

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 42809 steps/s (collection: 2.181s, learning 0.115s)
             Mean action noise std: 1.45
          Mean value_function loss: 11.3640
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 46.4370
                       Mean reward: 31.50
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.8913
    Episode_Reward/rotating_object: 5.4760
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.30s
                      Time elapsed: 00:05:27
                               ETA: 00:52:39

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 42812 steps/s (collection: 2.183s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 13.5480
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.4886
                       Mean reward: 30.67
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 0.9013
    Episode_Reward/rotating_object: 5.5175
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.30s
                      Time elapsed: 00:05:29
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 42833 steps/s (collection: 2.182s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 12.5945
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 46.5442
                       Mean reward: 25.67
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 0.8930
    Episode_Reward/rotating_object: 5.6753
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.30s
                      Time elapsed: 00:05:32
                               ETA: 00:52:34

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 42908 steps/s (collection: 2.179s, learning 0.112s)
             Mean action noise std: 1.46
          Mean value_function loss: 13.4482
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 46.6116
                       Mean reward: 26.78
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.8634
    Episode_Reward/rotating_object: 4.9318
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.29s
                      Time elapsed: 00:05:34
                               ETA: 00:52:31

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 42594 steps/s (collection: 2.196s, learning 0.112s)
             Mean action noise std: 1.46
          Mean value_function loss: 11.2328
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.6462
                       Mean reward: 45.59
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 0.8718
    Episode_Reward/rotating_object: 6.7361
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.31s
                      Time elapsed: 00:05:36
                               ETA: 00:52:28

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 42448 steps/s (collection: 2.203s, learning 0.113s)
             Mean action noise std: 1.46
          Mean value_function loss: 11.4993
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.7062
                       Mean reward: 34.58
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 0.8769
    Episode_Reward/rotating_object: 6.6862
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.32s
                      Time elapsed: 00:05:39
                               ETA: 00:52:26

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 42401 steps/s (collection: 2.191s, learning 0.127s)
             Mean action noise std: 1.47
          Mean value_function loss: 11.7798
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.7629
                       Mean reward: 38.22
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 0.8689
    Episode_Reward/rotating_object: 5.7407
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.32s
                      Time elapsed: 00:05:41
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 42457 steps/s (collection: 2.186s, learning 0.130s)
             Mean action noise std: 1.47
          Mean value_function loss: 11.3236
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.8178
                       Mean reward: 31.21
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 0.8409
    Episode_Reward/rotating_object: 5.5543
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.32s
                      Time elapsed: 00:05:43
                               ETA: 00:52:21

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 42561 steps/s (collection: 2.194s, learning 0.115s)
             Mean action noise std: 1.47
          Mean value_function loss: 12.1624
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.8722
                       Mean reward: 21.61
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 0.8714
    Episode_Reward/rotating_object: 4.5668
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.31s
                      Time elapsed: 00:05:45
                               ETA: 00:52:19

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 42838 steps/s (collection: 2.174s, learning 0.121s)
             Mean action noise std: 1.48
          Mean value_function loss: 11.9136
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.9330
                       Mean reward: 37.60
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 0.8635
    Episode_Reward/rotating_object: 5.7329
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.29s
                      Time elapsed: 00:05:48
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 42713 steps/s (collection: 2.189s, learning 0.113s)
             Mean action noise std: 1.48
          Mean value_function loss: 11.7984
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 47.0080
                       Mean reward: 41.23
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 0.8699
    Episode_Reward/rotating_object: 6.6544
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.30s
                      Time elapsed: 00:05:50
                               ETA: 00:52:14

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 42933 steps/s (collection: 2.163s, learning 0.127s)
             Mean action noise std: 1.48
          Mean value_function loss: 11.6450
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.0703
                       Mean reward: 27.81
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 0.8746
    Episode_Reward/rotating_object: 6.3773
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.29s
                      Time elapsed: 00:05:52
                               ETA: 00:52:11

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 44781 steps/s (collection: 2.082s, learning 0.113s)
             Mean action noise std: 1.49
          Mean value_function loss: 13.1071
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.1362
                       Mean reward: 31.21
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 0.8561
    Episode_Reward/rotating_object: 6.0993
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.20s
                      Time elapsed: 00:05:55
                               ETA: 00:52:08

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 45025 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 12.1067
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.1970
                       Mean reward: 27.68
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 0.8430
    Episode_Reward/rotating_object: 5.6715
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.18s
                      Time elapsed: 00:05:57
                               ETA: 00:52:04

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 45045 steps/s (collection: 2.070s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 11.7928
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.2629
                       Mean reward: 23.74
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 0.8329
    Episode_Reward/rotating_object: 5.7577
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.18s
                      Time elapsed: 00:05:59
                               ETA: 00:52:01

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 44760 steps/s (collection: 2.080s, learning 0.116s)
             Mean action noise std: 1.50
          Mean value_function loss: 13.5797
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.3166
                       Mean reward: 45.07
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 0.8193
    Episode_Reward/rotating_object: 6.3875
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.20s
                      Time elapsed: 00:06:01
                               ETA: 00:51:57

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 45343 steps/s (collection: 2.056s, learning 0.112s)
             Mean action noise std: 1.50
          Mean value_function loss: 14.4946
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.3573
                       Mean reward: 42.54
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.8382
    Episode_Reward/rotating_object: 6.4726
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.17s
                      Time elapsed: 00:06:03
                               ETA: 00:51:54

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 44977 steps/s (collection: 2.071s, learning 0.115s)
             Mean action noise std: 1.50
          Mean value_function loss: 14.1142
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.3993
                       Mean reward: 42.10
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 0.8317
    Episode_Reward/rotating_object: 6.1997
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.19s
                      Time elapsed: 00:06:05
                               ETA: 00:51:50

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 43633 steps/s (collection: 2.126s, learning 0.127s)
             Mean action noise std: 1.51
          Mean value_function loss: 12.9665
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.4588
                       Mean reward: 33.11
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.8309
    Episode_Reward/rotating_object: 6.4733
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.25s
                      Time elapsed: 00:06:08
                               ETA: 00:51:47

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 42711 steps/s (collection: 2.190s, learning 0.112s)
             Mean action noise std: 1.51
          Mean value_function loss: 11.9581
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.5005
                       Mean reward: 40.03
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 0.8152
    Episode_Reward/rotating_object: 6.4835
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.30s
                      Time elapsed: 00:06:10
                               ETA: 00:51:45

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 43411 steps/s (collection: 2.153s, learning 0.111s)
             Mean action noise std: 1.51
          Mean value_function loss: 14.0669
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.5625
                       Mean reward: 38.51
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 0.8448
    Episode_Reward/rotating_object: 6.6444
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.26s
                      Time elapsed: 00:06:12
                               ETA: 00:51:42

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 43160 steps/s (collection: 2.164s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 14.5062
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.6090
                       Mean reward: 30.68
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 0.8635
    Episode_Reward/rotating_object: 7.2790
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.28s
                      Time elapsed: 00:06:15
                               ETA: 00:51:40

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 43346 steps/s (collection: 2.150s, learning 0.118s)
             Mean action noise std: 1.52
          Mean value_function loss: 15.1985
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.6594
                       Mean reward: 29.32
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.8408
    Episode_Reward/rotating_object: 6.9027
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.27s
                      Time elapsed: 00:06:17
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 43435 steps/s (collection: 2.150s, learning 0.113s)
             Mean action noise std: 1.52
          Mean value_function loss: 15.6147
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 47.7102
                       Mean reward: 51.23
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 0.8712
    Episode_Reward/rotating_object: 6.7963
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.26s
                      Time elapsed: 00:06:19
                               ETA: 00:51:34

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 43204 steps/s (collection: 2.161s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 14.8630
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 47.7560
                       Mean reward: 42.51
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 0.8602
    Episode_Reward/rotating_object: 6.3109
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.28s
                      Time elapsed: 00:06:21
                               ETA: 00:51:32

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 43432 steps/s (collection: 2.151s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 12.0529
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.7921
                       Mean reward: 35.79
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 0.8511
    Episode_Reward/rotating_object: 5.6377
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.26s
                      Time elapsed: 00:06:24
                               ETA: 00:51:29

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 43009 steps/s (collection: 2.172s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 14.1340
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.8453
                       Mean reward: 30.02
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 0.8749
    Episode_Reward/rotating_object: 6.8031
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.29s
                      Time elapsed: 00:06:26
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 42837 steps/s (collection: 2.180s, learning 0.115s)
             Mean action noise std: 1.53
          Mean value_function loss: 17.9886
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.9103
                       Mean reward: 35.60
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 0.8560
    Episode_Reward/rotating_object: 5.7639
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.29s
                      Time elapsed: 00:06:28
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 42671 steps/s (collection: 2.191s, learning 0.112s)
             Mean action noise std: 1.53
          Mean value_function loss: 20.6539
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 47.9498
                       Mean reward: 32.48
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 0.8454
    Episode_Reward/rotating_object: 6.2102
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.30s
                      Time elapsed: 00:06:31
                               ETA: 00:51:21

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 43115 steps/s (collection: 2.167s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 16.2675
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 47.9781
                       Mean reward: 40.69
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 0.8498
    Episode_Reward/rotating_object: 6.8872
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.28s
                      Time elapsed: 00:06:33
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 42726 steps/s (collection: 2.187s, learning 0.114s)
             Mean action noise std: 1.54
          Mean value_function loss: 18.6944
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.0342
                       Mean reward: 28.71
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 0.8432
    Episode_Reward/rotating_object: 5.5460
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.30s
                      Time elapsed: 00:06:35
                               ETA: 00:51:16

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 42506 steps/s (collection: 2.194s, learning 0.119s)
             Mean action noise std: 1.54
          Mean value_function loss: 21.6176
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.0633
                       Mean reward: 37.50
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.8308
    Episode_Reward/rotating_object: 5.7844
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.31s
                      Time elapsed: 00:06:37
                               ETA: 00:51:14

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 42670 steps/s (collection: 2.183s, learning 0.121s)
             Mean action noise std: 1.54
          Mean value_function loss: 21.3428
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 48.0993
                       Mean reward: 38.01
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 0.8766
    Episode_Reward/rotating_object: 6.0884
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.30s
                      Time elapsed: 00:06:40
                               ETA: 00:51:12

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 42646 steps/s (collection: 2.192s, learning 0.113s)
             Mean action noise std: 1.55
          Mean value_function loss: 18.6827
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.1435
                       Mean reward: 49.69
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 0.8651
    Episode_Reward/rotating_object: 6.1233
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.31s
                      Time elapsed: 00:06:42
                               ETA: 00:51:09

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 43001 steps/s (collection: 2.165s, learning 0.121s)
             Mean action noise std: 1.55
          Mean value_function loss: 18.0906
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.1736
                       Mean reward: 39.58
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 0.8411
    Episode_Reward/rotating_object: 6.2813
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.29s
                      Time elapsed: 00:06:44
                               ETA: 00:51:07

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 42995 steps/s (collection: 2.173s, learning 0.113s)
             Mean action noise std: 1.55
          Mean value_function loss: 17.6231
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.2030
                       Mean reward: 31.06
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 0.8387
    Episode_Reward/rotating_object: 7.1048
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.29s
                      Time elapsed: 00:06:47
                               ETA: 00:51:04

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 42974 steps/s (collection: 2.174s, learning 0.113s)
             Mean action noise std: 1.55
          Mean value_function loss: 16.4231
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.2387
                       Mean reward: 53.39
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 0.8608
    Episode_Reward/rotating_object: 7.3939
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.29s
                      Time elapsed: 00:06:49
                               ETA: 00:51:02

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 43172 steps/s (collection: 2.152s, learning 0.125s)
             Mean action noise std: 1.56
          Mean value_function loss: 18.5900
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 48.2867
                       Mean reward: 42.47
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 0.8427
    Episode_Reward/rotating_object: 6.9108
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.28s
                      Time elapsed: 00:06:51
                               ETA: 00:50:59

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 42738 steps/s (collection: 2.186s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 17.7635
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.3240
                       Mean reward: 36.20
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 0.8392
    Episode_Reward/rotating_object: 7.6413
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.30s
                      Time elapsed: 00:06:53
                               ETA: 00:50:57

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 42452 steps/s (collection: 2.203s, learning 0.112s)
             Mean action noise std: 1.56
          Mean value_function loss: 21.2510
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.3738
                       Mean reward: 28.23
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 0.8282
    Episode_Reward/rotating_object: 7.7323
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.32s
                      Time elapsed: 00:06:56
                               ETA: 00:50:55

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 43256 steps/s (collection: 2.159s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 18.7580
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 48.4130
                       Mean reward: 25.35
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 0.8197
    Episode_Reward/rotating_object: 7.2570
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.27s
                      Time elapsed: 00:06:58
                               ETA: 00:50:52

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 40983 steps/s (collection: 2.265s, learning 0.134s)
             Mean action noise std: 1.57
          Mean value_function loss: 20.3087
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.4675
                       Mean reward: 33.57
               Mean episode length: 224.91
    Episode_Reward/reaching_object: 0.8243
    Episode_Reward/rotating_object: 6.7837
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.40s
                      Time elapsed: 00:07:00
                               ETA: 00:50:50

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 41168 steps/s (collection: 2.255s, learning 0.133s)
             Mean action noise std: 1.57
          Mean value_function loss: 24.3538
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.5190
                       Mean reward: 37.78
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 0.8436
    Episode_Reward/rotating_object: 7.0110
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.39s
                      Time elapsed: 00:07:03
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 40762 steps/s (collection: 2.276s, learning 0.136s)
             Mean action noise std: 1.57
          Mean value_function loss: 21.2361
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.5658
                       Mean reward: 31.40
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 0.8161
    Episode_Reward/rotating_object: 6.8433
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.41s
                      Time elapsed: 00:07:05
                               ETA: 00:50:47

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 40441 steps/s (collection: 2.295s, learning 0.136s)
             Mean action noise std: 1.57
          Mean value_function loss: 23.5555
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.6022
                       Mean reward: 32.23
               Mean episode length: 222.73
    Episode_Reward/reaching_object: 0.7829
    Episode_Reward/rotating_object: 6.9788
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.43s
                      Time elapsed: 00:07:08
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 42060 steps/s (collection: 2.223s, learning 0.114s)
             Mean action noise std: 1.58
          Mean value_function loss: 21.8427
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.6370
                       Mean reward: 43.01
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 0.8245
    Episode_Reward/rotating_object: 7.5830
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.34s
                      Time elapsed: 00:07:10
                               ETA: 00:50:43

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 43287 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 1.58
          Mean value_function loss: 24.1398
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 48.6772
                       Mean reward: 35.71
               Mean episode length: 216.57
    Episode_Reward/reaching_object: 0.8052
    Episode_Reward/rotating_object: 7.3493
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.27s
                      Time elapsed: 00:07:12
                               ETA: 00:50:41

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 42133 steps/s (collection: 2.213s, learning 0.120s)
             Mean action noise std: 1.58
          Mean value_function loss: 22.7376
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.7227
                       Mean reward: 46.68
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 0.8192
    Episode_Reward/rotating_object: 9.2788
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.33s
                      Time elapsed: 00:07:15
                               ETA: 00:50:38

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 42726 steps/s (collection: 2.185s, learning 0.116s)
             Mean action noise std: 1.59
          Mean value_function loss: 28.6960
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.7713
                       Mean reward: 39.75
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 0.8439
    Episode_Reward/rotating_object: 9.0140
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.30s
                      Time elapsed: 00:07:17
                               ETA: 00:50:36

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 42652 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 1.59
          Mean value_function loss: 25.0716
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 48.8061
                       Mean reward: 47.77
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 0.8356
    Episode_Reward/rotating_object: 7.6391
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.30s
                      Time elapsed: 00:07:19
                               ETA: 00:50:34

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 41851 steps/s (collection: 2.218s, learning 0.131s)
             Mean action noise std: 1.59
          Mean value_function loss: 25.7362
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 48.8360
                       Mean reward: 40.65
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 0.8165
    Episode_Reward/rotating_object: 9.2305
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.35s
                      Time elapsed: 00:07:22
                               ETA: 00:50:32

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 42968 steps/s (collection: 2.173s, learning 0.115s)
             Mean action noise std: 1.59
          Mean value_function loss: 25.9883
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.8565
                       Mean reward: 48.94
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 0.8275
    Episode_Reward/rotating_object: 9.0715
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.29s
                      Time elapsed: 00:07:24
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 41995 steps/s (collection: 2.226s, learning 0.115s)
             Mean action noise std: 1.59
          Mean value_function loss: 23.9325
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.8819
                       Mean reward: 48.63
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 0.8046
    Episode_Reward/rotating_object: 8.8156
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.34s
                      Time elapsed: 00:07:26
                               ETA: 00:50:27

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 42478 steps/s (collection: 2.190s, learning 0.124s)
             Mean action noise std: 1.59
          Mean value_function loss: 23.5898
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.9132
                       Mean reward: 39.18
               Mean episode length: 222.97
    Episode_Reward/reaching_object: 0.8035
    Episode_Reward/rotating_object: 8.5198
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.31s
                      Time elapsed: 00:07:29
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 42766 steps/s (collection: 2.183s, learning 0.115s)
             Mean action noise std: 1.60
          Mean value_function loss: 26.6220
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.9474
                       Mean reward: 38.37
               Mean episode length: 228.30
    Episode_Reward/reaching_object: 0.8208
    Episode_Reward/rotating_object: 9.2723
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.30s
                      Time elapsed: 00:07:31
                               ETA: 00:50:22

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 41873 steps/s (collection: 2.224s, learning 0.124s)
             Mean action noise std: 1.60
          Mean value_function loss: 26.3432
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 48.9794
                       Mean reward: 48.06
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 0.8586
    Episode_Reward/rotating_object: 9.9056
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.35s
                      Time elapsed: 00:07:33
                               ETA: 00:50:20

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 42501 steps/s (collection: 2.197s, learning 0.116s)
             Mean action noise std: 1.60
          Mean value_function loss: 25.4034
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 49.0201
                       Mean reward: 45.65
               Mean episode length: 228.56
    Episode_Reward/reaching_object: 0.8154
    Episode_Reward/rotating_object: 9.8364
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.31s
                      Time elapsed: 00:07:35
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 43008 steps/s (collection: 2.174s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 27.9231
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.0797
                       Mean reward: 50.85
               Mean episode length: 225.46
    Episode_Reward/reaching_object: 0.8167
    Episode_Reward/rotating_object: 8.3047
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.29s
                      Time elapsed: 00:07:38
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 42857 steps/s (collection: 2.181s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 26.7471
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.1226
                       Mean reward: 54.31
               Mean episode length: 228.18
    Episode_Reward/reaching_object: 0.8301
    Episode_Reward/rotating_object: 9.6745
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.29s
                      Time elapsed: 00:07:40
                               ETA: 00:50:13

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 42522 steps/s (collection: 2.197s, learning 0.115s)
             Mean action noise std: 1.61
          Mean value_function loss: 25.4510
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.1606
                       Mean reward: 49.73
               Mean episode length: 227.65
    Episode_Reward/reaching_object: 0.8226
    Episode_Reward/rotating_object: 10.0449
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.31s
                      Time elapsed: 00:07:42
                               ETA: 00:50:11

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 42882 steps/s (collection: 2.181s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 24.5197
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.1925
                       Mean reward: 59.14
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 0.8451
    Episode_Reward/rotating_object: 9.3105
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.29s
                      Time elapsed: 00:07:45
                               ETA: 00:50:08

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 42092 steps/s (collection: 2.223s, learning 0.113s)
             Mean action noise std: 1.61
          Mean value_function loss: 28.2679
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 49.2338
                       Mean reward: 52.62
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 0.8629
    Episode_Reward/rotating_object: 9.5037
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.34s
                      Time elapsed: 00:07:47
                               ETA: 00:50:06

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 42967 steps/s (collection: 2.176s, learning 0.112s)
             Mean action noise std: 1.62
          Mean value_function loss: 25.5740
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 49.2814
                       Mean reward: 49.56
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 0.7941
    Episode_Reward/rotating_object: 8.2727
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.29s
                      Time elapsed: 00:07:49
                               ETA: 00:50:03

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 43320 steps/s (collection: 2.156s, learning 0.113s)
             Mean action noise std: 1.62
          Mean value_function loss: 29.4282
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.3448
                       Mean reward: 47.03
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 0.8143
    Episode_Reward/rotating_object: 8.3524
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.27s
                      Time elapsed: 00:07:52
                               ETA: 00:50:01

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 43494 steps/s (collection: 2.147s, learning 0.114s)
             Mean action noise std: 1.62
          Mean value_function loss: 24.1237
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 49.3977
                       Mean reward: 51.85
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 0.8468
    Episode_Reward/rotating_object: 10.0606
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.26s
                      Time elapsed: 00:07:54
                               ETA: 00:49:58

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 43432 steps/s (collection: 2.148s, learning 0.116s)
             Mean action noise std: 1.63
          Mean value_function loss: 30.2903
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 49.4438
                       Mean reward: 51.16
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 0.8113
    Episode_Reward/rotating_object: 9.8482
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.26s
                      Time elapsed: 00:07:56
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 43046 steps/s (collection: 2.170s, learning 0.113s)
             Mean action noise std: 1.63
          Mean value_function loss: 27.9166
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 49.4826
                       Mean reward: 41.56
               Mean episode length: 223.18
    Episode_Reward/reaching_object: 0.8273
    Episode_Reward/rotating_object: 9.9604
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.28s
                      Time elapsed: 00:07:58
                               ETA: 00:49:53

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 43054 steps/s (collection: 2.171s, learning 0.113s)
             Mean action noise std: 1.63
          Mean value_function loss: 27.7653
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 49.5240
                       Mean reward: 43.64
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 0.7953
    Episode_Reward/rotating_object: 9.5085
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.28s
                      Time elapsed: 00:08:01
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 42787 steps/s (collection: 2.183s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 29.0888
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.5715
                       Mean reward: 55.85
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 0.7973
    Episode_Reward/rotating_object: 9.4232
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.30s
                      Time elapsed: 00:08:03
                               ETA: 00:49:48

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 42735 steps/s (collection: 2.184s, learning 0.116s)
             Mean action noise std: 1.64
          Mean value_function loss: 27.0144
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 49.6176
                       Mean reward: 58.56
               Mean episode length: 233.25
    Episode_Reward/reaching_object: 0.8175
    Episode_Reward/rotating_object: 11.2577
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.30s
                      Time elapsed: 00:08:05
                               ETA: 00:49:46

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 42516 steps/s (collection: 2.188s, learning 0.125s)
             Mean action noise std: 1.64
          Mean value_function loss: 28.3827
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 49.6662
                       Mean reward: 56.25
               Mean episode length: 223.41
    Episode_Reward/reaching_object: 0.8048
    Episode_Reward/rotating_object: 9.2851
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.31s
                      Time elapsed: 00:08:08
                               ETA: 00:49:43

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 42420 steps/s (collection: 2.201s, learning 0.116s)
             Mean action noise std: 1.64
          Mean value_function loss: 25.8840
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.7147
                       Mean reward: 52.95
               Mean episode length: 220.07
    Episode_Reward/reaching_object: 0.8483
    Episode_Reward/rotating_object: 11.7806
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.32s
                      Time elapsed: 00:08:10
                               ETA: 00:49:41

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 41901 steps/s (collection: 2.219s, learning 0.127s)
             Mean action noise std: 1.65
          Mean value_function loss: 24.8615
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 49.7654
                       Mean reward: 62.61
               Mean episode length: 223.01
    Episode_Reward/reaching_object: 0.8069
    Episode_Reward/rotating_object: 9.8964
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.35s
                      Time elapsed: 00:08:12
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 41672 steps/s (collection: 2.247s, learning 0.112s)
             Mean action noise std: 1.65
          Mean value_function loss: 21.8552
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 49.8135
                       Mean reward: 55.26
               Mean episode length: 225.84
    Episode_Reward/reaching_object: 0.8495
    Episode_Reward/rotating_object: 12.5911
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.36s
                      Time elapsed: 00:08:15
                               ETA: 00:49:37

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 42327 steps/s (collection: 2.210s, learning 0.112s)
             Mean action noise std: 1.65
          Mean value_function loss: 28.0576
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 49.8571
                       Mean reward: 41.31
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 0.8060
    Episode_Reward/rotating_object: 9.4703
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.32s
                      Time elapsed: 00:08:17
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 42071 steps/s (collection: 2.224s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 25.3802
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.8964
                       Mean reward: 59.90
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 0.8546
    Episode_Reward/rotating_object: 10.4610
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.34s
                      Time elapsed: 00:08:19
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 41816 steps/s (collection: 2.232s, learning 0.118s)
             Mean action noise std: 1.66
          Mean value_function loss: 25.2057
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.9500
                       Mean reward: 45.81
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 0.8903
    Episode_Reward/rotating_object: 11.1194
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.35s
                      Time elapsed: 00:08:22
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 42434 steps/s (collection: 2.204s, learning 0.112s)
             Mean action noise std: 1.66
          Mean value_function loss: 20.4273
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 50.0007
                       Mean reward: 41.70
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 0.8837
    Episode_Reward/rotating_object: 8.9623
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.32s
                      Time elapsed: 00:08:24
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 42249 steps/s (collection: 2.215s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 23.8146
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.0584
                       Mean reward: 67.79
               Mean episode length: 225.40
    Episode_Reward/reaching_object: 0.8605
    Episode_Reward/rotating_object: 9.7921
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.33s
                      Time elapsed: 00:08:26
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 42317 steps/s (collection: 2.205s, learning 0.118s)
             Mean action noise std: 1.67
          Mean value_function loss: 22.3292
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.1007
                       Mean reward: 39.26
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 0.8422
    Episode_Reward/rotating_object: 7.8294
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.32s
                      Time elapsed: 00:08:29
                               ETA: 00:49:24

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 42548 steps/s (collection: 2.188s, learning 0.123s)
             Mean action noise std: 1.67
          Mean value_function loss: 23.7397
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 50.1442
                       Mean reward: 42.49
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 0.8953
    Episode_Reward/rotating_object: 10.4660
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.31s
                      Time elapsed: 00:08:31
                               ETA: 00:49:21

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 42218 steps/s (collection: 2.216s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 21.3826
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 50.2042
                       Mean reward: 61.62
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 0.8980
    Episode_Reward/rotating_object: 9.9652
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.33s
                      Time elapsed: 00:08:33
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 42126 steps/s (collection: 2.220s, learning 0.113s)
             Mean action noise std: 1.68
          Mean value_function loss: 24.2150
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.2524
                       Mean reward: 55.87
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 0.8780
    Episode_Reward/rotating_object: 9.4999
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.33s
                      Time elapsed: 00:08:36
                               ETA: 00:49:17

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 42958 steps/s (collection: 2.176s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 27.0173
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.2862
                       Mean reward: 61.71
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 0.8938
    Episode_Reward/rotating_object: 10.7042
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.29s
                      Time elapsed: 00:08:38
                               ETA: 00:49:14

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 42627 steps/s (collection: 2.181s, learning 0.125s)
             Mean action noise std: 1.68
          Mean value_function loss: 26.4379
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 50.3216
                       Mean reward: 55.75
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 0.8681
    Episode_Reward/rotating_object: 9.0981
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.31s
                      Time elapsed: 00:08:40
                               ETA: 00:49:12

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 43002 steps/s (collection: 2.173s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 24.0980
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 50.3574
                       Mean reward: 40.54
               Mean episode length: 224.82
    Episode_Reward/reaching_object: 0.8450
    Episode_Reward/rotating_object: 8.1998
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.29s
                      Time elapsed: 00:08:42
                               ETA: 00:49:10

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 43433 steps/s (collection: 2.151s, learning 0.112s)
             Mean action noise std: 1.69
          Mean value_function loss: 27.4205
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.4022
                       Mean reward: 33.76
               Mean episode length: 228.33
    Episode_Reward/reaching_object: 0.8780
    Episode_Reward/rotating_object: 9.4571
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.26s
                      Time elapsed: 00:08:45
                               ETA: 00:49:07

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 43138 steps/s (collection: 2.163s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 27.0642
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.4414
                       Mean reward: 56.11
               Mean episode length: 231.48
    Episode_Reward/reaching_object: 0.8765
    Episode_Reward/rotating_object: 10.5934
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.28s
                      Time elapsed: 00:08:47
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 42761 steps/s (collection: 2.186s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 24.8376
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 50.4882
                       Mean reward: 61.71
               Mean episode length: 220.50
    Episode_Reward/reaching_object: 0.8567
    Episode_Reward/rotating_object: 9.0159
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.30s
                      Time elapsed: 00:08:49
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 42868 steps/s (collection: 2.181s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 27.4425
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 50.5482
                       Mean reward: 59.98
               Mean episode length: 223.51
    Episode_Reward/reaching_object: 0.8802
    Episode_Reward/rotating_object: 12.8128
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.29s
                      Time elapsed: 00:08:52
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 42430 steps/s (collection: 2.202s, learning 0.115s)
             Mean action noise std: 1.70
          Mean value_function loss: 29.2150
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 50.5976
                       Mean reward: 48.69
               Mean episode length: 225.85
    Episode_Reward/reaching_object: 0.8752
    Episode_Reward/rotating_object: 9.9209
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.32s
                      Time elapsed: 00:08:54
                               ETA: 00:48:57

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 42445 steps/s (collection: 2.202s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 29.0059
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 50.6344
                       Mean reward: 60.74
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.8786
    Episode_Reward/rotating_object: 11.9966
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.32s
                      Time elapsed: 00:08:56
                               ETA: 00:48:55

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 42256 steps/s (collection: 2.211s, learning 0.115s)
             Mean action noise std: 1.71
          Mean value_function loss: 25.1727
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 50.6787
                       Mean reward: 47.22
               Mean episode length: 221.20
    Episode_Reward/reaching_object: 0.8216
    Episode_Reward/rotating_object: 9.6886
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.33s
                      Time elapsed: 00:08:59
                               ETA: 00:48:53

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 42587 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 1.71
          Mean value_function loss: 26.9573
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 50.7220
                       Mean reward: 59.49
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 0.8614
    Episode_Reward/rotating_object: 10.1351
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.31s
                      Time elapsed: 00:09:01
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 42242 steps/s (collection: 2.212s, learning 0.115s)
             Mean action noise std: 1.71
          Mean value_function loss: 23.9211
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.7662
                       Mean reward: 60.38
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 0.8808
    Episode_Reward/rotating_object: 10.4812
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.33s
                      Time elapsed: 00:09:03
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 42497 steps/s (collection: 2.201s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 24.4659
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.7960
                       Mean reward: 50.88
               Mean episode length: 228.24
    Episode_Reward/reaching_object: 0.8521
    Episode_Reward/rotating_object: 10.6239
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.31s
                      Time elapsed: 00:09:05
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 42901 steps/s (collection: 2.178s, learning 0.113s)
             Mean action noise std: 1.72
          Mean value_function loss: 24.6730
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 50.8344
                       Mean reward: 60.63
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 0.8477
    Episode_Reward/rotating_object: 8.7429
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.29s
                      Time elapsed: 00:09:08
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 42805 steps/s (collection: 2.183s, learning 0.113s)
             Mean action noise std: 1.72
          Mean value_function loss: 26.8915
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.8703
                       Mean reward: 72.52
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 0.8788
    Episode_Reward/rotating_object: 12.7861
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.30s
                      Time elapsed: 00:09:10
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 42051 steps/s (collection: 2.218s, learning 0.119s)
             Mean action noise std: 1.72
          Mean value_function loss: 27.4558
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 50.9127
                       Mean reward: 61.64
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 0.8908
    Episode_Reward/rotating_object: 11.4575
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.34s
                      Time elapsed: 00:09:12
                               ETA: 00:48:39

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 42665 steps/s (collection: 2.190s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 29.4391
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 50.9569
                       Mean reward: 57.95
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 0.8963
    Episode_Reward/rotating_object: 11.3399
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.30s
                      Time elapsed: 00:09:15
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 42430 steps/s (collection: 2.201s, learning 0.116s)
             Mean action noise std: 1.73
          Mean value_function loss: 29.4706
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.0103
                       Mean reward: 73.16
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 0.8887
    Episode_Reward/rotating_object: 11.5371
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.32s
                      Time elapsed: 00:09:17
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 42435 steps/s (collection: 2.201s, learning 0.115s)
             Mean action noise std: 1.73
          Mean value_function loss: 35.8599
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.0466
                       Mean reward: 56.00
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 0.8914
    Episode_Reward/rotating_object: 11.0520
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.32s
                      Time elapsed: 00:09:19
                               ETA: 00:48:32

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 42391 steps/s (collection: 2.207s, learning 0.112s)
             Mean action noise std: 1.73
          Mean value_function loss: 44.2539
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.0724
                       Mean reward: 70.67
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 0.8783
    Episode_Reward/rotating_object: 10.9057
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.32s
                      Time elapsed: 00:09:22
                               ETA: 00:48:30

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 41396 steps/s (collection: 2.257s, learning 0.118s)
             Mean action noise std: 1.74
          Mean value_function loss: 38.5358
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 51.0950
                       Mean reward: 78.00
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 0.9067
    Episode_Reward/rotating_object: 12.6420
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.37s
                      Time elapsed: 00:09:24
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 42271 steps/s (collection: 2.212s, learning 0.114s)
             Mean action noise std: 1.74
          Mean value_function loss: 41.1785
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 51.1328
                       Mean reward: 33.84
               Mean episode length: 223.84
    Episode_Reward/reaching_object: 0.8816
    Episode_Reward/rotating_object: 10.2473
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.33s
                      Time elapsed: 00:09:26
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 43013 steps/s (collection: 2.173s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 42.7995
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.1682
                       Mean reward: 43.56
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 0.8803
    Episode_Reward/rotating_object: 11.2257
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.29s
                      Time elapsed: 00:09:29
                               ETA: 00:48:23

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 42631 steps/s (collection: 2.180s, learning 0.126s)
             Mean action noise std: 1.74
          Mean value_function loss: 43.1337
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 51.2075
                       Mean reward: 56.12
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 0.8853
    Episode_Reward/rotating_object: 11.4130
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.31s
                      Time elapsed: 00:09:31
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 42819 steps/s (collection: 2.183s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 38.8517
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 51.2515
                       Mean reward: 66.41
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 0.9009
    Episode_Reward/rotating_object: 12.2162
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.30s
                      Time elapsed: 00:09:33
                               ETA: 00:48:18

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 43021 steps/s (collection: 2.174s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 43.9757
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 51.2924
                       Mean reward: 62.34
               Mean episode length: 219.28
    Episode_Reward/reaching_object: 0.8649
    Episode_Reward/rotating_object: 11.0982
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.28s
                      Time elapsed: 00:09:36
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 43160 steps/s (collection: 2.166s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 40.4661
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.3272
                       Mean reward: 69.24
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 0.9436
    Episode_Reward/rotating_object: 14.2635
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.28s
                      Time elapsed: 00:09:38
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 43087 steps/s (collection: 2.167s, learning 0.115s)
             Mean action noise std: 1.75
          Mean value_function loss: 36.9923
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 51.3531
                       Mean reward: 78.56
               Mean episode length: 212.86
    Episode_Reward/reaching_object: 0.8967
    Episode_Reward/rotating_object: 12.7228
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.28s
                      Time elapsed: 00:09:40
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 42673 steps/s (collection: 2.189s, learning 0.115s)
             Mean action noise std: 1.75
          Mean value_function loss: 41.1778
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.3738
                       Mean reward: 77.36
               Mean episode length: 225.68
    Episode_Reward/reaching_object: 0.9020
    Episode_Reward/rotating_object: 13.2751
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.30s
                      Time elapsed: 00:09:42
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 42130 steps/s (collection: 2.218s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 39.1338
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 51.3981
                       Mean reward: 88.24
               Mean episode length: 221.72
    Episode_Reward/reaching_object: 0.9000
    Episode_Reward/rotating_object: 17.5127
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.33s
                      Time elapsed: 00:09:45
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 42337 steps/s (collection: 2.197s, learning 0.125s)
             Mean action noise std: 1.76
          Mean value_function loss: 44.7247
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 51.4419
                       Mean reward: 66.74
               Mean episode length: 224.29
    Episode_Reward/reaching_object: 0.8992
    Episode_Reward/rotating_object: 11.8870
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.32s
                      Time elapsed: 00:09:47
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 42021 steps/s (collection: 2.211s, learning 0.129s)
             Mean action noise std: 1.76
          Mean value_function loss: 44.5123
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 51.4780
                       Mean reward: 82.34
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 0.8963
    Episode_Reward/rotating_object: 12.5678
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.34s
                      Time elapsed: 00:09:49
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 42489 steps/s (collection: 2.200s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 46.0817
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 51.5118
                       Mean reward: 83.47
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 0.9297
    Episode_Reward/rotating_object: 17.0064
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.31s
                      Time elapsed: 00:09:52
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 41983 steps/s (collection: 2.227s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 41.3749
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 51.5429
                       Mean reward: 70.43
               Mean episode length: 220.39
    Episode_Reward/reaching_object: 0.9051
    Episode_Reward/rotating_object: 15.3110
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.34s
                      Time elapsed: 00:09:54
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 41660 steps/s (collection: 2.235s, learning 0.125s)
             Mean action noise std: 1.77
          Mean value_function loss: 44.5221
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 51.5773
                       Mean reward: 91.16
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 0.9301
    Episode_Reward/rotating_object: 15.6676
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.36s
                      Time elapsed: 00:09:56
                               ETA: 00:47:55

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 42482 steps/s (collection: 2.200s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 44.9612
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 51.6179
                       Mean reward: 56.88
               Mean episode length: 219.19
    Episode_Reward/reaching_object: 0.9033
    Episode_Reward/rotating_object: 13.8730
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.31s
                      Time elapsed: 00:09:59
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 42146 steps/s (collection: 2.217s, learning 0.116s)
             Mean action noise std: 1.77
          Mean value_function loss: 45.2133
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.6420
                       Mean reward: 79.76
               Mean episode length: 216.10
    Episode_Reward/reaching_object: 0.9385
    Episode_Reward/rotating_object: 15.0922
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.33s
                      Time elapsed: 00:10:01
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 42280 steps/s (collection: 2.202s, learning 0.123s)
             Mean action noise std: 1.77
          Mean value_function loss: 43.6427
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.6663
                       Mean reward: 97.70
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 0.9687
    Episode_Reward/rotating_object: 14.9583
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.33s
                      Time elapsed: 00:10:03
                               ETA: 00:47:48

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 42756 steps/s (collection: 2.183s, learning 0.116s)
             Mean action noise std: 1.78
          Mean value_function loss: 36.1718
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 51.6922
                       Mean reward: 70.32
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.9497
    Episode_Reward/rotating_object: 15.5347
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.30s
                      Time elapsed: 00:10:06
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 42510 steps/s (collection: 2.198s, learning 0.115s)
             Mean action noise std: 1.78
          Mean value_function loss: 39.7203
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 51.7325
                       Mean reward: 69.42
               Mean episode length: 224.77
    Episode_Reward/reaching_object: 0.9711
    Episode_Reward/rotating_object: 15.6859
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.31s
                      Time elapsed: 00:10:08
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 42245 steps/s (collection: 2.212s, learning 0.115s)
             Mean action noise std: 1.78
          Mean value_function loss: 44.8735
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 51.7709
                       Mean reward: 84.08
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 0.9375
    Episode_Reward/rotating_object: 16.0212
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.33s
                      Time elapsed: 00:10:10
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 42292 steps/s (collection: 2.212s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 47.9341
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 51.8140
                       Mean reward: 96.84
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 0.9302
    Episode_Reward/rotating_object: 14.8334
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.32s
                      Time elapsed: 00:10:13
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 42267 steps/s (collection: 2.213s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 49.5110
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 51.8606
                       Mean reward: 85.69
               Mean episode length: 220.56
    Episode_Reward/reaching_object: 0.9283
    Episode_Reward/rotating_object: 16.4017
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.33s
                      Time elapsed: 00:10:15
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 42844 steps/s (collection: 2.182s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 52.7930
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.8978
                       Mean reward: 87.21
               Mean episode length: 222.60
    Episode_Reward/reaching_object: 0.9609
    Episode_Reward/rotating_object: 17.0399
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.29s
                      Time elapsed: 00:10:17
                               ETA: 00:47:35

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 42704 steps/s (collection: 2.189s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 53.1298
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 51.9286
                       Mean reward: 112.56
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 0.9611
    Episode_Reward/rotating_object: 15.6690
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.30s
                      Time elapsed: 00:10:20
                               ETA: 00:47:32

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 42616 steps/s (collection: 2.195s, learning 0.112s)
             Mean action noise std: 1.79
          Mean value_function loss: 53.7289
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 51.9553
                       Mean reward: 76.92
               Mean episode length: 218.43
    Episode_Reward/reaching_object: 0.9615
    Episode_Reward/rotating_object: 17.1815
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.31s
                      Time elapsed: 00:10:22
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 42381 steps/s (collection: 2.207s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 52.8745
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.9880
                       Mean reward: 78.96
               Mean episode length: 220.58
    Episode_Reward/reaching_object: 0.9867
    Episode_Reward/rotating_object: 17.3229
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.32s
                      Time elapsed: 00:10:24
                               ETA: 00:47:28

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 42647 steps/s (collection: 2.191s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 54.9323
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.0208
                       Mean reward: 84.76
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 0.9947
    Episode_Reward/rotating_object: 16.1094
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.31s
                      Time elapsed: 00:10:26
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 42558 steps/s (collection: 2.198s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 55.9620
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 52.0489
                       Mean reward: 119.84
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 1.0230
    Episode_Reward/rotating_object: 16.5235
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.31s
                      Time elapsed: 00:10:29
                               ETA: 00:47:23

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 42250 steps/s (collection: 2.213s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 52.9452
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 52.0916
                       Mean reward: 104.56
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 0.9641
    Episode_Reward/rotating_object: 16.2079
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.33s
                      Time elapsed: 00:10:31
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 42060 steps/s (collection: 2.225s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 57.4967
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 52.1311
                       Mean reward: 77.98
               Mean episode length: 216.94
    Episode_Reward/reaching_object: 0.9704
    Episode_Reward/rotating_object: 16.2104
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.34s
                      Time elapsed: 00:10:33
                               ETA: 00:47:18

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 41197 steps/s (collection: 2.273s, learning 0.113s)
             Mean action noise std: 1.81
          Mean value_function loss: 53.9162
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.1658
                       Mean reward: 83.37
               Mean episode length: 218.40
    Episode_Reward/reaching_object: 1.0183
    Episode_Reward/rotating_object: 18.6877
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.39s
                      Time elapsed: 00:10:36
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 41914 steps/s (collection: 2.230s, learning 0.115s)
             Mean action noise std: 1.81
          Mean value_function loss: 46.9527
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 52.2026
                       Mean reward: 126.73
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.0283
    Episode_Reward/rotating_object: 19.3368
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.35s
                      Time elapsed: 00:10:38
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 41954 steps/s (collection: 2.228s, learning 0.115s)
             Mean action noise std: 1.81
          Mean value_function loss: 51.4842
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 52.2402
                       Mean reward: 103.16
               Mean episode length: 213.63
    Episode_Reward/reaching_object: 0.9795
    Episode_Reward/rotating_object: 17.3229
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.34s
                      Time elapsed: 00:10:41
                               ETA: 00:47:12

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 42327 steps/s (collection: 2.210s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 50.9548
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 52.2766
                       Mean reward: 97.01
               Mean episode length: 221.55
    Episode_Reward/reaching_object: 1.0203
    Episode_Reward/rotating_object: 18.5074
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.32s
                      Time elapsed: 00:10:43
                               ETA: 00:47:10

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 41841 steps/s (collection: 2.232s, learning 0.117s)
             Mean action noise std: 1.82
          Mean value_function loss: 56.4525
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 52.3032
                       Mean reward: 119.13
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 19.7337
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.35s
                      Time elapsed: 00:10:45
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 42045 steps/s (collection: 2.221s, learning 0.117s)
             Mean action noise std: 1.82
          Mean value_function loss: 57.1271
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.3362
                       Mean reward: 86.25
               Mean episode length: 219.02
    Episode_Reward/reaching_object: 1.0223
    Episode_Reward/rotating_object: 18.9669
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.34s
                      Time elapsed: 00:10:48
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 42058 steps/s (collection: 2.221s, learning 0.116s)
             Mean action noise std: 1.82
          Mean value_function loss: 52.7350
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 52.3692
                       Mean reward: 116.94
               Mean episode length: 223.14
    Episode_Reward/reaching_object: 1.0236
    Episode_Reward/rotating_object: 21.5498
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.34s
                      Time elapsed: 00:10:50
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 41620 steps/s (collection: 2.248s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 58.5327
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.3969
                       Mean reward: 89.55
               Mean episode length: 220.98
    Episode_Reward/reaching_object: 1.0165
    Episode_Reward/rotating_object: 20.0957
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.36s
                      Time elapsed: 00:10:52
                               ETA: 00:47:01

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 41478 steps/s (collection: 2.256s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 60.0990
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 52.4216
                       Mean reward: 88.76
               Mean episode length: 220.23
    Episode_Reward/reaching_object: 1.0329
    Episode_Reward/rotating_object: 19.5020
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.37s
                      Time elapsed: 00:10:55
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 41787 steps/s (collection: 2.238s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 58.2418
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 52.4578
                       Mean reward: 129.95
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 19.9125
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.35s
                      Time elapsed: 00:10:57
                               ETA: 00:46:57

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 42091 steps/s (collection: 2.222s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 57.2414
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.4962
                       Mean reward: 127.12
               Mean episode length: 226.85
    Episode_Reward/reaching_object: 1.0722
    Episode_Reward/rotating_object: 20.2005
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.34s
                      Time elapsed: 00:10:59
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 42142 steps/s (collection: 2.218s, learning 0.114s)
             Mean action noise std: 1.83
          Mean value_function loss: 55.3431
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 52.5227
                       Mean reward: 138.45
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 1.0859
    Episode_Reward/rotating_object: 24.6919
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.33s
                      Time elapsed: 00:11:02
                               ETA: 00:46:52

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 41512 steps/s (collection: 2.242s, learning 0.126s)
             Mean action noise std: 1.84
          Mean value_function loss: 58.9510
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.5533
                       Mean reward: 101.61
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 1.0553
    Episode_Reward/rotating_object: 20.2738
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.37s
                      Time elapsed: 00:11:04
                               ETA: 00:46:50

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 42417 steps/s (collection: 2.204s, learning 0.113s)
             Mean action noise std: 1.84
          Mean value_function loss: 64.6995
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.5803
                       Mean reward: 108.47
               Mean episode length: 216.45
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 22.8023
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.32s
                      Time elapsed: 00:11:06
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 42490 steps/s (collection: 2.202s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 59.6041
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 52.6048
                       Mean reward: 95.71
               Mean episode length: 221.17
    Episode_Reward/reaching_object: 1.0959
    Episode_Reward/rotating_object: 23.6133
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.31s
                      Time elapsed: 00:11:09
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 43096 steps/s (collection: 2.169s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 50.6623
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 52.6364
                       Mean reward: 117.32
               Mean episode length: 214.27
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 21.3271
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.28s
                      Time elapsed: 00:11:11
                               ETA: 00:46:43

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 42665 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 1.84
          Mean value_function loss: 53.9925
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 52.6658
                       Mean reward: 124.73
               Mean episode length: 212.17
    Episode_Reward/reaching_object: 1.0243
    Episode_Reward/rotating_object: 23.3555
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.30s
                      Time elapsed: 00:11:13
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 42263 steps/s (collection: 2.213s, learning 0.113s)
             Mean action noise std: 1.85
          Mean value_function loss: 52.2073
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 52.6947
                       Mean reward: 138.89
               Mean episode length: 207.69
    Episode_Reward/reaching_object: 1.0224
    Episode_Reward/rotating_object: 22.3799
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.33s
                      Time elapsed: 00:11:16
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 41562 steps/s (collection: 2.236s, learning 0.129s)
             Mean action noise std: 1.85
          Mean value_function loss: 56.6671
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.7156
                       Mean reward: 95.99
               Mean episode length: 207.90
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 23.9781
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.37s
                      Time elapsed: 00:11:18
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 41279 steps/s (collection: 2.252s, learning 0.129s)
             Mean action noise std: 1.85
          Mean value_function loss: 60.7284
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 52.7340
                       Mean reward: 124.92
               Mean episode length: 219.92
    Episode_Reward/reaching_object: 1.0357
    Episode_Reward/rotating_object: 23.2901
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.38s
                      Time elapsed: 00:11:20
                               ETA: 00:46:34

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 41308 steps/s (collection: 2.265s, learning 0.115s)
             Mean action noise std: 1.85
          Mean value_function loss: 60.6459
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 52.7628
                       Mean reward: 130.20
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 23.8504
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.38s
                      Time elapsed: 00:11:23
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 41495 steps/s (collection: 2.254s, learning 0.115s)
             Mean action noise std: 1.85
          Mean value_function loss: 55.8267
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.7935
                       Mean reward: 110.91
               Mean episode length: 224.94
    Episode_Reward/reaching_object: 1.0881
    Episode_Reward/rotating_object: 21.7348
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.37s
                      Time elapsed: 00:11:25
                               ETA: 00:46:30

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 41535 steps/s (collection: 2.251s, learning 0.116s)
             Mean action noise std: 1.86
          Mean value_function loss: 51.5157
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.8176
                       Mean reward: 124.94
               Mean episode length: 219.92
    Episode_Reward/reaching_object: 1.0725
    Episode_Reward/rotating_object: 23.9736
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.37s
                      Time elapsed: 00:11:27
                               ETA: 00:46:28

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 41324 steps/s (collection: 2.262s, learning 0.117s)
             Mean action noise std: 1.86
          Mean value_function loss: 50.3232
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 52.8392
                       Mean reward: 148.57
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 24.6452
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.38s
                      Time elapsed: 00:11:30
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 41555 steps/s (collection: 2.251s, learning 0.114s)
             Mean action noise std: 1.86
          Mean value_function loss: 57.1530
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 52.8624
                       Mean reward: 138.08
               Mean episode length: 226.28
    Episode_Reward/reaching_object: 1.0909
    Episode_Reward/rotating_object: 25.0557
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.37s
                      Time elapsed: 00:11:32
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 41953 steps/s (collection: 2.231s, learning 0.112s)
             Mean action noise std: 1.86
          Mean value_function loss: 61.4151
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.8881
                       Mean reward: 105.33
               Mean episode length: 210.43
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 23.8312
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.34s
                      Time elapsed: 00:11:34
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 41396 steps/s (collection: 2.252s, learning 0.123s)
             Mean action noise std: 1.86
          Mean value_function loss: 61.8472
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 52.9055
                       Mean reward: 148.14
               Mean episode length: 222.60
    Episode_Reward/reaching_object: 1.0986
    Episode_Reward/rotating_object: 26.1458
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.37s
                      Time elapsed: 00:11:37
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 41284 steps/s (collection: 2.264s, learning 0.118s)
             Mean action noise std: 1.86
          Mean value_function loss: 73.7214
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 52.9261
                       Mean reward: 151.70
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.1154
    Episode_Reward/rotating_object: 24.0307
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.38s
                      Time elapsed: 00:11:39
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 41102 steps/s (collection: 2.277s, learning 0.114s)
             Mean action noise std: 1.86
          Mean value_function loss: 63.3735
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 52.9444
                       Mean reward: 147.78
               Mean episode length: 225.53
    Episode_Reward/reaching_object: 1.1258
    Episode_Reward/rotating_object: 28.6043
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.39s
                      Time elapsed: 00:11:42
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 41725 steps/s (collection: 2.240s, learning 0.116s)
             Mean action noise std: 1.87
          Mean value_function loss: 69.0266
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 52.9726
                       Mean reward: 134.64
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.1272
    Episode_Reward/rotating_object: 26.1498
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.36s
                      Time elapsed: 00:11:44
                               ETA: 00:46:13

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 41789 steps/s (collection: 2.240s, learning 0.112s)
             Mean action noise std: 1.87
          Mean value_function loss: 56.4247
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.9943
                       Mean reward: 124.85
               Mean episode length: 225.71
    Episode_Reward/reaching_object: 1.1353
    Episode_Reward/rotating_object: 23.9710
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.35s
                      Time elapsed: 00:11:46
                               ETA: 00:46:11

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 41713 steps/s (collection: 2.245s, learning 0.112s)
             Mean action noise std: 1.87
          Mean value_function loss: 54.1055
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.0181
                       Mean reward: 129.72
               Mean episode length: 226.35
    Episode_Reward/reaching_object: 1.1486
    Episode_Reward/rotating_object: 24.1495
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.36s
                      Time elapsed: 00:11:49
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 41704 steps/s (collection: 2.246s, learning 0.112s)
             Mean action noise std: 1.87
          Mean value_function loss: 55.4531
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.0452
                       Mean reward: 135.24
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 26.0871
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.36s
                      Time elapsed: 00:11:51
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 41692 steps/s (collection: 2.241s, learning 0.116s)
             Mean action noise std: 1.87
          Mean value_function loss: 52.4445
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 53.0696
                       Mean reward: 129.09
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.1583
    Episode_Reward/rotating_object: 26.7342
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.36s
                      Time elapsed: 00:11:53
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 42048 steps/s (collection: 2.222s, learning 0.116s)
             Mean action noise std: 1.88
          Mean value_function loss: 57.6324
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.0888
                       Mean reward: 108.49
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.1578
    Episode_Reward/rotating_object: 26.8579
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.34s
                      Time elapsed: 00:11:56
                               ETA: 00:46:02

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 42111 steps/s (collection: 2.222s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 54.7831
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.1156
                       Mean reward: 153.83
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 1.1476
    Episode_Reward/rotating_object: 29.0104
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.33s
                      Time elapsed: 00:11:58
                               ETA: 00:46:00

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 41972 steps/s (collection: 2.226s, learning 0.116s)
             Mean action noise std: 1.88
          Mean value_function loss: 61.6990
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 53.1419
                       Mean reward: 152.16
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 1.1215
    Episode_Reward/rotating_object: 25.9555
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.34s
                      Time elapsed: 00:12:00
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 42219 steps/s (collection: 2.216s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 57.5215
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.1662
                       Mean reward: 140.75
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.1491
    Episode_Reward/rotating_object: 31.1636
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.33s
                      Time elapsed: 00:12:03
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 41852 steps/s (collection: 2.237s, learning 0.112s)
             Mean action noise std: 1.88
          Mean value_function loss: 56.6074
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 53.1909
                       Mean reward: 141.69
               Mean episode length: 214.76
    Episode_Reward/reaching_object: 1.1265
    Episode_Reward/rotating_object: 31.8125
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.35s
                      Time elapsed: 00:12:05
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 42041 steps/s (collection: 2.226s, learning 0.112s)
             Mean action noise std: 1.89
          Mean value_function loss: 58.7396
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 53.2189
                       Mean reward: 169.54
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.1585
    Episode_Reward/rotating_object: 30.2591
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.34s
                      Time elapsed: 00:12:07
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 41975 steps/s (collection: 2.228s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 60.4990
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.2423
                       Mean reward: 156.74
               Mean episode length: 223.24
    Episode_Reward/reaching_object: 1.1179
    Episode_Reward/rotating_object: 29.1510
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.34s
                      Time elapsed: 00:12:10
                               ETA: 00:45:49

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 41879 steps/s (collection: 2.233s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 55.7751
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.2626
                       Mean reward: 179.79
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 1.1348
    Episode_Reward/rotating_object: 32.9215
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.35s
                      Time elapsed: 00:12:12
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 41155 steps/s (collection: 2.275s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 66.5691
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.2910
                       Mean reward: 163.75
               Mean episode length: 224.98
    Episode_Reward/reaching_object: 1.1362
    Episode_Reward/rotating_object: 29.1527
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.39s
                      Time elapsed: 00:12:15
                               ETA: 00:45:45

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 41059 steps/s (collection: 2.278s, learning 0.117s)
             Mean action noise std: 1.89
          Mean value_function loss: 68.2503
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.3189
                       Mean reward: 168.14
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.1628
    Episode_Reward/rotating_object: 30.4137
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.39s
                      Time elapsed: 00:12:17
                               ETA: 00:45:43

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 41224 steps/s (collection: 2.270s, learning 0.115s)
             Mean action noise std: 1.89
          Mean value_function loss: 72.8336
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.3417
                       Mean reward: 148.22
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 1.1467
    Episode_Reward/rotating_object: 31.0234
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.38s
                      Time elapsed: 00:12:19
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 41749 steps/s (collection: 2.237s, learning 0.118s)
             Mean action noise std: 1.90
          Mean value_function loss: 66.0815
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 53.3614
                       Mean reward: 193.94
               Mean episode length: 222.26
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 31.1971
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.35s
                      Time elapsed: 00:12:22
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 41419 steps/s (collection: 2.260s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 63.3525
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 53.3858
                       Mean reward: 179.05
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.1744
    Episode_Reward/rotating_object: 33.2747
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.37s
                      Time elapsed: 00:12:24
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 41508 steps/s (collection: 2.253s, learning 0.115s)
             Mean action noise std: 1.90
          Mean value_function loss: 69.2791
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 53.4071
                       Mean reward: 158.06
               Mean episode length: 218.35
    Episode_Reward/reaching_object: 1.1694
    Episode_Reward/rotating_object: 31.9817
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.37s
                      Time elapsed: 00:12:26
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 41588 steps/s (collection: 2.251s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 66.3908
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.4247
                       Mean reward: 177.09
               Mean episode length: 233.44
    Episode_Reward/reaching_object: 1.1536
    Episode_Reward/rotating_object: 31.7392
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.36s
                      Time elapsed: 00:12:29
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 41522 steps/s (collection: 2.243s, learning 0.124s)
             Mean action noise std: 1.90
          Mean value_function loss: 71.0480
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.4456
                       Mean reward: 140.92
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.1501
    Episode_Reward/rotating_object: 29.5305
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.37s
                      Time elapsed: 00:12:31
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 41850 steps/s (collection: 2.236s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 57.8332
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 53.4700
                       Mean reward: 170.08
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 1.1568
    Episode_Reward/rotating_object: 34.0759
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.35s
                      Time elapsed: 00:12:33
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 41611 steps/s (collection: 2.248s, learning 0.115s)
             Mean action noise std: 1.91
          Mean value_function loss: 65.6045
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 53.4961
                       Mean reward: 168.13
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.1413
    Episode_Reward/rotating_object: 31.5748
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.36s
                      Time elapsed: 00:12:36
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 41967 steps/s (collection: 2.229s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 67.5736
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.5257
                       Mean reward: 191.72
               Mean episode length: 219.53
    Episode_Reward/reaching_object: 1.1439
    Episode_Reward/rotating_object: 33.7431
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.34s
                      Time elapsed: 00:12:38
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 41990 steps/s (collection: 2.228s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 70.8408
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 53.5480
                       Mean reward: 166.16
               Mean episode length: 219.41
    Episode_Reward/reaching_object: 1.1386
    Episode_Reward/rotating_object: 34.1374
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.34s
                      Time elapsed: 00:12:41
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 41703 steps/s (collection: 2.244s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 64.9676
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 53.5693
                       Mean reward: 181.54
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.1413
    Episode_Reward/rotating_object: 32.0542
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.36s
                      Time elapsed: 00:12:43
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 42002 steps/s (collection: 2.228s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 62.3068
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 53.5918
                       Mean reward: 171.04
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.1760
    Episode_Reward/rotating_object: 34.9798
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.34s
                      Time elapsed: 00:12:45
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 42295 steps/s (collection: 2.212s, learning 0.112s)
             Mean action noise std: 1.91
          Mean value_function loss: 65.5148
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.6098
                       Mean reward: 150.93
               Mean episode length: 213.45
    Episode_Reward/reaching_object: 1.1469
    Episode_Reward/rotating_object: 33.1109
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.32s
                      Time elapsed: 00:12:48
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 42466 steps/s (collection: 2.203s, learning 0.112s)
             Mean action noise std: 1.92
          Mean value_function loss: 66.2912
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.6265
                       Mean reward: 175.82
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 1.1524
    Episode_Reward/rotating_object: 36.0706
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.31s
                      Time elapsed: 00:12:50
                               ETA: 00:45:12

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 42127 steps/s (collection: 2.219s, learning 0.115s)
             Mean action noise std: 1.92
          Mean value_function loss: 62.8812
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.6506
                       Mean reward: 157.93
               Mean episode length: 224.98
    Episode_Reward/reaching_object: 1.1494
    Episode_Reward/rotating_object: 32.3209
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.33s
                      Time elapsed: 00:12:52
                               ETA: 00:45:10

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 42556 steps/s (collection: 2.198s, learning 0.112s)
             Mean action noise std: 1.92
          Mean value_function loss: 60.0044
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.6684
                       Mean reward: 160.35
               Mean episode length: 221.03
    Episode_Reward/reaching_object: 1.1533
    Episode_Reward/rotating_object: 31.0376
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 2.31s
                      Time elapsed: 00:12:54
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 41805 steps/s (collection: 2.239s, learning 0.112s)
             Mean action noise std: 1.92
          Mean value_function loss: 65.8851
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.6830
                       Mean reward: 193.38
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.1721
    Episode_Reward/rotating_object: 34.2029
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 2.35s
                      Time elapsed: 00:12:57
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 42249 steps/s (collection: 2.211s, learning 0.116s)
             Mean action noise std: 1.92
          Mean value_function loss: 67.7873
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 53.7042
                       Mean reward: 179.54
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 1.1960
    Episode_Reward/rotating_object: 36.5138
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 2.33s
                      Time elapsed: 00:12:59
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 41990 steps/s (collection: 2.227s, learning 0.114s)
             Mean action noise std: 1.92
          Mean value_function loss: 68.7775
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.7215
                       Mean reward: 210.24
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.2019
    Episode_Reward/rotating_object: 35.3854
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 2.34s
                      Time elapsed: 00:13:02
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 41601 steps/s (collection: 2.247s, learning 0.116s)
             Mean action noise std: 1.92
          Mean value_function loss: 72.5993
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.7374
                       Mean reward: 192.14
               Mean episode length: 224.09
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 35.3831
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 2.36s
                      Time elapsed: 00:13:04
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 41525 steps/s (collection: 2.253s, learning 0.114s)
             Mean action noise std: 1.93
          Mean value_function loss: 69.3311
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.7548
                       Mean reward: 169.08
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 35.1506
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 2.37s
                      Time elapsed: 00:13:06
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 41226 steps/s (collection: 2.272s, learning 0.112s)
             Mean action noise std: 1.93
          Mean value_function loss: 67.7013
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.7751
                       Mean reward: 200.31
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 37.0711
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 2.38s
                      Time elapsed: 00:13:09
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 41306 steps/s (collection: 2.264s, learning 0.116s)
             Mean action noise std: 1.93
          Mean value_function loss: 74.4675
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 53.7998
                       Mean reward: 198.63
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.1846
    Episode_Reward/rotating_object: 39.7144
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 2.38s
                      Time elapsed: 00:13:11
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 41739 steps/s (collection: 2.240s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 62.6305
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.8268
                       Mean reward: 153.29
               Mean episode length: 219.09
    Episode_Reward/reaching_object: 1.1729
    Episode_Reward/rotating_object: 34.7027
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 2.36s
                      Time elapsed: 00:13:13
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 41402 steps/s (collection: 2.259s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 74.2723
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 53.8506
                       Mean reward: 178.45
               Mean episode length: 218.34
    Episode_Reward/reaching_object: 1.1771
    Episode_Reward/rotating_object: 37.6200
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.37s
                      Time elapsed: 00:13:16
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 41440 steps/s (collection: 2.244s, learning 0.128s)
             Mean action noise std: 1.93
          Mean value_function loss: 66.5607
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 53.8707
                       Mean reward: 168.24
               Mean episode length: 228.80
    Episode_Reward/reaching_object: 1.1804
    Episode_Reward/rotating_object: 36.7782
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.37s
                      Time elapsed: 00:13:18
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 41334 steps/s (collection: 2.257s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 69.6888
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 53.8906
                       Mean reward: 227.03
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.2066
    Episode_Reward/rotating_object: 39.4333
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.38s
                      Time elapsed: 00:13:20
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 41563 steps/s (collection: 2.251s, learning 0.114s)
             Mean action noise std: 1.94
          Mean value_function loss: 66.4051
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.9156
                       Mean reward: 216.01
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 1.1459
    Episode_Reward/rotating_object: 38.2922
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.37s
                      Time elapsed: 00:13:23
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 41667 steps/s (collection: 2.245s, learning 0.115s)
             Mean action noise std: 1.94
          Mean value_function loss: 68.5897
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.9361
                       Mean reward: 189.95
               Mean episode length: 218.65
    Episode_Reward/reaching_object: 1.1585
    Episode_Reward/rotating_object: 39.3364
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.36s
                      Time elapsed: 00:13:25
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 41223 steps/s (collection: 2.263s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 73.1167
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.9531
                       Mean reward: 205.49
               Mean episode length: 221.38
    Episode_Reward/reaching_object: 1.1699
    Episode_Reward/rotating_object: 38.3985
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.38s
                      Time elapsed: 00:13:28
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 41656 steps/s (collection: 2.247s, learning 0.113s)
             Mean action noise std: 1.94
          Mean value_function loss: 64.2561
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.9676
                       Mean reward: 197.59
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 37.6301
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.36s
                      Time elapsed: 00:13:30
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 41702 steps/s (collection: 2.244s, learning 0.113s)
             Mean action noise std: 1.94
          Mean value_function loss: 73.0663
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.9882
                       Mean reward: 183.76
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.1957
    Episode_Reward/rotating_object: 37.9668
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.36s
                      Time elapsed: 00:13:32
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 41987 steps/s (collection: 2.229s, learning 0.112s)
             Mean action noise std: 1.94
          Mean value_function loss: 70.6863
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.0082
                       Mean reward: 195.28
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.1527
    Episode_Reward/rotating_object: 35.4305
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.34s
                      Time elapsed: 00:13:35
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 42173 steps/s (collection: 2.219s, learning 0.112s)
             Mean action noise std: 1.95
          Mean value_function loss: 65.1515
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.0275
                       Mean reward: 198.36
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 1.1993
    Episode_Reward/rotating_object: 38.7849
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.33s
                      Time elapsed: 00:13:37
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 42365 steps/s (collection: 2.208s, learning 0.112s)
             Mean action noise std: 1.95
          Mean value_function loss: 66.3963
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.0413
                       Mean reward: 195.88
               Mean episode length: 228.49
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 38.1351
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.32s
                      Time elapsed: 00:13:39
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 42340 steps/s (collection: 2.209s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 74.1900
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.0587
                       Mean reward: 195.67
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 41.1332
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.32s
                      Time elapsed: 00:13:42
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 42051 steps/s (collection: 2.224s, learning 0.114s)
             Mean action noise std: 1.95
          Mean value_function loss: 84.7782
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.0805
                       Mean reward: 228.12
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 1.1953
    Episode_Reward/rotating_object: 42.0688
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.34s
                      Time elapsed: 00:13:44
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 41660 steps/s (collection: 2.244s, learning 0.116s)
             Mean action noise std: 1.95
          Mean value_function loss: 77.8118
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.0949
                       Mean reward: 231.11
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.2256
    Episode_Reward/rotating_object: 41.2262
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.36s
                      Time elapsed: 00:13:46
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 41662 steps/s (collection: 2.244s, learning 0.115s)
             Mean action noise std: 1.95
          Mean value_function loss: 85.6124
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.1041
                       Mean reward: 226.84
               Mean episode length: 229.40
    Episode_Reward/reaching_object: 1.1882
    Episode_Reward/rotating_object: 41.2248
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.36s
                      Time elapsed: 00:13:49
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 40843 steps/s (collection: 2.293s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 83.4864
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.1167
                       Mean reward: 215.31
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 38.8973
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.41s
                      Time elapsed: 00:13:51
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 41438 steps/s (collection: 2.258s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 81.7800
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.1351
                       Mean reward: 228.28
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 1.2131
    Episode_Reward/rotating_object: 42.2434
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.37s
                      Time elapsed: 00:13:53
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 40705 steps/s (collection: 2.289s, learning 0.126s)
             Mean action noise std: 1.96
          Mean value_function loss: 92.9322
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.1547
                       Mean reward: 239.00
               Mean episode length: 221.12
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 44.3671
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.41s
                      Time elapsed: 00:13:56
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 41551 steps/s (collection: 2.251s, learning 0.115s)
             Mean action noise std: 1.96
          Mean value_function loss: 83.0694
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.1667
                       Mean reward: 228.28
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.2314
    Episode_Reward/rotating_object: 41.9516
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.37s
                      Time elapsed: 00:13:58
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 41186 steps/s (collection: 2.271s, learning 0.116s)
             Mean action noise std: 1.96
          Mean value_function loss: 85.7580
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.1833
                       Mean reward: 210.14
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 1.2206
    Episode_Reward/rotating_object: 44.7219
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.39s
                      Time elapsed: 00:14:01
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 41508 steps/s (collection: 2.253s, learning 0.115s)
             Mean action noise std: 1.96
          Mean value_function loss: 85.9712
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.2068
                       Mean reward: 234.91
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 43.0909
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.37s
                      Time elapsed: 00:14:03
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 41358 steps/s (collection: 2.263s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 73.4442
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.2321
                       Mean reward: 241.83
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 48.1501
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.38s
                      Time elapsed: 00:14:05
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 41338 steps/s (collection: 2.251s, learning 0.127s)
             Mean action noise std: 1.96
          Mean value_function loss: 76.6910
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.2486
                       Mean reward: 204.00
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 42.4629
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.38s
                      Time elapsed: 00:14:08
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 41301 steps/s (collection: 2.250s, learning 0.130s)
             Mean action noise std: 1.97
          Mean value_function loss: 73.6397
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.2664
                       Mean reward: 244.22
               Mean episode length: 221.26
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 45.9539
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.38s
                      Time elapsed: 00:14:10
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 41844 steps/s (collection: 2.236s, learning 0.113s)
             Mean action noise std: 1.97
          Mean value_function loss: 71.8122
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.2845
                       Mean reward: 233.74
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 46.3908
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.35s
                      Time elapsed: 00:14:12
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 41179 steps/s (collection: 2.275s, learning 0.112s)
             Mean action noise std: 1.97
          Mean value_function loss: 85.2719
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 54.2998
                       Mean reward: 239.93
               Mean episode length: 238.68
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 44.7155
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.39s
                      Time elapsed: 00:14:15
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 41412 steps/s (collection: 2.261s, learning 0.113s)
             Mean action noise std: 1.97
          Mean value_function loss: 75.8871
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.3163
                       Mean reward: 221.98
               Mean episode length: 229.45
    Episode_Reward/reaching_object: 1.1957
    Episode_Reward/rotating_object: 42.7035
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.37s
                      Time elapsed: 00:14:17
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 41654 steps/s (collection: 2.246s, learning 0.114s)
             Mean action noise std: 1.97
          Mean value_function loss: 76.8014
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.3289
                       Mean reward: 211.36
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 1.1872
    Episode_Reward/rotating_object: 42.6907
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.36s
                      Time elapsed: 00:14:20
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 41604 steps/s (collection: 2.247s, learning 0.116s)
             Mean action noise std: 1.97
          Mean value_function loss: 73.1128
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.3473
                       Mean reward: 212.31
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 44.8530
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.36s
                      Time elapsed: 00:14:22
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 40452 steps/s (collection: 2.283s, learning 0.147s)
             Mean action noise std: 1.97
          Mean value_function loss: 79.1803
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.3703
                       Mean reward: 213.40
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 40.3070
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.43s
                      Time elapsed: 00:14:24
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 39878 steps/s (collection: 2.331s, learning 0.135s)
             Mean action noise std: 1.97
          Mean value_function loss: 72.8708
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.3853
                       Mean reward: 210.53
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 41.5244
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.47s
                      Time elapsed: 00:14:27
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 42630 steps/s (collection: 2.195s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 75.7544
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.3988
                       Mean reward: 232.85
               Mean episode length: 223.90
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 46.7864
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.31s
                      Time elapsed: 00:14:29
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 41778 steps/s (collection: 2.240s, learning 0.113s)
             Mean action noise std: 1.98
          Mean value_function loss: 78.3602
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.4148
                       Mean reward: 257.36
               Mean episode length: 225.08
    Episode_Reward/reaching_object: 1.2045
    Episode_Reward/rotating_object: 42.6064
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.35s
                      Time elapsed: 00:14:32
                               ETA: 00:43:38

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 42159 steps/s (collection: 2.219s, learning 0.112s)
             Mean action noise std: 1.98
          Mean value_function loss: 79.4455
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.4337
                       Mean reward: 251.59
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.1814
    Episode_Reward/rotating_object: 41.6086
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.33s
                      Time elapsed: 00:14:34
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 40812 steps/s (collection: 2.294s, learning 0.114s)
             Mean action noise std: 1.98
          Mean value_function loss: 70.7893
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.4530
                       Mean reward: 247.60
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.2743
    Episode_Reward/rotating_object: 47.4779
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.41s
                      Time elapsed: 00:14:36
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 41855 steps/s (collection: 2.234s, learning 0.115s)
             Mean action noise std: 1.98
          Mean value_function loss: 70.3505
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 54.4667
                       Mean reward: 229.54
               Mean episode length: 222.03
    Episode_Reward/reaching_object: 1.2254
    Episode_Reward/rotating_object: 46.4345
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.35s
                      Time elapsed: 00:14:39
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 41365 steps/s (collection: 2.263s, learning 0.114s)
             Mean action noise std: 1.98
          Mean value_function loss: 77.3327
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 54.4810
                       Mean reward: 186.99
               Mean episode length: 229.10
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 42.0387
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.38s
                      Time elapsed: 00:14:41
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 40905 steps/s (collection: 2.285s, learning 0.118s)
             Mean action noise std: 1.98
          Mean value_function loss: 85.6688
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.5016
                       Mean reward: 205.98
               Mean episode length: 221.95
    Episode_Reward/reaching_object: 1.1737
    Episode_Reward/rotating_object: 43.3164
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.40s
                      Time elapsed: 00:14:43
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 41861 steps/s (collection: 2.235s, learning 0.113s)
             Mean action noise std: 1.99
          Mean value_function loss: 83.3055
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.5241
                       Mean reward: 274.43
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 45.3192
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.35s
                      Time elapsed: 00:14:46
                               ETA: 00:43:25

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 41589 steps/s (collection: 2.251s, learning 0.113s)
             Mean action noise std: 1.99
          Mean value_function loss: 83.1450
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.5444
                       Mean reward: 248.10
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 45.1011
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.36s
                      Time elapsed: 00:14:48
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 41915 steps/s (collection: 2.231s, learning 0.114s)
             Mean action noise std: 1.99
          Mean value_function loss: 81.8387
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 54.5652
                       Mean reward: 237.41
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.2045
    Episode_Reward/rotating_object: 46.1180
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.35s
                      Time elapsed: 00:14:50
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 41504 steps/s (collection: 2.253s, learning 0.115s)
             Mean action noise std: 1.99
          Mean value_function loss: 75.8488
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.5808
                       Mean reward: 235.29
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 47.7362
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.37s
                      Time elapsed: 00:14:53
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 41367 steps/s (collection: 2.262s, learning 0.115s)
             Mean action noise std: 1.99
          Mean value_function loss: 71.0912
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.5944
                       Mean reward: 276.28
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 48.5276
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.38s
                      Time elapsed: 00:14:55
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 41138 steps/s (collection: 2.274s, learning 0.116s)
             Mean action noise std: 1.99
          Mean value_function loss: 75.9750
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.6137
                       Mean reward: 210.44
               Mean episode length: 213.40
    Episode_Reward/reaching_object: 1.1828
    Episode_Reward/rotating_object: 45.0454
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.39s
                      Time elapsed: 00:14:58
                               ETA: 00:43:14

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 41575 steps/s (collection: 2.253s, learning 0.112s)
             Mean action noise std: 1.99
          Mean value_function loss: 73.1383
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.6403
                       Mean reward: 254.16
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.2207
    Episode_Reward/rotating_object: 47.6170
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.36s
                      Time elapsed: 00:15:00
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 41487 steps/s (collection: 2.256s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 77.2128
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 54.6570
                       Mean reward: 199.14
               Mean episode length: 220.65
    Episode_Reward/reaching_object: 1.1929
    Episode_Reward/rotating_object: 46.7357
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.37s
                      Time elapsed: 00:15:02
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 41698 steps/s (collection: 2.245s, learning 0.113s)
             Mean action noise std: 2.00
          Mean value_function loss: 77.1862
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 54.6716
                       Mean reward: 257.49
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 46.7161
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.36s
                      Time elapsed: 00:15:05
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 41270 steps/s (collection: 2.269s, learning 0.113s)
             Mean action noise std: 2.00
          Mean value_function loss: 84.1118
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.6880
                       Mean reward: 245.35
               Mean episode length: 238.68
    Episode_Reward/reaching_object: 1.2450
    Episode_Reward/rotating_object: 50.2378
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.38s
                      Time elapsed: 00:15:07
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 41500 steps/s (collection: 2.256s, learning 0.113s)
             Mean action noise std: 2.00
          Mean value_function loss: 86.6904
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.7097
                       Mean reward: 201.93
               Mean episode length: 210.14
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 46.4044
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.37s
                      Time elapsed: 00:15:09
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 41286 steps/s (collection: 2.270s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 85.1327
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.7316
                       Mean reward: 259.63
               Mean episode length: 230.61
    Episode_Reward/reaching_object: 1.2488
    Episode_Reward/rotating_object: 51.7091
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.38s
                      Time elapsed: 00:15:12
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 41813 steps/s (collection: 2.235s, learning 0.116s)
             Mean action noise std: 2.00
          Mean value_function loss: 87.3445
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.7434
                       Mean reward: 215.65
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.2227
    Episode_Reward/rotating_object: 46.6145
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.35s
                      Time elapsed: 00:15:14
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 41992 steps/s (collection: 2.228s, learning 0.113s)
             Mean action noise std: 2.00
          Mean value_function loss: 89.7687
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 54.7626
                       Mean reward: 270.29
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 49.4927
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.34s
                      Time elapsed: 00:15:17
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 41960 steps/s (collection: 2.231s, learning 0.112s)
             Mean action noise std: 2.01
          Mean value_function loss: 83.2497
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.7801
                       Mean reward: 226.21
               Mean episode length: 224.04
    Episode_Reward/reaching_object: 1.2416
    Episode_Reward/rotating_object: 48.5418
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.34s
                      Time elapsed: 00:15:19
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 42022 steps/s (collection: 2.227s, learning 0.112s)
             Mean action noise std: 2.01
          Mean value_function loss: 73.8387
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.7948
                       Mean reward: 270.14
               Mean episode length: 224.02
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 52.9758
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.34s
                      Time elapsed: 00:15:21
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 42132 steps/s (collection: 2.206s, learning 0.127s)
             Mean action noise std: 2.01
          Mean value_function loss: 76.1555
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.8154
                       Mean reward: 267.52
               Mean episode length: 225.79
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 48.2228
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.33s
                      Time elapsed: 00:15:24
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 42453 steps/s (collection: 2.204s, learning 0.111s)
             Mean action noise std: 2.01
          Mean value_function loss: 78.6965
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 54.8335
                       Mean reward: 268.11
               Mean episode length: 223.95
    Episode_Reward/reaching_object: 1.2197
    Episode_Reward/rotating_object: 51.8128
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.32s
                      Time elapsed: 00:15:26
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 42180 steps/s (collection: 2.217s, learning 0.113s)
             Mean action noise std: 2.01
          Mean value_function loss: 74.0482
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.8495
                       Mean reward: 296.65
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 1.2445
    Episode_Reward/rotating_object: 53.3512
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.33s
                      Time elapsed: 00:15:28
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 42191 steps/s (collection: 2.216s, learning 0.114s)
             Mean action noise std: 2.01
          Mean value_function loss: 71.6501
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.8674
                       Mean reward: 263.52
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.2191
    Episode_Reward/rotating_object: 49.6227
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.33s
                      Time elapsed: 00:15:30
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 41287 steps/s (collection: 2.254s, learning 0.127s)
             Mean action noise std: 2.01
          Mean value_function loss: 74.1881
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.8818
                       Mean reward: 283.56
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.2525
    Episode_Reward/rotating_object: 55.9331
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.38s
                      Time elapsed: 00:15:33
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 41608 steps/s (collection: 2.237s, learning 0.125s)
             Mean action noise std: 2.02
          Mean value_function loss: 89.6421
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.9031
                       Mean reward: 267.83
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.2564
    Episode_Reward/rotating_object: 52.4088
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.36s
                      Time elapsed: 00:15:35
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 41710 steps/s (collection: 2.241s, learning 0.116s)
             Mean action noise std: 2.02
          Mean value_function loss: 89.9949
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 54.9208
                       Mean reward: 246.92
               Mean episode length: 215.70
    Episode_Reward/reaching_object: 1.2177
    Episode_Reward/rotating_object: 54.0662
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.36s
                      Time elapsed: 00:15:38
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 41590 steps/s (collection: 2.248s, learning 0.115s)
             Mean action noise std: 2.02
          Mean value_function loss: 83.7653
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.9355
                       Mean reward: 314.80
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 1.2730
    Episode_Reward/rotating_object: 57.6311
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.36s
                      Time elapsed: 00:15:40
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 42021 steps/s (collection: 2.224s, learning 0.116s)
             Mean action noise std: 2.02
          Mean value_function loss: 80.1529
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 54.9483
                       Mean reward: 263.27
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 1.2380
    Episode_Reward/rotating_object: 52.8294
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.34s
                      Time elapsed: 00:15:42
                               ETA: 00:42:31

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 42088 steps/s (collection: 2.222s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 78.2414
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.9625
                       Mean reward: 241.18
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.2522
    Episode_Reward/rotating_object: 52.2902
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.34s
                      Time elapsed: 00:15:45
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 41557 steps/s (collection: 2.252s, learning 0.114s)
             Mean action noise std: 2.02
          Mean value_function loss: 80.2377
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.9774
                       Mean reward: 287.73
               Mean episode length: 222.91
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 53.1346
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.37s
                      Time elapsed: 00:15:47
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 41837 steps/s (collection: 2.236s, learning 0.114s)
             Mean action noise std: 2.02
          Mean value_function loss: 72.8306
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.9941
                       Mean reward: 285.18
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 52.6667
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.35s
                      Time elapsed: 00:15:49
                               ETA: 00:42:24

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 41375 steps/s (collection: 2.261s, learning 0.115s)
             Mean action noise std: 2.02
          Mean value_function loss: 76.2348
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.0032
                       Mean reward: 294.81
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 56.0923
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.38s
                      Time elapsed: 00:15:52
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 41450 steps/s (collection: 2.251s, learning 0.121s)
             Mean action noise std: 2.03
          Mean value_function loss: 82.5840
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.0135
                       Mean reward: 319.21
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.2603
    Episode_Reward/rotating_object: 59.7830
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.37s
                      Time elapsed: 00:15:54
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 41610 steps/s (collection: 2.249s, learning 0.113s)
             Mean action noise std: 2.03
          Mean value_function loss: 79.4065
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.0261
                       Mean reward: 306.92
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.2872
    Episode_Reward/rotating_object: 60.7334
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.36s
                      Time elapsed: 00:15:56
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 41717 steps/s (collection: 2.244s, learning 0.112s)
             Mean action noise std: 2.03
          Mean value_function loss: 80.2366
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.0401
                       Mean reward: 287.92
               Mean episode length: 225.75
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 56.8961
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.36s
                      Time elapsed: 00:15:59
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 41741 steps/s (collection: 2.242s, learning 0.113s)
             Mean action noise std: 2.03
          Mean value_function loss: 88.6917
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.0621
                       Mean reward: 287.95
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.2452
    Episode_Reward/rotating_object: 54.9767
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.36s
                      Time elapsed: 00:16:01
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 42091 steps/s (collection: 2.219s, learning 0.116s)
             Mean action noise std: 2.03
          Mean value_function loss: 88.0512
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.0809
                       Mean reward: 282.66
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 56.2087
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.34s
                      Time elapsed: 00:16:04
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 42066 steps/s (collection: 2.209s, learning 0.128s)
             Mean action noise std: 2.03
          Mean value_function loss: 93.5615
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.0986
                       Mean reward: 264.97
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.2071
    Episode_Reward/rotating_object: 53.9254
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.34s
                      Time elapsed: 00:16:06
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 42210 steps/s (collection: 2.216s, learning 0.113s)
             Mean action noise std: 2.03
          Mean value_function loss: 85.3164
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 55.1133
                       Mean reward: 248.24
               Mean episode length: 225.62
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 55.7589
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.33s
                      Time elapsed: 00:16:08
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 42375 steps/s (collection: 2.204s, learning 0.115s)
             Mean action noise std: 2.03
          Mean value_function loss: 75.9275
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.1287
                       Mean reward: 297.28
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.2541
    Episode_Reward/rotating_object: 56.4308
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.32s
                      Time elapsed: 00:16:10
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 42158 steps/s (collection: 2.205s, learning 0.127s)
             Mean action noise std: 2.04
          Mean value_function loss: 72.9246
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.1449
                       Mean reward: 294.71
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.2743
    Episode_Reward/rotating_object: 58.5504
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.33s
                      Time elapsed: 00:16:13
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 41764 steps/s (collection: 2.235s, learning 0.119s)
             Mean action noise std: 2.04
          Mean value_function loss: 82.5262
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.1613
                       Mean reward: 304.54
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 58.0688
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.35s
                      Time elapsed: 00:16:15
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 41964 steps/s (collection: 2.228s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 76.8410
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.1798
                       Mean reward: 330.64
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 54.9947
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.34s
                      Time elapsed: 00:16:18
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 41329 steps/s (collection: 2.247s, learning 0.132s)
             Mean action noise std: 2.04
          Mean value_function loss: 81.0223
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.1955
                       Mean reward: 277.93
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 1.2465
    Episode_Reward/rotating_object: 57.6708
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.38s
                      Time elapsed: 00:16:20
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 41677 steps/s (collection: 2.243s, learning 0.116s)
             Mean action noise std: 2.04
          Mean value_function loss: 77.1599
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.2168
                       Mean reward: 325.29
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.2746
    Episode_Reward/rotating_object: 61.3438
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.36s
                      Time elapsed: 00:16:22
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 41378 steps/s (collection: 2.262s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 85.0029
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.2344
                       Mean reward: 325.01
               Mean episode length: 217.28
    Episode_Reward/reaching_object: 1.2021
    Episode_Reward/rotating_object: 57.6258
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.38s
                      Time elapsed: 00:16:25
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 41850 steps/s (collection: 2.233s, learning 0.116s)
             Mean action noise std: 2.04
          Mean value_function loss: 84.3631
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.2475
                       Mean reward: 323.04
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.2637
    Episode_Reward/rotating_object: 59.9099
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.35s
                      Time elapsed: 00:16:27
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 41636 steps/s (collection: 2.232s, learning 0.129s)
             Mean action noise std: 2.05
          Mean value_function loss: 87.1595
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.2626
                       Mean reward: 315.00
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.2532
    Episode_Reward/rotating_object: 60.7287
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.36s
                      Time elapsed: 00:16:29
                               ETA: 00:41:46

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 42116 steps/s (collection: 2.220s, learning 0.114s)
             Mean action noise std: 2.05
          Mean value_function loss: 81.6038
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2773
                       Mean reward: 334.29
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.2473
    Episode_Reward/rotating_object: 58.9787
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.33s
                      Time elapsed: 00:16:32
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 41772 steps/s (collection: 2.240s, learning 0.114s)
             Mean action noise std: 2.05
          Mean value_function loss: 83.3851
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.2871
                       Mean reward: 318.80
               Mean episode length: 219.01
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 59.3751
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.35s
                      Time elapsed: 00:16:34
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 41861 steps/s (collection: 2.233s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 83.7045
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.2978
                       Mean reward: 335.54
               Mean episode length: 226.96
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 64.4624
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.35s
                      Time elapsed: 00:16:36
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 41697 steps/s (collection: 2.238s, learning 0.120s)
             Mean action noise std: 2.05
          Mean value_function loss: 81.7370
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.3151
                       Mean reward: 329.25
               Mean episode length: 223.71
    Episode_Reward/reaching_object: 1.2578
    Episode_Reward/rotating_object: 63.0862
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.36s
                      Time elapsed: 00:16:39
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 41822 steps/s (collection: 2.232s, learning 0.118s)
             Mean action noise std: 2.05
          Mean value_function loss: 80.9947
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.3367
                       Mean reward: 347.40
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.2527
    Episode_Reward/rotating_object: 64.1832
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.35s
                      Time elapsed: 00:16:41
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 41768 steps/s (collection: 2.236s, learning 0.118s)
             Mean action noise std: 2.05
          Mean value_function loss: 77.9326
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.3516
                       Mean reward: 318.27
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 62.6584
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.35s
                      Time elapsed: 00:16:43
                               ETA: 00:41:32

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 41682 steps/s (collection: 2.241s, learning 0.118s)
             Mean action noise std: 2.05
          Mean value_function loss: 90.1278
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.3668
                       Mean reward: 367.73
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 61.7495
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.36s
                      Time elapsed: 00:16:46
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 41857 steps/s (collection: 2.234s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 84.5070
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 55.3754
                       Mean reward: 344.14
               Mean episode length: 231.96
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 64.8437
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.35s
                      Time elapsed: 00:16:48
                               ETA: 00:41:27

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 42027 steps/s (collection: 2.226s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 82.1055
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.3803
                       Mean reward: 324.84
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.2320
    Episode_Reward/rotating_object: 63.9539
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.34s
                      Time elapsed: 00:16:50
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 42228 steps/s (collection: 2.215s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 88.5938
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.3901
                       Mean reward: 314.24
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 60.2197
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.33s
                      Time elapsed: 00:16:53
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 42178 steps/s (collection: 2.207s, learning 0.124s)
             Mean action noise std: 2.06
          Mean value_function loss: 79.5116
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.4082
                       Mean reward: 321.20
               Mean episode length: 219.37
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 63.3081
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.33s
                      Time elapsed: 00:16:55
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 42229 steps/s (collection: 2.214s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 76.5602
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.4233
                       Mean reward: 303.95
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 63.6437
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.33s
                      Time elapsed: 00:16:57
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 41815 steps/s (collection: 2.239s, learning 0.112s)
             Mean action noise std: 2.06
          Mean value_function loss: 80.5922
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.4418
                       Mean reward: 361.68
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.2740
    Episode_Reward/rotating_object: 64.7603
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.35s
                      Time elapsed: 00:17:00
                               ETA: 00:41:16

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 41892 steps/s (collection: 2.234s, learning 0.112s)
             Mean action noise std: 2.06
          Mean value_function loss: 84.6645
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.4555
                       Mean reward: 289.86
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 1.2254
    Episode_Reward/rotating_object: 61.1697
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.35s
                      Time elapsed: 00:17:02
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 42092 steps/s (collection: 2.224s, learning 0.112s)
             Mean action noise std: 2.06
          Mean value_function loss: 83.1654
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.4761
                       Mean reward: 332.99
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 62.6045
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.34s
                      Time elapsed: 00:17:05
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 41740 steps/s (collection: 2.234s, learning 0.121s)
             Mean action noise std: 2.06
          Mean value_function loss: 83.3078
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.4953
                       Mean reward: 288.03
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 1.2487
    Episode_Reward/rotating_object: 63.3545
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.36s
                      Time elapsed: 00:17:07
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 41572 steps/s (collection: 2.248s, learning 0.116s)
             Mean action noise std: 2.07
          Mean value_function loss: 81.1578
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.5117
                       Mean reward: 354.27
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 1.2688
    Episode_Reward/rotating_object: 68.0707
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.36s
                      Time elapsed: 00:17:09
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 41091 steps/s (collection: 2.276s, learning 0.116s)
             Mean action noise std: 2.07
          Mean value_function loss: 79.9704
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.5282
                       Mean reward: 320.37
               Mean episode length: 227.60
    Episode_Reward/reaching_object: 1.2723
    Episode_Reward/rotating_object: 66.7560
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.39s
                      Time elapsed: 00:17:12
                               ETA: 00:41:04

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 41301 steps/s (collection: 2.264s, learning 0.116s)
             Mean action noise std: 2.07
          Mean value_function loss: 97.9478
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.5442
                       Mean reward: 334.95
               Mean episode length: 219.82
    Episode_Reward/reaching_object: 1.2390
    Episode_Reward/rotating_object: 68.3613
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.38s
                      Time elapsed: 00:17:14
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 41871 steps/s (collection: 2.232s, learning 0.115s)
             Mean action noise std: 2.07
          Mean value_function loss: 93.9139
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.5551
                       Mean reward: 360.82
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 1.2402
    Episode_Reward/rotating_object: 64.4284
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.35s
                      Time elapsed: 00:17:16
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 41807 steps/s (collection: 2.237s, learning 0.114s)
             Mean action noise std: 2.07
          Mean value_function loss: 91.5002
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.5710
                       Mean reward: 364.28
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 73.3446
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.35s
                      Time elapsed: 00:17:19
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 42037 steps/s (collection: 2.216s, learning 0.123s)
             Mean action noise std: 2.07
          Mean value_function loss: 93.6612
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.5849
                       Mean reward: 335.30
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.2736
    Episode_Reward/rotating_object: 67.0711
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.34s
                      Time elapsed: 00:17:21
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 41706 steps/s (collection: 2.240s, learning 0.117s)
             Mean action noise std: 2.07
          Mean value_function loss: 99.3037
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.6028
                       Mean reward: 333.40
               Mean episode length: 223.88
    Episode_Reward/reaching_object: 1.2459
    Episode_Reward/rotating_object: 64.2908
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.36s
                      Time elapsed: 00:17:23
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 41638 steps/s (collection: 2.246s, learning 0.115s)
             Mean action noise std: 2.08
          Mean value_function loss: 90.4723
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.6275
                       Mean reward: 367.92
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.2818
    Episode_Reward/rotating_object: 67.1800
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.36s
                      Time elapsed: 00:17:26
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.232s, learning 0.114s)
             Mean action noise std: 2.08
          Mean value_function loss: 83.6472
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.6497
                       Mean reward: 389.39
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 1.3086
    Episode_Reward/rotating_object: 71.4844
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.35s
                      Time elapsed: 00:17:28
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 41744 steps/s (collection: 2.242s, learning 0.113s)
             Mean action noise std: 2.08
          Mean value_function loss: 89.2475
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 55.6655
                       Mean reward: 309.69
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 1.2667
    Episode_Reward/rotating_object: 65.2051
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.35s
                      Time elapsed: 00:17:30
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 41526 steps/s (collection: 2.241s, learning 0.126s)
             Mean action noise std: 2.08
          Mean value_function loss: 85.8556
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.6817
                       Mean reward: 301.77
               Mean episode length: 219.55
    Episode_Reward/reaching_object: 1.2752
    Episode_Reward/rotating_object: 66.4019
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.37s
                      Time elapsed: 00:17:33
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 41681 steps/s (collection: 2.227s, learning 0.132s)
             Mean action noise std: 2.08
          Mean value_function loss: 76.9003
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.7011
                       Mean reward: 356.18
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 1.2769
    Episode_Reward/rotating_object: 68.1783
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.36s
                      Time elapsed: 00:17:35
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 41559 steps/s (collection: 2.243s, learning 0.122s)
             Mean action noise std: 2.08
          Mean value_function loss: 87.7613
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.7230
                       Mean reward: 356.77
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 1.2551
    Episode_Reward/rotating_object: 65.6440
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.37s
                      Time elapsed: 00:17:38
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 41756 steps/s (collection: 2.242s, learning 0.113s)
             Mean action noise std: 2.09
          Mean value_function loss: 85.2305
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.7394
                       Mean reward: 349.51
               Mean episode length: 222.12
    Episode_Reward/reaching_object: 1.2718
    Episode_Reward/rotating_object: 69.6895
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.35s
                      Time elapsed: 00:17:40
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 42430 steps/s (collection: 2.204s, learning 0.113s)
             Mean action noise std: 2.09
          Mean value_function loss: 85.2931
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.7567
                       Mean reward: 392.94
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 1.2792
    Episode_Reward/rotating_object: 72.4312
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.32s
                      Time elapsed: 00:17:42
                               ETA: 00:40:35

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 42791 steps/s (collection: 2.186s, learning 0.111s)
             Mean action noise std: 2.09
          Mean value_function loss: 84.3284
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.7729
                       Mean reward: 348.50
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.2852
    Episode_Reward/rotating_object: 71.2856
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.30s
                      Time elapsed: 00:17:45
                               ETA: 00:40:32

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 42183 steps/s (collection: 2.219s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 93.8935
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.7817
                       Mean reward: 367.37
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 70.2196
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.33s
                      Time elapsed: 00:17:47
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 42432 steps/s (collection: 2.205s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 89.5464
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.7952
                       Mean reward: 360.69
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.2796
    Episode_Reward/rotating_object: 65.6625
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.32s
                      Time elapsed: 00:17:49
                               ETA: 00:40:28

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 42102 steps/s (collection: 2.223s, learning 0.111s)
             Mean action noise std: 2.09
          Mean value_function loss: 93.7175
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.8123
                       Mean reward: 395.67
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 1.2878
    Episode_Reward/rotating_object: 73.9175
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.33s
                      Time elapsed: 00:17:51
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 42195 steps/s (collection: 2.218s, learning 0.112s)
             Mean action noise std: 2.09
          Mean value_function loss: 84.4762
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.8287
                       Mean reward: 340.08
               Mean episode length: 219.10
    Episode_Reward/reaching_object: 1.2611
    Episode_Reward/rotating_object: 69.9473
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.33s
                      Time elapsed: 00:17:54
                               ETA: 00:40:23

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 41779 steps/s (collection: 2.238s, learning 0.114s)
             Mean action noise std: 2.09
          Mean value_function loss: 88.0103
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.8446
                       Mean reward: 388.22
               Mean episode length: 222.84
    Episode_Reward/reaching_object: 1.2704
    Episode_Reward/rotating_object: 72.2690
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.35s
                      Time elapsed: 00:17:56
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 42262 steps/s (collection: 2.211s, learning 0.115s)
             Mean action noise std: 2.10
          Mean value_function loss: 79.2990
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.8643
                       Mean reward: 390.94
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 72.9926
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.33s
                      Time elapsed: 00:17:59
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 41997 steps/s (collection: 2.228s, learning 0.112s)
             Mean action noise std: 2.10
          Mean value_function loss: 79.0865
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.8785
                       Mean reward: 340.32
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.2860
    Episode_Reward/rotating_object: 68.7904
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.34s
                      Time elapsed: 00:18:01
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 42267 steps/s (collection: 2.213s, learning 0.113s)
             Mean action noise std: 2.10
          Mean value_function loss: 81.0210
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.8956
                       Mean reward: 358.44
               Mean episode length: 225.36
    Episode_Reward/reaching_object: 1.2883
    Episode_Reward/rotating_object: 72.7308
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.33s
                      Time elapsed: 00:18:03
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 41720 steps/s (collection: 2.241s, learning 0.116s)
             Mean action noise std: 2.10
          Mean value_function loss: 88.6191
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 55.9089
                       Mean reward: 395.96
               Mean episode length: 224.64
    Episode_Reward/reaching_object: 1.2514
    Episode_Reward/rotating_object: 72.5118
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.36s
                      Time elapsed: 00:18:06
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 41575 steps/s (collection: 2.250s, learning 0.115s)
             Mean action noise std: 2.10
          Mean value_function loss: 76.5994
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.9250
                       Mean reward: 369.88
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.3051
    Episode_Reward/rotating_object: 75.2138
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.36s
                      Time elapsed: 00:18:08
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 42001 steps/s (collection: 2.227s, learning 0.113s)
             Mean action noise std: 2.10
          Mean value_function loss: 79.3499
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.9413
                       Mean reward: 366.06
               Mean episode length: 220.07
    Episode_Reward/reaching_object: 1.2787
    Episode_Reward/rotating_object: 73.7144
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.34s
                      Time elapsed: 00:18:10
                               ETA: 00:40:07

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 41924 steps/s (collection: 2.231s, learning 0.114s)
             Mean action noise std: 2.10
          Mean value_function loss: 87.5297
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.9587
                       Mean reward: 390.27
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.2949
    Episode_Reward/rotating_object: 74.7629
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.34s
                      Time elapsed: 00:18:13
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 41709 steps/s (collection: 2.242s, learning 0.114s)
             Mean action noise std: 2.11
          Mean value_function loss: 98.0075
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.9802
                       Mean reward: 354.95
               Mean episode length: 221.66
    Episode_Reward/reaching_object: 1.2610
    Episode_Reward/rotating_object: 73.4876
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.36s
                      Time elapsed: 00:18:15
                               ETA: 00:40:02

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 41778 steps/s (collection: 2.240s, learning 0.113s)
             Mean action noise std: 2.11
          Mean value_function loss: 88.3587
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.0078
                       Mean reward: 383.23
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 1.2849
    Episode_Reward/rotating_object: 73.3584
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.35s
                      Time elapsed: 00:18:17
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 41958 steps/s (collection: 2.229s, learning 0.114s)
             Mean action noise std: 2.11
          Mean value_function loss: 85.8410
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.0231
                       Mean reward: 398.41
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.2896
    Episode_Reward/rotating_object: 73.9007
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.34s
                      Time elapsed: 00:18:20
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 41673 steps/s (collection: 2.240s, learning 0.119s)
             Mean action noise std: 2.11
          Mean value_function loss: 81.5997
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.0337
                       Mean reward: 362.39
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 1.2719
    Episode_Reward/rotating_object: 68.0865
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.36s
                      Time elapsed: 00:18:22
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 40988 steps/s (collection: 2.272s, learning 0.127s)
             Mean action noise std: 2.11
          Mean value_function loss: 85.1642
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.0443
                       Mean reward: 357.86
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 1.3163
    Episode_Reward/rotating_object: 74.3529
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.40s
                      Time elapsed: 00:18:24
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 41389 steps/s (collection: 2.261s, learning 0.114s)
             Mean action noise std: 2.11
          Mean value_function loss: 100.9710
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.0559
                       Mean reward: 415.72
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.3384
    Episode_Reward/rotating_object: 76.9471
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.38s
                      Time elapsed: 00:18:27
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 41452 steps/s (collection: 2.254s, learning 0.117s)
             Mean action noise std: 2.11
          Mean value_function loss: 80.5725
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 56.0676
                       Mean reward: 377.34
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.2948
    Episode_Reward/rotating_object: 72.1247
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.37s
                      Time elapsed: 00:18:29
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 40921 steps/s (collection: 2.284s, learning 0.119s)
             Mean action noise std: 2.11
          Mean value_function loss: 84.0580
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.0851
                       Mean reward: 403.48
               Mean episode length: 220.55
    Episode_Reward/reaching_object: 1.2949
    Episode_Reward/rotating_object: 74.9087
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.40s
                      Time elapsed: 00:18:32
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 41706 steps/s (collection: 2.244s, learning 0.113s)
             Mean action noise std: 2.12
          Mean value_function loss: 80.3507
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.0995
                       Mean reward: 378.42
               Mean episode length: 230.10
    Episode_Reward/reaching_object: 1.3270
    Episode_Reward/rotating_object: 77.5858
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.36s
                      Time elapsed: 00:18:34
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 42518 steps/s (collection: 2.201s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 85.5882
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.1114
                       Mean reward: 391.19
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.3338
    Episode_Reward/rotating_object: 77.8478
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.31s
                      Time elapsed: 00:18:36
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 44983 steps/s (collection: 2.074s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 96.8020
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.1265
                       Mean reward: 388.17
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 1.3235
    Episode_Reward/rotating_object: 70.8358
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.19s
                      Time elapsed: 00:18:38
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 43845 steps/s (collection: 2.121s, learning 0.121s)
             Mean action noise std: 2.12
          Mean value_function loss: 98.0800
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.1431
                       Mean reward: 410.12
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.3407
    Episode_Reward/rotating_object: 77.4117
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.24s
                      Time elapsed: 00:18:41
                               ETA: 00:39:37

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 44551 steps/s (collection: 2.096s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 87.2360
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 56.1607
                       Mean reward: 357.97
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 1.3328
    Episode_Reward/rotating_object: 73.9772
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.21s
                      Time elapsed: 00:18:43
                               ETA: 00:39:34

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 43448 steps/s (collection: 2.150s, learning 0.113s)
             Mean action noise std: 2.12
          Mean value_function loss: 94.8839
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 56.1835
                       Mean reward: 384.76
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.3507
    Episode_Reward/rotating_object: 76.0740
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.26s
                      Time elapsed: 00:18:45
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 43810 steps/s (collection: 2.129s, learning 0.115s)
             Mean action noise std: 2.12
          Mean value_function loss: 91.7280
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.2020
                       Mean reward: 415.99
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 1.3227
    Episode_Reward/rotating_object: 80.0608
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.24s
                      Time elapsed: 00:18:47
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 43357 steps/s (collection: 2.147s, learning 0.120s)
             Mean action noise std: 2.13
          Mean value_function loss: 106.6604
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.2145
                       Mean reward: 392.52
               Mean episode length: 225.08
    Episode_Reward/reaching_object: 1.3077
    Episode_Reward/rotating_object: 77.8120
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.27s
                      Time elapsed: 00:18:50
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 40439 steps/s (collection: 2.316s, learning 0.115s)
             Mean action noise std: 2.13
          Mean value_function loss: 99.6063
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.2263
                       Mean reward: 427.93
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 1.2915
    Episode_Reward/rotating_object: 76.9270
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.43s
                      Time elapsed: 00:18:52
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 41622 steps/s (collection: 2.247s, learning 0.115s)
             Mean action noise std: 2.13
          Mean value_function loss: 100.1447
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.2360
                       Mean reward: 404.07
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.3262
    Episode_Reward/rotating_object: 76.2215
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.36s
                      Time elapsed: 00:18:54
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 41351 steps/s (collection: 2.249s, learning 0.128s)
             Mean action noise std: 2.13
          Mean value_function loss: 100.5323
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 56.2542
                       Mean reward: 428.43
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.3492
    Episode_Reward/rotating_object: 74.2703
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.38s
                      Time elapsed: 00:18:57
                               ETA: 00:39:20

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 41182 steps/s (collection: 2.275s, learning 0.112s)
             Mean action noise std: 2.13
          Mean value_function loss: 92.6276
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.2663
                       Mean reward: 433.91
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.3144
    Episode_Reward/rotating_object: 72.0429
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.39s
                      Time elapsed: 00:18:59
                               ETA: 00:39:18

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 41758 steps/s (collection: 2.237s, learning 0.117s)
             Mean action noise std: 2.13
          Mean value_function loss: 98.1578
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.2749
                       Mean reward: 360.70
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 1.3398
    Episode_Reward/rotating_object: 73.2458
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.35s
                      Time elapsed: 00:19:02
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 40549 steps/s (collection: 2.306s, learning 0.118s)
             Mean action noise std: 2.13
          Mean value_function loss: 95.4651
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.2905
                       Mean reward: 423.04
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.3776
    Episode_Reward/rotating_object: 79.9723
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.42s
                      Time elapsed: 00:19:04
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 40914 steps/s (collection: 2.287s, learning 0.115s)
             Mean action noise std: 2.13
          Mean value_function loss: 91.8646
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.3050
                       Mean reward: 381.14
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.3755
    Episode_Reward/rotating_object: 75.3658
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.40s
                      Time elapsed: 00:19:06
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 41307 steps/s (collection: 2.264s, learning 0.116s)
             Mean action noise std: 2.13
          Mean value_function loss: 99.0910
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.3171
                       Mean reward: 400.63
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 1.3813
    Episode_Reward/rotating_object: 79.5801
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.38s
                      Time elapsed: 00:19:09
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 41688 steps/s (collection: 2.243s, learning 0.115s)
             Mean action noise std: 2.14
          Mean value_function loss: 94.2477
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 56.3322
                       Mean reward: 415.28
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.3790
    Episode_Reward/rotating_object: 78.5443
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.36s
                      Time elapsed: 00:19:11
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 40927 steps/s (collection: 2.275s, learning 0.127s)
             Mean action noise std: 2.14
          Mean value_function loss: 91.7454
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.3494
                       Mean reward: 398.66
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.3869
    Episode_Reward/rotating_object: 81.1901
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.40s
                      Time elapsed: 00:19:13
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 41841 steps/s (collection: 2.235s, learning 0.115s)
             Mean action noise std: 2.14
          Mean value_function loss: 108.4681
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.3614
                       Mean reward: 401.27
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 1.3714
    Episode_Reward/rotating_object: 80.9085
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.35s
                      Time elapsed: 00:19:16
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 42120 steps/s (collection: 2.222s, learning 0.112s)
             Mean action noise std: 2.14
          Mean value_function loss: 107.0650
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 56.3726
                       Mean reward: 406.77
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.3747
    Episode_Reward/rotating_object: 80.1406
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.33s
                      Time elapsed: 00:19:18
                               ETA: 00:39:00

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 42015 steps/s (collection: 2.228s, learning 0.112s)
             Mean action noise std: 2.14
          Mean value_function loss: 100.6081
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.3811
                       Mean reward: 400.60
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.3871
    Episode_Reward/rotating_object: 77.2883
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.34s
                      Time elapsed: 00:19:21
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 42016 steps/s (collection: 2.226s, learning 0.113s)
             Mean action noise std: 2.14
          Mean value_function loss: 108.4840
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 56.3992
                       Mean reward: 389.48
               Mean episode length: 231.20
    Episode_Reward/reaching_object: 1.3884
    Episode_Reward/rotating_object: 76.8927
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.34s
                      Time elapsed: 00:19:23
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 42131 steps/s (collection: 2.217s, learning 0.117s)
             Mean action noise std: 2.14
          Mean value_function loss: 117.6908
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.4100
                       Mean reward: 449.43
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.4049
    Episode_Reward/rotating_object: 84.0723
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.33s
                      Time elapsed: 00:19:25
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 41461 steps/s (collection: 2.254s, learning 0.117s)
             Mean action noise std: 2.14
          Mean value_function loss: 112.3775
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.4158
                       Mean reward: 475.07
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.4053
    Episode_Reward/rotating_object: 80.0706
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.37s
                      Time elapsed: 00:19:28
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 41290 steps/s (collection: 2.268s, learning 0.113s)
             Mean action noise std: 2.14
          Mean value_function loss: 123.2085
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.4248
                       Mean reward: 437.01
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.3660
    Episode_Reward/rotating_object: 84.6167
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.38s
                      Time elapsed: 00:19:30
                               ETA: 00:38:49

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 41614 steps/s (collection: 2.248s, learning 0.114s)
             Mean action noise std: 2.14
          Mean value_function loss: 108.4293
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.4395
                       Mean reward: 417.06
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.3776
    Episode_Reward/rotating_object: 82.5273
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.36s
                      Time elapsed: 00:19:32
                               ETA: 00:38:46

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 41495 steps/s (collection: 2.252s, learning 0.117s)
             Mean action noise std: 2.15
          Mean value_function loss: 113.2500
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.4488
                       Mean reward: 439.09
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.3832
    Episode_Reward/rotating_object: 80.9007
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.37s
                      Time elapsed: 00:19:35
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 41644 steps/s (collection: 2.245s, learning 0.116s)
             Mean action noise std: 2.15
          Mean value_function loss: 117.1033
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.4626
                       Mean reward: 396.44
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.3879
    Episode_Reward/rotating_object: 80.4441
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.36s
                      Time elapsed: 00:19:37
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 41515 steps/s (collection: 2.252s, learning 0.116s)
             Mean action noise std: 2.15
          Mean value_function loss: 125.4047
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.4748
                       Mean reward: 415.57
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.4415
    Episode_Reward/rotating_object: 83.5380
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.37s
                      Time elapsed: 00:19:39
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 41295 steps/s (collection: 2.265s, learning 0.116s)
             Mean action noise std: 2.15
          Mean value_function loss: 120.5450
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.4904
                       Mean reward: 457.72
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.4111
    Episode_Reward/rotating_object: 83.4198
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.38s
                      Time elapsed: 00:19:42
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 41490 steps/s (collection: 2.254s, learning 0.115s)
             Mean action noise std: 2.15
          Mean value_function loss: 118.9410
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.5043
                       Mean reward: 418.85
               Mean episode length: 225.76
    Episode_Reward/reaching_object: 1.4127
    Episode_Reward/rotating_object: 83.6569
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.37s
                      Time elapsed: 00:19:44
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 41551 steps/s (collection: 2.246s, learning 0.119s)
             Mean action noise std: 2.15
          Mean value_function loss: 124.4947
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.5233
                       Mean reward: 410.05
               Mean episode length: 219.76
    Episode_Reward/reaching_object: 1.3977
    Episode_Reward/rotating_object: 83.0057
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.37s
                      Time elapsed: 00:19:47
                               ETA: 00:38:33

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 41510 steps/s (collection: 2.254s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 124.3000
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.5420
                       Mean reward: 448.89
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.4696
    Episode_Reward/rotating_object: 89.4587
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.37s
                      Time elapsed: 00:19:49
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 41398 steps/s (collection: 2.261s, learning 0.114s)
             Mean action noise std: 2.16
          Mean value_function loss: 130.4562
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 56.5592
                       Mean reward: 402.56
               Mean episode length: 221.53
    Episode_Reward/reaching_object: 1.4109
    Episode_Reward/rotating_object: 90.0107
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.37s
                      Time elapsed: 00:19:51
                               ETA: 00:38:28

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 41281 steps/s (collection: 2.264s, learning 0.117s)
             Mean action noise std: 2.16
          Mean value_function loss: 110.2912
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.5734
                       Mean reward: 477.87
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.4526
    Episode_Reward/rotating_object: 90.9947
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.38s
                      Time elapsed: 00:19:54
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 41397 steps/s (collection: 2.262s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 117.5380
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.5876
                       Mean reward: 449.48
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.4074
    Episode_Reward/rotating_object: 86.5755
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.37s
                      Time elapsed: 00:19:56
                               ETA: 00:38:24

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 41537 steps/s (collection: 2.253s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 120.5012
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 56.5978
                       Mean reward: 454.03
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 1.4035
    Episode_Reward/rotating_object: 86.8007
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.37s
                      Time elapsed: 00:19:58
                               ETA: 00:38:22

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 41632 steps/s (collection: 2.247s, learning 0.114s)
             Mean action noise std: 2.16
          Mean value_function loss: 104.3197
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.6059
                       Mean reward: 472.82
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 1.4244
    Episode_Reward/rotating_object: 93.1124
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.36s
                      Time elapsed: 00:20:01
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 41623 steps/s (collection: 2.248s, learning 0.114s)
             Mean action noise std: 2.16
          Mean value_function loss: 110.9961
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.6194
                       Mean reward: 459.97
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.3949
    Episode_Reward/rotating_object: 92.7598
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.36s
                      Time elapsed: 00:20:03
                               ETA: 00:38:17

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 41894 steps/s (collection: 2.235s, learning 0.112s)
             Mean action noise std: 2.16
          Mean value_function loss: 106.3141
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 56.6294
                       Mean reward: 451.36
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.4112
    Episode_Reward/rotating_object: 89.7389
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.35s
                      Time elapsed: 00:20:05
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 42129 steps/s (collection: 2.222s, learning 0.112s)
             Mean action noise std: 2.16
          Mean value_function loss: 109.4326
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.6383
                       Mean reward: 457.02
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.3900
    Episode_Reward/rotating_object: 94.9067
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.33s
                      Time elapsed: 00:20:08
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 42062 steps/s (collection: 2.225s, learning 0.112s)
             Mean action noise std: 2.16
          Mean value_function loss: 114.2961
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 56.6454
                       Mean reward: 480.37
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.3603
    Episode_Reward/rotating_object: 92.0962
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.34s
                      Time elapsed: 00:20:10
                               ETA: 00:38:10

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 41919 steps/s (collection: 2.233s, learning 0.112s)
             Mean action noise std: 2.16
          Mean value_function loss: 109.9946
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.6513
                       Mean reward: 428.40
               Mean episode length: 226.48
    Episode_Reward/reaching_object: 1.3855
    Episode_Reward/rotating_object: 94.1835
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.35s
                      Time elapsed: 00:20:12
                               ETA: 00:38:08

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 42125 steps/s (collection: 2.221s, learning 0.112s)
             Mean action noise std: 2.17
          Mean value_function loss: 114.7859
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.6686
                       Mean reward: 431.74
               Mean episode length: 231.39
    Episode_Reward/reaching_object: 1.4112
    Episode_Reward/rotating_object: 89.2612
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.33s
                      Time elapsed: 00:20:15
                               ETA: 00:38:05

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 41990 steps/s (collection: 2.225s, learning 0.117s)
             Mean action noise std: 2.17
          Mean value_function loss: 121.2688
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.6928
                       Mean reward: 428.43
               Mean episode length: 216.85
    Episode_Reward/reaching_object: 1.3641
    Episode_Reward/rotating_object: 87.9215
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.34s
                      Time elapsed: 00:20:17
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 41706 steps/s (collection: 2.241s, learning 0.116s)
             Mean action noise std: 2.17
          Mean value_function loss: 117.5496
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.7043
                       Mean reward: 457.67
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 1.3782
    Episode_Reward/rotating_object: 90.9323
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.36s
                      Time elapsed: 00:20:19
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 41201 steps/s (collection: 2.268s, learning 0.118s)
             Mean action noise std: 2.17
          Mean value_function loss: 131.8490
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.7187
                       Mean reward: 430.39
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.3395
    Episode_Reward/rotating_object: 86.9910
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.39s
                      Time elapsed: 00:20:22
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 41404 steps/s (collection: 2.256s, learning 0.118s)
             Mean action noise std: 2.17
          Mean value_function loss: 113.3790
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.7294
                       Mean reward: 481.37
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.3733
    Episode_Reward/rotating_object: 91.9664
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.37s
                      Time elapsed: 00:20:24
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 41519 steps/s (collection: 2.251s, learning 0.116s)
             Mean action noise std: 2.17
          Mean value_function loss: 124.7947
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 56.7384
                       Mean reward: 463.09
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 1.3646
    Episode_Reward/rotating_object: 90.2321
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.37s
                      Time elapsed: 00:20:27
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 41543 steps/s (collection: 2.250s, learning 0.116s)
             Mean action noise std: 2.17
          Mean value_function loss: 115.7579
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.7428
                       Mean reward: 433.35
               Mean episode length: 220.52
    Episode_Reward/reaching_object: 1.3541
    Episode_Reward/rotating_object: 89.3486
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.37s
                      Time elapsed: 00:20:29
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 41427 steps/s (collection: 2.258s, learning 0.115s)
             Mean action noise std: 2.17
          Mean value_function loss: 114.5724
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.7495
                       Mean reward: 443.09
               Mean episode length: 221.42
    Episode_Reward/reaching_object: 1.3654
    Episode_Reward/rotating_object: 89.8340
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.37s
                      Time elapsed: 00:20:31
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 41387 steps/s (collection: 2.260s, learning 0.115s)
             Mean action noise std: 2.17
          Mean value_function loss: 123.7244
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.7637
                       Mean reward: 504.23
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.3677
    Episode_Reward/rotating_object: 92.9548
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.38s
                      Time elapsed: 00:20:34
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 41687 steps/s (collection: 2.246s, learning 0.112s)
             Mean action noise std: 2.18
          Mean value_function loss: 114.7886
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.7775
                       Mean reward: 465.94
               Mean episode length: 228.16
    Episode_Reward/reaching_object: 1.3741
    Episode_Reward/rotating_object: 93.2001
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.36s
                      Time elapsed: 00:20:36
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 41386 steps/s (collection: 2.260s, learning 0.116s)
             Mean action noise std: 2.18
          Mean value_function loss: 109.9652
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.7947
                       Mean reward: 487.24
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.4049
    Episode_Reward/rotating_object: 91.8188
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.38s
                      Time elapsed: 00:20:38
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 41306 steps/s (collection: 2.267s, learning 0.113s)
             Mean action noise std: 2.18
          Mean value_function loss: 112.6240
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 56.8096
                       Mean reward: 511.21
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.3887
    Episode_Reward/rotating_object: 96.2732
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.38s
                      Time elapsed: 00:20:41
                               ETA: 00:37:41

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 41315 steps/s (collection: 2.266s, learning 0.113s)
             Mean action noise std: 2.18
          Mean value_function loss: 116.0588
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.8144
                       Mean reward: 502.89
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.4254
    Episode_Reward/rotating_object: 95.6221
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.38s
                      Time elapsed: 00:20:43
                               ETA: 00:37:38

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 41361 steps/s (collection: 2.263s, learning 0.114s)
             Mean action noise std: 2.18
          Mean value_function loss: 111.8533
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.8204
                       Mean reward: 510.13
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.4021
    Episode_Reward/rotating_object: 96.3368
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.38s
                      Time elapsed: 00:20:46
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 41328 steps/s (collection: 2.266s, learning 0.113s)
             Mean action noise std: 2.18
          Mean value_function loss: 120.8462
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.8283
                       Mean reward: 454.59
               Mean episode length: 220.95
    Episode_Reward/reaching_object: 1.3703
    Episode_Reward/rotating_object: 93.4094
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.38s
                      Time elapsed: 00:20:48
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 40876 steps/s (collection: 2.293s, learning 0.112s)
             Mean action noise std: 2.18
          Mean value_function loss: 113.7829
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.8397
                       Mean reward: 494.01
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.3931
    Episode_Reward/rotating_object: 96.2221
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.40s
                      Time elapsed: 00:20:50
                               ETA: 00:37:32

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 41538 steps/s (collection: 2.253s, learning 0.113s)
             Mean action noise std: 2.18
          Mean value_function loss: 117.9506
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.8558
                       Mean reward: 484.25
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 1.3936
    Episode_Reward/rotating_object: 96.8911
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.37s
                      Time elapsed: 00:20:53
                               ETA: 00:37:29

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 41586 steps/s (collection: 2.244s, learning 0.120s)
             Mean action noise std: 2.18
          Mean value_function loss: 117.2389
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.8668
                       Mean reward: 452.30
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.3907
    Episode_Reward/rotating_object: 94.0916
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.36s
                      Time elapsed: 00:20:55
                               ETA: 00:37:27

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 40370 steps/s (collection: 2.317s, learning 0.118s)
             Mean action noise std: 2.19
          Mean value_function loss: 113.9788
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.8814
                       Mean reward: 518.79
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.3866
    Episode_Reward/rotating_object: 96.3800
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.44s
                      Time elapsed: 00:20:58
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 40618 steps/s (collection: 2.308s, learning 0.112s)
             Mean action noise std: 2.19
          Mean value_function loss: 112.7204
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 56.9002
                       Mean reward: 526.65
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 1.3763
    Episode_Reward/rotating_object: 94.0787
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.42s
                      Time elapsed: 00:21:00
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 41161 steps/s (collection: 2.268s, learning 0.120s)
             Mean action noise std: 2.19
          Mean value_function loss: 109.9055
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 56.9181
                       Mean reward: 481.38
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.3828
    Episode_Reward/rotating_object: 96.5394
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.39s
                      Time elapsed: 00:21:02
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 41223 steps/s (collection: 2.265s, learning 0.120s)
             Mean action noise std: 2.19
          Mean value_function loss: 108.9958
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.9249
                       Mean reward: 502.00
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.3737
    Episode_Reward/rotating_object: 97.4089
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.38s
                      Time elapsed: 00:21:05
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 41438 steps/s (collection: 2.260s, learning 0.112s)
             Mean action noise std: 2.19
          Mean value_function loss: 118.2991
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 56.9338
                       Mean reward: 511.79
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 1.3775
    Episode_Reward/rotating_object: 96.1389
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.37s
                      Time elapsed: 00:21:07
                               ETA: 00:37:16

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 41547 steps/s (collection: 2.253s, learning 0.114s)
             Mean action noise std: 2.19
          Mean value_function loss: 110.7128
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.9473
                       Mean reward: 516.19
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.3813
    Episode_Reward/rotating_object: 100.2695
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.37s
                      Time elapsed: 00:21:09
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 41738 steps/s (collection: 2.240s, learning 0.115s)
             Mean action noise std: 2.19
          Mean value_function loss: 109.9636
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.9614
                       Mean reward: 534.41
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.3518
    Episode_Reward/rotating_object: 100.7580
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.36s
                      Time elapsed: 00:21:12
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 41606 steps/s (collection: 2.246s, learning 0.116s)
             Mean action noise std: 2.19
          Mean value_function loss: 105.9873
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.9773
                       Mean reward: 488.34
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.3839
    Episode_Reward/rotating_object: 97.8064
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.36s
                      Time elapsed: 00:21:14
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 41952 steps/s (collection: 2.228s, learning 0.115s)
             Mean action noise std: 2.20
          Mean value_function loss: 92.7669
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.9883
                       Mean reward: 521.45
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 1.4148
    Episode_Reward/rotating_object: 100.8147
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.34s
                      Time elapsed: 00:21:17
                               ETA: 00:37:07

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 41872 steps/s (collection: 2.232s, learning 0.115s)
             Mean action noise std: 2.20
          Mean value_function loss: 101.5860
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.9954
                       Mean reward: 470.64
               Mean episode length: 224.46
    Episode_Reward/reaching_object: 1.3770
    Episode_Reward/rotating_object: 98.6707
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.35s
                      Time elapsed: 00:21:19
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 41326 steps/s (collection: 2.253s, learning 0.126s)
             Mean action noise std: 2.20
          Mean value_function loss: 107.7395
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.0020
                       Mean reward: 519.33
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.3872
    Episode_Reward/rotating_object: 101.1918
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.38s
                      Time elapsed: 00:21:21
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 41805 steps/s (collection: 2.229s, learning 0.123s)
             Mean action noise std: 2.20
          Mean value_function loss: 96.6289
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.0121
                       Mean reward: 512.10
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.3706
    Episode_Reward/rotating_object: 97.7976
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.35s
                      Time elapsed: 00:21:24
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 41525 steps/s (collection: 2.253s, learning 0.115s)
             Mean action noise std: 2.20
          Mean value_function loss: 92.0031
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.0226
                       Mean reward: 524.13
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.3918
    Episode_Reward/rotating_object: 103.7755
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.37s
                      Time elapsed: 00:21:26
                               ETA: 00:36:58

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 41924 steps/s (collection: 2.230s, learning 0.115s)
             Mean action noise std: 2.20
          Mean value_function loss: 109.7993
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.0291
                       Mean reward: 485.63
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.3891
    Episode_Reward/rotating_object: 101.2967
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.34s
                      Time elapsed: 00:21:28
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 41449 steps/s (collection: 2.249s, learning 0.123s)
             Mean action noise std: 2.20
          Mean value_function loss: 112.9358
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.0380
                       Mean reward: 472.47
               Mean episode length: 225.85
    Episode_Reward/reaching_object: 1.3430
    Episode_Reward/rotating_object: 95.7411
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.37s
                      Time elapsed: 00:21:31
                               ETA: 00:36:53

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 41791 steps/s (collection: 2.238s, learning 0.114s)
             Mean action noise std: 2.20
          Mean value_function loss: 110.0364
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.0480
                       Mean reward: 496.65
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 1.3968
    Episode_Reward/rotating_object: 101.7683
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.35s
                      Time elapsed: 00:21:33
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 41705 steps/s (collection: 2.245s, learning 0.112s)
             Mean action noise std: 2.20
          Mean value_function loss: 117.4348
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.0615
                       Mean reward: 531.47
               Mean episode length: 240.87
    Episode_Reward/reaching_object: 1.3878
    Episode_Reward/rotating_object: 100.8253
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.36s
                      Time elapsed: 00:21:35
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 41559 steps/s (collection: 2.251s, learning 0.114s)
             Mean action noise std: 2.20
          Mean value_function loss: 118.7002
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.0715
                       Mean reward: 518.47
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.3554
    Episode_Reward/rotating_object: 98.9155
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.37s
                      Time elapsed: 00:21:38
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 41444 steps/s (collection: 2.258s, learning 0.114s)
             Mean action noise std: 2.21
          Mean value_function loss: 119.5833
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.0837
                       Mean reward: 479.79
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.3958
    Episode_Reward/rotating_object: 99.0773
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.37s
                      Time elapsed: 00:21:40
                               ETA: 00:36:44

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 41301 steps/s (collection: 2.264s, learning 0.116s)
             Mean action noise std: 2.21
          Mean value_function loss: 124.4400
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.0965
                       Mean reward: 526.60
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.3976
    Episode_Reward/rotating_object: 100.9162
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.38s
                      Time elapsed: 00:21:43
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 42008 steps/s (collection: 2.227s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 125.3100
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 57.1047
                       Mean reward: 505.79
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.3762
    Episode_Reward/rotating_object: 98.8503
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.34s
                      Time elapsed: 00:21:45
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 42293 steps/s (collection: 2.212s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 122.0710
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.1081
                       Mean reward: 493.11
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.3651
    Episode_Reward/rotating_object: 98.8476
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.32s
                      Time elapsed: 00:21:47
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 42081 steps/s (collection: 2.223s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 118.8753
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.1158
                       Mean reward: 509.41
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 1.3954
    Episode_Reward/rotating_object: 101.4252
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.34s
                      Time elapsed: 00:21:50
                               ETA: 00:36:35

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 42006 steps/s (collection: 2.227s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 109.9556
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.1272
                       Mean reward: 483.70
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 1.3883
    Episode_Reward/rotating_object: 101.6144
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.34s
                      Time elapsed: 00:21:52
                               ETA: 00:36:32

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 42025 steps/s (collection: 2.223s, learning 0.116s)
             Mean action noise std: 2.21
          Mean value_function loss: 112.8499
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.1346
                       Mean reward: 513.25
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 1.3988
    Episode_Reward/rotating_object: 101.9551
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.34s
                      Time elapsed: 00:21:54
                               ETA: 00:36:30

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 41782 steps/s (collection: 2.239s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 117.3236
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.1441
                       Mean reward: 480.49
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 1.3540
    Episode_Reward/rotating_object: 96.0716
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.35s
                      Time elapsed: 00:21:57
                               ETA: 00:36:28

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 41786 steps/s (collection: 2.232s, learning 0.120s)
             Mean action noise std: 2.21
          Mean value_function loss: 116.3925
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.1532
                       Mean reward: 496.53
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.3774
    Episode_Reward/rotating_object: 99.2897
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.35s
                      Time elapsed: 00:21:59
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 41623 steps/s (collection: 2.247s, learning 0.114s)
             Mean action noise std: 2.21
          Mean value_function loss: 121.9345
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.1627
                       Mean reward: 485.68
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.3957
    Episode_Reward/rotating_object: 97.8191
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.36s
                      Time elapsed: 00:22:01
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 41662 steps/s (collection: 2.247s, learning 0.112s)
             Mean action noise std: 2.21
          Mean value_function loss: 113.5287
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.1739
                       Mean reward: 540.54
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 1.4046
    Episode_Reward/rotating_object: 102.2285
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.36s
                      Time elapsed: 00:22:04
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 41459 steps/s (collection: 2.257s, learning 0.114s)
             Mean action noise std: 2.22
          Mean value_function loss: 111.3294
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.1890
                       Mean reward: 530.08
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.4178
    Episode_Reward/rotating_object: 100.3578
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.37s
                      Time elapsed: 00:22:06
                               ETA: 00:36:18

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 41771 steps/s (collection: 2.239s, learning 0.114s)
             Mean action noise std: 2.22
          Mean value_function loss: 101.4592
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.2057
                       Mean reward: 530.93
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.4181
    Episode_Reward/rotating_object: 102.6996
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.35s
                      Time elapsed: 00:22:08
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 41730 steps/s (collection: 2.243s, learning 0.113s)
             Mean action noise std: 2.22
          Mean value_function loss: 112.8132
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.2160
                       Mean reward: 528.64
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 1.4360
    Episode_Reward/rotating_object: 99.5691
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.36s
                      Time elapsed: 00:22:11
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 41849 steps/s (collection: 2.236s, learning 0.113s)
             Mean action noise std: 2.22
          Mean value_function loss: 111.9584
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.2256
                       Mean reward: 522.96
               Mean episode length: 229.65
    Episode_Reward/reaching_object: 1.4180
    Episode_Reward/rotating_object: 103.0252
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.35s
                      Time elapsed: 00:22:13
                               ETA: 00:36:12

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 41717 steps/s (collection: 2.239s, learning 0.117s)
             Mean action noise std: 2.22
          Mean value_function loss: 103.5133
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 57.2380
                       Mean reward: 478.28
               Mean episode length: 215.80
    Episode_Reward/reaching_object: 1.4124
    Episode_Reward/rotating_object: 104.5500
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.36s
                      Time elapsed: 00:22:15
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 41618 steps/s (collection: 2.248s, learning 0.114s)
             Mean action noise std: 2.22
          Mean value_function loss: 108.4805
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.2557
                       Mean reward: 488.81
               Mean episode length: 216.11
    Episode_Reward/reaching_object: 1.3794
    Episode_Reward/rotating_object: 104.4432
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.36s
                      Time elapsed: 00:22:18
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 41887 steps/s (collection: 2.233s, learning 0.114s)
             Mean action noise std: 2.22
          Mean value_function loss: 106.9311
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.2714
                       Mean reward: 528.86
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.3963
    Episode_Reward/rotating_object: 104.3349
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.35s
                      Time elapsed: 00:22:20
                               ETA: 00:36:05

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 41640 steps/s (collection: 2.241s, learning 0.120s)
             Mean action noise std: 2.22
          Mean value_function loss: 107.0478
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 57.2826
                       Mean reward: 508.44
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 1.3642
    Episode_Reward/rotating_object: 102.2780
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.36s
                      Time elapsed: 00:22:22
                               ETA: 00:36:02

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 41257 steps/s (collection: 2.270s, learning 0.112s)
             Mean action noise std: 2.23
          Mean value_function loss: 103.6340
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.2932
                       Mean reward: 527.71
               Mean episode length: 221.22
    Episode_Reward/reaching_object: 1.3908
    Episode_Reward/rotating_object: 105.5660
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.38s
                      Time elapsed: 00:22:25
                               ETA: 00:36:00

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 41473 steps/s (collection: 2.257s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 116.4086
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.3103
                       Mean reward: 570.09
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.3984
    Episode_Reward/rotating_object: 105.7291
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.37s
                      Time elapsed: 00:22:27
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 41769 steps/s (collection: 2.241s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 95.0330
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.3221
                       Mean reward: 520.26
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.3738
    Episode_Reward/rotating_object: 103.2444
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.35s
                      Time elapsed: 00:22:30
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 42071 steps/s (collection: 2.224s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 100.6611
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 57.3336
                       Mean reward: 546.28
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.4128
    Episode_Reward/rotating_object: 106.0828
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.34s
                      Time elapsed: 00:22:32
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 42645 steps/s (collection: 2.194s, learning 0.111s)
             Mean action noise std: 2.23
          Mean value_function loss: 102.7544
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.3499
                       Mean reward: 543.20
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.4039
    Episode_Reward/rotating_object: 107.5964
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.31s
                      Time elapsed: 00:22:34
                               ETA: 00:35:51

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 42499 steps/s (collection: 2.200s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 104.4302
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.3659
                       Mean reward: 533.52
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.3589
    Episode_Reward/rotating_object: 103.2279
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.31s
                      Time elapsed: 00:22:37
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 41774 steps/s (collection: 2.221s, learning 0.132s)
             Mean action noise std: 2.23
          Mean value_function loss: 102.1201
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.3704
                       Mean reward: 498.22
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 1.3700
    Episode_Reward/rotating_object: 101.8552
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.35s
                      Time elapsed: 00:22:39
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 42507 steps/s (collection: 2.200s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 104.7554
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.3772
                       Mean reward: 576.19
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.3836
    Episode_Reward/rotating_object: 109.0682
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.31s
                      Time elapsed: 00:22:41
                               ETA: 00:35:44

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 41509 steps/s (collection: 2.248s, learning 0.121s)
             Mean action noise std: 2.24
          Mean value_function loss: 104.6056
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.3898
                       Mean reward: 524.99
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 1.3760
    Episode_Reward/rotating_object: 104.1656
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.37s
                      Time elapsed: 00:22:44
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 41593 steps/s (collection: 2.251s, learning 0.112s)
             Mean action noise std: 2.24
          Mean value_function loss: 112.1110
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 57.3982
                       Mean reward: 546.87
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.3668
    Episode_Reward/rotating_object: 105.2992
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.36s
                      Time elapsed: 00:22:46
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 41250 steps/s (collection: 2.253s, learning 0.130s)
             Mean action noise std: 2.24
          Mean value_function loss: 111.4741
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 57.4087
                       Mean reward: 521.55
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.3884
    Episode_Reward/rotating_object: 106.6518
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.38s
                      Time elapsed: 00:22:48
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 40671 steps/s (collection: 2.301s, learning 0.116s)
             Mean action noise std: 2.24
          Mean value_function loss: 105.2558
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.4297
                       Mean reward: 555.14
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.3829
    Episode_Reward/rotating_object: 108.4718
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.42s
                      Time elapsed: 00:22:51
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 40977 steps/s (collection: 2.282s, learning 0.117s)
             Mean action noise std: 2.24
          Mean value_function loss: 108.2971
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.4492
                       Mean reward: 534.29
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.3818
    Episode_Reward/rotating_object: 104.4366
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.40s
                      Time elapsed: 00:22:53
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 41577 steps/s (collection: 2.245s, learning 0.119s)
             Mean action noise std: 2.24
          Mean value_function loss: 104.2411
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.4665
                       Mean reward: 518.89
               Mean episode length: 221.47
    Episode_Reward/reaching_object: 1.3872
    Episode_Reward/rotating_object: 107.5092
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.36s
                      Time elapsed: 00:22:56
                               ETA: 00:35:30

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 41788 steps/s (collection: 2.239s, learning 0.113s)
             Mean action noise std: 2.24
          Mean value_function loss: 101.5927
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.4726
                       Mean reward: 561.73
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.3995
    Episode_Reward/rotating_object: 107.0662
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.35s
                      Time elapsed: 00:22:58
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 40833 steps/s (collection: 2.281s, learning 0.126s)
             Mean action noise std: 2.24
          Mean value_function loss: 101.3558
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 57.4796
                       Mean reward: 527.30
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.4063
    Episode_Reward/rotating_object: 106.7576
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.41s
                      Time elapsed: 00:23:00
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 41364 steps/s (collection: 2.262s, learning 0.115s)
             Mean action noise std: 2.25
          Mean value_function loss: 114.5326
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.4909
                       Mean reward: 590.27
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.3755
    Episode_Reward/rotating_object: 104.4868
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.38s
                      Time elapsed: 00:23:03
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 41760 steps/s (collection: 2.238s, learning 0.116s)
             Mean action noise std: 2.25
          Mean value_function loss: 106.2699
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.5077
                       Mean reward: 539.98
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 1.4194
    Episode_Reward/rotating_object: 108.9787
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.35s
                      Time elapsed: 00:23:05
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 41752 steps/s (collection: 2.238s, learning 0.117s)
             Mean action noise std: 2.25
          Mean value_function loss: 106.7597
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 57.5263
                       Mean reward: 557.28
               Mean episode length: 224.68
    Episode_Reward/reaching_object: 1.3936
    Episode_Reward/rotating_object: 107.8082
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.35s
                      Time elapsed: 00:23:07
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 41836 steps/s (collection: 2.236s, learning 0.113s)
             Mean action noise std: 2.25
          Mean value_function loss: 96.8231
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.5463
                       Mean reward: 559.81
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 1.4119
    Episode_Reward/rotating_object: 109.4792
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.35s
                      Time elapsed: 00:23:10
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 41558 steps/s (collection: 2.249s, learning 0.116s)
             Mean action noise std: 2.25
          Mean value_function loss: 102.8226
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 57.5566
                       Mean reward: 553.33
               Mean episode length: 222.53
    Episode_Reward/reaching_object: 1.3752
    Episode_Reward/rotating_object: 108.2226
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.37s
                      Time elapsed: 00:23:12
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 41670 steps/s (collection: 2.243s, learning 0.116s)
             Mean action noise std: 2.25
          Mean value_function loss: 113.1883
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.5621
                       Mean reward: 514.25
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.3899
    Episode_Reward/rotating_object: 107.6375
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.36s
                      Time elapsed: 00:23:14
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 41475 steps/s (collection: 2.250s, learning 0.120s)
             Mean action noise std: 2.25
          Mean value_function loss: 102.8948
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.5658
                       Mean reward: 571.97
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.3985
    Episode_Reward/rotating_object: 110.7180
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.37s
                      Time elapsed: 00:23:17
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 41479 steps/s (collection: 2.244s, learning 0.126s)
             Mean action noise std: 2.25
          Mean value_function loss: 104.9562
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.5703
                       Mean reward: 524.29
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 1.3889
    Episode_Reward/rotating_object: 107.8443
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.37s
                      Time elapsed: 00:23:19
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 41765 steps/s (collection: 2.227s, learning 0.126s)
             Mean action noise std: 2.25
          Mean value_function loss: 100.6681
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.5781
                       Mean reward: 561.44
               Mean episode length: 231.46
    Episode_Reward/reaching_object: 1.3871
    Episode_Reward/rotating_object: 111.9076
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.35s
                      Time elapsed: 00:23:22
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 42063 steps/s (collection: 2.224s, learning 0.113s)
             Mean action noise std: 2.26
          Mean value_function loss: 97.6836
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.5902
                       Mean reward: 567.91
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.3896
    Episode_Reward/rotating_object: 111.8703
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.34s
                      Time elapsed: 00:23:24
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 42353 steps/s (collection: 2.209s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 103.7742
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.6068
                       Mean reward: 534.62
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 1.3993
    Episode_Reward/rotating_object: 108.4764
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.32s
                      Time elapsed: 00:23:26
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 42400 steps/s (collection: 2.207s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 104.2623
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.6239
                       Mean reward: 587.59
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 1.4048
    Episode_Reward/rotating_object: 108.8036
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.32s
                      Time elapsed: 00:23:29
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 42440 steps/s (collection: 2.204s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 103.8114
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.6424
                       Mean reward: 496.16
               Mean episode length: 218.17
    Episode_Reward/reaching_object: 1.3510
    Episode_Reward/rotating_object: 103.1961
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.32s
                      Time elapsed: 00:23:31
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 42241 steps/s (collection: 2.211s, learning 0.116s)
             Mean action noise std: 2.26
          Mean value_function loss: 100.0204
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.6616
                       Mean reward: 527.34
               Mean episode length: 222.10
    Episode_Reward/reaching_object: 1.4116
    Episode_Reward/rotating_object: 109.4072
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.33s
                      Time elapsed: 00:23:33
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 41982 steps/s (collection: 2.224s, learning 0.117s)
             Mean action noise std: 2.26
          Mean value_function loss: 105.6704
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.6734
                       Mean reward: 561.94
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 1.4009
    Episode_Reward/rotating_object: 114.9877
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.34s
                      Time elapsed: 00:23:35
                               ETA: 00:34:51

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 42405 steps/s (collection: 2.204s, learning 0.114s)
             Mean action noise std: 2.26
          Mean value_function loss: 97.4651
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.6832
                       Mean reward: 563.00
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.4002
    Episode_Reward/rotating_object: 108.7342
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.32s
                      Time elapsed: 00:23:38
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 42094 steps/s (collection: 2.219s, learning 0.116s)
             Mean action noise std: 2.27
          Mean value_function loss: 106.6572
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.6913
                       Mean reward: 555.35
               Mean episode length: 221.50
    Episode_Reward/reaching_object: 1.3562
    Episode_Reward/rotating_object: 110.6981
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.34s
                      Time elapsed: 00:23:40
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 42123 steps/s (collection: 2.221s, learning 0.112s)
             Mean action noise std: 2.27
          Mean value_function loss: 103.8773
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.7021
                       Mean reward: 556.19
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 1.3778
    Episode_Reward/rotating_object: 111.7381
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.33s
                      Time elapsed: 00:23:42
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 42252 steps/s (collection: 2.211s, learning 0.116s)
             Mean action noise std: 2.27
          Mean value_function loss: 92.0510
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.7163
                       Mean reward: 590.80
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.3907
    Episode_Reward/rotating_object: 115.2085
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.33s
                      Time elapsed: 00:23:45
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 42080 steps/s (collection: 2.222s, learning 0.115s)
             Mean action noise std: 2.27
          Mean value_function loss: 99.8994
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.7288
                       Mean reward: 570.20
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.3895
    Episode_Reward/rotating_object: 112.5942
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.34s
                      Time elapsed: 00:23:47
                               ETA: 00:34:39

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 42209 steps/s (collection: 2.210s, learning 0.119s)
             Mean action noise std: 2.27
          Mean value_function loss: 97.3281
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.7415
                       Mean reward: 554.62
               Mean episode length: 228.13
    Episode_Reward/reaching_object: 1.3900
    Episode_Reward/rotating_object: 112.1503
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.33s
                      Time elapsed: 00:23:49
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.231s, learning 0.115s)
             Mean action noise std: 2.27
          Mean value_function loss: 95.3127
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 57.7577
                       Mean reward: 511.10
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.3763
    Episode_Reward/rotating_object: 109.7164
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.35s
                      Time elapsed: 00:23:52
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 41913 steps/s (collection: 2.231s, learning 0.114s)
             Mean action noise std: 2.27
          Mean value_function loss: 104.4470
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.7728
                       Mean reward: 582.21
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.4109
    Episode_Reward/rotating_object: 114.3622
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.35s
                      Time elapsed: 00:23:54
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 41863 steps/s (collection: 2.234s, learning 0.114s)
             Mean action noise std: 2.28
          Mean value_function loss: 106.2465
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 57.7846
                       Mean reward: 555.29
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 1.3912
    Episode_Reward/rotating_object: 115.3221
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.35s
                      Time elapsed: 00:23:57
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 41676 steps/s (collection: 2.247s, learning 0.112s)
             Mean action noise std: 2.28
          Mean value_function loss: 106.6749
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.8011
                       Mean reward: 589.33
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.3770
    Episode_Reward/rotating_object: 110.3638
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.36s
                      Time elapsed: 00:23:59
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 42014 steps/s (collection: 2.226s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 89.5320
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.8140
                       Mean reward: 567.99
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 1.4019
    Episode_Reward/rotating_object: 113.9665
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.34s
                      Time elapsed: 00:24:01
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 42180 steps/s (collection: 2.218s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 103.0781
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.8249
                       Mean reward: 569.59
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.4281
    Episode_Reward/rotating_object: 116.5565
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.33s
                      Time elapsed: 00:24:04
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 41864 steps/s (collection: 2.235s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 103.2453
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 57.8394
                       Mean reward: 603.28
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 1.3990
    Episode_Reward/rotating_object: 116.7382
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.35s
                      Time elapsed: 00:24:06
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 41643 steps/s (collection: 2.247s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 92.1308
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.8606
                       Mean reward: 553.90
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.3777
    Episode_Reward/rotating_object: 112.7763
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.36s
                      Time elapsed: 00:24:08
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 41944 steps/s (collection: 2.227s, learning 0.117s)
             Mean action noise std: 2.29
          Mean value_function loss: 94.7030
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.8880
                       Mean reward: 576.05
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 1.4060
    Episode_Reward/rotating_object: 114.2707
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.34s
                      Time elapsed: 00:24:11
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 42440 steps/s (collection: 2.203s, learning 0.113s)
             Mean action noise std: 2.29
          Mean value_function loss: 106.3553
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 57.9130
                       Mean reward: 557.15
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 1.3554
    Episode_Reward/rotating_object: 111.5956
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.32s
                      Time elapsed: 00:24:13
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 42158 steps/s (collection: 2.219s, learning 0.113s)
             Mean action noise std: 2.29
          Mean value_function loss: 95.6080
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.9287
                       Mean reward: 575.37
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.3874
    Episode_Reward/rotating_object: 108.8634
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.33s
                      Time elapsed: 00:24:15
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 42563 steps/s (collection: 2.197s, learning 0.113s)
             Mean action noise std: 2.29
          Mean value_function loss: 98.3508
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.9420
                       Mean reward: 578.52
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 1.4108
    Episode_Reward/rotating_object: 113.1095
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.31s
                      Time elapsed: 00:24:18
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 42363 steps/s (collection: 2.208s, learning 0.113s)
             Mean action noise std: 2.29
          Mean value_function loss: 95.3122
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.9528
                       Mean reward: 570.15
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 1.4183
    Episode_Reward/rotating_object: 115.1570
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.32s
                      Time elapsed: 00:24:20
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 42589 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 2.29
          Mean value_function loss: 92.2054
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.9628
                       Mean reward: 591.76
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.3988
    Episode_Reward/rotating_object: 119.2590
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.31s
                      Time elapsed: 00:24:22
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 42334 steps/s (collection: 2.209s, learning 0.113s)
             Mean action noise std: 2.30
          Mean value_function loss: 91.9725
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.9781
                       Mean reward: 569.08
               Mean episode length: 236.77
    Episode_Reward/reaching_object: 1.3959
    Episode_Reward/rotating_object: 114.0679
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.32s
                      Time elapsed: 00:24:24
                               ETA: 00:34:02

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 42158 steps/s (collection: 2.201s, learning 0.131s)
             Mean action noise std: 2.30
          Mean value_function loss: 93.4399
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.9992
                       Mean reward: 568.18
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 1.4163
    Episode_Reward/rotating_object: 114.6006
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.33s
                      Time elapsed: 00:24:27
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 41859 steps/s (collection: 2.234s, learning 0.115s)
             Mean action noise std: 2.30
          Mean value_function loss: 94.2430
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 58.0152
                       Mean reward: 587.21
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 1.4167
    Episode_Reward/rotating_object: 116.9625
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.35s
                      Time elapsed: 00:24:29
                               ETA: 00:33:57

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 41994 steps/s (collection: 2.225s, learning 0.115s)
             Mean action noise std: 2.30
          Mean value_function loss: 86.6615
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.0199
                       Mean reward: 580.83
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.4207
    Episode_Reward/rotating_object: 116.5921
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.34s
                      Time elapsed: 00:24:32
                               ETA: 00:33:55

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 41877 steps/s (collection: 2.232s, learning 0.116s)
             Mean action noise std: 2.30
          Mean value_function loss: 95.8975
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.0289
                       Mean reward: 576.79
               Mean episode length: 231.16
    Episode_Reward/reaching_object: 1.4135
    Episode_Reward/rotating_object: 117.3268
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.35s
                      Time elapsed: 00:24:34
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 42077 steps/s (collection: 2.223s, learning 0.113s)
             Mean action noise std: 2.30
          Mean value_function loss: 94.6581
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.0438
                       Mean reward: 575.41
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 1.4073
    Episode_Reward/rotating_object: 113.9593
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.34s
                      Time elapsed: 00:24:36
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 41851 steps/s (collection: 2.234s, learning 0.115s)
             Mean action noise std: 2.30
          Mean value_function loss: 98.2441
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.0609
                       Mean reward: 611.18
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 1.4261
    Episode_Reward/rotating_object: 120.1347
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.35s
                      Time elapsed: 00:24:39
                               ETA: 00:33:48

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 42254 steps/s (collection: 2.214s, learning 0.112s)
             Mean action noise std: 2.30
          Mean value_function loss: 93.3515
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 58.0756
                       Mean reward: 573.95
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.4128
    Episode_Reward/rotating_object: 118.0569
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.33s
                      Time elapsed: 00:24:41
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 42008 steps/s (collection: 2.226s, learning 0.114s)
             Mean action noise std: 2.31
          Mean value_function loss: 90.2447
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.0943
                       Mean reward: 572.88
               Mean episode length: 230.50
    Episode_Reward/reaching_object: 1.4214
    Episode_Reward/rotating_object: 115.7209
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.34s
                      Time elapsed: 00:24:43
                               ETA: 00:33:43

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 41964 steps/s (collection: 2.230s, learning 0.112s)
             Mean action noise std: 2.31
          Mean value_function loss: 98.5295
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.1097
                       Mean reward: 573.56
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.4307
    Episode_Reward/rotating_object: 116.4945
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.34s
                      Time elapsed: 00:24:46
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 42203 steps/s (collection: 2.216s, learning 0.113s)
             Mean action noise std: 2.31
          Mean value_function loss: 97.2342
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.1314
                       Mean reward: 597.98
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.4294
    Episode_Reward/rotating_object: 116.5359
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.33s
                      Time elapsed: 00:24:48
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 42109 steps/s (collection: 2.217s, learning 0.117s)
             Mean action noise std: 2.31
          Mean value_function loss: 88.4401
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.1503
                       Mean reward: 565.28
               Mean episode length: 229.77
    Episode_Reward/reaching_object: 1.4319
    Episode_Reward/rotating_object: 118.2872
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.33s
                      Time elapsed: 00:24:50
                               ETA: 00:33:36

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 41532 steps/s (collection: 2.251s, learning 0.116s)
             Mean action noise std: 2.31
          Mean value_function loss: 94.8670
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 58.1613
                       Mean reward: 541.32
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.4199
    Episode_Reward/rotating_object: 117.0129
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.37s
                      Time elapsed: 00:24:53
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 41785 steps/s (collection: 2.236s, learning 0.116s)
             Mean action noise std: 2.32
          Mean value_function loss: 91.6115
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.1734
                       Mean reward: 633.99
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 1.4076
    Episode_Reward/rotating_object: 117.6582
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.35s
                      Time elapsed: 00:24:55
                               ETA: 00:33:31

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 42069 steps/s (collection: 2.224s, learning 0.113s)
             Mean action noise std: 2.32
          Mean value_function loss: 82.9024
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.1934
                       Mean reward: 566.71
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 1.4412
    Episode_Reward/rotating_object: 118.8410
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.34s
                      Time elapsed: 00:24:57
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 42366 steps/s (collection: 2.208s, learning 0.113s)
             Mean action noise std: 2.32
          Mean value_function loss: 94.8232
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 58.2117
                       Mean reward: 593.97
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.4151
    Episode_Reward/rotating_object: 117.3996
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.32s
                      Time elapsed: 00:25:00
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 42610 steps/s (collection: 2.191s, learning 0.116s)
             Mean action noise std: 2.32
          Mean value_function loss: 85.5227
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.2248
                       Mean reward: 598.73
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.4122
    Episode_Reward/rotating_object: 119.1491
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.31s
                      Time elapsed: 00:25:02
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 42865 steps/s (collection: 2.182s, learning 0.112s)
             Mean action noise std: 2.32
          Mean value_function loss: 91.0702
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.2336
                       Mean reward: 623.00
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 1.4542
    Episode_Reward/rotating_object: 121.1255
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.29s
                      Time elapsed: 00:25:04
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 42702 steps/s (collection: 2.191s, learning 0.112s)
             Mean action noise std: 2.32
          Mean value_function loss: 89.1713
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.2484
                       Mean reward: 620.20
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.4158
    Episode_Reward/rotating_object: 116.2383
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.30s
                      Time elapsed: 00:25:07
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 42584 steps/s (collection: 2.183s, learning 0.125s)
             Mean action noise std: 2.32
          Mean value_function loss: 86.0198
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.2607
                       Mean reward: 619.63
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.4013
    Episode_Reward/rotating_object: 117.3797
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.31s
                      Time elapsed: 00:25:09
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 42584 steps/s (collection: 2.180s, learning 0.128s)
             Mean action noise std: 2.33
          Mean value_function loss: 87.5203
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.2794
                       Mean reward: 625.09
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.4245
    Episode_Reward/rotating_object: 119.6472
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.31s
                      Time elapsed: 00:25:11
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 42575 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 2.33
          Mean value_function loss: 84.2659
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.3093
                       Mean reward: 629.80
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.4530
    Episode_Reward/rotating_object: 124.3475
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.31s
                      Time elapsed: 00:25:13
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 41478 steps/s (collection: 2.255s, learning 0.115s)
             Mean action noise std: 2.33
          Mean value_function loss: 88.2416
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.3268
                       Mean reward: 633.99
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.4256
    Episode_Reward/rotating_object: 122.6300
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.37s
                      Time elapsed: 00:25:16
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 42374 steps/s (collection: 2.206s, learning 0.114s)
             Mean action noise std: 2.33
          Mean value_function loss: 91.2493
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.3481
                       Mean reward: 590.41
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.4393
    Episode_Reward/rotating_object: 121.9932
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.32s
                      Time elapsed: 00:25:18
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 42013 steps/s (collection: 2.226s, learning 0.114s)
             Mean action noise std: 2.34
          Mean value_function loss: 79.1523
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.3694
                       Mean reward: 597.94
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.4124
    Episode_Reward/rotating_object: 120.8452
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.34s
                      Time elapsed: 00:25:20
                               ETA: 00:33:05

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 41268 steps/s (collection: 2.265s, learning 0.117s)
             Mean action noise std: 2.34
          Mean value_function loss: 87.0409
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.3798
                       Mean reward: 596.08
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.4118
    Episode_Reward/rotating_object: 119.4777
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.38s
                      Time elapsed: 00:25:23
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 42267 steps/s (collection: 2.213s, learning 0.113s)
             Mean action noise std: 2.34
          Mean value_function loss: 82.5790
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.3944
                       Mean reward: 584.33
               Mean episode length: 227.84
    Episode_Reward/reaching_object: 1.3853
    Episode_Reward/rotating_object: 118.1106
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.33s
                      Time elapsed: 00:25:25
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 42273 steps/s (collection: 2.211s, learning 0.114s)
             Mean action noise std: 2.34
          Mean value_function loss: 88.8980
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 58.4041
                       Mean reward: 647.32
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 1.4450
    Episode_Reward/rotating_object: 124.4136
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.33s
                      Time elapsed: 00:25:27
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 41484 steps/s (collection: 2.248s, learning 0.121s)
             Mean action noise std: 2.34
          Mean value_function loss: 82.5421
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.4111
                       Mean reward: 614.88
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 1.3974
    Episode_Reward/rotating_object: 120.5320
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.37s
                      Time elapsed: 00:25:30
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 39529 steps/s (collection: 2.348s, learning 0.139s)
             Mean action noise std: 2.34
          Mean value_function loss: 83.3790
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.4299
                       Mean reward: 592.89
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 1.3903
    Episode_Reward/rotating_object: 120.7823
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.49s
                      Time elapsed: 00:25:32
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 39837 steps/s (collection: 2.346s, learning 0.122s)
             Mean action noise std: 2.34
          Mean value_function loss: 90.1290
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.4534
                       Mean reward: 592.23
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 1.4075
    Episode_Reward/rotating_object: 120.7651
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.47s
                      Time elapsed: 00:25:35
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 40291 steps/s (collection: 2.322s, learning 0.118s)
             Mean action noise std: 2.35
          Mean value_function loss: 94.0802
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 58.4620
                       Mean reward: 613.57
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.4234
    Episode_Reward/rotating_object: 119.4061
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.44s
                      Time elapsed: 00:25:37
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 39288 steps/s (collection: 2.381s, learning 0.121s)
             Mean action noise std: 2.35
          Mean value_function loss: 93.6562
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.4728
                       Mean reward: 580.45
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 1.4152
    Episode_Reward/rotating_object: 121.8945
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.50s
                      Time elapsed: 00:25:40
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 40207 steps/s (collection: 2.314s, learning 0.131s)
             Mean action noise std: 2.35
          Mean value_function loss: 99.3389
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.4888
                       Mean reward: 611.95
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.4206
    Episode_Reward/rotating_object: 123.4951
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.44s
                      Time elapsed: 00:25:42
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 40257 steps/s (collection: 2.314s, learning 0.128s)
             Mean action noise std: 2.35
          Mean value_function loss: 87.7500
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.5085
                       Mean reward: 603.98
               Mean episode length: 231.38
    Episode_Reward/reaching_object: 1.3963
    Episode_Reward/rotating_object: 118.8258
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.44s
                      Time elapsed: 00:25:45
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 40789 steps/s (collection: 2.285s, learning 0.125s)
             Mean action noise std: 2.35
          Mean value_function loss: 76.3933
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.5227
                       Mean reward: 613.19
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 1.4149
    Episode_Reward/rotating_object: 120.6826
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.41s
                      Time elapsed: 00:25:47
                               ETA: 00:32:41

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 39813 steps/s (collection: 2.346s, learning 0.123s)
             Mean action noise std: 2.36
          Mean value_function loss: 77.9878
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 58.5535
                       Mean reward: 624.67
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 1.4061
    Episode_Reward/rotating_object: 122.5718
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.47s
                      Time elapsed: 00:25:50
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 40959 steps/s (collection: 2.288s, learning 0.112s)
             Mean action noise std: 2.36
          Mean value_function loss: 86.4302
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.5755
                       Mean reward: 616.64
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.4032
    Episode_Reward/rotating_object: 120.1284
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.40s
                      Time elapsed: 00:25:52
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 42415 steps/s (collection: 2.204s, learning 0.114s)
             Mean action noise std: 2.36
          Mean value_function loss: 80.9036
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.5881
                       Mean reward: 638.47
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.4171
    Episode_Reward/rotating_object: 122.5105
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.32s
                      Time elapsed: 00:25:54
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 41511 steps/s (collection: 2.254s, learning 0.114s)
             Mean action noise std: 2.36
          Mean value_function loss: 87.1159
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.6003
                       Mean reward: 563.97
               Mean episode length: 220.01
    Episode_Reward/reaching_object: 1.4108
    Episode_Reward/rotating_object: 120.9331
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.37s
                      Time elapsed: 00:25:57
                               ETA: 00:32:32

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 42114 steps/s (collection: 2.221s, learning 0.114s)
             Mean action noise std: 2.36
          Mean value_function loss: 79.0229
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.6174
                       Mean reward: 596.42
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.3906
    Episode_Reward/rotating_object: 119.8369
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 2.33s
                      Time elapsed: 00:25:59
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 42470 steps/s (collection: 2.199s, learning 0.116s)
             Mean action noise std: 2.37
          Mean value_function loss: 75.2288
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.6489
                       Mean reward: 639.92
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.4372
    Episode_Reward/rotating_object: 125.2075
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 2.31s
                      Time elapsed: 00:26:01
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 41924 steps/s (collection: 2.225s, learning 0.120s)
             Mean action noise std: 2.37
          Mean value_function loss: 82.0440
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.6731
                       Mean reward: 626.65
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 1.4197
    Episode_Reward/rotating_object: 123.7891
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 2.34s
                      Time elapsed: 00:26:04
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 41891 steps/s (collection: 2.231s, learning 0.116s)
             Mean action noise std: 2.37
          Mean value_function loss: 91.1135
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 58.6900
                       Mean reward: 611.01
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 1.4196
    Episode_Reward/rotating_object: 122.1289
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 2.35s
                      Time elapsed: 00:26:06
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 41986 steps/s (collection: 2.222s, learning 0.119s)
             Mean action noise std: 2.37
          Mean value_function loss: 78.0364
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.6983
                       Mean reward: 618.21
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 1.3905
    Episode_Reward/rotating_object: 119.7692
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 2.34s
                      Time elapsed: 00:26:08
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 42248 steps/s (collection: 2.213s, learning 0.114s)
             Mean action noise std: 2.37
          Mean value_function loss: 72.8814
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.7090
                       Mean reward: 640.85
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 1.4154
    Episode_Reward/rotating_object: 125.3722
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 2.33s
                      Time elapsed: 00:26:11
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 41905 steps/s (collection: 2.228s, learning 0.118s)
             Mean action noise std: 2.37
          Mean value_function loss: 77.0624
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.7207
                       Mean reward: 623.08
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.4168
    Episode_Reward/rotating_object: 125.8904
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 2.35s
                      Time elapsed: 00:26:13
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 41895 steps/s (collection: 2.232s, learning 0.114s)
             Mean action noise std: 2.38
          Mean value_function loss: 77.4436
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.7341
                       Mean reward: 629.18
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.4245
    Episode_Reward/rotating_object: 124.5317
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 2.35s
                      Time elapsed: 00:26:15
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 41932 steps/s (collection: 2.228s, learning 0.117s)
             Mean action noise std: 2.38
          Mean value_function loss: 79.1225
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 58.7513
                       Mean reward: 592.23
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.4286
    Episode_Reward/rotating_object: 123.0759
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 2.34s
                      Time elapsed: 00:26:18
                               ETA: 00:32:11

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 42433 steps/s (collection: 2.202s, learning 0.115s)
             Mean action noise std: 2.38
          Mean value_function loss: 80.4025
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.7630
                       Mean reward: 642.47
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 1.4019
    Episode_Reward/rotating_object: 121.6390
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 2.32s
                      Time elapsed: 00:26:20
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 42184 steps/s (collection: 2.209s, learning 0.121s)
             Mean action noise std: 2.38
          Mean value_function loss: 73.9803
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.7793
                       Mean reward: 628.11
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.4533
    Episode_Reward/rotating_object: 126.2447
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.33s
                      Time elapsed: 00:26:22
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 42160 steps/s (collection: 2.215s, learning 0.116s)
             Mean action noise std: 2.38
          Mean value_function loss: 77.0837
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.8004
                       Mean reward: 666.89
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.4276
    Episode_Reward/rotating_object: 127.2540
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.33s
                      Time elapsed: 00:26:25
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 41842 steps/s (collection: 2.216s, learning 0.133s)
             Mean action noise std: 2.38
          Mean value_function loss: 79.7374
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.8191
                       Mean reward: 601.19
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 1.4425
    Episode_Reward/rotating_object: 124.6462
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.35s
                      Time elapsed: 00:26:27
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 41791 steps/s (collection: 2.237s, learning 0.115s)
             Mean action noise std: 2.39
          Mean value_function loss: 83.5331
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 58.8391
                       Mean reward: 633.64
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.4300
    Episode_Reward/rotating_object: 125.9101
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.35s
                      Time elapsed: 00:26:29
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 41687 steps/s (collection: 2.243s, learning 0.115s)
             Mean action noise std: 2.39
          Mean value_function loss: 83.3768
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.8443
                       Mean reward: 636.96
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.4054
    Episode_Reward/rotating_object: 123.9821
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.36s
                      Time elapsed: 00:26:32
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 42126 steps/s (collection: 2.221s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 74.7253
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.8581
                       Mean reward: 640.50
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.4249
    Episode_Reward/rotating_object: 126.2263
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.33s
                      Time elapsed: 00:26:34
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 42210 steps/s (collection: 2.217s, learning 0.112s)
             Mean action noise std: 2.39
          Mean value_function loss: 75.4605
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.8746
                       Mean reward: 609.17
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.4090
    Episode_Reward/rotating_object: 121.5403
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.33s
                      Time elapsed: 00:26:36
                               ETA: 00:31:52

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 42945 steps/s (collection: 2.177s, learning 0.112s)
             Mean action noise std: 2.39
          Mean value_function loss: 76.4962
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.8970
                       Mean reward: 674.96
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 1.4145
    Episode_Reward/rotating_object: 126.7265
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.29s
                      Time elapsed: 00:26:39
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 42998 steps/s (collection: 2.174s, learning 0.112s)
             Mean action noise std: 2.40
          Mean value_function loss: 71.3217
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.9213
                       Mean reward: 663.79
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 1.4453
    Episode_Reward/rotating_object: 128.4948
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.29s
                      Time elapsed: 00:26:41
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 43050 steps/s (collection: 2.166s, learning 0.118s)
             Mean action noise std: 2.40
          Mean value_function loss: 73.8815
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.9346
                       Mean reward: 644.09
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.4368
    Episode_Reward/rotating_object: 127.8998
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.28s
                      Time elapsed: 00:26:43
                               ETA: 00:31:45

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 43142 steps/s (collection: 2.165s, learning 0.114s)
             Mean action noise std: 2.40
          Mean value_function loss: 72.5556
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.9429
                       Mean reward: 634.06
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 1.4483
    Episode_Reward/rotating_object: 127.2301
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.28s
                      Time elapsed: 00:26:45
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 42653 steps/s (collection: 2.192s, learning 0.112s)
             Mean action noise std: 2.40
          Mean value_function loss: 72.4001
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.9572
                       Mean reward: 640.00
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.4381
    Episode_Reward/rotating_object: 125.5039
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.30s
                      Time elapsed: 00:26:48
                               ETA: 00:31:40

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 42506 steps/s (collection: 2.201s, learning 0.112s)
             Mean action noise std: 2.40
          Mean value_function loss: 77.6513
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.9667
                       Mean reward: 624.00
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.4177
    Episode_Reward/rotating_object: 126.5603
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.31s
                      Time elapsed: 00:26:50
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 42567 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 75.6257
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.9754
                       Mean reward: 654.87
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 1.4409
    Episode_Reward/rotating_object: 129.3345
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.31s
                      Time elapsed: 00:26:52
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 42285 steps/s (collection: 2.210s, learning 0.115s)
             Mean action noise std: 2.41
          Mean value_function loss: 74.7683
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.0048
                       Mean reward: 655.98
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.4347
    Episode_Reward/rotating_object: 128.0415
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.32s
                      Time elapsed: 00:26:55
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 41858 steps/s (collection: 2.233s, learning 0.115s)
             Mean action noise std: 2.41
          Mean value_function loss: 78.8131
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 59.0195
                       Mean reward: 650.14
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.4176
    Episode_Reward/rotating_object: 125.2262
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.35s
                      Time elapsed: 00:26:57
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 42487 steps/s (collection: 2.201s, learning 0.112s)
             Mean action noise std: 2.41
          Mean value_function loss: 70.5160
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.0359
                       Mean reward: 643.13
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 1.4247
    Episode_Reward/rotating_object: 128.2351
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.31s
                      Time elapsed: 00:26:59
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 42216 steps/s (collection: 2.215s, learning 0.114s)
             Mean action noise std: 2.41
          Mean value_function loss: 74.0526
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.0652
                       Mean reward: 645.30
               Mean episode length: 235.19
    Episode_Reward/reaching_object: 1.4206
    Episode_Reward/rotating_object: 126.7247
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.33s
                      Time elapsed: 00:27:02
                               ETA: 00:31:26

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 41844 steps/s (collection: 2.235s, learning 0.114s)
             Mean action noise std: 2.41
          Mean value_function loss: 76.1187
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.0919
                       Mean reward: 627.30
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.4361
    Episode_Reward/rotating_object: 127.3426
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.35s
                      Time elapsed: 00:27:04
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 42341 steps/s (collection: 2.209s, learning 0.113s)
             Mean action noise std: 2.42
          Mean value_function loss: 75.9688
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.1055
                       Mean reward: 672.86
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.4185
    Episode_Reward/rotating_object: 127.6719
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.32s
                      Time elapsed: 00:27:06
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 42052 steps/s (collection: 2.222s, learning 0.116s)
             Mean action noise std: 2.42
          Mean value_function loss: 70.5888
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.1170
                       Mean reward: 667.24
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.3881
    Episode_Reward/rotating_object: 128.0989
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.34s
                      Time elapsed: 00:27:09
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 41935 steps/s (collection: 2.229s, learning 0.115s)
             Mean action noise std: 2.42
          Mean value_function loss: 76.0605
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.1309
                       Mean reward: 664.74
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.4337
    Episode_Reward/rotating_object: 131.4745
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.34s
                      Time elapsed: 00:27:11
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 42183 steps/s (collection: 2.214s, learning 0.117s)
             Mean action noise std: 2.42
          Mean value_function loss: 73.3366
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.1494
                       Mean reward: 639.52
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.4361
    Episode_Reward/rotating_object: 128.4300
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.33s
                      Time elapsed: 00:27:13
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 42563 steps/s (collection: 2.195s, learning 0.114s)
             Mean action noise std: 2.42
          Mean value_function loss: 77.3903
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.1702
                       Mean reward: 660.49
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.4039
    Episode_Reward/rotating_object: 128.8596
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.31s
                      Time elapsed: 00:27:16
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 42077 steps/s (collection: 2.223s, learning 0.113s)
             Mean action noise std: 2.43
          Mean value_function loss: 69.8064
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.1876
                       Mean reward: 642.93
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.4018
    Episode_Reward/rotating_object: 129.1552
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.34s
                      Time elapsed: 00:27:18
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 42378 steps/s (collection: 2.198s, learning 0.122s)
             Mean action noise std: 2.43
          Mean value_function loss: 70.6855
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.2048
                       Mean reward: 647.82
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.4313
    Episode_Reward/rotating_object: 129.9353
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.32s
                      Time elapsed: 00:27:20
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 42693 steps/s (collection: 2.189s, learning 0.114s)
             Mean action noise std: 2.43
          Mean value_function loss: 63.3886
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.2133
                       Mean reward: 628.20
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.4345
    Episode_Reward/rotating_object: 129.5198
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.30s
                      Time elapsed: 00:27:23
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 41859 steps/s (collection: 2.233s, learning 0.115s)
             Mean action noise std: 2.43
          Mean value_function loss: 62.0341
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.2293
                       Mean reward: 661.53
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.4313
    Episode_Reward/rotating_object: 129.8815
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.35s
                      Time elapsed: 00:27:25
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 42860 steps/s (collection: 2.181s, learning 0.113s)
             Mean action noise std: 2.43
          Mean value_function loss: 63.5320
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.2383
                       Mean reward: 680.22
               Mean episode length: 241.09
    Episode_Reward/reaching_object: 1.4438
    Episode_Reward/rotating_object: 133.2161
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.29s
                      Time elapsed: 00:27:27
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 42116 steps/s (collection: 2.207s, learning 0.127s)
             Mean action noise std: 2.43
          Mean value_function loss: 62.8787
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 59.2467
                       Mean reward: 650.89
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.4358
    Episode_Reward/rotating_object: 132.4441
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.33s
                      Time elapsed: 00:27:30
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 42726 steps/s (collection: 2.188s, learning 0.113s)
             Mean action noise std: 2.44
          Mean value_function loss: 68.4234
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.2656
                       Mean reward: 664.16
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 1.4364
    Episode_Reward/rotating_object: 132.7289
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.30s
                      Time elapsed: 00:27:32
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 42317 steps/s (collection: 2.197s, learning 0.126s)
             Mean action noise std: 2.44
          Mean value_function loss: 72.6677
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.2838
                       Mean reward: 626.25
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.4194
    Episode_Reward/rotating_object: 128.8971
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.32s
                      Time elapsed: 00:27:34
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 42451 steps/s (collection: 2.189s, learning 0.127s)
             Mean action noise std: 2.44
          Mean value_function loss: 65.7128
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.3055
                       Mean reward: 674.93
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.4246
    Episode_Reward/rotating_object: 131.3263
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.32s
                      Time elapsed: 00:27:37
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 42589 steps/s (collection: 2.196s, learning 0.112s)
             Mean action noise std: 2.44
          Mean value_function loss: 65.0003
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.3295
                       Mean reward: 650.03
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.4384
    Episode_Reward/rotating_object: 132.6359
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.31s
                      Time elapsed: 00:27:39
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 42626 steps/s (collection: 2.194s, learning 0.112s)
             Mean action noise std: 2.45
          Mean value_function loss: 68.0094
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.3555
                       Mean reward: 690.00
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 1.4467
    Episode_Reward/rotating_object: 135.0237
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.31s
                      Time elapsed: 00:27:41
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 42266 steps/s (collection: 2.213s, learning 0.113s)
             Mean action noise std: 2.45
          Mean value_function loss: 76.5467
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.3814
                       Mean reward: 635.49
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.3825
    Episode_Reward/rotating_object: 124.0541
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.33s
                      Time elapsed: 00:27:44
                               ETA: 00:30:44

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 42396 steps/s (collection: 2.207s, learning 0.112s)
             Mean action noise std: 2.45
          Mean value_function loss: 67.3871
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.4034
                       Mean reward: 652.99
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 1.4135
    Episode_Reward/rotating_object: 129.5750
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.32s
                      Time elapsed: 00:27:46
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 42381 steps/s (collection: 2.204s, learning 0.116s)
             Mean action noise std: 2.45
          Mean value_function loss: 63.7258
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.4241
                       Mean reward: 655.61
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 1.4156
    Episode_Reward/rotating_object: 131.7442
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.32s
                      Time elapsed: 00:27:48
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 42762 steps/s (collection: 2.186s, learning 0.113s)
             Mean action noise std: 2.46
          Mean value_function loss: 64.0221
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.4463
                       Mean reward: 672.61
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.4173
    Episode_Reward/rotating_object: 130.0169
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.30s
                      Time elapsed: 00:27:50
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 42724 steps/s (collection: 2.182s, learning 0.119s)
             Mean action noise std: 2.46
          Mean value_function loss: 71.2680
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.4689
                       Mean reward: 664.19
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.4239
    Episode_Reward/rotating_object: 132.1372
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.30s
                      Time elapsed: 00:27:53
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 42442 steps/s (collection: 2.203s, learning 0.113s)
             Mean action noise std: 2.46
          Mean value_function loss: 72.0589
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.4906
                       Mean reward: 658.50
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.3818
    Episode_Reward/rotating_object: 129.8211
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.32s
                      Time elapsed: 00:27:55
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 42629 steps/s (collection: 2.193s, learning 0.113s)
             Mean action noise std: 2.46
          Mean value_function loss: 63.9867
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.5127
                       Mean reward: 662.60
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 1.4162
    Episode_Reward/rotating_object: 132.2954
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.31s
                      Time elapsed: 00:27:57
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 42602 steps/s (collection: 2.192s, learning 0.116s)
             Mean action noise std: 2.47
          Mean value_function loss: 69.9097
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.5286
                       Mean reward: 632.54
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 1.4130
    Episode_Reward/rotating_object: 127.6556
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.31s
                      Time elapsed: 00:28:00
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 42647 steps/s (collection: 2.190s, learning 0.115s)
             Mean action noise std: 2.47
          Mean value_function loss: 62.4370
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.5440
                       Mean reward: 687.78
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.4315
    Episode_Reward/rotating_object: 132.8428
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.31s
                      Time elapsed: 00:28:02
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 42700 steps/s (collection: 2.188s, learning 0.114s)
             Mean action noise std: 2.47
          Mean value_function loss: 68.0640
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.5530
                       Mean reward: 693.30
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 1.4110
    Episode_Reward/rotating_object: 131.7084
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.30s
                      Time elapsed: 00:28:04
                               ETA: 00:30:22

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 42270 steps/s (collection: 2.209s, learning 0.116s)
             Mean action noise std: 2.47
          Mean value_function loss: 70.2456
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.5596
                       Mean reward: 644.42
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 1.3973
    Episode_Reward/rotating_object: 132.4999
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.33s
                      Time elapsed: 00:28:07
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 41578 steps/s (collection: 2.251s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 64.0012
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.5797
                       Mean reward: 666.70
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 1.4200
    Episode_Reward/rotating_object: 132.9630
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.36s
                      Time elapsed: 00:28:09
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 42671 steps/s (collection: 2.192s, learning 0.112s)
             Mean action noise std: 2.48
          Mean value_function loss: 62.2936
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.6021
                       Mean reward: 694.59
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 1.4290
    Episode_Reward/rotating_object: 131.4424
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.30s
                      Time elapsed: 00:28:11
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 42553 steps/s (collection: 2.195s, learning 0.115s)
             Mean action noise std: 2.48
          Mean value_function loss: 63.6092
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.6191
                       Mean reward: 683.30
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.4459
    Episode_Reward/rotating_object: 133.2330
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.31s
                      Time elapsed: 00:28:14
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 42728 steps/s (collection: 2.188s, learning 0.112s)
             Mean action noise std: 2.48
          Mean value_function loss: 62.6417
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.6317
                       Mean reward: 645.58
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 1.4084
    Episode_Reward/rotating_object: 130.8870
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.30s
                      Time elapsed: 00:28:16
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 43077 steps/s (collection: 2.170s, learning 0.112s)
             Mean action noise std: 2.48
          Mean value_function loss: 66.6694
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.6501
                       Mean reward: 699.02
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 1.4475
    Episode_Reward/rotating_object: 135.5641
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.28s
                      Time elapsed: 00:28:18
                               ETA: 00:30:08

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 43283 steps/s (collection: 2.159s, learning 0.113s)
             Mean action noise std: 2.48
          Mean value_function loss: 65.5235
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.6687
                       Mean reward: 650.10
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 1.4276
    Episode_Reward/rotating_object: 130.5306
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.27s
                      Time elapsed: 00:28:20
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 43239 steps/s (collection: 2.161s, learning 0.113s)
             Mean action noise std: 2.48
          Mean value_function loss: 61.1861
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.6849
                       Mean reward: 659.91
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.4363
    Episode_Reward/rotating_object: 132.2784
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.27s
                      Time elapsed: 00:28:23
                               ETA: 00:30:03

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 43138 steps/s (collection: 2.167s, learning 0.112s)
             Mean action noise std: 2.49
          Mean value_function loss: 62.8667
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.6987
                       Mean reward: 656.19
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.4067
    Episode_Reward/rotating_object: 130.8393
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.28s
                      Time elapsed: 00:28:25
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 43186 steps/s (collection: 2.164s, learning 0.112s)
             Mean action noise std: 2.49
          Mean value_function loss: 63.4796
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.7223
                       Mean reward: 651.01
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.4163
    Episode_Reward/rotating_object: 130.9364
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.28s
                      Time elapsed: 00:28:27
                               ETA: 00:29:58

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 43154 steps/s (collection: 2.166s, learning 0.111s)
             Mean action noise std: 2.49
          Mean value_function loss: 64.3393
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 59.7471
                       Mean reward: 680.82
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 1.4357
    Episode_Reward/rotating_object: 134.6459
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.28s
                      Time elapsed: 00:28:30
                               ETA: 00:29:56

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 42251 steps/s (collection: 2.211s, learning 0.116s)
             Mean action noise std: 2.50
          Mean value_function loss: 56.9243
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.7746
                       Mean reward: 672.03
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.4373
    Episode_Reward/rotating_object: 133.0809
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.33s
                      Time elapsed: 00:28:32
                               ETA: 00:29:54

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 42825 steps/s (collection: 2.178s, learning 0.118s)
             Mean action noise std: 2.50
          Mean value_function loss: 62.6495
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 59.7935
                       Mean reward: 682.88
               Mean episode length: 240.38
    Episode_Reward/reaching_object: 1.4265
    Episode_Reward/rotating_object: 133.3073
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.30s
                      Time elapsed: 00:28:34
                               ETA: 00:29:51

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 42848 steps/s (collection: 2.181s, learning 0.114s)
             Mean action noise std: 2.50
          Mean value_function loss: 59.5556
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 59.8014
                       Mean reward: 650.65
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 1.4448
    Episode_Reward/rotating_object: 134.7523
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.29s
                      Time elapsed: 00:28:36
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 43022 steps/s (collection: 2.172s, learning 0.113s)
             Mean action noise std: 2.50
          Mean value_function loss: 55.9948
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.8108
                       Mean reward: 666.07
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 1.4454
    Episode_Reward/rotating_object: 135.4058
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.28s
                      Time elapsed: 00:28:39
                               ETA: 00:29:47

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 42710 steps/s (collection: 2.186s, learning 0.115s)
             Mean action noise std: 2.50
          Mean value_function loss: 65.4419
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 59.8292
                       Mean reward: 691.96
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.4579
    Episode_Reward/rotating_object: 135.2265
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.30s
                      Time elapsed: 00:28:41
                               ETA: 00:29:44

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 43020 steps/s (collection: 2.173s, learning 0.112s)
             Mean action noise std: 2.50
          Mean value_function loss: 70.8812
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.8442
                       Mean reward: 693.78
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.4151
    Episode_Reward/rotating_object: 134.7816
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.29s
                      Time elapsed: 00:28:43
                               ETA: 00:29:42

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 42843 steps/s (collection: 2.168s, learning 0.126s)
             Mean action noise std: 2.50
          Mean value_function loss: 62.3019
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.8506
                       Mean reward: 714.64
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 1.4326
    Episode_Reward/rotating_object: 135.6900
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.29s
                      Time elapsed: 00:28:46
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 42888 steps/s (collection: 2.178s, learning 0.114s)
             Mean action noise std: 2.51
          Mean value_function loss: 60.2864
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.8672
                       Mean reward: 692.93
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 1.4454
    Episode_Reward/rotating_object: 136.1683
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.29s
                      Time elapsed: 00:28:48
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 42590 steps/s (collection: 2.195s, learning 0.114s)
             Mean action noise std: 2.51
          Mean value_function loss: 53.4622
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.8902
                       Mean reward: 674.97
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 1.4289
    Episode_Reward/rotating_object: 130.1072
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.31s
                      Time elapsed: 00:28:50
                               ETA: 00:29:35

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 42998 steps/s (collection: 2.168s, learning 0.118s)
             Mean action noise std: 2.51
          Mean value_function loss: 51.3229
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.9074
                       Mean reward: 714.32
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 1.4602
    Episode_Reward/rotating_object: 136.9026
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.29s
                      Time elapsed: 00:28:53
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 43061 steps/s (collection: 2.170s, learning 0.113s)
             Mean action noise std: 2.51
          Mean value_function loss: 56.7957
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.9170
                       Mean reward: 686.36
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 1.4572
    Episode_Reward/rotating_object: 135.3702
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.28s
                      Time elapsed: 00:28:55
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 43011 steps/s (collection: 2.173s, learning 0.113s)
             Mean action noise std: 2.51
          Mean value_function loss: 61.2557
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.9361
                       Mean reward: 688.25
               Mean episode length: 245.10
    Episode_Reward/reaching_object: 1.4522
    Episode_Reward/rotating_object: 137.3639
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.29s
                      Time elapsed: 00:28:57
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 42883 steps/s (collection: 2.178s, learning 0.115s)
             Mean action noise std: 2.52
          Mean value_function loss: 60.5650
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.9529
                       Mean reward: 699.54
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 1.4398
    Episode_Reward/rotating_object: 137.8639
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.29s
                      Time elapsed: 00:28:59
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 42456 steps/s (collection: 2.198s, learning 0.117s)
             Mean action noise std: 2.52
          Mean value_function loss: 59.6334
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 59.9687
                       Mean reward: 689.15
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.4619
    Episode_Reward/rotating_object: 138.4008
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.32s
                      Time elapsed: 00:29:02
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 42903 steps/s (collection: 2.176s, learning 0.115s)
             Mean action noise std: 2.52
          Mean value_function loss: 67.7387
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.9807
                       Mean reward: 708.09
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.4622
    Episode_Reward/rotating_object: 139.3250
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.29s
                      Time elapsed: 00:29:04
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 43081 steps/s (collection: 2.167s, learning 0.114s)
             Mean action noise std: 2.52
          Mean value_function loss: 60.4543
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.0007
                       Mean reward: 654.37
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.4332
    Episode_Reward/rotating_object: 133.3930
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.28s
                      Time elapsed: 00:29:06
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 43054 steps/s (collection: 2.169s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 62.7044
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.0244
                       Mean reward: 701.49
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.4354
    Episode_Reward/rotating_object: 135.3227
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.28s
                      Time elapsed: 00:29:09
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 42830 steps/s (collection: 2.182s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 60.9987
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 60.0476
                       Mean reward: 709.90
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.4255
    Episode_Reward/rotating_object: 134.8067
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.30s
                      Time elapsed: 00:29:11
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 43305 steps/s (collection: 2.156s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 58.4432
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.0608
                       Mean reward: 703.29
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.4355
    Episode_Reward/rotating_object: 136.8499
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.27s
                      Time elapsed: 00:29:13
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 43100 steps/s (collection: 2.165s, learning 0.115s)
             Mean action noise std: 2.53
          Mean value_function loss: 54.4009
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.0768
                       Mean reward: 696.00
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 1.4657
    Episode_Reward/rotating_object: 139.7931
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.28s
                      Time elapsed: 00:29:15
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 43118 steps/s (collection: 2.167s, learning 0.113s)
             Mean action noise std: 2.53
          Mean value_function loss: 58.6899
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.0920
                       Mean reward: 693.87
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.4469
    Episode_Reward/rotating_object: 138.2581
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.28s
                      Time elapsed: 00:29:18
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 42958 steps/s (collection: 2.175s, learning 0.113s)
             Mean action noise std: 2.54
          Mean value_function loss: 58.0472
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.1154
                       Mean reward: 678.18
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 1.4520
    Episode_Reward/rotating_object: 136.9054
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.29s
                      Time elapsed: 00:29:20
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 42615 steps/s (collection: 2.194s, learning 0.113s)
             Mean action noise std: 2.54
          Mean value_function loss: 60.5523
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.1376
                       Mean reward: 654.80
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.4375
    Episode_Reward/rotating_object: 135.1133
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.31s
                      Time elapsed: 00:29:22
                               ETA: 00:29:01

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 42680 steps/s (collection: 2.189s, learning 0.114s)
             Mean action noise std: 2.54
          Mean value_function loss: 58.6729
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.1481
                       Mean reward: 704.80
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 1.4586
    Episode_Reward/rotating_object: 136.5847
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.30s
                      Time elapsed: 00:29:25
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 42876 steps/s (collection: 2.179s, learning 0.114s)
             Mean action noise std: 2.54
          Mean value_function loss: 57.2057
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.1586
                       Mean reward: 691.77
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.4268
    Episode_Reward/rotating_object: 134.1653
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.29s
                      Time elapsed: 00:29:27
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 43099 steps/s (collection: 2.167s, learning 0.114s)
             Mean action noise std: 2.54
          Mean value_function loss: 57.3266
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.1779
                       Mean reward: 706.17
               Mean episode length: 247.37
    Episode_Reward/reaching_object: 1.4624
    Episode_Reward/rotating_object: 138.2209
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.28s
                      Time elapsed: 00:29:29
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 42064 steps/s (collection: 2.222s, learning 0.115s)
             Mean action noise std: 2.54
          Mean value_function loss: 62.7162
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.2017
                       Mean reward: 712.75
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 1.4336
    Episode_Reward/rotating_object: 136.7676
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.34s
                      Time elapsed: 00:29:32
                               ETA: 00:28:52

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 42983 steps/s (collection: 2.174s, learning 0.113s)
             Mean action noise std: 2.55
          Mean value_function loss: 47.2860
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.2275
                       Mean reward: 690.42
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 1.4325
    Episode_Reward/rotating_object: 137.1521
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.29s
                      Time elapsed: 00:29:34
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 42789 steps/s (collection: 2.182s, learning 0.115s)
             Mean action noise std: 2.55
          Mean value_function loss: 55.4070
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.2508
                       Mean reward: 671.77
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.4394
    Episode_Reward/rotating_object: 136.6219
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.30s
                      Time elapsed: 00:29:36
                               ETA: 00:28:47

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 43105 steps/s (collection: 2.167s, learning 0.114s)
             Mean action noise std: 2.55
          Mean value_function loss: 63.8467
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.2702
                       Mean reward: 687.37
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.4327
    Episode_Reward/rotating_object: 137.4430
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.28s
                      Time elapsed: 00:29:38
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 42432 steps/s (collection: 2.204s, learning 0.113s)
             Mean action noise std: 2.55
          Mean value_function loss: 62.4491
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.2799
                       Mean reward: 680.73
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.4169
    Episode_Reward/rotating_object: 135.8208
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.32s
                      Time elapsed: 00:29:41
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 43148 steps/s (collection: 2.160s, learning 0.118s)
             Mean action noise std: 2.56
          Mean value_function loss: 56.0097
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.2941
                       Mean reward: 724.63
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 1.4409
    Episode_Reward/rotating_object: 139.9494
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.28s
                      Time elapsed: 00:29:43
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 43011 steps/s (collection: 2.169s, learning 0.117s)
             Mean action noise std: 2.56
          Mean value_function loss: 57.9524
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.3101
                       Mean reward: 686.00
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 1.4417
    Episode_Reward/rotating_object: 137.4886
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.29s
                      Time elapsed: 00:29:45
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 43028 steps/s (collection: 2.168s, learning 0.116s)
             Mean action noise std: 2.56
          Mean value_function loss: 54.6714
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.3291
                       Mean reward: 690.95
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.4182
    Episode_Reward/rotating_object: 134.3582
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.28s
                      Time elapsed: 00:29:48
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 42160 steps/s (collection: 2.218s, learning 0.114s)
             Mean action noise std: 2.56
          Mean value_function loss: 63.0479
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3625
                       Mean reward: 698.11
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.4311
    Episode_Reward/rotating_object: 137.0807
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.33s
                      Time elapsed: 00:29:50
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 42223 steps/s (collection: 2.214s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 56.0953
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 60.3838
                       Mean reward: 715.33
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.4192
    Episode_Reward/rotating_object: 136.6650
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.33s
                      Time elapsed: 00:29:52
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 42861 steps/s (collection: 2.179s, learning 0.115s)
             Mean action noise std: 2.57
          Mean value_function loss: 53.3335
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.3979
                       Mean reward: 700.18
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.4439
    Episode_Reward/rotating_object: 136.9482
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.29s
                      Time elapsed: 00:29:55
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 42902 steps/s (collection: 2.165s, learning 0.127s)
             Mean action noise std: 2.57
          Mean value_function loss: 54.0403
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.4100
                       Mean reward: 684.15
               Mean episode length: 242.48
    Episode_Reward/reaching_object: 1.4530
    Episode_Reward/rotating_object: 140.5508
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.29s
                      Time elapsed: 00:29:57
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 42903 steps/s (collection: 2.178s, learning 0.113s)
             Mean action noise std: 2.57
          Mean value_function loss: 52.0776
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.4317
                       Mean reward: 647.61
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.4311
    Episode_Reward/rotating_object: 136.1968
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.29s
                      Time elapsed: 00:29:59
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 43296 steps/s (collection: 2.158s, learning 0.112s)
             Mean action noise std: 2.57
          Mean value_function loss: 61.4163
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.4544
                       Mean reward: 670.58
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.4515
    Episode_Reward/rotating_object: 137.3140
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.27s
                      Time elapsed: 00:30:01
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 43384 steps/s (collection: 2.154s, learning 0.112s)
             Mean action noise std: 2.58
          Mean value_function loss: 59.1192
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.4719
                       Mean reward: 674.45
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.4440
    Episode_Reward/rotating_object: 137.7091
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.27s
                      Time elapsed: 00:30:04
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 43310 steps/s (collection: 2.155s, learning 0.115s)
             Mean action noise std: 2.58
          Mean value_function loss: 57.8314
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.4892
                       Mean reward: 695.65
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.4627
    Episode_Reward/rotating_object: 140.2514
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.27s
                      Time elapsed: 00:30:06
                               ETA: 00:28:16

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 42714 steps/s (collection: 2.186s, learning 0.115s)
             Mean action noise std: 2.58
          Mean value_function loss: 54.1789
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.5101
                       Mean reward: 699.93
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 1.4684
    Episode_Reward/rotating_object: 137.6744
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.30s
                      Time elapsed: 00:30:08
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 42587 steps/s (collection: 2.181s, learning 0.127s)
             Mean action noise std: 2.58
          Mean value_function loss: 58.3306
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 60.5367
                       Mean reward: 687.28
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 1.4659
    Episode_Reward/rotating_object: 138.2308
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.31s
                      Time elapsed: 00:30:11
                               ETA: 00:28:11

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 43051 steps/s (collection: 2.171s, learning 0.113s)
             Mean action noise std: 2.59
          Mean value_function loss: 58.2659
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.5484
                       Mean reward: 668.89
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.4224
    Episode_Reward/rotating_object: 133.8391
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.28s
                      Time elapsed: 00:30:13
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 43171 steps/s (collection: 2.163s, learning 0.114s)
             Mean action noise std: 2.59
          Mean value_function loss: 53.4330
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.5664
                       Mean reward: 731.86
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 1.4490
    Episode_Reward/rotating_object: 138.3884
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.28s
                      Time elapsed: 00:30:15
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 42503 steps/s (collection: 2.186s, learning 0.126s)
             Mean action noise std: 2.59
          Mean value_function loss: 50.2969
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.5930
                       Mean reward: 703.15
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 1.4506
    Episode_Reward/rotating_object: 137.7379
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.31s
                      Time elapsed: 00:30:17
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 42813 steps/s (collection: 2.175s, learning 0.121s)
             Mean action noise std: 2.59
          Mean value_function loss: 52.6797
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.6203
                       Mean reward: 690.64
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.4621
    Episode_Reward/rotating_object: 141.3415
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.30s
                      Time elapsed: 00:30:20
                               ETA: 00:28:02

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 42777 steps/s (collection: 2.179s, learning 0.119s)
             Mean action noise std: 2.60
          Mean value_function loss: 49.2380
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.6436
                       Mean reward: 681.88
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 1.4502
    Episode_Reward/rotating_object: 139.3963
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.30s
                      Time elapsed: 00:30:22
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 43040 steps/s (collection: 2.172s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 50.5853
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 60.6629
                       Mean reward: 685.11
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.4578
    Episode_Reward/rotating_object: 140.1216
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.28s
                      Time elapsed: 00:30:24
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 42910 steps/s (collection: 2.176s, learning 0.115s)
             Mean action noise std: 2.60
          Mean value_function loss: 58.9774
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.6855
                       Mean reward: 696.69
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 1.4539
    Episode_Reward/rotating_object: 138.6902
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.29s
                      Time elapsed: 00:30:27
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 43043 steps/s (collection: 2.170s, learning 0.114s)
             Mean action noise std: 2.60
          Mean value_function loss: 60.3953
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.7085
                       Mean reward: 729.54
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 1.4574
    Episode_Reward/rotating_object: 138.4932
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.28s
                      Time elapsed: 00:30:29
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 43310 steps/s (collection: 2.154s, learning 0.115s)
             Mean action noise std: 2.61
          Mean value_function loss: 57.7015
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.7301
                       Mean reward: 717.24
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.4493
    Episode_Reward/rotating_object: 140.2605
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.27s
                      Time elapsed: 00:30:31
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 42667 steps/s (collection: 2.190s, learning 0.114s)
             Mean action noise std: 2.61
          Mean value_function loss: 56.4439
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.7481
                       Mean reward: 686.18
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.4455
    Episode_Reward/rotating_object: 138.5603
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.30s
                      Time elapsed: 00:30:33
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 43101 steps/s (collection: 2.166s, learning 0.115s)
             Mean action noise std: 2.61
          Mean value_function loss: 57.6437
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.7672
                       Mean reward: 707.98
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 1.4350
    Episode_Reward/rotating_object: 138.7874
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.28s
                      Time elapsed: 00:30:36
                               ETA: 00:27:45

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 42463 steps/s (collection: 2.198s, learning 0.117s)
             Mean action noise std: 2.61
          Mean value_function loss: 59.2541
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.7872
                       Mean reward: 690.32
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.4128
    Episode_Reward/rotating_object: 134.7827
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.32s
                      Time elapsed: 00:30:38
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 43069 steps/s (collection: 2.166s, learning 0.116s)
             Mean action noise std: 2.62
          Mean value_function loss: 55.7299
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 60.8148
                       Mean reward: 694.19
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.4534
    Episode_Reward/rotating_object: 140.4146
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.28s
                      Time elapsed: 00:30:40
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 42334 steps/s (collection: 2.209s, learning 0.113s)
             Mean action noise std: 2.62
          Mean value_function loss: 52.9655
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.8369
                       Mean reward: 729.62
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.4558
    Episode_Reward/rotating_object: 140.2340
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.32s
                      Time elapsed: 00:30:43
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 43658 steps/s (collection: 2.137s, learning 0.115s)
             Mean action noise std: 2.62
          Mean value_function loss: 51.1064
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.8583
                       Mean reward: 705.42
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 1.4637
    Episode_Reward/rotating_object: 140.4020
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.25s
                      Time elapsed: 00:30:45
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 43276 steps/s (collection: 2.159s, learning 0.113s)
             Mean action noise std: 2.63
          Mean value_function loss: 53.5125
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.8821
                       Mean reward: 696.28
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 1.4474
    Episode_Reward/rotating_object: 138.4287
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.27s
                      Time elapsed: 00:30:47
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 43325 steps/s (collection: 2.156s, learning 0.113s)
             Mean action noise std: 2.63
          Mean value_function loss: 52.3293
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.8920
                       Mean reward: 714.36
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.4640
    Episode_Reward/rotating_object: 141.0607
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.27s
                      Time elapsed: 00:30:49
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 43627 steps/s (collection: 2.140s, learning 0.113s)
             Mean action noise std: 2.63
          Mean value_function loss: 48.7227
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.9127
                       Mean reward: 726.46
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.4580
    Episode_Reward/rotating_object: 140.2279
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.25s
                      Time elapsed: 00:30:52
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 43596 steps/s (collection: 2.143s, learning 0.112s)
             Mean action noise std: 2.63
          Mean value_function loss: 53.8428
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 60.9420
                       Mean reward: 681.71
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.4802
    Episode_Reward/rotating_object: 140.3503
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.25s
                      Time elapsed: 00:30:54
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 43008 steps/s (collection: 2.169s, learning 0.116s)
             Mean action noise std: 2.63
          Mean value_function loss: 56.4927
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.9621
                       Mean reward: 682.91
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 1.4494
    Episode_Reward/rotating_object: 137.4664
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.29s
                      Time elapsed: 00:30:56
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 43140 steps/s (collection: 2.162s, learning 0.116s)
             Mean action noise std: 2.64
          Mean value_function loss: 50.8512
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.9808
                       Mean reward: 731.18
               Mean episode length: 246.91
    Episode_Reward/reaching_object: 1.4518
    Episode_Reward/rotating_object: 139.0235
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.28s
                      Time elapsed: 00:30:58
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 42879 steps/s (collection: 2.177s, learning 0.115s)
             Mean action noise std: 2.64
          Mean value_function loss: 58.1709
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.0038
                       Mean reward: 691.59
               Mean episode length: 242.79
    Episode_Reward/reaching_object: 1.4691
    Episode_Reward/rotating_object: 139.1843
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.29s
                      Time elapsed: 00:31:01
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 42992 steps/s (collection: 2.174s, learning 0.112s)
             Mean action noise std: 2.64
          Mean value_function loss: 56.0344
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 61.0272
                       Mean reward: 716.91
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.4583
    Episode_Reward/rotating_object: 139.1409
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.29s
                      Time elapsed: 00:31:03
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 43486 steps/s (collection: 2.148s, learning 0.113s)
             Mean action noise std: 2.64
          Mean value_function loss: 57.4842
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.0480
                       Mean reward: 714.30
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 1.4517
    Episode_Reward/rotating_object: 139.8677
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.26s
                      Time elapsed: 00:31:05
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 42833 steps/s (collection: 2.183s, learning 0.112s)
             Mean action noise std: 2.65
          Mean value_function loss: 54.4081
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.0650
                       Mean reward: 691.83
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 1.4336
    Episode_Reward/rotating_object: 137.8649
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.30s
                      Time elapsed: 00:31:08
                               ETA: 00:27:12

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 43237 steps/s (collection: 2.158s, learning 0.115s)
             Mean action noise std: 2.65
          Mean value_function loss: 53.1108
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.0898
                       Mean reward: 731.67
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.4837
    Episode_Reward/rotating_object: 142.7813
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.27s
                      Time elapsed: 00:31:10
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 43196 steps/s (collection: 2.157s, learning 0.118s)
             Mean action noise std: 2.65
          Mean value_function loss: 51.5349
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.1137
                       Mean reward: 700.72
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.4631
    Episode_Reward/rotating_object: 140.0852
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.28s
                      Time elapsed: 00:31:12
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 43161 steps/s (collection: 2.156s, learning 0.122s)
             Mean action noise std: 2.66
          Mean value_function loss: 49.1014
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.1406
                       Mean reward: 719.20
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.4925
    Episode_Reward/rotating_object: 142.7810
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.28s
                      Time elapsed: 00:31:14
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 42848 steps/s (collection: 2.183s, learning 0.112s)
             Mean action noise std: 2.66
          Mean value_function loss: 48.4165
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.1673
                       Mean reward: 698.60
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.4400
    Episode_Reward/rotating_object: 135.5621
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.29s
                      Time elapsed: 00:31:17
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 43101 steps/s (collection: 2.171s, learning 0.110s)
             Mean action noise std: 2.66
          Mean value_function loss: 51.8489
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.1823
                       Mean reward: 696.49
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.4780
    Episode_Reward/rotating_object: 140.4651
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.28s
                      Time elapsed: 00:31:19
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 45801 steps/s (collection: 2.037s, learning 0.110s)
             Mean action noise std: 2.66
          Mean value_function loss: 45.1316
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 61.1968
                       Mean reward: 735.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.4909
    Episode_Reward/rotating_object: 143.2186
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.15s
                      Time elapsed: 00:31:21
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 45601 steps/s (collection: 2.045s, learning 0.111s)
             Mean action noise std: 2.67
          Mean value_function loss: 50.7364
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.2163
                       Mean reward: 714.81
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.4995
    Episode_Reward/rotating_object: 140.8785
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.16s
                      Time elapsed: 00:31:23
                               ETA: 00:26:55

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 45821 steps/s (collection: 2.032s, learning 0.114s)
             Mean action noise std: 2.67
          Mean value_function loss: 51.0245
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 61.2403
                       Mean reward: 751.14
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.4758
    Episode_Reward/rotating_object: 140.5822
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.15s
                      Time elapsed: 00:31:25
                               ETA: 00:26:53

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 45548 steps/s (collection: 2.044s, learning 0.114s)
             Mean action noise std: 2.67
          Mean value_function loss: 47.8948
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.2540
                       Mean reward: 732.19
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.4890
    Episode_Reward/rotating_object: 141.2672
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.16s
                      Time elapsed: 00:31:28
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 46123 steps/s (collection: 2.019s, learning 0.112s)
             Mean action noise std: 2.67
          Mean value_function loss: 52.2879
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.2669
                       Mean reward: 688.90
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.4733
    Episode_Reward/rotating_object: 140.7344
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.13s
                      Time elapsed: 00:31:30
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 46678 steps/s (collection: 1.993s, learning 0.113s)
             Mean action noise std: 2.67
          Mean value_function loss: 46.0758
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.2790
                       Mean reward: 727.10
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.5098
    Episode_Reward/rotating_object: 142.9375
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.11s
                      Time elapsed: 00:31:32
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 46084 steps/s (collection: 2.010s, learning 0.123s)
             Mean action noise std: 2.68
          Mean value_function loss: 53.5440
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.2908
                       Mean reward: 710.62
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 1.4612
    Episode_Reward/rotating_object: 139.3985
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.13s
                      Time elapsed: 00:31:34
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 43373 steps/s (collection: 2.151s, learning 0.115s)
             Mean action noise std: 2.68
          Mean value_function loss: 46.0391
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.3164
                       Mean reward: 723.06
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.5031
    Episode_Reward/rotating_object: 142.3157
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.27s
                      Time elapsed: 00:31:36
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 43574 steps/s (collection: 2.144s, learning 0.112s)
             Mean action noise std: 2.68
          Mean value_function loss: 47.0336
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.3307
                       Mean reward: 712.74
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.5021
    Episode_Reward/rotating_object: 143.5903
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.26s
                      Time elapsed: 00:31:39
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 43844 steps/s (collection: 2.129s, learning 0.113s)
             Mean action noise std: 2.68
          Mean value_function loss: 53.1296
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.3438
                       Mean reward: 731.18
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.5136
    Episode_Reward/rotating_object: 143.3929
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.24s
                      Time elapsed: 00:31:41
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 43855 steps/s (collection: 2.126s, learning 0.116s)
             Mean action noise std: 2.68
          Mean value_function loss: 55.6898
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.3628
                       Mean reward: 735.96
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.4662
    Episode_Reward/rotating_object: 139.0795
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.24s
                      Time elapsed: 00:31:43
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 44074 steps/s (collection: 2.117s, learning 0.113s)
             Mean action noise std: 2.69
          Mean value_function loss: 61.7597
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 61.3861
                       Mean reward: 698.11
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.4809
    Episode_Reward/rotating_object: 138.7405
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.23s
                      Time elapsed: 00:31:45
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 43767 steps/s (collection: 2.132s, learning 0.115s)
             Mean action noise std: 2.69
          Mean value_function loss: 45.7767
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.4019
                       Mean reward: 714.75
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.4834
    Episode_Reward/rotating_object: 141.6986
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.25s
                      Time elapsed: 00:31:47
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 43499 steps/s (collection: 2.147s, learning 0.113s)
             Mean action noise std: 2.69
          Mean value_function loss: 44.7290
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.4206
                       Mean reward: 704.75
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.5250
    Episode_Reward/rotating_object: 143.2861
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.26s
                      Time elapsed: 00:31:50
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 43627 steps/s (collection: 2.137s, learning 0.116s)
             Mean action noise std: 2.69
          Mean value_function loss: 54.8943
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.4490
                       Mean reward: 726.17
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 1.4971
    Episode_Reward/rotating_object: 143.6178
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.25s
                      Time elapsed: 00:31:52
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 43328 steps/s (collection: 2.153s, learning 0.116s)
             Mean action noise std: 2.70
          Mean value_function loss: 53.3976
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 61.4722
                       Mean reward: 724.18
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.4941
    Episode_Reward/rotating_object: 144.2365
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.27s
                      Time elapsed: 00:31:54
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 43132 steps/s (collection: 2.149s, learning 0.130s)
             Mean action noise std: 2.70
          Mean value_function loss: 51.9806
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 61.4858
                       Mean reward: 702.25
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.4874
    Episode_Reward/rotating_object: 140.5991
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.28s
                      Time elapsed: 00:31:57
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 43762 steps/s (collection: 2.134s, learning 0.112s)
             Mean action noise std: 2.70
          Mean value_function loss: 46.9414
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.4939
                       Mean reward: 702.27
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.5060
    Episode_Reward/rotating_object: 142.6452
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.25s
                      Time elapsed: 00:31:59
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 43475 steps/s (collection: 2.143s, learning 0.118s)
             Mean action noise std: 2.70
          Mean value_function loss: 53.0610
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.5105
                       Mean reward: 743.42
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 1.5010
    Episode_Reward/rotating_object: 141.7115
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.26s
                      Time elapsed: 00:32:01
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 43266 steps/s (collection: 2.156s, learning 0.116s)
             Mean action noise std: 2.70
          Mean value_function loss: 58.0799
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.5305
                       Mean reward: 743.17
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.4971
    Episode_Reward/rotating_object: 142.4180
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.27s
                      Time elapsed: 00:32:03
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 42945 steps/s (collection: 2.173s, learning 0.116s)
             Mean action noise std: 2.71
          Mean value_function loss: 55.7929
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.5612
                       Mean reward: 704.65
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.4931
    Episode_Reward/rotating_object: 142.5715
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.29s
                      Time elapsed: 00:32:06
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 43265 steps/s (collection: 2.159s, learning 0.113s)
             Mean action noise std: 2.71
          Mean value_function loss: 52.3134
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.5891
                       Mean reward: 721.30
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 1.5077
    Episode_Reward/rotating_object: 141.5804
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.27s
                      Time elapsed: 00:32:08
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 43157 steps/s (collection: 2.163s, learning 0.115s)
             Mean action noise std: 2.71
          Mean value_function loss: 54.1717
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.6063
                       Mean reward: 728.11
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.4926
    Episode_Reward/rotating_object: 142.0441
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.28s
                      Time elapsed: 00:32:10
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 43163 steps/s (collection: 2.163s, learning 0.114s)
             Mean action noise std: 2.72
          Mean value_function loss: 40.5348
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.6220
                       Mean reward: 745.32
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.5001
    Episode_Reward/rotating_object: 143.4958
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.28s
                      Time elapsed: 00:32:12
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 43005 steps/s (collection: 2.172s, learning 0.114s)
             Mean action noise std: 2.72
          Mean value_function loss: 55.6390
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.6369
                       Mean reward: 719.78
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.5031
    Episode_Reward/rotating_object: 142.5360
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.29s
                      Time elapsed: 00:32:15
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 43629 steps/s (collection: 2.141s, learning 0.112s)
             Mean action noise std: 2.72
          Mean value_function loss: 54.4620
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.6539
                       Mean reward: 722.80
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.5004
    Episode_Reward/rotating_object: 144.1298
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.25s
                      Time elapsed: 00:32:17
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 43449 steps/s (collection: 2.145s, learning 0.117s)
             Mean action noise std: 2.72
          Mean value_function loss: 44.4177
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.6730
                       Mean reward: 724.62
               Mean episode length: 241.91
    Episode_Reward/reaching_object: 1.5162
    Episode_Reward/rotating_object: 145.3729
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.26s
                      Time elapsed: 00:32:19
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 43722 steps/s (collection: 2.128s, learning 0.120s)
             Mean action noise std: 2.72
          Mean value_function loss: 53.8271
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.6917
                       Mean reward: 712.69
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 1.5078
    Episode_Reward/rotating_object: 140.7004
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.25s
                      Time elapsed: 00:32:21
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 43768 steps/s (collection: 2.119s, learning 0.127s)
             Mean action noise std: 2.73
          Mean value_function loss: 49.0903
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.7084
                       Mean reward: 711.32
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.5066
    Episode_Reward/rotating_object: 143.4041
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.25s
                      Time elapsed: 00:32:24
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 44229 steps/s (collection: 2.102s, learning 0.120s)
             Mean action noise std: 2.73
          Mean value_function loss: 48.9383
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.7208
                       Mean reward: 718.93
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 1.5095
    Episode_Reward/rotating_object: 141.8525
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.22s
                      Time elapsed: 00:32:26
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 44280 steps/s (collection: 2.108s, learning 0.112s)
             Mean action noise std: 2.73
          Mean value_function loss: 56.3080
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.7337
                       Mean reward: 763.55
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.5178
    Episode_Reward/rotating_object: 146.0666
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.22s
                      Time elapsed: 00:32:28
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 43582 steps/s (collection: 2.143s, learning 0.113s)
             Mean action noise std: 2.73
          Mean value_function loss: 44.4707
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.7468
                       Mean reward: 735.46
               Mean episode length: 240.52
    Episode_Reward/reaching_object: 1.5272
    Episode_Reward/rotating_object: 144.6809
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.26s
                      Time elapsed: 00:32:30
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 42857 steps/s (collection: 2.177s, learning 0.116s)
             Mean action noise std: 2.73
          Mean value_function loss: 48.6215
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.7594
                       Mean reward: 765.68
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 1.5332
    Episode_Reward/rotating_object: 144.9673
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.29s
                      Time elapsed: 00:32:33
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 42546 steps/s (collection: 2.194s, learning 0.116s)
             Mean action noise std: 2.74
          Mean value_function loss: 49.5192
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.7709
                       Mean reward: 718.34
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.4962
    Episode_Reward/rotating_object: 142.7287
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.31s
                      Time elapsed: 00:32:35
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 43347 steps/s (collection: 2.155s, learning 0.113s)
             Mean action noise std: 2.74
          Mean value_function loss: 51.8251
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.7882
                       Mean reward: 707.54
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.5128
    Episode_Reward/rotating_object: 144.6724
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.27s
                      Time elapsed: 00:32:37
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 43651 steps/s (collection: 2.138s, learning 0.114s)
             Mean action noise std: 2.74
          Mean value_function loss: 48.6169
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.8125
                       Mean reward: 733.14
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 1.5219
    Episode_Reward/rotating_object: 144.0496
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.25s
                      Time elapsed: 00:32:40
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 43062 steps/s (collection: 2.167s, learning 0.116s)
             Mean action noise std: 2.74
          Mean value_function loss: 42.5588
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.8245
                       Mean reward: 739.51
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.5521
    Episode_Reward/rotating_object: 147.8710
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.28s
                      Time elapsed: 00:32:42
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 43528 steps/s (collection: 2.146s, learning 0.113s)
             Mean action noise std: 2.74
          Mean value_function loss: 50.5394
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.8415
                       Mean reward: 704.39
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.5129
    Episode_Reward/rotating_object: 141.8634
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.26s
                      Time elapsed: 00:32:44
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 43410 steps/s (collection: 2.150s, learning 0.114s)
             Mean action noise std: 2.75
          Mean value_function loss: 40.9523
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 61.8642
                       Mean reward: 755.93
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 1.5312
    Episode_Reward/rotating_object: 145.0611
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.26s
                      Time elapsed: 00:32:46
                               ETA: 00:25:26

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 43551 steps/s (collection: 2.142s, learning 0.115s)
             Mean action noise std: 2.75
          Mean value_function loss: 40.9062
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.8846
                       Mean reward: 745.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.5466
    Episode_Reward/rotating_object: 145.2780
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.26s
                      Time elapsed: 00:32:49
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 43152 steps/s (collection: 2.163s, learning 0.115s)
             Mean action noise std: 2.75
          Mean value_function loss: 37.7806
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.9031
                       Mean reward: 739.85
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.5516
    Episode_Reward/rotating_object: 149.7329
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.28s
                      Time elapsed: 00:32:51
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 43243 steps/s (collection: 2.160s, learning 0.114s)
             Mean action noise std: 2.75
          Mean value_function loss: 47.3963
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.9244
                       Mean reward: 754.38
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.5353
    Episode_Reward/rotating_object: 145.8424
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.27s
                      Time elapsed: 00:32:53
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 43168 steps/s (collection: 2.149s, learning 0.128s)
             Mean action noise std: 2.76
          Mean value_function loss: 48.9727
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.9484
                       Mean reward: 749.45
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.5232
    Episode_Reward/rotating_object: 145.0446
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.28s
                      Time elapsed: 00:32:55
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 43382 steps/s (collection: 2.153s, learning 0.113s)
             Mean action noise std: 2.76
          Mean value_function loss: 45.3336
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.9657
                       Mean reward: 752.80
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.5182
    Episode_Reward/rotating_object: 143.8485
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.27s
                      Time elapsed: 00:32:58
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 43199 steps/s (collection: 2.160s, learning 0.116s)
             Mean action noise std: 2.76
          Mean value_function loss: 60.8977
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.9921
                       Mean reward: 735.44
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.5026
    Episode_Reward/rotating_object: 142.6743
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.28s
                      Time elapsed: 00:33:00
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 42919 steps/s (collection: 2.166s, learning 0.125s)
             Mean action noise std: 2.77
          Mean value_function loss: 52.2119
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.0188
                       Mean reward: 704.02
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.5030
    Episode_Reward/rotating_object: 141.4942
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.29s
                      Time elapsed: 00:33:02
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 43287 steps/s (collection: 2.156s, learning 0.115s)
             Mean action noise std: 2.77
          Mean value_function loss: 50.8943
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.0437
                       Mean reward: 719.68
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.5323
    Episode_Reward/rotating_object: 146.4375
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.27s
                      Time elapsed: 00:33:05
                               ETA: 00:25:07

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 43053 steps/s (collection: 2.169s, learning 0.114s)
             Mean action noise std: 2.77
          Mean value_function loss: 37.1559
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.0684
                       Mean reward: 738.79
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 1.5324
    Episode_Reward/rotating_object: 146.4774
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.28s
                      Time elapsed: 00:33:07
                               ETA: 00:25:05

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 43021 steps/s (collection: 2.170s, learning 0.115s)
             Mean action noise std: 2.77
          Mean value_function loss: 54.2168
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 62.0921
                       Mean reward: 726.63
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 1.5055
    Episode_Reward/rotating_object: 144.0665
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.29s
                      Time elapsed: 00:33:09
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 43729 steps/s (collection: 2.132s, learning 0.116s)
             Mean action noise std: 2.78
          Mean value_function loss: 44.3452
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.1106
                       Mean reward: 761.68
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.5452
    Episode_Reward/rotating_object: 146.8049
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.25s
                      Time elapsed: 00:33:11
                               ETA: 00:25:00

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 43827 steps/s (collection: 2.131s, learning 0.112s)
             Mean action noise std: 2.78
          Mean value_function loss: 43.0044
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 62.1281
                       Mean reward: 736.19
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 1.5467
    Episode_Reward/rotating_object: 146.6095
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.24s
                      Time elapsed: 00:33:14
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 43719 steps/s (collection: 2.135s, learning 0.113s)
             Mean action noise std: 2.78
          Mean value_function loss: 47.5162
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.1581
                       Mean reward: 695.11
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.5150
    Episode_Reward/rotating_object: 143.2689
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.25s
                      Time elapsed: 00:33:16
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 43583 steps/s (collection: 2.141s, learning 0.115s)
             Mean action noise std: 2.79
          Mean value_function loss: 47.1330
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.1810
                       Mean reward: 738.82
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.5440
    Episode_Reward/rotating_object: 147.8773
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.26s
                      Time elapsed: 00:33:18
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 43584 steps/s (collection: 2.143s, learning 0.112s)
             Mean action noise std: 2.79
          Mean value_function loss: 54.6715
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.2045
                       Mean reward: 718.27
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 1.5153
    Episode_Reward/rotating_object: 141.3898
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.26s
                      Time elapsed: 00:33:20
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 43605 steps/s (collection: 2.142s, learning 0.113s)
             Mean action noise std: 2.79
          Mean value_function loss: 47.2101
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.2218
                       Mean reward: 722.76
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 1.5350
    Episode_Reward/rotating_object: 144.9306
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.25s
                      Time elapsed: 00:33:23
                               ETA: 00:24:48

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 43669 steps/s (collection: 2.138s, learning 0.113s)
             Mean action noise std: 2.79
          Mean value_function loss: 56.1658
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.2470
                       Mean reward: 728.08
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 1.5053
    Episode_Reward/rotating_object: 142.8649
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.25s
                      Time elapsed: 00:33:25
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 43572 steps/s (collection: 2.142s, learning 0.114s)
             Mean action noise std: 2.80
          Mean value_function loss: 47.6576
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.2757
                       Mean reward: 752.47
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 1.5111
    Episode_Reward/rotating_object: 145.3121
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.26s
                      Time elapsed: 00:33:27
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 43151 steps/s (collection: 2.155s, learning 0.123s)
             Mean action noise std: 2.80
          Mean value_function loss: 54.1214
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.2902
                       Mean reward: 711.20
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 1.5231
    Episode_Reward/rotating_object: 145.6172
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.28s
                      Time elapsed: 00:33:29
                               ETA: 00:24:41

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 43033 steps/s (collection: 2.167s, learning 0.117s)
             Mean action noise std: 2.80
          Mean value_function loss: 48.7000
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.3104
                       Mean reward: 721.24
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.5303
    Episode_Reward/rotating_object: 144.5802
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.28s
                      Time elapsed: 00:33:32
                               ETA: 00:24:39

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 42646 steps/s (collection: 2.190s, learning 0.115s)
             Mean action noise std: 2.80
          Mean value_function loss: 50.5269
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.3340
                       Mean reward: 737.98
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.5374
    Episode_Reward/rotating_object: 144.7809
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.31s
                      Time elapsed: 00:33:34
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 43282 steps/s (collection: 2.156s, learning 0.116s)
             Mean action noise std: 2.81
          Mean value_function loss: 54.6728
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.3507
                       Mean reward: 713.41
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.5300
    Episode_Reward/rotating_object: 144.0517
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.27s
                      Time elapsed: 00:33:36
                               ETA: 00:24:34

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 43164 steps/s (collection: 2.150s, learning 0.127s)
             Mean action noise std: 2.81
          Mean value_function loss: 56.6262
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.3643
                       Mean reward: 771.30
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 1.5159
    Episode_Reward/rotating_object: 144.0850
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.28s
                      Time elapsed: 00:33:39
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 42834 steps/s (collection: 2.180s, learning 0.115s)
             Mean action noise std: 2.81
          Mean value_function loss: 53.4051
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.3820
                       Mean reward: 715.93
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.5143
    Episode_Reward/rotating_object: 143.5052
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.29s
                      Time elapsed: 00:33:41
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 43306 steps/s (collection: 2.158s, learning 0.112s)
             Mean action noise std: 2.81
          Mean value_function loss: 46.7303
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.4025
                       Mean reward: 732.40
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 1.5478
    Episode_Reward/rotating_object: 146.3389
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.27s
                      Time elapsed: 00:33:43
                               ETA: 00:24:27

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 43419 steps/s (collection: 2.139s, learning 0.125s)
             Mean action noise std: 2.82
          Mean value_function loss: 49.7774
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.4256
                       Mean reward: 752.62
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.5177
    Episode_Reward/rotating_object: 143.9135
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.26s
                      Time elapsed: 00:33:45
                               ETA: 00:24:25

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 43255 steps/s (collection: 2.157s, learning 0.116s)
             Mean action noise std: 2.82
          Mean value_function loss: 48.6945
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.4441
                       Mean reward: 734.89
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.5047
    Episode_Reward/rotating_object: 142.9310
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.27s
                      Time elapsed: 00:33:48
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 43222 steps/s (collection: 2.162s, learning 0.112s)
             Mean action noise std: 2.82
          Mean value_function loss: 43.2703
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.4650
                       Mean reward: 734.28
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.5227
    Episode_Reward/rotating_object: 145.7795
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.27s
                      Time elapsed: 00:33:50
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 42671 steps/s (collection: 2.183s, learning 0.121s)
             Mean action noise std: 2.82
          Mean value_function loss: 47.5144
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 62.4903
                       Mean reward: 714.93
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.4988
    Episode_Reward/rotating_object: 141.3872
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.30s
                      Time elapsed: 00:33:52
                               ETA: 00:24:18

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 42910 steps/s (collection: 2.173s, learning 0.118s)
             Mean action noise std: 2.83
          Mean value_function loss: 46.3341
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.5172
                       Mean reward: 707.66
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.5405
    Episode_Reward/rotating_object: 147.5548
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.29s
                      Time elapsed: 00:33:54
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 42943 steps/s (collection: 2.174s, learning 0.115s)
             Mean action noise std: 2.83
          Mean value_function loss: 56.6925
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.5442
                       Mean reward: 731.58
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 1.5159
    Episode_Reward/rotating_object: 144.1733
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.29s
                      Time elapsed: 00:33:57
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 43316 steps/s (collection: 2.156s, learning 0.113s)
             Mean action noise std: 2.83
          Mean value_function loss: 45.8388
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.5747
                       Mean reward: 735.28
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.5262
    Episode_Reward/rotating_object: 145.2350
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.27s
                      Time elapsed: 00:33:59
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 43566 steps/s (collection: 2.124s, learning 0.133s)
             Mean action noise std: 2.84
          Mean value_function loss: 49.9700
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 62.6003
                       Mean reward: 730.75
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 1.5308
    Episode_Reward/rotating_object: 146.3397
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.26s
                      Time elapsed: 00:34:01
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 43795 steps/s (collection: 2.127s, learning 0.118s)
             Mean action noise std: 2.84
          Mean value_function loss: 51.0154
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.6250
                       Mean reward: 742.36
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 1.5336
    Episode_Reward/rotating_object: 145.1927
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.24s
                      Time elapsed: 00:34:04
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 43615 steps/s (collection: 2.136s, learning 0.118s)
             Mean action noise std: 2.84
          Mean value_function loss: 46.2122
               Mean surrogate loss: 0.0159
                 Mean entropy loss: 62.6456
                       Mean reward: 722.10
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.5297
    Episode_Reward/rotating_object: 145.7879
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.25s
                      Time elapsed: 00:34:06
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 42642 steps/s (collection: 2.186s, learning 0.120s)
             Mean action noise std: 2.84
          Mean value_function loss: 46.5484
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 62.6479
                       Mean reward: 729.63
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 145.8148
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.31s
                      Time elapsed: 00:34:08
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 43474 steps/s (collection: 2.148s, learning 0.113s)
             Mean action noise std: 2.84
          Mean value_function loss: 47.3371
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 62.6493
                       Mean reward: 726.44
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.5318
    Episode_Reward/rotating_object: 147.0362
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.26s
                      Time elapsed: 00:34:10
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 43028 steps/s (collection: 2.171s, learning 0.113s)
             Mean action noise std: 2.84
          Mean value_function loss: 47.4836
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.6546
                       Mean reward: 736.86
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.5445
    Episode_Reward/rotating_object: 149.3293
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.28s
                      Time elapsed: 00:34:13
                               ETA: 00:23:56

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 42704 steps/s (collection: 2.189s, learning 0.113s)
             Mean action noise std: 2.85
          Mean value_function loss: 49.8057
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.6731
                       Mean reward: 727.70
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.5500
    Episode_Reward/rotating_object: 147.4876
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.30s
                      Time elapsed: 00:34:15
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 43054 steps/s (collection: 2.169s, learning 0.114s)
             Mean action noise std: 2.85
          Mean value_function loss: 53.4136
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.7033
                       Mean reward: 729.60
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 1.5159
    Episode_Reward/rotating_object: 142.7066
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.28s
                      Time elapsed: 00:34:17
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 43194 steps/s (collection: 2.148s, learning 0.127s)
             Mean action noise std: 2.85
          Mean value_function loss: 47.8939
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.7248
                       Mean reward: 707.58
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 1.5462
    Episode_Reward/rotating_object: 144.9093
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.28s
                      Time elapsed: 00:34:20
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 43582 steps/s (collection: 2.142s, learning 0.114s)
             Mean action noise std: 2.85
          Mean value_function loss: 51.5141
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 62.7434
                       Mean reward: 746.88
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.5156
    Episode_Reward/rotating_object: 143.4375
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.26s
                      Time elapsed: 00:34:22
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 43020 steps/s (collection: 2.171s, learning 0.114s)
             Mean action noise std: 2.85
          Mean value_function loss: 50.6851
               Mean surrogate loss: 0.0047
                 Mean entropy loss: 62.7584
                       Mean reward: 721.62
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 1.5153
    Episode_Reward/rotating_object: 144.4488
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.29s
                      Time elapsed: 00:34:24
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 43049 steps/s (collection: 2.166s, learning 0.117s)
             Mean action noise std: 2.86
          Mean value_function loss: 44.0853
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 62.7607
                       Mean reward: 760.76
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.5447
    Episode_Reward/rotating_object: 149.9148
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.28s
                      Time elapsed: 00:34:26
                               ETA: 00:23:42

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 43009 steps/s (collection: 2.172s, learning 0.114s)
             Mean action noise std: 2.86
          Mean value_function loss: 49.7335
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.7682
                       Mean reward: 734.61
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 1.5125
    Episode_Reward/rotating_object: 145.4745
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.29s
                      Time elapsed: 00:34:29
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 43380 steps/s (collection: 2.150s, learning 0.116s)
             Mean action noise std: 2.86
          Mean value_function loss: 48.9592
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.7891
                       Mean reward: 716.23
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.5078
    Episode_Reward/rotating_object: 144.1904
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.27s
                      Time elapsed: 00:34:31
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 43268 steps/s (collection: 2.158s, learning 0.114s)
             Mean action noise std: 2.86
          Mean value_function loss: 44.9132
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.8138
                       Mean reward: 726.71
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.5002
    Episode_Reward/rotating_object: 146.1709
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.27s
                      Time elapsed: 00:34:33
                               ETA: 00:23:35

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 42951 steps/s (collection: 2.174s, learning 0.115s)
             Mean action noise std: 2.87
          Mean value_function loss: 51.7703
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.8351
                       Mean reward: 695.25
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.5079
    Episode_Reward/rotating_object: 145.6492
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.29s
                      Time elapsed: 00:34:35
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 42836 steps/s (collection: 2.181s, learning 0.114s)
             Mean action noise std: 2.87
          Mean value_function loss: 50.9749
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.8646
                       Mean reward: 745.35
               Mean episode length: 244.34
    Episode_Reward/reaching_object: 1.5136
    Episode_Reward/rotating_object: 147.2437
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.29s
                      Time elapsed: 00:34:38
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 42826 steps/s (collection: 2.182s, learning 0.113s)
             Mean action noise std: 2.87
          Mean value_function loss: 40.2059
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.8921
                       Mean reward: 740.14
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.5102
    Episode_Reward/rotating_object: 146.6640
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.30s
                      Time elapsed: 00:34:40
                               ETA: 00:23:28

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 43128 steps/s (collection: 2.162s, learning 0.117s)
             Mean action noise std: 2.87
          Mean value_function loss: 57.6604
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.9136
                       Mean reward: 699.58
               Mean episode length: 234.16
    Episode_Reward/reaching_object: 1.5209
    Episode_Reward/rotating_object: 145.0030
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.28s
                      Time elapsed: 00:34:42
                               ETA: 00:23:26

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 43451 steps/s (collection: 2.150s, learning 0.113s)
             Mean action noise std: 2.88
          Mean value_function loss: 52.1164
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 62.9299
                       Mean reward: 716.90
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.5244
    Episode_Reward/rotating_object: 145.7993
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.26s
                      Time elapsed: 00:34:45
                               ETA: 00:23:24

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 43166 steps/s (collection: 2.163s, learning 0.114s)
             Mean action noise std: 2.88
          Mean value_function loss: 55.2860
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.9496
                       Mean reward: 751.22
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 1.5219
    Episode_Reward/rotating_object: 147.7232
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.28s
                      Time elapsed: 00:34:47
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 43534 steps/s (collection: 2.144s, learning 0.114s)
             Mean action noise std: 2.88
          Mean value_function loss: 48.8387
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.9780
                       Mean reward: 730.10
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.5219
    Episode_Reward/rotating_object: 145.5041
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.26s
                      Time elapsed: 00:34:49
                               ETA: 00:23:19

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 43424 steps/s (collection: 2.141s, learning 0.123s)
             Mean action noise std: 2.89
          Mean value_function loss: 47.4639
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 63.0100
                       Mean reward: 737.32
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.5417
    Episode_Reward/rotating_object: 146.2279
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.26s
                      Time elapsed: 00:34:51
                               ETA: 00:23:16

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 43601 steps/s (collection: 2.142s, learning 0.113s)
             Mean action noise std: 2.89
          Mean value_function loss: 51.1100
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 63.0304
                       Mean reward: 743.45
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.5379
    Episode_Reward/rotating_object: 148.2031
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.25s
                      Time elapsed: 00:34:54
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 43743 steps/s (collection: 2.131s, learning 0.117s)
             Mean action noise std: 2.89
          Mean value_function loss: 44.5798
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.0452
                       Mean reward: 753.91
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.5461
    Episode_Reward/rotating_object: 145.6135
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.25s
                      Time elapsed: 00:34:56
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 43889 steps/s (collection: 2.127s, learning 0.113s)
             Mean action noise std: 2.89
          Mean value_function loss: 44.4271
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 63.0578
                       Mean reward: 728.06
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.5515
    Episode_Reward/rotating_object: 146.7456
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.24s
                      Time elapsed: 00:34:58
                               ETA: 00:23:09

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 43876 steps/s (collection: 2.127s, learning 0.113s)
             Mean action noise std: 2.89
          Mean value_function loss: 45.9298
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 63.0640
                       Mean reward: 721.42
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.5315
    Episode_Reward/rotating_object: 145.3298
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.24s
                      Time elapsed: 00:35:00
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 44090 steps/s (collection: 2.115s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 41.5580
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 63.0791
                       Mean reward: 751.79
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 1.5253
    Episode_Reward/rotating_object: 146.3848
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.23s
                      Time elapsed: 00:35:03
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 43942 steps/s (collection: 2.122s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 43.3382
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 63.0975
                       Mean reward: 740.22
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.5614
    Episode_Reward/rotating_object: 147.9684
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.24s
                      Time elapsed: 00:35:05
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 43555 steps/s (collection: 2.144s, learning 0.113s)
             Mean action noise std: 2.90
          Mean value_function loss: 56.0362
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 63.1125
                       Mean reward: 723.08
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 1.5195
    Episode_Reward/rotating_object: 144.8633
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.26s
                      Time elapsed: 00:35:07
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 42892 steps/s (collection: 2.176s, learning 0.116s)
             Mean action noise std: 2.90
          Mean value_function loss: 48.0906
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 63.1335
                       Mean reward: 758.99
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.5388
    Episode_Reward/rotating_object: 147.3591
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.29s
                      Time elapsed: 00:35:09
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 43596 steps/s (collection: 2.140s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 49.4551
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 63.1507
                       Mean reward: 718.19
               Mean episode length: 232.16
    Episode_Reward/reaching_object: 1.5037
    Episode_Reward/rotating_object: 143.9909
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.25s
                      Time elapsed: 00:35:12
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 43641 steps/s (collection: 2.137s, learning 0.116s)
             Mean action noise std: 2.91
          Mean value_function loss: 46.4764
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.1749
                       Mean reward: 738.93
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 1.5367
    Episode_Reward/rotating_object: 145.9187
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.25s
                      Time elapsed: 00:35:14
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 43821 steps/s (collection: 2.129s, learning 0.115s)
             Mean action noise std: 2.91
          Mean value_function loss: 55.1374
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.1952
                       Mean reward: 733.46
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 1.5424
    Episode_Reward/rotating_object: 147.6976
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.24s
                      Time elapsed: 00:35:16
                               ETA: 00:22:50

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 43177 steps/s (collection: 2.163s, learning 0.114s)
             Mean action noise std: 2.91
          Mean value_function loss: 53.2993
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 63.2149
                       Mean reward: 702.79
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 1.5253
    Episode_Reward/rotating_object: 143.6632
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.28s
                      Time elapsed: 00:35:18
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 43898 steps/s (collection: 2.127s, learning 0.112s)
             Mean action noise std: 2.91
          Mean value_function loss: 55.6404
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.2391
                       Mean reward: 728.14
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.5078
    Episode_Reward/rotating_object: 146.0354
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.24s
                      Time elapsed: 00:35:21
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 43537 steps/s (collection: 2.142s, learning 0.116s)
             Mean action noise std: 2.92
          Mean value_function loss: 53.9331
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.2599
                       Mean reward: 721.38
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.5237
    Episode_Reward/rotating_object: 146.3788
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.26s
                      Time elapsed: 00:35:23
                               ETA: 00:22:43

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 43538 steps/s (collection: 2.143s, learning 0.115s)
             Mean action noise std: 2.92
          Mean value_function loss: 48.4316
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.2725
                       Mean reward: 738.67
               Mean episode length: 243.89
    Episode_Reward/reaching_object: 1.5195
    Episode_Reward/rotating_object: 147.0414
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.26s
                      Time elapsed: 00:35:25
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 43124 steps/s (collection: 2.166s, learning 0.114s)
             Mean action noise std: 2.92
          Mean value_function loss: 45.8033
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 63.2836
                       Mean reward: 760.15
               Mean episode length: 246.27
    Episode_Reward/reaching_object: 1.5330
    Episode_Reward/rotating_object: 145.6951
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.28s
                      Time elapsed: 00:35:27
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 43754 steps/s (collection: 2.131s, learning 0.116s)
             Mean action noise std: 2.92
          Mean value_function loss: 48.3302
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.2970
                       Mean reward: 759.26
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 1.5333
    Episode_Reward/rotating_object: 146.8923
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.25s
                      Time elapsed: 00:35:30
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 43567 steps/s (collection: 2.145s, learning 0.112s)
             Mean action noise std: 2.92
          Mean value_function loss: 48.9631
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.3129
                       Mean reward: 759.73
               Mean episode length: 244.96
    Episode_Reward/reaching_object: 1.5232
    Episode_Reward/rotating_object: 146.0125
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.26s
                      Time elapsed: 00:35:32
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 43859 steps/s (collection: 2.128s, learning 0.113s)
             Mean action noise std: 2.93
          Mean value_function loss: 44.7705
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.3394
                       Mean reward: 738.11
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.5392
    Episode_Reward/rotating_object: 145.5094
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.24s
                      Time elapsed: 00:35:34
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 43631 steps/s (collection: 2.139s, learning 0.114s)
             Mean action noise std: 2.93
          Mean value_function loss: 45.4208
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 63.3635
                       Mean reward: 738.86
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.5255
    Episode_Reward/rotating_object: 144.2626
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.25s
                      Time elapsed: 00:35:36
                               ETA: 00:22:29

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 43923 steps/s (collection: 2.127s, learning 0.111s)
             Mean action noise std: 2.93
          Mean value_function loss: 56.1663
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.3843
                       Mean reward: 756.35
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.5326
    Episode_Reward/rotating_object: 146.2342
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.24s
                      Time elapsed: 00:35:39
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 44331 steps/s (collection: 2.106s, learning 0.112s)
             Mean action noise std: 2.94
          Mean value_function loss: 45.2949
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 63.4077
                       Mean reward: 746.48
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 1.5517
    Episode_Reward/rotating_object: 148.8771
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.22s
                      Time elapsed: 00:35:41
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 44069 steps/s (collection: 2.115s, learning 0.115s)
             Mean action noise std: 2.94
          Mean value_function loss: 42.1860
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 63.4272
                       Mean reward: 744.79
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.5330
    Episode_Reward/rotating_object: 147.7600
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.23s
                      Time elapsed: 00:35:43
                               ETA: 00:22:22

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 44037 steps/s (collection: 2.120s, learning 0.112s)
             Mean action noise std: 2.94
          Mean value_function loss: 41.2461
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.4418
                       Mean reward: 760.05
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 1.5488
    Episode_Reward/rotating_object: 148.4284
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.23s
                      Time elapsed: 00:35:45
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 43874 steps/s (collection: 2.129s, learning 0.112s)
             Mean action noise std: 2.94
          Mean value_function loss: 49.7362
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 63.4643
                       Mean reward: 737.91
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.5030
    Episode_Reward/rotating_object: 143.6296
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.24s
                      Time elapsed: 00:35:48
                               ETA: 00:22:17

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 43945 steps/s (collection: 2.124s, learning 0.113s)
             Mean action noise std: 2.95
          Mean value_function loss: 44.6342
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 63.4904
                       Mean reward: 756.23
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.5263
    Episode_Reward/rotating_object: 146.4033
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.24s
                      Time elapsed: 00:35:50
                               ETA: 00:22:15

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 43383 steps/s (collection: 2.146s, learning 0.120s)
             Mean action noise std: 2.95
          Mean value_function loss: 41.4430
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.5120
                       Mean reward: 715.75
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 1.5488
    Episode_Reward/rotating_object: 147.5589
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.27s
                      Time elapsed: 00:35:52
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 43497 steps/s (collection: 2.146s, learning 0.114s)
             Mean action noise std: 2.95
          Mean value_function loss: 43.8287
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 63.5267
                       Mean reward: 770.94
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 1.5589
    Episode_Reward/rotating_object: 149.0805
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.26s
                      Time elapsed: 00:35:54
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 43589 steps/s (collection: 2.140s, learning 0.115s)
             Mean action noise std: 2.95
          Mean value_function loss: 51.0309
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 63.5339
                       Mean reward: 749.80
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.5313
    Episode_Reward/rotating_object: 147.1698
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.26s
                      Time elapsed: 00:35:57
                               ETA: 00:22:08

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 43691 steps/s (collection: 2.135s, learning 0.115s)
             Mean action noise std: 2.95
          Mean value_function loss: 44.0665
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 63.5476
                       Mean reward: 750.36
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 1.5715
    Episode_Reward/rotating_object: 151.5124
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.25s
                      Time elapsed: 00:35:59
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 43775 steps/s (collection: 2.131s, learning 0.115s)
             Mean action noise std: 2.96
          Mean value_function loss: 52.9244
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.5670
                       Mean reward: 730.69
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 1.5183
    Episode_Reward/rotating_object: 144.1329
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.25s
                      Time elapsed: 00:36:01
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 43202 steps/s (collection: 2.162s, learning 0.113s)
             Mean action noise std: 2.96
          Mean value_function loss: 47.2757
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 63.5899
                       Mean reward: 731.94
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 1.5408
    Episode_Reward/rotating_object: 146.3790
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.28s
                      Time elapsed: 00:36:03
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 43422 steps/s (collection: 2.150s, learning 0.114s)
             Mean action noise std: 2.96
          Mean value_function loss: 45.8845
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.6088
                       Mean reward: 756.61
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 1.5185
    Episode_Reward/rotating_object: 146.0927
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.26s
                      Time elapsed: 00:36:06
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 43212 steps/s (collection: 2.158s, learning 0.117s)
             Mean action noise std: 2.96
          Mean value_function loss: 44.2246
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 63.6292
                       Mean reward: 766.33
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.5663
    Episode_Reward/rotating_object: 150.4418
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.27s
                      Time elapsed: 00:36:08
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 43608 steps/s (collection: 2.139s, learning 0.115s)
             Mean action noise std: 2.97
          Mean value_function loss: 37.0049
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.6521
                       Mean reward: 767.76
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 1.5566
    Episode_Reward/rotating_object: 150.2200
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.25s
                      Time elapsed: 00:36:10
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 43742 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 44.6229
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 63.6745
                       Mean reward: 780.97
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 1.5673
    Episode_Reward/rotating_object: 148.4248
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.25s
                      Time elapsed: 00:36:12
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 43723 steps/s (collection: 2.133s, learning 0.115s)
             Mean action noise std: 2.97
          Mean value_function loss: 48.9756
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.6993
                       Mean reward: 727.09
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.5403
    Episode_Reward/rotating_object: 149.2728
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.25s
                      Time elapsed: 00:36:15
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 43709 steps/s (collection: 2.133s, learning 0.116s)
             Mean action noise std: 2.98
          Mean value_function loss: 46.1569
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.7285
                       Mean reward: 751.82
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 1.5266
    Episode_Reward/rotating_object: 145.5825
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.25s
                      Time elapsed: 00:36:17
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 43692 steps/s (collection: 2.137s, learning 0.113s)
             Mean action noise std: 2.98
          Mean value_function loss: 45.5589
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 63.7442
                       Mean reward: 712.04
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.5187
    Episode_Reward/rotating_object: 143.7306
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.25s
                      Time elapsed: 00:36:19
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 43653 steps/s (collection: 2.137s, learning 0.115s)
             Mean action noise std: 2.98
          Mean value_function loss: 47.7557
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 63.7608
                       Mean reward: 729.03
               Mean episode length: 234.47
    Episode_Reward/reaching_object: 1.5489
    Episode_Reward/rotating_object: 148.6389
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.25s
                      Time elapsed: 00:36:21
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 43507 steps/s (collection: 2.143s, learning 0.116s)
             Mean action noise std: 2.98
          Mean value_function loss: 36.6722
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.7847
                       Mean reward: 757.75
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.5448
    Episode_Reward/rotating_object: 150.0179
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.26s
                      Time elapsed: 00:36:24
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 43475 steps/s (collection: 2.141s, learning 0.120s)
             Mean action noise std: 2.99
          Mean value_function loss: 56.0524
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 63.8060
                       Mean reward: 731.15
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.5353
    Episode_Reward/rotating_object: 146.2334
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.26s
                      Time elapsed: 00:36:26
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 43603 steps/s (collection: 2.142s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 46.8789
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 63.8305
                       Mean reward: 720.11
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 1.5422
    Episode_Reward/rotating_object: 147.4364
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.25s
                      Time elapsed: 00:36:28
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 43520 steps/s (collection: 2.133s, learning 0.126s)
             Mean action noise std: 2.99
          Mean value_function loss: 44.5727
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 63.8451
                       Mean reward: 786.19
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 1.5400
    Episode_Reward/rotating_object: 148.3072
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.26s
                      Time elapsed: 00:36:30
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 43910 steps/s (collection: 2.127s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 45.4347
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.8575
                       Mean reward: 755.88
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.5367
    Episode_Reward/rotating_object: 145.5435
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.24s
                      Time elapsed: 00:36:33
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 43949 steps/s (collection: 2.125s, learning 0.112s)
             Mean action noise std: 3.00
          Mean value_function loss: 48.2672
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.8737
                       Mean reward: 709.13
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.5534
    Episode_Reward/rotating_object: 148.3181
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.24s
                      Time elapsed: 00:36:35
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 44154 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 3.00
          Mean value_function loss: 32.9820
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 63.8859
                       Mean reward: 785.96
               Mean episode length: 249.27
    Episode_Reward/reaching_object: 1.5640
    Episode_Reward/rotating_object: 150.5347
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.23s
                      Time elapsed: 00:36:37
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 44279 steps/s (collection: 2.109s, learning 0.111s)
             Mean action noise std: 3.00
          Mean value_function loss: 40.7330
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 63.8891
                       Mean reward: 755.07
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.5463
    Episode_Reward/rotating_object: 148.1474
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.22s
                      Time elapsed: 00:36:39
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 44011 steps/s (collection: 2.106s, learning 0.127s)
             Mean action noise std: 3.00
          Mean value_function loss: 45.3702
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.8997
                       Mean reward: 764.59
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 1.5543
    Episode_Reward/rotating_object: 150.2226
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.23s
                      Time elapsed: 00:36:42
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 44061 steps/s (collection: 2.116s, learning 0.115s)
             Mean action noise std: 3.00
          Mean value_function loss: 42.8212
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.9243
                       Mean reward: 741.49
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.5294
    Episode_Reward/rotating_object: 146.8884
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.23s
                      Time elapsed: 00:36:44
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 43647 steps/s (collection: 2.130s, learning 0.123s)
             Mean action noise std: 3.01
          Mean value_function loss: 34.7002
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 63.9500
                       Mean reward: 751.00
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.5860
    Episode_Reward/rotating_object: 152.8750
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.25s
                      Time elapsed: 00:36:46
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 44049 steps/s (collection: 2.120s, learning 0.112s)
             Mean action noise std: 3.01
          Mean value_function loss: 40.5715
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 63.9739
                       Mean reward: 754.13
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.5512
    Episode_Reward/rotating_object: 147.3549
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.23s
                      Time elapsed: 00:36:48
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 43588 steps/s (collection: 2.138s, learning 0.117s)
             Mean action noise std: 3.01
          Mean value_function loss: 43.3241
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 63.9913
                       Mean reward: 752.51
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 1.5683
    Episode_Reward/rotating_object: 149.4452
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.26s
                      Time elapsed: 00:36:51
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 43851 steps/s (collection: 2.129s, learning 0.112s)
             Mean action noise std: 3.01
          Mean value_function loss: 46.7540
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 64.0049
                       Mean reward: 752.64
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.5404
    Episode_Reward/rotating_object: 148.7777
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.24s
                      Time elapsed: 00:36:53
                               ETA: 00:21:09

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 43380 steps/s (collection: 2.142s, learning 0.124s)
             Mean action noise std: 3.01
          Mean value_function loss: 39.4608
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 64.0208
                       Mean reward: 749.04
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 148.3291
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.27s
                      Time elapsed: 00:36:55
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 43036 steps/s (collection: 2.169s, learning 0.116s)
             Mean action noise std: 3.02
          Mean value_function loss: 51.6579
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 64.0371
                       Mean reward: 722.22
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.5424
    Episode_Reward/rotating_object: 149.0031
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.28s
                      Time elapsed: 00:36:57
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 43481 steps/s (collection: 2.143s, learning 0.118s)
             Mean action noise std: 3.02
          Mean value_function loss: 50.3973
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 64.0655
                       Mean reward: 724.11
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.5422
    Episode_Reward/rotating_object: 147.0709
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.26s
                      Time elapsed: 00:37:00
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 43573 steps/s (collection: 2.130s, learning 0.126s)
             Mean action noise std: 3.02
          Mean value_function loss: 45.6896
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.0864
                       Mean reward: 740.74
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.5388
    Episode_Reward/rotating_object: 146.0190
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.26s
                      Time elapsed: 00:37:02
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 43332 steps/s (collection: 2.146s, learning 0.123s)
             Mean action noise std: 3.03
          Mean value_function loss: 36.9523
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 64.1025
                       Mean reward: 766.05
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.5750
    Episode_Reward/rotating_object: 152.5895
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.27s
                      Time elapsed: 00:37:04
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 43713 steps/s (collection: 2.134s, learning 0.115s)
             Mean action noise std: 3.03
          Mean value_function loss: 48.8181
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 64.1165
                       Mean reward: 744.08
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 1.5175
    Episode_Reward/rotating_object: 145.5560
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.25s
                      Time elapsed: 00:37:06
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 43586 steps/s (collection: 2.139s, learning 0.116s)
             Mean action noise std: 3.03
          Mean value_function loss: 37.1209
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 64.1362
                       Mean reward: 738.39
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.5668
    Episode_Reward/rotating_object: 149.3983
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.26s
                      Time elapsed: 00:37:09
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 43827 steps/s (collection: 2.129s, learning 0.114s)
             Mean action noise std: 3.03
          Mean value_function loss: 36.3427
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.1549
                       Mean reward: 748.63
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.5492
    Episode_Reward/rotating_object: 149.0246
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.24s
                      Time elapsed: 00:37:11
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 43774 steps/s (collection: 2.133s, learning 0.113s)
             Mean action noise std: 3.03
          Mean value_function loss: 37.3641
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 64.1720
                       Mean reward: 744.42
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.5596
    Episode_Reward/rotating_object: 150.6435
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.25s
                      Time elapsed: 00:37:13
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 43287 steps/s (collection: 2.142s, learning 0.129s)
             Mean action noise std: 3.04
          Mean value_function loss: 56.8711
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 64.1871
                       Mean reward: 706.34
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 1.5104
    Episode_Reward/rotating_object: 145.5886
        Episode_Reward/action_rate: -0.0583
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.27s
                      Time elapsed: 00:37:15
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 43676 steps/s (collection: 2.139s, learning 0.112s)
             Mean action noise std: 3.04
          Mean value_function loss: 43.1186
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 64.2070
                       Mean reward: 750.42
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 1.5357
    Episode_Reward/rotating_object: 148.2479
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.25s
                      Time elapsed: 00:37:18
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 43944 steps/s (collection: 2.126s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 41.5374
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 64.2324
                       Mean reward: 750.18
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.5399
    Episode_Reward/rotating_object: 147.7155
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.24s
                      Time elapsed: 00:37:20
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 44117 steps/s (collection: 2.116s, learning 0.112s)
             Mean action noise std: 3.04
          Mean value_function loss: 47.2701
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.2435
                       Mean reward: 732.40
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 1.5441
    Episode_Reward/rotating_object: 147.7635
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.23s
                      Time elapsed: 00:37:22
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 44326 steps/s (collection: 2.106s, learning 0.112s)
             Mean action noise std: 3.04
          Mean value_function loss: 43.8134
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 64.2516
                       Mean reward: 745.04
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.5360
    Episode_Reward/rotating_object: 148.6185
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.22s
                      Time elapsed: 00:37:24
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 44027 steps/s (collection: 2.116s, learning 0.117s)
             Mean action noise std: 3.05
          Mean value_function loss: 52.3789
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 64.2664
                       Mean reward: 743.59
               Mean episode length: 238.12
    Episode_Reward/reaching_object: 1.5441
    Episode_Reward/rotating_object: 147.8883
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.23s
                      Time elapsed: 00:37:27
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 44278 steps/s (collection: 2.107s, learning 0.113s)
             Mean action noise std: 3.05
          Mean value_function loss: 38.8349
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 64.2881
                       Mean reward: 753.64
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 1.5627
    Episode_Reward/rotating_object: 150.5912
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.22s
                      Time elapsed: 00:37:29
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 43319 steps/s (collection: 2.157s, learning 0.112s)
             Mean action noise std: 3.05
          Mean value_function loss: 41.7156
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.3095
                       Mean reward: 771.18
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.5735
    Episode_Reward/rotating_object: 152.4141
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.27s
                      Time elapsed: 00:37:31
                               ETA: 00:20:28

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 43667 steps/s (collection: 2.135s, learning 0.117s)
             Mean action noise std: 3.06
          Mean value_function loss: 44.9523
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.3322
                       Mean reward: 746.29
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 1.5511
    Episode_Reward/rotating_object: 151.0244
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.25s
                      Time elapsed: 00:37:33
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 43585 steps/s (collection: 2.138s, learning 0.117s)
             Mean action noise std: 3.06
          Mean value_function loss: 41.5864
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 64.3581
                       Mean reward: 779.78
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 1.5510
    Episode_Reward/rotating_object: 151.4864
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.26s
                      Time elapsed: 00:37:36
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 43609 steps/s (collection: 2.138s, learning 0.116s)
             Mean action noise std: 3.06
          Mean value_function loss: 45.0742
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 64.3827
                       Mean reward: 756.01
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 1.5344
    Episode_Reward/rotating_object: 147.0888
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.25s
                      Time elapsed: 00:37:38
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 43786 steps/s (collection: 2.122s, learning 0.123s)
             Mean action noise std: 3.06
          Mean value_function loss: 38.6587
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 64.3930
                       Mean reward: 774.75
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 1.5352
    Episode_Reward/rotating_object: 147.7941
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.25s
                      Time elapsed: 00:37:40
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 43881 steps/s (collection: 2.128s, learning 0.112s)
             Mean action noise std: 3.07
          Mean value_function loss: 45.6417
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 64.4052
                       Mean reward: 757.84
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.5715
    Episode_Reward/rotating_object: 151.8953
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.24s
                      Time elapsed: 00:37:42
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 43673 steps/s (collection: 2.136s, learning 0.115s)
             Mean action noise std: 3.07
          Mean value_function loss: 41.5326
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 64.4307
                       Mean reward: 765.03
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.5467
    Episode_Reward/rotating_object: 149.7722
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.25s
                      Time elapsed: 00:37:45
                               ETA: 00:20:14

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 43889 steps/s (collection: 2.118s, learning 0.122s)
             Mean action noise std: 3.07
          Mean value_function loss: 38.7493
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 64.4582
                       Mean reward: 779.22
               Mean episode length: 249.12
    Episode_Reward/reaching_object: 1.5600
    Episode_Reward/rotating_object: 150.8615
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.24s
                      Time elapsed: 00:37:47
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 43644 steps/s (collection: 2.135s, learning 0.117s)
             Mean action noise std: 3.07
          Mean value_function loss: 46.2888
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 64.4823
                       Mean reward: 760.20
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 1.5417
    Episode_Reward/rotating_object: 148.7879
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.25s
                      Time elapsed: 00:37:49
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 43800 steps/s (collection: 2.127s, learning 0.118s)
             Mean action noise std: 3.08
          Mean value_function loss: 34.7844
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 64.5035
                       Mean reward: 762.01
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.5634
    Episode_Reward/rotating_object: 151.9710
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.24s
                      Time elapsed: 00:37:51
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 44110 steps/s (collection: 2.113s, learning 0.116s)
             Mean action noise std: 3.08
          Mean value_function loss: 48.8303
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 64.5201
                       Mean reward: 755.30
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 1.5233
    Episode_Reward/rotating_object: 146.6520
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.23s
                      Time elapsed: 00:37:54
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 44050 steps/s (collection: 2.117s, learning 0.115s)
             Mean action noise std: 3.08
          Mean value_function loss: 47.6631
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.5416
                       Mean reward: 747.08
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 1.5528
    Episode_Reward/rotating_object: 149.5346
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.23s
                      Time elapsed: 00:37:56
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 43820 steps/s (collection: 2.130s, learning 0.113s)
             Mean action noise std: 3.09
          Mean value_function loss: 47.6317
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 64.5715
                       Mean reward: 750.55
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.5463
    Episode_Reward/rotating_object: 149.5645
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.24s
                      Time elapsed: 00:37:58
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 43581 steps/s (collection: 2.141s, learning 0.114s)
             Mean action noise std: 3.09
          Mean value_function loss: 41.6086
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 64.5910
                       Mean reward: 768.44
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 1.5378
    Episode_Reward/rotating_object: 147.4990
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.26s
                      Time elapsed: 00:38:00
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 43402 steps/s (collection: 2.151s, learning 0.114s)
             Mean action noise std: 3.09
          Mean value_function loss: 44.6660
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 64.6112
                       Mean reward: 763.59
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.5482
    Episode_Reward/rotating_object: 151.2755
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.26s
                      Time elapsed: 00:38:03
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 43655 steps/s (collection: 2.136s, learning 0.116s)
             Mean action noise std: 3.09
          Mean value_function loss: 45.5807
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.6302
                       Mean reward: 737.41
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.5369
    Episode_Reward/rotating_object: 146.2748
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.25s
                      Time elapsed: 00:38:05
                               ETA: 00:19:53

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 43824 steps/s (collection: 2.132s, learning 0.111s)
             Mean action noise std: 3.10
          Mean value_function loss: 42.3528
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 64.6574
                       Mean reward: 760.96
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 1.5483
    Episode_Reward/rotating_object: 148.5282
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.24s
                      Time elapsed: 00:38:07
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 44103 steps/s (collection: 2.115s, learning 0.114s)
             Mean action noise std: 3.10
          Mean value_function loss: 52.6634
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.6801
                       Mean reward: 708.58
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.5320
    Episode_Reward/rotating_object: 147.4440
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.23s
                      Time elapsed: 00:38:09
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 44026 steps/s (collection: 2.107s, learning 0.126s)
             Mean action noise std: 3.10
          Mean value_function loss: 44.9104
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.7053
                       Mean reward: 740.19
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.5468
    Episode_Reward/rotating_object: 149.7473
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.23s
                      Time elapsed: 00:38:12
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 44432 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 3.10
          Mean value_function loss: 50.0819
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 64.7218
                       Mean reward: 746.37
               Mean episode length: 234.90
    Episode_Reward/reaching_object: 1.5448
    Episode_Reward/rotating_object: 149.5166
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.21s
                      Time elapsed: 00:38:14
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 44008 steps/s (collection: 2.111s, learning 0.123s)
             Mean action noise std: 3.11
          Mean value_function loss: 33.7696
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 64.7353
                       Mean reward: 776.56
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.5709
    Episode_Reward/rotating_object: 151.1759
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.23s
                      Time elapsed: 00:38:16
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 44241 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 3.11
          Mean value_function loss: 52.9508
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 64.7447
                       Mean reward: 724.28
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.5536
    Episode_Reward/rotating_object: 148.7939
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.22s
                      Time elapsed: 00:38:18
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 44670 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 3.11
          Mean value_function loss: 51.7742
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 64.7600
                       Mean reward: 772.91
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.5571
    Episode_Reward/rotating_object: 147.9058
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.20s
                      Time elapsed: 00:38:20
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 44389 steps/s (collection: 2.102s, learning 0.113s)
             Mean action noise std: 3.11
          Mean value_function loss: 45.9181
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 64.7917
                       Mean reward: 742.46
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.5523
    Episode_Reward/rotating_object: 149.5102
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.21s
                      Time elapsed: 00:38:23
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 43388 steps/s (collection: 2.154s, learning 0.112s)
             Mean action noise std: 3.12
          Mean value_function loss: 53.2302
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 64.8195
                       Mean reward: 731.52
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.5719
    Episode_Reward/rotating_object: 149.8139
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.27s
                      Time elapsed: 00:38:25
                               ETA: 00:19:32

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 44130 steps/s (collection: 2.115s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 40.7288
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 64.8403
                       Mean reward: 767.27
               Mean episode length: 244.66
    Episode_Reward/reaching_object: 1.5494
    Episode_Reward/rotating_object: 148.5475
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.23s
                      Time elapsed: 00:38:27
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 44141 steps/s (collection: 2.109s, learning 0.118s)
             Mean action noise std: 3.12
          Mean value_function loss: 51.4328
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.8659
                       Mean reward: 752.43
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 1.5676
    Episode_Reward/rotating_object: 149.1534
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.23s
                      Time elapsed: 00:38:29
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 44084 steps/s (collection: 2.117s, learning 0.113s)
             Mean action noise std: 3.13
          Mean value_function loss: 40.3613
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.8930
                       Mean reward: 762.54
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.5786
    Episode_Reward/rotating_object: 152.0239
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.23s
                      Time elapsed: 00:38:32
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 43613 steps/s (collection: 2.125s, learning 0.129s)
             Mean action noise std: 3.13
          Mean value_function loss: 42.2997
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.9079
                       Mean reward: 708.29
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.5655
    Episode_Reward/rotating_object: 147.6044
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.25s
                      Time elapsed: 00:38:34
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 44284 steps/s (collection: 2.106s, learning 0.113s)
             Mean action noise std: 3.13
          Mean value_function loss: 33.5397
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 64.9189
                       Mean reward: 757.72
               Mean episode length: 239.75
    Episode_Reward/reaching_object: 1.5675
    Episode_Reward/rotating_object: 151.4417
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.22s
                      Time elapsed: 00:38:36
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 44263 steps/s (collection: 2.106s, learning 0.115s)
             Mean action noise std: 3.13
          Mean value_function loss: 45.7937
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 64.9361
                       Mean reward: 769.62
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 1.5534
    Episode_Reward/rotating_object: 148.5606
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 2.22s
                      Time elapsed: 00:38:38
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 43825 steps/s (collection: 2.119s, learning 0.124s)
             Mean action noise std: 3.14
          Mean value_function loss: 44.2246
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 64.9529
                       Mean reward: 753.42
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.5526
    Episode_Reward/rotating_object: 146.6306
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 2.24s
                      Time elapsed: 00:38:40
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 42841 steps/s (collection: 2.180s, learning 0.114s)
             Mean action noise std: 3.14
          Mean value_function loss: 41.7634
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 64.9749
                       Mean reward: 767.63
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 1.5542
    Episode_Reward/rotating_object: 148.5519
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 2.29s
                      Time elapsed: 00:38:43
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 43910 steps/s (collection: 2.121s, learning 0.118s)
             Mean action noise std: 3.14
          Mean value_function loss: 41.5620
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.0000
                       Mean reward: 755.77
               Mean episode length: 242.58
    Episode_Reward/reaching_object: 1.5785
    Episode_Reward/rotating_object: 151.4817
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 2.24s
                      Time elapsed: 00:38:45
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 44246 steps/s (collection: 2.107s, learning 0.114s)
             Mean action noise std: 3.15
          Mean value_function loss: 46.4238
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 65.0273
                       Mean reward: 780.65
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 1.5607
    Episode_Reward/rotating_object: 150.2729
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 2.22s
                      Time elapsed: 00:38:47
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 43841 steps/s (collection: 2.125s, learning 0.117s)
             Mean action noise std: 3.15
          Mean value_function loss: 43.4916
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 65.0502
                       Mean reward: 754.30
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.5249
    Episode_Reward/rotating_object: 147.8648
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 2.24s
                      Time elapsed: 00:38:49
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 43810 steps/s (collection: 2.128s, learning 0.115s)
             Mean action noise std: 3.15
          Mean value_function loss: 48.1122
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 65.0686
                       Mean reward: 740.90
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.5530
    Episode_Reward/rotating_object: 149.5795
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 2.24s
                      Time elapsed: 00:38:52
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 43403 steps/s (collection: 2.137s, learning 0.128s)
             Mean action noise std: 3.15
          Mean value_function loss: 55.7689
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 65.0956
                       Mean reward: 706.50
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.5484
    Episode_Reward/rotating_object: 147.2753
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 2.26s
                      Time elapsed: 00:38:54
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 43747 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 3.16
          Mean value_function loss: 39.4258
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 65.1231
                       Mean reward: 747.69
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 1.5908
    Episode_Reward/rotating_object: 153.0653
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 2.25s
                      Time elapsed: 00:38:56
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 44210 steps/s (collection: 2.111s, learning 0.113s)
             Mean action noise std: 3.16
          Mean value_function loss: 39.7225
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.1434
                       Mean reward: 771.61
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 149.2033
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.22s
                      Time elapsed: 00:38:58
                               ETA: 00:18:57

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 44256 steps/s (collection: 2.109s, learning 0.112s)
             Mean action noise std: 3.16
          Mean value_function loss: 52.0433
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 65.1585
                       Mean reward: 767.49
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 1.5569
    Episode_Reward/rotating_object: 149.9299
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.22s
                      Time elapsed: 00:39:01
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 44244 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 3.16
          Mean value_function loss: 47.7406
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.1837
                       Mean reward: 775.61
               Mean episode length: 244.51
    Episode_Reward/reaching_object: 1.5525
    Episode_Reward/rotating_object: 148.8103
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.22s
                      Time elapsed: 00:39:03
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 44642 steps/s (collection: 2.090s, learning 0.112s)
             Mean action noise std: 3.17
          Mean value_function loss: 46.3104
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 65.2140
                       Mean reward: 744.11
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.5454
    Episode_Reward/rotating_object: 148.5475
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.20s
                      Time elapsed: 00:39:05
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 44467 steps/s (collection: 2.097s, learning 0.114s)
             Mean action noise std: 3.17
          Mean value_function loss: 46.7302
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.2339
                       Mean reward: 748.74
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.5361
    Episode_Reward/rotating_object: 149.4903
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.21s
                      Time elapsed: 00:39:07
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 44523 steps/s (collection: 2.096s, learning 0.112s)
             Mean action noise std: 3.17
          Mean value_function loss: 46.6665
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 65.2587
                       Mean reward: 783.96
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 1.5404
    Episode_Reward/rotating_object: 148.9328
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.21s
                      Time elapsed: 00:39:10
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 44134 steps/s (collection: 2.114s, learning 0.113s)
             Mean action noise std: 3.17
          Mean value_function loss: 50.3565
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 65.2715
                       Mean reward: 768.57
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 1.5417
    Episode_Reward/rotating_object: 148.5113
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.23s
                      Time elapsed: 00:39:12
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 44053 steps/s (collection: 2.116s, learning 0.116s)
             Mean action noise std: 3.18
          Mean value_function loss: 49.3142
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.2862
                       Mean reward: 771.29
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 149.1646
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.23s
                      Time elapsed: 00:39:14
                               ETA: 00:18:40

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 43744 steps/s (collection: 2.131s, learning 0.116s)
             Mean action noise std: 3.18
          Mean value_function loss: 44.3230
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 65.3056
                       Mean reward: 741.99
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 1.5347
    Episode_Reward/rotating_object: 147.2579
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.25s
                      Time elapsed: 00:39:16
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 44312 steps/s (collection: 2.100s, learning 0.118s)
             Mean action noise std: 3.18
          Mean value_function loss: 46.7440
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 65.3214
                       Mean reward: 701.23
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.5374
    Episode_Reward/rotating_object: 145.2660
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.22s
                      Time elapsed: 00:39:18
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 44216 steps/s (collection: 2.110s, learning 0.113s)
             Mean action noise std: 3.18
          Mean value_function loss: 42.1961
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 65.3395
                       Mean reward: 738.01
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 1.5606
    Episode_Reward/rotating_object: 149.0387
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.22s
                      Time elapsed: 00:39:21
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 43910 steps/s (collection: 2.126s, learning 0.113s)
             Mean action noise std: 3.19
          Mean value_function loss: 57.5703
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.3526
                       Mean reward: 727.70
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 1.5470
    Episode_Reward/rotating_object: 149.2005
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.24s
                      Time elapsed: 00:39:23
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 42813 steps/s (collection: 2.179s, learning 0.117s)
             Mean action noise std: 3.19
          Mean value_function loss: 47.5149
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 65.3677
                       Mean reward: 754.11
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.5762
    Episode_Reward/rotating_object: 150.7376
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.30s
                      Time elapsed: 00:39:25
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 43256 steps/s (collection: 2.160s, learning 0.113s)
             Mean action noise std: 3.19
          Mean value_function loss: 44.3407
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 65.3774
                       Mean reward: 763.26
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.5641
    Episode_Reward/rotating_object: 148.1915
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.27s
                      Time elapsed: 00:39:27
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 44032 steps/s (collection: 2.112s, learning 0.121s)
             Mean action noise std: 3.19
          Mean value_function loss: 58.8770
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 65.3881
                       Mean reward: 716.77
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 1.5372
    Episode_Reward/rotating_object: 146.3032
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.23s
                      Time elapsed: 00:39:30
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 43795 steps/s (collection: 2.133s, learning 0.112s)
             Mean action noise std: 3.19
          Mean value_function loss: 45.4582
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.4061
                       Mean reward: 763.22
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 1.5643
    Episode_Reward/rotating_object: 150.2637
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.24s
                      Time elapsed: 00:39:32
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 44323 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 3.20
          Mean value_function loss: 47.4751
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.4288
                       Mean reward: 744.45
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.5494
    Episode_Reward/rotating_object: 148.8895
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.22s
                      Time elapsed: 00:39:34
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 44182 steps/s (collection: 2.110s, learning 0.115s)
             Mean action noise std: 3.20
          Mean value_function loss: 44.6273
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 65.4469
                       Mean reward: 740.64
               Mean episode length: 242.27
    Episode_Reward/reaching_object: 1.5606
    Episode_Reward/rotating_object: 146.2170
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.22s
                      Time elapsed: 00:39:36
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 44207 steps/s (collection: 2.111s, learning 0.113s)
             Mean action noise std: 3.20
          Mean value_function loss: 43.4925
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 65.4570
                       Mean reward: 776.18
               Mean episode length: 242.00
    Episode_Reward/reaching_object: 1.5534
    Episode_Reward/rotating_object: 148.6529
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.22s
                      Time elapsed: 00:39:39
                               ETA: 00:18:14

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 43684 steps/s (collection: 2.135s, learning 0.115s)
             Mean action noise std: 3.20
          Mean value_function loss: 56.9692
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.4687
                       Mean reward: 762.39
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.5341
    Episode_Reward/rotating_object: 147.3023
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.25s
                      Time elapsed: 00:39:41
                               ETA: 00:18:12

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 43610 steps/s (collection: 2.139s, learning 0.115s)
             Mean action noise std: 3.21
          Mean value_function loss: 44.4854
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 65.4899
                       Mean reward: 782.23
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 1.5699
    Episode_Reward/rotating_object: 151.4314
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.25s
                      Time elapsed: 00:39:43
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 44256 steps/s (collection: 2.110s, learning 0.111s)
             Mean action noise std: 3.21
          Mean value_function loss: 47.3414
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.5117
                       Mean reward: 737.21
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.5550
    Episode_Reward/rotating_object: 148.7903
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.22s
                      Time elapsed: 00:39:45
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 44665 steps/s (collection: 2.089s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 45.5772
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.5338
                       Mean reward: 775.60
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 1.5334
    Episode_Reward/rotating_object: 150.1516
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.20s
                      Time elapsed: 00:39:48
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 44037 steps/s (collection: 2.120s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 40.8376
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.5492
                       Mean reward: 740.69
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 1.5643
    Episode_Reward/rotating_object: 151.2030
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.23s
                      Time elapsed: 00:39:50
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 44586 steps/s (collection: 2.093s, learning 0.112s)
             Mean action noise std: 3.22
          Mean value_function loss: 36.6689
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 65.5658
                       Mean reward: 784.28
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.5700
    Episode_Reward/rotating_object: 151.6035
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.20s
                      Time elapsed: 00:39:52
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 44360 steps/s (collection: 2.104s, learning 0.112s)
             Mean action noise std: 3.22
          Mean value_function loss: 40.9983
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 65.5832
                       Mean reward: 757.42
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.5689
    Episode_Reward/rotating_object: 151.5088
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.22s
                      Time elapsed: 00:39:54
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 44236 steps/s (collection: 2.106s, learning 0.116s)
             Mean action noise std: 3.22
          Mean value_function loss: 51.7562
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 65.5937
                       Mean reward: 768.75
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.5532
    Episode_Reward/rotating_object: 148.7509
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.22s
                      Time elapsed: 00:39:56
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 44445 steps/s (collection: 2.100s, learning 0.112s)
             Mean action noise std: 3.22
          Mean value_function loss: 50.7420
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.6082
                       Mean reward: 757.20
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 1.5426
    Episode_Reward/rotating_object: 146.7345
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.21s
                      Time elapsed: 00:39:59
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 43727 steps/s (collection: 2.134s, learning 0.114s)
             Mean action noise std: 3.23
          Mean value_function loss: 46.6730
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 65.6354
                       Mean reward: 734.75
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.5472
    Episode_Reward/rotating_object: 148.5534
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.25s
                      Time elapsed: 00:40:01
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 44070 steps/s (collection: 2.115s, learning 0.115s)
             Mean action noise std: 3.23
          Mean value_function loss: 41.4661
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 65.6611
                       Mean reward: 738.84
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 1.5700
    Episode_Reward/rotating_object: 152.8073
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.23s
                      Time elapsed: 00:40:03
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 43905 steps/s (collection: 2.126s, learning 0.113s)
             Mean action noise std: 3.23
          Mean value_function loss: 36.9419
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 65.6777
                       Mean reward: 769.64
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 1.5815
    Episode_Reward/rotating_object: 153.2012
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.24s
                      Time elapsed: 00:40:05
                               ETA: 00:17:46

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 44134 steps/s (collection: 2.112s, learning 0.115s)
             Mean action noise std: 3.23
          Mean value_function loss: 42.5547
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 65.6923
                       Mean reward: 753.37
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 1.5433
    Episode_Reward/rotating_object: 148.2245
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.23s
                      Time elapsed: 00:40:08
                               ETA: 00:17:44

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 43541 steps/s (collection: 2.143s, learning 0.115s)
             Mean action noise std: 3.24
          Mean value_function loss: 39.9621
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 65.7138
                       Mean reward: 794.68
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.5682
    Episode_Reward/rotating_object: 152.4866
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.26s
                      Time elapsed: 00:40:10
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 43683 steps/s (collection: 2.136s, learning 0.115s)
             Mean action noise std: 3.24
          Mean value_function loss: 58.0276
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 65.7235
                       Mean reward: 719.99
               Mean episode length: 228.00
    Episode_Reward/reaching_object: 1.5388
    Episode_Reward/rotating_object: 148.9428
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.25s
                      Time elapsed: 00:40:12
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 43711 steps/s (collection: 2.134s, learning 0.115s)
             Mean action noise std: 3.24
          Mean value_function loss: 36.6482
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 65.7336
                       Mean reward: 747.98
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 147.9365
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.25s
                      Time elapsed: 00:40:14
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 43392 steps/s (collection: 2.143s, learning 0.122s)
             Mean action noise std: 3.24
          Mean value_function loss: 39.8698
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 65.7487
                       Mean reward: 780.74
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 1.5743
    Episode_Reward/rotating_object: 152.3146
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.27s
                      Time elapsed: 00:40:17
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 44031 steps/s (collection: 2.119s, learning 0.114s)
             Mean action noise std: 3.24
          Mean value_function loss: 48.6770
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 65.7705
                       Mean reward: 726.72
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.5583
    Episode_Reward/rotating_object: 152.2126
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.23s
                      Time elapsed: 00:40:19
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 43759 steps/s (collection: 2.133s, learning 0.114s)
             Mean action noise std: 3.25
          Mean value_function loss: 52.0090
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.7889
                       Mean reward: 774.85
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 1.5748
    Episode_Reward/rotating_object: 151.8994
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.25s
                      Time elapsed: 00:40:21
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 43822 steps/s (collection: 2.131s, learning 0.112s)
             Mean action noise std: 3.25
          Mean value_function loss: 55.6054
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.8108
                       Mean reward: 747.29
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.5356
    Episode_Reward/rotating_object: 149.3011
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.24s
                      Time elapsed: 00:40:23
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 43752 steps/s (collection: 2.134s, learning 0.112s)
             Mean action noise std: 3.25
          Mean value_function loss: 49.1539
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 65.8325
                       Mean reward: 754.75
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 1.5344
    Episode_Reward/rotating_object: 148.5820
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.25s
                      Time elapsed: 00:40:26
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 43612 steps/s (collection: 2.138s, learning 0.116s)
             Mean action noise std: 3.25
          Mean value_function loss: 40.7512
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.8421
                       Mean reward: 768.25
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 151.4273
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.25s
                      Time elapsed: 00:40:28
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 43133 steps/s (collection: 2.152s, learning 0.127s)
             Mean action noise std: 3.26
          Mean value_function loss: 49.2984
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.8569
                       Mean reward: 743.16
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.5453
    Episode_Reward/rotating_object: 148.8275
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.28s
                      Time elapsed: 00:40:30
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 42845 steps/s (collection: 2.180s, learning 0.114s)
             Mean action noise std: 3.26
          Mean value_function loss: 47.3750
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.8803
                       Mean reward: 773.69
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.5759
    Episode_Reward/rotating_object: 152.4626
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.29s
                      Time elapsed: 00:40:32
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 43297 steps/s (collection: 2.157s, learning 0.113s)
             Mean action noise std: 3.26
          Mean value_function loss: 43.7431
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.9054
                       Mean reward: 776.54
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.5913
    Episode_Reward/rotating_object: 152.5878
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.27s
                      Time elapsed: 00:40:35
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 43744 steps/s (collection: 2.133s, learning 0.114s)
             Mean action noise std: 3.26
          Mean value_function loss: 44.1592
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.9212
                       Mean reward: 772.80
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 1.5800
    Episode_Reward/rotating_object: 151.9731
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.25s
                      Time elapsed: 00:40:37
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 43853 steps/s (collection: 2.127s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 47.0731
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.9368
                       Mean reward: 726.52
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 1.5515
    Episode_Reward/rotating_object: 146.6801
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.24s
                      Time elapsed: 00:40:39
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 43609 steps/s (collection: 2.140s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 43.5834
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 65.9554
                       Mean reward: 773.35
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 1.5839
    Episode_Reward/rotating_object: 149.0084
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.25s
                      Time elapsed: 00:40:41
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 43672 steps/s (collection: 2.137s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 48.9939
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 65.9723
                       Mean reward: 745.63
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.5803
    Episode_Reward/rotating_object: 150.4553
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.25s
                      Time elapsed: 00:40:44
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 43937 steps/s (collection: 2.123s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 40.1171
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.9837
                       Mean reward: 755.30
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.5968
    Episode_Reward/rotating_object: 151.2639
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.24s
                      Time elapsed: 00:40:46
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 43539 steps/s (collection: 2.143s, learning 0.115s)
             Mean action noise std: 3.27
          Mean value_function loss: 39.0336
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 65.9950
                       Mean reward: 736.74
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.5914
    Episode_Reward/rotating_object: 147.3845
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.26s
                      Time elapsed: 00:40:48
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 42944 steps/s (collection: 2.172s, learning 0.117s)
             Mean action noise std: 3.28
          Mean value_function loss: 38.4664
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.0031
                       Mean reward: 772.96
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 1.6036
    Episode_Reward/rotating_object: 152.7902
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.29s
                      Time elapsed: 00:40:50
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 43792 steps/s (collection: 2.132s, learning 0.113s)
             Mean action noise std: 3.28
          Mean value_function loss: 40.3934
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 66.0099
                       Mean reward: 767.53
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.5969
    Episode_Reward/rotating_object: 151.7149
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.24s
                      Time elapsed: 00:40:53
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 42917 steps/s (collection: 2.170s, learning 0.121s)
             Mean action noise std: 3.28
          Mean value_function loss: 31.6474
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.0175
                       Mean reward: 770.16
               Mean episode length: 247.00
    Episode_Reward/reaching_object: 1.5984
    Episode_Reward/rotating_object: 152.6449
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.29s
                      Time elapsed: 00:40:55
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 42959 steps/s (collection: 2.165s, learning 0.123s)
             Mean action noise std: 3.28
          Mean value_function loss: 44.2978
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 66.0287
                       Mean reward: 756.67
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.5813
    Episode_Reward/rotating_object: 152.4008
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.29s
                      Time elapsed: 00:40:57
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 43567 steps/s (collection: 2.131s, learning 0.125s)
             Mean action noise std: 3.28
          Mean value_function loss: 47.4921
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 66.0484
                       Mean reward: 735.61
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 1.5627
    Episode_Reward/rotating_object: 149.7807
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.26s
                      Time elapsed: 00:41:00
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 43606 steps/s (collection: 2.139s, learning 0.115s)
             Mean action noise std: 3.29
          Mean value_function loss: 40.3598
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 66.0691
                       Mean reward: 770.53
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.5781
    Episode_Reward/rotating_object: 150.6578
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.25s
                      Time elapsed: 00:41:02
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 43163 steps/s (collection: 2.163s, learning 0.115s)
             Mean action noise std: 3.29
          Mean value_function loss: 50.2317
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 66.0919
                       Mean reward: 764.28
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.5759
    Episode_Reward/rotating_object: 150.6976
        Episode_Reward/action_rate: -0.0682
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.28s
                      Time elapsed: 00:41:04
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 42484 steps/s (collection: 2.194s, learning 0.120s)
             Mean action noise std: 3.29
          Mean value_function loss: 49.3843
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.1065
                       Mean reward: 706.53
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.5686
    Episode_Reward/rotating_object: 149.5872
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.31s
                      Time elapsed: 00:41:06
                               ETA: 00:16:43

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 43861 steps/s (collection: 2.125s, learning 0.116s)
             Mean action noise std: 3.29
          Mean value_function loss: 48.8945
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 66.1286
                       Mean reward: 755.61
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.5704
    Episode_Reward/rotating_object: 150.8254
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.24s
                      Time elapsed: 00:41:09
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 43654 steps/s (collection: 2.137s, learning 0.115s)
             Mean action noise std: 3.30
          Mean value_function loss: 42.6610
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 66.1497
                       Mean reward: 771.61
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 1.5830
    Episode_Reward/rotating_object: 151.0025
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.25s
                      Time elapsed: 00:41:11
                               ETA: 00:16:38

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 43443 steps/s (collection: 2.148s, learning 0.115s)
             Mean action noise std: 3.30
          Mean value_function loss: 45.3359
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 66.1677
                       Mean reward: 788.81
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 1.5838
    Episode_Reward/rotating_object: 151.4155
        Episode_Reward/action_rate: -0.0688
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.26s
                      Time elapsed: 00:41:13
                               ETA: 00:16:36

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 43111 steps/s (collection: 2.165s, learning 0.115s)
             Mean action noise std: 3.30
          Mean value_function loss: 38.2511
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.1859
                       Mean reward: 781.27
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.5805
    Episode_Reward/rotating_object: 151.2930
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.28s
                      Time elapsed: 00:41:15
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 43632 steps/s (collection: 2.141s, learning 0.112s)
             Mean action noise std: 3.31
          Mean value_function loss: 55.1789
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 66.2047
                       Mean reward: 791.23
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 1.5658
    Episode_Reward/rotating_object: 149.6717
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.25s
                      Time elapsed: 00:41:18
                               ETA: 00:16:31

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 43295 steps/s (collection: 2.144s, learning 0.127s)
             Mean action noise std: 3.31
          Mean value_function loss: 48.5651
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 66.2272
                       Mean reward: 769.97
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.6004
    Episode_Reward/rotating_object: 153.0383
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.27s
                      Time elapsed: 00:41:20
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 43463 steps/s (collection: 2.150s, learning 0.112s)
             Mean action noise std: 3.31
          Mean value_function loss: 29.3569
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 66.2433
                       Mean reward: 799.13
               Mean episode length: 248.60
    Episode_Reward/reaching_object: 1.5872
    Episode_Reward/rotating_object: 152.7127
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.26s
                      Time elapsed: 00:41:22
                               ETA: 00:16:27

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 44369 steps/s (collection: 2.103s, learning 0.113s)
             Mean action noise std: 3.31
          Mean value_function loss: 32.3360
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 66.2548
                       Mean reward: 783.92
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 1.6069
    Episode_Reward/rotating_object: 153.0138
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.22s
                      Time elapsed: 00:41:24
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 44371 steps/s (collection: 2.104s, learning 0.112s)
             Mean action noise std: 3.32
          Mean value_function loss: 41.5911
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.2719
                       Mean reward: 743.25
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 1.5678
    Episode_Reward/rotating_object: 149.2435
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.22s
                      Time elapsed: 00:41:27
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 44567 steps/s (collection: 2.093s, learning 0.113s)
             Mean action noise std: 3.32
          Mean value_function loss: 49.3728
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 66.2917
                       Mean reward: 746.32
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.5752
    Episode_Reward/rotating_object: 150.9124
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.21s
                      Time elapsed: 00:41:29
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 44529 steps/s (collection: 2.081s, learning 0.127s)
             Mean action noise std: 3.32
          Mean value_function loss: 39.7260
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.3100
                       Mean reward: 744.09
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 1.5732
    Episode_Reward/rotating_object: 151.7559
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.21s
                      Time elapsed: 00:41:31
                               ETA: 00:16:17

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 44535 steps/s (collection: 2.096s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 42.5649
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 66.3311
                       Mean reward: 790.28
               Mean episode length: 244.65
    Episode_Reward/reaching_object: 1.5740
    Episode_Reward/rotating_object: 150.1375
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.21s
                      Time elapsed: 00:41:33
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 44332 steps/s (collection: 2.103s, learning 0.114s)
             Mean action noise std: 3.32
          Mean value_function loss: 44.3570
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 66.3421
                       Mean reward: 794.47
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 1.5752
    Episode_Reward/rotating_object: 152.2516
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.22s
                      Time elapsed: 00:41:35
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 44256 steps/s (collection: 2.105s, learning 0.116s)
             Mean action noise std: 3.33
          Mean value_function loss: 46.6836
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.3564
                       Mean reward: 751.25
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.5759
    Episode_Reward/rotating_object: 150.5096
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.22s
                      Time elapsed: 00:41:38
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 43263 steps/s (collection: 2.144s, learning 0.128s)
             Mean action noise std: 3.33
          Mean value_function loss: 46.2478
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 66.3818
                       Mean reward: 747.20
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 1.5689
    Episode_Reward/rotating_object: 151.5840
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.27s
                      Time elapsed: 00:41:40
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 43597 steps/s (collection: 2.132s, learning 0.123s)
             Mean action noise std: 3.33
          Mean value_function loss: 47.6226
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 66.4069
                       Mean reward: 759.62
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.5785
    Episode_Reward/rotating_object: 150.1467
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.25s
                      Time elapsed: 00:41:42
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 43610 steps/s (collection: 2.143s, learning 0.111s)
             Mean action noise std: 3.34
          Mean value_function loss: 48.6310
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 66.4257
                       Mean reward: 762.18
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.5758
    Episode_Reward/rotating_object: 152.5879
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.25s
                      Time elapsed: 00:41:44
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 43333 steps/s (collection: 2.140s, learning 0.128s)
             Mean action noise std: 3.34
          Mean value_function loss: 47.0508
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 66.4431
                       Mean reward: 763.28
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.5723
    Episode_Reward/rotating_object: 149.7699
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.27s
                      Time elapsed: 00:41:47
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 44455 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 3.34
          Mean value_function loss: 40.7385
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 66.4533
                       Mean reward: 776.63
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.5660
    Episode_Reward/rotating_object: 150.9750
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.21s
                      Time elapsed: 00:41:49
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 44143 steps/s (collection: 2.114s, learning 0.113s)
             Mean action noise std: 3.34
          Mean value_function loss: 46.5849
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 66.4660
                       Mean reward: 764.85
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.5661
    Episode_Reward/rotating_object: 150.0759
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.23s
                      Time elapsed: 00:41:51
                               ETA: 00:15:56

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 44169 steps/s (collection: 2.112s, learning 0.113s)
             Mean action noise std: 3.35
          Mean value_function loss: 38.2104
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 66.4873
                       Mean reward: 757.23
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.5914
    Episode_Reward/rotating_object: 152.3309
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.23s
                      Time elapsed: 00:41:53
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 43286 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 3.35
          Mean value_function loss: 32.1245
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 66.5084
                       Mean reward: 799.73
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.6134
    Episode_Reward/rotating_object: 154.2501
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.27s
                      Time elapsed: 00:41:56
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 44049 steps/s (collection: 2.118s, learning 0.113s)
             Mean action noise std: 3.35
          Mean value_function loss: 43.6224
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 66.5242
                       Mean reward: 777.36
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 1.5912
    Episode_Reward/rotating_object: 149.6271
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.23s
                      Time elapsed: 00:41:58
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 43402 steps/s (collection: 2.146s, learning 0.118s)
             Mean action noise std: 3.35
          Mean value_function loss: 41.2086
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 66.5469
                       Mean reward: 787.14
               Mean episode length: 246.76
    Episode_Reward/reaching_object: 1.5988
    Episode_Reward/rotating_object: 153.2020
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.26s
                      Time elapsed: 00:42:00
                               ETA: 00:15:47

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 43954 steps/s (collection: 2.121s, learning 0.116s)
             Mean action noise std: 3.36
          Mean value_function loss: 54.0645
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 66.5783
                       Mean reward: 742.86
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 1.5620
    Episode_Reward/rotating_object: 147.1029
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.24s
                      Time elapsed: 00:42:02
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 43352 steps/s (collection: 2.153s, learning 0.115s)
             Mean action noise std: 3.36
          Mean value_function loss: 41.7306
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 66.6059
                       Mean reward: 792.24
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.6104
    Episode_Reward/rotating_object: 152.5635
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.27s
                      Time elapsed: 00:42:05
                               ETA: 00:15:42

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 43766 steps/s (collection: 2.133s, learning 0.113s)
             Mean action noise std: 3.36
          Mean value_function loss: 49.9067
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 66.6266
                       Mean reward: 771.75
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.5953
    Episode_Reward/rotating_object: 151.2534
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.25s
                      Time elapsed: 00:42:07
                               ETA: 00:15:40

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 43932 steps/s (collection: 2.123s, learning 0.115s)
             Mean action noise std: 3.37
          Mean value_function loss: 39.9665
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 66.6488
                       Mean reward: 790.26
               Mean episode length: 246.88
    Episode_Reward/reaching_object: 1.6028
    Episode_Reward/rotating_object: 153.3606
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.24s
                      Time elapsed: 00:42:09
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 44100 steps/s (collection: 2.117s, learning 0.112s)
             Mean action noise std: 3.37
          Mean value_function loss: 42.9630
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 66.6652
                       Mean reward: 780.42
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.5906
    Episode_Reward/rotating_object: 151.5030
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.23s
                      Time elapsed: 00:42:11
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 44281 steps/s (collection: 2.108s, learning 0.112s)
             Mean action noise std: 3.37
          Mean value_function loss: 53.2772
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 66.6797
                       Mean reward: 784.53
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.5837
    Episode_Reward/rotating_object: 151.7047
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.22s
                      Time elapsed: 00:42:14
                               ETA: 00:15:33

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 44087 steps/s (collection: 2.106s, learning 0.124s)
             Mean action noise std: 3.37
          Mean value_function loss: 44.9810
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.7004
                       Mean reward: 764.11
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.5832
    Episode_Reward/rotating_object: 151.1808
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.23s
                      Time elapsed: 00:42:16
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 44169 steps/s (collection: 2.113s, learning 0.112s)
             Mean action noise std: 3.38
          Mean value_function loss: 41.5826
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 66.7252
                       Mean reward: 792.95
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.6218
    Episode_Reward/rotating_object: 154.1048
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.23s
                      Time elapsed: 00:42:18
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 44254 steps/s (collection: 2.109s, learning 0.112s)
             Mean action noise std: 3.38
          Mean value_function loss: 49.5336
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 66.7448
                       Mean reward: 772.58
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.5680
    Episode_Reward/rotating_object: 148.7536
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.22s
                      Time elapsed: 00:42:20
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 44159 steps/s (collection: 2.108s, learning 0.118s)
             Mean action noise std: 3.38
          Mean value_function loss: 48.8124
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 66.7588
                       Mean reward: 774.49
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 1.6152
    Episode_Reward/rotating_object: 153.3113
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.23s
                      Time elapsed: 00:42:23
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 44164 steps/s (collection: 2.102s, learning 0.124s)
             Mean action noise std: 3.38
          Mean value_function loss: 48.7889
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.7754
                       Mean reward: 717.23
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 1.5727
    Episode_Reward/rotating_object: 150.5409
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.23s
                      Time elapsed: 00:42:25
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 42009 steps/s (collection: 2.210s, learning 0.131s)
             Mean action noise std: 3.39
          Mean value_function loss: 39.5598
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 66.8013
                       Mean reward: 752.21
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 1.6108
    Episode_Reward/rotating_object: 151.6053
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.34s
                      Time elapsed: 00:42:27
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 43063 steps/s (collection: 2.167s, learning 0.116s)
             Mean action noise std: 3.39
          Mean value_function loss: 42.7199
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 66.8226
                       Mean reward: 771.21
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 1.5915
    Episode_Reward/rotating_object: 151.4447
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.28s
                      Time elapsed: 00:42:29
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 43784 steps/s (collection: 2.132s, learning 0.113s)
             Mean action noise std: 3.39
          Mean value_function loss: 56.0964
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.8399
                       Mean reward: 740.50
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 1.5856
    Episode_Reward/rotating_object: 150.4078
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.25s
                      Time elapsed: 00:42:32
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 43175 steps/s (collection: 2.162s, learning 0.115s)
             Mean action noise std: 3.40
          Mean value_function loss: 44.4986
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 66.8599
                       Mean reward: 766.78
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.5722
    Episode_Reward/rotating_object: 149.5248
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.28s
                      Time elapsed: 00:42:34
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 43836 steps/s (collection: 2.129s, learning 0.113s)
             Mean action noise std: 3.40
          Mean value_function loss: 41.5542
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 66.8724
                       Mean reward: 747.87
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.6163
    Episode_Reward/rotating_object: 151.9699
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.24s
                      Time elapsed: 00:42:36
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 43576 steps/s (collection: 2.142s, learning 0.114s)
             Mean action noise std: 3.40
          Mean value_function loss: 43.7672
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 66.8868
                       Mean reward: 758.13
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.6118
    Episode_Reward/rotating_object: 153.0489
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.26s
                      Time elapsed: 00:42:38
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 43540 steps/s (collection: 2.143s, learning 0.115s)
             Mean action noise std: 3.40
          Mean value_function loss: 50.3982
               Mean surrogate loss: 0.0359
                 Mean entropy loss: 66.9053
                       Mean reward: 759.83
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 1.5987
    Episode_Reward/rotating_object: 149.2766
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.26s
                      Time elapsed: 00:42:41
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 43802 steps/s (collection: 2.130s, learning 0.115s)
             Mean action noise std: 3.40
          Mean value_function loss: 31.3747
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 66.9074
                       Mean reward: 748.15
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 1.6038
    Episode_Reward/rotating_object: 150.9246
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.24s
                      Time elapsed: 00:42:43
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 43466 steps/s (collection: 2.148s, learning 0.113s)
             Mean action noise std: 3.40
          Mean value_function loss: 43.7553
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.9128
                       Mean reward: 761.66
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.5980
    Episode_Reward/rotating_object: 151.0701
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.26s
                      Time elapsed: 00:42:45
                               ETA: 00:15:00

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 43675 steps/s (collection: 2.118s, learning 0.132s)
             Mean action noise std: 3.41
          Mean value_function loss: 50.5738
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.9320
                       Mean reward: 749.38
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 1.5923
    Episode_Reward/rotating_object: 150.5377
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.25s
                      Time elapsed: 00:42:47
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 43901 steps/s (collection: 2.127s, learning 0.112s)
             Mean action noise std: 3.41
          Mean value_function loss: 44.3799
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 66.9522
                       Mean reward: 786.31
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.6316
    Episode_Reward/rotating_object: 154.0350
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.24s
                      Time elapsed: 00:42:50
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 44208 steps/s (collection: 2.109s, learning 0.115s)
             Mean action noise std: 3.41
          Mean value_function loss: 49.4020
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 66.9659
                       Mean reward: 754.97
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.6020
    Episode_Reward/rotating_object: 151.9950
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.22s
                      Time elapsed: 00:42:52
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 43705 steps/s (collection: 2.135s, learning 0.114s)
             Mean action noise std: 3.41
          Mean value_function loss: 57.6358
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 66.9831
                       Mean reward: 763.88
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 1.5920
    Episode_Reward/rotating_object: 148.9958
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.25s
                      Time elapsed: 00:42:54
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 43606 steps/s (collection: 2.142s, learning 0.112s)
             Mean action noise std: 3.42
          Mean value_function loss: 42.2349
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 67.0063
                       Mean reward: 754.25
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 1.5941
    Episode_Reward/rotating_object: 152.7954
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.25s
                      Time elapsed: 00:42:56
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 43685 steps/s (collection: 2.135s, learning 0.116s)
             Mean action noise std: 3.42
          Mean value_function loss: 45.1507
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.0176
                       Mean reward: 779.39
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.6024
    Episode_Reward/rotating_object: 151.8751
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.25s
                      Time elapsed: 00:42:59
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 43417 steps/s (collection: 2.147s, learning 0.117s)
             Mean action noise std: 3.42
          Mean value_function loss: 48.3433
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.0368
                       Mean reward: 761.77
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.5811
    Episode_Reward/rotating_object: 149.6293
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.26s
                      Time elapsed: 00:43:01
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 44340 steps/s (collection: 2.103s, learning 0.114s)
             Mean action noise std: 3.42
          Mean value_function loss: 56.2503
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 67.0603
                       Mean reward: 746.53
               Mean episode length: 236.51
    Episode_Reward/reaching_object: 1.5794
    Episode_Reward/rotating_object: 148.7218
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.22s
                      Time elapsed: 00:43:03
                               ETA: 00:14:41

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 44291 steps/s (collection: 2.106s, learning 0.113s)
             Mean action noise std: 3.43
          Mean value_function loss: 38.0830
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 67.0880
                       Mean reward: 776.04
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 1.6153
    Episode_Reward/rotating_object: 153.6935
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.22s
                      Time elapsed: 00:43:05
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 44860 steps/s (collection: 2.080s, learning 0.111s)
             Mean action noise std: 3.43
          Mean value_function loss: 47.6297
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 67.1134
                       Mean reward: 772.49
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.6020
    Episode_Reward/rotating_object: 152.2484
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.19s
                      Time elapsed: 00:43:07
                               ETA: 00:14:37

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 44557 steps/s (collection: 2.094s, learning 0.112s)
             Mean action noise std: 3.44
          Mean value_function loss: 62.0075
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 67.1363
                       Mean reward: 719.43
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.5857
    Episode_Reward/rotating_object: 147.5145
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.21s
                      Time elapsed: 00:43:10
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 44551 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 3.44
          Mean value_function loss: 45.6027
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 67.1536
                       Mean reward: 735.53
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.5853
    Episode_Reward/rotating_object: 148.5289
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.21s
                      Time elapsed: 00:43:12
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 44617 steps/s (collection: 2.091s, learning 0.112s)
             Mean action noise std: 3.44
          Mean value_function loss: 61.1480
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.1730
                       Mean reward: 759.52
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.5713
    Episode_Reward/rotating_object: 148.5278
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.20s
                      Time elapsed: 00:43:14
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 44095 steps/s (collection: 2.117s, learning 0.112s)
             Mean action noise std: 3.44
          Mean value_function loss: 47.0650
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 67.1963
                       Mean reward: 767.40
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 1.5810
    Episode_Reward/rotating_object: 151.3724
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.23s
                      Time elapsed: 00:43:16
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 44053 steps/s (collection: 2.116s, learning 0.116s)
             Mean action noise std: 3.44
          Mean value_function loss: 41.5677
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 67.2112
                       Mean reward: 776.15
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 1.6114
    Episode_Reward/rotating_object: 152.6583
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.23s
                      Time elapsed: 00:43:19
                               ETA: 00:14:25

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 43598 steps/s (collection: 2.142s, learning 0.113s)
             Mean action noise std: 3.45
          Mean value_function loss: 45.7478
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 67.2150
                       Mean reward: 756.33
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 1.6039
    Episode_Reward/rotating_object: 150.9392
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.25s
                      Time elapsed: 00:43:21
                               ETA: 00:14:23

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 44324 steps/s (collection: 2.103s, learning 0.115s)
             Mean action noise std: 3.45
          Mean value_function loss: 47.9098
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.2267
                       Mean reward: 726.94
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.5738
    Episode_Reward/rotating_object: 146.4414
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.22s
                      Time elapsed: 00:43:23
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 44362 steps/s (collection: 2.101s, learning 0.115s)
             Mean action noise std: 3.45
          Mean value_function loss: 40.3875
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 67.2454
                       Mean reward: 760.39
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.5957
    Episode_Reward/rotating_object: 149.8896
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.22s
                      Time elapsed: 00:43:25
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 44622 steps/s (collection: 2.087s, learning 0.116s)
             Mean action noise std: 3.45
          Mean value_function loss: 36.8864
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 67.2562
                       Mean reward: 782.08
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.6142
    Episode_Reward/rotating_object: 151.4941
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.20s
                      Time elapsed: 00:43:27
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 44197 steps/s (collection: 2.109s, learning 0.115s)
             Mean action noise std: 3.45
          Mean value_function loss: 48.9661
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.2663
                       Mean reward: 734.56
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.5915
    Episode_Reward/rotating_object: 150.1133
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.22s
                      Time elapsed: 00:43:30
                               ETA: 00:14:13

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 43783 steps/s (collection: 2.133s, learning 0.112s)
             Mean action noise std: 3.46
          Mean value_function loss: 42.3858
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 67.2850
                       Mean reward: 768.91
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 1.5854
    Episode_Reward/rotating_object: 146.9440
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.25s
                      Time elapsed: 00:43:32
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 43591 steps/s (collection: 2.137s, learning 0.118s)
             Mean action noise std: 3.46
          Mean value_function loss: 48.8765
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 67.3064
                       Mean reward: 756.52
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 1.6012
    Episode_Reward/rotating_object: 151.8197
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.26s
                      Time elapsed: 00:43:34
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 43977 steps/s (collection: 2.122s, learning 0.113s)
             Mean action noise std: 3.46
          Mean value_function loss: 48.4678
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 67.3248
                       Mean reward: 774.98
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.6076
    Episode_Reward/rotating_object: 150.6688
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.24s
                      Time elapsed: 00:43:36
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 44114 steps/s (collection: 2.116s, learning 0.112s)
             Mean action noise std: 3.46
          Mean value_function loss: 48.4020
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 67.3442
                       Mean reward: 753.12
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 1.6076
    Episode_Reward/rotating_object: 150.4070
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.23s
                      Time elapsed: 00:43:39
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 43656 steps/s (collection: 2.136s, learning 0.116s)
             Mean action noise std: 3.47
          Mean value_function loss: 44.4632
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.3601
                       Mean reward: 759.06
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.6167
    Episode_Reward/rotating_object: 151.2480
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.25s
                      Time elapsed: 00:43:41
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 43446 steps/s (collection: 2.149s, learning 0.114s)
             Mean action noise std: 3.47
          Mean value_function loss: 45.0259
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.3706
                       Mean reward: 728.99
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.5940
    Episode_Reward/rotating_object: 149.2952
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.26s
                      Time elapsed: 00:43:43
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 44145 steps/s (collection: 2.114s, learning 0.113s)
             Mean action noise std: 3.47
          Mean value_function loss: 37.2530
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 67.3872
                       Mean reward: 780.75
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.6180
    Episode_Reward/rotating_object: 151.8383
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.23s
                      Time elapsed: 00:43:45
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 44038 steps/s (collection: 2.118s, learning 0.115s)
             Mean action noise std: 3.47
          Mean value_function loss: 42.8535
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 67.4038
                       Mean reward: 784.68
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 1.6448
    Episode_Reward/rotating_object: 154.0723
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.23s
                      Time elapsed: 00:43:48
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 44193 steps/s (collection: 2.112s, learning 0.112s)
             Mean action noise std: 3.48
          Mean value_function loss: 47.3617
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.4228
                       Mean reward: 758.32
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.6086
    Episode_Reward/rotating_object: 149.6124
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.22s
                      Time elapsed: 00:43:50
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 44396 steps/s (collection: 2.100s, learning 0.114s)
             Mean action noise std: 3.48
          Mean value_function loss: 43.1011
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 67.4401
                       Mean reward: 751.51
               Mean episode length: 238.41
    Episode_Reward/reaching_object: 1.6172
    Episode_Reward/rotating_object: 151.5337
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.21s
                      Time elapsed: 00:43:52
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 44407 steps/s (collection: 2.102s, learning 0.112s)
             Mean action noise std: 3.48
          Mean value_function loss: 52.2826
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 67.4482
                       Mean reward: 778.46
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.5947
    Episode_Reward/rotating_object: 149.5004
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.21s
                      Time elapsed: 00:43:54
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 44526 steps/s (collection: 2.095s, learning 0.113s)
             Mean action noise std: 3.48
          Mean value_function loss: 50.0209
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 67.4568
                       Mean reward: 771.07
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.5888
    Episode_Reward/rotating_object: 148.6212
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.21s
                      Time elapsed: 00:43:56
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 44588 steps/s (collection: 2.091s, learning 0.114s)
             Mean action noise std: 3.48
          Mean value_function loss: 50.7255
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.4618
                       Mean reward: 769.86
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 1.5973
    Episode_Reward/rotating_object: 151.0107
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.20s
                      Time elapsed: 00:43:59
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 44424 steps/s (collection: 2.097s, learning 0.116s)
             Mean action noise std: 3.48
          Mean value_function loss: 47.4655
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.4747
                       Mean reward: 743.49
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.6111
    Episode_Reward/rotating_object: 153.5777
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.21s
                      Time elapsed: 00:44:01
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 43888 steps/s (collection: 2.121s, learning 0.118s)
             Mean action noise std: 3.48
          Mean value_function loss: 61.4649
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 67.4871
                       Mean reward: 771.93
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.5942
    Episode_Reward/rotating_object: 148.6546
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.24s
                      Time elapsed: 00:44:03
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 46331 steps/s (collection: 2.011s, learning 0.110s)
             Mean action noise std: 3.49
          Mean value_function loss: 47.8767
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.4988
                       Mean reward: 763.63
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 1.5745
    Episode_Reward/rotating_object: 148.2329
        Episode_Reward/action_rate: -0.0759
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.12s
                      Time elapsed: 00:44:05
                               ETA: 00:13:36

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 46806 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 3.49
          Mean value_function loss: 41.7793
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 67.5157
                       Mean reward: 800.93
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.5937
    Episode_Reward/rotating_object: 149.9033
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.10s
                      Time elapsed: 00:44:07
                               ETA: 00:13:34

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 46218 steps/s (collection: 2.017s, learning 0.110s)
             Mean action noise std: 3.49
          Mean value_function loss: 45.4894
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 67.5314
                       Mean reward: 733.36
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.5932
    Episode_Reward/rotating_object: 148.7773
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.13s
                      Time elapsed: 00:44:09
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 45626 steps/s (collection: 2.040s, learning 0.115s)
             Mean action noise std: 3.50
          Mean value_function loss: 51.2481
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 67.5541
                       Mean reward: 758.23
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.6035
    Episode_Reward/rotating_object: 151.9151
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.15s
                      Time elapsed: 00:44:12
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 46187 steps/s (collection: 2.013s, learning 0.115s)
             Mean action noise std: 3.50
          Mean value_function loss: 36.7146
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 67.5778
                       Mean reward: 802.58
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 1.5918
    Episode_Reward/rotating_object: 151.1758
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.13s
                      Time elapsed: 00:44:14
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 46140 steps/s (collection: 2.016s, learning 0.114s)
             Mean action noise std: 3.50
          Mean value_function loss: 53.4626
               Mean surrogate loss: 0.1662
                 Mean entropy loss: 67.5908
                       Mean reward: 751.40
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.6021
    Episode_Reward/rotating_object: 151.0606
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.13s
                      Time elapsed: 00:44:16
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 44337 steps/s (collection: 2.096s, learning 0.121s)
             Mean action noise std: 3.50
          Mean value_function loss: 73.2015
               Mean surrogate loss: 0.0066
                 Mean entropy loss: 67.5934
                       Mean reward: 753.15
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.5803
    Episode_Reward/rotating_object: 148.6252
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.22s
                      Time elapsed: 00:44:18
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 43345 steps/s (collection: 2.154s, learning 0.113s)
             Mean action noise std: 3.50
          Mean value_function loss: 75.6299
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 67.5945
                       Mean reward: 761.06
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 1.5967
    Episode_Reward/rotating_object: 151.2357
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.27s
                      Time elapsed: 00:44:20
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 43598 steps/s (collection: 2.143s, learning 0.112s)
             Mean action noise std: 3.50
          Mean value_function loss: 67.7663
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.5972
                       Mean reward: 762.41
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 1.5692
    Episode_Reward/rotating_object: 148.1447
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.25s
                      Time elapsed: 00:44:23
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 43596 steps/s (collection: 2.139s, learning 0.115s)
             Mean action noise std: 3.50
          Mean value_function loss: 68.5121
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.6072
                       Mean reward: 707.41
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.5760
    Episode_Reward/rotating_object: 146.5295
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.25s
                      Time elapsed: 00:44:25
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 43799 steps/s (collection: 2.132s, learning 0.112s)
             Mean action noise std: 3.50
          Mean value_function loss: 59.6328
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 67.6287
                       Mean reward: 735.29
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.5574
    Episode_Reward/rotating_object: 147.5483
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.24s
                      Time elapsed: 00:44:27
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 43821 steps/s (collection: 2.129s, learning 0.115s)
             Mean action noise std: 3.51
          Mean value_function loss: 56.2062
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.6420
                       Mean reward: 755.00
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.5650
    Episode_Reward/rotating_object: 148.4255
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.24s
                      Time elapsed: 00:44:29
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 43855 steps/s (collection: 2.127s, learning 0.115s)
             Mean action noise std: 3.51
          Mean value_function loss: 69.1262
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.6603
                       Mean reward: 743.06
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.5402
    Episode_Reward/rotating_object: 146.9087
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.24s
                      Time elapsed: 00:44:32
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 43796 steps/s (collection: 2.130s, learning 0.114s)
             Mean action noise std: 3.51
          Mean value_function loss: 70.2328
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 67.6748
                       Mean reward: 737.61
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.5324
    Episode_Reward/rotating_object: 143.6254
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.24s
                      Time elapsed: 00:44:34
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 43779 steps/s (collection: 2.134s, learning 0.112s)
             Mean action noise std: 3.51
          Mean value_function loss: 63.5291
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.6923
                       Mean reward: 762.57
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 1.5355
    Episode_Reward/rotating_object: 143.3240
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.25s
                      Time elapsed: 00:44:36
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 43954 steps/s (collection: 2.107s, learning 0.129s)
             Mean action noise std: 3.52
          Mean value_function loss: 44.5952
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 67.7108
                       Mean reward: 738.18
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 1.5807
    Episode_Reward/rotating_object: 145.1714
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.24s
                      Time elapsed: 00:44:38
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 44745 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 3.52
          Mean value_function loss: 47.7425
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.7193
                       Mean reward: 737.48
               Mean episode length: 247.52
    Episode_Reward/reaching_object: 1.5728
    Episode_Reward/rotating_object: 141.5097
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.20s
                      Time elapsed: 00:44:41
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 44538 steps/s (collection: 2.095s, learning 0.112s)
             Mean action noise std: 3.52
          Mean value_function loss: 49.4011
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 67.7398
                       Mean reward: 761.70
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.5602
    Episode_Reward/rotating_object: 144.1223
        Episode_Reward/action_rate: -0.0806
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.21s
                      Time elapsed: 00:44:43
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 44589 steps/s (collection: 2.092s, learning 0.113s)
             Mean action noise std: 3.52
          Mean value_function loss: 55.4875
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.7654
                       Mean reward: 726.34
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.5592
    Episode_Reward/rotating_object: 144.9842
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.20s
                      Time elapsed: 00:44:45
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 44723 steps/s (collection: 2.084s, learning 0.114s)
             Mean action noise std: 3.53
          Mean value_function loss: 57.5239
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 67.7901
                       Mean reward: 745.72
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.5589
    Episode_Reward/rotating_object: 145.4008
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.20s
                      Time elapsed: 00:44:47
                               ETA: 00:12:52

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 42953 steps/s (collection: 2.176s, learning 0.113s)
             Mean action noise std: 3.53
          Mean value_function loss: 56.4151
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 67.8143
                       Mean reward: 716.71
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.5164
    Episode_Reward/rotating_object: 144.4735
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.29s
                      Time elapsed: 00:44:49
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 44280 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 3.53
          Mean value_function loss: 60.6906
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 67.8346
                       Mean reward: 716.35
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.5427
    Episode_Reward/rotating_object: 144.6919
        Episode_Reward/action_rate: -0.0806
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.22s
                      Time elapsed: 00:44:52
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 44306 steps/s (collection: 2.100s, learning 0.119s)
             Mean action noise std: 3.54
          Mean value_function loss: 54.3017
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.8510
                       Mean reward: 762.72
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 1.5395
    Episode_Reward/rotating_object: 146.3655
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.22s
                      Time elapsed: 00:44:54
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 42881 steps/s (collection: 2.179s, learning 0.114s)
             Mean action noise std: 3.54
          Mean value_function loss: 46.0234
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.8740
                       Mean reward: 758.41
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.5321
    Episode_Reward/rotating_object: 145.8835
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.29s
                      Time elapsed: 00:44:56
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 44035 steps/s (collection: 2.116s, learning 0.116s)
             Mean action noise std: 3.54
          Mean value_function loss: 53.0531
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 67.8920
                       Mean reward: 753.93
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 147.9609
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.23s
                      Time elapsed: 00:44:58
                               ETA: 00:12:40

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 44193 steps/s (collection: 2.109s, learning 0.116s)
             Mean action noise std: 3.55
          Mean value_function loss: 43.7212
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 67.9162
                       Mean reward: 733.45
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.5248
    Episode_Reward/rotating_object: 146.1798
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.22s
                      Time elapsed: 00:45:01
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 44029 steps/s (collection: 2.120s, learning 0.113s)
             Mean action noise std: 3.55
          Mean value_function loss: 38.9603
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 67.9527
                       Mean reward: 740.66
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 1.5423
    Episode_Reward/rotating_object: 148.0840
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.23s
                      Time elapsed: 00:45:03
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 44366 steps/s (collection: 2.099s, learning 0.116s)
             Mean action noise std: 3.55
          Mean value_function loss: 49.0862
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 67.9689
                       Mean reward: 728.39
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.5231
    Episode_Reward/rotating_object: 146.0504
        Episode_Reward/action_rate: -0.0797
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.22s
                      Time elapsed: 00:45:05
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 43902 steps/s (collection: 2.126s, learning 0.113s)
             Mean action noise std: 3.55
          Mean value_function loss: 39.7004
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.9861
                       Mean reward: 757.28
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 1.5429
    Episode_Reward/rotating_object: 147.6810
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.24s
                      Time elapsed: 00:45:07
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 43999 steps/s (collection: 2.118s, learning 0.116s)
             Mean action noise std: 3.56
          Mean value_function loss: 47.9686
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 68.0103
                       Mean reward: 742.26
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 1.5458
    Episode_Reward/rotating_object: 148.0082
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.23s
                      Time elapsed: 00:45:10
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 44329 steps/s (collection: 2.102s, learning 0.115s)
             Mean action noise std: 3.56
          Mean value_function loss: 44.2618
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 68.0259
                       Mean reward: 747.62
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 1.5579
    Episode_Reward/rotating_object: 150.1362
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.22s
                      Time elapsed: 00:45:12
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 44093 steps/s (collection: 2.116s, learning 0.114s)
             Mean action noise std: 3.56
          Mean value_function loss: 50.3903
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.0416
                       Mean reward: 742.22
               Mean episode length: 239.06
    Episode_Reward/reaching_object: 1.5496
    Episode_Reward/rotating_object: 148.5015
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.23s
                      Time elapsed: 00:45:14
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 43693 steps/s (collection: 2.122s, learning 0.128s)
             Mean action noise std: 3.56
          Mean value_function loss: 43.4210
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.0602
                       Mean reward: 744.93
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.5518
    Episode_Reward/rotating_object: 150.4337
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.25s
                      Time elapsed: 00:45:16
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 43799 steps/s (collection: 2.127s, learning 0.117s)
             Mean action noise std: 3.57
          Mean value_function loss: 48.6843
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 68.0761
                       Mean reward: 744.93
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 1.5466
    Episode_Reward/rotating_object: 147.9892
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.24s
                      Time elapsed: 00:45:19
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 44295 steps/s (collection: 2.105s, learning 0.115s)
             Mean action noise std: 3.57
          Mean value_function loss: 49.2592
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.0893
                       Mean reward: 715.02
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 1.5484
    Episode_Reward/rotating_object: 148.7194
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.22s
                      Time elapsed: 00:45:21
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 44347 steps/s (collection: 2.102s, learning 0.114s)
             Mean action noise std: 3.57
          Mean value_function loss: 46.7240
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 68.1054
                       Mean reward: 762.76
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.5415
    Episode_Reward/rotating_object: 149.1242
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.22s
                      Time elapsed: 00:45:23
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 44449 steps/s (collection: 2.099s, learning 0.112s)
             Mean action noise std: 3.57
          Mean value_function loss: 49.6438
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.1219
                       Mean reward: 760.08
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.5562
    Episode_Reward/rotating_object: 148.7598
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.21s
                      Time elapsed: 00:45:25
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 44890 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 3.57
          Mean value_function loss: 41.3045
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 68.1333
                       Mean reward: 789.52
               Mean episode length: 248.54
    Episode_Reward/reaching_object: 1.5865
    Episode_Reward/rotating_object: 152.0118
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.19s
                      Time elapsed: 00:45:27
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 44431 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 37.1448
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.1409
                       Mean reward: 768.09
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 1.5739
    Episode_Reward/rotating_object: 151.5807
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.21s
                      Time elapsed: 00:45:30
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 44870 steps/s (collection: 2.078s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 43.4744
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.1558
                       Mean reward: 773.04
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 1.5609
    Episode_Reward/rotating_object: 151.3241
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.19s
                      Time elapsed: 00:45:32
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 44688 steps/s (collection: 2.087s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 48.4896
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.1745
                       Mean reward: 791.57
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 1.5637
    Episode_Reward/rotating_object: 152.0735
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.20s
                      Time elapsed: 00:45:34
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 43821 steps/s (collection: 2.130s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 46.1403
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 68.1956
                       Mean reward: 741.46
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.5699
    Episode_Reward/rotating_object: 149.0630
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.24s
                      Time elapsed: 00:45:36
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 44073 steps/s (collection: 2.118s, learning 0.113s)
             Mean action noise std: 3.59
          Mean value_function loss: 50.0906
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.2142
                       Mean reward: 732.12
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.5466
    Episode_Reward/rotating_object: 147.9509
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.23s
                      Time elapsed: 00:45:38
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 44260 steps/s (collection: 2.108s, learning 0.113s)
             Mean action noise std: 3.59
          Mean value_function loss: 49.7218
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 68.2302
                       Mean reward: 741.94
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.5316
    Episode_Reward/rotating_object: 148.6436
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.22s
                      Time elapsed: 00:45:41
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 44430 steps/s (collection: 2.097s, learning 0.116s)
             Mean action noise std: 3.59
          Mean value_function loss: 52.5223
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 68.2494
                       Mean reward: 772.90
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.5513
    Episode_Reward/rotating_object: 148.2103
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.21s
                      Time elapsed: 00:45:43
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 43618 steps/s (collection: 2.136s, learning 0.118s)
             Mean action noise std: 3.59
          Mean value_function loss: 43.0161
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.2744
                       Mean reward: 760.91
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 1.5711
    Episode_Reward/rotating_object: 151.0605
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.25s
                      Time elapsed: 00:45:45
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 43713 steps/s (collection: 2.119s, learning 0.130s)
             Mean action noise std: 3.60
          Mean value_function loss: 46.1589
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 68.2907
                       Mean reward: 770.55
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 1.5845
    Episode_Reward/rotating_object: 154.6798
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.25s
                      Time elapsed: 00:45:47
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 44135 steps/s (collection: 2.112s, learning 0.115s)
             Mean action noise std: 3.60
          Mean value_function loss: 46.6844
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 68.3095
                       Mean reward: 731.94
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.5778
    Episode_Reward/rotating_object: 149.7887
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.23s
                      Time elapsed: 00:45:50
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 43848 steps/s (collection: 2.127s, learning 0.115s)
             Mean action noise std: 3.60
          Mean value_function loss: 51.6057
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.3289
                       Mean reward: 734.12
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.5560
    Episode_Reward/rotating_object: 148.2286
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.24s
                      Time elapsed: 00:45:52
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 43316 steps/s (collection: 2.155s, learning 0.115s)
             Mean action noise std: 3.61
          Mean value_function loss: 41.7316
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.3553
                       Mean reward: 774.70
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 1.5796
    Episode_Reward/rotating_object: 151.3491
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.27s
                      Time elapsed: 00:45:54
                               ETA: 00:11:42

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 43296 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 3.61
          Mean value_function loss: 37.4958
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 68.3688
                       Mean reward: 767.01
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.6067
    Episode_Reward/rotating_object: 154.6939
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.27s
                      Time elapsed: 00:45:56
                               ETA: 00:11:40

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 44451 steps/s (collection: 2.095s, learning 0.117s)
             Mean action noise std: 3.61
          Mean value_function loss: 50.8829
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 68.3885
                       Mean reward: 749.91
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.5738
    Episode_Reward/rotating_object: 151.2531
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.21s
                      Time elapsed: 00:45:59
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 44577 steps/s (collection: 2.091s, learning 0.115s)
             Mean action noise std: 3.62
          Mean value_function loss: 39.3273
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 68.4165
                       Mean reward: 767.26
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 1.5889
    Episode_Reward/rotating_object: 151.2513
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.21s
                      Time elapsed: 00:46:01
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 44364 steps/s (collection: 2.103s, learning 0.113s)
             Mean action noise std: 3.62
          Mean value_function loss: 41.8786
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.4398
                       Mean reward: 780.76
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.5870
    Episode_Reward/rotating_object: 150.0667
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.22s
                      Time elapsed: 00:46:03
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 42888 steps/s (collection: 2.179s, learning 0.113s)
             Mean action noise std: 3.62
          Mean value_function loss: 47.1928
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 68.4613
                       Mean reward: 783.27
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.6103
    Episode_Reward/rotating_object: 153.4222
        Episode_Reward/action_rate: -0.0848
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.29s
                      Time elapsed: 00:46:05
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 44928 steps/s (collection: 2.074s, learning 0.114s)
             Mean action noise std: 3.62
          Mean value_function loss: 51.6047
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.4759
                       Mean reward: 706.00
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 1.5770
    Episode_Reward/rotating_object: 149.3470
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.19s
                      Time elapsed: 00:46:07
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 44733 steps/s (collection: 2.084s, learning 0.114s)
             Mean action noise std: 3.63
          Mean value_function loss: 43.0427
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 68.4985
                       Mean reward: 774.55
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.5805
    Episode_Reward/rotating_object: 150.5377
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.20s
                      Time elapsed: 00:46:10
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 44934 steps/s (collection: 2.073s, learning 0.115s)
             Mean action noise std: 3.63
          Mean value_function loss: 46.5581
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 68.5087
                       Mean reward: 729.11
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.5452
    Episode_Reward/rotating_object: 146.2635
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.19s
                      Time elapsed: 00:46:12
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 44708 steps/s (collection: 2.083s, learning 0.116s)
             Mean action noise std: 3.63
          Mean value_function loss: 50.3440
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.5280
                       Mean reward: 758.22
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.5733
    Episode_Reward/rotating_object: 151.0418
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.20s
                      Time elapsed: 00:46:14
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 44837 steps/s (collection: 2.080s, learning 0.113s)
             Mean action noise std: 3.63
          Mean value_function loss: 41.1714
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 68.5557
                       Mean reward: 787.78
               Mean episode length: 247.41
    Episode_Reward/reaching_object: 1.5905
    Episode_Reward/rotating_object: 152.1372
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.19s
                      Time elapsed: 00:46:16
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 45117 steps/s (collection: 2.067s, learning 0.112s)
             Mean action noise std: 3.64
          Mean value_function loss: 52.4694
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.5738
                       Mean reward: 756.47
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 1.5810
    Episode_Reward/rotating_object: 152.1637
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.18s
                      Time elapsed: 00:46:18
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 45126 steps/s (collection: 2.066s, learning 0.112s)
             Mean action noise std: 3.64
          Mean value_function loss: 45.4789
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 68.5901
                       Mean reward: 747.24
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 1.5808
    Episode_Reward/rotating_object: 149.5321
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.18s
                      Time elapsed: 00:46:21
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 45125 steps/s (collection: 2.066s, learning 0.113s)
             Mean action noise std: 3.64
          Mean value_function loss: 43.7988
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 68.6072
                       Mean reward: 776.62
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.5663
    Episode_Reward/rotating_object: 151.4620
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.18s
                      Time elapsed: 00:46:23
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 44781 steps/s (collection: 2.082s, learning 0.113s)
             Mean action noise std: 3.64
          Mean value_function loss: 52.0691
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 68.6294
                       Mean reward: 749.07
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.5738
    Episode_Reward/rotating_object: 152.5580
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.20s
                      Time elapsed: 00:46:25
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 45369 steps/s (collection: 2.054s, learning 0.112s)
             Mean action noise std: 3.65
          Mean value_function loss: 52.9388
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 68.6502
                       Mean reward: 748.88
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.5535
    Episode_Reward/rotating_object: 148.9274
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.17s
                      Time elapsed: 00:46:27
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 44060 steps/s (collection: 2.113s, learning 0.118s)
             Mean action noise std: 3.65
          Mean value_function loss: 50.7375
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.6723
                       Mean reward: 778.13
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.5939
    Episode_Reward/rotating_object: 152.6438
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.23s
                      Time elapsed: 00:46:29
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 44449 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 3.65
          Mean value_function loss: 50.8651
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 68.6946
                       Mean reward: 713.27
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.5648
    Episode_Reward/rotating_object: 148.7974
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.21s
                      Time elapsed: 00:46:32
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 44551 steps/s (collection: 2.093s, learning 0.114s)
             Mean action noise std: 3.65
          Mean value_function loss: 46.3977
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.7092
                       Mean reward: 761.29
               Mean episode length: 242.62
    Episode_Reward/reaching_object: 1.5701
    Episode_Reward/rotating_object: 148.0486
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.21s
                      Time elapsed: 00:46:34
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 44109 steps/s (collection: 2.113s, learning 0.116s)
             Mean action noise std: 3.66
          Mean value_function loss: 48.6320
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.7247
                       Mean reward: 718.02
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.5844
    Episode_Reward/rotating_object: 150.1138
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.23s
                      Time elapsed: 00:46:36
                               ETA: 00:10:58

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 44499 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 3.66
          Mean value_function loss: 48.6336
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 68.7438
                       Mean reward: 756.01
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.5581
    Episode_Reward/rotating_object: 148.4941
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.21s
                      Time elapsed: 00:46:38
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 44133 steps/s (collection: 2.112s, learning 0.116s)
             Mean action noise std: 3.66
          Mean value_function loss: 50.0416
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 68.7626
                       Mean reward: 792.91
               Mean episode length: 249.58
    Episode_Reward/reaching_object: 1.5887
    Episode_Reward/rotating_object: 151.4217
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.23s
                      Time elapsed: 00:46:40
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 44201 steps/s (collection: 2.111s, learning 0.113s)
             Mean action noise std: 3.66
          Mean value_function loss: 48.7359
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 68.7812
                       Mean reward: 767.84
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.6044
    Episode_Reward/rotating_object: 151.3561
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.22s
                      Time elapsed: 00:46:43
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 44150 steps/s (collection: 2.111s, learning 0.116s)
             Mean action noise std: 3.67
          Mean value_function loss: 48.1167
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.7983
                       Mean reward: 733.40
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 1.6010
    Episode_Reward/rotating_object: 152.6246
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.23s
                      Time elapsed: 00:46:45
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 43389 steps/s (collection: 2.138s, learning 0.127s)
             Mean action noise std: 3.67
          Mean value_function loss: 52.4639
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 68.8136
                       Mean reward: 764.77
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.5999
    Episode_Reward/rotating_object: 151.1286
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.27s
                      Time elapsed: 00:46:47
                               ETA: 00:10:46

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 44300 steps/s (collection: 2.103s, learning 0.116s)
             Mean action noise std: 3.67
          Mean value_function loss: 54.2815
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.8226
                       Mean reward: 772.06
               Mean episode length: 240.43
    Episode_Reward/reaching_object: 1.5966
    Episode_Reward/rotating_object: 150.8611
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.22s
                      Time elapsed: 00:46:49
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 43104 steps/s (collection: 2.146s, learning 0.134s)
             Mean action noise std: 3.67
          Mean value_function loss: 39.6512
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 68.8277
                       Mean reward: 761.27
               Mean episode length: 244.73
    Episode_Reward/reaching_object: 1.6089
    Episode_Reward/rotating_object: 151.4424
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.28s
                      Time elapsed: 00:46:52
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 44378 steps/s (collection: 2.103s, learning 0.113s)
             Mean action noise std: 3.67
          Mean value_function loss: 52.0135
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 68.8317
                       Mean reward: 792.21
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 1.6114
    Episode_Reward/rotating_object: 150.9371
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.22s
                      Time elapsed: 00:46:54
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 44634 steps/s (collection: 2.089s, learning 0.113s)
             Mean action noise std: 3.68
          Mean value_function loss: 50.2845
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 68.8453
                       Mean reward: 756.26
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 1.5970
    Episode_Reward/rotating_object: 149.0656
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.20s
                      Time elapsed: 00:46:56
                               ETA: 00:10:37

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 44339 steps/s (collection: 2.102s, learning 0.115s)
             Mean action noise std: 3.68
          Mean value_function loss: 47.2916
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 68.8625
                       Mean reward: 778.43
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.5779
    Episode_Reward/rotating_object: 150.8441
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.22s
                      Time elapsed: 00:46:58
                               ETA: 00:10:35

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 44535 steps/s (collection: 2.096s, learning 0.112s)
             Mean action noise std: 3.68
          Mean value_function loss: 49.6967
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.8867
                       Mean reward: 757.16
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.5846
    Episode_Reward/rotating_object: 149.4395
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.21s
                      Time elapsed: 00:47:01
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 44556 steps/s (collection: 2.092s, learning 0.114s)
             Mean action noise std: 3.68
          Mean value_function loss: 41.2524
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 68.9118
                       Mean reward: 773.58
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.6007
    Episode_Reward/rotating_object: 150.7366
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.21s
                      Time elapsed: 00:47:03
                               ETA: 00:10:30

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 43863 steps/s (collection: 2.129s, learning 0.112s)
             Mean action noise std: 3.69
          Mean value_function loss: 56.4680
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.9259
                       Mean reward: 746.54
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.5677
    Episode_Reward/rotating_object: 147.8658
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.24s
                      Time elapsed: 00:47:05
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 44525 steps/s (collection: 2.095s, learning 0.113s)
             Mean action noise std: 3.69
          Mean value_function loss: 43.5327
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.9432
                       Mean reward: 743.65
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.5869
    Episode_Reward/rotating_object: 151.5446
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.21s
                      Time elapsed: 00:47:07
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 43791 steps/s (collection: 2.131s, learning 0.114s)
             Mean action noise std: 3.69
          Mean value_function loss: 58.2075
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 68.9584
                       Mean reward: 742.25
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.5738
    Episode_Reward/rotating_object: 150.0776
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.24s
                      Time elapsed: 00:47:09
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 44358 steps/s (collection: 2.102s, learning 0.114s)
             Mean action noise std: 3.70
          Mean value_function loss: 45.4936
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 68.9806
                       Mean reward: 766.20
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 1.5818
    Episode_Reward/rotating_object: 148.8799
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.22s
                      Time elapsed: 00:47:12
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 44127 steps/s (collection: 2.113s, learning 0.115s)
             Mean action noise std: 3.70
          Mean value_function loss: 38.1904
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 69.0094
                       Mean reward: 770.11
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 1.6125
    Episode_Reward/rotating_object: 154.2243
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.23s
                      Time elapsed: 00:47:14
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 44316 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 3.70
          Mean value_function loss: 42.3658
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.0304
                       Mean reward: 754.27
               Mean episode length: 241.09
    Episode_Reward/reaching_object: 1.5966
    Episode_Reward/rotating_object: 150.9943
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.22s
                      Time elapsed: 00:47:16
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 44756 steps/s (collection: 2.084s, learning 0.112s)
             Mean action noise std: 3.71
          Mean value_function loss: 35.2799
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.0523
                       Mean reward: 788.33
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 1.6219
    Episode_Reward/rotating_object: 153.2476
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.20s
                      Time elapsed: 00:47:18
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 44778 steps/s (collection: 2.082s, learning 0.114s)
             Mean action noise std: 3.71
          Mean value_function loss: 53.5773
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.0716
                       Mean reward: 771.86
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.5914
    Episode_Reward/rotating_object: 151.6838
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.20s
                      Time elapsed: 00:47:20
                               ETA: 00:10:11

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 44312 steps/s (collection: 2.102s, learning 0.116s)
             Mean action noise std: 3.71
          Mean value_function loss: 56.2559
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.0951
                       Mean reward: 759.30
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.5873
    Episode_Reward/rotating_object: 148.7019
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.22s
                      Time elapsed: 00:47:23
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 43852 steps/s (collection: 2.130s, learning 0.112s)
             Mean action noise std: 3.71
          Mean value_function loss: 54.9670
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.1112
                       Mean reward: 742.09
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.5770
    Episode_Reward/rotating_object: 147.2161
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.24s
                      Time elapsed: 00:47:25
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 44255 steps/s (collection: 2.108s, learning 0.114s)
             Mean action noise std: 3.72
          Mean value_function loss: 53.3950
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.1257
                       Mean reward: 797.44
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 1.6157
    Episode_Reward/rotating_object: 152.1038
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.22s
                      Time elapsed: 00:47:27
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 44185 steps/s (collection: 2.112s, learning 0.112s)
             Mean action noise std: 3.72
          Mean value_function loss: 42.2014
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 69.1433
                       Mean reward: 767.50
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.6012
    Episode_Reward/rotating_object: 149.8921
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.22s
                      Time elapsed: 00:47:29
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 43994 steps/s (collection: 2.118s, learning 0.116s)
             Mean action noise std: 3.72
          Mean value_function loss: 38.4584
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.1568
                       Mean reward: 779.12
               Mean episode length: 245.25
    Episode_Reward/reaching_object: 1.6316
    Episode_Reward/rotating_object: 153.3492
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.23s
                      Time elapsed: 00:47:32
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 43988 steps/s (collection: 2.117s, learning 0.118s)
             Mean action noise std: 3.72
          Mean value_function loss: 45.2656
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 69.1672
                       Mean reward: 744.91
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.6007
    Episode_Reward/rotating_object: 152.0874
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.23s
                      Time elapsed: 00:47:34
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 44362 steps/s (collection: 2.088s, learning 0.128s)
             Mean action noise std: 3.73
          Mean value_function loss: 45.8544
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.1828
                       Mean reward: 792.82
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.5982
    Episode_Reward/rotating_object: 150.8151
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.22s
                      Time elapsed: 00:47:36
                               ETA: 00:09:55

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 44423 steps/s (collection: 2.097s, learning 0.116s)
             Mean action noise std: 3.73
          Mean value_function loss: 34.8116
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 69.2002
                       Mean reward: 783.24
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.6244
    Episode_Reward/rotating_object: 154.3470
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.21s
                      Time elapsed: 00:47:38
                               ETA: 00:09:53

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 44191 steps/s (collection: 2.112s, learning 0.113s)
             Mean action noise std: 3.73
          Mean value_function loss: 49.4616
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.2092
                       Mean reward: 754.21
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 1.6117
    Episode_Reward/rotating_object: 150.3053
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.22s
                      Time elapsed: 00:47:41
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 44203 steps/s (collection: 2.106s, learning 0.118s)
             Mean action noise std: 3.73
          Mean value_function loss: 47.1481
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.2196
                       Mean reward: 765.17
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 1.5957
    Episode_Reward/rotating_object: 150.1556
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.22s
                      Time elapsed: 00:47:43
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 44338 steps/s (collection: 2.102s, learning 0.115s)
             Mean action noise std: 3.73
          Mean value_function loss: 35.8691
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 69.2354
                       Mean reward: 796.06
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.6367
    Episode_Reward/rotating_object: 155.6755
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.22s
                      Time elapsed: 00:47:45
                               ETA: 00:09:46

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 44502 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 3.74
          Mean value_function loss: 39.9155
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 69.2498
                       Mean reward: 754.96
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 1.6190
    Episode_Reward/rotating_object: 152.2993
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.21s
                      Time elapsed: 00:47:47
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 43816 steps/s (collection: 2.118s, learning 0.125s)
             Mean action noise std: 3.74
          Mean value_function loss: 41.5616
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 69.2633
                       Mean reward: 809.02
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.6492
    Episode_Reward/rotating_object: 157.0590
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.24s
                      Time elapsed: 00:47:49
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 44275 steps/s (collection: 2.107s, learning 0.113s)
             Mean action noise std: 3.74
          Mean value_function loss: 41.3022
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 69.2776
                       Mean reward: 787.93
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.6315
    Episode_Reward/rotating_object: 155.4711
        Episode_Reward/action_rate: -0.0896
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.22s
                      Time elapsed: 00:47:52
                               ETA: 00:09:39

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 44193 steps/s (collection: 2.110s, learning 0.114s)
             Mean action noise std: 3.74
          Mean value_function loss: 47.1966
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.2957
                       Mean reward: 763.17
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.5942
    Episode_Reward/rotating_object: 149.8246
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.22s
                      Time elapsed: 00:47:54
                               ETA: 00:09:37

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 43992 steps/s (collection: 2.121s, learning 0.113s)
             Mean action noise std: 3.75
          Mean value_function loss: 45.6263
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 69.3190
                       Mean reward: 797.22
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.6126
    Episode_Reward/rotating_object: 153.7090
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.23s
                      Time elapsed: 00:47:56
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 44348 steps/s (collection: 2.099s, learning 0.118s)
             Mean action noise std: 3.75
          Mean value_function loss: 43.5025
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.3354
                       Mean reward: 796.59
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.6215
    Episode_Reward/rotating_object: 154.0461
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.22s
                      Time elapsed: 00:47:58
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 44934 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 3.75
          Mean value_function loss: 37.4518
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 69.3458
                       Mean reward: 780.76
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.6395
    Episode_Reward/rotating_object: 156.2839
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.19s
                      Time elapsed: 00:48:00
                               ETA: 00:09:30

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 44915 steps/s (collection: 2.077s, learning 0.112s)
             Mean action noise std: 3.75
          Mean value_function loss: 38.9201
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 69.3524
                       Mean reward: 765.05
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 1.6097
    Episode_Reward/rotating_object: 151.6310
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.19s
                      Time elapsed: 00:48:03
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 44737 steps/s (collection: 2.081s, learning 0.117s)
             Mean action noise std: 3.75
          Mean value_function loss: 38.6562
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 69.3572
                       Mean reward: 756.56
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.6032
    Episode_Reward/rotating_object: 153.6393
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.20s
                      Time elapsed: 00:48:05
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 44608 steps/s (collection: 2.070s, learning 0.134s)
             Mean action noise std: 3.76
          Mean value_function loss: 39.1053
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 69.3674
                       Mean reward: 776.07
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 1.6166
    Episode_Reward/rotating_object: 154.7900
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.20s
                      Time elapsed: 00:48:07
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 44708 steps/s (collection: 2.086s, learning 0.113s)
             Mean action noise std: 3.76
          Mean value_function loss: 36.8821
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.3783
                       Mean reward: 784.35
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.6282
    Episode_Reward/rotating_object: 152.6929
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.20s
                      Time elapsed: 00:48:09
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 44844 steps/s (collection: 2.080s, learning 0.112s)
             Mean action noise std: 3.76
          Mean value_function loss: 31.4422
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.3902
                       Mean reward: 785.12
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 1.6372
    Episode_Reward/rotating_object: 155.7448
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.19s
                      Time elapsed: 00:48:11
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 44267 steps/s (collection: 2.103s, learning 0.117s)
             Mean action noise std: 3.76
          Mean value_function loss: 40.5403
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 69.3982
                       Mean reward: 787.58
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 1.6121
    Episode_Reward/rotating_object: 153.5579
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.22s
                      Time elapsed: 00:48:14
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 44499 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 3.76
          Mean value_function loss: 34.2678
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 69.4085
                       Mean reward: 791.13
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 1.6139
    Episode_Reward/rotating_object: 155.1318
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.21s
                      Time elapsed: 00:48:16
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 43948 steps/s (collection: 2.107s, learning 0.130s)
             Mean action noise std: 3.77
          Mean value_function loss: 40.9197
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.4166
                       Mean reward: 772.52
               Mean episode length: 245.33
    Episode_Reward/reaching_object: 1.5858
    Episode_Reward/rotating_object: 151.3441
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.24s
                      Time elapsed: 00:48:18
                               ETA: 00:09:11

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 44631 steps/s (collection: 2.075s, learning 0.127s)
             Mean action noise std: 3.77
          Mean value_function loss: 43.6498
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 69.4285
                       Mean reward: 757.01
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.5818
    Episode_Reward/rotating_object: 150.8783
        Episode_Reward/action_rate: -0.0896
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.20s
                      Time elapsed: 00:48:20
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 44777 steps/s (collection: 2.070s, learning 0.125s)
             Mean action noise std: 3.77
          Mean value_function loss: 39.3038
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.4433
                       Mean reward: 775.07
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.6026
    Episode_Reward/rotating_object: 152.8272
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.20s
                      Time elapsed: 00:48:23
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 44648 steps/s (collection: 2.090s, learning 0.112s)
             Mean action noise std: 3.77
          Mean value_function loss: 43.5947
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.4585
                       Mean reward: 792.76
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 1.5886
    Episode_Reward/rotating_object: 151.4814
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.20s
                      Time elapsed: 00:48:25
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 44406 steps/s (collection: 2.098s, learning 0.115s)
             Mean action noise std: 3.78
          Mean value_function loss: 42.1173
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 69.4800
                       Mean reward: 789.20
               Mean episode length: 243.10
    Episode_Reward/reaching_object: 1.5885
    Episode_Reward/rotating_object: 152.4975
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.21s
                      Time elapsed: 00:48:27
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 44444 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 3.78
          Mean value_function loss: 46.1335
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 69.4982
                       Mean reward: 781.57
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.5863
    Episode_Reward/rotating_object: 152.1818
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.21s
                      Time elapsed: 00:48:29
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 45000 steps/s (collection: 2.072s, learning 0.113s)
             Mean action noise std: 3.78
          Mean value_function loss: 38.8337
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.5115
                       Mean reward: 778.11
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 1.6092
    Episode_Reward/rotating_object: 155.0214
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.18s
                      Time elapsed: 00:48:31
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 44205 steps/s (collection: 2.110s, learning 0.113s)
             Mean action noise std: 3.78
          Mean value_function loss: 49.2093
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.5262
                       Mean reward: 768.97
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.5786
    Episode_Reward/rotating_object: 150.9553
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.22s
                      Time elapsed: 00:48:34
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 44784 steps/s (collection: 2.080s, learning 0.115s)
             Mean action noise std: 3.79
          Mean value_function loss: 41.7326
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.5469
                       Mean reward: 768.76
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.5778
    Episode_Reward/rotating_object: 152.5406
        Episode_Reward/action_rate: -0.0902
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.20s
                      Time elapsed: 00:48:36
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 43241 steps/s (collection: 2.143s, learning 0.130s)
             Mean action noise std: 3.79
          Mean value_function loss: 34.9143
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 69.5620
                       Mean reward: 803.71
               Mean episode length: 247.63
    Episode_Reward/reaching_object: 1.6116
    Episode_Reward/rotating_object: 155.5652
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.27s
                      Time elapsed: 00:48:38
                               ETA: 00:08:50

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 44806 steps/s (collection: 2.082s, learning 0.112s)
             Mean action noise std: 3.79
          Mean value_function loss: 47.1145
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 69.5748
                       Mean reward: 785.20
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.5840
    Episode_Reward/rotating_object: 152.2985
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.19s
                      Time elapsed: 00:48:40
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 44751 steps/s (collection: 2.084s, learning 0.112s)
             Mean action noise std: 3.79
          Mean value_function loss: 37.7986
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.5860
                       Mean reward: 757.84
               Mean episode length: 236.28
    Episode_Reward/reaching_object: 1.6032
    Episode_Reward/rotating_object: 154.3906
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.20s
                      Time elapsed: 00:48:42
                               ETA: 00:08:46

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 44560 steps/s (collection: 2.093s, learning 0.113s)
             Mean action noise std: 3.80
          Mean value_function loss: 33.6153
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.6012
                       Mean reward: 764.87
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.6014
    Episode_Reward/rotating_object: 153.6062
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.21s
                      Time elapsed: 00:48:45
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 45420 steps/s (collection: 2.049s, learning 0.115s)
             Mean action noise std: 3.80
          Mean value_function loss: 41.6175
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.6211
                       Mean reward: 798.65
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.5857
    Episode_Reward/rotating_object: 152.7545
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.16s
                      Time elapsed: 00:48:47
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 44746 steps/s (collection: 2.081s, learning 0.116s)
             Mean action noise std: 3.80
          Mean value_function loss: 37.3909
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.6394
                       Mean reward: 784.43
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.6237
    Episode_Reward/rotating_object: 155.0498
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.20s
                      Time elapsed: 00:48:49
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 45263 steps/s (collection: 2.058s, learning 0.114s)
             Mean action noise std: 3.80
          Mean value_function loss: 41.3495
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.6573
                       Mean reward: 770.12
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.5859
    Episode_Reward/rotating_object: 152.0752
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.17s
                      Time elapsed: 00:48:51
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 45335 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 3.81
          Mean value_function loss: 29.3249
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 69.6754
                       Mean reward: 775.70
               Mean episode length: 246.76
    Episode_Reward/reaching_object: 1.6203
    Episode_Reward/rotating_object: 153.9397
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.17s
                      Time elapsed: 00:48:53
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 45117 steps/s (collection: 2.067s, learning 0.112s)
             Mean action noise std: 3.81
          Mean value_function loss: 44.6944
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.6839
                       Mean reward: 746.02
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 1.6193
    Episode_Reward/rotating_object: 155.3681
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.18s
                      Time elapsed: 00:48:56
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 44611 steps/s (collection: 2.090s, learning 0.113s)
             Mean action noise std: 3.81
          Mean value_function loss: 36.2558
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.6921
                       Mean reward: 776.52
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.6231
    Episode_Reward/rotating_object: 155.9395
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.20s
                      Time elapsed: 00:48:58
                               ETA: 00:08:29

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 45205 steps/s (collection: 2.062s, learning 0.112s)
             Mean action noise std: 3.81
          Mean value_function loss: 41.3537
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.7020
                       Mean reward: 771.04
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 1.6263
    Episode_Reward/rotating_object: 154.6880
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.17s
                      Time elapsed: 00:49:00
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 44932 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 3.82
          Mean value_function loss: 42.0582
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 69.7198
                       Mean reward: 798.78
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 1.6184
    Episode_Reward/rotating_object: 154.1815
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.19s
                      Time elapsed: 00:49:02
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 44540 steps/s (collection: 2.092s, learning 0.116s)
             Mean action noise std: 3.82
          Mean value_function loss: 40.9616
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.7348
                       Mean reward: 790.99
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 1.6323
    Episode_Reward/rotating_object: 155.7724
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.21s
                      Time elapsed: 00:49:04
                               ETA: 00:08:23

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 44363 steps/s (collection: 2.085s, learning 0.131s)
             Mean action noise std: 3.82
          Mean value_function loss: 45.0017
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.7514
                       Mean reward: 741.56
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.6011
    Episode_Reward/rotating_object: 150.7255
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.22s
                      Time elapsed: 00:49:06
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 44777 steps/s (collection: 2.081s, learning 0.115s)
             Mean action noise std: 3.82
          Mean value_function loss: 30.9199
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 69.7692
                       Mean reward: 802.64
               Mean episode length: 247.55
    Episode_Reward/reaching_object: 1.6517
    Episode_Reward/rotating_object: 157.2432
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.20s
                      Time elapsed: 00:49:09
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 44442 steps/s (collection: 2.100s, learning 0.112s)
             Mean action noise std: 3.82
          Mean value_function loss: 42.2112
               Mean surrogate loss: 0.0041
                 Mean entropy loss: 69.7749
                       Mean reward: 768.10
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.6093
    Episode_Reward/rotating_object: 151.9844
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.21s
                      Time elapsed: 00:49:11
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 44932 steps/s (collection: 2.076s, learning 0.112s)
             Mean action noise std: 3.82
          Mean value_function loss: 40.5471
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 69.7761
                       Mean reward: 785.26
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.6218
    Episode_Reward/rotating_object: 152.5717
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.19s
                      Time elapsed: 00:49:13
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 44475 steps/s (collection: 2.096s, learning 0.114s)
             Mean action noise std: 3.83
          Mean value_function loss: 31.8728
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.7819
                       Mean reward: 774.65
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.6550
    Episode_Reward/rotating_object: 155.9661
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.21s
                      Time elapsed: 00:49:15
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 44638 steps/s (collection: 2.088s, learning 0.114s)
             Mean action noise std: 3.83
          Mean value_function loss: 33.5648
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 69.7954
                       Mean reward: 810.72
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 1.6552
    Episode_Reward/rotating_object: 155.8738
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.20s
                      Time elapsed: 00:49:18
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 44937 steps/s (collection: 2.073s, learning 0.115s)
             Mean action noise std: 3.83
          Mean value_function loss: 32.4849
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 69.8075
                       Mean reward: 783.15
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.6493
    Episode_Reward/rotating_object: 156.0056
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.19s
                      Time elapsed: 00:49:20
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 45114 steps/s (collection: 2.064s, learning 0.115s)
             Mean action noise std: 3.83
          Mean value_function loss: 45.5436
               Mean surrogate loss: 0.0060
                 Mean entropy loss: 69.8157
                       Mean reward: 758.44
               Mean episode length: 236.66
    Episode_Reward/reaching_object: 1.6390
    Episode_Reward/rotating_object: 155.0698
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.18s
                      Time elapsed: 00:49:22
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 44691 steps/s (collection: 2.084s, learning 0.116s)
             Mean action noise std: 3.83
          Mean value_function loss: 30.2369
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 69.8174
                       Mean reward: 789.44
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 1.6348
    Episode_Reward/rotating_object: 155.6178
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.20s
                      Time elapsed: 00:49:24
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 44324 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 3.83
          Mean value_function loss: 30.6073
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 69.8190
                       Mean reward: 779.11
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.6383
    Episode_Reward/rotating_object: 156.8244
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.22s
                      Time elapsed: 00:49:26
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 44034 steps/s (collection: 2.103s, learning 0.130s)
             Mean action noise std: 3.83
          Mean value_function loss: 38.3514
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.8221
                       Mean reward: 749.63
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.6178
    Episode_Reward/rotating_object: 153.6958
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.23s
                      Time elapsed: 00:49:29
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 44820 steps/s (collection: 2.080s, learning 0.113s)
             Mean action noise std: 3.84
          Mean value_function loss: 45.0373
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.8305
                       Mean reward: 775.37
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.6237
    Episode_Reward/rotating_object: 154.3293
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.19s
                      Time elapsed: 00:49:31
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 44795 steps/s (collection: 2.082s, learning 0.112s)
             Mean action noise std: 3.84
          Mean value_function loss: 40.6956
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 69.8439
                       Mean reward: 776.03
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.6363
    Episode_Reward/rotating_object: 155.1415
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.19s
                      Time elapsed: 00:49:33
                               ETA: 00:07:52

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 44702 steps/s (collection: 2.082s, learning 0.117s)
             Mean action noise std: 3.84
          Mean value_function loss: 43.2949
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.8635
                       Mean reward: 785.41
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.5971
    Episode_Reward/rotating_object: 152.7185
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.20s
                      Time elapsed: 00:49:35
                               ETA: 00:07:50

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 45019 steps/s (collection: 2.072s, learning 0.112s)
             Mean action noise std: 3.84
          Mean value_function loss: 33.3400
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 69.8829
                       Mean reward: 788.56
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.6373
    Episode_Reward/rotating_object: 155.7041
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.18s
                      Time elapsed: 00:49:37
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 44875 steps/s (collection: 2.064s, learning 0.126s)
             Mean action noise std: 3.85
          Mean value_function loss: 39.2990
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 69.8987
                       Mean reward: 781.30
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.6204
    Episode_Reward/rotating_object: 154.3947
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.19s
                      Time elapsed: 00:49:39
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 45124 steps/s (collection: 2.066s, learning 0.112s)
             Mean action noise std: 3.85
          Mean value_function loss: 40.2937
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.9087
                       Mean reward: 815.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.6303
    Episode_Reward/rotating_object: 155.3660
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.18s
                      Time elapsed: 00:49:42
                               ETA: 00:07:43

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 44782 steps/s (collection: 2.068s, learning 0.127s)
             Mean action noise std: 3.85
          Mean value_function loss: 47.8847
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.9210
                       Mean reward: 753.77
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.6113
    Episode_Reward/rotating_object: 151.6688
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.20s
                      Time elapsed: 00:49:44
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 44750 steps/s (collection: 2.082s, learning 0.114s)
             Mean action noise std: 3.85
          Mean value_function loss: 52.0043
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.9380
                       Mean reward: 766.46
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.6110
    Episode_Reward/rotating_object: 151.7867
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.20s
                      Time elapsed: 00:49:46
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 44545 steps/s (collection: 2.095s, learning 0.112s)
             Mean action noise std: 3.85
          Mean value_function loss: 48.8461
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 69.9531
                       Mean reward: 768.36
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.6166
    Episode_Reward/rotating_object: 153.3810
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.21s
                      Time elapsed: 00:49:48
                               ETA: 00:07:36

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 44628 steps/s (collection: 2.090s, learning 0.113s)
             Mean action noise std: 3.86
          Mean value_function loss: 40.6370
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.9633
                       Mean reward: 789.65
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.6263
    Episode_Reward/rotating_object: 153.5251
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.20s
                      Time elapsed: 00:49:50
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 44328 steps/s (collection: 2.101s, learning 0.117s)
             Mean action noise std: 3.86
          Mean value_function loss: 35.3370
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 69.9740
                       Mean reward: 763.13
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.6481
    Episode_Reward/rotating_object: 155.2259
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.22s
                      Time elapsed: 00:49:53
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 44259 steps/s (collection: 2.107s, learning 0.115s)
             Mean action noise std: 3.86
          Mean value_function loss: 32.3175
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 69.9849
                       Mean reward: 816.14
               Mean episode length: 249.62
    Episode_Reward/reaching_object: 1.6464
    Episode_Reward/rotating_object: 155.9376
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.22s
                      Time elapsed: 00:49:55
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 44425 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 3.86
          Mean value_function loss: 45.9525
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 69.9995
                       Mean reward: 759.69
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.6298
    Episode_Reward/rotating_object: 153.9667
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.21s
                      Time elapsed: 00:49:57
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 44625 steps/s (collection: 2.086s, learning 0.117s)
             Mean action noise std: 3.87
          Mean value_function loss: 48.4956
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 70.0152
                       Mean reward: 772.27
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.6317
    Episode_Reward/rotating_object: 154.9185
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.20s
                      Time elapsed: 00:49:59
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 44308 steps/s (collection: 2.102s, learning 0.117s)
             Mean action noise std: 3.87
          Mean value_function loss: 46.8310
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 70.0379
                       Mean reward: 763.80
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.6216
    Episode_Reward/rotating_object: 152.6797
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.22s
                      Time elapsed: 00:50:02
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 44327 steps/s (collection: 2.102s, learning 0.116s)
             Mean action noise std: 3.87
          Mean value_function loss: 37.5096
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 70.0594
                       Mean reward: 781.21
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 1.6503
    Episode_Reward/rotating_object: 157.1913
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.22s
                      Time elapsed: 00:50:04
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 44618 steps/s (collection: 2.088s, learning 0.115s)
             Mean action noise std: 3.87
          Mean value_function loss: 39.6552
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 70.0714
                       Mean reward: 778.54
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 1.6207
    Episode_Reward/rotating_object: 151.8259
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.20s
                      Time elapsed: 00:50:06
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 44120 steps/s (collection: 2.114s, learning 0.114s)
             Mean action noise std: 3.88
          Mean value_function loss: 40.1881
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 70.0860
                       Mean reward: 778.09
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 1.6280
    Episode_Reward/rotating_object: 153.9626
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.23s
                      Time elapsed: 00:50:08
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 44936 steps/s (collection: 2.074s, learning 0.114s)
             Mean action noise std: 3.88
          Mean value_function loss: 45.1153
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 70.1036
                       Mean reward: 753.24
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.6343
    Episode_Reward/rotating_object: 155.1366
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.19s
                      Time elapsed: 00:50:10
                               ETA: 00:07:13

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 44759 steps/s (collection: 2.080s, learning 0.116s)
             Mean action noise std: 3.88
          Mean value_function loss: 44.8448
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 70.1218
                       Mean reward: 748.22
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 1.6178
    Episode_Reward/rotating_object: 153.5190
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.20s
                      Time elapsed: 00:50:13
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 44780 steps/s (collection: 2.081s, learning 0.114s)
             Mean action noise std: 3.89
          Mean value_function loss: 34.9515
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 70.1425
                       Mean reward: 807.07
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.6414
    Episode_Reward/rotating_object: 155.3806
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.20s
                      Time elapsed: 00:50:15
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 45175 steps/s (collection: 2.062s, learning 0.114s)
             Mean action noise std: 3.89
          Mean value_function loss: 35.5197
               Mean surrogate loss: 0.0181
                 Mean entropy loss: 70.1566
                       Mean reward: 794.39
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 1.6355
    Episode_Reward/rotating_object: 156.1592
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.18s
                      Time elapsed: 00:50:17
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 44994 steps/s (collection: 2.072s, learning 0.113s)
             Mean action noise std: 3.89
          Mean value_function loss: 39.6892
               Mean surrogate loss: 0.0123
                 Mean entropy loss: 70.1586
                       Mean reward: 780.27
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.6274
    Episode_Reward/rotating_object: 156.3428
        Episode_Reward/action_rate: -0.0965
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.18s
                      Time elapsed: 00:50:19
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 44582 steps/s (collection: 2.083s, learning 0.122s)
             Mean action noise std: 3.89
          Mean value_function loss: 44.2704
               Mean surrogate loss: 0.0047
                 Mean entropy loss: 70.1591
                       Mean reward: 796.91
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 1.6026
    Episode_Reward/rotating_object: 152.9523
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.21s
                      Time elapsed: 00:50:21
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 45410 steps/s (collection: 2.052s, learning 0.113s)
             Mean action noise std: 3.89
          Mean value_function loss: 32.6421
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 70.1599
                       Mean reward: 787.51
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 1.6406
    Episode_Reward/rotating_object: 158.3180
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.16s
                      Time elapsed: 00:50:23
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 45574 steps/s (collection: 2.042s, learning 0.115s)
             Mean action noise std: 3.89
          Mean value_function loss: 28.9070
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 70.1614
                       Mean reward: 788.32
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 1.6087
    Episode_Reward/rotating_object: 155.4989
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.16s
                      Time elapsed: 00:50:26
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 45681 steps/s (collection: 2.040s, learning 0.112s)
             Mean action noise std: 3.89
          Mean value_function loss: 26.8562
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 70.1625
                       Mean reward: 806.11
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.6271
    Episode_Reward/rotating_object: 157.9184
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.15s
                      Time elapsed: 00:50:28
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 45688 steps/s (collection: 2.025s, learning 0.127s)
             Mean action noise std: 3.89
          Mean value_function loss: 28.3131
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.1664
                       Mean reward: 813.76
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.6065
    Episode_Reward/rotating_object: 157.0562
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.15s
                      Time elapsed: 00:50:30
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 45895 steps/s (collection: 2.029s, learning 0.113s)
             Mean action noise std: 3.89
          Mean value_function loss: 35.9106
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.1753
                       Mean reward: 775.44
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.5869
    Episode_Reward/rotating_object: 154.2588
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.14s
                      Time elapsed: 00:50:32
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 46007 steps/s (collection: 2.025s, learning 0.112s)
             Mean action noise std: 3.89
          Mean value_function loss: 34.7495
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 70.1952
                       Mean reward: 770.12
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.5845
    Episode_Reward/rotating_object: 155.6060
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.14s
                      Time elapsed: 00:50:34
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 45158 steps/s (collection: 2.064s, learning 0.112s)
             Mean action noise std: 3.90
          Mean value_function loss: 42.9035
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 70.2125
                       Mean reward: 756.39
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.5906
    Episode_Reward/rotating_object: 155.3715
        Episode_Reward/action_rate: -0.0979
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.18s
                      Time elapsed: 00:50:36
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 45016 steps/s (collection: 2.071s, learning 0.113s)
             Mean action noise std: 3.90
          Mean value_function loss: 38.0609
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 70.2271
                       Mean reward: 804.16
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 1.5786
    Episode_Reward/rotating_object: 155.3466
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.18s
                      Time elapsed: 00:50:39
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 45039 steps/s (collection: 2.069s, learning 0.114s)
             Mean action noise std: 3.90
          Mean value_function loss: 38.6724
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 70.2442
                       Mean reward: 753.44
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.5761
    Episode_Reward/rotating_object: 154.4450
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.18s
                      Time elapsed: 00:50:41
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 44711 steps/s (collection: 2.084s, learning 0.115s)
             Mean action noise std: 3.90
          Mean value_function loss: 31.3234
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 70.2547
                       Mean reward: 811.84
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.5976
    Episode_Reward/rotating_object: 158.0824
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.20s
                      Time elapsed: 00:50:43
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 44848 steps/s (collection: 2.076s, learning 0.116s)
             Mean action noise std: 3.91
          Mean value_function loss: 37.4896
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 70.2612
                       Mean reward: 805.87
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.5915
    Episode_Reward/rotating_object: 156.8308
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.19s
                      Time elapsed: 00:50:45
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 44997 steps/s (collection: 2.072s, learning 0.113s)
             Mean action noise std: 3.91
          Mean value_function loss: 38.1601
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 70.2698
                       Mean reward: 772.70
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 1.6175
    Episode_Reward/rotating_object: 157.8543
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.18s
                      Time elapsed: 00:50:47
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 44881 steps/s (collection: 2.072s, learning 0.118s)
             Mean action noise std: 3.91
          Mean value_function loss: 36.6212
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 70.2786
                       Mean reward: 788.02
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 1.6181
    Episode_Reward/rotating_object: 157.5247
        Episode_Reward/action_rate: -0.0986
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.19s
                      Time elapsed: 00:50:50
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 44973 steps/s (collection: 2.066s, learning 0.120s)
             Mean action noise std: 3.91
          Mean value_function loss: 35.3674
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 70.2931
                       Mean reward: 782.82
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 1.6220
    Episode_Reward/rotating_object: 156.3542
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.19s
                      Time elapsed: 00:50:52
                               ETA: 00:06:29

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 44575 steps/s (collection: 2.091s, learning 0.115s)
             Mean action noise std: 3.91
          Mean value_function loss: 39.0528
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 70.3091
                       Mean reward: 787.74
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 1.5957
    Episode_Reward/rotating_object: 153.9872
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.21s
                      Time elapsed: 00:50:54
                               ETA: 00:06:27

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 44504 steps/s (collection: 2.094s, learning 0.115s)
             Mean action noise std: 3.92
          Mean value_function loss: 36.3145
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 70.3240
                       Mean reward: 801.76
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.6186
    Episode_Reward/rotating_object: 156.4688
        Episode_Reward/action_rate: -0.0978
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.21s
                      Time elapsed: 00:50:56
                               ETA: 00:06:25

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 44173 steps/s (collection: 2.102s, learning 0.123s)
             Mean action noise std: 3.92
          Mean value_function loss: 51.3038
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 70.3418
                       Mean reward: 785.41
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 1.5834
    Episode_Reward/rotating_object: 153.3973
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 2.23s
                      Time elapsed: 00:50:58
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 44067 steps/s (collection: 2.117s, learning 0.114s)
             Mean action noise std: 3.92
          Mean value_function loss: 44.1527
               Mean surrogate loss: 0.0317
                 Mean entropy loss: 70.3596
                       Mean reward: 772.79
               Mean episode length: 242.76
    Episode_Reward/reaching_object: 1.6204
    Episode_Reward/rotating_object: 156.5083
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 2.23s
                      Time elapsed: 00:51:01
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 44881 steps/s (collection: 2.076s, learning 0.114s)
             Mean action noise std: 3.92
          Mean value_function loss: 28.9786
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 70.3633
                       Mean reward: 793.46
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.6088
    Episode_Reward/rotating_object: 156.1364
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 2.19s
                      Time elapsed: 00:51:03
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 45420 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 3.92
          Mean value_function loss: 28.0593
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 70.3643
                       Mean reward: 787.79
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.6293
    Episode_Reward/rotating_object: 157.7194
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 2.16s
                      Time elapsed: 00:51:05
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 45412 steps/s (collection: 2.051s, learning 0.114s)
             Mean action noise std: 3.92
          Mean value_function loss: 29.2998
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 70.3676
                       Mean reward: 773.39
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.6018
    Episode_Reward/rotating_object: 156.7518
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 2.16s
                      Time elapsed: 00:51:07
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 44948 steps/s (collection: 2.072s, learning 0.115s)
             Mean action noise std: 3.93
          Mean value_function loss: 31.5478
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 70.3807
                       Mean reward: 813.81
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.5953
    Episode_Reward/rotating_object: 155.6727
        Episode_Reward/action_rate: -0.0984
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 2.19s
                      Time elapsed: 00:51:09
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 45377 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 3.93
          Mean value_function loss: 29.9583
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.3956
                       Mean reward: 806.46
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 1.6012
    Episode_Reward/rotating_object: 158.5133
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 2.17s
                      Time elapsed: 00:51:11
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 46075 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 3.93
          Mean value_function loss: 44.2411
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 70.4091
                       Mean reward: 784.67
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.5414
    Episode_Reward/rotating_object: 151.6839
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 2.13s
                      Time elapsed: 00:51:14
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 46182 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 3.93
          Mean value_function loss: 36.5455
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 70.4264
                       Mean reward: 793.85
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 1.5832
    Episode_Reward/rotating_object: 155.6819
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 2.13s
                      Time elapsed: 00:51:16
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 45906 steps/s (collection: 2.029s, learning 0.112s)
             Mean action noise std: 3.93
          Mean value_function loss: 32.0943
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.4420
                       Mean reward: 790.66
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.5895
    Episode_Reward/rotating_object: 156.3351
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.14s
                      Time elapsed: 00:51:18
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 45405 steps/s (collection: 2.039s, learning 0.126s)
             Mean action noise std: 3.94
          Mean value_function loss: 27.3572
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 70.4554
                       Mean reward: 804.41
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 1.5847
    Episode_Reward/rotating_object: 156.6598
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.17s
                      Time elapsed: 00:51:20
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 45744 steps/s (collection: 2.037s, learning 0.111s)
             Mean action noise std: 3.94
          Mean value_function loss: 38.0623
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 70.4664
                       Mean reward: 811.67
               Mean episode length: 247.12
    Episode_Reward/reaching_object: 1.5523
    Episode_Reward/rotating_object: 155.2814
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.15s
                      Time elapsed: 00:51:22
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 45598 steps/s (collection: 2.043s, learning 0.113s)
             Mean action noise std: 3.94
          Mean value_function loss: 33.8921
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 70.4827
                       Mean reward: 775.27
               Mean episode length: 242.82
    Episode_Reward/reaching_object: 1.5846
    Episode_Reward/rotating_object: 154.7489
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.16s
                      Time elapsed: 00:51:24
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 45719 steps/s (collection: 2.035s, learning 0.115s)
             Mean action noise std: 3.94
          Mean value_function loss: 41.9745
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 70.4992
                       Mean reward: 792.79
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.5699
    Episode_Reward/rotating_object: 155.0610
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.15s
                      Time elapsed: 00:51:26
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 45306 steps/s (collection: 2.057s, learning 0.113s)
             Mean action noise std: 3.95
          Mean value_function loss: 36.7786
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 70.5127
                       Mean reward: 799.00
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 1.6052
    Episode_Reward/rotating_object: 156.7348
        Episode_Reward/action_rate: -0.0989
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.17s
                      Time elapsed: 00:51:29
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 44999 steps/s (collection: 2.071s, learning 0.113s)
             Mean action noise std: 3.95
          Mean value_function loss: 38.5933
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 70.5253
                       Mean reward: 788.21
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.6021
    Episode_Reward/rotating_object: 154.7648
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.18s
                      Time elapsed: 00:51:31
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 45290 steps/s (collection: 2.057s, learning 0.114s)
             Mean action noise std: 3.95
          Mean value_function loss: 43.2889
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 70.5454
                       Mean reward: 760.29
               Mean episode length: 236.74
    Episode_Reward/reaching_object: 1.5810
    Episode_Reward/rotating_object: 153.0267
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.17s
                      Time elapsed: 00:51:33
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 44777 steps/s (collection: 2.082s, learning 0.114s)
             Mean action noise std: 3.95
          Mean value_function loss: 35.4408
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 70.5648
                       Mean reward: 786.64
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 1.6046
    Episode_Reward/rotating_object: 154.4225
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.20s
                      Time elapsed: 00:51:35
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 44940 steps/s (collection: 2.072s, learning 0.116s)
             Mean action noise std: 3.96
          Mean value_function loss: 36.8621
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 70.5789
                       Mean reward: 766.09
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.5960
    Episode_Reward/rotating_object: 155.0128
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.19s
                      Time elapsed: 00:51:37
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 44550 steps/s (collection: 2.089s, learning 0.118s)
             Mean action noise std: 3.96
          Mean value_function loss: 41.4193
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 70.5886
                       Mean reward: 776.88
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 1.6303
    Episode_Reward/rotating_object: 156.0755
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.21s
                      Time elapsed: 00:51:40
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 45016 steps/s (collection: 2.070s, learning 0.114s)
             Mean action noise std: 3.96
          Mean value_function loss: 36.0792
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 70.5997
                       Mean reward: 798.62
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.6102
    Episode_Reward/rotating_object: 155.1128
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.18s
                      Time elapsed: 00:51:42
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 45007 steps/s (collection: 2.067s, learning 0.117s)
             Mean action noise std: 3.96
          Mean value_function loss: 37.7063
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 70.6113
                       Mean reward: 805.85
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.6276
    Episode_Reward/rotating_object: 159.1791
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.18s
                      Time elapsed: 00:51:44
                               ETA: 00:05:34

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 44923 steps/s (collection: 2.071s, learning 0.117s)
             Mean action noise std: 3.97
          Mean value_function loss: 42.1396
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 70.6244
                       Mean reward: 773.16
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.5989
    Episode_Reward/rotating_object: 154.1786
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.19s
                      Time elapsed: 00:51:46
                               ETA: 00:05:32

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 44639 steps/s (collection: 2.086s, learning 0.116s)
             Mean action noise std: 3.97
          Mean value_function loss: 31.3432
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 70.6317
                       Mean reward: 782.20
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 1.6343
    Episode_Reward/rotating_object: 158.3646
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.20s
                      Time elapsed: 00:51:48
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 44004 steps/s (collection: 2.120s, learning 0.114s)
             Mean action noise std: 3.97
          Mean value_function loss: 43.6696
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 70.6433
                       Mean reward: 759.84
               Mean episode length: 236.96
    Episode_Reward/reaching_object: 1.6346
    Episode_Reward/rotating_object: 155.9966
        Episode_Reward/action_rate: -0.1004
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.23s
                      Time elapsed: 00:51:51
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 44359 steps/s (collection: 2.102s, learning 0.114s)
             Mean action noise std: 3.97
          Mean value_function loss: 31.0345
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 70.6536
                       Mean reward: 796.01
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.6351
    Episode_Reward/rotating_object: 156.9810
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.22s
                      Time elapsed: 00:51:53
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 44650 steps/s (collection: 2.081s, learning 0.120s)
             Mean action noise std: 3.97
          Mean value_function loss: 36.2039
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 70.6580
                       Mean reward: 799.76
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 1.6439
    Episode_Reward/rotating_object: 155.4090
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.20s
                      Time elapsed: 00:51:55
                               ETA: 00:05:23

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 44893 steps/s (collection: 2.073s, learning 0.117s)
             Mean action noise std: 3.97
          Mean value_function loss: 35.3955
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 70.6653
                       Mean reward: 792.47
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 1.6365
    Episode_Reward/rotating_object: 156.5925
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.19s
                      Time elapsed: 00:51:57
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 44746 steps/s (collection: 2.082s, learning 0.115s)
             Mean action noise std: 3.98
          Mean value_function loss: 40.8929
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 70.6755
                       Mean reward: 814.33
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 1.6494
    Episode_Reward/rotating_object: 158.1418
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.20s
                      Time elapsed: 00:51:59
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 45107 steps/s (collection: 2.066s, learning 0.113s)
             Mean action noise std: 3.98
          Mean value_function loss: 30.4619
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 70.6826
                       Mean reward: 812.56
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 1.6444
    Episode_Reward/rotating_object: 156.6169
        Episode_Reward/action_rate: -0.1008
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.18s
                      Time elapsed: 00:52:02
                               ETA: 00:05:16

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 45567 steps/s (collection: 2.044s, learning 0.113s)
             Mean action noise std: 3.98
          Mean value_function loss: 31.7370
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 70.6907
                       Mean reward: 815.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.6441
    Episode_Reward/rotating_object: 157.0164
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.16s
                      Time elapsed: 00:52:04
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 45474 steps/s (collection: 2.048s, learning 0.113s)
             Mean action noise std: 3.98
          Mean value_function loss: 41.7829
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 70.6988
                       Mean reward: 794.61
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.6354
    Episode_Reward/rotating_object: 154.9035
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.16s
                      Time elapsed: 00:52:06
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 45406 steps/s (collection: 2.052s, learning 0.113s)
             Mean action noise std: 3.98
          Mean value_function loss: 39.0614
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 70.7080
                       Mean reward: 787.48
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.6278
    Episode_Reward/rotating_object: 156.6460
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.16s
                      Time elapsed: 00:52:08
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 45548 steps/s (collection: 2.045s, learning 0.113s)
             Mean action noise std: 3.99
          Mean value_function loss: 37.7502
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 70.7250
                       Mean reward: 760.07
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 1.6192
    Episode_Reward/rotating_object: 153.3091
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.16s
                      Time elapsed: 00:52:10
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 45779 steps/s (collection: 2.034s, learning 0.113s)
             Mean action noise std: 3.99
          Mean value_function loss: 33.6018
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 70.7334
                       Mean reward: 779.66
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.6530
    Episode_Reward/rotating_object: 156.0303
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.15s
                      Time elapsed: 00:52:12
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 45484 steps/s (collection: 2.049s, learning 0.112s)
             Mean action noise std: 3.99
          Mean value_function loss: 41.2511
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.7441
                       Mean reward: 793.68
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.6127
    Episode_Reward/rotating_object: 155.1456
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.16s
                      Time elapsed: 00:52:15
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 45376 steps/s (collection: 2.053s, learning 0.113s)
             Mean action noise std: 3.99
          Mean value_function loss: 35.0454
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 70.7641
                       Mean reward: 788.20
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 1.6373
    Episode_Reward/rotating_object: 158.0720
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.17s
                      Time elapsed: 00:52:17
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 45117 steps/s (collection: 2.062s, learning 0.117s)
             Mean action noise std: 4.00
          Mean value_function loss: 32.6351
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 70.7832
                       Mean reward: 798.21
               Mean episode length: 247.22
    Episode_Reward/reaching_object: 1.6364
    Episode_Reward/rotating_object: 155.6035
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.18s
                      Time elapsed: 00:52:19
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 44476 steps/s (collection: 2.096s, learning 0.114s)
             Mean action noise std: 4.00
          Mean value_function loss: 29.4423
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.7995
                       Mean reward: 794.87
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 1.6281
    Episode_Reward/rotating_object: 155.6912
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.21s
                      Time elapsed: 00:52:21
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 45252 steps/s (collection: 2.060s, learning 0.113s)
             Mean action noise std: 4.00
          Mean value_function loss: 36.0853
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 70.8095
                       Mean reward: 809.80
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 1.6299
    Episode_Reward/rotating_object: 157.9670
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.17s
                      Time elapsed: 00:52:23
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 45614 steps/s (collection: 2.040s, learning 0.115s)
             Mean action noise std: 4.00
          Mean value_function loss: 40.2521
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 70.8234
                       Mean reward: 793.03
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.6162
    Episode_Reward/rotating_object: 156.0328
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.16s
                      Time elapsed: 00:52:25
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 45220 steps/s (collection: 2.062s, learning 0.112s)
             Mean action noise std: 4.01
          Mean value_function loss: 42.1746
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 70.8447
                       Mean reward: 804.61
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 1.6228
    Episode_Reward/rotating_object: 156.7287
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.17s
                      Time elapsed: 00:52:28
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 45369 steps/s (collection: 2.051s, learning 0.116s)
             Mean action noise std: 4.01
          Mean value_function loss: 37.0709
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 70.8716
                       Mean reward: 788.39
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.6335
    Episode_Reward/rotating_object: 159.2559
        Episode_Reward/action_rate: -0.1031
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.17s
                      Time elapsed: 00:52:30
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 44556 steps/s (collection: 2.080s, learning 0.127s)
             Mean action noise std: 4.01
          Mean value_function loss: 39.4165
               Mean surrogate loss: 0.0362
                 Mean entropy loss: 70.8906
                       Mean reward: 796.89
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 1.6213
    Episode_Reward/rotating_object: 157.0482
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.21s
                      Time elapsed: 00:52:32
                               ETA: 00:04:43

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 45452 steps/s (collection: 2.051s, learning 0.112s)
             Mean action noise std: 4.01
          Mean value_function loss: 36.3081
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 70.8931
                       Mean reward: 801.79
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.6182
    Episode_Reward/rotating_object: 155.1131
        Episode_Reward/action_rate: -0.1022
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.16s
                      Time elapsed: 00:52:34
                               ETA: 00:04:41

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 45439 steps/s (collection: 2.049s, learning 0.114s)
             Mean action noise std: 4.01
          Mean value_function loss: 45.2544
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.8970
                       Mean reward: 779.34
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 1.6097
    Episode_Reward/rotating_object: 154.2513
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.16s
                      Time elapsed: 00:52:36
                               ETA: 00:04:39

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 45252 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 4.02
          Mean value_function loss: 43.8671
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 70.9073
                       Mean reward: 795.94
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 1.5993
    Episode_Reward/rotating_object: 154.0507
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.17s
                      Time elapsed: 00:52:38
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 45777 steps/s (collection: 2.032s, learning 0.116s)
             Mean action noise std: 4.02
          Mean value_function loss: 49.1431
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.9293
                       Mean reward: 815.76
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.5875
    Episode_Reward/rotating_object: 154.6797
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.15s
                      Time elapsed: 00:52:41
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 45642 steps/s (collection: 2.029s, learning 0.125s)
             Mean action noise std: 4.02
          Mean value_function loss: 35.2188
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 70.9629
                       Mean reward: 802.38
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 1.6064
    Episode_Reward/rotating_object: 157.5117
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.15s
                      Time elapsed: 00:52:43
                               ETA: 00:04:32

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 45490 steps/s (collection: 2.049s, learning 0.112s)
             Mean action noise std: 4.03
          Mean value_function loss: 39.9639
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 70.9829
                       Mean reward: 804.26
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.5729
    Episode_Reward/rotating_object: 155.1137
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.16s
                      Time elapsed: 00:52:45
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 45646 steps/s (collection: 2.033s, learning 0.121s)
             Mean action noise std: 4.03
          Mean value_function loss: 35.2873
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.0019
                       Mean reward: 792.47
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.5722
    Episode_Reward/rotating_object: 156.3791
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.15s
                      Time elapsed: 00:52:47
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 45154 steps/s (collection: 2.064s, learning 0.113s)
             Mean action noise std: 4.03
          Mean value_function loss: 43.2444
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.0241
                       Mean reward: 782.65
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.5595
    Episode_Reward/rotating_object: 156.5472
        Episode_Reward/action_rate: -0.1041
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.18s
                      Time elapsed: 00:52:49
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 45685 steps/s (collection: 2.034s, learning 0.118s)
             Mean action noise std: 4.04
          Mean value_function loss: 32.0695
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.0438
                       Mean reward: 781.54
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 1.5549
    Episode_Reward/rotating_object: 156.9493
        Episode_Reward/action_rate: -0.1044
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.15s
                      Time elapsed: 00:52:51
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 45112 steps/s (collection: 2.043s, learning 0.136s)
             Mean action noise std: 4.04
          Mean value_function loss: 41.2079
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 71.0627
                       Mean reward: 776.81
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.5221
    Episode_Reward/rotating_object: 154.6897
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.18s
                      Time elapsed: 00:52:54
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 44015 steps/s (collection: 2.120s, learning 0.114s)
             Mean action noise std: 4.04
          Mean value_function loss: 33.3732
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 71.0768
                       Mean reward: 788.70
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 1.5442
    Episode_Reward/rotating_object: 156.6583
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.23s
                      Time elapsed: 00:52:56
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 46000 steps/s (collection: 2.023s, learning 0.114s)
             Mean action noise std: 4.04
          Mean value_function loss: 33.0210
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.0936
                       Mean reward: 765.37
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 1.5362
    Episode_Reward/rotating_object: 151.8477
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.14s
                      Time elapsed: 00:52:58
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 45559 steps/s (collection: 2.044s, learning 0.114s)
             Mean action noise std: 4.05
          Mean value_function loss: 35.7532
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 71.1106
                       Mean reward: 753.11
               Mean episode length: 232.85
    Episode_Reward/reaching_object: 1.5383
    Episode_Reward/rotating_object: 153.6824
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.16s
                      Time elapsed: 00:53:00
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 45306 steps/s (collection: 2.051s, learning 0.119s)
             Mean action noise std: 4.05
          Mean value_function loss: 43.0294
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 71.1283
                       Mean reward: 773.33
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 1.5545
    Episode_Reward/rotating_object: 156.2157
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.17s
                      Time elapsed: 00:53:02
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 45472 steps/s (collection: 2.049s, learning 0.113s)
             Mean action noise std: 4.05
          Mean value_function loss: 41.5209
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 71.1477
                       Mean reward: 761.65
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.5386
    Episode_Reward/rotating_object: 153.8501
        Episode_Reward/action_rate: -0.1043
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.16s
                      Time elapsed: 00:53:04
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 45680 steps/s (collection: 2.037s, learning 0.115s)
             Mean action noise std: 4.06
          Mean value_function loss: 28.5947
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 71.1752
                       Mean reward: 798.09
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.5476
    Episode_Reward/rotating_object: 153.8290
        Episode_Reward/action_rate: -0.1052
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.15s
                      Time elapsed: 00:53:07
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 44525 steps/s (collection: 2.095s, learning 0.113s)
             Mean action noise std: 4.06
          Mean value_function loss: 39.9356
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 71.1963
                       Mean reward: 754.23
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.5654
    Episode_Reward/rotating_object: 155.3546
        Episode_Reward/action_rate: -0.1054
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.21s
                      Time elapsed: 00:53:09
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 45155 steps/s (collection: 2.064s, learning 0.113s)
             Mean action noise std: 4.06
          Mean value_function loss: 34.4837
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 71.2120
                       Mean reward: 775.86
               Mean episode length: 239.03
    Episode_Reward/reaching_object: 1.5651
    Episode_Reward/rotating_object: 155.8305
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.18s
                      Time elapsed: 00:53:11
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 44800 steps/s (collection: 2.082s, learning 0.112s)
             Mean action noise std: 4.06
          Mean value_function loss: 29.7902
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 71.2218
                       Mean reward: 808.05
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 1.6046
    Episode_Reward/rotating_object: 159.1163
        Episode_Reward/action_rate: -0.1072
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.19s
                      Time elapsed: 00:53:13
                               ETA: 00:04:00

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 45081 steps/s (collection: 2.053s, learning 0.128s)
             Mean action noise std: 4.06
          Mean value_function loss: 44.2675
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 71.2314
                       Mean reward: 777.51
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.5764
    Episode_Reward/rotating_object: 156.9815
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.18s
                      Time elapsed: 00:53:15
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 44511 steps/s (collection: 2.077s, learning 0.131s)
             Mean action noise std: 4.07
          Mean value_function loss: 31.9123
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 71.2399
                       Mean reward: 769.24
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.6027
    Episode_Reward/rotating_object: 157.4925
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.21s
                      Time elapsed: 00:53:18
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 45433 steps/s (collection: 2.049s, learning 0.114s)
             Mean action noise std: 4.07
          Mean value_function loss: 37.8569
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.2528
                       Mean reward: 789.14
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.5766
    Episode_Reward/rotating_object: 154.9523
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.16s
                      Time elapsed: 00:53:20
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 45528 steps/s (collection: 2.045s, learning 0.114s)
             Mean action noise std: 4.07
          Mean value_function loss: 30.6381
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 71.2721
                       Mean reward: 791.59
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.6077
    Episode_Reward/rotating_object: 158.6637
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.16s
                      Time elapsed: 00:53:22
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 44969 steps/s (collection: 2.054s, learning 0.132s)
             Mean action noise std: 4.07
          Mean value_function loss: 29.9949
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 71.2864
                       Mean reward: 790.79
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 1.6122
    Episode_Reward/rotating_object: 156.9936
        Episode_Reward/action_rate: -0.1070
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.19s
                      Time elapsed: 00:53:24
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 45278 steps/s (collection: 2.056s, learning 0.115s)
             Mean action noise std: 4.08
          Mean value_function loss: 26.5882
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 71.2964
                       Mean reward: 793.66
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.6089
    Episode_Reward/rotating_object: 156.8345
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.17s
                      Time elapsed: 00:53:26
                               ETA: 00:03:46

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 45085 steps/s (collection: 2.059s, learning 0.122s)
             Mean action noise std: 4.08
          Mean value_function loss: 33.0069
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 71.3053
                       Mean reward: 807.56
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.6172
    Episode_Reward/rotating_object: 160.0732
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.18s
                      Time elapsed: 00:53:28
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 45167 steps/s (collection: 2.064s, learning 0.112s)
             Mean action noise std: 4.08
          Mean value_function loss: 37.0001
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 71.3233
                       Mean reward: 781.76
               Mean episode length: 239.77
    Episode_Reward/reaching_object: 1.6131
    Episode_Reward/rotating_object: 156.4662
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.18s
                      Time elapsed: 00:53:31
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 44595 steps/s (collection: 2.087s, learning 0.118s)
             Mean action noise std: 4.08
          Mean value_function loss: 41.3481
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 71.3395
                       Mean reward: 760.06
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 1.5982
    Episode_Reward/rotating_object: 155.5624
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.20s
                      Time elapsed: 00:53:33
                               ETA: 00:03:39

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 44665 steps/s (collection: 2.087s, learning 0.114s)
             Mean action noise std: 4.09
          Mean value_function loss: 42.3089
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 71.3497
                       Mean reward: 777.41
               Mean episode length: 236.65
    Episode_Reward/reaching_object: 1.6092
    Episode_Reward/rotating_object: 155.2689
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.20s
                      Time elapsed: 00:53:35
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 44729 steps/s (collection: 2.081s, learning 0.116s)
             Mean action noise std: 4.09
          Mean value_function loss: 29.0951
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 71.3655
                       Mean reward: 806.99
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.6224
    Episode_Reward/rotating_object: 157.2190
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.20s
                      Time elapsed: 00:53:37
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 45067 steps/s (collection: 2.062s, learning 0.119s)
             Mean action noise std: 4.09
          Mean value_function loss: 30.8533
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.3758
                       Mean reward: 785.85
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 1.6350
    Episode_Reward/rotating_object: 154.7331
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.18s
                      Time elapsed: 00:53:39
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 45018 steps/s (collection: 2.069s, learning 0.114s)
             Mean action noise std: 4.09
          Mean value_function loss: 36.9133
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 71.3907
                       Mean reward: 777.99
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 1.6290
    Episode_Reward/rotating_object: 156.5589
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.18s
                      Time elapsed: 00:53:42
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 45854 steps/s (collection: 2.030s, learning 0.114s)
             Mean action noise std: 4.10
          Mean value_function loss: 38.4255
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 71.4071
                       Mean reward: 799.52
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.6124
    Episode_Reward/rotating_object: 156.8712
        Episode_Reward/action_rate: -0.1063
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.14s
                      Time elapsed: 00:53:44
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 45527 steps/s (collection: 2.041s, learning 0.118s)
             Mean action noise std: 4.10
          Mean value_function loss: 39.1531
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 71.4204
                       Mean reward: 791.70
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.6015
    Episode_Reward/rotating_object: 154.3996
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.16s
                      Time elapsed: 00:53:46
                               ETA: 00:03:25

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 45199 steps/s (collection: 2.062s, learning 0.113s)
             Mean action noise std: 4.10
          Mean value_function loss: 37.6578
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 71.4278
                       Mean reward: 795.34
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.6342
    Episode_Reward/rotating_object: 157.0901
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.17s
                      Time elapsed: 00:53:48
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 46057 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 4.10
          Mean value_function loss: 27.0781
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 71.4417
                       Mean reward: 805.72
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 1.6536
    Episode_Reward/rotating_object: 158.3164
        Episode_Reward/action_rate: -0.1085
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.13s
                      Time elapsed: 00:53:50
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 45377 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 4.10
          Mean value_function loss: 29.7790
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 71.4498
                       Mean reward: 778.38
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 1.6391
    Episode_Reward/rotating_object: 156.3836
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.17s
                      Time elapsed: 00:53:52
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 45683 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 4.10
          Mean value_function loss: 40.6032
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 71.4510
                       Mean reward: 759.74
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.6030
    Episode_Reward/rotating_object: 154.4834
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.15s
                      Time elapsed: 00:53:54
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 45380 steps/s (collection: 2.044s, learning 0.122s)
             Mean action noise std: 4.10
          Mean value_function loss: 30.6404
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 71.4548
                       Mean reward: 796.34
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.6269
    Episode_Reward/rotating_object: 158.3739
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.17s
                      Time elapsed: 00:53:57
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 44893 steps/s (collection: 2.066s, learning 0.124s)
             Mean action noise std: 4.11
          Mean value_function loss: 28.8069
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 71.4640
                       Mean reward: 820.39
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 1.6205
    Episode_Reward/rotating_object: 156.8970
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.19s
                      Time elapsed: 00:53:59
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 45515 steps/s (collection: 2.048s, learning 0.112s)
             Mean action noise std: 4.11
          Mean value_function loss: 33.2559
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 71.4800
                       Mean reward: 807.17
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.6293
    Episode_Reward/rotating_object: 159.8542
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.16s
                      Time elapsed: 00:54:01
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 45088 steps/s (collection: 2.063s, learning 0.117s)
             Mean action noise std: 4.11
          Mean value_function loss: 39.9708
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 71.4958
                       Mean reward: 820.94
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.6172
    Episode_Reward/rotating_object: 158.0466
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.18s
                      Time elapsed: 00:54:03
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 45001 steps/s (collection: 2.067s, learning 0.117s)
             Mean action noise std: 4.12
          Mean value_function loss: 38.3694
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 71.5180
                       Mean reward: 779.41
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.6099
    Episode_Reward/rotating_object: 155.1419
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.18s
                      Time elapsed: 00:54:05
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 45422 steps/s (collection: 2.051s, learning 0.113s)
             Mean action noise std: 4.12
          Mean value_function loss: 32.8377
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.5316
                       Mean reward: 791.62
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.6237
    Episode_Reward/rotating_object: 156.7270
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.16s
                      Time elapsed: 00:54:08
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 45121 steps/s (collection: 2.063s, learning 0.116s)
             Mean action noise std: 4.12
          Mean value_function loss: 27.2728
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.5427
                       Mean reward: 825.06
               Mean episode length: 249.40
    Episode_Reward/reaching_object: 1.6471
    Episode_Reward/rotating_object: 161.1855
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.18s
                      Time elapsed: 00:54:10
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 45449 steps/s (collection: 2.049s, learning 0.114s)
             Mean action noise std: 4.12
          Mean value_function loss: 30.5740
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 71.5589
                       Mean reward: 792.54
               Mean episode length: 242.76
    Episode_Reward/reaching_object: 1.6465
    Episode_Reward/rotating_object: 159.4688
        Episode_Reward/action_rate: -0.1099
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.16s
                      Time elapsed: 00:54:12
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 45888 steps/s (collection: 2.028s, learning 0.114s)
             Mean action noise std: 4.12
          Mean value_function loss: 22.3738
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 71.5707
                       Mean reward: 829.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.6299
    Episode_Reward/rotating_object: 158.4680
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.14s
                      Time elapsed: 00:54:14
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 45382 steps/s (collection: 2.052s, learning 0.114s)
             Mean action noise std: 4.13
          Mean value_function loss: 26.2954
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 71.5758
                       Mean reward: 818.66
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.6446
    Episode_Reward/rotating_object: 158.9192
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.17s
                      Time elapsed: 00:54:16
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 45579 steps/s (collection: 2.043s, learning 0.114s)
             Mean action noise std: 4.13
          Mean value_function loss: 27.3614
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 71.5886
                       Mean reward: 800.38
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.6347
    Episode_Reward/rotating_object: 160.1380
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.16s
                      Time elapsed: 00:54:18
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 45575 steps/s (collection: 2.043s, learning 0.114s)
             Mean action noise std: 4.13
          Mean value_function loss: 34.7373
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 71.6079
                       Mean reward: 787.31
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 1.6264
    Episode_Reward/rotating_object: 157.9579
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.16s
                      Time elapsed: 00:54:21
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 45176 steps/s (collection: 2.063s, learning 0.113s)
             Mean action noise std: 4.13
          Mean value_function loss: 35.5934
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.6187
                       Mean reward: 807.06
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.6158
    Episode_Reward/rotating_object: 156.3259
        Episode_Reward/action_rate: -0.1094
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.18s
                      Time elapsed: 00:54:23
                               ETA: 00:02:46

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 45295 steps/s (collection: 2.052s, learning 0.118s)
             Mean action noise std: 4.14
          Mean value_function loss: 31.5094
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 71.6338
                       Mean reward: 797.88
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 1.6364
    Episode_Reward/rotating_object: 158.5680
        Episode_Reward/action_rate: -0.1106
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.17s
                      Time elapsed: 00:54:25
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 45560 steps/s (collection: 2.044s, learning 0.114s)
             Mean action noise std: 4.14
          Mean value_function loss: 31.4616
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 71.6545
                       Mean reward: 807.14
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.6178
    Episode_Reward/rotating_object: 158.0088
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.16s
                      Time elapsed: 00:54:27
                               ETA: 00:02:42

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 45403 steps/s (collection: 2.050s, learning 0.115s)
             Mean action noise std: 4.14
          Mean value_function loss: 29.3005
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 71.6712
                       Mean reward: 795.31
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 1.6358
    Episode_Reward/rotating_object: 158.0511
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.17s
                      Time elapsed: 00:54:29
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 45744 steps/s (collection: 2.036s, learning 0.113s)
             Mean action noise std: 4.15
          Mean value_function loss: 39.1763
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 71.6827
                       Mean reward: 776.18
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 1.6485
    Episode_Reward/rotating_object: 159.9341
        Episode_Reward/action_rate: -0.1107
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.15s
                      Time elapsed: 00:54:31
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 45992 steps/s (collection: 2.023s, learning 0.115s)
             Mean action noise std: 4.15
          Mean value_function loss: 23.4621
               Mean surrogate loss: 0.0098
                 Mean entropy loss: 71.6888
                       Mean reward: 809.12
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.6683
    Episode_Reward/rotating_object: 160.2515
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.14s
                      Time elapsed: 00:54:33
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 45786 steps/s (collection: 2.034s, learning 0.113s)
             Mean action noise std: 4.15
          Mean value_function loss: 23.5182
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 71.6896
                       Mean reward: 809.26
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.6473
    Episode_Reward/rotating_object: 160.1637
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.15s
                      Time elapsed: 00:54:36
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 45817 steps/s (collection: 2.032s, learning 0.114s)
             Mean action noise std: 4.15
          Mean value_function loss: 28.9695
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 71.6919
                       Mean reward: 797.17
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.6434
    Episode_Reward/rotating_object: 159.6802
        Episode_Reward/action_rate: -0.1107
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.15s
                      Time elapsed: 00:54:38
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 46092 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 4.15
          Mean value_function loss: 27.5828
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 71.7023
                       Mean reward: 803.49
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 1.6365
    Episode_Reward/rotating_object: 157.5492
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.13s
                      Time elapsed: 00:54:40
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 45985 steps/s (collection: 2.013s, learning 0.124s)
             Mean action noise std: 4.15
          Mean value_function loss: 27.9708
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 71.7187
                       Mean reward: 817.09
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.6538
    Episode_Reward/rotating_object: 160.9958
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.14s
                      Time elapsed: 00:54:42
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 46192 steps/s (collection: 2.015s, learning 0.113s)
             Mean action noise std: 4.16
          Mean value_function loss: 37.3632
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.7333
                       Mean reward: 792.72
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 1.5992
    Episode_Reward/rotating_object: 156.0029
        Episode_Reward/action_rate: -0.1096
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.13s
                      Time elapsed: 00:54:44
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 45683 steps/s (collection: 2.032s, learning 0.119s)
             Mean action noise std: 4.16
          Mean value_function loss: 21.3966
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.7471
                       Mean reward: 798.17
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.6420
    Episode_Reward/rotating_object: 161.1150
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.15s
                      Time elapsed: 00:54:46
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 45270 steps/s (collection: 2.060s, learning 0.112s)
             Mean action noise std: 4.16
          Mean value_function loss: 31.7622
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 71.7571
                       Mean reward: 818.76
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.6335
    Episode_Reward/rotating_object: 161.3156
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.17s
                      Time elapsed: 00:54:48
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 45103 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 4.16
          Mean value_function loss: 30.4880
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 71.7664
                       Mean reward: 805.53
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 1.6198
    Episode_Reward/rotating_object: 158.3027
        Episode_Reward/action_rate: -0.1117
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.18s
                      Time elapsed: 00:54:51
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 45270 steps/s (collection: 2.043s, learning 0.129s)
             Mean action noise std: 4.16
          Mean value_function loss: 24.9391
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 71.7808
                       Mean reward: 800.11
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 1.6372
    Episode_Reward/rotating_object: 160.5957
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.17s
                      Time elapsed: 00:54:53
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 45240 steps/s (collection: 2.044s, learning 0.129s)
             Mean action noise std: 4.17
          Mean value_function loss: 37.7116
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 71.7975
                       Mean reward: 820.04
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 1.6018
    Episode_Reward/rotating_object: 157.2986
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.17s
                      Time elapsed: 00:54:55
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 45004 steps/s (collection: 2.059s, learning 0.125s)
             Mean action noise std: 4.17
          Mean value_function loss: 28.7907
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 71.8137
                       Mean reward: 812.40
               Mean episode length: 248.56
    Episode_Reward/reaching_object: 1.6084
    Episode_Reward/rotating_object: 157.6454
        Episode_Reward/action_rate: -0.1117
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.18s
                      Time elapsed: 00:54:57
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 45060 steps/s (collection: 2.067s, learning 0.115s)
             Mean action noise std: 4.17
          Mean value_function loss: 27.2170
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 71.8280
                       Mean reward: 823.54
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 1.6063
    Episode_Reward/rotating_object: 156.3448
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.18s
                      Time elapsed: 00:54:59
                               ETA: 00:02:07

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 45722 steps/s (collection: 2.034s, learning 0.116s)
             Mean action noise std: 4.17
          Mean value_function loss: 27.9485
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 71.8392
                       Mean reward: 795.82
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.6372
    Episode_Reward/rotating_object: 160.2369
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.15s
                      Time elapsed: 00:55:02
                               ETA: 00:02:05

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 45434 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 41.5362
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.8509
                       Mean reward: 811.43
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 1.6050
    Episode_Reward/rotating_object: 156.4259
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.16s
                      Time elapsed: 00:55:04
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 45610 steps/s (collection: 2.041s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 34.0995
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.8624
                       Mean reward: 790.23
               Mean episode length: 243.19
    Episode_Reward/reaching_object: 1.6297
    Episode_Reward/rotating_object: 156.5234
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.16s
                      Time elapsed: 00:55:06
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 44973 steps/s (collection: 2.073s, learning 0.113s)
             Mean action noise std: 4.18
          Mean value_function loss: 40.7828
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 71.8741
                       Mean reward: 803.48
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 1.6183
    Episode_Reward/rotating_object: 157.8964
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.19s
                      Time elapsed: 00:55:08
                               ETA: 00:01:58

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 45211 steps/s (collection: 2.060s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 45.4196
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 71.8845
                       Mean reward: 813.09
               Mean episode length: 247.27
    Episode_Reward/reaching_object: 1.6045
    Episode_Reward/rotating_object: 155.2866
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.17s
                      Time elapsed: 00:55:10
                               ETA: 00:01:56

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 45226 steps/s (collection: 2.060s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 29.0833
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 71.8881
                       Mean reward: 808.61
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.6482
    Episode_Reward/rotating_object: 159.8940
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.17s
                      Time elapsed: 00:55:12
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 45344 steps/s (collection: 2.054s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 33.3460
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.8950
                       Mean reward: 785.95
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.6089
    Episode_Reward/rotating_object: 156.4664
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.17s
                      Time elapsed: 00:55:15
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 45601 steps/s (collection: 2.040s, learning 0.116s)
             Mean action noise std: 4.19
          Mean value_function loss: 35.5072
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.9103
                       Mean reward: 798.60
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.6485
    Episode_Reward/rotating_object: 160.0730
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.16s
                      Time elapsed: 00:55:17
                               ETA: 00:01:49

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 45465 steps/s (collection: 2.047s, learning 0.115s)
             Mean action noise std: 4.19
          Mean value_function loss: 32.2794
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.9244
                       Mean reward: 815.02
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.6462
    Episode_Reward/rotating_object: 160.4405
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.16s
                      Time elapsed: 00:55:19
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 46126 steps/s (collection: 2.018s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 30.1301
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 71.9365
                       Mean reward: 793.21
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.6315
    Episode_Reward/rotating_object: 156.8512
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.13s
                      Time elapsed: 00:55:21
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 45978 steps/s (collection: 2.026s, learning 0.112s)
             Mean action noise std: 4.19
          Mean value_function loss: 26.3740
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 71.9471
                       Mean reward: 799.00
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 1.6480
    Episode_Reward/rotating_object: 158.8082
        Episode_Reward/action_rate: -0.1133
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.14s
                      Time elapsed: 00:55:23
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 45816 steps/s (collection: 2.033s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 25.1517
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 71.9571
                       Mean reward: 826.92
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 1.6408
    Episode_Reward/rotating_object: 161.0503
        Episode_Reward/action_rate: -0.1137
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.15s
                      Time elapsed: 00:55:25
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 45822 steps/s (collection: 2.031s, learning 0.115s)
             Mean action noise std: 4.20
          Mean value_function loss: 22.6499
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 71.9643
                       Mean reward: 803.01
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 1.6536
    Episode_Reward/rotating_object: 160.7012
        Episode_Reward/action_rate: -0.1133
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.15s
                      Time elapsed: 00:55:27
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 45802 steps/s (collection: 2.020s, learning 0.127s)
             Mean action noise std: 4.20
          Mean value_function loss: 34.7219
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 71.9773
                       Mean reward: 780.31
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.6297
    Episode_Reward/rotating_object: 156.9096
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.15s
                      Time elapsed: 00:55:30
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 45991 steps/s (collection: 2.024s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 29.4466
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 71.9952
                       Mean reward: 800.27
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 1.6250
    Episode_Reward/rotating_object: 157.5085
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.14s
                      Time elapsed: 00:55:32
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 45970 steps/s (collection: 2.026s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 28.6870
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 72.0083
                       Mean reward: 807.40
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.6220
    Episode_Reward/rotating_object: 159.3200
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.14s
                      Time elapsed: 00:55:34
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 45689 steps/s (collection: 2.037s, learning 0.115s)
             Mean action noise std: 4.21
          Mean value_function loss: 29.4898
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 72.0191
                       Mean reward: 815.44
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.6376
    Episode_Reward/rotating_object: 159.2194
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.15s
                      Time elapsed: 00:55:36
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 44941 steps/s (collection: 2.066s, learning 0.122s)
             Mean action noise std: 4.21
          Mean value_function loss: 32.7924
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 72.0316
                       Mean reward: 794.29
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 1.6263
    Episode_Reward/rotating_object: 157.9523
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.19s
                      Time elapsed: 00:55:38
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 44549 steps/s (collection: 2.093s, learning 0.114s)
             Mean action noise std: 4.21
          Mean value_function loss: 21.9052
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 72.0391
                       Mean reward: 821.58
               Mean episode length: 249.79
    Episode_Reward/reaching_object: 1.6547
    Episode_Reward/rotating_object: 161.9835
        Episode_Reward/action_rate: -0.1148
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.21s
                      Time elapsed: 00:55:40
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 46044 steps/s (collection: 2.022s, learning 0.113s)
             Mean action noise std: 4.21
          Mean value_function loss: 35.4033
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 72.0440
                       Mean reward: 801.37
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.6103
    Episode_Reward/rotating_object: 157.4597
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.13s
                      Time elapsed: 00:55:43
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 45743 steps/s (collection: 2.022s, learning 0.127s)
             Mean action noise std: 4.21
          Mean value_function loss: 31.6390
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 72.0568
                       Mean reward: 777.21
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 1.6204
    Episode_Reward/rotating_object: 157.3368
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.15s
                      Time elapsed: 00:55:45
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 45505 steps/s (collection: 2.032s, learning 0.128s)
             Mean action noise std: 4.22
          Mean value_function loss: 36.8605
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 72.0795
                       Mean reward: 785.11
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.6223
    Episode_Reward/rotating_object: 157.9837
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.16s
                      Time elapsed: 00:55:47
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 45201 steps/s (collection: 2.060s, learning 0.115s)
             Mean action noise std: 4.22
          Mean value_function loss: 45.4644
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 72.1038
                       Mean reward: 817.64
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 1.6154
    Episode_Reward/rotating_object: 156.8990
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.17s
                      Time elapsed: 00:55:49
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 45714 steps/s (collection: 2.037s, learning 0.113s)
             Mean action noise std: 4.22
          Mean value_function loss: 32.5328
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 72.1175
                       Mean reward: 820.48
               Mean episode length: 247.29
    Episode_Reward/reaching_object: 1.6013
    Episode_Reward/rotating_object: 157.0014
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.15s
                      Time elapsed: 00:55:51
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 44852 steps/s (collection: 2.079s, learning 0.113s)
             Mean action noise std: 4.22
          Mean value_function loss: 26.5075
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.1260
                       Mean reward: 818.26
               Mean episode length: 247.63
    Episode_Reward/reaching_object: 1.6336
    Episode_Reward/rotating_object: 159.6735
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.19s
                      Time elapsed: 00:55:53
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 44723 steps/s (collection: 2.084s, learning 0.114s)
             Mean action noise std: 4.23
          Mean value_function loss: 32.8132
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 72.1407
                       Mean reward: 787.14
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.6166
    Episode_Reward/rotating_object: 159.0357
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.20s
                      Time elapsed: 00:55:56
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 44980 steps/s (collection: 2.069s, learning 0.116s)
             Mean action noise std: 4.23
          Mean value_function loss: 31.5744
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 72.1596
                       Mean reward: 801.69
               Mean episode length: 243.19
    Episode_Reward/reaching_object: 1.6244
    Episode_Reward/rotating_object: 159.7264
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.19s
                      Time elapsed: 00:55:58
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 45600 steps/s (collection: 2.039s, learning 0.117s)
             Mean action noise std: 4.23
          Mean value_function loss: 39.5461
               Mean surrogate loss: 0.0051
                 Mean entropy loss: 72.1837
                       Mean reward: 765.97
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 1.6133
    Episode_Reward/rotating_object: 158.0049
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.16s
                      Time elapsed: 00:56:00
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 45236 steps/s (collection: 2.057s, learning 0.116s)
             Mean action noise std: 4.23
          Mean value_function loss: 31.8437
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 72.1961
                       Mean reward: 775.12
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.6279
    Episode_Reward/rotating_object: 158.6113
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.17s
                      Time elapsed: 00:56:02
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 45632 steps/s (collection: 2.039s, learning 0.115s)
             Mean action noise std: 4.24
          Mean value_function loss: 27.5449
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 72.2010
                       Mean reward: 801.11
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 1.6287
    Episode_Reward/rotating_object: 158.1097
        Episode_Reward/action_rate: -0.1137
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.15s
                      Time elapsed: 00:56:04
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 45869 steps/s (collection: 2.030s, learning 0.114s)
             Mean action noise std: 4.24
          Mean value_function loss: 22.8332
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 72.2091
                       Mean reward: 819.43
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 1.6239
    Episode_Reward/rotating_object: 159.0665
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.14s
                      Time elapsed: 00:56:06
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 45571 steps/s (collection: 2.045s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 20.4051
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 72.2202
                       Mean reward: 796.67
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 1.6191
    Episode_Reward/rotating_object: 161.0888
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.16s
                      Time elapsed: 00:56:09
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 46395 steps/s (collection: 2.006s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 21.2967
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 72.2312
                       Mean reward: 813.25
               Mean episode length: 246.99
    Episode_Reward/reaching_object: 1.6239
    Episode_Reward/rotating_object: 160.7310
        Episode_Reward/action_rate: -0.1150
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.12s
                      Time elapsed: 00:56:11
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 46437 steps/s (collection: 2.004s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 23.8285
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 72.2392
                       Mean reward: 820.14
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.6269
    Episode_Reward/rotating_object: 160.2224
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.12s
                      Time elapsed: 00:56:13
                               ETA: 00:00:50

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 46069 steps/s (collection: 2.020s, learning 0.114s)
             Mean action noise std: 4.24
          Mean value_function loss: 23.0332
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 72.2451
                       Mean reward: 806.72
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 1.6147
    Episode_Reward/rotating_object: 161.3105
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.13s
                      Time elapsed: 00:56:15
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 45983 steps/s (collection: 2.025s, learning 0.113s)
             Mean action noise std: 4.25
          Mean value_function loss: 23.0237
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 72.2571
                       Mean reward: 825.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.6178
    Episode_Reward/rotating_object: 161.5666
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.14s
                      Time elapsed: 00:56:17
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 45943 steps/s (collection: 2.027s, learning 0.112s)
             Mean action noise std: 4.25
          Mean value_function loss: 31.8362
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 72.2685
                       Mean reward: 790.21
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.5960
    Episode_Reward/rotating_object: 158.9014
        Episode_Reward/action_rate: -0.1140
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.14s
                      Time elapsed: 00:56:19
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 46007 steps/s (collection: 2.025s, learning 0.112s)
             Mean action noise std: 4.25
          Mean value_function loss: 25.9564
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 72.2754
                       Mean reward: 814.27
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.5990
    Episode_Reward/rotating_object: 161.2835
        Episode_Reward/action_rate: -0.1148
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.14s
                      Time elapsed: 00:56:21
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 45789 steps/s (collection: 2.032s, learning 0.115s)
             Mean action noise std: 4.25
          Mean value_function loss: 27.0337
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.2938
                       Mean reward: 813.09
               Mean episode length: 247.16
    Episode_Reward/reaching_object: 1.6193
    Episode_Reward/rotating_object: 160.1511
        Episode_Reward/action_rate: -0.1152
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.15s
                      Time elapsed: 00:56:23
                               ETA: 00:00:38

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 44854 steps/s (collection: 2.072s, learning 0.120s)
             Mean action noise std: 4.26
          Mean value_function loss: 32.4162
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 72.3172
                       Mean reward: 804.59
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.6290
    Episode_Reward/rotating_object: 160.4906
        Episode_Reward/action_rate: -0.1150
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.19s
                      Time elapsed: 00:56:26
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 45275 steps/s (collection: 2.056s, learning 0.116s)
             Mean action noise std: 4.26
          Mean value_function loss: 32.4090
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 72.3324
                       Mean reward: 804.43
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.6244
    Episode_Reward/rotating_object: 160.2071
        Episode_Reward/action_rate: -0.1150
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.17s
                      Time elapsed: 00:56:28
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 45268 steps/s (collection: 2.054s, learning 0.117s)
             Mean action noise std: 4.26
          Mean value_function loss: 32.1493
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 72.3447
                       Mean reward: 779.50
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.6323
    Episode_Reward/rotating_object: 159.9665
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.17s
                      Time elapsed: 00:56:30
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 45376 steps/s (collection: 2.051s, learning 0.116s)
             Mean action noise std: 4.26
          Mean value_function loss: 28.6155
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 72.3564
                       Mean reward: 807.69
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.6344
    Episode_Reward/rotating_object: 159.3127
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.17s
                      Time elapsed: 00:56:32
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 45465 steps/s (collection: 2.045s, learning 0.117s)
             Mean action noise std: 4.27
          Mean value_function loss: 28.3498
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 72.3702
                       Mean reward: 823.59
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.6514
    Episode_Reward/rotating_object: 160.8461
        Episode_Reward/action_rate: -0.1155
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.16s
                      Time elapsed: 00:56:34
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 45106 steps/s (collection: 2.055s, learning 0.125s)
             Mean action noise std: 4.27
          Mean value_function loss: 31.4862
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 72.3778
                       Mean reward: 803.14
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 1.6561
    Episode_Reward/rotating_object: 159.7651
        Episode_Reward/action_rate: -0.1158
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.18s
                      Time elapsed: 00:56:36
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 44988 steps/s (collection: 2.069s, learning 0.116s)
             Mean action noise std: 4.27
          Mean value_function loss: 31.7535
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 72.3942
                       Mean reward: 807.59
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.6585
    Episode_Reward/rotating_object: 159.0726
        Episode_Reward/action_rate: -0.1152
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.19s
                      Time elapsed: 00:56:39
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 45324 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 4.27
          Mean value_function loss: 34.0313
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 72.4134
                       Mean reward: 792.84
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.6432
    Episode_Reward/rotating_object: 159.6244
        Episode_Reward/action_rate: -0.1153
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.17s
                      Time elapsed: 00:56:41
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 45676 steps/s (collection: 2.034s, learning 0.118s)
             Mean action noise std: 4.28
          Mean value_function loss: 37.0811
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 72.4306
                       Mean reward: 807.43
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.6096
    Episode_Reward/rotating_object: 155.4349
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.15s
                      Time elapsed: 00:56:43
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 45393 steps/s (collection: 2.051s, learning 0.115s)
             Mean action noise std: 4.28
          Mean value_function loss: 27.0378
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 72.4466
                       Mean reward: 780.36
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.6557
    Episode_Reward/rotating_object: 160.0187
        Episode_Reward/action_rate: -0.1167
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.17s
                      Time elapsed: 00:56:45
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 46399 steps/s (collection: 2.008s, learning 0.111s)
             Mean action noise std: 4.28
          Mean value_function loss: 23.5867
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 72.4611
                       Mean reward: 824.25
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 1.6652
    Episode_Reward/rotating_object: 161.8445
        Episode_Reward/action_rate: -0.1176
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.12s
                      Time elapsed: 00:56:47
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 46933 steps/s (collection: 1.984s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 33.6308
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 72.4749
                       Mean reward: 802.76
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.6225
    Episode_Reward/rotating_object: 159.5929
        Episode_Reward/action_rate: -0.1156
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.09s
                      Time elapsed: 00:56:49
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 47511 steps/s (collection: 1.957s, learning 0.112s)
             Mean action noise std: 4.29
          Mean value_function loss: 28.1335
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 72.4854
                       Mean reward: 812.12
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 1.6459
    Episode_Reward/rotating_object: 161.5000
        Episode_Reward/action_rate: -0.1180
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.07s
                      Time elapsed: 00:56:51
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 48162 steps/s (collection: 1.928s, learning 0.113s)
             Mean action noise std: 4.29
          Mean value_function loss: 33.4752
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 72.4969
                       Mean reward: 801.70
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.6226
    Episode_Reward/rotating_object: 158.5075
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.04s
                      Time elapsed: 00:56:53
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 47469 steps/s (collection: 1.956s, learning 0.115s)
             Mean action noise std: 4.29
          Mean value_function loss: 29.6502
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 72.5017
                       Mean reward: 791.40
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.6023
    Episode_Reward/rotating_object: 156.9598
        Episode_Reward/action_rate: -0.1157
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.07s
                      Time elapsed: 00:56:56
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 47625 steps/s (collection: 1.950s, learning 0.114s)
             Mean action noise std: 4.29
          Mean value_function loss: 31.2958
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 72.5077
                       Mean reward: 826.04
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 1.6134
    Episode_Reward/rotating_object: 159.5795
        Episode_Reward/action_rate: -0.1165
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.06s
                      Time elapsed: 00:56:58
                               ETA: 00:00:02

