################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10276 steps/s (collection: 9.316s, learning 0.250s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0024
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.2255
                       Mean reward: 0.00
               Mean episode length: 21.40
    Episode_Reward/reaching_object: 0.0006
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0003
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.57s
                      Time elapsed: 00:00:09
                               ETA: 03:59:09

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14445 steps/s (collection: 6.604s, learning 0.202s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 31.2977
                       Mean reward: 0.00
               Mean episode length: 45.09
    Episode_Reward/reaching_object: 0.0017
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0006
          Episode_Reward/joint_vel: -0.0009
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.81s
                      Time elapsed: 00:00:16
                               ETA: 03:24:30

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14584 steps/s (collection: 6.579s, learning 0.162s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.3775
                       Mean reward: 0.00
               Mean episode length: 69.30
    Episode_Reward/reaching_object: 0.0030
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0011
          Episode_Reward/joint_vel: -0.0015
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.74s
                      Time elapsed: 00:00:23
                               ETA: 03:12:20

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14750 steps/s (collection: 6.520s, learning 0.145s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 31.3945
                       Mean reward: 0.01
               Mean episode length: 93.06
    Episode_Reward/reaching_object: 0.0045
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0020
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.66s
                      Time elapsed: 00:00:29
                               ETA: 03:05:43

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14832 steps/s (collection: 6.477s, learning 0.151s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.4645
                       Mean reward: 0.01
               Mean episode length: 117.24
    Episode_Reward/reaching_object: 0.0059
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0026
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.63s
                      Time elapsed: 00:00:36
                               ETA: 03:01:32

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 13967 steps/s (collection: 6.889s, learning 0.148s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 31.5079
                       Mean reward: 0.01
               Mean episode length: 141.16
    Episode_Reward/reaching_object: 0.0072
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0024
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 7.04s
                      Time elapsed: 00:00:43
                               ETA: 03:00:24

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 14229 steps/s (collection: 6.673s, learning 0.236s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.5296
                       Mean reward: 0.01
               Mean episode length: 165.69
    Episode_Reward/reaching_object: 0.0091
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0038
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.91s
                      Time elapsed: 00:00:50
                               ETA: 02:59:06

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14650 steps/s (collection: 6.581s, learning 0.129s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 31.5404
                       Mean reward: 0.02
               Mean episode length: 189.43
    Episode_Reward/reaching_object: 0.0115
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0032
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.71s
                      Time elapsed: 00:00:57
                               ETA: 02:57:28

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 16711 steps/s (collection: 5.768s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 31.5379
                       Mean reward: 0.03
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 0.0130
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.88s
                      Time elapsed: 00:01:02
                               ETA: 02:53:54

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 59293 steps/s (collection: 1.493s, learning 0.165s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 31.5631
                       Mean reward: 0.04
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 0.0176
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.66s
                      Time elapsed: 00:01:04
                               ETA: 02:40:31

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 58949 steps/s (collection: 1.488s, learning 0.180s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 31.5923
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0204
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.67s
                      Time elapsed: 00:01:06
                               ETA: 02:29:36

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 59980 steps/s (collection: 1.479s, learning 0.160s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 31.6280
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0246
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.64s
                      Time elapsed: 00:01:07
                               ETA: 02:20:26

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 56134 steps/s (collection: 1.606s, learning 0.145s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 31.6448
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0283
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.75s
                      Time elapsed: 00:01:09
                               ETA: 02:12:53

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 58476 steps/s (collection: 1.576s, learning 0.105s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 31.6618
                       Mean reward: 0.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0341
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.68s
                      Time elapsed: 00:01:11
                               ETA: 02:06:17

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 63044 steps/s (collection: 1.434s, learning 0.125s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 31.6706
                       Mean reward: 0.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0426
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.56s
                      Time elapsed: 00:01:12
                               ETA: 02:00:21

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 60360 steps/s (collection: 1.538s, learning 0.091s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 31.6988
                       Mean reward: 0.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0525
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.63s
                      Time elapsed: 00:01:14
                               ETA: 01:55:17

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 60679 steps/s (collection: 1.483s, learning 0.138s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 31.7447
                       Mean reward: 0.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0722
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.62s
                      Time elapsed: 00:01:16
                               ETA: 01:50:47

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 58478 steps/s (collection: 1.573s, learning 0.108s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0009
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 31.7940
                       Mean reward: 0.50
               Mean episode length: 249.20
    Episode_Reward/reaching_object: 0.0953
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.68s
                      Time elapsed: 00:01:17
                               ETA: 01:46:52

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 56500 steps/s (collection: 1.634s, learning 0.106s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0015
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 31.8390
                       Mean reward: 0.56
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.1110
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.74s
                      Time elapsed: 00:01:19
                               ETA: 01:43:26

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 54391 steps/s (collection: 1.663s, learning 0.145s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0064
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 31.9422
                       Mean reward: 0.69
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.1467
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.81s
                      Time elapsed: 00:01:21
                               ETA: 01:40:25

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 54132 steps/s (collection: 1.703s, learning 0.113s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0335
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 32.0246
                       Mean reward: 0.87
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.1746
    Episode_Reward/rotating_object: 0.0174
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.82s
                      Time elapsed: 00:01:23
                               ETA: 01:37:43

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 54343 steps/s (collection: 1.702s, learning 0.107s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0042
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.0843
                       Mean reward: 1.00
               Mean episode length: 236.96
    Episode_Reward/reaching_object: 0.2181
    Episode_Reward/rotating_object: 0.0032
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.81s
                      Time elapsed: 00:01:25
                               ETA: 01:35:14

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 53493 steps/s (collection: 1.747s, learning 0.091s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0045
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 32.2147
                       Mean reward: 1.26
               Mean episode length: 233.88
    Episode_Reward/reaching_object: 0.2419
    Episode_Reward/rotating_object: 0.0041
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 8.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.84s
                      Time elapsed: 00:01:26
                               ETA: 01:33:00

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 52849 steps/s (collection: 1.772s, learning 0.088s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0054
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 32.2478
                       Mean reward: 1.23
               Mean episode length: 225.99
    Episode_Reward/reaching_object: 0.2398
    Episode_Reward/rotating_object: 0.0102
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 8.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.86s
                      Time elapsed: 00:01:28
                               ETA: 01:30:58

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 50693 steps/s (collection: 1.790s, learning 0.149s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0066
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 32.3226
                       Mean reward: 1.55
               Mean episode length: 226.55
    Episode_Reward/reaching_object: 0.2843
    Episode_Reward/rotating_object: 0.0115
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 6.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.94s
                      Time elapsed: 00:01:30
                               ETA: 01:29:11

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 52814 steps/s (collection: 1.763s, learning 0.098s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0098
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 32.3786
                       Mean reward: 1.58
               Mean episode length: 220.59
    Episode_Reward/reaching_object: 0.2923
    Episode_Reward/rotating_object: 0.0134
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 5.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.86s
                      Time elapsed: 00:01:32
                               ETA: 01:27:27

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 50844 steps/s (collection: 1.777s, learning 0.156s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0119
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 32.4803
                       Mean reward: 1.70
               Mean episode length: 214.91
    Episode_Reward/reaching_object: 0.3106
    Episode_Reward/rotating_object: 0.0288
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 3.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.93s
                      Time elapsed: 00:01:34
                               ETA: 01:25:55

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 51368 steps/s (collection: 1.777s, learning 0.137s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0135
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 32.5732
                       Mean reward: 1.74
               Mean episode length: 212.58
    Episode_Reward/reaching_object: 0.3318
    Episode_Reward/rotating_object: 0.0248
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 2.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.91s
                      Time elapsed: 00:01:36
                               ETA: 01:24:28

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 49090 steps/s (collection: 1.804s, learning 0.199s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0632
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.6748
                       Mean reward: 2.01
               Mean episode length: 209.55
    Episode_Reward/reaching_object: 0.3368
    Episode_Reward/rotating_object: 0.0284
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 3.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.7500
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.00s
                      Time elapsed: 00:01:38
                               ETA: 01:23:12

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 50057 steps/s (collection: 1.827s, learning 0.137s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0374
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 32.7812
                       Mean reward: 1.91
               Mean episode length: 202.99
    Episode_Reward/reaching_object: 0.3583
    Episode_Reward/rotating_object: 0.0738
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 3.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.96s
                      Time elapsed: 00:01:40
                               ETA: 01:21:58

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 51396 steps/s (collection: 1.811s, learning 0.102s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0315
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 32.9090
                       Mean reward: 1.99
               Mean episode length: 203.92
    Episode_Reward/reaching_object: 0.3812
    Episode_Reward/rotating_object: 0.0357
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 3.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.91s
                      Time elapsed: 00:01:42
                               ETA: 01:20:47

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 50713 steps/s (collection: 1.823s, learning 0.116s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.0438
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 33.0379
                       Mean reward: 2.52
               Mean episode length: 209.09
    Episode_Reward/reaching_object: 0.4051
    Episode_Reward/rotating_object: 0.0763
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 6.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.94s
                      Time elapsed: 00:01:44
                               ETA: 01:19:41

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 50426 steps/s (collection: 1.831s, learning 0.118s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.0413
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 33.1852
                       Mean reward: 2.55
               Mean episode length: 207.67
    Episode_Reward/reaching_object: 0.4302
    Episode_Reward/rotating_object: 0.0737
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 6.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.95s
                      Time elapsed: 00:01:46
                               ETA: 01:18:40

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 50616 steps/s (collection: 1.850s, learning 0.092s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.1570
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.2849
                       Mean reward: 2.52
               Mean episode length: 216.28
    Episode_Reward/reaching_object: 0.4616
    Episode_Reward/rotating_object: 0.0772
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 8.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.8333
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.94s
                      Time elapsed: 00:01:48
                               ETA: 01:17:42

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 49596 steps/s (collection: 1.858s, learning 0.124s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.2325
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.4150
                       Mean reward: 3.98
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 0.4990
    Episode_Reward/rotating_object: 0.1932
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 10.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.98s
                      Time elapsed: 00:01:50
                               ETA: 01:16:48

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 49924 steps/s (collection: 1.858s, learning 0.111s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.3022
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 33.5497
                       Mean reward: 3.94
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 0.5192
    Episode_Reward/rotating_object: 0.1691
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.97s
                      Time elapsed: 00:01:52
                               ETA: 01:15:58

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 48458 steps/s (collection: 1.937s, learning 0.092s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.2763
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.7454
                       Mean reward: 4.62
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 0.5711
    Episode_Reward/rotating_object: 0.3079
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.03s
                      Time elapsed: 00:01:54
                               ETA: 01:15:12

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 48912 steps/s (collection: 1.891s, learning 0.119s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.2432
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 33.8763
                       Mean reward: 5.81
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 0.6185
    Episode_Reward/rotating_object: 0.3288
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.01s
                      Time elapsed: 00:01:56
                               ETA: 01:14:27

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 50239 steps/s (collection: 1.869s, learning 0.088s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.2624
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.0237
                       Mean reward: 5.16
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 0.6571
    Episode_Reward/rotating_object: 0.3539
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.96s
                      Time elapsed: 00:01:58
                               ETA: 01:13:43

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 50614 steps/s (collection: 1.838s, learning 0.104s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.4246
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.1060
                       Mean reward: 6.60
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 0.4761
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.94s
                      Time elapsed: 00:01:59
                               ETA: 01:13:00

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 49852 steps/s (collection: 1.867s, learning 0.105s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.9616
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.2177
                       Mean reward: 5.63
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.6728
    Episode_Reward/rotating_object: 0.4713
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.97s
                      Time elapsed: 00:02:01
                               ETA: 01:12:21

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 49136 steps/s (collection: 1.882s, learning 0.119s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.6329
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.2980
                       Mean reward: 6.61
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 0.7101
    Episode_Reward/rotating_object: 0.6266
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.00s
                      Time elapsed: 00:02:03
                               ETA: 01:11:44

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 49246 steps/s (collection: 1.888s, learning 0.109s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.7578
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.3670
                       Mean reward: 8.30
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 0.7401
    Episode_Reward/rotating_object: 1.0914
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.00s
                      Time elapsed: 00:02:05
                               ETA: 01:11:09

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 48598 steps/s (collection: 1.857s, learning 0.166s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.3978
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.4357
                       Mean reward: 7.59
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 0.7090
    Episode_Reward/rotating_object: 0.9361
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.02s
                      Time elapsed: 00:02:07
                               ETA: 01:10:36

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 50003 steps/s (collection: 1.865s, learning 0.101s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.5343
               Mean surrogate loss: 0.0058
                 Mean entropy loss: 34.4761
                       Mean reward: 9.44
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 0.7128
    Episode_Reward/rotating_object: 1.5231
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.97s
                      Time elapsed: 00:02:09
                               ETA: 01:10:03

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 50985 steps/s (collection: 1.831s, learning 0.097s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.9422
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.4847
                       Mean reward: 12.79
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 1.3527
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.93s
                      Time elapsed: 00:02:11
                               ETA: 01:09:29

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 50272 steps/s (collection: 1.859s, learning 0.097s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.8334
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 34.5645
                       Mean reward: 16.97
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 0.7209
    Episode_Reward/rotating_object: 1.5914
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.96s
                      Time elapsed: 00:02:13
                               ETA: 01:08:58

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 50341 steps/s (collection: 1.847s, learning 0.106s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.2037
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 34.6513
                       Mean reward: 9.01
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 0.7462
    Episode_Reward/rotating_object: 2.1210
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.95s
                      Time elapsed: 00:02:15
                               ETA: 01:08:28

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 49801 steps/s (collection: 1.875s, learning 0.099s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.1613
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.6886
                       Mean reward: 16.68
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 0.7757
    Episode_Reward/rotating_object: 2.1726
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.97s
                      Time elapsed: 00:02:17
                               ETA: 01:08:00

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 50191 steps/s (collection: 1.848s, learning 0.111s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.9416
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.7558
                       Mean reward: 10.05
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 1.9629
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.96s
                      Time elapsed: 00:02:19
                               ETA: 01:07:33

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 49386 steps/s (collection: 1.871s, learning 0.120s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.9475
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 34.8338
                       Mean reward: 15.54
               Mean episode length: 239.75
    Episode_Reward/reaching_object: 0.7564
    Episode_Reward/rotating_object: 2.4827
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.99s
                      Time elapsed: 00:02:21
                               ETA: 01:07:07

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 49134 steps/s (collection: 1.900s, learning 0.100s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.7989
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.8936
                       Mean reward: 11.05
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 0.7676
    Episode_Reward/rotating_object: 1.7148
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.00s
                      Time elapsed: 00:02:23
                               ETA: 01:06:43

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 49953 steps/s (collection: 1.863s, learning 0.104s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.3634
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.9880
                       Mean reward: 13.26
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 0.7640
    Episode_Reward/rotating_object: 1.6800
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.97s
                      Time elapsed: 00:02:25
                               ETA: 01:06:18

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 50169 steps/s (collection: 1.833s, learning 0.126s)
             Mean action noise std: 1.19
          Mean value_function loss: 3.6715
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.0727
                       Mean reward: 12.10
               Mean episode length: 247.14
    Episode_Reward/reaching_object: 0.7668
    Episode_Reward/rotating_object: 1.7148
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.96s
                      Time elapsed: 00:02:27
                               ETA: 01:05:54

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 48987 steps/s (collection: 1.843s, learning 0.163s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.0713
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.1598
                       Mean reward: 21.65
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 0.7853
    Episode_Reward/rotating_object: 2.4860
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.01s
                      Time elapsed: 00:02:29
                               ETA: 01:05:32

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 50032 steps/s (collection: 1.834s, learning 0.131s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.1029
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 35.2705
                       Mean reward: 16.55
               Mean episode length: 246.75
    Episode_Reward/reaching_object: 0.7882
    Episode_Reward/rotating_object: 2.3522
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.96s
                      Time elapsed: 00:02:31
                               ETA: 01:05:10

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 48787 steps/s (collection: 1.797s, learning 0.218s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.7371
               Mean surrogate loss: 0.0073
                 Mean entropy loss: 35.3107
                       Mean reward: 16.38
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.7957
    Episode_Reward/rotating_object: 2.5176
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.01s
                      Time elapsed: 00:02:33
                               ETA: 01:04:50

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 50313 steps/s (collection: 1.824s, learning 0.130s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.6974
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 35.3190
                       Mean reward: 25.29
               Mean episode length: 248.45
    Episode_Reward/reaching_object: 0.7735
    Episode_Reward/rotating_object: 2.8360
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.95s
                      Time elapsed: 00:02:35
                               ETA: 01:04:29

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 49205 steps/s (collection: 1.818s, learning 0.180s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.0504
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 35.3471
                       Mean reward: 18.10
               Mean episode length: 249.24
    Episode_Reward/reaching_object: 0.7796
    Episode_Reward/rotating_object: 1.9858
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.00s
                      Time elapsed: 00:02:37
                               ETA: 01:04:10

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 51754 steps/s (collection: 1.799s, learning 0.100s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.5294
               Mean surrogate loss: 0.0071
                 Mean entropy loss: 35.3630
                       Mean reward: 21.36
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.7670
    Episode_Reward/rotating_object: 2.6338
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.90s
                      Time elapsed: 00:02:39
                               ETA: 01:03:48

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 49607 steps/s (collection: 1.854s, learning 0.128s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.4940
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 35.3729
                       Mean reward: 15.39
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 1.8673
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.98s
                      Time elapsed: 00:02:41
                               ETA: 01:03:30

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 50763 steps/s (collection: 1.827s, learning 0.110s)
             Mean action noise std: 1.21
          Mean value_function loss: 3.1560
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 35.4268
                       Mean reward: 20.42
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 2.4735
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.94s
                      Time elapsed: 00:02:43
                               ETA: 01:03:11

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 50674 steps/s (collection: 1.824s, learning 0.116s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.9400
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 35.4850
                       Mean reward: 12.38
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 2.5087
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.94s
                      Time elapsed: 00:02:45
                               ETA: 01:02:52

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 50344 steps/s (collection: 1.860s, learning 0.093s)
             Mean action noise std: 1.22
          Mean value_function loss: 3.4561
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.5535
                       Mean reward: 18.33
               Mean episode length: 241.96
    Episode_Reward/reaching_object: 0.7079
    Episode_Reward/rotating_object: 2.1163
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0126
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.95s
                      Time elapsed: 00:02:47
                               ETA: 01:02:34

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 50816 steps/s (collection: 1.825s, learning 0.109s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.7570
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.6286
                       Mean reward: 23.36
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 0.7235
    Episode_Reward/rotating_object: 2.8991
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.93s
                      Time elapsed: 00:02:49
                               ETA: 01:02:17

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 50675 steps/s (collection: 1.842s, learning 0.098s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.4527
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.7338
                       Mean reward: 15.45
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 0.7075
    Episode_Reward/rotating_object: 2.0838
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.94s
                      Time elapsed: 00:02:51
                               ETA: 01:02:00

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 46522 steps/s (collection: 2.008s, learning 0.105s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.7318
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 35.7738
                       Mean reward: 21.37
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 2.4432
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.11s
                      Time elapsed: 00:02:53
                               ETA: 01:01:47

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 51129 steps/s (collection: 1.830s, learning 0.093s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.5037
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 35.8121
                       Mean reward: 15.10
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 0.7092
    Episode_Reward/rotating_object: 2.4522
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.92s
                      Time elapsed: 00:02:55
                               ETA: 01:01:30

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 50226 steps/s (collection: 1.851s, learning 0.107s)
             Mean action noise std: 1.24
          Mean value_function loss: 4.3703
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.8527
                       Mean reward: 22.84
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 0.6958
    Episode_Reward/rotating_object: 2.3641
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.96s
                      Time elapsed: 00:02:57
                               ETA: 01:01:15

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 49806 steps/s (collection: 1.867s, learning 0.106s)
             Mean action noise std: 1.24
          Mean value_function loss: 4.1856
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 35.9078
                       Mean reward: 14.85
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 0.7092
    Episode_Reward/rotating_object: 2.9158
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.97s
                      Time elapsed: 00:02:59
                               ETA: 01:01:00

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 50501 steps/s (collection: 1.850s, learning 0.097s)
             Mean action noise std: 1.24
          Mean value_function loss: 5.0502
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 35.9512
                       Mean reward: 12.33
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 0.7078
    Episode_Reward/rotating_object: 2.1117
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.95s
                      Time elapsed: 00:03:01
                               ETA: 01:00:45

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 51672 steps/s (collection: 1.813s, learning 0.089s)
             Mean action noise std: 1.24
          Mean value_function loss: 5.3406
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.9870
                       Mean reward: 14.50
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 0.7017
    Episode_Reward/rotating_object: 3.4524
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.90s
                      Time elapsed: 00:03:02
                               ETA: 01:00:30

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 51129 steps/s (collection: 1.830s, learning 0.093s)
             Mean action noise std: 1.25
          Mean value_function loss: 5.8829
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.0647
                       Mean reward: 22.15
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.7172
    Episode_Reward/rotating_object: 3.0420
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.92s
                      Time elapsed: 00:03:04
                               ETA: 01:00:15

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 50444 steps/s (collection: 1.840s, learning 0.109s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.6530
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.1463
                       Mean reward: 22.17
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 0.7187
    Episode_Reward/rotating_object: 3.1110
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.95s
                      Time elapsed: 00:03:06
                               ETA: 01:00:02

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 49389 steps/s (collection: 1.881s, learning 0.110s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.5118
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 36.2212
                       Mean reward: 33.63
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 0.6797
    Episode_Reward/rotating_object: 3.6644
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.99s
                      Time elapsed: 00:03:08
                               ETA: 00:59:49

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 49664 steps/s (collection: 1.841s, learning 0.138s)
             Mean action noise std: 1.26
          Mean value_function loss: 5.4933
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.2538
                       Mean reward: 16.01
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 0.6939
    Episode_Reward/rotating_object: 2.9398
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.98s
                      Time elapsed: 00:03:10
                               ETA: 00:59:36

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 48515 steps/s (collection: 1.907s, learning 0.119s)
             Mean action noise std: 1.26
          Mean value_function loss: 5.4274
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.3182
                       Mean reward: 18.92
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 0.6958
    Episode_Reward/rotating_object: 3.4944
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.03s
                      Time elapsed: 00:03:12
                               ETA: 00:59:25

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 48548 steps/s (collection: 1.864s, learning 0.161s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.4978
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.3712
                       Mean reward: 22.08
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 0.7030
    Episode_Reward/rotating_object: 3.3642
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.02s
                      Time elapsed: 00:03:14
                               ETA: 00:59:14

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 50428 steps/s (collection: 1.811s, learning 0.138s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.8905
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 36.4243
                       Mean reward: 17.51
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 0.7011
    Episode_Reward/rotating_object: 3.8301
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.95s
                      Time elapsed: 00:03:16
                               ETA: 00:59:01

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 50172 steps/s (collection: 1.857s, learning 0.103s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.3688
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 36.4429
                       Mean reward: 23.83
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 0.7370
    Episode_Reward/rotating_object: 4.6243
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.96s
                      Time elapsed: 00:03:18
                               ETA: 00:58:49

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 50515 steps/s (collection: 1.845s, learning 0.101s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.6645
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.4852
                       Mean reward: 29.92
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 4.3455
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.95s
                      Time elapsed: 00:03:20
                               ETA: 00:58:37

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 49912 steps/s (collection: 1.834s, learning 0.136s)
             Mean action noise std: 1.27
          Mean value_function loss: 6.6777
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 36.5159
                       Mean reward: 20.12
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 3.2527
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.97s
                      Time elapsed: 00:03:22
                               ETA: 00:58:26

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 50271 steps/s (collection: 1.840s, learning 0.115s)
             Mean action noise std: 1.27
          Mean value_function loss: 6.1033
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 36.5270
                       Mean reward: 26.13
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 0.7113
    Episode_Reward/rotating_object: 4.4927
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.96s
                      Time elapsed: 00:03:24
                               ETA: 00:58:15

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 50204 steps/s (collection: 1.835s, learning 0.123s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.2994
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 36.5331
                       Mean reward: 18.44
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 0.7032
    Episode_Reward/rotating_object: 3.2395
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.96s
                      Time elapsed: 00:03:26
                               ETA: 00:58:04

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 50168 steps/s (collection: 1.865s, learning 0.095s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.6761
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 36.5514
                       Mean reward: 22.65
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.6986
    Episode_Reward/rotating_object: 3.7808
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.96s
                      Time elapsed: 00:03:28
                               ETA: 00:57:53

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 51228 steps/s (collection: 1.816s, learning 0.103s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.4011
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 36.5943
                       Mean reward: 30.87
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.7109
    Episode_Reward/rotating_object: 4.5352
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.92s
                      Time elapsed: 00:03:30
                               ETA: 00:57:42

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 51093 steps/s (collection: 1.823s, learning 0.101s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.8022
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 36.6370
                       Mean reward: 21.88
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.6931
    Episode_Reward/rotating_object: 4.4003
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.92s
                      Time elapsed: 00:03:32
                               ETA: 00:57:31

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 50642 steps/s (collection: 1.837s, learning 0.105s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.5030
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.6582
                       Mean reward: 18.14
               Mean episode length: 247.21
    Episode_Reward/reaching_object: 0.6770
    Episode_Reward/rotating_object: 3.6724
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.94s
                      Time elapsed: 00:03:34
                               ETA: 00:57:20

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 50435 steps/s (collection: 1.842s, learning 0.108s)
             Mean action noise std: 1.29
          Mean value_function loss: 7.4057
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.7240
                       Mean reward: 21.72
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.6807
    Episode_Reward/rotating_object: 4.6412
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.95s
                      Time elapsed: 00:03:36
                               ETA: 00:57:10

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 50933 steps/s (collection: 1.829s, learning 0.101s)
             Mean action noise std: 1.29
          Mean value_function loss: 7.2154
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 36.7839
                       Mean reward: 15.84
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 4.8503
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.93s
                      Time elapsed: 00:03:38
                               ETA: 00:57:00

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 50546 steps/s (collection: 1.834s, learning 0.111s)
             Mean action noise std: 1.29
          Mean value_function loss: 7.3427
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 36.8008
                       Mean reward: 21.57
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 0.6826
    Episode_Reward/rotating_object: 3.4334
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.94s
                      Time elapsed: 00:03:40
                               ETA: 00:56:50

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 51202 steps/s (collection: 1.808s, learning 0.112s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.0633
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 36.8224
                       Mean reward: 22.97
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 0.6817
    Episode_Reward/rotating_object: 4.0467
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.92s
                      Time elapsed: 00:03:42
                               ETA: 00:56:40

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 50486 steps/s (collection: 1.821s, learning 0.127s)
             Mean action noise std: 1.30
          Mean value_function loss: 8.8111
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.8610
                       Mean reward: 26.50
               Mean episode length: 242.74
    Episode_Reward/reaching_object: 0.6708
    Episode_Reward/rotating_object: 4.6983
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.95s
                      Time elapsed: 00:03:43
                               ETA: 00:56:31

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 50499 steps/s (collection: 1.822s, learning 0.125s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.6251
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 36.9187
                       Mean reward: 18.40
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 4.1139
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.95s
                      Time elapsed: 00:03:45
                               ETA: 00:56:21

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 50405 steps/s (collection: 1.813s, learning 0.138s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.4756
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 36.9588
                       Mean reward: 30.65
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.6937
    Episode_Reward/rotating_object: 5.4193
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.95s
                      Time elapsed: 00:03:47
                               ETA: 00:56:12

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 51611 steps/s (collection: 1.793s, learning 0.111s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.4408
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 37.0133
                       Mean reward: 27.68
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 5.1408
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.90s
                      Time elapsed: 00:03:49
                               ETA: 00:56:03

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 50065 steps/s (collection: 1.826s, learning 0.138s)
             Mean action noise std: 1.31
          Mean value_function loss: 9.5158
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 37.0688
                       Mean reward: 21.19
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.6720
    Episode_Reward/rotating_object: 3.8761
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.96s
                      Time elapsed: 00:03:51
                               ETA: 00:55:54

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 50113 steps/s (collection: 1.828s, learning 0.134s)
             Mean action noise std: 1.31
          Mean value_function loss: 9.8775
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.1276
                       Mean reward: 20.71
               Mean episode length: 245.08
    Episode_Reward/reaching_object: 0.6950
    Episode_Reward/rotating_object: 5.5893
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.96s
                      Time elapsed: 00:03:53
                               ETA: 00:55:45

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 52108 steps/s (collection: 1.796s, learning 0.090s)
             Mean action noise std: 1.32
          Mean value_function loss: 11.7555
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.1916
                       Mean reward: 27.75
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.6610
    Episode_Reward/rotating_object: 5.1422
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.89s
                      Time elapsed: 00:03:55
                               ETA: 00:55:36

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 49424 steps/s (collection: 1.884s, learning 0.105s)
             Mean action noise std: 1.32
          Mean value_function loss: 9.0508
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.2383
                       Mean reward: 22.84
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 3.9386
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.99s
                      Time elapsed: 00:03:57
                               ETA: 00:55:28

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 50742 steps/s (collection: 1.830s, learning 0.107s)
             Mean action noise std: 1.32
          Mean value_function loss: 10.2330
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.2714
                       Mean reward: 21.04
               Mean episode length: 239.77
    Episode_Reward/reaching_object: 0.6749
    Episode_Reward/rotating_object: 4.0615
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.94s
                      Time elapsed: 00:03:59
                               ETA: 00:55:20

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 49295 steps/s (collection: 1.898s, learning 0.097s)
             Mean action noise std: 1.32
          Mean value_function loss: 10.7757
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.3033
                       Mean reward: 23.86
               Mean episode length: 234.72
    Episode_Reward/reaching_object: 0.6709
    Episode_Reward/rotating_object: 4.3588
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.99s
                      Time elapsed: 00:04:01
                               ETA: 00:55:12

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 50480 steps/s (collection: 1.852s, learning 0.096s)
             Mean action noise std: 1.33
          Mean value_function loss: 10.4841
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.3624
                       Mean reward: 24.06
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 0.6547
    Episode_Reward/rotating_object: 4.4123
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.95s
                      Time elapsed: 00:04:03
                               ETA: 00:55:04

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 49447 steps/s (collection: 1.875s, learning 0.113s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.0063
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.4153
                       Mean reward: 40.53
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 0.6858
    Episode_Reward/rotating_object: 5.6046
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.99s
                      Time elapsed: 00:04:05
                               ETA: 00:54:57

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 48205 steps/s (collection: 1.912s, learning 0.128s)
             Mean action noise std: 1.33
          Mean value_function loss: 10.5793
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.4541
                       Mean reward: 25.74
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 0.6821
    Episode_Reward/rotating_object: 5.8670
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.04s
                      Time elapsed: 00:04:07
                               ETA: 00:54:50

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 50202 steps/s (collection: 1.856s, learning 0.103s)
             Mean action noise std: 1.33
          Mean value_function loss: 11.0028
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.5055
                       Mean reward: 23.93
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 5.3604
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.96s
                      Time elapsed: 00:04:09
                               ETA: 00:54:42

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 51033 steps/s (collection: 1.833s, learning 0.093s)
             Mean action noise std: 1.34
          Mean value_function loss: 12.5693
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.5567
                       Mean reward: 40.52
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 0.6862
    Episode_Reward/rotating_object: 6.2979
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.93s
                      Time elapsed: 00:04:11
                               ETA: 00:54:35

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 48045 steps/s (collection: 1.888s, learning 0.158s)
             Mean action noise std: 1.34
          Mean value_function loss: 12.9759
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.6096
                       Mean reward: 45.48
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 0.7040
    Episode_Reward/rotating_object: 7.0742
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.05s
                      Time elapsed: 00:04:13
                               ETA: 00:54:28

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 50895 steps/s (collection: 1.844s, learning 0.088s)
             Mean action noise std: 1.34
          Mean value_function loss: 11.3897
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 37.6621
                       Mean reward: 23.21
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 0.6632
    Episode_Reward/rotating_object: 5.8799
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.93s
                      Time elapsed: 00:04:15
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 51903 steps/s (collection: 1.799s, learning 0.095s)
             Mean action noise std: 1.35
          Mean value_function loss: 11.6419
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 37.7273
                       Mean reward: 41.07
               Mean episode length: 244.89
    Episode_Reward/reaching_object: 0.6737
    Episode_Reward/rotating_object: 6.6166
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.89s
                      Time elapsed: 00:04:17
                               ETA: 00:54:13

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 50918 steps/s (collection: 1.830s, learning 0.101s)
             Mean action noise std: 1.35
          Mean value_function loss: 12.8072
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.8071
                       Mean reward: 28.05
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 0.6896
    Episode_Reward/rotating_object: 5.3607
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.93s
                      Time elapsed: 00:04:19
                               ETA: 00:54:05

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 48414 steps/s (collection: 1.919s, learning 0.111s)
             Mean action noise std: 1.36
          Mean value_function loss: 12.9562
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 37.8695
                       Mean reward: 27.50
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 0.6711
    Episode_Reward/rotating_object: 5.9882
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.03s
                      Time elapsed: 00:04:21
                               ETA: 00:53:59

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 50648 steps/s (collection: 1.834s, learning 0.107s)
             Mean action noise std: 1.36
          Mean value_function loss: 14.1536
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.9215
                       Mean reward: 25.29
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 0.6789
    Episode_Reward/rotating_object: 5.9845
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.94s
                      Time elapsed: 00:04:23
                               ETA: 00:53:52

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 50283 steps/s (collection: 1.841s, learning 0.114s)
             Mean action noise std: 1.36
          Mean value_function loss: 14.5503
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 37.9713
                       Mean reward: 31.44
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 0.6792
    Episode_Reward/rotating_object: 6.5330
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.95s
                      Time elapsed: 00:04:25
                               ETA: 00:53:45

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 50237 steps/s (collection: 1.841s, learning 0.116s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.8085
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.0274
                       Mean reward: 32.46
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 0.6768
    Episode_Reward/rotating_object: 5.6637
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.96s
                      Time elapsed: 00:04:27
                               ETA: 00:53:38

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 51817 steps/s (collection: 1.796s, learning 0.101s)
             Mean action noise std: 1.37
          Mean value_function loss: 15.5746
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.0706
                       Mean reward: 45.58
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 0.6927
    Episode_Reward/rotating_object: 7.2306
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.90s
                      Time elapsed: 00:04:28
                               ETA: 00:53:31

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 51575 steps/s (collection: 1.813s, learning 0.093s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.3221
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 38.1123
                       Mean reward: 42.39
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.7038
    Episode_Reward/rotating_object: 7.4636
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.91s
                      Time elapsed: 00:04:30
                               ETA: 00:53:24

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 50426 steps/s (collection: 1.849s, learning 0.100s)
             Mean action noise std: 1.37
          Mean value_function loss: 15.4369
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 38.1500
                       Mean reward: 33.13
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.6806
    Episode_Reward/rotating_object: 6.1349
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.95s
                      Time elapsed: 00:04:32
                               ETA: 00:53:17

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 50505 steps/s (collection: 1.855s, learning 0.091s)
             Mean action noise std: 1.38
          Mean value_function loss: 17.6526
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.1945
                       Mean reward: 46.09
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 0.6811
    Episode_Reward/rotating_object: 7.1808
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.95s
                      Time elapsed: 00:04:34
                               ETA: 00:53:10

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 49118 steps/s (collection: 1.892s, learning 0.110s)
             Mean action noise std: 1.38
          Mean value_function loss: 15.7824
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 38.2427
                       Mean reward: 38.08
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.6724
    Episode_Reward/rotating_object: 7.4721
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.00s
                      Time elapsed: 00:04:36
                               ETA: 00:53:05

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 50533 steps/s (collection: 1.839s, learning 0.106s)
             Mean action noise std: 1.38
          Mean value_function loss: 15.6977
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.2881
                       Mean reward: 45.40
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 8.0959
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.95s
                      Time elapsed: 00:04:38
                               ETA: 00:52:58

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 49275 steps/s (collection: 1.876s, learning 0.119s)
             Mean action noise std: 1.39
          Mean value_function loss: 18.9523
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 38.3407
                       Mean reward: 47.99
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 0.6811
    Episode_Reward/rotating_object: 7.7557
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.99s
                      Time elapsed: 00:04:40
                               ETA: 00:52:52

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 48570 steps/s (collection: 1.912s, learning 0.112s)
             Mean action noise std: 1.39
          Mean value_function loss: 17.4442
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 38.3921
                       Mean reward: 52.64
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 0.6374
    Episode_Reward/rotating_object: 6.4996
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.02s
                      Time elapsed: 00:04:42
                               ETA: 00:52:47

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 49282 steps/s (collection: 1.866s, learning 0.128s)
             Mean action noise std: 1.39
          Mean value_function loss: 17.0061
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 38.4370
                       Mean reward: 31.40
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 0.6566
    Episode_Reward/rotating_object: 7.1440
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.99s
                      Time elapsed: 00:04:44
                               ETA: 00:52:41

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 49695 steps/s (collection: 1.863s, learning 0.115s)
             Mean action noise std: 1.39
          Mean value_function loss: 16.1487
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.4731
                       Mean reward: 33.23
               Mean episode length: 225.94
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 8.1246
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.98s
                      Time elapsed: 00:04:46
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 49879 steps/s (collection: 1.875s, learning 0.096s)
             Mean action noise std: 1.40
          Mean value_function loss: 17.8167
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.5172
                       Mean reward: 42.18
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 0.6575
    Episode_Reward/rotating_object: 6.7969
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.97s
                      Time elapsed: 00:04:48
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 50071 steps/s (collection: 1.846s, learning 0.118s)
             Mean action noise std: 1.40
          Mean value_function loss: 19.1648
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 38.5616
                       Mean reward: 32.58
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 0.6736
    Episode_Reward/rotating_object: 6.7031
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.96s
                      Time elapsed: 00:04:50
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 49561 steps/s (collection: 1.836s, learning 0.148s)
             Mean action noise std: 1.40
          Mean value_function loss: 19.3844
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 38.5980
                       Mean reward: 39.33
               Mean episode length: 227.72
    Episode_Reward/reaching_object: 0.6567
    Episode_Reward/rotating_object: 8.6988
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.98s
                      Time elapsed: 00:04:52
                               ETA: 00:52:18

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 50100 steps/s (collection: 1.846s, learning 0.116s)
             Mean action noise std: 1.41
          Mean value_function loss: 19.0458
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 38.6369
                       Mean reward: 55.75
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 0.6605
    Episode_Reward/rotating_object: 7.8115
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.96s
                      Time elapsed: 00:04:54
                               ETA: 00:52:13

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 49481 steps/s (collection: 1.886s, learning 0.100s)
             Mean action noise std: 1.41
          Mean value_function loss: 17.3866
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 38.6823
                       Mean reward: 41.54
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 8.1267
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.99s
                      Time elapsed: 00:04:56
                               ETA: 00:52:07

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 49034 steps/s (collection: 1.900s, learning 0.105s)
             Mean action noise std: 1.41
          Mean value_function loss: 17.2993
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 38.7273
                       Mean reward: 30.13
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 0.6737
    Episode_Reward/rotating_object: 7.8778
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.00s
                      Time elapsed: 00:04:58
                               ETA: 00:52:02

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 47913 steps/s (collection: 1.935s, learning 0.117s)
             Mean action noise std: 1.42
          Mean value_function loss: 16.3837
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 38.7801
                       Mean reward: 25.55
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 0.6390
    Episode_Reward/rotating_object: 7.2637
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.05s
                      Time elapsed: 00:05:00
                               ETA: 00:51:57

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 49631 steps/s (collection: 1.864s, learning 0.117s)
             Mean action noise std: 1.42
          Mean value_function loss: 20.8490
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.8418
                       Mean reward: 36.47
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 0.6214
    Episode_Reward/rotating_object: 6.7670
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.8750
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.98s
                      Time elapsed: 00:05:02
                               ETA: 00:51:52

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 50317 steps/s (collection: 1.866s, learning 0.088s)
             Mean action noise std: 1.42
          Mean value_function loss: 23.2597
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.8946
                       Mean reward: 43.13
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 0.6353
    Episode_Reward/rotating_object: 8.8449
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 11.1250
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.95s
                      Time elapsed: 00:05:04
                               ETA: 00:51:47

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 49556 steps/s (collection: 1.877s, learning 0.107s)
             Mean action noise std: 1.43
          Mean value_function loss: 20.6927
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 38.9432
                       Mean reward: 35.28
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 0.6531
    Episode_Reward/rotating_object: 8.4797
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.98s
                      Time elapsed: 00:05:06
                               ETA: 00:51:41

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 48379 steps/s (collection: 1.929s, learning 0.103s)
             Mean action noise std: 1.43
          Mean value_function loss: 22.7164
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 39.0046
                       Mean reward: 44.74
               Mean episode length: 231.11
    Episode_Reward/reaching_object: 0.6504
    Episode_Reward/rotating_object: 8.0598
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.03s
                      Time elapsed: 00:05:08
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 50174 steps/s (collection: 1.867s, learning 0.092s)
             Mean action noise std: 1.43
          Mean value_function loss: 19.8314
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 39.0572
                       Mean reward: 48.22
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 0.6510
    Episode_Reward/rotating_object: 8.0778
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.96s
                      Time elapsed: 00:05:10
                               ETA: 00:51:31

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 48368 steps/s (collection: 1.908s, learning 0.125s)
             Mean action noise std: 1.44
          Mean value_function loss: 18.2385
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.1171
                       Mean reward: 39.99
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 0.6266
    Episode_Reward/rotating_object: 7.9800
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.03s
                      Time elapsed: 00:05:12
                               ETA: 00:51:27

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 49361 steps/s (collection: 1.899s, learning 0.093s)
             Mean action noise std: 1.44
          Mean value_function loss: 26.9472
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.1762
                       Mean reward: 34.04
               Mean episode length: 223.72
    Episode_Reward/reaching_object: 0.6274
    Episode_Reward/rotating_object: 7.6113
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.99s
                      Time elapsed: 00:05:14
                               ETA: 00:51:22

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 48445 steps/s (collection: 1.940s, learning 0.090s)
             Mean action noise std: 1.44
          Mean value_function loss: 24.2205
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 39.2289
                       Mean reward: 38.41
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 0.6172
    Episode_Reward/rotating_object: 7.7605
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.9167
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.03s
                      Time elapsed: 00:05:16
                               ETA: 00:51:17

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 49841 steps/s (collection: 1.859s, learning 0.113s)
             Mean action noise std: 1.45
          Mean value_function loss: 24.3540
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.2880
                       Mean reward: 52.67
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 0.6228
    Episode_Reward/rotating_object: 8.4520
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.97s
                      Time elapsed: 00:05:18
                               ETA: 00:51:12

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 46491 steps/s (collection: 2.002s, learning 0.112s)
             Mean action noise std: 1.45
          Mean value_function loss: 23.3749
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 39.3379
                       Mean reward: 59.61
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 0.6140
    Episode_Reward/rotating_object: 8.6067
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.11s
                      Time elapsed: 00:05:20
                               ETA: 00:51:09

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 48887 steps/s (collection: 1.893s, learning 0.118s)
             Mean action noise std: 1.45
          Mean value_function loss: 24.5530
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 39.3675
                       Mean reward: 34.29
               Mean episode length: 228.25
    Episode_Reward/reaching_object: 0.6320
    Episode_Reward/rotating_object: 8.8098
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.01s
                      Time elapsed: 00:05:22
                               ETA: 00:51:04

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 49433 steps/s (collection: 1.894s, learning 0.095s)
             Mean action noise std: 1.45
          Mean value_function loss: 26.1508
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.3948
                       Mean reward: 51.52
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 0.6327
    Episode_Reward/rotating_object: 9.3309
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.99s
                      Time elapsed: 00:05:24
                               ETA: 00:50:59

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 49440 steps/s (collection: 1.897s, learning 0.092s)
             Mean action noise std: 1.46
          Mean value_function loss: 27.2566
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 39.4388
                       Mean reward: 41.57
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 0.6358
    Episode_Reward/rotating_object: 7.7831
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.99s
                      Time elapsed: 00:05:26
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 49531 steps/s (collection: 1.879s, learning 0.106s)
             Mean action noise std: 1.46
          Mean value_function loss: 24.8292
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.4941
                       Mean reward: 52.73
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 0.6321
    Episode_Reward/rotating_object: 9.1476
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.98s
                      Time elapsed: 00:05:28
                               ETA: 00:50:50

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 50286 steps/s (collection: 1.866s, learning 0.089s)
             Mean action noise std: 1.46
          Mean value_function loss: 24.4722
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 39.5406
                       Mean reward: 50.78
               Mean episode length: 226.10
    Episode_Reward/reaching_object: 0.6106
    Episode_Reward/rotating_object: 9.0893
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.95s
                      Time elapsed: 00:05:30
                               ETA: 00:50:45

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 49215 steps/s (collection: 1.881s, learning 0.116s)
             Mean action noise std: 1.47
          Mean value_function loss: 26.6643
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 39.5727
                       Mean reward: 37.61
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 0.6021
    Episode_Reward/rotating_object: 8.8779
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.00s
                      Time elapsed: 00:05:32
                               ETA: 00:50:40

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 50300 steps/s (collection: 1.862s, learning 0.092s)
             Mean action noise std: 1.47
          Mean value_function loss: 24.3388
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 39.5962
                       Mean reward: 59.18
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 0.6365
    Episode_Reward/rotating_object: 9.3116
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.95s
                      Time elapsed: 00:05:34
                               ETA: 00:50:35

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 49292 steps/s (collection: 1.899s, learning 0.095s)
             Mean action noise std: 1.47
          Mean value_function loss: 25.2650
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.6212
                       Mean reward: 54.81
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 0.6310
    Episode_Reward/rotating_object: 9.4974
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.99s
                      Time elapsed: 00:05:36
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 48412 steps/s (collection: 1.927s, learning 0.103s)
             Mean action noise std: 1.47
          Mean value_function loss: 26.2656
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.6643
                       Mean reward: 43.37
               Mean episode length: 227.06
    Episode_Reward/reaching_object: 0.6288
    Episode_Reward/rotating_object: 9.1004
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.03s
                      Time elapsed: 00:05:38
                               ETA: 00:50:27

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 48298 steps/s (collection: 1.930s, learning 0.106s)
             Mean action noise std: 1.48
          Mean value_function loss: 23.4699
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.7194
                       Mean reward: 47.84
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 11.2143
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.04s
                      Time elapsed: 00:05:40
                               ETA: 00:50:22

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 49849 steps/s (collection: 1.868s, learning 0.104s)
             Mean action noise std: 1.48
          Mean value_function loss: 27.1433
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 39.7653
                       Mean reward: 47.77
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 0.6445
    Episode_Reward/rotating_object: 9.9166
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.97s
                      Time elapsed: 00:05:42
                               ETA: 00:50:18

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 49939 steps/s (collection: 1.861s, learning 0.107s)
             Mean action noise std: 1.48
          Mean value_function loss: 29.8071
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.8067
                       Mean reward: 49.74
               Mean episode length: 217.98
    Episode_Reward/reaching_object: 0.6379
    Episode_Reward/rotating_object: 10.7304
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.97s
                      Time elapsed: 00:05:44
                               ETA: 00:50:13

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 49680 steps/s (collection: 1.881s, learning 0.098s)
             Mean action noise std: 1.48
          Mean value_function loss: 28.3970
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 39.8396
                       Mean reward: 76.22
               Mean episode length: 223.39
    Episode_Reward/reaching_object: 0.6345
    Episode_Reward/rotating_object: 11.6652
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.98s
                      Time elapsed: 00:05:46
                               ETA: 00:50:09

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 48743 steps/s (collection: 1.914s, learning 0.103s)
             Mean action noise std: 1.49
          Mean value_function loss: 31.8764
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.8631
                       Mean reward: 45.53
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 0.6241
    Episode_Reward/rotating_object: 9.4888
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.02s
                      Time elapsed: 00:05:48
                               ETA: 00:50:05

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 50580 steps/s (collection: 1.853s, learning 0.090s)
             Mean action noise std: 1.49
          Mean value_function loss: 33.8121
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 39.9069
                       Mean reward: 55.92
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 10.0410
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.94s
                      Time elapsed: 00:05:50
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 50312 steps/s (collection: 1.862s, learning 0.092s)
             Mean action noise std: 1.49
          Mean value_function loss: 35.7639
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 39.9548
                       Mean reward: 60.37
               Mean episode length: 229.12
    Episode_Reward/reaching_object: 0.6481
    Episode_Reward/rotating_object: 10.2912
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.95s
                      Time elapsed: 00:05:52
                               ETA: 00:49:55

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 48464 steps/s (collection: 1.932s, learning 0.097s)
             Mean action noise std: 1.50
          Mean value_function loss: 34.5153
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.9960
                       Mean reward: 54.21
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 0.6531
    Episode_Reward/rotating_object: 10.8207
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.03s
                      Time elapsed: 00:05:54
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 49873 steps/s (collection: 1.874s, learning 0.097s)
             Mean action noise std: 1.50
          Mean value_function loss: 35.3752
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 40.0264
                       Mean reward: 56.66
               Mean episode length: 214.67
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 11.0009
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.97s
                      Time elapsed: 00:05:56
                               ETA: 00:49:47

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 50768 steps/s (collection: 1.838s, learning 0.099s)
             Mean action noise std: 1.50
          Mean value_function loss: 32.7892
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.0662
                       Mean reward: 60.22
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 0.6836
    Episode_Reward/rotating_object: 12.1092
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.94s
                      Time elapsed: 00:05:58
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 48491 steps/s (collection: 1.931s, learning 0.096s)
             Mean action noise std: 1.50
          Mean value_function loss: 32.7589
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 40.1048
                       Mean reward: 65.87
               Mean episode length: 225.53
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 11.5725
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.03s
                      Time elapsed: 00:06:00
                               ETA: 00:49:38

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 50246 steps/s (collection: 1.866s, learning 0.091s)
             Mean action noise std: 1.50
          Mean value_function loss: 30.3787
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.1222
                       Mean reward: 48.70
               Mean episode length: 228.47
    Episode_Reward/reaching_object: 0.6552
    Episode_Reward/rotating_object: 10.0842
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 11.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.96s
                      Time elapsed: 00:06:02
                               ETA: 00:49:34

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 48811 steps/s (collection: 1.866s, learning 0.148s)
             Mean action noise std: 1.50
          Mean value_function loss: 32.3899
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.1403
                       Mean reward: 45.79
               Mean episode length: 218.10
    Episode_Reward/reaching_object: 0.6565
    Episode_Reward/rotating_object: 10.4255
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 11.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.01s
                      Time elapsed: 00:06:04
                               ETA: 00:49:30

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 48926 steps/s (collection: 1.859s, learning 0.151s)
             Mean action noise std: 1.51
          Mean value_function loss: 31.3068
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 40.1568
                       Mean reward: 48.73
               Mean episode length: 225.48
    Episode_Reward/reaching_object: 0.6703
    Episode_Reward/rotating_object: 11.5227
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.01s
                      Time elapsed: 00:06:06
                               ETA: 00:49:26

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 48634 steps/s (collection: 1.894s, learning 0.127s)
             Mean action noise std: 1.51
          Mean value_function loss: 28.2406
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.1867
                       Mean reward: 58.62
               Mean episode length: 221.07
    Episode_Reward/reaching_object: 0.6525
    Episode_Reward/rotating_object: 11.7945
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.02s
                      Time elapsed: 00:06:08
                               ETA: 00:49:22

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 48387 steps/s (collection: 1.903s, learning 0.128s)
             Mean action noise std: 1.51
          Mean value_function loss: 28.8866
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.2308
                       Mean reward: 49.12
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 0.6790
    Episode_Reward/rotating_object: 12.4621
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.03s
                      Time elapsed: 00:06:10
                               ETA: 00:49:19

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 47785 steps/s (collection: 1.903s, learning 0.155s)
             Mean action noise std: 1.51
          Mean value_function loss: 28.0153
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.2565
                       Mean reward: 44.49
               Mean episode length: 218.96
    Episode_Reward/reaching_object: 0.6379
    Episode_Reward/rotating_object: 10.6729
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.06s
                      Time elapsed: 00:06:12
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 49188 steps/s (collection: 1.887s, learning 0.112s)
             Mean action noise std: 1.51
          Mean value_function loss: 31.5027
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.2798
                       Mean reward: 61.11
               Mean episode length: 225.94
    Episode_Reward/reaching_object: 0.6667
    Episode_Reward/rotating_object: 14.0584
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.00s
                      Time elapsed: 00:06:14
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 49167 steps/s (collection: 1.867s, learning 0.133s)
             Mean action noise std: 1.52
          Mean value_function loss: 30.1065
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.3117
                       Mean reward: 68.12
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 0.6783
    Episode_Reward/rotating_object: 13.8354
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.00s
                      Time elapsed: 00:06:16
                               ETA: 00:49:07

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 49817 steps/s (collection: 1.875s, learning 0.099s)
             Mean action noise std: 1.52
          Mean value_function loss: 34.2703
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.3420
                       Mean reward: 109.73
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 0.6449
    Episode_Reward/rotating_object: 13.1681
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.97s
                      Time elapsed: 00:06:18
                               ETA: 00:49:03

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 48531 steps/s (collection: 1.883s, learning 0.142s)
             Mean action noise std: 1.52
          Mean value_function loss: 35.1515
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.3653
                       Mean reward: 38.13
               Mean episode length: 225.01
    Episode_Reward/reaching_object: 0.6496
    Episode_Reward/rotating_object: 10.7954
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.03s
                      Time elapsed: 00:06:20
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 49212 steps/s (collection: 1.906s, learning 0.092s)
             Mean action noise std: 1.52
          Mean value_function loss: 36.3690
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 40.3948
                       Mean reward: 80.12
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.6780
    Episode_Reward/rotating_object: 14.2180
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.00s
                      Time elapsed: 00:06:22
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 49670 steps/s (collection: 1.869s, learning 0.111s)
             Mean action noise std: 1.52
          Mean value_function loss: 40.3809
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.4246
                       Mean reward: 53.44
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 12.7387
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.98s
                      Time elapsed: 00:06:24
                               ETA: 00:48:52

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 48758 steps/s (collection: 1.902s, learning 0.114s)
             Mean action noise std: 1.53
          Mean value_function loss: 41.2904
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.4532
                       Mean reward: 81.82
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 0.6615
    Episode_Reward/rotating_object: 14.2097
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.02s
                      Time elapsed: 00:06:26
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 47916 steps/s (collection: 1.950s, learning 0.102s)
             Mean action noise std: 1.53
          Mean value_function loss: 39.1513
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.4871
                       Mean reward: 76.35
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 0.6634
    Episode_Reward/rotating_object: 14.8717
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.05s
                      Time elapsed: 00:06:28
                               ETA: 00:48:45

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 49262 steps/s (collection: 1.899s, learning 0.096s)
             Mean action noise std: 1.53
          Mean value_function loss: 39.4955
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 40.5230
                       Mean reward: 73.83
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 0.6935
    Episode_Reward/rotating_object: 15.8969
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.00s
                      Time elapsed: 00:06:30
                               ETA: 00:48:41

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 49290 steps/s (collection: 1.855s, learning 0.139s)
             Mean action noise std: 1.53
          Mean value_function loss: 45.0666
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.5524
                       Mean reward: 81.04
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 0.6816
    Episode_Reward/rotating_object: 14.8403
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.99s
                      Time elapsed: 00:06:32
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 50244 steps/s (collection: 1.824s, learning 0.133s)
             Mean action noise std: 1.53
          Mean value_function loss: 45.9149
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.5739
                       Mean reward: 76.22
               Mean episode length: 223.81
    Episode_Reward/reaching_object: 0.6649
    Episode_Reward/rotating_object: 14.6289
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.96s
                      Time elapsed: 00:06:34
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 49079 steps/s (collection: 1.865s, learning 0.138s)
             Mean action noise std: 1.54
          Mean value_function loss: 45.6588
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.5861
                       Mean reward: 73.38
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 0.7060
    Episode_Reward/rotating_object: 13.8064
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.00s
                      Time elapsed: 00:06:36
                               ETA: 00:48:29

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 48346 steps/s (collection: 1.876s, learning 0.157s)
             Mean action noise std: 1.54
          Mean value_function loss: 44.2341
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 40.6091
                       Mean reward: 61.12
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 15.1382
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.03s
                      Time elapsed: 00:06:38
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 48517 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 51.8277
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 40.6320
                       Mean reward: 66.39
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 0.6886
    Episode_Reward/rotating_object: 13.0981
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.03s
                      Time elapsed: 00:06:40
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 49301 steps/s (collection: 1.863s, learning 0.131s)
             Mean action noise std: 1.54
          Mean value_function loss: 51.8578
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.6652
                       Mean reward: 75.83
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 0.7257
    Episode_Reward/rotating_object: 14.6387
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.99s
                      Time elapsed: 00:06:42
                               ETA: 00:48:19

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 50376 steps/s (collection: 1.862s, learning 0.090s)
             Mean action noise std: 1.54
          Mean value_function loss: 54.2147
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.6894
                       Mean reward: 66.66
               Mean episode length: 225.39
    Episode_Reward/reaching_object: 0.7257
    Episode_Reward/rotating_object: 17.9420
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.95s
                      Time elapsed: 00:06:44
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 50002 steps/s (collection: 1.878s, learning 0.088s)
             Mean action noise std: 1.55
          Mean value_function loss: 51.0816
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.7085
                       Mean reward: 121.58
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 0.7388
    Episode_Reward/rotating_object: 17.1602
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.97s
                      Time elapsed: 00:06:46
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 47963 steps/s (collection: 1.865s, learning 0.185s)
             Mean action noise std: 1.55
          Mean value_function loss: 55.3458
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 40.7372
                       Mean reward: 86.91
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 0.7397
    Episode_Reward/rotating_object: 17.8136
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.05s
                      Time elapsed: 00:06:48
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 47999 steps/s (collection: 1.928s, learning 0.120s)
             Mean action noise std: 1.55
          Mean value_function loss: 52.5024
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 40.7732
                       Mean reward: 91.42
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 18.2291
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.05s
                      Time elapsed: 00:06:50
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 48735 steps/s (collection: 1.919s, learning 0.099s)
             Mean action noise std: 1.55
          Mean value_function loss: 54.6810
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.8020
                       Mean reward: 81.18
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 0.7332
    Episode_Reward/rotating_object: 16.7846
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.02s
                      Time elapsed: 00:06:52
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 49373 steps/s (collection: 1.895s, learning 0.096s)
             Mean action noise std: 1.55
          Mean value_function loss: 60.2704
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 40.8356
                       Mean reward: 87.16
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 18.1223
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.99s
                      Time elapsed: 00:06:54
                               ETA: 00:47:57

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 48942 steps/s (collection: 1.920s, learning 0.089s)
             Mean action noise std: 1.56
          Mean value_function loss: 60.1217
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 40.8582
                       Mean reward: 99.49
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 17.8634
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.01s
                      Time elapsed: 00:06:56
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 47798 steps/s (collection: 1.922s, learning 0.135s)
             Mean action noise std: 1.56
          Mean value_function loss: 61.9468
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 40.8735
                       Mean reward: 89.88
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 0.7355
    Episode_Reward/rotating_object: 17.4307
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.06s
                      Time elapsed: 00:06:58
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 48726 steps/s (collection: 1.896s, learning 0.121s)
             Mean action noise std: 1.56
          Mean value_function loss: 62.3192
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 40.8916
                       Mean reward: 83.45
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 0.7586
    Episode_Reward/rotating_object: 18.5331
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.02s
                      Time elapsed: 00:07:00
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 46761 steps/s (collection: 2.002s, learning 0.100s)
             Mean action noise std: 1.56
          Mean value_function loss: 65.9254
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 40.9094
                       Mean reward: 80.28
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 18.1120
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.10s
                      Time elapsed: 00:07:02
                               ETA: 00:47:45

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 48334 steps/s (collection: 1.933s, learning 0.101s)
             Mean action noise std: 1.56
          Mean value_function loss: 54.0685
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.9279
                       Mean reward: 110.27
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 21.0179
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.03s
                      Time elapsed: 00:07:04
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 44424 steps/s (collection: 2.105s, learning 0.108s)
             Mean action noise std: 1.56
          Mean value_function loss: 62.7486
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.9457
                       Mean reward: 101.09
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 0.7655
    Episode_Reward/rotating_object: 20.7035
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.21s
                      Time elapsed: 00:07:07
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 47657 steps/s (collection: 1.954s, learning 0.109s)
             Mean action noise std: 1.56
          Mean value_function loss: 63.8375
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 40.9631
                       Mean reward: 90.88
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 18.2293
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.06s
                      Time elapsed: 00:07:09
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 47595 steps/s (collection: 1.962s, learning 0.104s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.1995
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 40.9850
                       Mean reward: 102.63
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 20.2978
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.07s
                      Time elapsed: 00:07:11
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 48356 steps/s (collection: 1.940s, learning 0.093s)
             Mean action noise std: 1.57
          Mean value_function loss: 54.5002
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 41.0088
                       Mean reward: 67.07
               Mean episode length: 226.85
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 18.0105
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.03s
                      Time elapsed: 00:07:13
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 47682 steps/s (collection: 1.936s, learning 0.126s)
             Mean action noise std: 1.57
          Mean value_function loss: 52.8281
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.0285
                       Mean reward: 96.07
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 0.7264
    Episode_Reward/rotating_object: 19.7686
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.06s
                      Time elapsed: 00:07:15
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 48079 steps/s (collection: 1.940s, learning 0.105s)
             Mean action noise std: 1.57
          Mean value_function loss: 50.5093
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 41.0505
                       Mean reward: 112.08
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 20.6146
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.04s
                      Time elapsed: 00:07:17
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 45090 steps/s (collection: 2.021s, learning 0.159s)
             Mean action noise std: 1.57
          Mean value_function loss: 51.7626
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 41.0723
                       Mean reward: 116.41
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 0.7358
    Episode_Reward/rotating_object: 20.7919
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.18s
                      Time elapsed: 00:07:19
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 45939 steps/s (collection: 1.994s, learning 0.146s)
             Mean action noise std: 1.57
          Mean value_function loss: 56.1696
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 41.0931
                       Mean reward: 109.10
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 21.1491
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.14s
                      Time elapsed: 00:07:21
                               ETA: 00:47:19

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 47003 steps/s (collection: 1.986s, learning 0.105s)
             Mean action noise std: 1.57
          Mean value_function loss: 56.1702
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.1012
                       Mean reward: 103.11
               Mean episode length: 225.94
    Episode_Reward/reaching_object: 0.7379
    Episode_Reward/rotating_object: 24.4223
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.09s
                      Time elapsed: 00:07:23
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 47138 steps/s (collection: 1.977s, learning 0.108s)
             Mean action noise std: 1.58
          Mean value_function loss: 58.6428
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.1187
                       Mean reward: 100.30
               Mean episode length: 225.36
    Episode_Reward/reaching_object: 0.7191
    Episode_Reward/rotating_object: 22.5142
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.09s
                      Time elapsed: 00:07:25
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 47640 steps/s (collection: 1.950s, learning 0.114s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.1484
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.1375
                       Mean reward: 105.88
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 0.7064
    Episode_Reward/rotating_object: 23.1904
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.06s
                      Time elapsed: 00:07:27
                               ETA: 00:47:11

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 46679 steps/s (collection: 2.009s, learning 0.097s)
             Mean action noise std: 1.58
          Mean value_function loss: 57.2443
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 41.1650
                       Mean reward: 136.13
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.7396
    Episode_Reward/rotating_object: 24.0080
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.11s
                      Time elapsed: 00:07:29
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 48079 steps/s (collection: 1.934s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 60.0952
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 41.1867
                       Mean reward: 128.94
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 0.7172
    Episode_Reward/rotating_object: 22.6454
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.04s
                      Time elapsed: 00:07:31
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 47791 steps/s (collection: 1.960s, learning 0.097s)
             Mean action noise std: 1.58
          Mean value_function loss: 63.3876
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 41.2013
                       Mean reward: 124.52
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 0.7239
    Episode_Reward/rotating_object: 23.0608
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.06s
                      Time elapsed: 00:07:34
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 46769 steps/s (collection: 1.995s, learning 0.107s)
             Mean action noise std: 1.58
          Mean value_function loss: 68.1018
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.2171
                       Mean reward: 77.63
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 22.0333
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.10s
                      Time elapsed: 00:07:36
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 47226 steps/s (collection: 1.971s, learning 0.110s)
             Mean action noise std: 1.58
          Mean value_function loss: 62.4139
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 41.2338
                       Mean reward: 129.81
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 27.2403
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.08s
                      Time elapsed: 00:07:38
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 47111 steps/s (collection: 1.968s, learning 0.118s)
             Mean action noise std: 1.59
          Mean value_function loss: 63.9570
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.2619
                       Mean reward: 93.03
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.7206
    Episode_Reward/rotating_object: 24.7048
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.09s
                      Time elapsed: 00:07:40
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 48273 steps/s (collection: 1.925s, learning 0.112s)
             Mean action noise std: 1.59
          Mean value_function loss: 64.4371
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.2974
                       Mean reward: 160.64
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 26.3280
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.04s
                      Time elapsed: 00:07:42
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 49161 steps/s (collection: 1.902s, learning 0.098s)
             Mean action noise std: 1.59
          Mean value_function loss: 60.9879
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 41.3239
                       Mean reward: 137.38
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 25.9854
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.00s
                      Time elapsed: 00:07:44
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 48494 steps/s (collection: 1.932s, learning 0.095s)
             Mean action noise std: 1.59
          Mean value_function loss: 72.7670
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 41.3495
                       Mean reward: 119.53
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 0.7170
    Episode_Reward/rotating_object: 24.6379
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.03s
                      Time elapsed: 00:07:46
                               ETA: 00:46:44

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 48570 steps/s (collection: 1.915s, learning 0.109s)
             Mean action noise std: 1.59
          Mean value_function loss: 71.9585
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.3735
                       Mean reward: 142.39
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 28.0719
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.02s
                      Time elapsed: 00:07:48
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 48234 steps/s (collection: 1.942s, learning 0.096s)
             Mean action noise std: 1.60
          Mean value_function loss: 69.8929
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 41.3998
                       Mean reward: 120.84
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 0.7103
    Episode_Reward/rotating_object: 25.2250
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.04s
                      Time elapsed: 00:07:50
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 48017 steps/s (collection: 1.941s, learning 0.107s)
             Mean action noise std: 1.60
          Mean value_function loss: 68.2555
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 41.4234
                       Mean reward: 124.55
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 25.9476
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.05s
                      Time elapsed: 00:07:52
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 47384 steps/s (collection: 1.973s, learning 0.102s)
             Mean action noise std: 1.60
          Mean value_function loss: 60.6895
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 41.4425
                       Mean reward: 151.89
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 27.2826
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.07s
                      Time elapsed: 00:07:54
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 49145 steps/s (collection: 1.897s, learning 0.103s)
             Mean action noise std: 1.60
          Mean value_function loss: 61.7593
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.4570
                       Mean reward: 142.81
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 0.7122
    Episode_Reward/rotating_object: 24.4020
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.00s
                      Time elapsed: 00:07:56
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 47888 steps/s (collection: 1.932s, learning 0.120s)
             Mean action noise std: 1.60
          Mean value_function loss: 57.5012
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.4746
                       Mean reward: 149.57
               Mean episode length: 228.17
    Episode_Reward/reaching_object: 0.7070
    Episode_Reward/rotating_object: 24.2254
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.05s
                      Time elapsed: 00:07:58
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 46892 steps/s (collection: 1.989s, learning 0.107s)
             Mean action noise std: 1.60
          Mean value_function loss: 60.9459
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 41.4975
                       Mean reward: 138.29
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 26.3779
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.10s
                      Time elapsed: 00:08:00
                               ETA: 00:46:24

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 48098 steps/s (collection: 1.902s, learning 0.142s)
             Mean action noise std: 1.60
          Mean value_function loss: 60.8986
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.5148
                       Mean reward: 131.89
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 25.4684
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.04s
                      Time elapsed: 00:08:02
                               ETA: 00:46:21

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 49549 steps/s (collection: 1.893s, learning 0.091s)
             Mean action noise std: 1.61
          Mean value_function loss: 61.6481
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 41.5368
                       Mean reward: 157.90
               Mean episode length: 234.26
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 28.1497
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.98s
                      Time elapsed: 00:08:04
                               ETA: 00:46:17

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 47214 steps/s (collection: 1.982s, learning 0.101s)
             Mean action noise std: 1.61
          Mean value_function loss: 63.2867
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 41.5538
                       Mean reward: 153.61
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 0.7109
    Episode_Reward/rotating_object: 26.6150
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.08s
                      Time elapsed: 00:08:06
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 47672 steps/s (collection: 1.929s, learning 0.133s)
             Mean action noise std: 1.61
          Mean value_function loss: 66.9411
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.5711
                       Mean reward: 129.41
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 26.1890
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.06s
                      Time elapsed: 00:08:08
                               ETA: 00:46:12

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 46931 steps/s (collection: 1.975s, learning 0.120s)
             Mean action noise std: 1.61
          Mean value_function loss: 64.3933
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 41.5936
                       Mean reward: 111.47
               Mean episode length: 225.80
    Episode_Reward/reaching_object: 0.6736
    Episode_Reward/rotating_object: 23.9818
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.09s
                      Time elapsed: 00:08:10
                               ETA: 00:46:09

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 47800 steps/s (collection: 1.946s, learning 0.111s)
             Mean action noise std: 1.61
          Mean value_function loss: 60.8427
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.6149
                       Mean reward: 150.61
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 0.7198
    Episode_Reward/rotating_object: 31.2098
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.06s
                      Time elapsed: 00:08:13
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 47524 steps/s (collection: 1.968s, learning 0.100s)
             Mean action noise std: 1.61
          Mean value_function loss: 57.7100
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.6315
                       Mean reward: 172.82
               Mean episode length: 222.22
    Episode_Reward/reaching_object: 0.6974
    Episode_Reward/rotating_object: 30.9286
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.07s
                      Time elapsed: 00:08:15
                               ETA: 00:46:04

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 47677 steps/s (collection: 1.963s, learning 0.099s)
             Mean action noise std: 1.61
          Mean value_function loss: 59.2527
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.6524
                       Mean reward: 167.35
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 0.7133
    Episode_Reward/rotating_object: 31.4710
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.06s
                      Time elapsed: 00:08:17
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 46298 steps/s (collection: 2.008s, learning 0.115s)
             Mean action noise std: 1.62
          Mean value_function loss: 55.2922
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.6651
                       Mean reward: 178.02
               Mean episode length: 222.93
    Episode_Reward/reaching_object: 0.6997
    Episode_Reward/rotating_object: 29.4808
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.12s
                      Time elapsed: 00:08:19
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 48314 steps/s (collection: 1.942s, learning 0.093s)
             Mean action noise std: 1.62
          Mean value_function loss: 57.6828
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.6836
                       Mean reward: 146.63
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 30.4949
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.03s
                      Time elapsed: 00:08:21
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 47646 steps/s (collection: 1.971s, learning 0.092s)
             Mean action noise std: 1.62
          Mean value_function loss: 54.7415
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.7058
                       Mean reward: 154.89
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 0.7084
    Episode_Reward/rotating_object: 31.6532
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.06s
                      Time elapsed: 00:08:23
                               ETA: 00:45:53

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 48010 steps/s (collection: 1.935s, learning 0.112s)
             Mean action noise std: 1.62
          Mean value_function loss: 53.1795
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.7311
                       Mean reward: 144.42
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 0.6964
    Episode_Reward/rotating_object: 29.2187
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.05s
                      Time elapsed: 00:08:25
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 48033 steps/s (collection: 1.932s, learning 0.115s)
             Mean action noise std: 1.62
          Mean value_function loss: 63.4382
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 41.7495
                       Mean reward: 152.38
               Mean episode length: 225.86
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 30.9561
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.05s
                      Time elapsed: 00:08:27
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 48324 steps/s (collection: 1.932s, learning 0.102s)
             Mean action noise std: 1.62
          Mean value_function loss: 63.2709
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 41.7686
                       Mean reward: 153.51
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 0.6995
    Episode_Reward/rotating_object: 30.3394
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.03s
                      Time elapsed: 00:08:29
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 48265 steps/s (collection: 1.943s, learning 0.094s)
             Mean action noise std: 1.63
          Mean value_function loss: 68.1257
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 41.7859
                       Mean reward: 172.68
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 0.7011
    Episode_Reward/rotating_object: 30.7918
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.04s
                      Time elapsed: 00:08:31
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 48274 steps/s (collection: 1.947s, learning 0.090s)
             Mean action noise std: 1.63
          Mean value_function loss: 74.1766
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 41.8040
                       Mean reward: 135.40
               Mean episode length: 224.18
    Episode_Reward/reaching_object: 0.6845
    Episode_Reward/rotating_object: 28.4730
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.04s
                      Time elapsed: 00:08:33
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 47379 steps/s (collection: 1.935s, learning 0.140s)
             Mean action noise std: 1.63
          Mean value_function loss: 78.4679
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 41.8147
                       Mean reward: 164.65
               Mean episode length: 223.73
    Episode_Reward/reaching_object: 0.7374
    Episode_Reward/rotating_object: 36.5835
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.07s
                      Time elapsed: 00:08:35
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 44816 steps/s (collection: 2.035s, learning 0.159s)
             Mean action noise std: 1.63
          Mean value_function loss: 68.6538
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 41.8207
                       Mean reward: 166.75
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 0.7273
    Episode_Reward/rotating_object: 31.8304
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.19s
                      Time elapsed: 00:08:37
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 45624 steps/s (collection: 2.031s, learning 0.124s)
             Mean action noise std: 1.63
          Mean value_function loss: 72.1184
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 41.8332
                       Mean reward: 194.61
               Mean episode length: 237.99
    Episode_Reward/reaching_object: 0.7329
    Episode_Reward/rotating_object: 36.0374
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.15s
                      Time elapsed: 00:08:40
                               ETA: 00:45:32

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 47306 steps/s (collection: 1.972s, learning 0.106s)
             Mean action noise std: 1.63
          Mean value_function loss: 72.2651
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.8516
                       Mean reward: 157.72
               Mean episode length: 230.83
    Episode_Reward/reaching_object: 0.7341
    Episode_Reward/rotating_object: 35.3792
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.08s
                      Time elapsed: 00:08:42
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 47167 steps/s (collection: 1.994s, learning 0.091s)
             Mean action noise std: 1.63
          Mean value_function loss: 65.7036
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 41.8711
                       Mean reward: 205.77
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 37.5054
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.08s
                      Time elapsed: 00:08:44
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 48557 steps/s (collection: 1.915s, learning 0.110s)
             Mean action noise std: 1.63
          Mean value_function loss: 66.5544
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.8934
                       Mean reward: 178.10
               Mean episode length: 229.29
    Episode_Reward/reaching_object: 0.7361
    Episode_Reward/rotating_object: 35.3771
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.02s
                      Time elapsed: 00:08:46
                               ETA: 00:45:24

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 47346 steps/s (collection: 1.958s, learning 0.119s)
             Mean action noise std: 1.64
          Mean value_function loss: 65.9999
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 41.9158
                       Mean reward: 185.69
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 0.7277
    Episode_Reward/rotating_object: 36.3228
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.08s
                      Time elapsed: 00:08:48
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 47092 steps/s (collection: 1.991s, learning 0.096s)
             Mean action noise std: 1.64
          Mean value_function loss: 74.1279
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 41.9341
                       Mean reward: 172.00
               Mean episode length: 217.40
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 36.5455
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.09s
                      Time elapsed: 00:08:50
                               ETA: 00:45:18

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 46912 steps/s (collection: 2.002s, learning 0.094s)
             Mean action noise std: 1.64
          Mean value_function loss: 77.9747
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.9506
                       Mean reward: 175.84
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 0.7053
    Episode_Reward/rotating_object: 34.5000
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.10s
                      Time elapsed: 00:08:52
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 45935 steps/s (collection: 2.031s, learning 0.110s)
             Mean action noise std: 1.64
          Mean value_function loss: 82.0191
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.9638
                       Mean reward: 156.72
               Mean episode length: 219.05
    Episode_Reward/reaching_object: 0.7081
    Episode_Reward/rotating_object: 32.8212
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.14s
                      Time elapsed: 00:08:54
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 47527 steps/s (collection: 1.969s, learning 0.099s)
             Mean action noise std: 1.64
          Mean value_function loss: 80.3155
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 41.9741
                       Mean reward: 165.49
               Mean episode length: 219.50
    Episode_Reward/reaching_object: 0.6926
    Episode_Reward/rotating_object: 33.8198
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.07s
                      Time elapsed: 00:08:56
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 46692 steps/s (collection: 1.974s, learning 0.132s)
             Mean action noise std: 1.64
          Mean value_function loss: 86.9732
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.9886
                       Mean reward: 182.87
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 0.7346
    Episode_Reward/rotating_object: 35.6327
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.11s
                      Time elapsed: 00:08:58
                               ETA: 00:45:08

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 47390 steps/s (collection: 1.937s, learning 0.138s)
             Mean action noise std: 1.64
          Mean value_function loss: 80.9901
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 42.0057
                       Mean reward: 194.67
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 35.9900
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.07s
                      Time elapsed: 00:09:00
                               ETA: 00:45:06

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 47058 steps/s (collection: 1.963s, learning 0.126s)
             Mean action noise std: 1.64
          Mean value_function loss: 82.6922
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 42.0199
                       Mean reward: 209.83
               Mean episode length: 222.18
    Episode_Reward/reaching_object: 0.7580
    Episode_Reward/rotating_object: 39.0182
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.09s
                      Time elapsed: 00:09:02
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 44914 steps/s (collection: 2.060s, learning 0.129s)
             Mean action noise std: 1.64
          Mean value_function loss: 80.0934
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 42.0356
                       Mean reward: 179.53
               Mean episode length: 224.51
    Episode_Reward/reaching_object: 0.7461
    Episode_Reward/rotating_object: 36.5644
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.19s
                      Time elapsed: 00:09:05
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 45873 steps/s (collection: 2.037s, learning 0.106s)
             Mean action noise std: 1.65
          Mean value_function loss: 77.7694
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 42.0539
                       Mean reward: 187.80
               Mean episode length: 216.04
    Episode_Reward/reaching_object: 0.7290
    Episode_Reward/rotating_object: 37.3481
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.14s
                      Time elapsed: 00:09:07
                               ETA: 00:44:59

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 46042 steps/s (collection: 2.045s, learning 0.091s)
             Mean action noise std: 1.65
          Mean value_function loss: 79.8487
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.0755
                       Mean reward: 218.08
               Mean episode length: 229.42
    Episode_Reward/reaching_object: 0.7539
    Episode_Reward/rotating_object: 39.0961
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.14s
                      Time elapsed: 00:09:09
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 46858 steps/s (collection: 2.003s, learning 0.095s)
             Mean action noise std: 1.65
          Mean value_function loss: 81.0076
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.0828
                       Mean reward: 201.60
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 0.7556
    Episode_Reward/rotating_object: 39.2856
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.10s
                      Time elapsed: 00:09:11
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 46631 steps/s (collection: 2.012s, learning 0.096s)
             Mean action noise std: 1.65
          Mean value_function loss: 90.0728
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.0942
                       Mean reward: 193.61
               Mean episode length: 218.61
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 38.4933
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.11s
                      Time elapsed: 00:09:13
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 45425 steps/s (collection: 2.066s, learning 0.099s)
             Mean action noise std: 1.65
          Mean value_function loss: 86.6797
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.1081
                       Mean reward: 247.98
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 0.7619
    Episode_Reward/rotating_object: 41.3355
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.16s
                      Time elapsed: 00:09:15
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 44624 steps/s (collection: 2.029s, learning 0.174s)
             Mean action noise std: 1.65
          Mean value_function loss: 81.1228
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.1269
                       Mean reward: 247.35
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 0.7550
    Episode_Reward/rotating_object: 39.7133
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.20s
                      Time elapsed: 00:09:17
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 46957 steps/s (collection: 1.962s, learning 0.132s)
             Mean action noise std: 1.65
          Mean value_function loss: 76.1625
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.1489
                       Mean reward: 200.65
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 40.1106
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.09s
                      Time elapsed: 00:09:20
                               ETA: 00:44:45

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 46899 steps/s (collection: 2.001s, learning 0.095s)
             Mean action noise std: 1.65
          Mean value_function loss: 72.5885
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.1714
                       Mean reward: 220.00
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 41.9856
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.10s
                      Time elapsed: 00:09:22
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 43846 steps/s (collection: 2.145s, learning 0.097s)
             Mean action noise std: 1.66
          Mean value_function loss: 70.6850
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 42.1876
                       Mean reward: 196.81
               Mean episode length: 212.15
    Episode_Reward/reaching_object: 0.7459
    Episode_Reward/rotating_object: 43.2103
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.24s
                      Time elapsed: 00:09:24
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 44562 steps/s (collection: 2.101s, learning 0.105s)
             Mean action noise std: 1.66
          Mean value_function loss: 85.0946
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.2070
                       Mean reward: 211.49
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 0.7253
    Episode_Reward/rotating_object: 41.0568
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.21s
                      Time elapsed: 00:09:26
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 44528 steps/s (collection: 2.070s, learning 0.138s)
             Mean action noise std: 1.66
          Mean value_function loss: 86.0813
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 42.2197
                       Mean reward: 217.01
               Mean episode length: 224.28
    Episode_Reward/reaching_object: 0.7405
    Episode_Reward/rotating_object: 45.2618
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.21s
                      Time elapsed: 00:09:28
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 44156 steps/s (collection: 2.123s, learning 0.103s)
             Mean action noise std: 1.66
          Mean value_function loss: 99.5004
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 42.2324
                       Mean reward: 227.76
               Mean episode length: 217.69
    Episode_Reward/reaching_object: 0.6902
    Episode_Reward/rotating_object: 37.9829
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.23s
                      Time elapsed: 00:09:31
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 43472 steps/s (collection: 2.167s, learning 0.094s)
             Mean action noise std: 1.66
          Mean value_function loss: 105.7261
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.2456
                       Mean reward: 208.70
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 0.7326
    Episode_Reward/rotating_object: 45.2077
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.26s
                      Time elapsed: 00:09:33
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 44016 steps/s (collection: 2.102s, learning 0.131s)
             Mean action noise std: 1.66
          Mean value_function loss: 107.7860
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 42.2637
                       Mean reward: 185.78
               Mean episode length: 206.40
    Episode_Reward/reaching_object: 0.7183
    Episode_Reward/rotating_object: 41.6482
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.23s
                      Time elapsed: 00:09:35
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 43164 steps/s (collection: 2.151s, learning 0.127s)
             Mean action noise std: 1.66
          Mean value_function loss: 120.4040
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.2877
                       Mean reward: 207.02
               Mean episode length: 217.87
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 44.9665
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.28s
                      Time elapsed: 00:09:37
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 44397 steps/s (collection: 2.090s, learning 0.124s)
             Mean action noise std: 1.67
          Mean value_function loss: 117.0792
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.3115
                       Mean reward: 222.34
               Mean episode length: 205.01
    Episode_Reward/reaching_object: 0.7245
    Episode_Reward/rotating_object: 43.2328
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.21s
                      Time elapsed: 00:09:40
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 43950 steps/s (collection: 2.102s, learning 0.135s)
             Mean action noise std: 1.67
          Mean value_function loss: 113.6024
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 42.3204
                       Mean reward: 239.05
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 0.7815
    Episode_Reward/rotating_object: 46.0097
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.24s
                      Time elapsed: 00:09:42
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 44898 steps/s (collection: 2.081s, learning 0.109s)
             Mean action noise std: 1.67
          Mean value_function loss: 103.8405
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.3266
                       Mean reward: 211.59
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 39.9722
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.19s
                      Time elapsed: 00:09:44
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 43576 steps/s (collection: 2.067s, learning 0.189s)
             Mean action noise std: 1.67
          Mean value_function loss: 93.3006
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.3381
                       Mean reward: 215.58
               Mean episode length: 200.85
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 41.4232
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.26s
                      Time elapsed: 00:09:46
                               ETA: 00:44:22

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 41066 steps/s (collection: 2.187s, learning 0.206s)
             Mean action noise std: 1.67
          Mean value_function loss: 100.1456
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 42.3562
                       Mean reward: 217.02
               Mean episode length: 207.10
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 43.1764
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.39s
                      Time elapsed: 00:09:49
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 45577 steps/s (collection: 2.050s, learning 0.107s)
             Mean action noise std: 1.67
          Mean value_function loss: 90.4975
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.3717
                       Mean reward: 243.08
               Mean episode length: 218.78
    Episode_Reward/reaching_object: 0.7585
    Episode_Reward/rotating_object: 46.8074
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.16s
                      Time elapsed: 00:09:51
                               ETA: 00:44:19

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 44855 steps/s (collection: 2.097s, learning 0.094s)
             Mean action noise std: 1.67
          Mean value_function loss: 97.0443
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.3862
                       Mean reward: 215.59
               Mean episode length: 223.84
    Episode_Reward/reaching_object: 0.7708
    Episode_Reward/rotating_object: 47.2237
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.19s
                      Time elapsed: 00:09:53
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 45027 steps/s (collection: 2.087s, learning 0.096s)
             Mean action noise std: 1.67
          Mean value_function loss: 95.1563
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 42.4028
                       Mean reward: 285.62
               Mean episode length: 224.58
    Episode_Reward/reaching_object: 0.7853
    Episode_Reward/rotating_object: 49.8391
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.18s
                      Time elapsed: 00:09:55
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 44313 steps/s (collection: 2.093s, learning 0.125s)
             Mean action noise std: 1.67
          Mean value_function loss: 89.7263
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.4170
                       Mean reward: 269.59
               Mean episode length: 225.70
    Episode_Reward/reaching_object: 0.8058
    Episode_Reward/rotating_object: 55.0213
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.22s
                      Time elapsed: 00:09:57
                               ETA: 00:44:13

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 41507 steps/s (collection: 2.150s, learning 0.218s)
             Mean action noise std: 1.68
          Mean value_function loss: 104.1276
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 42.4368
                       Mean reward: 262.40
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 0.8144
    Episode_Reward/rotating_object: 52.6272
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.37s
                      Time elapsed: 00:10:00
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 41309 steps/s (collection: 2.242s, learning 0.138s)
             Mean action noise std: 1.68
          Mean value_function loss: 105.5868
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 42.4625
                       Mean reward: 289.85
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 0.7965
    Episode_Reward/rotating_object: 53.2000
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.38s
                      Time elapsed: 00:10:02
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 43210 steps/s (collection: 2.179s, learning 0.096s)
             Mean action noise std: 1.68
          Mean value_function loss: 105.0577
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.4787
                       Mean reward: 261.91
               Mean episode length: 226.13
    Episode_Reward/reaching_object: 0.8055
    Episode_Reward/rotating_object: 51.2129
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.28s
                      Time elapsed: 00:10:04
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 40760 steps/s (collection: 2.213s, learning 0.199s)
             Mean action noise std: 1.68
          Mean value_function loss: 102.3973
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.4907
                       Mean reward: 259.20
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 0.8149
    Episode_Reward/rotating_object: 50.6458
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.41s
                      Time elapsed: 00:10:07
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 45218 steps/s (collection: 2.072s, learning 0.102s)
             Mean action noise std: 1.68
          Mean value_function loss: 103.9454
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 42.5028
                       Mean reward: 276.08
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 0.8035
    Episode_Reward/rotating_object: 52.1589
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.17s
                      Time elapsed: 00:10:09
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 45209 steps/s (collection: 2.062s, learning 0.113s)
             Mean action noise std: 1.68
          Mean value_function loss: 91.6376
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.5186
                       Mean reward: 265.32
               Mean episode length: 211.15
    Episode_Reward/reaching_object: 0.8155
    Episode_Reward/rotating_object: 55.6048
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.17s
                      Time elapsed: 00:10:11
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 44256 steps/s (collection: 2.124s, learning 0.097s)
             Mean action noise std: 1.69
          Mean value_function loss: 95.9751
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.5388
                       Mean reward: 231.93
               Mean episode length: 214.20
    Episode_Reward/reaching_object: 0.7914
    Episode_Reward/rotating_object: 52.2538
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.22s
                      Time elapsed: 00:10:13
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 44337 steps/s (collection: 2.113s, learning 0.105s)
             Mean action noise std: 1.69
          Mean value_function loss: 91.3331
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 42.5539
                       Mean reward: 304.17
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 0.8145
    Episode_Reward/rotating_object: 54.7063
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.22s
                      Time elapsed: 00:10:16
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 44358 steps/s (collection: 2.110s, learning 0.106s)
             Mean action noise std: 1.69
          Mean value_function loss: 86.9236
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.5585
                       Mean reward: 258.38
               Mean episode length: 220.54
    Episode_Reward/reaching_object: 0.8085
    Episode_Reward/rotating_object: 53.0153
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.22s
                      Time elapsed: 00:10:18
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 44696 steps/s (collection: 2.095s, learning 0.104s)
             Mean action noise std: 1.69
          Mean value_function loss: 92.6257
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.5675
                       Mean reward: 349.82
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 0.8194
    Episode_Reward/rotating_object: 59.1695
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.20s
                      Time elapsed: 00:10:20
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.032s, learning 0.102s)
             Mean action noise std: 1.69
          Mean value_function loss: 94.6397
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.5901
                       Mean reward: 282.55
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 0.8109
    Episode_Reward/rotating_object: 60.0120
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.13s
                      Time elapsed: 00:10:22
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 45498 steps/s (collection: 2.065s, learning 0.096s)
             Mean action noise std: 1.69
          Mean value_function loss: 102.8048
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6102
                       Mean reward: 281.79
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 0.8214
    Episode_Reward/rotating_object: 55.9603
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.16s
                      Time elapsed: 00:10:24
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 42888 steps/s (collection: 2.173s, learning 0.119s)
             Mean action noise std: 1.69
          Mean value_function loss: 101.5821
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.6266
                       Mean reward: 311.80
               Mean episode length: 238.97
    Episode_Reward/reaching_object: 0.8247
    Episode_Reward/rotating_object: 59.5856
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.29s
                      Time elapsed: 00:10:27
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 43586 steps/s (collection: 2.101s, learning 0.155s)
             Mean action noise std: 1.69
          Mean value_function loss: 96.8082
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.6413
                       Mean reward: 312.77
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 0.8161
    Episode_Reward/rotating_object: 58.5878
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.26s
                      Time elapsed: 00:10:29
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 45138 steps/s (collection: 2.080s, learning 0.098s)
             Mean action noise std: 1.69
          Mean value_function loss: 102.5828
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.6557
                       Mean reward: 264.98
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 0.8205
    Episode_Reward/rotating_object: 56.1980
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.18s
                      Time elapsed: 00:10:31
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 46035 steps/s (collection: 2.025s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 108.4947
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6733
                       Mean reward: 316.22
               Mean episode length: 217.05
    Episode_Reward/reaching_object: 0.8133
    Episode_Reward/rotating_object: 60.2828
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.14s
                      Time elapsed: 00:10:33
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 46047 steps/s (collection: 2.039s, learning 0.096s)
             Mean action noise std: 1.70
          Mean value_function loss: 88.9899
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 42.6834
                       Mean reward: 306.67
               Mean episode length: 225.66
    Episode_Reward/reaching_object: 0.8292
    Episode_Reward/rotating_object: 60.3917
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.13s
                      Time elapsed: 00:10:35
                               ETA: 00:43:41

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 46016 steps/s (collection: 2.034s, learning 0.102s)
             Mean action noise std: 1.70
          Mean value_function loss: 97.7996
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 42.6913
                       Mean reward: 311.76
               Mean episode length: 223.20
    Episode_Reward/reaching_object: 0.8155
    Episode_Reward/rotating_object: 61.3117
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.14s
                      Time elapsed: 00:10:37
                               ETA: 00:43:38

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 45918 steps/s (collection: 2.037s, learning 0.104s)
             Mean action noise std: 1.70
          Mean value_function loss: 99.4558
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.6965
                       Mean reward: 292.98
               Mean episode length: 219.64
    Episode_Reward/reaching_object: 0.8524
    Episode_Reward/rotating_object: 66.7493
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.14s
                      Time elapsed: 00:10:40
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 44073 steps/s (collection: 2.066s, learning 0.164s)
             Mean action noise std: 1.70
          Mean value_function loss: 107.2119
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.7025
                       Mean reward: 327.13
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.8285
    Episode_Reward/rotating_object: 62.1032
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.23s
                      Time elapsed: 00:10:42
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 44960 steps/s (collection: 2.066s, learning 0.121s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.8190
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.7135
                       Mean reward: 300.56
               Mean episode length: 224.87
    Episode_Reward/reaching_object: 0.8207
    Episode_Reward/rotating_object: 61.5182
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.19s
                      Time elapsed: 00:10:44
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 44686 steps/s (collection: 2.098s, learning 0.102s)
             Mean action noise std: 1.70
          Mean value_function loss: 110.3988
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.7254
                       Mean reward: 338.75
               Mean episode length: 226.82
    Episode_Reward/reaching_object: 0.8243
    Episode_Reward/rotating_object: 64.6622
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.20s
                      Time elapsed: 00:10:46
                               ETA: 00:43:30

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 44982 steps/s (collection: 2.082s, learning 0.103s)
             Mean action noise std: 1.70
          Mean value_function loss: 113.9598
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.7327
                       Mean reward: 288.52
               Mean episode length: 210.13
    Episode_Reward/reaching_object: 0.7902
    Episode_Reward/rotating_object: 60.0276
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.19s
                      Time elapsed: 00:10:48
                               ETA: 00:43:28

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 44864 steps/s (collection: 2.079s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.3695
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.7397
                       Mean reward: 289.18
               Mean episode length: 211.20
    Episode_Reward/reaching_object: 0.8222
    Episode_Reward/rotating_object: 66.7397
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.19s
                      Time elapsed: 00:10:51
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 44044 steps/s (collection: 2.101s, learning 0.131s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.4202
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.7495
                       Mean reward: 343.78
               Mean episode length: 218.55
    Episode_Reward/reaching_object: 0.8195
    Episode_Reward/rotating_object: 65.9882
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.23s
                      Time elapsed: 00:10:53
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 42463 steps/s (collection: 2.194s, learning 0.121s)
             Mean action noise std: 1.70
          Mean value_function loss: 106.4171
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.7602
                       Mean reward: 372.64
               Mean episode length: 228.30
    Episode_Reward/reaching_object: 0.8210
    Episode_Reward/rotating_object: 63.1981
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.32s
                      Time elapsed: 00:10:55
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 44739 steps/s (collection: 2.097s, learning 0.101s)
             Mean action noise std: 1.70
          Mean value_function loss: 102.2628
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.7675
                       Mean reward: 297.67
               Mean episode length: 219.13
    Episode_Reward/reaching_object: 0.8334
    Episode_Reward/rotating_object: 66.0374
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.20s
                      Time elapsed: 00:10:57
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 45805 steps/s (collection: 2.044s, learning 0.103s)
             Mean action noise std: 1.70
          Mean value_function loss: 96.5496
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.7755
                       Mean reward: 363.97
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 0.8287
    Episode_Reward/rotating_object: 65.3419
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.15s
                      Time elapsed: 00:10:59
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 43780 steps/s (collection: 2.128s, learning 0.117s)
             Mean action noise std: 1.71
          Mean value_function loss: 115.5773
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.7861
                       Mean reward: 360.66
               Mean episode length: 225.91
    Episode_Reward/reaching_object: 0.8075
    Episode_Reward/rotating_object: 63.7228
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.25s
                      Time elapsed: 00:11:02
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 42591 steps/s (collection: 2.159s, learning 0.149s)
             Mean action noise std: 1.71
          Mean value_function loss: 102.4353
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.7971
                       Mean reward: 317.51
               Mean episode length: 220.16
    Episode_Reward/reaching_object: 0.8326
    Episode_Reward/rotating_object: 67.5143
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.31s
                      Time elapsed: 00:11:04
                               ETA: 00:43:14

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 43261 steps/s (collection: 2.166s, learning 0.106s)
             Mean action noise std: 1.71
          Mean value_function loss: 118.7627
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 42.8107
                       Mean reward: 368.49
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 0.8254
    Episode_Reward/rotating_object: 68.6622
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.27s
                      Time elapsed: 00:11:06
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 44657 steps/s (collection: 2.101s, learning 0.101s)
             Mean action noise std: 1.71
          Mean value_function loss: 124.8797
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.8257
                       Mean reward: 375.11
               Mean episode length: 221.25
    Episode_Reward/reaching_object: 0.8451
    Episode_Reward/rotating_object: 70.3453
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.20s
                      Time elapsed: 00:11:08
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 41742 steps/s (collection: 2.172s, learning 0.183s)
             Mean action noise std: 1.71
          Mean value_function loss: 121.8885
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 42.8360
                       Mean reward: 361.64
               Mean episode length: 224.60
    Episode_Reward/reaching_object: 0.8279
    Episode_Reward/rotating_object: 68.7255
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.36s
                      Time elapsed: 00:11:11
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 44217 steps/s (collection: 2.127s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 116.8819
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.8388
                       Mean reward: 378.65
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 0.8232
    Episode_Reward/rotating_object: 67.1824
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.22s
                      Time elapsed: 00:11:13
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 42098 steps/s (collection: 2.185s, learning 0.151s)
             Mean action noise std: 1.71
          Mean value_function loss: 109.7727
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.8455
                       Mean reward: 355.03
               Mean episode length: 211.87
    Episode_Reward/reaching_object: 0.8238
    Episode_Reward/rotating_object: 70.0105
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.34s
                      Time elapsed: 00:11:15
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 41054 steps/s (collection: 2.245s, learning 0.149s)
             Mean action noise std: 1.71
          Mean value_function loss: 118.6037
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.8556
                       Mean reward: 350.07
               Mean episode length: 214.11
    Episode_Reward/reaching_object: 0.8220
    Episode_Reward/rotating_object: 66.1102
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.39s
                      Time elapsed: 00:11:18
                               ETA: 00:43:04

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 43918 steps/s (collection: 2.093s, learning 0.146s)
             Mean action noise std: 1.71
          Mean value_function loss: 110.5008
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.8629
                       Mean reward: 381.70
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 0.8816
    Episode_Reward/rotating_object: 74.8115
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.24s
                      Time elapsed: 00:11:20
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 44476 steps/s (collection: 2.095s, learning 0.116s)
             Mean action noise std: 1.71
          Mean value_function loss: 101.6662
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.8769
                       Mean reward: 388.71
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 0.8788
    Episode_Reward/rotating_object: 75.9255
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.21s
                      Time elapsed: 00:11:22
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 43413 steps/s (collection: 2.153s, learning 0.112s)
             Mean action noise std: 1.71
          Mean value_function loss: 114.5299
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.8937
                       Mean reward: 334.35
               Mean episode length: 213.41
    Episode_Reward/reaching_object: 0.8388
    Episode_Reward/rotating_object: 74.2218
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.26s
                      Time elapsed: 00:11:24
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 44678 steps/s (collection: 2.104s, learning 0.096s)
             Mean action noise std: 1.71
          Mean value_function loss: 127.5472
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.9056
                       Mean reward: 376.20
               Mean episode length: 224.73
    Episode_Reward/reaching_object: 0.8472
    Episode_Reward/rotating_object: 73.5935
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.20s
                      Time elapsed: 00:11:27
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 38941 steps/s (collection: 2.386s, learning 0.139s)
             Mean action noise std: 1.72
          Mean value_function loss: 124.4815
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.9114
                       Mean reward: 383.63
               Mean episode length: 223.25
    Episode_Reward/reaching_object: 0.8536
    Episode_Reward/rotating_object: 75.8271
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.52s
                      Time elapsed: 00:11:29
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 35060 steps/s (collection: 2.541s, learning 0.263s)
             Mean action noise std: 1.72
          Mean value_function loss: 123.7242
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 42.9221
                       Mean reward: 393.83
               Mean episode length: 228.34
    Episode_Reward/reaching_object: 0.8791
    Episode_Reward/rotating_object: 75.0746
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.80s
                      Time elapsed: 00:11:32
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 34213 steps/s (collection: 2.652s, learning 0.222s)
             Mean action noise std: 1.72
          Mean value_function loss: 127.9552
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 42.9378
                       Mean reward: 377.52
               Mean episode length: 229.42
    Episode_Reward/reaching_object: 0.8208
    Episode_Reward/rotating_object: 68.5694
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.87s
                      Time elapsed: 00:11:35
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 34312 steps/s (collection: 2.645s, learning 0.220s)
             Mean action noise std: 1.72
          Mean value_function loss: 111.7001
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 42.9427
                       Mean reward: 395.59
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 0.8703
    Episode_Reward/rotating_object: 78.2733
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.86s
                      Time elapsed: 00:11:38
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 36611 steps/s (collection: 2.564s, learning 0.121s)
             Mean action noise std: 1.72
          Mean value_function loss: 117.8139
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.9485
                       Mean reward: 369.32
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 0.8364
    Episode_Reward/rotating_object: 73.8052
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.69s
                      Time elapsed: 00:11:40
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 36453 steps/s (collection: 2.571s, learning 0.126s)
             Mean action noise std: 1.72
          Mean value_function loss: 109.4260
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.9567
                       Mean reward: 374.08
               Mean episode length: 213.93
    Episode_Reward/reaching_object: 0.8319
    Episode_Reward/rotating_object: 74.2855
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.70s
                      Time elapsed: 00:11:43
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 35008 steps/s (collection: 2.600s, learning 0.208s)
             Mean action noise std: 1.72
          Mean value_function loss: 114.3925
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.9671
                       Mean reward: 386.32
               Mean episode length: 213.24
    Episode_Reward/reaching_object: 0.8476
    Episode_Reward/rotating_object: 76.8513
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.81s
                      Time elapsed: 00:11:46
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 39975 steps/s (collection: 2.359s, learning 0.100s)
             Mean action noise std: 1.72
          Mean value_function loss: 114.2446
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.9800
                       Mean reward: 443.38
               Mean episode length: 234.47
    Episode_Reward/reaching_object: 0.8731
    Episode_Reward/rotating_object: 78.8778
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.46s
                      Time elapsed: 00:11:48
                               ETA: 00:42:55

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 40207 steps/s (collection: 2.305s, learning 0.140s)
             Mean action noise std: 1.72
          Mean value_function loss: 123.0606
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.9876
                       Mean reward: 395.06
               Mean episode length: 219.13
    Episode_Reward/reaching_object: 0.8582
    Episode_Reward/rotating_object: 78.9499
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.44s
                      Time elapsed: 00:11:51
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 42109 steps/s (collection: 2.198s, learning 0.137s)
             Mean action noise std: 1.72
          Mean value_function loss: 128.0820
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 42.9947
                       Mean reward: 404.41
               Mean episode length: 219.83
    Episode_Reward/reaching_object: 0.8657
    Episode_Reward/rotating_object: 78.0061
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.33s
                      Time elapsed: 00:11:53
                               ETA: 00:42:52

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 42821 steps/s (collection: 2.177s, learning 0.119s)
             Mean action noise std: 1.72
          Mean value_function loss: 123.2944
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.0021
                       Mean reward: 408.78
               Mean episode length: 220.10
    Episode_Reward/reaching_object: 0.8601
    Episode_Reward/rotating_object: 77.5932
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.30s
                      Time elapsed: 00:11:55
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 40516 steps/s (collection: 2.288s, learning 0.139s)
             Mean action noise std: 1.72
          Mean value_function loss: 124.8278
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.0107
                       Mean reward: 390.51
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 0.8346
    Episode_Reward/rotating_object: 76.2172
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.43s
                      Time elapsed: 00:11:58
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 40884 steps/s (collection: 2.271s, learning 0.133s)
             Mean action noise std: 1.73
          Mean value_function loss: 118.7573
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.0227
                       Mean reward: 390.33
               Mean episode length: 220.99
    Episode_Reward/reaching_object: 0.8718
    Episode_Reward/rotating_object: 82.7461
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.40s
                      Time elapsed: 00:12:00
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 41238 steps/s (collection: 2.261s, learning 0.123s)
             Mean action noise std: 1.73
          Mean value_function loss: 120.2984
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.0364
                       Mean reward: 403.63
               Mean episode length: 214.87
    Episode_Reward/reaching_object: 0.8623
    Episode_Reward/rotating_object: 84.6222
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.38s
                      Time elapsed: 00:12:03
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 43775 steps/s (collection: 2.105s, learning 0.141s)
             Mean action noise std: 1.73
          Mean value_function loss: 121.9996
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.0468
                       Mean reward: 412.32
               Mean episode length: 224.74
    Episode_Reward/reaching_object: 0.8615
    Episode_Reward/rotating_object: 82.6666
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.25s
                      Time elapsed: 00:12:05
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 42572 steps/s (collection: 2.179s, learning 0.130s)
             Mean action noise std: 1.73
          Mean value_function loss: 122.4337
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.0540
                       Mean reward: 420.95
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 0.8766
    Episode_Reward/rotating_object: 85.8776
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.31s
                      Time elapsed: 00:12:07
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 41324 steps/s (collection: 2.254s, learning 0.125s)
             Mean action noise std: 1.73
          Mean value_function loss: 116.7236
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.0608
                       Mean reward: 409.67
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 0.8592
    Episode_Reward/rotating_object: 83.8290
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.38s
                      Time elapsed: 00:12:10
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 17760 steps/s (collection: 5.414s, learning 0.121s)
             Mean action noise std: 1.73
          Mean value_function loss: 115.6775
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.0661
                       Mean reward: 419.93
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 0.8453
    Episode_Reward/rotating_object: 80.3229
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.54s
                      Time elapsed: 00:12:15
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 13734 steps/s (collection: 7.034s, learning 0.124s)
             Mean action noise std: 1.73
          Mean value_function loss: 111.4532
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.0727
                       Mean reward: 443.41
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 0.8671
    Episode_Reward/rotating_object: 84.1627
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 7.16s
                      Time elapsed: 00:12:22
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 13062 steps/s (collection: 7.373s, learning 0.152s)
             Mean action noise std: 1.73
          Mean value_function loss: 117.1778
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 43.0785
                       Mean reward: 470.22
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 0.8647
    Episode_Reward/rotating_object: 86.8554
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 7.53s
                      Time elapsed: 00:12:30
                               ETA: 00:43:21

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 13762 steps/s (collection: 7.022s, learning 0.121s)
             Mean action noise std: 1.73
          Mean value_function loss: 115.4811
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.0853
                       Mean reward: 429.40
               Mean episode length: 221.15
    Episode_Reward/reaching_object: 0.8422
    Episode_Reward/rotating_object: 82.4149
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 7.14s
                      Time elapsed: 00:12:37
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 13831 steps/s (collection: 6.970s, learning 0.137s)
             Mean action noise std: 1.73
          Mean value_function loss: 127.4486
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.0932
                       Mean reward: 472.61
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 0.8731
    Episode_Reward/rotating_object: 85.6007
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 7.11s
                      Time elapsed: 00:12:44
                               ETA: 00:43:50

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14959 steps/s (collection: 6.438s, learning 0.133s)
             Mean action noise std: 1.73
          Mean value_function loss: 126.3874
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.1032
                       Mean reward: 450.17
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 0.8604
    Episode_Reward/rotating_object: 84.2239
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.57s
                      Time elapsed: 00:12:51
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 14541 steps/s (collection: 6.628s, learning 0.132s)
             Mean action noise std: 1.73
          Mean value_function loss: 120.4276
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.1107
                       Mean reward: 393.33
               Mean episode length: 214.90
    Episode_Reward/reaching_object: 0.8651
    Episode_Reward/rotating_object: 82.6184
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.76s
                      Time elapsed: 00:12:57
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14520 steps/s (collection: 6.630s, learning 0.140s)
             Mean action noise std: 1.73
          Mean value_function loss: 124.0948
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.1151
                       Mean reward: 410.46
               Mean episode length: 214.67
    Episode_Reward/reaching_object: 0.8373
    Episode_Reward/rotating_object: 80.0103
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.77s
                      Time elapsed: 00:13:04
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13370 steps/s (collection: 7.227s, learning 0.126s)
             Mean action noise std: 1.73
          Mean value_function loss: 117.7385
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.1251
                       Mean reward: 408.81
               Mean episode length: 211.42
    Episode_Reward/reaching_object: 0.8583
    Episode_Reward/rotating_object: 86.0900
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.35s
                      Time elapsed: 00:13:12
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 44482 steps/s (collection: 2.100s, learning 0.110s)
             Mean action noise std: 1.73
          Mean value_function loss: 122.5616
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.1318
                       Mean reward: 418.77
               Mean episode length: 216.79
    Episode_Reward/reaching_object: 0.8434
    Episode_Reward/rotating_object: 82.3828
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.21s
                      Time elapsed: 00:13:14
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 48038 steps/s (collection: 1.954s, learning 0.093s)
             Mean action noise std: 1.74
          Mean value_function loss: 126.2502
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.1409
                       Mean reward: 390.38
               Mean episode length: 202.96
    Episode_Reward/reaching_object: 0.8508
    Episode_Reward/rotating_object: 81.2903
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.05s
                      Time elapsed: 00:13:16
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 45930 steps/s (collection: 2.037s, learning 0.103s)
             Mean action noise std: 1.74
          Mean value_function loss: 120.2127
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.1506
                       Mean reward: 469.06
               Mean episode length: 228.84
    Episode_Reward/reaching_object: 0.8480
    Episode_Reward/rotating_object: 84.9255
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.14s
                      Time elapsed: 00:13:18
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 45218 steps/s (collection: 2.066s, learning 0.108s)
             Mean action noise std: 1.74
          Mean value_function loss: 127.9219
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.1614
                       Mean reward: 433.68
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 0.8664
    Episode_Reward/rotating_object: 86.5200
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.17s
                      Time elapsed: 00:13:20
                               ETA: 00:44:32

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 47756 steps/s (collection: 1.948s, learning 0.110s)
             Mean action noise std: 1.74
          Mean value_function loss: 125.7648
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.1746
                       Mean reward: 419.78
               Mean episode length: 221.83
    Episode_Reward/reaching_object: 0.8431
    Episode_Reward/rotating_object: 83.8928
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.06s
                      Time elapsed: 00:13:22
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 48495 steps/s (collection: 1.927s, learning 0.101s)
             Mean action noise std: 1.74
          Mean value_function loss: 126.9146
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.1860
                       Mean reward: 471.42
               Mean episode length: 214.80
    Episode_Reward/reaching_object: 0.8441
    Episode_Reward/rotating_object: 87.6807
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.03s
                      Time elapsed: 00:13:24
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 46126 steps/s (collection: 2.003s, learning 0.128s)
             Mean action noise std: 1.74
          Mean value_function loss: 117.3213
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.1979
                       Mean reward: 437.31
               Mean episode length: 225.36
    Episode_Reward/reaching_object: 0.8766
    Episode_Reward/rotating_object: 89.7856
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.13s
                      Time elapsed: 00:13:26
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 47456 steps/s (collection: 1.953s, learning 0.119s)
             Mean action noise std: 1.74
          Mean value_function loss: 108.4551
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.2037
                       Mean reward: 412.12
               Mean episode length: 215.15
    Episode_Reward/reaching_object: 0.8318
    Episode_Reward/rotating_object: 83.9620
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.07s
                      Time elapsed: 00:13:28
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 44926 steps/s (collection: 2.019s, learning 0.170s)
             Mean action noise std: 1.74
          Mean value_function loss: 111.2296
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.2092
                       Mean reward: 429.85
               Mean episode length: 224.67
    Episode_Reward/reaching_object: 0.8548
    Episode_Reward/rotating_object: 85.0700
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.19s
                      Time elapsed: 00:13:31
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 43776 steps/s (collection: 2.121s, learning 0.124s)
             Mean action noise std: 1.74
          Mean value_function loss: 113.9596
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.2175
                       Mean reward: 463.44
               Mean episode length: 222.07
    Episode_Reward/reaching_object: 0.8704
    Episode_Reward/rotating_object: 89.9237
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.25s
                      Time elapsed: 00:13:33
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 44362 steps/s (collection: 2.084s, learning 0.132s)
             Mean action noise std: 1.74
          Mean value_function loss: 108.3606
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.2283
                       Mean reward: 428.58
               Mean episode length: 214.70
    Episode_Reward/reaching_object: 0.8558
    Episode_Reward/rotating_object: 88.2759
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.22s
                      Time elapsed: 00:13:35
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 45105 steps/s (collection: 2.070s, learning 0.109s)
             Mean action noise std: 1.74
          Mean value_function loss: 105.8054
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.2334
                       Mean reward: 502.02
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 0.8776
    Episode_Reward/rotating_object: 94.3515
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.18s
                      Time elapsed: 00:13:37
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 47204 steps/s (collection: 1.981s, learning 0.101s)
             Mean action noise std: 1.74
          Mean value_function loss: 116.8336
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.2399
                       Mean reward: 490.73
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 0.8704
    Episode_Reward/rotating_object: 93.1999
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.08s
                      Time elapsed: 00:13:39
                               ETA: 00:44:06

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 46387 steps/s (collection: 2.023s, learning 0.096s)
             Mean action noise std: 1.74
          Mean value_function loss: 102.0095
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.2486
                       Mean reward: 434.88
               Mean episode length: 222.01
    Episode_Reward/reaching_object: 0.8705
    Episode_Reward/rotating_object: 93.7277
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.12s
                      Time elapsed: 00:13:41
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 46909 steps/s (collection: 1.931s, learning 0.165s)
             Mean action noise std: 1.75
          Mean value_function loss: 103.9595
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.2565
                       Mean reward: 426.47
               Mean episode length: 208.95
    Episode_Reward/reaching_object: 0.8489
    Episode_Reward/rotating_object: 88.6479
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.10s
                      Time elapsed: 00:13:44
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 44049 steps/s (collection: 2.037s, learning 0.195s)
             Mean action noise std: 1.75
          Mean value_function loss: 98.9421
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.2661
                       Mean reward: 462.09
               Mean episode length: 223.77
    Episode_Reward/reaching_object: 0.8518
    Episode_Reward/rotating_object: 89.6574
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.23s
                      Time elapsed: 00:13:46
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 36589 steps/s (collection: 2.551s, learning 0.136s)
             Mean action noise std: 1.75
          Mean value_function loss: 99.6418
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.2713
                       Mean reward: 491.19
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 0.8766
    Episode_Reward/rotating_object: 92.9890
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.69s
                      Time elapsed: 00:13:48
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 45388 steps/s (collection: 2.022s, learning 0.144s)
             Mean action noise std: 1.75
          Mean value_function loss: 114.4349
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.2795
                       Mean reward: 412.10
               Mean episode length: 206.81
    Episode_Reward/reaching_object: 0.8435
    Episode_Reward/rotating_object: 90.5074
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.17s
                      Time elapsed: 00:13:51
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 47522 steps/s (collection: 1.963s, learning 0.105s)
             Mean action noise std: 1.75
          Mean value_function loss: 109.5831
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 43.2883
                       Mean reward: 510.50
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 0.8841
    Episode_Reward/rotating_object: 95.7281
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.07s
                      Time elapsed: 00:13:53
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 46797 steps/s (collection: 2.002s, learning 0.099s)
             Mean action noise std: 1.75
          Mean value_function loss: 109.0139
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 43.2900
                       Mean reward: 445.44
               Mean episode length: 218.28
    Episode_Reward/reaching_object: 0.8593
    Episode_Reward/rotating_object: 93.1313
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.10s
                      Time elapsed: 00:13:55
                               ETA: 00:43:48

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 43069 steps/s (collection: 2.175s, learning 0.108s)
             Mean action noise std: 1.75
          Mean value_function loss: 109.9094
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.2924
                       Mean reward: 493.23
               Mean episode length: 222.61
    Episode_Reward/reaching_object: 0.8806
    Episode_Reward/rotating_object: 95.7822
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.28s
                      Time elapsed: 00:13:57
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 45521 steps/s (collection: 2.068s, learning 0.092s)
             Mean action noise std: 1.75
          Mean value_function loss: 102.3981
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.2963
                       Mean reward: 493.03
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 0.8660
    Episode_Reward/rotating_object: 92.0379
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.16s
                      Time elapsed: 00:13:59
                               ETA: 00:43:42

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 43417 steps/s (collection: 2.116s, learning 0.148s)
             Mean action noise std: 1.75
          Mean value_function loss: 107.5413
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.3031
                       Mean reward: 495.43
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 0.8737
    Episode_Reward/rotating_object: 93.0014
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.26s
                      Time elapsed: 00:14:01
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 45025 steps/s (collection: 2.056s, learning 0.127s)
             Mean action noise std: 1.75
          Mean value_function loss: 107.3681
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.3133
                       Mean reward: 507.48
               Mean episode length: 226.64
    Episode_Reward/reaching_object: 0.8718
    Episode_Reward/rotating_object: 95.4775
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.18s
                      Time elapsed: 00:14:04
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 44018 steps/s (collection: 2.143s, learning 0.091s)
             Mean action noise std: 1.75
          Mean value_function loss: 100.1274
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.3203
                       Mean reward: 517.35
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 0.8998
    Episode_Reward/rotating_object: 102.1463
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0294
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.23s
                      Time elapsed: 00:14:06
                               ETA: 00:43:35

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 41712 steps/s (collection: 2.264s, learning 0.093s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.2433
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.3247
                       Mean reward: 466.91
               Mean episode length: 214.33
    Episode_Reward/reaching_object: 0.8844
    Episode_Reward/rotating_object: 98.9754
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.36s
                      Time elapsed: 00:14:08
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 37412 steps/s (collection: 2.387s, learning 0.240s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.5477
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.3271
                       Mean reward: 483.95
               Mean episode length: 222.58
    Episode_Reward/reaching_object: 0.8730
    Episode_Reward/rotating_object: 96.8691
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.63s
                      Time elapsed: 00:14:11
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 44093 steps/s (collection: 2.111s, learning 0.119s)
             Mean action noise std: 1.75
          Mean value_function loss: 103.2312
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.3323
                       Mean reward: 494.05
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 0.8808
    Episode_Reward/rotating_object: 96.5295
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.23s
                      Time elapsed: 00:14:13
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 45637 steps/s (collection: 2.042s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 102.8532
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.3408
                       Mean reward: 530.49
               Mean episode length: 229.30
    Episode_Reward/reaching_object: 0.8826
    Episode_Reward/rotating_object: 100.4843
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.15s
                      Time elapsed: 00:14:15
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 45347 steps/s (collection: 2.063s, learning 0.105s)
             Mean action noise std: 1.75
          Mean value_function loss: 107.6279
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.3498
                       Mean reward: 509.38
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 0.8571
    Episode_Reward/rotating_object: 97.2815
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.17s
                      Time elapsed: 00:14:17
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 46451 steps/s (collection: 1.990s, learning 0.126s)
             Mean action noise std: 1.75
          Mean value_function loss: 107.2856
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.3542
                       Mean reward: 493.27
               Mean episode length: 217.75
    Episode_Reward/reaching_object: 0.8968
    Episode_Reward/rotating_object: 102.2387
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.12s
                      Time elapsed: 00:14:20
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 46960 steps/s (collection: 1.976s, learning 0.117s)
             Mean action noise std: 1.75
          Mean value_function loss: 111.8933
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.3562
                       Mean reward: 516.11
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 0.8583
    Episode_Reward/rotating_object: 96.7925
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.09s
                      Time elapsed: 00:14:22
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 46885 steps/s (collection: 1.975s, learning 0.122s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.0505
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.3608
                       Mean reward: 538.55
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 0.8944
    Episode_Reward/rotating_object: 103.9575
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.10s
                      Time elapsed: 00:14:24
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 46728 steps/s (collection: 1.996s, learning 0.108s)
             Mean action noise std: 1.76
          Mean value_function loss: 96.4621
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.3673
                       Mean reward: 535.39
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 0.8941
    Episode_Reward/rotating_object: 98.0603
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.10s
                      Time elapsed: 00:14:26
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 47543 steps/s (collection: 1.954s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 103.8798
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.3744
                       Mean reward: 487.79
               Mean episode length: 225.22
    Episode_Reward/reaching_object: 0.9039
    Episode_Reward/rotating_object: 102.9120
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.07s
                      Time elapsed: 00:14:28
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 46250 steps/s (collection: 2.006s, learning 0.119s)
             Mean action noise std: 1.76
          Mean value_function loss: 114.7066
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.3809
                       Mean reward: 508.16
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 0.8906
    Episode_Reward/rotating_object: 100.4680
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.13s
                      Time elapsed: 00:14:30
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 46509 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 1.76
          Mean value_function loss: 104.2128
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.3885
                       Mean reward: 529.66
               Mean episode length: 224.94
    Episode_Reward/reaching_object: 0.9080
    Episode_Reward/rotating_object: 105.5251
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.11s
                      Time elapsed: 00:14:32
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 47386 steps/s (collection: 1.967s, learning 0.108s)
             Mean action noise std: 1.76
          Mean value_function loss: 107.2648
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.3961
                       Mean reward: 501.04
               Mean episode length: 220.69
    Episode_Reward/reaching_object: 0.8713
    Episode_Reward/rotating_object: 99.3485
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.07s
                      Time elapsed: 00:14:34
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 47444 steps/s (collection: 1.954s, learning 0.118s)
             Mean action noise std: 1.76
          Mean value_function loss: 103.6249
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.4027
                       Mean reward: 532.54
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 0.8912
    Episode_Reward/rotating_object: 103.1484
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.07s
                      Time elapsed: 00:14:36
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 47289 steps/s (collection: 1.969s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 104.2217
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.4145
                       Mean reward: 514.27
               Mean episode length: 222.81
    Episode_Reward/reaching_object: 0.8895
    Episode_Reward/rotating_object: 101.0400
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.08s
                      Time elapsed: 00:14:38
                               ETA: 00:42:54

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 46494 steps/s (collection: 2.004s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 101.4650
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.4220
                       Mean reward: 534.09
               Mean episode length: 222.44
    Episode_Reward/reaching_object: 0.8960
    Episode_Reward/rotating_object: 103.9912
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.11s
                      Time elapsed: 00:14:40
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 46668 steps/s (collection: 1.990s, learning 0.117s)
             Mean action noise std: 1.76
          Mean value_function loss: 97.9575
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.4312
                       Mean reward: 519.93
               Mean episode length: 228.39
    Episode_Reward/reaching_object: 0.8934
    Episode_Reward/rotating_object: 102.2621
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.11s
                      Time elapsed: 00:14:43
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 46510 steps/s (collection: 1.985s, learning 0.128s)
             Mean action noise std: 1.76
          Mean value_function loss: 96.4030
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.4348
                       Mean reward: 485.68
               Mean episode length: 216.32
    Episode_Reward/reaching_object: 0.8723
    Episode_Reward/rotating_object: 99.7462
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.11s
                      Time elapsed: 00:14:45
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 45819 steps/s (collection: 2.030s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 105.8464
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.4390
                       Mean reward: 525.27
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 0.8940
    Episode_Reward/rotating_object: 105.3710
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.15s
                      Time elapsed: 00:14:47
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 46164 steps/s (collection: 2.014s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 95.9854
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.4454
                       Mean reward: 505.84
               Mean episode length: 224.37
    Episode_Reward/reaching_object: 0.8916
    Episode_Reward/rotating_object: 104.4685
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.13s
                      Time elapsed: 00:14:49
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 45121 steps/s (collection: 2.063s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 105.1298
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.4520
                       Mean reward: 515.15
               Mean episode length: 218.05
    Episode_Reward/reaching_object: 0.8825
    Episode_Reward/rotating_object: 105.3391
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.18s
                      Time elapsed: 00:14:51
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 46664 steps/s (collection: 1.989s, learning 0.118s)
             Mean action noise std: 1.76
          Mean value_function loss: 106.9265
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.4616
                       Mean reward: 492.08
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 0.8721
    Episode_Reward/rotating_object: 99.4901
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.11s
                      Time elapsed: 00:14:53
                               ETA: 00:42:34

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 45060 steps/s (collection: 2.066s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 102.0936
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.4695
                       Mean reward: 533.55
               Mean episode length: 226.48
    Episode_Reward/reaching_object: 0.8917
    Episode_Reward/rotating_object: 103.2873
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.18s
                      Time elapsed: 00:14:55
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 45931 steps/s (collection: 2.030s, learning 0.110s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.8415
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.4792
                       Mean reward: 531.59
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 0.9106
    Episode_Reward/rotating_object: 107.3477
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.14s
                      Time elapsed: 00:14:58
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 47879 steps/s (collection: 1.938s, learning 0.115s)
             Mean action noise std: 1.77
          Mean value_function loss: 94.2259
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.4874
                       Mean reward: 552.76
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.9226
    Episode_Reward/rotating_object: 110.2020
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.05s
                      Time elapsed: 00:15:00
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 47182 steps/s (collection: 1.968s, learning 0.115s)
             Mean action noise std: 1.77
          Mean value_function loss: 96.2403
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.4920
                       Mean reward: 551.11
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 0.9110
    Episode_Reward/rotating_object: 109.1305
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.08s
                      Time elapsed: 00:15:02
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 45089 steps/s (collection: 2.065s, learning 0.115s)
             Mean action noise std: 1.77
          Mean value_function loss: 90.6532
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.4980
                       Mean reward: 498.82
               Mean episode length: 220.03
    Episode_Reward/reaching_object: 0.8890
    Episode_Reward/rotating_object: 103.6482
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.18s
                      Time elapsed: 00:15:04
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 46791 steps/s (collection: 2.000s, learning 0.101s)
             Mean action noise std: 1.77
          Mean value_function loss: 88.6600
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.5020
                       Mean reward: 542.20
               Mean episode length: 224.70
    Episode_Reward/reaching_object: 0.9260
    Episode_Reward/rotating_object: 111.4216
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.10s
                      Time elapsed: 00:15:06
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 46229 steps/s (collection: 2.012s, learning 0.115s)
             Mean action noise std: 1.77
          Mean value_function loss: 94.2450
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.5064
                       Mean reward: 493.73
               Mean episode length: 222.84
    Episode_Reward/reaching_object: 0.9115
    Episode_Reward/rotating_object: 108.7922
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.13s
                      Time elapsed: 00:15:08
                               ETA: 00:42:15

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 46803 steps/s (collection: 1.981s, learning 0.119s)
             Mean action noise std: 1.77
          Mean value_function loss: 103.8657
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.5136
                       Mean reward: 533.51
               Mean episode length: 220.32
    Episode_Reward/reaching_object: 0.8976
    Episode_Reward/rotating_object: 107.1112
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.10s
                      Time elapsed: 00:15:10
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 47840 steps/s (collection: 1.943s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.6742
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.5206
                       Mean reward: 504.89
               Mean episode length: 220.71
    Episode_Reward/reaching_object: 0.8852
    Episode_Reward/rotating_object: 105.3561
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.05s
                      Time elapsed: 00:15:12
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 47175 steps/s (collection: 1.983s, learning 0.101s)
             Mean action noise std: 1.77
          Mean value_function loss: 104.8088
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.5274
                       Mean reward: 539.91
               Mean episode length: 223.20
    Episode_Reward/reaching_object: 0.9127
    Episode_Reward/rotating_object: 110.5318
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.08s
                      Time elapsed: 00:15:14
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 46604 steps/s (collection: 2.004s, learning 0.105s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.1429
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.5384
                       Mean reward: 544.65
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 0.8951
    Episode_Reward/rotating_object: 105.9672
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.11s
                      Time elapsed: 00:15:16
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 46418 steps/s (collection: 2.013s, learning 0.105s)
             Mean action noise std: 1.77
          Mean value_function loss: 87.4758
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.5460
                       Mean reward: 571.18
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 0.9105
    Episode_Reward/rotating_object: 106.0963
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.12s
                      Time elapsed: 00:15:19
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 43291 steps/s (collection: 2.141s, learning 0.130s)
             Mean action noise std: 1.77
          Mean value_function loss: 96.0032
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.5542
                       Mean reward: 548.60
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 0.9307
    Episode_Reward/rotating_object: 110.6030
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.27s
                      Time elapsed: 00:15:21
                               ETA: 00:41:58

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 43664 steps/s (collection: 2.132s, learning 0.119s)
             Mean action noise std: 1.77
          Mean value_function loss: 105.1192
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.5657
                       Mean reward: 555.44
               Mean episode length: 228.18
    Episode_Reward/reaching_object: 0.9233
    Episode_Reward/rotating_object: 110.0981
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.25s
                      Time elapsed: 00:15:23
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 45466 steps/s (collection: 2.050s, learning 0.113s)
             Mean action noise std: 1.77
          Mean value_function loss: 110.9769
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.5738
                       Mean reward: 498.70
               Mean episode length: 214.10
    Episode_Reward/reaching_object: 0.9093
    Episode_Reward/rotating_object: 108.6393
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.16s
                      Time elapsed: 00:15:25
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 44722 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 97.3750
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.5794
                       Mean reward: 589.12
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 0.8908
    Episode_Reward/rotating_object: 104.0027
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.20s
                      Time elapsed: 00:15:27
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 46577 steps/s (collection: 1.992s, learning 0.118s)
             Mean action noise std: 1.78
          Mean value_function loss: 92.9699
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.5894
                       Mean reward: 539.86
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 0.9322
    Episode_Reward/rotating_object: 110.0562
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.11s
                      Time elapsed: 00:15:30
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 47073 steps/s (collection: 1.971s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 105.5736
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.6045
                       Mean reward: 556.85
               Mean episode length: 224.56
    Episode_Reward/reaching_object: 0.9240
    Episode_Reward/rotating_object: 109.9030
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.09s
                      Time elapsed: 00:15:32
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 46971 steps/s (collection: 1.977s, learning 0.116s)
             Mean action noise std: 1.78
          Mean value_function loss: 98.8573
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.6203
                       Mean reward: 552.92
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 0.9185
    Episode_Reward/rotating_object: 109.6314
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.09s
                      Time elapsed: 00:15:34
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 46474 steps/s (collection: 1.997s, learning 0.118s)
             Mean action noise std: 1.78
          Mean value_function loss: 91.0130
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.6287
                       Mean reward: 533.64
               Mean episode length: 211.28
    Episode_Reward/reaching_object: 0.9145
    Episode_Reward/rotating_object: 109.9680
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.12s
                      Time elapsed: 00:15:36
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 47030 steps/s (collection: 1.982s, learning 0.109s)
             Mean action noise std: 1.78
          Mean value_function loss: 87.8082
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.6344
                       Mean reward: 558.16
               Mean episode length: 224.14
    Episode_Reward/reaching_object: 0.9229
    Episode_Reward/rotating_object: 109.8411
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.09s
                      Time elapsed: 00:15:38
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 46941 steps/s (collection: 1.986s, learning 0.108s)
             Mean action noise std: 1.78
          Mean value_function loss: 100.5495
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.6437
                       Mean reward: 562.24
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 0.9204
    Episode_Reward/rotating_object: 109.5936
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.09s
                      Time elapsed: 00:15:40
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 46541 steps/s (collection: 2.021s, learning 0.091s)
             Mean action noise std: 1.78
          Mean value_function loss: 111.6326
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.6518
                       Mean reward: 594.42
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 0.9356
    Episode_Reward/rotating_object: 112.7336
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.11s
                      Time elapsed: 00:15:42
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 46552 steps/s (collection: 2.007s, learning 0.105s)
             Mean action noise std: 1.78
          Mean value_function loss: 91.4525
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.6585
                       Mean reward: 578.42
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 0.9350
    Episode_Reward/rotating_object: 114.1648
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.11s
                      Time elapsed: 00:15:44
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 47175 steps/s (collection: 1.975s, learning 0.109s)
             Mean action noise std: 1.78
          Mean value_function loss: 104.8870
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.6668
                       Mean reward: 552.63
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 0.9359
    Episode_Reward/rotating_object: 111.7878
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.08s
                      Time elapsed: 00:15:46
                               ETA: 00:41:26

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 46673 steps/s (collection: 1.997s, learning 0.109s)
             Mean action noise std: 1.78
          Mean value_function loss: 106.5044
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.6735
                       Mean reward: 582.95
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 0.9158
    Episode_Reward/rotating_object: 111.2453
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.11s
                      Time elapsed: 00:15:48
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 46613 steps/s (collection: 1.993s, learning 0.116s)
             Mean action noise std: 1.78
          Mean value_function loss: 99.9264
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.6815
                       Mean reward: 551.46
               Mean episode length: 232.44
    Episode_Reward/reaching_object: 0.9352
    Episode_Reward/rotating_object: 112.8572
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.11s
                      Time elapsed: 00:15:51
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 47101 steps/s (collection: 1.972s, learning 0.116s)
             Mean action noise std: 1.78
          Mean value_function loss: 100.7866
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.6889
                       Mean reward: 573.07
               Mean episode length: 226.28
    Episode_Reward/reaching_object: 0.9510
    Episode_Reward/rotating_object: 112.7467
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.09s
                      Time elapsed: 00:15:53
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 47177 steps/s (collection: 1.972s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 99.8147
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.6954
                       Mean reward: 605.39
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 0.9494
    Episode_Reward/rotating_object: 114.0157
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.08s
                      Time elapsed: 00:15:55
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 47729 steps/s (collection: 1.951s, learning 0.109s)
             Mean action noise std: 1.78
          Mean value_function loss: 86.7597
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.7026
                       Mean reward: 574.23
               Mean episode length: 227.49
    Episode_Reward/reaching_object: 0.9568
    Episode_Reward/rotating_object: 115.9348
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.06s
                      Time elapsed: 00:15:57
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 47342 steps/s (collection: 1.964s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 91.8390
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.7138
                       Mean reward: 567.55
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 0.9188
    Episode_Reward/rotating_object: 109.7257
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.08s
                      Time elapsed: 00:15:59
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 46384 steps/s (collection: 2.011s, learning 0.108s)
             Mean action noise std: 1.79
          Mean value_function loss: 93.1188
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.7225
                       Mean reward: 607.96
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 0.9337
    Episode_Reward/rotating_object: 112.9708
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.12s
                      Time elapsed: 00:16:01
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 46235 steps/s (collection: 2.013s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 92.0757
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.7317
                       Mean reward: 522.62
               Mean episode length: 216.57
    Episode_Reward/reaching_object: 0.9241
    Episode_Reward/rotating_object: 113.2502
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.13s
                      Time elapsed: 00:16:03
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 46027 steps/s (collection: 2.027s, learning 0.108s)
             Mean action noise std: 1.79
          Mean value_function loss: 91.8155
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.7390
                       Mean reward: 588.77
               Mean episode length: 224.55
    Episode_Reward/reaching_object: 0.9356
    Episode_Reward/rotating_object: 113.2956
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.14s
                      Time elapsed: 00:16:05
                               ETA: 00:41:01

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 46714 steps/s (collection: 1.990s, learning 0.114s)
             Mean action noise std: 1.79
          Mean value_function loss: 90.7940
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.7473
                       Mean reward: 501.58
               Mean episode length: 213.85
    Episode_Reward/reaching_object: 0.9466
    Episode_Reward/rotating_object: 117.6954
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.10s
                      Time elapsed: 00:16:07
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 46987 steps/s (collection: 1.979s, learning 0.114s)
             Mean action noise std: 1.79
          Mean value_function loss: 91.6585
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.7560
                       Mean reward: 596.10
               Mean episode length: 227.43
    Episode_Reward/reaching_object: 0.9126
    Episode_Reward/rotating_object: 111.1154
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.09s
                      Time elapsed: 00:16:09
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 46249 steps/s (collection: 2.007s, learning 0.119s)
             Mean action noise std: 1.79
          Mean value_function loss: 96.3140
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.7644
                       Mean reward: 546.82
               Mean episode length: 224.00
    Episode_Reward/reaching_object: 0.9305
    Episode_Reward/rotating_object: 113.5060
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.13s
                      Time elapsed: 00:16:12
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 46783 steps/s (collection: 1.983s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 85.3118
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.7707
                       Mean reward: 569.95
               Mean episode length: 223.50
    Episode_Reward/reaching_object: 0.9051
    Episode_Reward/rotating_object: 109.3012
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.10s
                      Time elapsed: 00:16:14
                               ETA: 00:40:50

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 46037 steps/s (collection: 2.004s, learning 0.131s)
             Mean action noise std: 1.79
          Mean value_function loss: 89.3094
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7774
                       Mean reward: 582.39
               Mean episode length: 227.16
    Episode_Reward/reaching_object: 0.9443
    Episode_Reward/rotating_object: 115.9985
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.14s
                      Time elapsed: 00:16:16
                               ETA: 00:40:47

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 46100 steps/s (collection: 2.012s, learning 0.121s)
             Mean action noise std: 1.79
          Mean value_function loss: 98.4071
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.7837
                       Mean reward: 597.86
               Mean episode length: 228.60
    Episode_Reward/reaching_object: 0.9341
    Episode_Reward/rotating_object: 115.9105
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.13s
                      Time elapsed: 00:16:18
                               ETA: 00:40:45

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 47556 steps/s (collection: 1.957s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 94.0573
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.7872
                       Mean reward: 559.19
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 0.9581
    Episode_Reward/rotating_object: 116.9281
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.07s
                      Time elapsed: 00:16:20
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 47512 steps/s (collection: 1.954s, learning 0.115s)
             Mean action noise std: 1.79
          Mean value_function loss: 85.8186
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.7902
                       Mean reward: 621.74
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 0.9738
    Episode_Reward/rotating_object: 119.7007
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.07s
                      Time elapsed: 00:16:22
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 47091 steps/s (collection: 1.970s, learning 0.117s)
             Mean action noise std: 1.79
          Mean value_function loss: 83.8025
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.7968
                       Mean reward: 594.38
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 0.9608
    Episode_Reward/rotating_object: 119.5995
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.09s
                      Time elapsed: 00:16:24
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 46941 steps/s (collection: 1.985s, learning 0.110s)
             Mean action noise std: 1.79
          Mean value_function loss: 84.5903
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.8063
                       Mean reward: 583.98
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 0.9458
    Episode_Reward/rotating_object: 115.4887
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.09s
                      Time elapsed: 00:16:26
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 48024 steps/s (collection: 1.953s, learning 0.094s)
             Mean action noise std: 1.80
          Mean value_function loss: 97.9816
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.8200
                       Mean reward: 621.95
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.9790
    Episode_Reward/rotating_object: 121.1193
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.05s
                      Time elapsed: 00:16:28
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 47560 steps/s (collection: 1.978s, learning 0.089s)
             Mean action noise std: 1.80
          Mean value_function loss: 95.0698
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.8324
                       Mean reward: 609.55
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 0.9457
    Episode_Reward/rotating_object: 117.8805
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.07s
                      Time elapsed: 00:16:30
                               ETA: 00:40:28

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 47935 steps/s (collection: 1.939s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 95.3768
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.8382
                       Mean reward: 599.35
               Mean episode length: 222.19
    Episode_Reward/reaching_object: 0.9476
    Episode_Reward/rotating_object: 120.6185
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.05s
                      Time elapsed: 00:16:32
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 47779 steps/s (collection: 1.959s, learning 0.098s)
             Mean action noise std: 1.80
          Mean value_function loss: 101.7615
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.8480
                       Mean reward: 591.27
               Mean episode length: 224.10
    Episode_Reward/reaching_object: 0.9478
    Episode_Reward/rotating_object: 118.3684
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.06s
                      Time elapsed: 00:16:35
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 45992 steps/s (collection: 2.028s, learning 0.109s)
             Mean action noise std: 1.80
          Mean value_function loss: 95.0078
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.8543
                       Mean reward: 608.84
               Mean episode length: 224.47
    Episode_Reward/reaching_object: 0.9433
    Episode_Reward/rotating_object: 118.2037
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.14s
                      Time elapsed: 00:16:37
                               ETA: 00:40:20

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 47288 steps/s (collection: 1.971s, learning 0.108s)
             Mean action noise std: 1.80
          Mean value_function loss: 89.0732
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.8617
                       Mean reward: 569.35
               Mean episode length: 216.53
    Episode_Reward/reaching_object: 0.9486
    Episode_Reward/rotating_object: 117.0539
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.08s
                      Time elapsed: 00:16:39
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 46727 steps/s (collection: 1.987s, learning 0.117s)
             Mean action noise std: 1.80
          Mean value_function loss: 84.5155
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.8725
                       Mean reward: 588.83
               Mean episode length: 232.32
    Episode_Reward/reaching_object: 0.9490
    Episode_Reward/rotating_object: 117.3618
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.10s
                      Time elapsed: 00:16:41
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 46822 steps/s (collection: 1.986s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 80.1741
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.8809
                       Mean reward: 589.97
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 0.9441
    Episode_Reward/rotating_object: 119.5092
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.10s
                      Time elapsed: 00:16:43
                               ETA: 00:40:11

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 46576 steps/s (collection: 1.983s, learning 0.127s)
             Mean action noise std: 1.80
          Mean value_function loss: 77.8649
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.8868
                       Mean reward: 588.93
               Mean episode length: 226.90
    Episode_Reward/reaching_object: 0.9533
    Episode_Reward/rotating_object: 118.8691
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.11s
                      Time elapsed: 00:16:45
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 47113 steps/s (collection: 1.966s, learning 0.120s)
             Mean action noise std: 1.80
          Mean value_function loss: 85.9458
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.8945
                       Mean reward: 602.01
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 0.9692
    Episode_Reward/rotating_object: 121.0297
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.09s
                      Time elapsed: 00:16:47
                               ETA: 00:40:06

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 46367 steps/s (collection: 1.996s, learning 0.124s)
             Mean action noise std: 1.80
          Mean value_function loss: 85.5774
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.9023
                       Mean reward: 614.36
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.9557
    Episode_Reward/rotating_object: 118.1520
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.12s
                      Time elapsed: 00:16:49
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 46064 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 88.0811
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.9125
                       Mean reward: 608.01
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.9795
    Episode_Reward/rotating_object: 125.7821
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.13s
                      Time elapsed: 00:16:51
                               ETA: 00:40:01

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 46170 steps/s (collection: 2.007s, learning 0.123s)
             Mean action noise std: 1.80
          Mean value_function loss: 91.1147
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.9238
                       Mean reward: 577.25
               Mean episode length: 220.37
    Episode_Reward/reaching_object: 0.9392
    Episode_Reward/rotating_object: 115.2011
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.13s
                      Time elapsed: 00:16:54
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 43794 steps/s (collection: 2.125s, learning 0.120s)
             Mean action noise std: 1.81
          Mean value_function loss: 87.9908
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.9336
                       Mean reward: 605.24
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 0.9527
    Episode_Reward/rotating_object: 118.5551
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.24s
                      Time elapsed: 00:16:56
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 45090 steps/s (collection: 2.081s, learning 0.099s)
             Mean action noise std: 1.81
          Mean value_function loss: 93.9739
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.9430
                       Mean reward: 629.91
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 0.9633
    Episode_Reward/rotating_object: 120.8308
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.18s
                      Time elapsed: 00:16:58
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 44042 steps/s (collection: 2.102s, learning 0.130s)
             Mean action noise std: 1.81
          Mean value_function loss: 80.3747
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.9539
                       Mean reward: 651.05
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 0.9835
    Episode_Reward/rotating_object: 124.0925
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.23s
                      Time elapsed: 00:17:00
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 45491 steps/s (collection: 2.055s, learning 0.106s)
             Mean action noise std: 1.81
          Mean value_function loss: 84.7588
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.9615
                       Mean reward: 616.32
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 0.9725
    Episode_Reward/rotating_object: 122.7618
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.16s
                      Time elapsed: 00:17:02
                               ETA: 00:39:48

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 45862 steps/s (collection: 2.046s, learning 0.097s)
             Mean action noise std: 1.81
          Mean value_function loss: 86.2329
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 43.9708
                       Mean reward: 610.87
               Mean episode length: 220.59
    Episode_Reward/reaching_object: 0.9379
    Episode_Reward/rotating_object: 118.5106
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.14s
                      Time elapsed: 00:17:04
                               ETA: 00:39:46

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 46408 steps/s (collection: 2.022s, learning 0.097s)
             Mean action noise std: 1.81
          Mean value_function loss: 92.5109
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.9838
                       Mean reward: 585.86
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 0.9540
    Episode_Reward/rotating_object: 119.0316
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.12s
                      Time elapsed: 00:17:07
                               ETA: 00:39:43

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 46811 steps/s (collection: 2.002s, learning 0.098s)
             Mean action noise std: 1.81
          Mean value_function loss: 77.3829
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.9918
                       Mean reward: 633.72
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.9924
    Episode_Reward/rotating_object: 126.7347
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.10s
                      Time elapsed: 00:17:09
                               ETA: 00:39:41

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 47186 steps/s (collection: 1.986s, learning 0.097s)
             Mean action noise std: 1.81
          Mean value_function loss: 92.8938
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.0000
                       Mean reward: 561.98
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 0.9579
    Episode_Reward/rotating_object: 119.7148
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.08s
                      Time elapsed: 00:17:11
                               ETA: 00:39:38

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 47404 steps/s (collection: 1.977s, learning 0.096s)
             Mean action noise std: 1.81
          Mean value_function loss: 80.3731
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.0123
                       Mean reward: 627.30
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 0.9744
    Episode_Reward/rotating_object: 123.5921
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.07s
                      Time elapsed: 00:17:13
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 46580 steps/s (collection: 2.021s, learning 0.089s)
             Mean action noise std: 1.81
          Mean value_function loss: 86.4673
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.0271
                       Mean reward: 615.61
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 0.9791
    Episode_Reward/rotating_object: 123.0750
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.11s
                      Time elapsed: 00:17:15
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 45859 steps/s (collection: 2.046s, learning 0.098s)
             Mean action noise std: 1.82
          Mean value_function loss: 90.6809
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.0394
                       Mean reward: 642.43
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 0.9765
    Episode_Reward/rotating_object: 124.0385
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.14s
                      Time elapsed: 00:17:17
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 45766 steps/s (collection: 2.027s, learning 0.121s)
             Mean action noise std: 1.82
          Mean value_function loss: 82.0292
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.0520
                       Mean reward: 582.81
               Mean episode length: 227.20
    Episode_Reward/reaching_object: 0.9373
    Episode_Reward/rotating_object: 118.0688
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.15s
                      Time elapsed: 00:17:19
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 45840 steps/s (collection: 2.027s, learning 0.118s)
             Mean action noise std: 1.82
          Mean value_function loss: 91.8908
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.0651
                       Mean reward: 635.63
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 0.9834
    Episode_Reward/rotating_object: 125.9265
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.14s
                      Time elapsed: 00:17:21
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 46555 steps/s (collection: 1.993s, learning 0.118s)
             Mean action noise std: 1.82
          Mean value_function loss: 80.9143
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.0760
                       Mean reward: 619.45
               Mean episode length: 226.75
    Episode_Reward/reaching_object: 0.9661
    Episode_Reward/rotating_object: 123.5778
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.11s
                      Time elapsed: 00:17:24
                               ETA: 00:39:22

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 47206 steps/s (collection: 1.986s, learning 0.097s)
             Mean action noise std: 1.82
          Mean value_function loss: 80.7171
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.0943
                       Mean reward: 618.04
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 0.9603
    Episode_Reward/rotating_object: 122.1175
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.08s
                      Time elapsed: 00:17:26
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 45231 steps/s (collection: 2.066s, learning 0.108s)
             Mean action noise std: 1.82
          Mean value_function loss: 70.4181
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.1191
                       Mean reward: 607.74
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 0.9919
    Episode_Reward/rotating_object: 126.1714
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.17s
                      Time elapsed: 00:17:28
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 45207 steps/s (collection: 2.061s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 81.9715
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.1314
                       Mean reward: 635.90
               Mean episode length: 231.23
    Episode_Reward/reaching_object: 0.9999
    Episode_Reward/rotating_object: 129.1801
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.17s
                      Time elapsed: 00:17:30
                               ETA: 00:39:15

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 46737 steps/s (collection: 2.008s, learning 0.096s)
             Mean action noise std: 1.82
          Mean value_function loss: 78.3780
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.1339
                       Mean reward: 630.09
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 0.9723
    Episode_Reward/rotating_object: 121.3690
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.10s
                      Time elapsed: 00:17:32
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 47204 steps/s (collection: 1.984s, learning 0.099s)
             Mean action noise std: 1.82
          Mean value_function loss: 72.1305
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.1440
                       Mean reward: 657.10
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 0.9828
    Episode_Reward/rotating_object: 126.3859
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.08s
                      Time elapsed: 00:17:34
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 46682 steps/s (collection: 2.006s, learning 0.100s)
             Mean action noise std: 1.83
          Mean value_function loss: 84.5821
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.1556
                       Mean reward: 621.71
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 0.9964
    Episode_Reward/rotating_object: 128.5765
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.11s
                      Time elapsed: 00:17:36
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 47348 steps/s (collection: 1.980s, learning 0.096s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.1558
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.1693
                       Mean reward: 668.17
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 0.9918
    Episode_Reward/rotating_object: 127.6032
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.08s
                      Time elapsed: 00:17:38
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 47587 steps/s (collection: 1.975s, learning 0.091s)
             Mean action noise std: 1.83
          Mean value_function loss: 79.3540
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.1790
                       Mean reward: 620.28
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.0007
    Episode_Reward/rotating_object: 129.0558
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.07s
                      Time elapsed: 00:17:40
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 45216 steps/s (collection: 2.058s, learning 0.116s)
             Mean action noise std: 1.83
          Mean value_function loss: 71.3962
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.1918
                       Mean reward: 645.23
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.0060
    Episode_Reward/rotating_object: 131.1625
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.17s
                      Time elapsed: 00:17:43
                               ETA: 00:38:59

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 46331 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 70.0610
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.2032
                       Mean reward: 643.42
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 0.9797
    Episode_Reward/rotating_object: 126.2895
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.12s
                      Time elapsed: 00:17:45
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 46308 steps/s (collection: 2.010s, learning 0.113s)
             Mean action noise std: 1.83
          Mean value_function loss: 72.0500
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.2107
                       Mean reward: 664.17
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 0.9972
    Episode_Reward/rotating_object: 131.7108
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.12s
                      Time elapsed: 00:17:47
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 47580 steps/s (collection: 1.971s, learning 0.095s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.0146
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.2179
                       Mean reward: 663.69
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 0.9871
    Episode_Reward/rotating_object: 127.2803
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.07s
                      Time elapsed: 00:17:49
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 45963 steps/s (collection: 2.039s, learning 0.100s)
             Mean action noise std: 1.83
          Mean value_function loss: 69.0573
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.2290
                       Mean reward: 672.07
               Mean episode length: 240.61
    Episode_Reward/reaching_object: 1.0030
    Episode_Reward/rotating_object: 132.1243
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.14s
                      Time elapsed: 00:17:51
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 45930 steps/s (collection: 2.036s, learning 0.104s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.7351
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 44.2395
                       Mean reward: 672.55
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 0.9775
    Episode_Reward/rotating_object: 124.9970
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.14s
                      Time elapsed: 00:17:53
                               ETA: 00:38:46

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 46749 steps/s (collection: 2.010s, learning 0.092s)
             Mean action noise std: 1.83
          Mean value_function loss: 81.1510
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.2491
                       Mean reward: 651.55
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 0.9922
    Episode_Reward/rotating_object: 128.2245
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.10s
                      Time elapsed: 00:17:55
                               ETA: 00:38:43

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 47642 steps/s (collection: 1.954s, learning 0.109s)
             Mean action noise std: 1.84
          Mean value_function loss: 75.9375
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.2577
                       Mean reward: 655.80
               Mean episode length: 234.03
    Episode_Reward/reaching_object: 0.9879
    Episode_Reward/rotating_object: 128.2555
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.06s
                      Time elapsed: 00:17:57
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 46461 steps/s (collection: 2.006s, learning 0.110s)
             Mean action noise std: 1.84
          Mean value_function loss: 76.6868
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.2730
                       Mean reward: 643.31
               Mean episode length: 229.49
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 123.4008
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.12s
                      Time elapsed: 00:17:59
                               ETA: 00:38:38

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 46665 steps/s (collection: 2.001s, learning 0.106s)
             Mean action noise std: 1.84
          Mean value_function loss: 71.3831
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.2821
                       Mean reward: 704.52
               Mean episode length: 245.08
    Episode_Reward/reaching_object: 1.0097
    Episode_Reward/rotating_object: 133.8633
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.11s
                      Time elapsed: 00:18:02
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 46271 steps/s (collection: 2.025s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 79.5769
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.2897
                       Mean reward: 643.97
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 0.9996
    Episode_Reward/rotating_object: 129.6397
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.12s
                      Time elapsed: 00:18:04
                               ETA: 00:38:33

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 46370 steps/s (collection: 2.029s, learning 0.091s)
             Mean action noise std: 1.84
          Mean value_function loss: 76.7633
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.2954
                       Mean reward: 648.15
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 1.0030
    Episode_Reward/rotating_object: 131.2092
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.12s
                      Time elapsed: 00:18:06
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 47314 steps/s (collection: 1.980s, learning 0.098s)
             Mean action noise std: 1.84
          Mean value_function loss: 63.2449
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.3070
                       Mean reward: 660.95
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 0.9879
    Episode_Reward/rotating_object: 126.9733
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.08s
                      Time elapsed: 00:18:08
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 42658 steps/s (collection: 2.211s, learning 0.093s)
             Mean action noise std: 1.84
          Mean value_function loss: 67.5250
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.3202
                       Mean reward: 642.40
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 1.0102
    Episode_Reward/rotating_object: 133.4305
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.30s
                      Time elapsed: 00:18:10
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 45798 steps/s (collection: 2.054s, learning 0.093s)
             Mean action noise std: 1.84
          Mean value_function loss: 68.3525
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.3307
                       Mean reward: 633.17
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 0.9914
    Episode_Reward/rotating_object: 129.0772
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.15s
                      Time elapsed: 00:18:12
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 42459 steps/s (collection: 2.192s, learning 0.123s)
             Mean action noise std: 1.84
          Mean value_function loss: 72.8532
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3448
                       Mean reward: 638.40
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 1.0006
    Episode_Reward/rotating_object: 130.3997
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.32s
                      Time elapsed: 00:18:15
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 45428 steps/s (collection: 2.067s, learning 0.097s)
             Mean action noise std: 1.84
          Mean value_function loss: 70.2186
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.3610
                       Mean reward: 648.29
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 0.9865
    Episode_Reward/rotating_object: 129.1092
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.16s
                      Time elapsed: 00:18:17
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 46504 steps/s (collection: 2.013s, learning 0.101s)
             Mean action noise std: 1.85
          Mean value_function loss: 75.3915
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.3745
                       Mean reward: 681.39
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.0101
    Episode_Reward/rotating_object: 133.8002
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.11s
                      Time elapsed: 00:18:19
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 43629 steps/s (collection: 2.123s, learning 0.130s)
             Mean action noise std: 1.85
          Mean value_function loss: 72.4877
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.3867
                       Mean reward: 656.51
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 0.9989
    Episode_Reward/rotating_object: 128.7694
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.25s
                      Time elapsed: 00:18:21
                               ETA: 00:38:13

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 45733 steps/s (collection: 2.059s, learning 0.091s)
             Mean action noise std: 1.85
          Mean value_function loss: 77.4204
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.3964
                       Mean reward: 692.06
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.9994
    Episode_Reward/rotating_object: 132.4670
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.15s
                      Time elapsed: 00:18:23
                               ETA: 00:38:11

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 43169 steps/s (collection: 2.108s, learning 0.170s)
             Mean action noise std: 1.85
          Mean value_function loss: 73.8694
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.4063
                       Mean reward: 705.16
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.0011
    Episode_Reward/rotating_object: 130.8586
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.28s
                      Time elapsed: 00:18:26
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 42718 steps/s (collection: 2.201s, learning 0.101s)
             Mean action noise std: 1.85
          Mean value_function loss: 77.8748
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.4170
                       Mean reward: 611.83
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 0.9851
    Episode_Reward/rotating_object: 130.5772
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.30s
                      Time elapsed: 00:18:28
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 45267 steps/s (collection: 2.070s, learning 0.102s)
             Mean action noise std: 1.85
          Mean value_function loss: 74.8567
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.4342
                       Mean reward: 665.05
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 0.9981
    Episode_Reward/rotating_object: 132.0954
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.17s
                      Time elapsed: 00:18:30
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 45122 steps/s (collection: 2.087s, learning 0.092s)
             Mean action noise std: 1.85
          Mean value_function loss: 67.8277
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.4560
                       Mean reward: 686.54
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.0019
    Episode_Reward/rotating_object: 134.3930
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.18s
                      Time elapsed: 00:18:32
                               ETA: 00:38:02

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 46257 steps/s (collection: 2.032s, learning 0.094s)
             Mean action noise std: 1.85
          Mean value_function loss: 63.5641
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.4709
                       Mean reward: 690.84
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 131.8477
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.13s
                      Time elapsed: 00:18:34
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 42851 steps/s (collection: 2.198s, learning 0.097s)
             Mean action noise std: 1.86
          Mean value_function loss: 61.3217
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.4917
                       Mean reward: 658.79
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.0240
    Episode_Reward/rotating_object: 133.7003
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.29s
                      Time elapsed: 00:18:37
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 42676 steps/s (collection: 2.176s, learning 0.127s)
             Mean action noise std: 1.86
          Mean value_function loss: 75.4780
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.5072
                       Mean reward: 619.75
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 0.9789
    Episode_Reward/rotating_object: 129.4690
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.30s
                      Time elapsed: 00:18:39
                               ETA: 00:37:55

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 42278 steps/s (collection: 2.215s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 74.2448
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.5213
                       Mean reward: 669.07
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 0.9885
    Episode_Reward/rotating_object: 132.1428
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.33s
                      Time elapsed: 00:18:41
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 43563 steps/s (collection: 2.118s, learning 0.139s)
             Mean action noise std: 1.86
          Mean value_function loss: 68.4116
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.5360
                       Mean reward: 653.50
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 0.9789
    Episode_Reward/rotating_object: 127.7112
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.26s
                      Time elapsed: 00:18:44
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 45470 steps/s (collection: 2.047s, learning 0.115s)
             Mean action noise std: 1.86
          Mean value_function loss: 80.3852
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.5481
                       Mean reward: 673.52
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 0.9944
    Episode_Reward/rotating_object: 132.2244
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.16s
                      Time elapsed: 00:18:46
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 43347 steps/s (collection: 2.174s, learning 0.094s)
             Mean action noise std: 1.86
          Mean value_function loss: 68.9307
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.5662
                       Mean reward: 657.86
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 0.9875
    Episode_Reward/rotating_object: 131.2247
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.27s
                      Time elapsed: 00:18:48
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 44150 steps/s (collection: 2.109s, learning 0.118s)
             Mean action noise std: 1.87
          Mean value_function loss: 83.0412
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.5819
                       Mean reward: 658.30
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 0.9523
    Episode_Reward/rotating_object: 124.7203
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.23s
                      Time elapsed: 00:18:50
                               ETA: 00:37:43

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 42960 steps/s (collection: 2.191s, learning 0.097s)
             Mean action noise std: 1.87
          Mean value_function loss: 72.7924
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.6064
                       Mean reward: 646.67
               Mean episode length: 226.97
    Episode_Reward/reaching_object: 0.9595
    Episode_Reward/rotating_object: 128.9725
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.29s
                      Time elapsed: 00:18:52
                               ETA: 00:37:41

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 42825 steps/s (collection: 2.126s, learning 0.169s)
             Mean action noise std: 1.87
          Mean value_function loss: 64.6366
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.6303
                       Mean reward: 658.96
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.9837
    Episode_Reward/rotating_object: 132.4085
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.30s
                      Time elapsed: 00:18:55
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 44080 steps/s (collection: 2.083s, learning 0.148s)
             Mean action noise std: 1.87
          Mean value_function loss: 66.5891
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.6526
                       Mean reward: 671.78
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 0.9935
    Episode_Reward/rotating_object: 135.3670
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.23s
                      Time elapsed: 00:18:57
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 44661 steps/s (collection: 2.103s, learning 0.098s)
             Mean action noise std: 1.87
          Mean value_function loss: 80.7818
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.6720
                       Mean reward: 625.99
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 0.9763
    Episode_Reward/rotating_object: 130.1082
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.20s
                      Time elapsed: 00:18:59
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 44162 steps/s (collection: 2.125s, learning 0.101s)
             Mean action noise std: 1.87
          Mean value_function loss: 76.3838
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.6916
                       Mean reward: 682.97
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 0.9758
    Episode_Reward/rotating_object: 133.2556
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.23s
                      Time elapsed: 00:19:01
                               ETA: 00:37:32

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 44478 steps/s (collection: 2.080s, learning 0.131s)
             Mean action noise std: 1.88
          Mean value_function loss: 81.1719
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.7163
                       Mean reward: 667.07
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 0.9826
    Episode_Reward/rotating_object: 131.7094
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.21s
                      Time elapsed: 00:19:04
                               ETA: 00:37:29

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 41024 steps/s (collection: 2.214s, learning 0.183s)
             Mean action noise std: 1.88
          Mean value_function loss: 81.6082
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.7389
                       Mean reward: 651.42
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 0.9806
    Episode_Reward/rotating_object: 131.1774
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.40s
                      Time elapsed: 00:19:06
                               ETA: 00:37:27

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 37818 steps/s (collection: 2.389s, learning 0.211s)
             Mean action noise std: 1.88
          Mean value_function loss: 67.5698
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.7637
                       Mean reward: 651.69
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 0.9788
    Episode_Reward/rotating_object: 129.7947
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.60s
                      Time elapsed: 00:19:09
                               ETA: 00:37:26

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 35834 steps/s (collection: 2.534s, learning 0.209s)
             Mean action noise std: 1.88
          Mean value_function loss: 82.0879
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.7922
                       Mean reward: 640.13
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 0.9616
    Episode_Reward/rotating_object: 127.9838
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.74s
                      Time elapsed: 00:19:11
                               ETA: 00:37:24

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 34292 steps/s (collection: 2.701s, learning 0.166s)
             Mean action noise std: 1.89
          Mean value_function loss: 77.2943
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.8186
                       Mean reward: 650.69
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 0.9941
    Episode_Reward/rotating_object: 133.2041
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.87s
                      Time elapsed: 00:19:14
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 37521 steps/s (collection: 2.433s, learning 0.187s)
             Mean action noise std: 1.89
          Mean value_function loss: 74.5028
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.8375
                       Mean reward: 660.78
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 0.9779
    Episode_Reward/rotating_object: 131.6554
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.62s
                      Time elapsed: 00:19:17
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 36665 steps/s (collection: 2.524s, learning 0.157s)
             Mean action noise std: 1.89
          Mean value_function loss: 71.2682
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.8542
                       Mean reward: 618.55
               Mean episode length: 219.42
    Episode_Reward/reaching_object: 0.9699
    Episode_Reward/rotating_object: 127.9682
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.68s
                      Time elapsed: 00:19:20
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 41037 steps/s (collection: 2.263s, learning 0.132s)
             Mean action noise std: 1.89
          Mean value_function loss: 71.9249
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.8768
                       Mean reward: 633.47
               Mean episode length: 224.08
    Episode_Reward/reaching_object: 0.9791
    Episode_Reward/rotating_object: 129.7998
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.40s
                      Time elapsed: 00:19:22
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 38003 steps/s (collection: 2.467s, learning 0.119s)
             Mean action noise std: 1.89
          Mean value_function loss: 63.5741
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.8972
                       Mean reward: 677.53
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 0.9883
    Episode_Reward/rotating_object: 132.8335
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.59s
                      Time elapsed: 00:19:25
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 42831 steps/s (collection: 2.203s, learning 0.093s)
             Mean action noise std: 1.89
          Mean value_function loss: 75.6297
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.9124
                       Mean reward: 610.66
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 0.9598
    Episode_Reward/rotating_object: 124.9612
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.30s
                      Time elapsed: 00:19:27
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 41403 steps/s (collection: 2.255s, learning 0.120s)
             Mean action noise std: 1.90
          Mean value_function loss: 64.0181
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.9349
                       Mean reward: 667.32
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 0.9876
    Episode_Reward/rotating_object: 130.4010
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.37s
                      Time elapsed: 00:19:29
                               ETA: 00:37:12

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 43684 steps/s (collection: 2.120s, learning 0.130s)
             Mean action noise std: 1.90
          Mean value_function loss: 76.8191
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.9559
                       Mean reward: 683.24
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 0.9958
    Episode_Reward/rotating_object: 131.0567
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.25s
                      Time elapsed: 00:19:31
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 44349 steps/s (collection: 2.103s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 63.9758
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.9728
                       Mean reward: 707.63
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.9925
    Episode_Reward/rotating_object: 133.0927
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.22s
                      Time elapsed: 00:19:34
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 43851 steps/s (collection: 2.112s, learning 0.130s)
             Mean action noise std: 1.90
          Mean value_function loss: 70.5944
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.9854
                       Mean reward: 655.43
               Mean episode length: 227.48
    Episode_Reward/reaching_object: 1.0121
    Episode_Reward/rotating_object: 136.3503
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.24s
                      Time elapsed: 00:19:36
                               ETA: 00:37:05

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 45322 steps/s (collection: 2.050s, learning 0.119s)
             Mean action noise std: 1.90
          Mean value_function loss: 70.5905
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.9995
                       Mean reward: 628.43
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 0.9972
    Episode_Reward/rotating_object: 131.7007
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.17s
                      Time elapsed: 00:19:38
                               ETA: 00:37:03

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 45253 steps/s (collection: 2.069s, learning 0.103s)
             Mean action noise std: 1.90
          Mean value_function loss: 69.6287
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.0193
                       Mean reward: 671.90
               Mean episode length: 230.67
    Episode_Reward/reaching_object: 0.9830
    Episode_Reward/rotating_object: 131.7455
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.17s
                      Time elapsed: 00:19:40
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 39977 steps/s (collection: 2.197s, learning 0.262s)
             Mean action noise std: 1.90
          Mean value_function loss: 56.4107
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.0307
                       Mean reward: 721.97
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 1.0040
    Episode_Reward/rotating_object: 136.3126
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.46s
                      Time elapsed: 00:19:43
                               ETA: 00:36:59

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 39940 steps/s (collection: 2.345s, learning 0.116s)
             Mean action noise std: 1.91
          Mean value_function loss: 70.9890
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.0430
                       Mean reward: 634.38
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.0075
    Episode_Reward/rotating_object: 135.5196
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.46s
                      Time elapsed: 00:19:45
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 44713 steps/s (collection: 2.058s, learning 0.140s)
             Mean action noise std: 1.91
          Mean value_function loss: 54.6483
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.0562
                       Mean reward: 678.55
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 1.0126
    Episode_Reward/rotating_object: 136.1804
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.20s
                      Time elapsed: 00:19:47
                               ETA: 00:36:54

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 45993 steps/s (collection: 2.044s, learning 0.094s)
             Mean action noise std: 1.91
          Mean value_function loss: 61.8732
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.0679
                       Mean reward: 673.75
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.0053
    Episode_Reward/rotating_object: 134.6385
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.14s
                      Time elapsed: 00:19:50
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 40774 steps/s (collection: 2.282s, learning 0.129s)
             Mean action noise std: 1.91
          Mean value_function loss: 58.1725
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.0797
                       Mean reward: 675.78
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.0243
    Episode_Reward/rotating_object: 138.1276
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.41s
                      Time elapsed: 00:19:52
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 45016 steps/s (collection: 2.079s, learning 0.105s)
             Mean action noise std: 1.91
          Mean value_function loss: 69.4154
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.0993
                       Mean reward: 647.01
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 0.9974
    Episode_Reward/rotating_object: 133.7305
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.18s
                      Time elapsed: 00:19:54
                               ETA: 00:36:47

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 44424 steps/s (collection: 2.089s, learning 0.124s)
             Mean action noise std: 1.91
          Mean value_function loss: 52.4789
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.1219
                       Mean reward: 728.77
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 1.0250
    Episode_Reward/rotating_object: 138.5530
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.21s
                      Time elapsed: 00:19:56
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 44963 steps/s (collection: 2.055s, learning 0.131s)
             Mean action noise std: 1.91
          Mean value_function loss: 59.1763
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.1362
                       Mean reward: 705.57
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.0084
    Episode_Reward/rotating_object: 136.3124
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.19s
                      Time elapsed: 00:19:59
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 40993 steps/s (collection: 2.232s, learning 0.166s)
             Mean action noise std: 1.92
          Mean value_function loss: 62.3592
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.1509
                       Mean reward: 694.48
               Mean episode length: 241.41
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 137.4824
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.40s
                      Time elapsed: 00:20:01
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 40710 steps/s (collection: 2.288s, learning 0.126s)
             Mean action noise std: 1.92
          Mean value_function loss: 76.8884
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.1631
                       Mean reward: 710.82
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.0128
    Episode_Reward/rotating_object: 136.1588
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.41s
                      Time elapsed: 00:20:03
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 44465 steps/s (collection: 2.100s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 74.3314
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.1764
                       Mean reward: 698.54
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.9949
    Episode_Reward/rotating_object: 133.0054
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.21s
                      Time elapsed: 00:20:06
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 43807 steps/s (collection: 2.126s, learning 0.118s)
             Mean action noise std: 1.92
          Mean value_function loss: 64.0852
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.1985
                       Mean reward: 682.53
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.0166
    Episode_Reward/rotating_object: 136.3786
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.24s
                      Time elapsed: 00:20:08
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 45211 steps/s (collection: 2.041s, learning 0.134s)
             Mean action noise std: 1.92
          Mean value_function loss: 63.2981
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.2207
                       Mean reward: 674.62
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 1.0393
    Episode_Reward/rotating_object: 139.0085
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.17s
                      Time elapsed: 00:20:10
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 41759 steps/s (collection: 2.246s, learning 0.108s)
             Mean action noise std: 1.93
          Mean value_function loss: 58.2687
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.2431
                       Mean reward: 652.06
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.0256
    Episode_Reward/rotating_object: 135.6380
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.35s
                      Time elapsed: 00:20:12
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 45088 steps/s (collection: 2.076s, learning 0.105s)
             Mean action noise std: 1.93
          Mean value_function loss: 58.9354
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.2562
                       Mean reward: 713.12
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.0267
    Episode_Reward/rotating_object: 138.8293
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.18s
                      Time elapsed: 00:20:14
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 40932 steps/s (collection: 2.277s, learning 0.125s)
             Mean action noise std: 1.93
          Mean value_function loss: 61.3767
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.2729
                       Mean reward: 688.15
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.0203
    Episode_Reward/rotating_object: 135.9044
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.40s
                      Time elapsed: 00:20:17
                               ETA: 00:36:25

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 43800 steps/s (collection: 2.144s, learning 0.101s)
             Mean action noise std: 1.93
          Mean value_function loss: 54.5790
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.2942
                       Mean reward: 674.39
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0218
    Episode_Reward/rotating_object: 135.5672
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.24s
                      Time elapsed: 00:20:19
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 40250 steps/s (collection: 2.332s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 50.2768
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.3095
                       Mean reward: 719.14
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 1.0395
    Episode_Reward/rotating_object: 139.9289
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.44s
                      Time elapsed: 00:20:22
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 44004 steps/s (collection: 2.134s, learning 0.100s)
             Mean action noise std: 1.93
          Mean value_function loss: 63.7178
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.3201
                       Mean reward: 711.35
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.0149
    Episode_Reward/rotating_object: 133.2240
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.23s
                      Time elapsed: 00:20:24
                               ETA: 00:36:18

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 43887 steps/s (collection: 2.126s, learning 0.114s)
             Mean action noise std: 1.93
          Mean value_function loss: 62.2770
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.3364
                       Mean reward: 678.71
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 135.9510
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.24s
                      Time elapsed: 00:20:26
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 43183 steps/s (collection: 2.143s, learning 0.134s)
             Mean action noise std: 1.94
          Mean value_function loss: 66.2688
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.3535
                       Mean reward: 738.88
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 1.0236
    Episode_Reward/rotating_object: 138.0945
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.28s
                      Time elapsed: 00:20:28
                               ETA: 00:36:14

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 43183 steps/s (collection: 2.171s, learning 0.105s)
             Mean action noise std: 1.94
          Mean value_function loss: 63.5825
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.3729
                       Mean reward: 689.85
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0271
    Episode_Reward/rotating_object: 137.2859
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.28s
                      Time elapsed: 00:20:31
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 41159 steps/s (collection: 2.191s, learning 0.198s)
             Mean action noise std: 1.94
          Mean value_function loss: 59.9113
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.3849
                       Mean reward: 683.34
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.0223
    Episode_Reward/rotating_object: 136.5044
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.39s
                      Time elapsed: 00:20:33
                               ETA: 00:36:09

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 40561 steps/s (collection: 2.299s, learning 0.125s)
             Mean action noise std: 1.94
          Mean value_function loss: 74.1543
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.4010
                       Mean reward: 689.84
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.0312
    Episode_Reward/rotating_object: 136.3469
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.42s
                      Time elapsed: 00:20:35
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 41417 steps/s (collection: 2.272s, learning 0.102s)
             Mean action noise std: 1.94
          Mean value_function loss: 69.1549
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.4202
                       Mean reward: 709.66
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.0177
    Episode_Reward/rotating_object: 135.6034
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.37s
                      Time elapsed: 00:20:38
                               ETA: 00:36:05

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 42640 steps/s (collection: 2.082s, learning 0.223s)
             Mean action noise std: 1.94
          Mean value_function loss: 55.2296
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.4411
                       Mean reward: 701.28
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 1.0337
    Episode_Reward/rotating_object: 137.6292
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.31s
                      Time elapsed: 00:20:40
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 44103 steps/s (collection: 2.117s, learning 0.112s)
             Mean action noise std: 1.95
          Mean value_function loss: 60.4147
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.4573
                       Mean reward: 682.61
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 1.0358
    Episode_Reward/rotating_object: 138.1995
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.23s
                      Time elapsed: 00:20:42
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 41532 steps/s (collection: 2.245s, learning 0.122s)
             Mean action noise std: 1.95
          Mean value_function loss: 57.5939
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.4716
                       Mean reward: 713.51
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 140.5471
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.37s
                      Time elapsed: 00:20:45
                               ETA: 00:35:59

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 41447 steps/s (collection: 2.179s, learning 0.193s)
             Mean action noise std: 1.95
          Mean value_function loss: 58.2292
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.4915
                       Mean reward: 712.39
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.0285
    Episode_Reward/rotating_object: 138.5644
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.37s
                      Time elapsed: 00:20:47
                               ETA: 00:35:57

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 40049 steps/s (collection: 2.335s, learning 0.120s)
             Mean action noise std: 1.95
          Mean value_function loss: 60.1371
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.5114
                       Mean reward: 685.93
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.0461
    Episode_Reward/rotating_object: 139.7243
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.45s
                      Time elapsed: 00:20:50
                               ETA: 00:35:55

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 40485 steps/s (collection: 2.308s, learning 0.121s)
             Mean action noise std: 1.95
          Mean value_function loss: 50.8223
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.5248
                       Mean reward: 715.04
               Mean episode length: 242.90
    Episode_Reward/reaching_object: 1.0464
    Episode_Reward/rotating_object: 140.2570
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.43s
                      Time elapsed: 00:20:52
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 42771 steps/s (collection: 2.199s, learning 0.100s)
             Mean action noise std: 1.95
          Mean value_function loss: 53.2498
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.5382
                       Mean reward: 725.76
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 1.0476
    Episode_Reward/rotating_object: 141.1697
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.30s
                      Time elapsed: 00:20:54
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 43761 steps/s (collection: 2.151s, learning 0.096s)
             Mean action noise std: 1.95
          Mean value_function loss: 55.8753
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.5445
                       Mean reward: 725.97
               Mean episode length: 247.48
    Episode_Reward/reaching_object: 1.0442
    Episode_Reward/rotating_object: 139.3947
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.25s
                      Time elapsed: 00:20:56
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 44252 steps/s (collection: 2.122s, learning 0.099s)
             Mean action noise std: 1.96
          Mean value_function loss: 61.1060
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.5558
                       Mean reward: 695.48
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.0258
    Episode_Reward/rotating_object: 137.0066
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.22s
                      Time elapsed: 00:20:59
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 44409 steps/s (collection: 2.070s, learning 0.144s)
             Mean action noise std: 1.96
          Mean value_function loss: 61.7410
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.5737
                       Mean reward: 695.19
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 1.0232
    Episode_Reward/rotating_object: 137.8521
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.21s
                      Time elapsed: 00:21:01
                               ETA: 00:35:43

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 43201 steps/s (collection: 2.184s, learning 0.092s)
             Mean action noise std: 1.96
          Mean value_function loss: 60.3447
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.5984
                       Mean reward: 688.61
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.0140
    Episode_Reward/rotating_object: 137.4854
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.28s
                      Time elapsed: 00:21:03
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 44232 steps/s (collection: 2.114s, learning 0.109s)
             Mean action noise std: 1.96
          Mean value_function loss: 56.5441
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.6210
                       Mean reward: 696.70
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.0306
    Episode_Reward/rotating_object: 137.6262
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.22s
                      Time elapsed: 00:21:05
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 43107 steps/s (collection: 2.166s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 62.2259
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.6380
                       Mean reward: 699.60
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.0270
    Episode_Reward/rotating_object: 137.6786
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.28s
                      Time elapsed: 00:21:08
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 44141 steps/s (collection: 2.121s, learning 0.106s)
             Mean action noise std: 1.97
          Mean value_function loss: 49.9206
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.6542
                       Mean reward: 720.21
               Mean episode length: 242.91
    Episode_Reward/reaching_object: 1.0379
    Episode_Reward/rotating_object: 140.2485
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.23s
                      Time elapsed: 00:21:10
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 44995 steps/s (collection: 2.072s, learning 0.113s)
             Mean action noise std: 1.97
          Mean value_function loss: 48.2187
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.6752
                       Mean reward: 718.99
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 1.0213
    Episode_Reward/rotating_object: 137.6018
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.18s
                      Time elapsed: 00:21:12
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 44225 steps/s (collection: 2.109s, learning 0.114s)
             Mean action noise std: 1.97
          Mean value_function loss: 51.9871
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.6958
                       Mean reward: 681.10
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.0421
    Episode_Reward/rotating_object: 140.6984
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.22s
                      Time elapsed: 00:21:14
                               ETA: 00:35:30

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 43965 steps/s (collection: 2.130s, learning 0.106s)
             Mean action noise std: 1.97
          Mean value_function loss: 53.5571
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.7080
                       Mean reward: 700.54
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.0221
    Episode_Reward/rotating_object: 138.9711
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.24s
                      Time elapsed: 00:21:17
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 42993 steps/s (collection: 2.177s, learning 0.110s)
             Mean action noise std: 1.97
          Mean value_function loss: 58.4765
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.7219
                       Mean reward: 712.90
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.0400
    Episode_Reward/rotating_object: 141.7128
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.29s
                      Time elapsed: 00:21:19
                               ETA: 00:35:25

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 42215 steps/s (collection: 2.159s, learning 0.170s)
             Mean action noise std: 1.98
          Mean value_function loss: 71.3881
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.7466
                       Mean reward: 678.88
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 136.2190
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.33s
                      Time elapsed: 00:21:21
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 44323 steps/s (collection: 2.118s, learning 0.100s)
             Mean action noise std: 1.98
          Mean value_function loss: 69.7541
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.7846
                       Mean reward: 670.05
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 0.9982
    Episode_Reward/rotating_object: 133.4664
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.22s
                      Time elapsed: 00:21:23
                               ETA: 00:35:20

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 40939 steps/s (collection: 2.198s, learning 0.204s)
             Mean action noise std: 1.98
          Mean value_function loss: 62.8805
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.8221
                       Mean reward: 691.53
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.0072
    Episode_Reward/rotating_object: 135.1777
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.40s
                      Time elapsed: 00:21:26
                               ETA: 00:35:18

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 34123 steps/s (collection: 2.715s, learning 0.166s)
             Mean action noise std: 1.98
          Mean value_function loss: 63.6636
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.8495
                       Mean reward: 674.95
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0235
    Episode_Reward/rotating_object: 137.4164
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.88s
                      Time elapsed: 00:21:29
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 36143 steps/s (collection: 2.563s, learning 0.157s)
             Mean action noise std: 1.99
          Mean value_function loss: 65.1670
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.8778
                       Mean reward: 697.04
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 1.0162
    Episode_Reward/rotating_object: 136.2543
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.72s
                      Time elapsed: 00:21:31
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 34218 steps/s (collection: 2.719s, learning 0.154s)
             Mean action noise std: 1.99
          Mean value_function loss: 54.6894
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.9095
                       Mean reward: 677.56
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.0269
    Episode_Reward/rotating_object: 138.3997
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.87s
                      Time elapsed: 00:21:34
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 35229 steps/s (collection: 2.528s, learning 0.262s)
             Mean action noise std: 1.99
          Mean value_function loss: 60.6002
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.9291
                       Mean reward: 702.73
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.0298
    Episode_Reward/rotating_object: 140.3139
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.79s
                      Time elapsed: 00:21:37
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 21294 steps/s (collection: 4.090s, learning 0.526s)
             Mean action noise std: 1.99
          Mean value_function loss: 66.6538
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.9443
                       Mean reward: 690.30
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.0132
    Episode_Reward/rotating_object: 136.0794
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 4.62s
                      Time elapsed: 00:21:42
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 20204 steps/s (collection: 4.429s, learning 0.436s)
             Mean action noise std: 1.99
          Mean value_function loss: 57.6070
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.9605
                       Mean reward: 670.35
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.0112
    Episode_Reward/rotating_object: 135.4913
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 4.87s
                      Time elapsed: 00:21:47
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 31166 steps/s (collection: 2.898s, learning 0.256s)
             Mean action noise std: 2.00
          Mean value_function loss: 61.1332
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.9791
                       Mean reward: 714.64
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0347
    Episode_Reward/rotating_object: 139.6897
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 3.15s
                      Time elapsed: 00:21:50
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 33933 steps/s (collection: 2.629s, learning 0.268s)
             Mean action noise std: 2.00
          Mean value_function loss: 56.4489
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.0063
                       Mean reward: 704.53
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.0316
    Episode_Reward/rotating_object: 139.2850
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.90s
                      Time elapsed: 00:21:53
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 32133 steps/s (collection: 2.850s, learning 0.210s)
             Mean action noise std: 2.00
          Mean value_function loss: 62.2103
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.0394
                       Mean reward: 730.52
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.0402
    Episode_Reward/rotating_object: 140.9653
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 3.06s
                      Time elapsed: 00:21:56
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 28623 steps/s (collection: 3.229s, learning 0.206s)
             Mean action noise std: 2.00
          Mean value_function loss: 55.4329
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.0620
                       Mean reward: 707.28
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.0190
    Episode_Reward/rotating_object: 137.9066
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 3.43s
                      Time elapsed: 00:21:59
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 27096 steps/s (collection: 3.247s, learning 0.381s)
             Mean action noise std: 2.00
          Mean value_function loss: 65.5158
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 46.0807
                       Mean reward: 709.61
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.0398
    Episode_Reward/rotating_object: 140.2258
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 3.63s
                      Time elapsed: 00:22:03
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 30951 steps/s (collection: 3.041s, learning 0.135s)
             Mean action noise std: 2.01
          Mean value_function loss: 54.7548
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.0968
                       Mean reward: 713.03
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.0458
    Episode_Reward/rotating_object: 139.9322
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 3.18s
                      Time elapsed: 00:22:06
                               ETA: 00:35:12

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 34555 steps/s (collection: 2.703s, learning 0.142s)
             Mean action noise std: 2.01
          Mean value_function loss: 56.3216
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.1107
                       Mean reward: 708.41
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.0312
    Episode_Reward/rotating_object: 139.0894
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.84s
                      Time elapsed: 00:22:09
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 35309 steps/s (collection: 2.452s, learning 0.332s)
             Mean action noise std: 2.01
          Mean value_function loss: 58.0108
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.1359
                       Mean reward: 710.64
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 139.1752
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.78s
                      Time elapsed: 00:22:12
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 33148 steps/s (collection: 2.751s, learning 0.215s)
             Mean action noise std: 2.01
          Mean value_function loss: 55.8289
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.1615
                       Mean reward: 702.62
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 142.9354
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.97s
                      Time elapsed: 00:22:14
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 42417 steps/s (collection: 2.189s, learning 0.129s)
             Mean action noise std: 2.01
          Mean value_function loss: 59.2351
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.1821
                       Mean reward: 727.32
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 1.0442
    Episode_Reward/rotating_object: 140.6732
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.32s
                      Time elapsed: 00:22:17
                               ETA: 00:35:05

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 42741 steps/s (collection: 2.162s, learning 0.138s)
             Mean action noise std: 2.02
          Mean value_function loss: 55.8712
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.2084
                       Mean reward: 682.05
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.0171
    Episode_Reward/rotating_object: 135.8846
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.30s
                      Time elapsed: 00:22:19
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 40802 steps/s (collection: 2.192s, learning 0.217s)
             Mean action noise std: 2.02
          Mean value_function loss: 52.1948
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.2347
                       Mean reward: 707.26
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.0441
    Episode_Reward/rotating_object: 139.1487
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.41s
                      Time elapsed: 00:22:22
                               ETA: 00:35:01

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 41907 steps/s (collection: 2.250s, learning 0.096s)
             Mean action noise std: 2.02
          Mean value_function loss: 57.0549
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.2585
                       Mean reward: 727.76
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 1.0276
    Episode_Reward/rotating_object: 139.2396
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.35s
                      Time elapsed: 00:22:24
                               ETA: 00:34:59

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 44360 steps/s (collection: 2.110s, learning 0.106s)
             Mean action noise std: 2.03
          Mean value_function loss: 55.9912
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.2842
                       Mean reward: 696.68
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 1.0299
    Episode_Reward/rotating_object: 138.5912
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.22s
                      Time elapsed: 00:22:26
                               ETA: 00:34:56

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 42777 steps/s (collection: 2.099s, learning 0.199s)
             Mean action noise std: 2.03
          Mean value_function loss: 50.2436
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.3093
                       Mean reward: 703.56
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 1.0407
    Episode_Reward/rotating_object: 140.8341
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.30s
                      Time elapsed: 00:22:28
                               ETA: 00:34:54

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 43624 steps/s (collection: 2.144s, learning 0.110s)
             Mean action noise std: 2.03
          Mean value_function loss: 52.0313
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.3316
                       Mean reward: 746.28
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.0512
    Episode_Reward/rotating_object: 143.9031
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.25s
                      Time elapsed: 00:22:31
                               ETA: 00:34:52

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 43193 steps/s (collection: 2.107s, learning 0.169s)
             Mean action noise std: 2.03
          Mean value_function loss: 70.5034
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.3497
                       Mean reward: 678.73
               Mean episode length: 227.48
    Episode_Reward/reaching_object: 1.0300
    Episode_Reward/rotating_object: 139.4427
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.28s
                      Time elapsed: 00:22:33
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 42337 steps/s (collection: 2.212s, learning 0.110s)
             Mean action noise std: 2.03
          Mean value_function loss: 66.3903
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.3645
                       Mean reward: 700.43
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.0085
    Episode_Reward/rotating_object: 135.0099
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.32s
                      Time elapsed: 00:22:35
                               ETA: 00:34:47

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 43993 steps/s (collection: 2.059s, learning 0.176s)
             Mean action noise std: 2.04
          Mean value_function loss: 61.5223
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.3841
                       Mean reward: 667.54
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.0200
    Episode_Reward/rotating_object: 137.5485
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.23s
                      Time elapsed: 00:22:37
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 44247 steps/s (collection: 2.108s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 61.8813
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.4055
                       Mean reward: 660.65
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 1.0234
    Episode_Reward/rotating_object: 137.0818
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.22s
                      Time elapsed: 00:22:40
                               ETA: 00:34:42

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 44571 steps/s (collection: 2.082s, learning 0.123s)
             Mean action noise std: 2.04
          Mean value_function loss: 64.9567
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.4275
                       Mean reward: 721.05
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 1.0277
    Episode_Reward/rotating_object: 138.5580
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.21s
                      Time elapsed: 00:22:42
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 43743 steps/s (collection: 2.133s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 52.2437
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.4582
                       Mean reward: 737.00
               Mean episode length: 244.59
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 141.7965
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.25s
                      Time elapsed: 00:22:44
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 41883 steps/s (collection: 2.139s, learning 0.208s)
             Mean action noise std: 2.05
          Mean value_function loss: 51.3764
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.5016
                       Mean reward: 681.32
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.0264
    Episode_Reward/rotating_object: 137.9118
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.35s
                      Time elapsed: 00:22:46
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 40702 steps/s (collection: 2.298s, learning 0.117s)
             Mean action noise std: 2.05
          Mean value_function loss: 64.6214
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.5290
                       Mean reward: 717.51
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.0272
    Episode_Reward/rotating_object: 141.2441
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.42s
                      Time elapsed: 00:22:49
                               ETA: 00:34:33

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 45249 steps/s (collection: 2.035s, learning 0.137s)
             Mean action noise std: 2.05
          Mean value_function loss: 56.2652
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.5535
                       Mean reward: 693.54
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 1.0211
    Episode_Reward/rotating_object: 138.0727
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.17s
                      Time elapsed: 00:22:51
                               ETA: 00:34:31

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 44406 steps/s (collection: 2.062s, learning 0.152s)
             Mean action noise std: 2.05
          Mean value_function loss: 48.8366
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.5807
                       Mean reward: 725.83
               Mean episode length: 245.24
    Episode_Reward/reaching_object: 1.0586
    Episode_Reward/rotating_object: 144.3108
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.21s
                      Time elapsed: 00:22:53
                               ETA: 00:34:28

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 45968 steps/s (collection: 2.007s, learning 0.132s)
             Mean action noise std: 2.06
          Mean value_function loss: 58.2084
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.6084
                       Mean reward: 709.25
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.0244
    Episode_Reward/rotating_object: 138.2098
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.14s
                      Time elapsed: 00:22:55
                               ETA: 00:34:26

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 45229 steps/s (collection: 2.041s, learning 0.133s)
             Mean action noise std: 2.06
          Mean value_function loss: 61.8485
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.6402
                       Mean reward: 678.22
               Mean episode length: 231.14
    Episode_Reward/reaching_object: 1.0297
    Episode_Reward/rotating_object: 139.6262
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.17s
                      Time elapsed: 00:22:58
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 45357 steps/s (collection: 2.044s, learning 0.124s)
             Mean action noise std: 2.06
          Mean value_function loss: 58.6438
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.6708
                       Mean reward: 751.39
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 1.0272
    Episode_Reward/rotating_object: 139.2844
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.17s
                      Time elapsed: 00:23:00
                               ETA: 00:34:21

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 42073 steps/s (collection: 2.131s, learning 0.206s)
             Mean action noise std: 2.07
          Mean value_function loss: 62.2963
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.7030
                       Mean reward: 705.16
               Mean episode length: 237.77
    Episode_Reward/reaching_object: 1.0182
    Episode_Reward/rotating_object: 136.4768
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.34s
                      Time elapsed: 00:23:02
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 42834 steps/s (collection: 2.135s, learning 0.160s)
             Mean action noise std: 2.07
          Mean value_function loss: 74.1034
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.7261
                       Mean reward: 711.76
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 141.2107
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.29s
                      Time elapsed: 00:23:04
                               ETA: 00:34:16

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 46508 steps/s (collection: 2.018s, learning 0.096s)
             Mean action noise std: 2.07
          Mean value_function loss: 63.0185
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.7577
                       Mean reward: 720.82
               Mean episode length: 238.23
    Episode_Reward/reaching_object: 1.0341
    Episode_Reward/rotating_object: 139.8144
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.11s
                      Time elapsed: 00:23:07
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 45516 steps/s (collection: 2.052s, learning 0.108s)
             Mean action noise std: 2.07
          Mean value_function loss: 63.9030
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.7785
                       Mean reward: 686.40
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 1.0353
    Episode_Reward/rotating_object: 141.5095
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.16s
                      Time elapsed: 00:23:09
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 44990 steps/s (collection: 2.067s, learning 0.118s)
             Mean action noise std: 2.08
          Mean value_function loss: 63.5895
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.8017
                       Mean reward: 697.36
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 1.0229
    Episode_Reward/rotating_object: 137.2034
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.18s
                      Time elapsed: 00:23:11
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 46695 steps/s (collection: 1.994s, learning 0.112s)
             Mean action noise std: 2.08
          Mean value_function loss: 57.0933
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.8089
                       Mean reward: 700.77
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.0245
    Episode_Reward/rotating_object: 137.8921
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.11s
                      Time elapsed: 00:23:13
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 47336 steps/s (collection: 1.986s, learning 0.091s)
             Mean action noise std: 2.08
          Mean value_function loss: 60.0600
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.8231
                       Mean reward: 697.02
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.0406
    Episode_Reward/rotating_object: 142.1570
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.08s
                      Time elapsed: 00:23:15
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 46673 steps/s (collection: 1.993s, learning 0.114s)
             Mean action noise std: 2.08
          Mean value_function loss: 59.8465
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.8417
                       Mean reward: 698.14
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.0211
    Episode_Reward/rotating_object: 139.0257
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.11s
                      Time elapsed: 00:23:17
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 40931 steps/s (collection: 2.264s, learning 0.138s)
             Mean action noise std: 2.08
          Mean value_function loss: 59.0832
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.8621
                       Mean reward: 698.50
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.0254
    Episode_Reward/rotating_object: 138.9208
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.40s
                      Time elapsed: 00:23:20
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 46013 steps/s (collection: 2.036s, learning 0.100s)
             Mean action noise std: 2.08
          Mean value_function loss: 70.2636
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.8834
                       Mean reward: 669.84
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 1.0152
    Episode_Reward/rotating_object: 135.3565
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.14s
                      Time elapsed: 00:23:22
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 48349 steps/s (collection: 1.937s, learning 0.097s)
             Mean action noise std: 2.09
          Mean value_function loss: 54.3383
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.8959
                       Mean reward: 718.84
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.0306
    Episode_Reward/rotating_object: 140.8991
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.03s
                      Time elapsed: 00:23:24
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 45604 steps/s (collection: 2.053s, learning 0.103s)
             Mean action noise std: 2.09
          Mean value_function loss: 67.6990
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.9162
                       Mean reward: 674.12
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.0259
    Episode_Reward/rotating_object: 138.6968
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.16s
                      Time elapsed: 00:23:26
                               ETA: 00:33:51

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 43749 steps/s (collection: 2.098s, learning 0.149s)
             Mean action noise std: 2.09
          Mean value_function loss: 68.4252
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.9409
                       Mean reward: 672.22
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.0195
    Episode_Reward/rotating_object: 135.8158
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.25s
                      Time elapsed: 00:23:28
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 47835 steps/s (collection: 1.950s, learning 0.105s)
             Mean action noise std: 2.09
          Mean value_function loss: 59.4775
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.9721
                       Mean reward: 698.64
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.0301
    Episode_Reward/rotating_object: 139.7602
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.06s
                      Time elapsed: 00:23:30
                               ETA: 00:33:46

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 44967 steps/s (collection: 1.976s, learning 0.210s)
             Mean action noise std: 2.10
          Mean value_function loss: 61.6121
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.9992
                       Mean reward: 693.33
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.0266
    Episode_Reward/rotating_object: 138.9480
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.19s
                      Time elapsed: 00:23:32
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 41163 steps/s (collection: 2.221s, learning 0.167s)
             Mean action noise std: 2.10
          Mean value_function loss: 46.8559
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.0242
                       Mean reward: 692.59
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.0461
    Episode_Reward/rotating_object: 142.1028
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0304
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.39s
                      Time elapsed: 00:23:35
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 44273 steps/s (collection: 2.097s, learning 0.124s)
             Mean action noise std: 2.10
          Mean value_function loss: 66.3694
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.0499
                       Mean reward: 675.14
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.0369
    Episode_Reward/rotating_object: 140.8976
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.22s
                      Time elapsed: 00:23:37
                               ETA: 00:33:39

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 45644 steps/s (collection: 2.037s, learning 0.117s)
             Mean action noise std: 2.10
          Mean value_function loss: 57.3851
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.0838
                       Mean reward: 688.92
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.0403
    Episode_Reward/rotating_object: 141.6286
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0303
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.15s
                      Time elapsed: 00:23:39
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 46632 steps/s (collection: 2.016s, learning 0.092s)
             Mean action noise std: 2.11
          Mean value_function loss: 59.0044
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.1089
                       Mean reward: 703.58
               Mean episode length: 242.82
    Episode_Reward/reaching_object: 1.0309
    Episode_Reward/rotating_object: 137.2610
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.11s
                      Time elapsed: 00:23:41
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 46630 steps/s (collection: 2.017s, learning 0.092s)
             Mean action noise std: 2.11
          Mean value_function loss: 65.2631
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.1301
                       Mean reward: 716.98
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.0232
    Episode_Reward/rotating_object: 140.9950
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.11s
                      Time elapsed: 00:23:43
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 47326 steps/s (collection: 1.948s, learning 0.129s)
             Mean action noise std: 2.11
          Mean value_function loss: 69.8748
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.1540
                       Mean reward: 705.72
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.0101
    Episode_Reward/rotating_object: 135.8465
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0297
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.08s
                      Time elapsed: 00:23:45
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 44324 steps/s (collection: 1.966s, learning 0.252s)
             Mean action noise std: 2.12
          Mean value_function loss: 60.5950
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.1873
                       Mean reward: 697.37
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 1.0361
    Episode_Reward/rotating_object: 138.8749
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.22s
                      Time elapsed: 00:23:48
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 41870 steps/s (collection: 2.209s, learning 0.139s)
             Mean action noise std: 2.12
          Mean value_function loss: 60.7630
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.2185
                       Mean reward: 655.85
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 1.0282
    Episode_Reward/rotating_object: 139.0739
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.35s
                      Time elapsed: 00:23:50
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 44696 steps/s (collection: 2.108s, learning 0.091s)
             Mean action noise std: 2.12
          Mean value_function loss: 52.6416
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.2386
                       Mean reward: 722.02
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 1.0394
    Episode_Reward/rotating_object: 141.6131
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.20s
                      Time elapsed: 00:23:52
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 45502 steps/s (collection: 2.054s, learning 0.107s)
             Mean action noise std: 2.12
          Mean value_function loss: 62.3069
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.2661
                       Mean reward: 693.45
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.0271
    Episode_Reward/rotating_object: 138.0870
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.16s
                      Time elapsed: 00:23:54
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 45138 steps/s (collection: 2.054s, learning 0.124s)
             Mean action noise std: 2.13
          Mean value_function loss: 65.2921
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.2922
                       Mean reward: 725.04
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 1.0348
    Episode_Reward/rotating_object: 140.9538
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.18s
                      Time elapsed: 00:23:57
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 46035 steps/s (collection: 2.037s, learning 0.099s)
             Mean action noise std: 2.13
          Mean value_function loss: 55.1672
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.3185
                       Mean reward: 729.67
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 1.0329
    Episode_Reward/rotating_object: 139.5122
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.14s
                      Time elapsed: 00:23:59
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 46018 steps/s (collection: 2.012s, learning 0.124s)
             Mean action noise std: 2.13
          Mean value_function loss: 44.4327
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.3412
                       Mean reward: 667.42
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 1.0223
    Episode_Reward/rotating_object: 137.2137
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.14s
                      Time elapsed: 00:24:01
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 47072 steps/s (collection: 1.977s, learning 0.111s)
             Mean action noise std: 2.13
          Mean value_function loss: 54.3338
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.3550
                       Mean reward: 693.32
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.0365
    Episode_Reward/rotating_object: 139.5529
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.09s
                      Time elapsed: 00:24:03
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 46274 steps/s (collection: 1.996s, learning 0.128s)
             Mean action noise std: 2.13
          Mean value_function loss: 62.6953
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.3754
                       Mean reward: 678.18
               Mean episode length: 233.75
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 141.0419
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.12s
                      Time elapsed: 00:24:05
                               ETA: 00:33:07

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 46411 steps/s (collection: 2.014s, learning 0.104s)
             Mean action noise std: 2.14
          Mean value_function loss: 54.9047
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.4102
                       Mean reward: 706.45
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0684
    Episode_Reward/rotating_object: 144.2394
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.12s
                      Time elapsed: 00:24:07
                               ETA: 00:33:05

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 47554 steps/s (collection: 1.978s, learning 0.090s)
             Mean action noise std: 2.14
          Mean value_function loss: 65.9285
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.4365
                       Mean reward: 683.79
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 1.0278
    Episode_Reward/rotating_object: 137.6652
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.07s
                      Time elapsed: 00:24:09
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 47028 steps/s (collection: 1.973s, learning 0.117s)
             Mean action noise std: 2.14
          Mean value_function loss: 56.4534
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.4646
                       Mean reward: 745.07
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.0506
    Episode_Reward/rotating_object: 143.5174
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.09s
                      Time elapsed: 00:24:11
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 47565 steps/s (collection: 1.947s, learning 0.120s)
             Mean action noise std: 2.15
          Mean value_function loss: 66.0272
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.4979
                       Mean reward: 701.85
               Mean episode length: 234.72
    Episode_Reward/reaching_object: 1.0275
    Episode_Reward/rotating_object: 138.0167
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.07s
                      Time elapsed: 00:24:13
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 43632 steps/s (collection: 2.094s, learning 0.159s)
             Mean action noise std: 2.15
          Mean value_function loss: 54.2430
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.5268
                       Mean reward: 693.35
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.0352
    Episode_Reward/rotating_object: 139.2509
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.25s
                      Time elapsed: 00:24:16
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 45963 steps/s (collection: 1.995s, learning 0.144s)
             Mean action noise std: 2.15
          Mean value_function loss: 67.7486
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.5486
                       Mean reward: 703.50
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.0349
    Episode_Reward/rotating_object: 139.7678
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.14s
                      Time elapsed: 00:24:18
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 47888 steps/s (collection: 1.934s, learning 0.119s)
             Mean action noise std: 2.15
          Mean value_function loss: 53.9591
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.5678
                       Mean reward: 696.42
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 1.0334
    Episode_Reward/rotating_object: 140.5220
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.05s
                      Time elapsed: 00:24:20
                               ETA: 00:32:49

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 48127 steps/s (collection: 1.945s, learning 0.098s)
             Mean action noise std: 2.16
          Mean value_function loss: 70.8931
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.5893
                       Mean reward: 677.87
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.0367
    Episode_Reward/rotating_object: 140.1434
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.04s
                      Time elapsed: 00:24:22
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 47606 steps/s (collection: 1.962s, learning 0.102s)
             Mean action noise std: 2.16
          Mean value_function loss: 60.9740
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.6260
                       Mean reward: 727.64
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 1.0397
    Episode_Reward/rotating_object: 140.2797
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.06s
                      Time elapsed: 00:24:24
                               ETA: 00:32:44

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 47143 steps/s (collection: 1.981s, learning 0.105s)
             Mean action noise std: 2.16
          Mean value_function loss: 60.2288
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.6589
                       Mean reward: 707.68
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.0455
    Episode_Reward/rotating_object: 141.8935
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.09s
                      Time elapsed: 00:24:26
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 47143 steps/s (collection: 1.965s, learning 0.121s)
             Mean action noise std: 2.17
          Mean value_function loss: 56.6162
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.6922
                       Mean reward: 709.84
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.0358
    Episode_Reward/rotating_object: 141.2695
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.09s
                      Time elapsed: 00:24:28
                               ETA: 00:32:39

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 47449 steps/s (collection: 1.970s, learning 0.102s)
             Mean action noise std: 2.17
          Mean value_function loss: 59.3349
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.7137
                       Mean reward: 698.16
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.0407
    Episode_Reward/rotating_object: 140.5162
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.07s
                      Time elapsed: 00:24:30
                               ETA: 00:32:37

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 47160 steps/s (collection: 1.994s, learning 0.091s)
             Mean action noise std: 2.17
          Mean value_function loss: 59.3296
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.7350
                       Mean reward: 703.00
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.0364
    Episode_Reward/rotating_object: 140.1357
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.08s
                      Time elapsed: 00:24:32
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 47307 steps/s (collection: 1.987s, learning 0.091s)
             Mean action noise std: 2.17
          Mean value_function loss: 60.1132
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.7604
                       Mean reward: 707.22
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.0237
    Episode_Reward/rotating_object: 138.8582
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.08s
                      Time elapsed: 00:24:34
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 46423 steps/s (collection: 2.000s, learning 0.117s)
             Mean action noise std: 2.17
          Mean value_function loss: 64.9633
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.7774
                       Mean reward: 710.72
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 1.0379
    Episode_Reward/rotating_object: 140.7139
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.12s
                      Time elapsed: 00:24:36
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 45052 steps/s (collection: 2.046s, learning 0.136s)
             Mean action noise std: 2.18
          Mean value_function loss: 55.7984
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.7978
                       Mean reward: 734.20
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 1.0410
    Episode_Reward/rotating_object: 141.7910
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.18s
                      Time elapsed: 00:24:39
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 41199 steps/s (collection: 2.144s, learning 0.242s)
             Mean action noise std: 2.18
          Mean value_function loss: 58.1961
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.8205
                       Mean reward: 741.79
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 140.4705
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.39s
                      Time elapsed: 00:24:41
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 46700 steps/s (collection: 2.012s, learning 0.093s)
             Mean action noise std: 2.18
          Mean value_function loss: 61.5276
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.8450
                       Mean reward: 670.31
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.0185
    Episode_Reward/rotating_object: 136.8753
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.10s
                      Time elapsed: 00:24:43
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 46205 steps/s (collection: 1.998s, learning 0.129s)
             Mean action noise std: 2.18
          Mean value_function loss: 70.4031
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.8708
                       Mean reward: 720.56
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 1.0490
    Episode_Reward/rotating_object: 140.4446
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.13s
                      Time elapsed: 00:24:45
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 42389 steps/s (collection: 2.193s, learning 0.126s)
             Mean action noise std: 2.19
          Mean value_function loss: 61.7502
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.9022
                       Mean reward: 693.34
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 138.9690
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.32s
                      Time elapsed: 00:24:48
                               ETA: 00:32:17

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 42201 steps/s (collection: 2.209s, learning 0.120s)
             Mean action noise std: 2.19
          Mean value_function loss: 57.5441
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.9291
                       Mean reward: 672.72
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 1.0277
    Episode_Reward/rotating_object: 138.1784
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.33s
                      Time elapsed: 00:24:50
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 45957 steps/s (collection: 2.040s, learning 0.099s)
             Mean action noise std: 2.19
          Mean value_function loss: 65.0489
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.9460
                       Mean reward: 680.25
               Mean episode length: 231.99
    Episode_Reward/reaching_object: 1.0274
    Episode_Reward/rotating_object: 137.6333
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.14s
                      Time elapsed: 00:24:52
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 46552 steps/s (collection: 2.014s, learning 0.098s)
             Mean action noise std: 2.19
          Mean value_function loss: 65.5391
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.9633
                       Mean reward: 712.63
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 1.0343
    Episode_Reward/rotating_object: 138.4704
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.11s
                      Time elapsed: 00:24:54
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 47214 steps/s (collection: 1.992s, learning 0.090s)
             Mean action noise std: 2.20
          Mean value_function loss: 56.3535
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.9949
                       Mean reward: 694.76
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.0434
    Episode_Reward/rotating_object: 140.6465
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.08s
                      Time elapsed: 00:24:56
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 44219 steps/s (collection: 2.114s, learning 0.109s)
             Mean action noise std: 2.20
          Mean value_function loss: 68.2319
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.0261
                       Mean reward: 700.64
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.0347
    Episode_Reward/rotating_object: 138.6293
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.22s
                      Time elapsed: 00:24:58
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 45783 steps/s (collection: 2.027s, learning 0.120s)
             Mean action noise std: 2.20
          Mean value_function loss: 72.0682
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 48.0433
                       Mean reward: 677.16
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 1.0254
    Episode_Reward/rotating_object: 137.6645
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.15s
                      Time elapsed: 00:25:01
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 44475 steps/s (collection: 2.105s, learning 0.105s)
             Mean action noise std: 2.20
          Mean value_function loss: 64.2347
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.0599
                       Mean reward: 704.68
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0261
    Episode_Reward/rotating_object: 138.3483
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.21s
                      Time elapsed: 00:25:03
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 46097 steps/s (collection: 2.039s, learning 0.094s)
             Mean action noise std: 2.21
          Mean value_function loss: 49.7937
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.0916
                       Mean reward: 711.22
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0333
    Episode_Reward/rotating_object: 139.9481
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.13s
                      Time elapsed: 00:25:05
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 46148 steps/s (collection: 2.020s, learning 0.110s)
             Mean action noise std: 2.21
          Mean value_function loss: 61.0971
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.1111
                       Mean reward: 689.54
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.0306
    Episode_Reward/rotating_object: 137.5869
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.13s
                      Time elapsed: 00:25:07
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 46471 steps/s (collection: 2.022s, learning 0.094s)
             Mean action noise std: 2.21
          Mean value_function loss: 61.4790
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.1226
                       Mean reward: 692.05
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.0315
    Episode_Reward/rotating_object: 140.1847
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.12s
                      Time elapsed: 00:25:09
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 45524 steps/s (collection: 2.030s, learning 0.130s)
             Mean action noise std: 2.21
          Mean value_function loss: 70.7772
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.1473
                       Mean reward: 722.49
               Mean episode length: 240.56
    Episode_Reward/reaching_object: 1.0392
    Episode_Reward/rotating_object: 139.9266
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.16s
                      Time elapsed: 00:25:11
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 45441 steps/s (collection: 2.060s, learning 0.103s)
             Mean action noise std: 2.22
          Mean value_function loss: 61.3848
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.1768
                       Mean reward: 695.37
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 1.0171
    Episode_Reward/rotating_object: 136.7108
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.16s
                      Time elapsed: 00:25:13
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 42117 steps/s (collection: 2.188s, learning 0.146s)
             Mean action noise std: 2.22
          Mean value_function loss: 61.1907
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.2003
                       Mean reward: 710.25
               Mean episode length: 236.77
    Episode_Reward/reaching_object: 1.0425
    Episode_Reward/rotating_object: 141.1215
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.33s
                      Time elapsed: 00:25:16
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 45685 steps/s (collection: 2.044s, learning 0.108s)
             Mean action noise std: 2.22
          Mean value_function loss: 49.4869
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.2224
                       Mean reward: 736.04
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 1.0412
    Episode_Reward/rotating_object: 141.4345
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.15s
                      Time elapsed: 00:25:18
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 26590 steps/s (collection: 3.582s, learning 0.115s)
             Mean action noise std: 2.22
          Mean value_function loss: 57.1338
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.2522
                       Mean reward: 699.48
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 1.0389
    Episode_Reward/rotating_object: 140.5342
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.70s
                      Time elapsed: 00:25:22
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 14286 steps/s (collection: 6.757s, learning 0.124s)
             Mean action noise std: 2.23
          Mean value_function loss: 47.9768
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.2882
                       Mean reward: 725.77
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.0395
    Episode_Reward/rotating_object: 141.5182
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.88s
                      Time elapsed: 00:25:29
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 14087 steps/s (collection: 6.864s, learning 0.114s)
             Mean action noise std: 2.23
          Mean value_function loss: 65.1252
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.3172
                       Mean reward: 702.14
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 1.0381
    Episode_Reward/rotating_object: 143.6400
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.98s
                      Time elapsed: 00:25:36
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14257 steps/s (collection: 6.763s, learning 0.133s)
             Mean action noise std: 2.23
          Mean value_function loss: 58.6636
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.3463
                       Mean reward: 684.80
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 1.0249
    Episode_Reward/rotating_object: 139.7687
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.90s
                      Time elapsed: 00:25:42
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14069 steps/s (collection: 6.867s, learning 0.120s)
             Mean action noise std: 2.24
          Mean value_function loss: 74.8391
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.3807
                       Mean reward: 686.30
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.0083
    Episode_Reward/rotating_object: 136.0065
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.99s
                      Time elapsed: 00:25:49
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14070 steps/s (collection: 6.837s, learning 0.149s)
             Mean action noise std: 2.24
          Mean value_function loss: 61.0371
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.4163
                       Mean reward: 689.69
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 1.0339
    Episode_Reward/rotating_object: 140.0842
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.99s
                      Time elapsed: 00:25:56
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14276 steps/s (collection: 6.741s, learning 0.145s)
             Mean action noise std: 2.24
          Mean value_function loss: 60.3486
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.4521
                       Mean reward: 718.43
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.0247
    Episode_Reward/rotating_object: 137.7469
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.89s
                      Time elapsed: 00:26:03
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14002 steps/s (collection: 6.884s, learning 0.137s)
             Mean action noise std: 2.25
          Mean value_function loss: 58.4425
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 48.4750
                       Mean reward: 708.84
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 1.0383
    Episode_Reward/rotating_object: 140.5191
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 7.02s
                      Time elapsed: 00:26:10
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14248 steps/s (collection: 6.768s, learning 0.132s)
             Mean action noise std: 2.25
          Mean value_function loss: 57.6133
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.4941
                       Mean reward: 705.22
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.0218
    Episode_Reward/rotating_object: 139.5027
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.90s
                      Time elapsed: 00:26:17
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 21409 steps/s (collection: 4.421s, learning 0.171s)
             Mean action noise std: 2.25
          Mean value_function loss: 61.7309
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.5249
                       Mean reward: 688.30
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.0283
    Episode_Reward/rotating_object: 139.3602
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.59s
                      Time elapsed: 00:26:22
                               ETA: 00:32:11

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 47030 steps/s (collection: 1.981s, learning 0.110s)
             Mean action noise std: 2.26
          Mean value_function loss: 55.7485
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 48.5575
                       Mean reward: 705.67
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.0429
    Episode_Reward/rotating_object: 142.3262
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.09s
                      Time elapsed: 00:26:24
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 47546 steps/s (collection: 1.977s, learning 0.091s)
             Mean action noise std: 2.26
          Mean value_function loss: 73.3116
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.5858
                       Mean reward: 691.73
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 1.0215
    Episode_Reward/rotating_object: 138.7715
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.07s
                      Time elapsed: 00:26:26
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 46720 steps/s (collection: 2.014s, learning 0.090s)
             Mean action noise std: 2.26
          Mean value_function loss: 61.7821
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.6160
                       Mean reward: 702.82
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 1.0340
    Episode_Reward/rotating_object: 140.5877
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.10s
                      Time elapsed: 00:26:28
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 48724 steps/s (collection: 1.929s, learning 0.089s)
             Mean action noise std: 2.27
          Mean value_function loss: 64.6444
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 48.6457
                       Mean reward: 722.99
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.0328
    Episode_Reward/rotating_object: 140.2637
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.02s
                      Time elapsed: 00:26:30
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 47466 steps/s (collection: 1.971s, learning 0.100s)
             Mean action noise std: 2.27
          Mean value_function loss: 69.6081
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.6830
                       Mean reward: 695.90
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 1.0278
    Episode_Reward/rotating_object: 138.3499
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.07s
                      Time elapsed: 00:26:32
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 47592 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 2.27
          Mean value_function loss: 52.0201
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 48.7117
                       Mean reward: 718.94
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 1.0335
    Episode_Reward/rotating_object: 138.2049
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.07s
                      Time elapsed: 00:26:34
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 46298 steps/s (collection: 1.950s, learning 0.173s)
             Mean action noise std: 2.27
          Mean value_function loss: 69.5951
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.7269
                       Mean reward: 696.06
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.0351
    Episode_Reward/rotating_object: 140.8436
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.12s
                      Time elapsed: 00:26:36
                               ETA: 00:31:52

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 46071 steps/s (collection: 1.965s, learning 0.169s)
             Mean action noise std: 2.28
          Mean value_function loss: 60.9144
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.7455
                       Mean reward: 732.40
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.0302
    Episode_Reward/rotating_object: 140.2220
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.13s
                      Time elapsed: 00:26:38
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 47995 steps/s (collection: 1.944s, learning 0.105s)
             Mean action noise std: 2.28
          Mean value_function loss: 61.6047
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.7793
                       Mean reward: 691.75
               Mean episode length: 233.70
    Episode_Reward/reaching_object: 1.0292
    Episode_Reward/rotating_object: 139.6678
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.05s
                      Time elapsed: 00:26:41
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 47225 steps/s (collection: 1.985s, learning 0.096s)
             Mean action noise std: 2.28
          Mean value_function loss: 55.1470
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.8189
                       Mean reward: 685.44
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 1.0317
    Episode_Reward/rotating_object: 141.0605
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.08s
                      Time elapsed: 00:26:43
                               ETA: 00:31:44

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 47869 steps/s (collection: 1.949s, learning 0.104s)
             Mean action noise std: 2.29
          Mean value_function loss: 63.7986
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.8496
                       Mean reward: 718.06
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.0274
    Episode_Reward/rotating_object: 140.7213
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.05s
                      Time elapsed: 00:26:45
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 48185 steps/s (collection: 1.948s, learning 0.092s)
             Mean action noise std: 2.29
          Mean value_function loss: 63.3170
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 48.8712
                       Mean reward: 721.00
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.0289
    Episode_Reward/rotating_object: 140.3153
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.04s
                      Time elapsed: 00:26:47
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 46586 steps/s (collection: 2.016s, learning 0.094s)
             Mean action noise std: 2.29
          Mean value_function loss: 65.3523
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.8896
                       Mean reward: 676.67
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 1.0198
    Episode_Reward/rotating_object: 139.7211
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.11s
                      Time elapsed: 00:26:49
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 47924 steps/s (collection: 1.954s, learning 0.097s)
             Mean action noise std: 2.29
          Mean value_function loss: 69.6614
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.9164
                       Mean reward: 649.20
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 1.0210
    Episode_Reward/rotating_object: 140.2495
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.05s
                      Time elapsed: 00:26:51
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 45603 steps/s (collection: 2.012s, learning 0.144s)
             Mean action noise std: 2.30
          Mean value_function loss: 65.0987
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.9437
                       Mean reward: 720.25
               Mean episode length: 238.41
    Episode_Reward/reaching_object: 1.0144
    Episode_Reward/rotating_object: 136.1158
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.16s
                      Time elapsed: 00:26:53
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 44501 steps/s (collection: 2.078s, learning 0.131s)
             Mean action noise std: 2.30
          Mean value_function loss: 60.8026
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.9725
                       Mean reward: 713.83
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 1.0251
    Episode_Reward/rotating_object: 141.0523
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.21s
                      Time elapsed: 00:26:55
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 37835 steps/s (collection: 2.422s, learning 0.176s)
             Mean action noise std: 2.30
          Mean value_function loss: 70.4730
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.0002
                       Mean reward: 713.20
               Mean episode length: 238.59
    Episode_Reward/reaching_object: 1.0113
    Episode_Reward/rotating_object: 139.1544
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.60s
                      Time elapsed: 00:26:58
                               ETA: 00:31:26

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 45040 steps/s (collection: 2.068s, learning 0.115s)
             Mean action noise std: 2.31
          Mean value_function loss: 72.0893
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 49.0285
                       Mean reward: 641.14
               Mean episode length: 222.57
    Episode_Reward/reaching_object: 1.0003
    Episode_Reward/rotating_object: 135.3076
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.18s
                      Time elapsed: 00:27:00
                               ETA: 00:31:24

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 45181 steps/s (collection: 2.058s, learning 0.118s)
             Mean action noise std: 2.31
          Mean value_function loss: 60.5165
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.0548
                       Mean reward: 699.50
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.0213
    Episode_Reward/rotating_object: 137.8127
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.18s
                      Time elapsed: 00:27:02
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 43419 steps/s (collection: 2.140s, learning 0.124s)
             Mean action noise std: 2.31
          Mean value_function loss: 61.8198
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 49.0763
                       Mean reward: 675.64
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 142.7862
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.26s
                      Time elapsed: 00:27:04
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 47470 steps/s (collection: 1.983s, learning 0.088s)
             Mean action noise std: 2.31
          Mean value_function loss: 54.6454
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.0995
                       Mean reward: 663.30
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.0110
    Episode_Reward/rotating_object: 138.1565
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.07s
                      Time elapsed: 00:27:06
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 48026 steps/s (collection: 1.956s, learning 0.091s)
             Mean action noise std: 2.32
          Mean value_function loss: 66.8660
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.1284
                       Mean reward: 714.67
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 1.0189
    Episode_Reward/rotating_object: 139.1740
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.05s
                      Time elapsed: 00:27:09
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 47524 steps/s (collection: 1.937s, learning 0.131s)
             Mean action noise std: 2.32
          Mean value_function loss: 60.8637
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.1524
                       Mean reward: 690.69
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.0103
    Episode_Reward/rotating_object: 137.5328
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.07s
                      Time elapsed: 00:27:11
                               ETA: 00:31:11

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 47733 steps/s (collection: 1.971s, learning 0.089s)
             Mean action noise std: 2.32
          Mean value_function loss: 61.4117
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.1811
                       Mean reward: 681.27
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.0207
    Episode_Reward/rotating_object: 140.7451
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.06s
                      Time elapsed: 00:27:13
                               ETA: 00:31:08

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 44735 steps/s (collection: 2.041s, learning 0.156s)
             Mean action noise std: 2.33
          Mean value_function loss: 61.7291
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.2135
                       Mean reward: 714.86
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 1.0244
    Episode_Reward/rotating_object: 140.7214
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.20s
                      Time elapsed: 00:27:15
                               ETA: 00:31:06

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 47318 steps/s (collection: 1.978s, learning 0.099s)
             Mean action noise std: 2.33
          Mean value_function loss: 46.2351
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.2492
                       Mean reward: 720.00
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 1.0319
    Episode_Reward/rotating_object: 139.8713
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.08s
                      Time elapsed: 00:27:17
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 47387 steps/s (collection: 1.970s, learning 0.104s)
             Mean action noise std: 2.33
          Mean value_function loss: 70.3722
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.2763
                       Mean reward: 715.38
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.0236
    Episode_Reward/rotating_object: 139.8003
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.07s
                      Time elapsed: 00:27:19
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 46983 steps/s (collection: 2.000s, learning 0.093s)
             Mean action noise std: 2.34
          Mean value_function loss: 64.8915
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.3001
                       Mean reward: 655.22
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 1.0184
    Episode_Reward/rotating_object: 138.6928
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.09s
                      Time elapsed: 00:27:21
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 47287 steps/s (collection: 1.991s, learning 0.088s)
             Mean action noise std: 2.34
          Mean value_function loss: 58.6887
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.3229
                       Mean reward: 691.46
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.0221
    Episode_Reward/rotating_object: 141.0635
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.08s
                      Time elapsed: 00:27:23
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 46981 steps/s (collection: 1.996s, learning 0.096s)
             Mean action noise std: 2.34
          Mean value_function loss: 59.0367
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.3381
                       Mean reward: 717.84
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0305
    Episode_Reward/rotating_object: 141.4347
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.09s
                      Time elapsed: 00:27:25
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 47637 steps/s (collection: 1.960s, learning 0.104s)
             Mean action noise std: 2.34
          Mean value_function loss: 61.8910
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.3541
                       Mean reward: 693.39
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.0279
    Episode_Reward/rotating_object: 141.6705
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.06s
                      Time elapsed: 00:27:27
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 45094 steps/s (collection: 2.040s, learning 0.140s)
             Mean action noise std: 2.35
          Mean value_function loss: 55.0616
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.3812
                       Mean reward: 712.93
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.0292
    Episode_Reward/rotating_object: 140.2565
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.18s
                      Time elapsed: 00:27:30
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 44391 steps/s (collection: 2.008s, learning 0.207s)
             Mean action noise std: 2.35
          Mean value_function loss: 63.4704
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.4098
                       Mean reward: 689.57
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.0300
    Episode_Reward/rotating_object: 140.0732
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.21s
                      Time elapsed: 00:27:32
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 46884 steps/s (collection: 1.999s, learning 0.098s)
             Mean action noise std: 2.35
          Mean value_function loss: 73.0536
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 49.4328
                       Mean reward: 693.68
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.0364
    Episode_Reward/rotating_object: 140.7801
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.10s
                      Time elapsed: 00:27:34
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 45827 steps/s (collection: 2.050s, learning 0.095s)
             Mean action noise std: 2.35
          Mean value_function loss: 72.2903
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.4524
                       Mean reward: 681.44
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.0200
    Episode_Reward/rotating_object: 138.3524
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.15s
                      Time elapsed: 00:27:36
                               ETA: 00:30:40

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 46793 steps/s (collection: 2.003s, learning 0.098s)
             Mean action noise std: 2.36
          Mean value_function loss: 54.4542
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.4765
                       Mean reward: 740.08
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 1.0318
    Episode_Reward/rotating_object: 140.6702
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.10s
                      Time elapsed: 00:27:38
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 45821 steps/s (collection: 2.052s, learning 0.094s)
             Mean action noise std: 2.36
          Mean value_function loss: 54.5191
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.4964
                       Mean reward: 645.48
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 137.3558
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.15s
                      Time elapsed: 00:27:40
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 46705 steps/s (collection: 1.990s, learning 0.115s)
             Mean action noise std: 2.36
          Mean value_function loss: 62.9565
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.5187
                       Mean reward: 687.47
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.0176
    Episode_Reward/rotating_object: 136.6048
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.10s
                      Time elapsed: 00:27:42
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 45004 steps/s (collection: 2.034s, learning 0.150s)
             Mean action noise std: 2.37
          Mean value_function loss: 60.9706
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.5442
                       Mean reward: 730.39
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.0520
    Episode_Reward/rotating_object: 142.6968
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.18s
                      Time elapsed: 00:27:45
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 44936 steps/s (collection: 1.995s, learning 0.192s)
             Mean action noise std: 2.37
          Mean value_function loss: 63.9631
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.5762
                       Mean reward: 707.63
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.0455
    Episode_Reward/rotating_object: 143.8130
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.19s
                      Time elapsed: 00:27:47
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 46070 steps/s (collection: 2.038s, learning 0.096s)
             Mean action noise std: 2.37
          Mean value_function loss: 59.7574
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.5953
                       Mean reward: 699.48
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0243
    Episode_Reward/rotating_object: 138.9451
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.13s
                      Time elapsed: 00:27:49
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 46873 steps/s (collection: 1.990s, learning 0.107s)
             Mean action noise std: 2.37
          Mean value_function loss: 59.0345
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.6153
                       Mean reward: 672.99
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.0181
    Episode_Reward/rotating_object: 136.4948
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.10s
                      Time elapsed: 00:27:51
                               ETA: 00:30:22

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 47224 steps/s (collection: 1.981s, learning 0.101s)
             Mean action noise std: 2.38
          Mean value_function loss: 67.4133
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.6376
                       Mean reward: 716.85
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 1.0388
    Episode_Reward/rotating_object: 141.4807
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.08s
                      Time elapsed: 00:27:53
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 46421 steps/s (collection: 2.025s, learning 0.093s)
             Mean action noise std: 2.38
          Mean value_function loss: 60.9982
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.6558
                       Mean reward: 667.67
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.0226
    Episode_Reward/rotating_object: 138.3624
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.12s
                      Time elapsed: 00:27:55
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 44848 steps/s (collection: 2.095s, learning 0.097s)
             Mean action noise std: 2.38
          Mean value_function loss: 58.5209
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.6901
                       Mean reward: 722.47
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 1.0346
    Episode_Reward/rotating_object: 142.5832
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.19s
                      Time elapsed: 00:27:57
                               ETA: 00:30:15

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 46442 steps/s (collection: 2.016s, learning 0.101s)
             Mean action noise std: 2.38
          Mean value_function loss: 64.6689
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.7166
                       Mean reward: 714.97
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 142.5973
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.12s
                      Time elapsed: 00:27:59
                               ETA: 00:30:12

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 45466 steps/s (collection: 2.001s, learning 0.161s)
             Mean action noise std: 2.39
          Mean value_function loss: 65.0163
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.7376
                       Mean reward: 717.65
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 1.0202
    Episode_Reward/rotating_object: 138.5641
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.16s
                      Time elapsed: 00:28:02
                               ETA: 00:30:10

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 43613 steps/s (collection: 2.147s, learning 0.107s)
             Mean action noise std: 2.39
          Mean value_function loss: 65.0371
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.7544
                       Mean reward: 731.96
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.0339
    Episode_Reward/rotating_object: 138.8190
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.25s
                      Time elapsed: 00:28:04
                               ETA: 00:30:07

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 46298 steps/s (collection: 2.006s, learning 0.117s)
             Mean action noise std: 2.39
          Mean value_function loss: 64.6025
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.7846
                       Mean reward: 737.48
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.0423
    Episode_Reward/rotating_object: 142.7957
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.12s
                      Time elapsed: 00:28:06
                               ETA: 00:30:05

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 44914 steps/s (collection: 2.098s, learning 0.091s)
             Mean action noise std: 2.40
          Mean value_function loss: 70.3981
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.8113
                       Mean reward: 726.78
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.0358
    Episode_Reward/rotating_object: 143.2548
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.19s
                      Time elapsed: 00:28:08
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 44870 steps/s (collection: 2.078s, learning 0.113s)
             Mean action noise std: 2.40
          Mean value_function loss: 60.5418
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.8344
                       Mean reward: 708.02
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.0133
    Episode_Reward/rotating_object: 137.7465
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.19s
                      Time elapsed: 00:28:10
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 47062 steps/s (collection: 1.993s, learning 0.096s)
             Mean action noise std: 2.40
          Mean value_function loss: 61.6380
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.8647
                       Mean reward: 712.82
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.0285
    Episode_Reward/rotating_object: 141.1663
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.09s
                      Time elapsed: 00:28:12
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 43111 steps/s (collection: 2.156s, learning 0.125s)
             Mean action noise std: 2.41
          Mean value_function loss: 61.7716
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.8941
                       Mean reward: 722.67
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.0263
    Episode_Reward/rotating_object: 142.0453
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.28s
                      Time elapsed: 00:28:15
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 41856 steps/s (collection: 2.242s, learning 0.107s)
             Mean action noise std: 2.41
          Mean value_function loss: 57.0544
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.9200
                       Mean reward: 743.21
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.0410
    Episode_Reward/rotating_object: 143.0007
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.35s
                      Time elapsed: 00:28:17
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 43021 steps/s (collection: 2.129s, learning 0.156s)
             Mean action noise std: 2.41
          Mean value_function loss: 61.7251
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.9384
                       Mean reward: 729.39
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 1.0268
    Episode_Reward/rotating_object: 141.2046
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.28s
                      Time elapsed: 00:28:19
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 45767 steps/s (collection: 2.055s, learning 0.093s)
             Mean action noise std: 2.41
          Mean value_function loss: 57.4007
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 49.9647
                       Mean reward: 707.19
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.0341
    Episode_Reward/rotating_object: 143.6940
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.15s
                      Time elapsed: 00:28:22
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 38742 steps/s (collection: 2.401s, learning 0.137s)
             Mean action noise std: 2.42
          Mean value_function loss: 62.2437
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.9852
                       Mean reward: 699.63
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 139.8800
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.54s
                      Time elapsed: 00:28:24
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 37698 steps/s (collection: 2.464s, learning 0.144s)
             Mean action noise std: 2.42
          Mean value_function loss: 59.5144
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.0178
                       Mean reward: 730.69
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.0126
    Episode_Reward/rotating_object: 138.7871
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.61s
                      Time elapsed: 00:28:27
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 41625 steps/s (collection: 2.265s, learning 0.097s)
             Mean action noise std: 2.42
          Mean value_function loss: 65.3184
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.0519
                       Mean reward: 690.19
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 0.9953
    Episode_Reward/rotating_object: 135.0842
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.36s
                      Time elapsed: 00:28:29
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 43778 steps/s (collection: 2.147s, learning 0.098s)
             Mean action noise std: 2.42
          Mean value_function loss: 54.2893
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.0690
                       Mean reward: 691.60
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.0251
    Episode_Reward/rotating_object: 139.3248
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.25s
                      Time elapsed: 00:28:31
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 43446 steps/s (collection: 2.164s, learning 0.099s)
             Mean action noise std: 2.43
          Mean value_function loss: 61.8261
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.0797
                       Mean reward: 718.36
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.0335
    Episode_Reward/rotating_object: 143.8271
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.26s
                      Time elapsed: 00:28:34
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 45183 steps/s (collection: 2.076s, learning 0.100s)
             Mean action noise std: 2.43
          Mean value_function loss: 71.1822
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.1002
                       Mean reward: 677.13
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.0031
    Episode_Reward/rotating_object: 137.9531
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.18s
                      Time elapsed: 00:28:36
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 41418 steps/s (collection: 2.265s, learning 0.108s)
             Mean action noise std: 2.43
          Mean value_function loss: 61.4495
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.1219
                       Mean reward: 638.74
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.0149
    Episode_Reward/rotating_object: 138.4308
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.37s
                      Time elapsed: 00:28:38
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 42380 steps/s (collection: 2.220s, learning 0.099s)
             Mean action noise std: 2.43
          Mean value_function loss: 60.0944
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.1461
                       Mean reward: 737.12
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 1.0174
    Episode_Reward/rotating_object: 139.7498
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.32s
                      Time elapsed: 00:28:40
                               ETA: 00:29:29

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 46580 steps/s (collection: 1.997s, learning 0.114s)
             Mean action noise std: 2.44
          Mean value_function loss: 69.9523
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.1648
                       Mean reward: 658.40
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 0.9923
    Episode_Reward/rotating_object: 134.9237
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.11s
                      Time elapsed: 00:28:43
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 46329 steps/s (collection: 2.033s, learning 0.089s)
             Mean action noise std: 2.44
          Mean value_function loss: 55.6697
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.1941
                       Mean reward: 738.48
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 1.0191
    Episode_Reward/rotating_object: 142.2465
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.12s
                      Time elapsed: 00:28:45
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 47482 steps/s (collection: 1.977s, learning 0.093s)
             Mean action noise std: 2.44
          Mean value_function loss: 58.2544
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.2265
                       Mean reward: 711.75
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 1.0239
    Episode_Reward/rotating_object: 141.2143
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.07s
                      Time elapsed: 00:28:47
                               ETA: 00:29:22

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 47642 steps/s (collection: 1.968s, learning 0.095s)
             Mean action noise std: 2.45
          Mean value_function loss: 58.5014
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.2460
                       Mean reward: 731.40
               Mean episode length: 248.55
    Episode_Reward/reaching_object: 1.0198
    Episode_Reward/rotating_object: 139.0177
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.06s
                      Time elapsed: 00:28:49
                               ETA: 00:29:19

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 47626 steps/s (collection: 1.969s, learning 0.095s)
             Mean action noise std: 2.45
          Mean value_function loss: 68.2465
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.2670
                       Mean reward: 682.38
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.0337
    Episode_Reward/rotating_object: 141.5673
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.06s
                      Time elapsed: 00:28:51
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 45453 steps/s (collection: 2.047s, learning 0.116s)
             Mean action noise std: 2.45
          Mean value_function loss: 66.4964
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.2904
                       Mean reward: 698.79
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 1.0146
    Episode_Reward/rotating_object: 139.5069
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.16s
                      Time elapsed: 00:28:53
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 46372 steps/s (collection: 2.002s, learning 0.118s)
             Mean action noise std: 2.45
          Mean value_function loss: 58.8334
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.3145
                       Mean reward: 719.41
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 1.0248
    Episode_Reward/rotating_object: 143.0014
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.12s
                      Time elapsed: 00:28:55
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 46855 steps/s (collection: 1.991s, learning 0.107s)
             Mean action noise std: 2.46
          Mean value_function loss: 57.8606
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.3352
                       Mean reward: 729.26
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.0051
    Episode_Reward/rotating_object: 136.4603
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.10s
                      Time elapsed: 00:28:57
                               ETA: 00:29:09

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 46196 steps/s (collection: 2.013s, learning 0.115s)
             Mean action noise std: 2.46
          Mean value_function loss: 63.6287
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.3574
                       Mean reward: 698.66
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 0.9971
    Episode_Reward/rotating_object: 136.2223
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.13s
                      Time elapsed: 00:28:59
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 45070 steps/s (collection: 2.082s, learning 0.099s)
             Mean action noise std: 2.46
          Mean value_function loss: 45.9781
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.3854
                       Mean reward: 714.11
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.0325
    Episode_Reward/rotating_object: 141.2512
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.18s
                      Time elapsed: 00:29:02
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 47680 steps/s (collection: 1.972s, learning 0.090s)
             Mean action noise std: 2.46
          Mean value_function loss: 65.3222
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.4081
                       Mean reward: 722.61
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.0428
    Episode_Reward/rotating_object: 145.3881
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.06s
                      Time elapsed: 00:29:04
                               ETA: 00:29:01

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 47634 steps/s (collection: 1.973s, learning 0.091s)
             Mean action noise std: 2.47
          Mean value_function loss: 83.2758
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.4419
                       Mean reward: 740.81
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 1.0198
    Episode_Reward/rotating_object: 142.2933
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.06s
                      Time elapsed: 00:29:06
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 44796 steps/s (collection: 2.099s, learning 0.096s)
             Mean action noise std: 2.47
          Mean value_function loss: 65.8216
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.4694
                       Mean reward: 692.95
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.0128
    Episode_Reward/rotating_object: 138.5283
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.19s
                      Time elapsed: 00:29:08
                               ETA: 00:28:56

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 46789 steps/s (collection: 2.005s, learning 0.096s)
             Mean action noise std: 2.47
          Mean value_function loss: 62.0383
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.4878
                       Mean reward: 677.15
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.0163
    Episode_Reward/rotating_object: 139.5047
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.10s
                      Time elapsed: 00:29:10
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 43878 steps/s (collection: 2.133s, learning 0.107s)
             Mean action noise std: 2.48
          Mean value_function loss: 60.7963
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.5174
                       Mean reward: 714.21
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 144.0451
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.24s
                      Time elapsed: 00:29:12
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 46117 steps/s (collection: 2.022s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 65.2701
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.5445
                       Mean reward: 716.49
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.0241
    Episode_Reward/rotating_object: 143.8026
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.13s
                      Time elapsed: 00:29:14
                               ETA: 00:28:49

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 46762 steps/s (collection: 1.977s, learning 0.125s)
             Mean action noise std: 2.48
          Mean value_function loss: 67.0692
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.5642
                       Mean reward: 712.78
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 0.9965
    Episode_Reward/rotating_object: 137.3971
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.10s
                      Time elapsed: 00:29:16
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 45859 steps/s (collection: 2.043s, learning 0.101s)
             Mean action noise std: 2.49
          Mean value_function loss: 72.3861
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.5893
                       Mean reward: 733.68
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 1.0171
    Episode_Reward/rotating_object: 142.6721
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.14s
                      Time elapsed: 00:29:19
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 45672 steps/s (collection: 2.046s, learning 0.106s)
             Mean action noise std: 2.49
          Mean value_function loss: 66.4388
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.6133
                       Mean reward: 679.71
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 0.9959
    Episode_Reward/rotating_object: 137.0965
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.15s
                      Time elapsed: 00:29:21
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 44013 steps/s (collection: 2.100s, learning 0.134s)
             Mean action noise std: 2.49
          Mean value_function loss: 70.3241
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.6384
                       Mean reward: 704.00
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 134.7816
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.23s
                      Time elapsed: 00:29:23
                               ETA: 00:28:39

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 46684 steps/s (collection: 1.999s, learning 0.107s)
             Mean action noise std: 2.49
          Mean value_function loss: 68.3197
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.6640
                       Mean reward: 675.39
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.0022
    Episode_Reward/rotating_object: 136.2646
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.11s
                      Time elapsed: 00:29:25
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 44930 steps/s (collection: 2.089s, learning 0.099s)
             Mean action noise std: 2.50
          Mean value_function loss: 67.5762
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.6802
                       Mean reward: 700.43
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.0259
    Episode_Reward/rotating_object: 140.4385
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.19s
                      Time elapsed: 00:29:27
                               ETA: 00:28:34

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 47229 steps/s (collection: 1.992s, learning 0.090s)
             Mean action noise std: 2.50
          Mean value_function loss: 73.1422
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.6981
                       Mean reward: 680.38
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.0135
    Episode_Reward/rotating_object: 139.1563
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.08s
                      Time elapsed: 00:29:29
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 47173 steps/s (collection: 1.989s, learning 0.095s)
             Mean action noise std: 2.50
          Mean value_function loss: 78.1688
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.7187
                       Mean reward: 672.09
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 134.6767
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.08s
                      Time elapsed: 00:29:31
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 46353 steps/s (collection: 2.020s, learning 0.101s)
             Mean action noise std: 2.50
          Mean value_function loss: 61.9918
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.7450
                       Mean reward: 704.75
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.9934
    Episode_Reward/rotating_object: 136.7030
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.12s
                      Time elapsed: 00:29:34
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 46718 steps/s (collection: 2.002s, learning 0.102s)
             Mean action noise std: 2.51
          Mean value_function loss: 53.7156
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.7715
                       Mean reward: 744.55
               Mean episode length: 242.62
    Episode_Reward/reaching_object: 1.0221
    Episode_Reward/rotating_object: 139.6656
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.10s
                      Time elapsed: 00:29:36
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 46480 steps/s (collection: 2.017s, learning 0.098s)
             Mean action noise std: 2.51
          Mean value_function loss: 71.8948
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.7938
                       Mean reward: 681.98
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0099
    Episode_Reward/rotating_object: 140.2433
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.11s
                      Time elapsed: 00:29:38
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 47468 steps/s (collection: 1.978s, learning 0.093s)
             Mean action noise std: 2.51
          Mean value_function loss: 71.6120
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.8249
                       Mean reward: 682.70
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 1.0095
    Episode_Reward/rotating_object: 137.8330
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.07s
                      Time elapsed: 00:29:40
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 47176 steps/s (collection: 1.990s, learning 0.094s)
             Mean action noise std: 2.52
          Mean value_function loss: 66.7586
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 50.8518
                       Mean reward: 686.78
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.0250
    Episode_Reward/rotating_object: 142.1980
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.08s
                      Time elapsed: 00:29:42
                               ETA: 00:28:16

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 47095 steps/s (collection: 1.981s, learning 0.107s)
             Mean action noise std: 2.52
          Mean value_function loss: 66.4418
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.8620
                       Mean reward: 691.77
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.0114
    Episode_Reward/rotating_object: 137.3823
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.09s
                      Time elapsed: 00:29:44
                               ETA: 00:28:14

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 46125 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 2.52
          Mean value_function loss: 71.1006
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.8817
                       Mean reward: 694.97
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 1.0121
    Episode_Reward/rotating_object: 139.8501
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.13s
                      Time elapsed: 00:29:46
                               ETA: 00:28:11

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 47285 steps/s (collection: 1.982s, learning 0.097s)
             Mean action noise std: 2.52
          Mean value_function loss: 68.0110
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 50.9078
                       Mean reward: 713.90
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.0079
    Episode_Reward/rotating_object: 138.6645
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.08s
                      Time elapsed: 00:29:48
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 47742 steps/s (collection: 1.965s, learning 0.094s)
             Mean action noise std: 2.52
          Mean value_function loss: 68.4198
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 50.9128
                       Mean reward: 723.87
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.0161
    Episode_Reward/rotating_object: 138.5359
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.06s
                      Time elapsed: 00:29:50
                               ETA: 00:28:06

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 47329 steps/s (collection: 1.988s, learning 0.089s)
             Mean action noise std: 2.53
          Mean value_function loss: 68.1180
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.9227
                       Mean reward: 712.53
               Mean episode length: 238.03
    Episode_Reward/reaching_object: 1.0317
    Episode_Reward/rotating_object: 142.8066
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.08s
                      Time elapsed: 00:29:52
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 47095 steps/s (collection: 1.976s, learning 0.112s)
             Mean action noise std: 2.53
          Mean value_function loss: 75.8803
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.9393
                       Mean reward: 687.92
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 138.5105
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.09s
                      Time elapsed: 00:29:54
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 47538 steps/s (collection: 1.976s, learning 0.092s)
             Mean action noise std: 2.53
          Mean value_function loss: 62.8058
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.9522
                       Mean reward: 720.79
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.0317
    Episode_Reward/rotating_object: 141.4279
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.07s
                      Time elapsed: 00:29:56
                               ETA: 00:27:58

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 47191 steps/s (collection: 1.981s, learning 0.103s)
             Mean action noise std: 2.53
          Mean value_function loss: 62.4325
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.9690
                       Mean reward: 713.96
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 1.0156
    Episode_Reward/rotating_object: 138.7089
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.08s
                      Time elapsed: 00:29:59
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 47415 steps/s (collection: 1.973s, learning 0.101s)
             Mean action noise std: 2.53
          Mean value_function loss: 65.6305
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.9872
                       Mean reward: 731.28
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 1.0287
    Episode_Reward/rotating_object: 143.1243
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.07s
                      Time elapsed: 00:30:01
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 44475 steps/s (collection: 2.084s, learning 0.127s)
             Mean action noise std: 2.54
          Mean value_function loss: 66.0222
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.0069
                       Mean reward: 736.39
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 1.0186
    Episode_Reward/rotating_object: 140.7811
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.21s
                      Time elapsed: 00:30:03
                               ETA: 00:27:51

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 43293 steps/s (collection: 2.164s, learning 0.107s)
             Mean action noise std: 2.54
          Mean value_function loss: 65.9239
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.0254
                       Mean reward: 677.61
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 137.8138
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.27s
                      Time elapsed: 00:30:05
                               ETA: 00:27:49

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 47089 steps/s (collection: 1.990s, learning 0.098s)
             Mean action noise std: 2.54
          Mean value_function loss: 71.7599
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.0453
                       Mean reward: 704.19
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.0073
    Episode_Reward/rotating_object: 138.6246
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.09s
                      Time elapsed: 00:30:07
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 43810 steps/s (collection: 2.104s, learning 0.140s)
             Mean action noise std: 2.54
          Mean value_function loss: 48.8937
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.0720
                       Mean reward: 719.67
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.0248
    Episode_Reward/rotating_object: 141.1125
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.24s
                      Time elapsed: 00:30:09
                               ETA: 00:27:44

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 38259 steps/s (collection: 2.410s, learning 0.160s)
             Mean action noise std: 2.55
          Mean value_function loss: 66.9358
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.1021
                       Mean reward: 697.58
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.0152
    Episode_Reward/rotating_object: 140.8404
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.57s
                      Time elapsed: 00:30:12
                               ETA: 00:27:42

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 35412 steps/s (collection: 2.564s, learning 0.211s)
             Mean action noise std: 2.55
          Mean value_function loss: 65.1339
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.1245
                       Mean reward: 718.05
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.0176
    Episode_Reward/rotating_object: 140.7630
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.78s
                      Time elapsed: 00:30:15
                               ETA: 00:27:40

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 41186 steps/s (collection: 2.236s, learning 0.151s)
             Mean action noise std: 2.55
          Mean value_function loss: 70.7216
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.1483
                       Mean reward: 692.10
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.0013
    Episode_Reward/rotating_object: 137.5713
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 18.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.39s
                      Time elapsed: 00:30:17
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 40305 steps/s (collection: 2.326s, learning 0.113s)
             Mean action noise std: 2.56
          Mean value_function loss: 73.8614
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.1760
                       Mean reward: 707.95
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.0090
    Episode_Reward/rotating_object: 141.2855
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.44s
                      Time elapsed: 00:30:20
                               ETA: 00:27:35

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 46096 steps/s (collection: 2.026s, learning 0.107s)
             Mean action noise std: 2.56
          Mean value_function loss: 80.7380
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.2081
                       Mean reward: 684.70
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.0105
    Episode_Reward/rotating_object: 138.0858
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.13s
                      Time elapsed: 00:30:22
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 45086 steps/s (collection: 2.086s, learning 0.094s)
             Mean action noise std: 2.56
          Mean value_function loss: 73.0162
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.2289
                       Mean reward: 670.26
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 140.0480
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.18s
                      Time elapsed: 00:30:24
                               ETA: 00:27:30

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 44546 steps/s (collection: 2.103s, learning 0.104s)
             Mean action noise std: 2.57
          Mean value_function loss: 57.9913
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.2464
                       Mean reward: 680.44
               Mean episode length: 239.17
    Episode_Reward/reaching_object: 1.0274
    Episode_Reward/rotating_object: 139.9837
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.21s
                      Time elapsed: 00:30:26
                               ETA: 00:27:28

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 44772 steps/s (collection: 2.093s, learning 0.103s)
             Mean action noise std: 2.57
          Mean value_function loss: 67.2535
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.2644
                       Mean reward: 710.94
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 1.0048
    Episode_Reward/rotating_object: 137.7589
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.20s
                      Time elapsed: 00:30:28
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 46309 steps/s (collection: 2.031s, learning 0.092s)
             Mean action noise std: 2.57
          Mean value_function loss: 73.5147
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.2815
                       Mean reward: 705.29
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.0142
    Episode_Reward/rotating_object: 138.0994
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.12s
                      Time elapsed: 00:30:30
                               ETA: 00:27:23

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 46919 steps/s (collection: 1.994s, learning 0.101s)
             Mean action noise std: 2.57
          Mean value_function loss: 59.2689
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.3061
                       Mean reward: 701.90
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 137.9119
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.10s
                      Time elapsed: 00:30:33
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 45820 steps/s (collection: 2.041s, learning 0.104s)
             Mean action noise std: 2.58
          Mean value_function loss: 59.1455
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.3326
                       Mean reward: 697.15
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.0180
    Episode_Reward/rotating_object: 139.6417
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.15s
                      Time elapsed: 00:30:35
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 46834 steps/s (collection: 2.001s, learning 0.098s)
             Mean action noise std: 2.58
          Mean value_function loss: 57.2290
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.3460
                       Mean reward: 634.44
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.0163
    Episode_Reward/rotating_object: 137.4135
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.10s
                      Time elapsed: 00:30:37
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 47152 steps/s (collection: 1.994s, learning 0.091s)
             Mean action noise std: 2.58
          Mean value_function loss: 55.5018
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.3649
                       Mean reward: 716.60
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.0245
    Episode_Reward/rotating_object: 143.9294
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.08s
                      Time elapsed: 00:30:39
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 46811 steps/s (collection: 2.008s, learning 0.092s)
             Mean action noise std: 2.58
          Mean value_function loss: 64.1468
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.3886
                       Mean reward: 693.90
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 1.0044
    Episode_Reward/rotating_object: 135.9705
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.10s
                      Time elapsed: 00:30:41
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 47034 steps/s (collection: 1.995s, learning 0.095s)
             Mean action noise std: 2.59
          Mean value_function loss: 69.6267
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.4096
                       Mean reward: 728.43
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 0.9997
    Episode_Reward/rotating_object: 136.4233
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.09s
                      Time elapsed: 00:30:43
                               ETA: 00:27:08

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 46399 steps/s (collection: 2.002s, learning 0.116s)
             Mean action noise std: 2.59
          Mean value_function loss: 75.8724
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.4327
                       Mean reward: 697.99
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 1.0006
    Episode_Reward/rotating_object: 136.7251
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.12s
                      Time elapsed: 00:30:45
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 46037 steps/s (collection: 2.011s, learning 0.125s)
             Mean action noise std: 2.59
          Mean value_function loss: 61.0648
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.4560
                       Mean reward: 717.90
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 1.0340
    Episode_Reward/rotating_object: 144.9746
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.14s
                      Time elapsed: 00:30:47
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 42379 steps/s (collection: 2.205s, learning 0.115s)
             Mean action noise std: 2.59
          Mean value_function loss: 62.0139
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.4776
                       Mean reward: 759.63
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 1.0056
    Episode_Reward/rotating_object: 139.4478
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.32s
                      Time elapsed: 00:30:50
                               ETA: 00:27:01

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 45920 steps/s (collection: 2.046s, learning 0.095s)
             Mean action noise std: 2.60
          Mean value_function loss: 62.3266
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.4967
                       Mean reward: 726.00
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 1.0077
    Episode_Reward/rotating_object: 139.8065
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.14s
                      Time elapsed: 00:30:52
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 44541 steps/s (collection: 2.111s, learning 0.096s)
             Mean action noise std: 2.60
          Mean value_function loss: 61.7903
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.5135
                       Mean reward: 675.90
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 0.9954
    Episode_Reward/rotating_object: 136.9259
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.21s
                      Time elapsed: 00:30:54
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 45420 steps/s (collection: 2.068s, learning 0.096s)
             Mean action noise std: 2.60
          Mean value_function loss: 72.1346
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.5374
                       Mean reward: 693.97
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0102
    Episode_Reward/rotating_object: 140.8475
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.16s
                      Time elapsed: 00:30:56
                               ETA: 00:26:53

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 46719 steps/s (collection: 1.999s, learning 0.105s)
             Mean action noise std: 2.60
          Mean value_function loss: 58.1577
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.5644
                       Mean reward: 709.58
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 1.0015
    Episode_Reward/rotating_object: 139.1045
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.10s
                      Time elapsed: 00:30:58
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 46598 steps/s (collection: 2.013s, learning 0.097s)
             Mean action noise std: 2.61
          Mean value_function loss: 84.8249
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.5828
                       Mean reward: 676.17
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 0.9976
    Episode_Reward/rotating_object: 138.2522
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.11s
                      Time elapsed: 00:31:00
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 45768 steps/s (collection: 2.035s, learning 0.113s)
             Mean action noise std: 2.61
          Mean value_function loss: 59.0519
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.6015
                       Mean reward: 718.88
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.0140
    Episode_Reward/rotating_object: 141.4326
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.15s
                      Time elapsed: 00:31:03
                               ETA: 00:26:46

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 46787 steps/s (collection: 1.987s, learning 0.114s)
             Mean action noise std: 2.61
          Mean value_function loss: 78.1125
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.6258
                       Mean reward: 708.37
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 0.9904
    Episode_Reward/rotating_object: 137.0974
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.10s
                      Time elapsed: 00:31:05
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 45906 steps/s (collection: 2.034s, learning 0.108s)
             Mean action noise std: 2.61
          Mean value_function loss: 67.4428
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.6458
                       Mean reward: 686.21
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 0.9814
    Episode_Reward/rotating_object: 137.0719
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.14s
                      Time elapsed: 00:31:07
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 45489 steps/s (collection: 2.063s, learning 0.098s)
             Mean action noise std: 2.62
          Mean value_function loss: 65.5599
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.6705
                       Mean reward: 679.10
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 0.9945
    Episode_Reward/rotating_object: 137.8644
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.16s
                      Time elapsed: 00:31:09
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 47233 steps/s (collection: 1.976s, learning 0.106s)
             Mean action noise std: 2.62
          Mean value_function loss: 77.3330
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.6904
                       Mean reward: 645.85
               Mean episode length: 221.17
    Episode_Reward/reaching_object: 1.0001
    Episode_Reward/rotating_object: 138.9155
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.08s
                      Time elapsed: 00:31:11
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 45546 steps/s (collection: 2.037s, learning 0.121s)
             Mean action noise std: 2.62
          Mean value_function loss: 65.3384
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.7071
                       Mean reward: 694.38
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.0075
    Episode_Reward/rotating_object: 140.7966
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.16s
                      Time elapsed: 00:31:13
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 46268 steps/s (collection: 2.000s, learning 0.125s)
             Mean action noise std: 2.62
          Mean value_function loss: 65.7296
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.7310
                       Mean reward: 694.32
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 1.0092
    Episode_Reward/rotating_object: 139.9533
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.12s
                      Time elapsed: 00:31:15
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 45988 steps/s (collection: 2.018s, learning 0.120s)
             Mean action noise std: 2.63
          Mean value_function loss: 70.0274
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.7594
                       Mean reward: 700.85
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.0097
    Episode_Reward/rotating_object: 138.6329
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.14s
                      Time elapsed: 00:31:17
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 46134 steps/s (collection: 2.019s, learning 0.112s)
             Mean action noise std: 2.63
          Mean value_function loss: 66.3210
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.7858
                       Mean reward: 658.55
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 135.1178
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.13s
                      Time elapsed: 00:31:20
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 45331 steps/s (collection: 2.070s, learning 0.098s)
             Mean action noise std: 2.63
          Mean value_function loss: 62.7287
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 51.8106
                       Mean reward: 719.13
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.0086
    Episode_Reward/rotating_object: 140.6562
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.17s
                      Time elapsed: 00:31:22
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 46604 steps/s (collection: 2.012s, learning 0.097s)
             Mean action noise std: 2.64
          Mean value_function loss: 60.1172
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.8282
                       Mean reward: 678.55
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0120
    Episode_Reward/rotating_object: 140.3605
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.11s
                      Time elapsed: 00:31:24
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 44855 steps/s (collection: 2.096s, learning 0.096s)
             Mean action noise std: 2.64
          Mean value_function loss: 66.2336
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.8512
                       Mean reward: 718.06
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 137.1779
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.19s
                      Time elapsed: 00:31:26
                               ETA: 00:26:19

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 45947 steps/s (collection: 2.037s, learning 0.102s)
             Mean action noise std: 2.64
          Mean value_function loss: 70.3338
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.8743
                       Mean reward: 696.37
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 1.0040
    Episode_Reward/rotating_object: 137.4312
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.14s
                      Time elapsed: 00:31:28
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 47200 steps/s (collection: 1.984s, learning 0.099s)
             Mean action noise std: 2.65
          Mean value_function loss: 67.4076
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.9001
                       Mean reward: 690.01
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 0.9939
    Episode_Reward/rotating_object: 138.0637
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.08s
                      Time elapsed: 00:31:30
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 45833 steps/s (collection: 2.031s, learning 0.113s)
             Mean action noise std: 2.65
          Mean value_function loss: 65.5833
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.9220
                       Mean reward: 712.08
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.0018
    Episode_Reward/rotating_object: 139.3000
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.14s
                      Time elapsed: 00:31:32
                               ETA: 00:26:12

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 44306 steps/s (collection: 2.105s, learning 0.114s)
             Mean action noise std: 2.65
          Mean value_function loss: 51.7218
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.9419
                       Mean reward: 724.49
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 1.0062
    Episode_Reward/rotating_object: 139.4486
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.22s
                      Time elapsed: 00:31:35
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 44046 steps/s (collection: 2.133s, learning 0.099s)
             Mean action noise std: 2.65
          Mean value_function loss: 56.4531
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.9627
                       Mean reward: 685.25
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.0112
    Episode_Reward/rotating_object: 139.3284
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.23s
                      Time elapsed: 00:31:37
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 44119 steps/s (collection: 2.127s, learning 0.102s)
             Mean action noise std: 2.66
          Mean value_function loss: 63.7161
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.9857
                       Mean reward: 667.49
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 0.9914
    Episode_Reward/rotating_object: 136.3882
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.23s
                      Time elapsed: 00:31:39
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 45734 steps/s (collection: 2.050s, learning 0.100s)
             Mean action noise std: 2.66
          Mean value_function loss: 72.4056
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.0041
                       Mean reward: 672.99
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 0.9971
    Episode_Reward/rotating_object: 141.5772
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.15s
                      Time elapsed: 00:31:41
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 38352 steps/s (collection: 2.394s, learning 0.169s)
             Mean action noise std: 2.66
          Mean value_function loss: 54.6519
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.0275
                       Mean reward: 706.68
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.0012
    Episode_Reward/rotating_object: 139.9317
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.56s
                      Time elapsed: 00:31:44
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 34088 steps/s (collection: 2.702s, learning 0.182s)
             Mean action noise std: 2.66
          Mean value_function loss: 55.2192
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.0512
                       Mean reward: 713.25
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 0.9935
    Episode_Reward/rotating_object: 138.5840
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.88s
                      Time elapsed: 00:31:47
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 41508 steps/s (collection: 2.232s, learning 0.136s)
             Mean action noise std: 2.67
          Mean value_function loss: 75.5870
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.0687
                       Mean reward: 659.62
               Mean episode length: 225.54
    Episode_Reward/reaching_object: 0.9883
    Episode_Reward/rotating_object: 139.5302
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.37s
                      Time elapsed: 00:31:49
                               ETA: 00:25:56

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 42054 steps/s (collection: 2.230s, learning 0.108s)
             Mean action noise std: 2.67
          Mean value_function loss: 71.4355
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.0874
                       Mean reward: 646.88
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 0.9624
    Episode_Reward/rotating_object: 134.6662
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.34s
                      Time elapsed: 00:31:51
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 43897 steps/s (collection: 2.132s, learning 0.108s)
             Mean action noise std: 2.67
          Mean value_function loss: 63.3959
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.1068
                       Mean reward: 684.93
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 0.9814
    Episode_Reward/rotating_object: 137.3431
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.24s
                      Time elapsed: 00:31:54
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 38884 steps/s (collection: 2.362s, learning 0.167s)
             Mean action noise std: 2.67
          Mean value_function loss: 65.5670
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.1286
                       Mean reward: 691.48
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 0.9920
    Episode_Reward/rotating_object: 140.8430
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.53s
                      Time elapsed: 00:31:56
                               ETA: 00:25:49

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 36588 steps/s (collection: 2.517s, learning 0.170s)
             Mean action noise std: 2.68
          Mean value_function loss: 80.4942
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.1483
                       Mean reward: 682.09
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 0.9920
    Episode_Reward/rotating_object: 137.9847
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.69s
                      Time elapsed: 00:31:59
                               ETA: 00:25:47

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 33993 steps/s (collection: 2.701s, learning 0.191s)
             Mean action noise std: 2.68
          Mean value_function loss: 62.5001
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.1777
                       Mean reward: 691.45
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.0045
    Episode_Reward/rotating_object: 140.8995
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.89s
                      Time elapsed: 00:32:02
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 34902 steps/s (collection: 2.606s, learning 0.211s)
             Mean action noise std: 2.68
          Mean value_function loss: 65.6560
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.2007
                       Mean reward: 696.82
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 0.9949
    Episode_Reward/rotating_object: 141.2480
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.82s
                      Time elapsed: 00:32:05
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 42456 steps/s (collection: 2.211s, learning 0.104s)
             Mean action noise std: 2.68
          Mean value_function loss: 69.7840
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.2154
                       Mean reward: 682.28
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 1.0024
    Episode_Reward/rotating_object: 139.5768
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.32s
                      Time elapsed: 00:32:07
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 45137 steps/s (collection: 2.076s, learning 0.102s)
             Mean action noise std: 2.69
          Mean value_function loss: 67.6909
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.2388
                       Mean reward: 693.15
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 0.9861
    Episode_Reward/rotating_object: 137.6937
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.18s
                      Time elapsed: 00:32:09
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 45620 steps/s (collection: 2.063s, learning 0.092s)
             Mean action noise std: 2.69
          Mean value_function loss: 66.4845
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.2682
                       Mean reward: 694.28
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 0.9947
    Episode_Reward/rotating_object: 136.8357
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.15s
                      Time elapsed: 00:32:11
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 45731 steps/s (collection: 2.053s, learning 0.097s)
             Mean action noise std: 2.69
          Mean value_function loss: 59.1289
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.2927
                       Mean reward: 714.74
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.0043
    Episode_Reward/rotating_object: 140.5198
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.15s
                      Time elapsed: 00:32:13
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 45789 steps/s (collection: 2.041s, learning 0.106s)
             Mean action noise std: 2.70
          Mean value_function loss: 84.7381
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.3151
                       Mean reward: 730.49
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.0073
    Episode_Reward/rotating_object: 139.3873
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.15s
                      Time elapsed: 00:32:15
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 43308 steps/s (collection: 2.156s, learning 0.114s)
             Mean action noise std: 2.70
          Mean value_function loss: 70.2072
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.3401
                       Mean reward: 710.27
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 0.9950
    Episode_Reward/rotating_object: 138.7165
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.27s
                      Time elapsed: 00:32:18
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 42816 steps/s (collection: 2.181s, learning 0.115s)
             Mean action noise std: 2.70
          Mean value_function loss: 61.9470
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.3669
                       Mean reward: 714.43
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.9931
    Episode_Reward/rotating_object: 137.9877
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.30s
                      Time elapsed: 00:32:20
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 43976 steps/s (collection: 2.130s, learning 0.105s)
             Mean action noise std: 2.71
          Mean value_function loss: 55.5637
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.3896
                       Mean reward: 744.05
               Mean episode length: 244.78
    Episode_Reward/reaching_object: 1.0121
    Episode_Reward/rotating_object: 141.2130
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.24s
                      Time elapsed: 00:32:22
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 44614 steps/s (collection: 2.104s, learning 0.100s)
             Mean action noise std: 2.71
          Mean value_function loss: 61.6306
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.4043
                       Mean reward: 681.11
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 137.7349
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.20s
                      Time elapsed: 00:32:24
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 43328 steps/s (collection: 2.165s, learning 0.104s)
             Mean action noise std: 2.71
          Mean value_function loss: 68.1222
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.4231
                       Mean reward: 710.66
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 0.9961
    Episode_Reward/rotating_object: 138.6130
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.27s
                      Time elapsed: 00:32:27
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 42412 steps/s (collection: 2.184s, learning 0.134s)
             Mean action noise std: 2.71
          Mean value_function loss: 71.5437
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.4493
                       Mean reward: 699.18
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.9885
    Episode_Reward/rotating_object: 134.6271
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.32s
                      Time elapsed: 00:32:29
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 41935 steps/s (collection: 2.243s, learning 0.102s)
             Mean action noise std: 2.72
          Mean value_function loss: 69.6254
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.4821
                       Mean reward: 727.76
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 1.0074
    Episode_Reward/rotating_object: 141.6075
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.34s
                      Time elapsed: 00:32:31
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 44034 steps/s (collection: 2.120s, learning 0.112s)
             Mean action noise std: 2.72
          Mean value_function loss: 61.0152
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.5147
                       Mean reward: 681.13
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 138.6284
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.23s
                      Time elapsed: 00:32:34
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 43803 steps/s (collection: 2.123s, learning 0.121s)
             Mean action noise std: 2.73
          Mean value_function loss: 62.7269
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.5423
                       Mean reward: 686.49
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 0.9880
    Episode_Reward/rotating_object: 135.7593
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.24s
                      Time elapsed: 00:32:36
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 44707 steps/s (collection: 2.099s, learning 0.100s)
             Mean action noise std: 2.73
          Mean value_function loss: 58.4915
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.5632
                       Mean reward: 696.56
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 1.0038
    Episode_Reward/rotating_object: 141.3994
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.20s
                      Time elapsed: 00:32:38
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 45334 steps/s (collection: 2.074s, learning 0.095s)
             Mean action noise std: 2.73
          Mean value_function loss: 77.6765
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.5836
                       Mean reward: 708.67
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.0050
    Episode_Reward/rotating_object: 142.7147
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.17s
                      Time elapsed: 00:32:40
                               ETA: 00:25:05

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 44008 steps/s (collection: 2.124s, learning 0.110s)
             Mean action noise std: 2.73
          Mean value_function loss: 69.9117
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.6022
                       Mean reward: 679.71
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 138.8830
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.23s
                      Time elapsed: 00:32:42
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 43233 steps/s (collection: 2.163s, learning 0.111s)
             Mean action noise std: 2.74
          Mean value_function loss: 71.6127
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.6219
                       Mean reward: 736.22
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 0.9953
    Episode_Reward/rotating_object: 140.5359
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.27s
                      Time elapsed: 00:32:45
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 40605 steps/s (collection: 2.305s, learning 0.116s)
             Mean action noise std: 2.74
          Mean value_function loss: 67.7734
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.6477
                       Mean reward: 727.56
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 0.9952
    Episode_Reward/rotating_object: 139.3630
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.42s
                      Time elapsed: 00:32:47
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 43833 steps/s (collection: 2.121s, learning 0.121s)
             Mean action noise std: 2.74
          Mean value_function loss: 76.4234
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.6716
                       Mean reward: 673.10
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 0.9893
    Episode_Reward/rotating_object: 137.7401
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.24s
                      Time elapsed: 00:32:49
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 44209 steps/s (collection: 2.107s, learning 0.117s)
             Mean action noise std: 2.74
          Mean value_function loss: 63.6373
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.6953
                       Mean reward: 719.13
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.9978
    Episode_Reward/rotating_object: 139.6472
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.22s
                      Time elapsed: 00:32:52
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 42760 steps/s (collection: 2.188s, learning 0.111s)
             Mean action noise std: 2.75
          Mean value_function loss: 56.8578
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.7101
                       Mean reward: 728.57
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.0120
    Episode_Reward/rotating_object: 141.2474
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.30s
                      Time elapsed: 00:32:54
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 43185 steps/s (collection: 2.167s, learning 0.110s)
             Mean action noise std: 2.75
          Mean value_function loss: 68.7312
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 52.7265
                       Mean reward: 698.75
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 0.9972
    Episode_Reward/rotating_object: 137.8361
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.28s
                      Time elapsed: 00:32:56
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 42364 steps/s (collection: 2.222s, learning 0.098s)
             Mean action noise std: 2.75
          Mean value_function loss: 53.9212
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.7491
                       Mean reward: 683.33
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 0.9985
    Episode_Reward/rotating_object: 139.9140
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.32s
                      Time elapsed: 00:32:59
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 39769 steps/s (collection: 2.347s, learning 0.125s)
             Mean action noise std: 2.75
          Mean value_function loss: 66.6146
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.7712
                       Mean reward: 730.19
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 1.0143
    Episode_Reward/rotating_object: 142.2506
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.47s
                      Time elapsed: 00:33:01
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 41409 steps/s (collection: 2.263s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 62.4828
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.7918
                       Mean reward: 720.48
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 1.0089
    Episode_Reward/rotating_object: 139.7742
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.37s
                      Time elapsed: 00:33:03
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 45323 steps/s (collection: 2.074s, learning 0.095s)
             Mean action noise std: 2.76
          Mean value_function loss: 80.1828
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.8139
                       Mean reward: 684.34
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 0.9945
    Episode_Reward/rotating_object: 137.8318
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.17s
                      Time elapsed: 00:33:06
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 44105 steps/s (collection: 2.127s, learning 0.102s)
             Mean action noise std: 2.76
          Mean value_function loss: 76.3382
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.8341
                       Mean reward: 661.12
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 1.0010
    Episode_Reward/rotating_object: 138.6647
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.23s
                      Time elapsed: 00:33:08
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 42049 steps/s (collection: 2.217s, learning 0.121s)
             Mean action noise std: 2.76
          Mean value_function loss: 73.1657
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.8521
                       Mean reward: 690.86
               Mean episode length: 231.85
    Episode_Reward/reaching_object: 0.9993
    Episode_Reward/rotating_object: 138.9426
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.34s
                      Time elapsed: 00:33:10
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 42154 steps/s (collection: 2.235s, learning 0.097s)
             Mean action noise std: 2.77
          Mean value_function loss: 60.3201
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.8704
                       Mean reward: 716.85
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 1.0000
    Episode_Reward/rotating_object: 139.7517
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.33s
                      Time elapsed: 00:33:12
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 44734 steps/s (collection: 2.090s, learning 0.107s)
             Mean action noise std: 2.77
          Mean value_function loss: 66.3503
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.8966
                       Mean reward: 664.44
               Mean episode length: 229.68
    Episode_Reward/reaching_object: 1.0105
    Episode_Reward/rotating_object: 139.8647
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.20s
                      Time elapsed: 00:33:15
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 43368 steps/s (collection: 2.162s, learning 0.105s)
             Mean action noise std: 2.77
          Mean value_function loss: 82.4449
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.9227
                       Mean reward: 682.38
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.0154
    Episode_Reward/rotating_object: 140.8424
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.27s
                      Time elapsed: 00:33:17
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 44083 steps/s (collection: 2.101s, learning 0.129s)
             Mean action noise std: 2.78
          Mean value_function loss: 76.2563
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.9395
                       Mean reward: 718.83
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 0.9994
    Episode_Reward/rotating_object: 139.2677
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.23s
                      Time elapsed: 00:33:19
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 43390 steps/s (collection: 2.164s, learning 0.102s)
             Mean action noise std: 2.78
          Mean value_function loss: 59.5388
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.9579
                       Mean reward: 692.98
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.0075
    Episode_Reward/rotating_object: 138.2707
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.27s
                      Time elapsed: 00:33:21
                               ETA: 00:24:23

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 45313 steps/s (collection: 2.071s, learning 0.098s)
             Mean action noise std: 2.78
          Mean value_function loss: 67.5425
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.9861
                       Mean reward: 734.61
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.0270
    Episode_Reward/rotating_object: 143.6071
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.17s
                      Time elapsed: 00:33:24
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 45416 steps/s (collection: 2.067s, learning 0.098s)
             Mean action noise std: 2.78
          Mean value_function loss: 75.6814
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0047
                       Mean reward: 705.44
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 1.0203
    Episode_Reward/rotating_object: 141.4117
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.16s
                      Time elapsed: 00:33:26
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 45211 steps/s (collection: 2.073s, learning 0.101s)
             Mean action noise std: 2.79
          Mean value_function loss: 84.0813
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.0145
                       Mean reward: 655.32
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 1.0060
    Episode_Reward/rotating_object: 137.1646
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.17s
                      Time elapsed: 00:33:28
                               ETA: 00:24:16

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 45217 steps/s (collection: 2.068s, learning 0.106s)
             Mean action noise std: 2.79
          Mean value_function loss: 92.3509
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.0265
                       Mean reward: 695.05
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 1.0227
    Episode_Reward/rotating_object: 141.5920
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.17s
                      Time elapsed: 00:33:30
                               ETA: 00:24:14

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 42740 steps/s (collection: 2.189s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 80.2425
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.0467
                       Mean reward: 701.10
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.9937
    Episode_Reward/rotating_object: 136.1070
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.30s
                      Time elapsed: 00:33:32
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 44605 steps/s (collection: 2.101s, learning 0.103s)
             Mean action noise std: 2.79
          Mean value_function loss: 79.7010
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.0723
                       Mean reward: 678.53
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 137.4466
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.20s
                      Time elapsed: 00:33:35
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 42870 steps/s (collection: 2.180s, learning 0.113s)
             Mean action noise std: 2.80
          Mean value_function loss: 74.9652
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0978
                       Mean reward: 680.83
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 134.0547
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.29s
                      Time elapsed: 00:33:37
                               ETA: 00:24:07

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 46067 steps/s (collection: 2.033s, learning 0.100s)
             Mean action noise std: 2.80
          Mean value_function loss: 59.0972
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.1104
                       Mean reward: 679.84
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.0153
    Episode_Reward/rotating_object: 138.4619
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.13s
                      Time elapsed: 00:33:39
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 44215 steps/s (collection: 2.122s, learning 0.102s)
             Mean action noise std: 2.80
          Mean value_function loss: 74.3316
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.1233
                       Mean reward: 695.12
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 0.9947
    Episode_Reward/rotating_object: 134.9770
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.22s
                      Time elapsed: 00:33:41
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 41426 steps/s (collection: 2.273s, learning 0.100s)
             Mean action noise std: 2.81
          Mean value_function loss: 60.1459
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.1477
                       Mean reward: 712.71
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.0149
    Episode_Reward/rotating_object: 142.0326
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.37s
                      Time elapsed: 00:33:44
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 43020 steps/s (collection: 2.174s, learning 0.111s)
             Mean action noise std: 2.81
          Mean value_function loss: 61.3154
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.1758
                       Mean reward: 719.31
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.0173
    Episode_Reward/rotating_object: 143.4162
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.29s
                      Time elapsed: 00:33:46
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 44142 steps/s (collection: 2.101s, learning 0.126s)
             Mean action noise std: 2.81
          Mean value_function loss: 69.0494
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.2020
                       Mean reward: 708.36
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.0036
    Episode_Reward/rotating_object: 137.6106
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.23s
                      Time elapsed: 00:33:48
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 45740 steps/s (collection: 2.050s, learning 0.100s)
             Mean action noise std: 2.81
          Mean value_function loss: 67.6136
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.2239
                       Mean reward: 678.55
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.0007
    Episode_Reward/rotating_object: 137.9820
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.15s
                      Time elapsed: 00:33:50
                               ETA: 00:23:53

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 45813 steps/s (collection: 2.036s, learning 0.110s)
             Mean action noise std: 2.82
          Mean value_function loss: 65.7595
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.2431
                       Mean reward: 697.58
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 1.0185
    Episode_Reward/rotating_object: 141.0434
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.15s
                      Time elapsed: 00:33:52
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 45351 steps/s (collection: 2.070s, learning 0.098s)
             Mean action noise std: 2.82
          Mean value_function loss: 65.6723
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.2626
                       Mean reward: 735.83
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 1.0092
    Episode_Reward/rotating_object: 139.0994
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.17s
                      Time elapsed: 00:33:55
                               ETA: 00:23:48

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 44768 steps/s (collection: 2.095s, learning 0.101s)
             Mean action noise std: 2.82
          Mean value_function loss: 64.2456
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.2817
                       Mean reward: 693.37
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 140.2175
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.20s
                      Time elapsed: 00:33:57
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 44169 steps/s (collection: 2.106s, learning 0.120s)
             Mean action noise std: 2.83
          Mean value_function loss: 56.7607
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.3072
                       Mean reward: 706.40
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.0213
    Episode_Reward/rotating_object: 142.1679
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.23s
                      Time elapsed: 00:33:59
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 43961 steps/s (collection: 2.118s, learning 0.119s)
             Mean action noise std: 2.83
          Mean value_function loss: 83.7333
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.3324
                       Mean reward: 693.91
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 139.7890
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.24s
                      Time elapsed: 00:34:01
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 41982 steps/s (collection: 2.224s, learning 0.117s)
             Mean action noise std: 2.83
          Mean value_function loss: 92.0552
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.3530
                       Mean reward: 687.78
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.0055
    Episode_Reward/rotating_object: 137.8175
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.34s
                      Time elapsed: 00:34:04
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 44644 steps/s (collection: 2.100s, learning 0.101s)
             Mean action noise std: 2.83
          Mean value_function loss: 68.9783
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.3717
                       Mean reward: 698.46
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.0064
    Episode_Reward/rotating_object: 137.7746
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.20s
                      Time elapsed: 00:34:06
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 43093 steps/s (collection: 2.177s, learning 0.105s)
             Mean action noise std: 2.84
          Mean value_function loss: 80.2081
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.3908
                       Mean reward: 661.10
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 0.9956
    Episode_Reward/rotating_object: 134.7373
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.28s
                      Time elapsed: 00:34:08
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 43949 steps/s (collection: 2.121s, learning 0.115s)
             Mean action noise std: 2.84
          Mean value_function loss: 86.0413
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.4102
                       Mean reward: 697.87
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 0.9903
    Episode_Reward/rotating_object: 135.6170
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.24s
                      Time elapsed: 00:34:10
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 44059 steps/s (collection: 2.128s, learning 0.103s)
             Mean action noise std: 2.84
          Mean value_function loss: 70.6023
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.4375
                       Mean reward: 709.31
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.0009
    Episode_Reward/rotating_object: 136.7981
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.23s
                      Time elapsed: 00:34:13
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 45569 steps/s (collection: 2.054s, learning 0.104s)
             Mean action noise std: 2.85
          Mean value_function loss: 79.4623
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.4687
                       Mean reward: 650.32
               Mean episode length: 225.26
    Episode_Reward/reaching_object: 0.9988
    Episode_Reward/rotating_object: 137.2245
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.16s
                      Time elapsed: 00:34:15
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 43542 steps/s (collection: 2.142s, learning 0.116s)
             Mean action noise std: 2.85
          Mean value_function loss: 75.8179
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.4927
                       Mean reward: 690.68
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 0.9910
    Episode_Reward/rotating_object: 136.4430
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.26s
                      Time elapsed: 00:34:17
                               ETA: 00:23:24

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 44087 steps/s (collection: 2.120s, learning 0.110s)
             Mean action noise std: 2.85
          Mean value_function loss: 77.6292
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.5175
                       Mean reward: 697.32
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.0173
    Episode_Reward/rotating_object: 141.1331
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.23s
                      Time elapsed: 00:34:19
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 42597 steps/s (collection: 2.192s, learning 0.116s)
             Mean action noise std: 2.85
          Mean value_function loss: 72.8172
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.5352
                       Mean reward: 673.44
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.0109
    Episode_Reward/rotating_object: 138.3082
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.31s
                      Time elapsed: 00:34:22
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 43387 steps/s (collection: 2.159s, learning 0.107s)
             Mean action noise std: 2.86
          Mean value_function loss: 74.7919
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.5497
                       Mean reward: 711.78
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 1.0097
    Episode_Reward/rotating_object: 135.9850
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.27s
                      Time elapsed: 00:34:24
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 44283 steps/s (collection: 2.105s, learning 0.115s)
             Mean action noise std: 2.86
          Mean value_function loss: 69.9008
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.5706
                       Mean reward: 711.10
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 1.0117
    Episode_Reward/rotating_object: 138.6990
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.22s
                      Time elapsed: 00:34:26
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 44685 steps/s (collection: 2.098s, learning 0.102s)
             Mean action noise std: 2.86
          Mean value_function loss: 88.9771
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.5882
                       Mean reward: 723.60
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 1.0031
    Episode_Reward/rotating_object: 135.7433
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.20s
                      Time elapsed: 00:34:28
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 45475 steps/s (collection: 2.059s, learning 0.103s)
             Mean action noise std: 2.87
          Mean value_function loss: 82.2429
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.6042
                       Mean reward: 669.08
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 0.9910
    Episode_Reward/rotating_object: 135.2674
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.16s
                      Time elapsed: 00:34:30
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 45566 steps/s (collection: 2.052s, learning 0.105s)
             Mean action noise std: 2.87
          Mean value_function loss: 69.8200
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.6242
                       Mean reward: 712.69
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 0.9982
    Episode_Reward/rotating_object: 135.9668
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.16s
                      Time elapsed: 00:34:33
                               ETA: 00:23:08

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 43418 steps/s (collection: 2.123s, learning 0.142s)
             Mean action noise std: 2.87
          Mean value_function loss: 68.0960
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.6417
                       Mean reward: 664.84
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.0119
    Episode_Reward/rotating_object: 138.8692
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.26s
                      Time elapsed: 00:34:35
                               ETA: 00:23:05

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 43530 steps/s (collection: 2.140s, learning 0.119s)
             Mean action noise std: 2.87
          Mean value_function loss: 74.0136
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.6630
                       Mean reward: 718.49
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.9924
    Episode_Reward/rotating_object: 137.6358
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.26s
                      Time elapsed: 00:34:37
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 44802 steps/s (collection: 2.090s, learning 0.105s)
             Mean action noise std: 2.88
          Mean value_function loss: 77.2256
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.6827
                       Mean reward: 660.83
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.0245
    Episode_Reward/rotating_object: 142.6338
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.19s
                      Time elapsed: 00:34:39
                               ETA: 00:23:01

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 45789 steps/s (collection: 2.043s, learning 0.104s)
             Mean action noise std: 2.88
          Mean value_function loss: 76.4679
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.7029
                       Mean reward: 646.25
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 0.9897
    Episode_Reward/rotating_object: 134.6380
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.15s
                      Time elapsed: 00:34:41
                               ETA: 00:22:58

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 45993 steps/s (collection: 2.039s, learning 0.099s)
             Mean action noise std: 2.88
          Mean value_function loss: 70.5031
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.7255
                       Mean reward: 720.84
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 1.0215
    Episode_Reward/rotating_object: 142.5329
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.14s
                      Time elapsed: 00:34:44
                               ETA: 00:22:56

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 40411 steps/s (collection: 2.312s, learning 0.120s)
             Mean action noise std: 2.88
          Mean value_function loss: 69.7852
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.7424
                       Mean reward: 717.23
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.0002
    Episode_Reward/rotating_object: 140.0887
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.43s
                      Time elapsed: 00:34:46
                               ETA: 00:22:54

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 43972 steps/s (collection: 2.094s, learning 0.142s)
             Mean action noise std: 2.89
          Mean value_function loss: 60.0335
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.7619
                       Mean reward: 701.37
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 138.2870
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.24s
                      Time elapsed: 00:34:48
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 43838 steps/s (collection: 2.124s, learning 0.119s)
             Mean action noise std: 2.89
          Mean value_function loss: 82.9510
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.7818
                       Mean reward: 646.95
               Mean episode length: 231.76
    Episode_Reward/reaching_object: 1.0078
    Episode_Reward/rotating_object: 137.1119
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.24s
                      Time elapsed: 00:34:50
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 44711 steps/s (collection: 2.092s, learning 0.107s)
             Mean action noise std: 2.89
          Mean value_function loss: 69.6867
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.8002
                       Mean reward: 672.14
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 0.9914
    Episode_Reward/rotating_object: 137.6333
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.20s
                      Time elapsed: 00:34:53
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 45185 steps/s (collection: 2.068s, learning 0.108s)
             Mean action noise std: 2.89
          Mean value_function loss: 81.1528
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.8139
                       Mean reward: 689.73
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 0.9797
    Episode_Reward/rotating_object: 133.9713
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.18s
                      Time elapsed: 00:34:55
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 43234 steps/s (collection: 2.148s, learning 0.126s)
             Mean action noise std: 2.90
          Mean value_function loss: 69.9986
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 53.8340
                       Mean reward: 677.83
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 1.0091
    Episode_Reward/rotating_object: 137.9012
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.27s
                      Time elapsed: 00:34:57
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 41173 steps/s (collection: 2.271s, learning 0.117s)
             Mean action noise std: 2.90
          Mean value_function loss: 81.4744
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.8558
                       Mean reward: 691.56
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 0.9739
    Episode_Reward/rotating_object: 131.3798
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.39s
                      Time elapsed: 00:34:59
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 42572 steps/s (collection: 2.203s, learning 0.106s)
             Mean action noise std: 2.90
          Mean value_function loss: 81.6188
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.8776
                       Mean reward: 731.47
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 1.0094
    Episode_Reward/rotating_object: 140.3090
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.31s
                      Time elapsed: 00:35:02
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 40637 steps/s (collection: 2.282s, learning 0.137s)
             Mean action noise std: 2.91
          Mean value_function loss: 68.9211
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.8980
                       Mean reward: 705.13
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.9995
    Episode_Reward/rotating_object: 137.0746
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.42s
                      Time elapsed: 00:35:04
                               ETA: 00:22:35

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 40771 steps/s (collection: 2.292s, learning 0.119s)
             Mean action noise std: 2.91
          Mean value_function loss: 82.4909
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.9159
                       Mean reward: 700.77
               Mean episode length: 239.75
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 136.4917
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.41s
                      Time elapsed: 00:35:07
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 42712 steps/s (collection: 2.186s, learning 0.115s)
             Mean action noise std: 2.91
          Mean value_function loss: 76.3936
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.9290
                       Mean reward: 667.43
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 0.9916
    Episode_Reward/rotating_object: 136.9017
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.30s
                      Time elapsed: 00:35:09
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 43657 steps/s (collection: 2.139s, learning 0.113s)
             Mean action noise std: 2.91
          Mean value_function loss: 86.4040
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.9425
                       Mean reward: 606.40
               Mean episode length: 218.85
    Episode_Reward/reaching_object: 0.9822
    Episode_Reward/rotating_object: 133.8136
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.25s
                      Time elapsed: 00:35:11
                               ETA: 00:22:28

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 43937 steps/s (collection: 2.131s, learning 0.107s)
             Mean action noise std: 2.91
          Mean value_function loss: 77.1773
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.9609
                       Mean reward: 692.20
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.0071
    Episode_Reward/rotating_object: 138.6531
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.24s
                      Time elapsed: 00:35:13
                               ETA: 00:22:26

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 42251 steps/s (collection: 2.210s, learning 0.117s)
             Mean action noise std: 2.92
          Mean value_function loss: 81.2463
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.9796
                       Mean reward: 676.21
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 0.9965
    Episode_Reward/rotating_object: 137.1035
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.33s
                      Time elapsed: 00:35:16
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 42276 steps/s (collection: 2.216s, learning 0.110s)
             Mean action noise std: 2.92
          Mean value_function loss: 79.6951
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.9983
                       Mean reward: 723.80
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.0001
    Episode_Reward/rotating_object: 140.2229
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.33s
                      Time elapsed: 00:35:18
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 44492 steps/s (collection: 2.098s, learning 0.112s)
             Mean action noise std: 2.92
          Mean value_function loss: 66.8483
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.0215
                       Mean reward: 703.35
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.0080
    Episode_Reward/rotating_object: 138.0050
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.21s
                      Time elapsed: 00:35:20
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 43880 steps/s (collection: 2.122s, learning 0.118s)
             Mean action noise std: 2.93
          Mean value_function loss: 81.5742
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.0381
                       Mean reward: 683.80
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.9842
    Episode_Reward/rotating_object: 134.1813
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.24s
                      Time elapsed: 00:35:22
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 45437 steps/s (collection: 2.015s, learning 0.148s)
             Mean action noise std: 2.93
          Mean value_function loss: 87.6388
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.0568
                       Mean reward: 677.53
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 0.9952
    Episode_Reward/rotating_object: 138.0319
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.16s
                      Time elapsed: 00:35:25
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 43219 steps/s (collection: 2.164s, learning 0.110s)
             Mean action noise std: 2.93
          Mean value_function loss: 88.0921
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.0706
                       Mean reward: 668.50
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 0.9876
    Episode_Reward/rotating_object: 134.9547
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.27s
                      Time elapsed: 00:35:27
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 43091 steps/s (collection: 2.171s, learning 0.110s)
             Mean action noise std: 2.93
          Mean value_function loss: 80.5136
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.0878
                       Mean reward: 651.87
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 0.9994
    Episode_Reward/rotating_object: 136.5427
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.28s
                      Time elapsed: 00:35:29
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 44129 steps/s (collection: 2.103s, learning 0.125s)
             Mean action noise std: 2.94
          Mean value_function loss: 69.9327
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.1075
                       Mean reward: 671.27
               Mean episode length: 231.10
    Episode_Reward/reaching_object: 1.0035
    Episode_Reward/rotating_object: 137.9307
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.23s
                      Time elapsed: 00:35:31
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 42514 steps/s (collection: 2.206s, learning 0.106s)
             Mean action noise std: 2.94
          Mean value_function loss: 81.2221
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.1326
                       Mean reward: 730.80
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.9998
    Episode_Reward/rotating_object: 137.7615
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.31s
                      Time elapsed: 00:35:34
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 44600 steps/s (collection: 2.095s, learning 0.110s)
             Mean action noise std: 2.94
          Mean value_function loss: 80.9950
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.1504
                       Mean reward: 713.51
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 0.9969
    Episode_Reward/rotating_object: 139.0722
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.20s
                      Time elapsed: 00:35:36
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 44413 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 2.94
          Mean value_function loss: 92.3462
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.1654
                       Mean reward: 676.58
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 0.9772
    Episode_Reward/rotating_object: 133.8562
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.21s
                      Time elapsed: 00:35:38
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 42971 steps/s (collection: 2.163s, learning 0.125s)
             Mean action noise std: 2.95
          Mean value_function loss: 79.8365
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.1815
                       Mean reward: 733.57
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.0024
    Episode_Reward/rotating_object: 138.4023
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.29s
                      Time elapsed: 00:35:40
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 45209 steps/s (collection: 2.067s, learning 0.108s)
             Mean action noise std: 2.95
          Mean value_function loss: 80.2647
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 54.2042
                       Mean reward: 658.84
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 0.9831
    Episode_Reward/rotating_object: 135.9762
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.17s
                      Time elapsed: 00:35:43
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 44293 steps/s (collection: 2.101s, learning 0.119s)
             Mean action noise std: 2.95
          Mean value_function loss: 65.6639
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.2290
                       Mean reward: 718.54
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 0.9933
    Episode_Reward/rotating_object: 134.6765
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.22s
                      Time elapsed: 00:35:45
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 41653 steps/s (collection: 2.260s, learning 0.100s)
             Mean action noise std: 2.95
          Mean value_function loss: 68.7517
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.2464
                       Mean reward: 664.30
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 0.9804
    Episode_Reward/rotating_object: 131.8828
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.36s
                      Time elapsed: 00:35:47
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 44515 steps/s (collection: 2.090s, learning 0.118s)
             Mean action noise std: 2.96
          Mean value_function loss: 69.9713
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.2648
                       Mean reward: 750.43
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 0.9995
    Episode_Reward/rotating_object: 140.1677
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.21s
                      Time elapsed: 00:35:49
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 44452 steps/s (collection: 2.086s, learning 0.126s)
             Mean action noise std: 2.96
          Mean value_function loss: 91.2476
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.2864
                       Mean reward: 686.35
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 0.9900
    Episode_Reward/rotating_object: 135.4606
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.21s
                      Time elapsed: 00:35:52
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 44735 steps/s (collection: 2.076s, learning 0.121s)
             Mean action noise std: 2.96
          Mean value_function loss: 80.6069
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.3094
                       Mean reward: 676.71
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 0.9849
    Episode_Reward/rotating_object: 135.1191
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.20s
                      Time elapsed: 00:35:54
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 43795 steps/s (collection: 2.130s, learning 0.115s)
             Mean action noise std: 2.96
          Mean value_function loss: 75.1477
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.3298
                       Mean reward: 700.58
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 0.9972
    Episode_Reward/rotating_object: 136.2865
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.24s
                      Time elapsed: 00:35:56
                               ETA: 00:21:41

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 42932 steps/s (collection: 2.155s, learning 0.135s)
             Mean action noise std: 2.97
          Mean value_function loss: 69.1873
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.3437
                       Mean reward: 691.64
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 0.9890
    Episode_Reward/rotating_object: 132.5365
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.29s
                      Time elapsed: 00:35:58
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 43073 steps/s (collection: 2.176s, learning 0.107s)
             Mean action noise std: 2.97
          Mean value_function loss: 88.4890
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.3621
                       Mean reward: 673.75
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 0.9829
    Episode_Reward/rotating_object: 133.5872
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.28s
                      Time elapsed: 00:36:01
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 45585 steps/s (collection: 2.056s, learning 0.101s)
             Mean action noise std: 2.97
          Mean value_function loss: 76.5629
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.3845
                       Mean reward: 671.93
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 0.9761
    Episode_Reward/rotating_object: 136.2003
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.16s
                      Time elapsed: 00:36:03
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 44370 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 2.97
          Mean value_function loss: 94.7601
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 54.3971
                       Mean reward: 683.46
               Mean episode length: 231.41
    Episode_Reward/reaching_object: 0.9833
    Episode_Reward/rotating_object: 136.8513
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.22s
                      Time elapsed: 00:36:05
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 43798 steps/s (collection: 2.092s, learning 0.153s)
             Mean action noise std: 2.98
          Mean value_function loss: 84.5290
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.4081
                       Mean reward: 649.35
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 0.9687
    Episode_Reward/rotating_object: 133.7212
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.24s
                      Time elapsed: 00:36:07
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 39160 steps/s (collection: 2.365s, learning 0.145s)
             Mean action noise std: 2.98
          Mean value_function loss: 64.8883
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.4335
                       Mean reward: 702.81
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.0012
    Episode_Reward/rotating_object: 138.9418
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.51s
                      Time elapsed: 00:36:10
                               ETA: 00:21:27

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 40719 steps/s (collection: 2.311s, learning 0.103s)
             Mean action noise std: 2.98
          Mean value_function loss: 83.1064
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.4536
                       Mean reward: 646.83
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 0.9789
    Episode_Reward/rotating_object: 132.6135
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.41s
                      Time elapsed: 00:36:12
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 45309 steps/s (collection: 2.050s, learning 0.120s)
             Mean action noise std: 2.99
          Mean value_function loss: 78.7934
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.4760
                       Mean reward: 681.21
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.0071
    Episode_Reward/rotating_object: 137.2287
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.17s
                      Time elapsed: 00:36:14
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 44457 steps/s (collection: 2.111s, learning 0.100s)
             Mean action noise std: 2.99
          Mean value_function loss: 89.7346
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.4955
                       Mean reward: 672.56
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.0110
    Episode_Reward/rotating_object: 138.6054
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.21s
                      Time elapsed: 00:36:17
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 45513 steps/s (collection: 2.048s, learning 0.112s)
             Mean action noise std: 2.99
          Mean value_function loss: 78.4651
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.5105
                       Mean reward: 703.53
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0077
    Episode_Reward/rotating_object: 138.2962
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.16s
                      Time elapsed: 00:36:19
                               ETA: 00:21:18

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 42435 steps/s (collection: 2.194s, learning 0.122s)
             Mean action noise std: 2.99
          Mean value_function loss: 72.5065
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.5354
                       Mean reward: 695.81
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 0.9943
    Episode_Reward/rotating_object: 134.7337
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.32s
                      Time elapsed: 00:36:21
                               ETA: 00:21:16

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 41383 steps/s (collection: 2.237s, learning 0.139s)
             Mean action noise std: 3.00
          Mean value_function loss: 92.5532
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.5553
                       Mean reward: 652.09
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 0.9738
    Episode_Reward/rotating_object: 131.4538
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.38s
                      Time elapsed: 00:36:23
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 42912 steps/s (collection: 2.185s, learning 0.106s)
             Mean action noise std: 3.00
          Mean value_function loss: 82.1159
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.5827
                       Mean reward: 639.16
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 0.9948
    Episode_Reward/rotating_object: 134.1690
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.29s
                      Time elapsed: 00:36:26
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 44590 steps/s (collection: 2.106s, learning 0.099s)
             Mean action noise std: 3.00
          Mean value_function loss: 83.2333
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.6018
                       Mean reward: 637.56
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 0.9795
    Episode_Reward/rotating_object: 132.7289
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.20s
                      Time elapsed: 00:36:28
                               ETA: 00:21:09

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 43006 steps/s (collection: 2.174s, learning 0.112s)
             Mean action noise std: 3.00
          Mean value_function loss: 73.7507
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.6135
                       Mean reward: 693.53
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.0072
    Episode_Reward/rotating_object: 137.6286
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.29s
                      Time elapsed: 00:36:30
                               ETA: 00:21:06

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 43844 steps/s (collection: 2.138s, learning 0.104s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.5370
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.6237
                       Mean reward: 650.47
               Mean episode length: 227.20
    Episode_Reward/reaching_object: 1.0030
    Episode_Reward/rotating_object: 137.6211
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.24s
                      Time elapsed: 00:36:32
                               ETA: 00:21:04

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 45649 steps/s (collection: 2.037s, learning 0.117s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.7948
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.6389
                       Mean reward: 684.20
               Mean episode length: 236.27
    Episode_Reward/reaching_object: 0.9866
    Episode_Reward/rotating_object: 135.6403
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.15s
                      Time elapsed: 00:36:35
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 44964 steps/s (collection: 2.075s, learning 0.112s)
             Mean action noise std: 3.01
          Mean value_function loss: 73.0691
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.6516
                       Mean reward: 697.82
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.0149
    Episode_Reward/rotating_object: 138.0617
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.19s
                      Time elapsed: 00:36:37
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 45676 steps/s (collection: 2.051s, learning 0.101s)
             Mean action noise std: 3.01
          Mean value_function loss: 74.0430
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.6669
                       Mean reward: 696.89
               Mean episode length: 237.75
    Episode_Reward/reaching_object: 1.0024
    Episode_Reward/rotating_object: 136.3588
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.15s
                      Time elapsed: 00:36:39
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 40974 steps/s (collection: 2.292s, learning 0.108s)
             Mean action noise std: 3.02
          Mean value_function loss: 67.3106
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.6868
                       Mean reward: 712.03
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.0065
    Episode_Reward/rotating_object: 139.8361
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.40s
                      Time elapsed: 00:36:41
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 44688 steps/s (collection: 2.095s, learning 0.105s)
             Mean action noise std: 3.02
          Mean value_function loss: 78.1953
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.7060
                       Mean reward: 667.80
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 0.9983
    Episode_Reward/rotating_object: 137.7392
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.20s
                      Time elapsed: 00:36:44
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 45131 steps/s (collection: 2.078s, learning 0.100s)
             Mean action noise std: 3.02
          Mean value_function loss: 64.9700
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.7240
                       Mean reward: 707.64
               Mean episode length: 240.24
    Episode_Reward/reaching_object: 1.0130
    Episode_Reward/rotating_object: 140.5929
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.18s
                      Time elapsed: 00:36:46
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 44068 steps/s (collection: 2.107s, learning 0.124s)
             Mean action noise std: 3.02
          Mean value_function loss: 65.0647
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.7438
                       Mean reward: 718.28
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.0025
    Episode_Reward/rotating_object: 138.6382
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.23s
                      Time elapsed: 00:36:48
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 43818 steps/s (collection: 2.140s, learning 0.104s)
             Mean action noise std: 3.03
          Mean value_function loss: 65.5849
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.7594
                       Mean reward: 716.90
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 0.9899
    Episode_Reward/rotating_object: 138.6638
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.24s
                      Time elapsed: 00:36:50
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 43342 steps/s (collection: 2.145s, learning 0.124s)
             Mean action noise std: 3.03
          Mean value_function loss: 72.5201
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.7752
                       Mean reward: 710.46
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.9988
    Episode_Reward/rotating_object: 137.9848
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.27s
                      Time elapsed: 00:36:52
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 44262 steps/s (collection: 2.088s, learning 0.133s)
             Mean action noise std: 3.03
          Mean value_function loss: 66.5712
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.7923
                       Mean reward: 694.42
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 1.0094
    Episode_Reward/rotating_object: 139.0007
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.22s
                      Time elapsed: 00:36:55
                               ETA: 00:20:41

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 42211 steps/s (collection: 2.160s, learning 0.169s)
             Mean action noise std: 3.03
          Mean value_function loss: 75.3199
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.8043
                       Mean reward: 698.43
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 0.9910
    Episode_Reward/rotating_object: 138.1979
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.33s
                      Time elapsed: 00:36:57
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 45405 steps/s (collection: 2.062s, learning 0.103s)
             Mean action noise std: 3.03
          Mean value_function loss: 73.6535
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.8178
                       Mean reward: 700.79
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 0.9891
    Episode_Reward/rotating_object: 137.5370
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.17s
                      Time elapsed: 00:36:59
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 43518 steps/s (collection: 2.153s, learning 0.106s)
             Mean action noise std: 3.04
          Mean value_function loss: 66.1849
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.8330
                       Mean reward: 685.18
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 0.9965
    Episode_Reward/rotating_object: 137.4750
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.26s
                      Time elapsed: 00:37:01
                               ETA: 00:20:34

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 45305 steps/s (collection: 2.056s, learning 0.114s)
             Mean action noise std: 3.04
          Mean value_function loss: 81.3678
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.8554
                       Mean reward: 731.17
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 0.9847
    Episode_Reward/rotating_object: 137.0749
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.17s
                      Time elapsed: 00:37:04
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 45525 steps/s (collection: 2.053s, learning 0.106s)
             Mean action noise std: 3.04
          Mean value_function loss: 74.8689
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.8818
                       Mean reward: 678.36
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 0.9794
    Episode_Reward/rotating_object: 135.5725
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.16s
                      Time elapsed: 00:37:06
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 43903 steps/s (collection: 2.130s, learning 0.110s)
             Mean action noise std: 3.05
          Mean value_function loss: 79.2796
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.9103
                       Mean reward: 720.84
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 0.9868
    Episode_Reward/rotating_object: 137.6192
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.24s
                      Time elapsed: 00:37:08
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 44642 steps/s (collection: 2.104s, learning 0.098s)
             Mean action noise std: 3.05
          Mean value_function loss: 73.9186
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.9337
                       Mean reward: 646.79
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 0.9501
    Episode_Reward/rotating_object: 132.3269
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.20s
                      Time elapsed: 00:37:10
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 45773 steps/s (collection: 2.038s, learning 0.110s)
             Mean action noise std: 3.05
          Mean value_function loss: 72.3326
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.9485
                       Mean reward: 681.19
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 0.9763
    Episode_Reward/rotating_object: 137.7768
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.15s
                      Time elapsed: 00:37:12
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 38832 steps/s (collection: 2.383s, learning 0.148s)
             Mean action noise std: 3.06
          Mean value_function loss: 65.0269
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.9618
                       Mean reward: 675.76
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 0.9986
    Episode_Reward/rotating_object: 139.4525
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.53s
                      Time elapsed: 00:37:15
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 40036 steps/s (collection: 2.290s, learning 0.165s)
             Mean action noise std: 3.06
          Mean value_function loss: 53.3148
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.9819
                       Mean reward: 686.68
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.9952
    Episode_Reward/rotating_object: 137.2260
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.46s
                      Time elapsed: 00:37:17
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 40349 steps/s (collection: 2.280s, learning 0.156s)
             Mean action noise std: 3.06
          Mean value_function loss: 79.3403
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.0015
                       Mean reward: 694.53
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 0.9696
    Episode_Reward/rotating_object: 136.6512
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.44s
                      Time elapsed: 00:37:20
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 39873 steps/s (collection: 2.350s, learning 0.115s)
             Mean action noise std: 3.06
          Mean value_function loss: 69.6947
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.0159
                       Mean reward: 707.57
               Mean episode length: 235.54
    Episode_Reward/reaching_object: 0.9937
    Episode_Reward/rotating_object: 140.2778
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.47s
                      Time elapsed: 00:37:22
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 45695 steps/s (collection: 2.053s, learning 0.098s)
             Mean action noise std: 3.07
          Mean value_function loss: 65.8153
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.0338
                       Mean reward: 698.61
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.9838
    Episode_Reward/rotating_object: 138.4168
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.15s
                      Time elapsed: 00:37:24
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45589 steps/s (collection: 2.035s, learning 0.121s)
             Mean action noise std: 3.07
          Mean value_function loss: 80.5885
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.0459
                       Mean reward: 693.81
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 0.9829
    Episode_Reward/rotating_object: 138.7094
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.16s
                      Time elapsed: 00:37:27
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 45442 steps/s (collection: 2.019s, learning 0.145s)
             Mean action noise std: 3.07
          Mean value_function loss: 71.2610
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.0628
                       Mean reward: 688.14
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 0.9551
    Episode_Reward/rotating_object: 134.1740
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.16s
                      Time elapsed: 00:37:29
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 45360 steps/s (collection: 2.022s, learning 0.146s)
             Mean action noise std: 3.07
          Mean value_function loss: 71.3614
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.0897
                       Mean reward: 666.47
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 0.9580
    Episode_Reward/rotating_object: 134.6343
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.17s
                      Time elapsed: 00:37:31
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 45887 steps/s (collection: 2.027s, learning 0.115s)
             Mean action noise std: 3.08
          Mean value_function loss: 74.8824
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.1106
                       Mean reward: 729.01
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.9752
    Episode_Reward/rotating_object: 140.2956
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.14s
                      Time elapsed: 00:37:33
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 47204 steps/s (collection: 1.976s, learning 0.107s)
             Mean action noise std: 3.08
          Mean value_function loss: 77.1800
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.1283
                       Mean reward: 706.65
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 0.9664
    Episode_Reward/rotating_object: 135.7758
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.08s
                      Time elapsed: 00:37:35
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 46031 steps/s (collection: 2.019s, learning 0.117s)
             Mean action noise std: 3.08
          Mean value_function loss: 58.1474
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.1452
                       Mean reward: 716.97
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 0.9772
    Episode_Reward/rotating_object: 138.2520
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.14s
                      Time elapsed: 00:37:37
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 46708 steps/s (collection: 2.005s, learning 0.099s)
             Mean action noise std: 3.08
          Mean value_function loss: 78.8130
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.1651
                       Mean reward: 689.88
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 0.9736
    Episode_Reward/rotating_object: 138.1178
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.10s
                      Time elapsed: 00:37:39
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 46261 steps/s (collection: 2.010s, learning 0.115s)
             Mean action noise std: 3.09
          Mean value_function loss: 79.2910
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.1850
                       Mean reward: 679.50
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 0.9779
    Episode_Reward/rotating_object: 137.6903
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.12s
                      Time elapsed: 00:37:41
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 46154 steps/s (collection: 2.030s, learning 0.100s)
             Mean action noise std: 3.09
          Mean value_function loss: 71.0617
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2096
                       Mean reward: 707.24
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 134.5892
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.13s
                      Time elapsed: 00:37:44
                               ETA: 00:19:49

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 45034 steps/s (collection: 2.040s, learning 0.143s)
             Mean action noise std: 3.09
          Mean value_function loss: 82.0811
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.2334
                       Mean reward: 700.61
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 0.9557
    Episode_Reward/rotating_object: 135.9656
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.18s
                      Time elapsed: 00:37:46
                               ETA: 00:19:47

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 44543 steps/s (collection: 2.001s, learning 0.206s)
             Mean action noise std: 3.10
          Mean value_function loss: 80.9377
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.2548
                       Mean reward: 693.24
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 0.9459
    Episode_Reward/rotating_object: 134.3162
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.21s
                      Time elapsed: 00:37:48
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 46104 steps/s (collection: 2.024s, learning 0.108s)
             Mean action noise std: 3.10
          Mean value_function loss: 81.5486
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.2760
                       Mean reward: 685.30
               Mean episode length: 230.95
    Episode_Reward/reaching_object: 0.9668
    Episode_Reward/rotating_object: 138.5591
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.13s
                      Time elapsed: 00:37:50
                               ETA: 00:19:42

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 44145 steps/s (collection: 2.128s, learning 0.099s)
             Mean action noise std: 3.10
          Mean value_function loss: 82.7080
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.2885
                       Mean reward: 698.24
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 0.9529
    Episode_Reward/rotating_object: 132.3413
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.23s
                      Time elapsed: 00:37:52
                               ETA: 00:19:40

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 44049 steps/s (collection: 2.073s, learning 0.159s)
             Mean action noise std: 3.11
          Mean value_function loss: 76.5609
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.3053
                       Mean reward: 675.06
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 0.9662
    Episode_Reward/rotating_object: 138.1182
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.23s
                      Time elapsed: 00:37:55
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 41262 steps/s (collection: 2.238s, learning 0.144s)
             Mean action noise std: 3.11
          Mean value_function loss: 65.8152
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.3252
                       Mean reward: 694.22
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 0.9673
    Episode_Reward/rotating_object: 137.4268
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.38s
                      Time elapsed: 00:37:57
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 43547 steps/s (collection: 2.162s, learning 0.096s)
             Mean action noise std: 3.11
          Mean value_function loss: 72.4673
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.3487
                       Mean reward: 680.01
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 0.9572
    Episode_Reward/rotating_object: 137.4868
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.26s
                      Time elapsed: 00:37:59
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 41775 steps/s (collection: 2.182s, learning 0.171s)
             Mean action noise std: 3.11
          Mean value_function loss: 71.7578
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.3692
                       Mean reward: 706.59
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 0.9716
    Episode_Reward/rotating_object: 138.4343
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.35s
                      Time elapsed: 00:38:02
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 38498 steps/s (collection: 2.401s, learning 0.152s)
             Mean action noise std: 3.12
          Mean value_function loss: 67.3569
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.3906
                       Mean reward: 685.59
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 137.9103
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.55s
                      Time elapsed: 00:38:04
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 45067 steps/s (collection: 2.063s, learning 0.118s)
             Mean action noise std: 3.12
          Mean value_function loss: 67.8948
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.4163
                       Mean reward: 689.70
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 0.9677
    Episode_Reward/rotating_object: 138.1012
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.18s
                      Time elapsed: 00:38:06
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 43053 steps/s (collection: 2.169s, learning 0.115s)
             Mean action noise std: 3.13
          Mean value_function loss: 94.2665
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.4447
                       Mean reward: 744.77
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.9580
    Episode_Reward/rotating_object: 136.0227
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.28s
                      Time elapsed: 00:38:09
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 43321 steps/s (collection: 2.135s, learning 0.134s)
             Mean action noise std: 3.13
          Mean value_function loss: 80.4297
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.4726
                       Mean reward: 679.30
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 0.9663
    Episode_Reward/rotating_object: 135.9667
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.27s
                      Time elapsed: 00:38:11
                               ETA: 00:19:21

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 45029 steps/s (collection: 2.031s, learning 0.152s)
             Mean action noise std: 3.13
          Mean value_function loss: 87.1409
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 55.4962
                       Mean reward: 716.18
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 0.9705
    Episode_Reward/rotating_object: 136.9401
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.18s
                      Time elapsed: 00:38:13
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 46299 steps/s (collection: 2.006s, learning 0.117s)
             Mean action noise std: 3.13
          Mean value_function loss: 71.1117
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.5123
                       Mean reward: 707.33
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 0.9689
    Episode_Reward/rotating_object: 136.3200
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.12s
                      Time elapsed: 00:38:15
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 46267 steps/s (collection: 2.031s, learning 0.094s)
             Mean action noise std: 3.14
          Mean value_function loss: 79.2025
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.5290
                       Mean reward: 735.08
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 0.9658
    Episode_Reward/rotating_object: 138.5481
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.12s
                      Time elapsed: 00:38:17
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 46844 steps/s (collection: 2.007s, learning 0.091s)
             Mean action noise std: 3.14
          Mean value_function loss: 72.6046
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.5448
                       Mean reward: 688.43
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 0.9725
    Episode_Reward/rotating_object: 137.6459
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.10s
                      Time elapsed: 00:38:19
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 13542 steps/s (collection: 7.143s, learning 0.116s)
             Mean action noise std: 3.14
          Mean value_function loss: 80.7211
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 55.5541
                       Mean reward: 715.15
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 0.9522
    Episode_Reward/rotating_object: 135.4919
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 7.26s
                      Time elapsed: 00:38:27
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 13616 steps/s (collection: 7.093s, learning 0.126s)
             Mean action noise std: 3.14
          Mean value_function loss: 67.2401
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.5630
                       Mean reward: 718.90
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 0.9821
    Episode_Reward/rotating_object: 139.4365
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 7.22s
                      Time elapsed: 00:38:34
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14408 steps/s (collection: 6.710s, learning 0.112s)
             Mean action noise std: 3.15
          Mean value_function loss: 73.3388
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.5798
                       Mean reward: 701.31
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 0.9514
    Episode_Reward/rotating_object: 135.2859
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.82s
                      Time elapsed: 00:38:41
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14732 steps/s (collection: 6.552s, learning 0.120s)
             Mean action noise std: 3.15
          Mean value_function loss: 82.0783
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.5987
                       Mean reward: 654.32
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.9483
    Episode_Reward/rotating_object: 129.9092
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.67s
                      Time elapsed: 00:38:47
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14383 steps/s (collection: 6.712s, learning 0.123s)
             Mean action noise std: 3.15
          Mean value_function loss: 73.1257
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.6182
                       Mean reward: 677.52
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 0.9410
    Episode_Reward/rotating_object: 134.3270
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.83s
                      Time elapsed: 00:38:54
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14939 steps/s (collection: 6.452s, learning 0.128s)
             Mean action noise std: 3.15
          Mean value_function loss: 71.6170
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.6464
                       Mean reward: 687.31
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 0.9662
    Episode_Reward/rotating_object: 136.9990
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.58s
                      Time elapsed: 00:39:01
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14448 steps/s (collection: 6.682s, learning 0.122s)
             Mean action noise std: 3.16
          Mean value_function loss: 73.4937
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.6715
                       Mean reward: 693.87
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 0.9739
    Episode_Reward/rotating_object: 138.2678
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.80s
                      Time elapsed: 00:39:08
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14346 steps/s (collection: 6.705s, learning 0.147s)
             Mean action noise std: 3.16
          Mean value_function loss: 84.2424
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.6895
                       Mean reward: 663.57
               Mean episode length: 226.75
    Episode_Reward/reaching_object: 0.9493
    Episode_Reward/rotating_object: 135.2282
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.85s
                      Time elapsed: 00:39:14
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 16119 steps/s (collection: 5.997s, learning 0.101s)
             Mean action noise std: 3.16
          Mean value_function loss: 72.7891
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.7114
                       Mean reward: 678.54
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 0.9704
    Episode_Reward/rotating_object: 136.4400
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0489
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 6.10s
                      Time elapsed: 00:39:21
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 45537 steps/s (collection: 2.034s, learning 0.125s)
             Mean action noise std: 3.17
          Mean value_function loss: 68.9886
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.7295
                       Mean reward: 701.84
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 0.9756
    Episode_Reward/rotating_object: 138.7055
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.16s
                      Time elapsed: 00:39:23
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 43309 steps/s (collection: 2.075s, learning 0.195s)
             Mean action noise std: 3.17
          Mean value_function loss: 67.8123
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.7417
                       Mean reward: 677.59
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 0.9568
    Episode_Reward/rotating_object: 133.7855
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.27s
                      Time elapsed: 00:39:25
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 44062 steps/s (collection: 2.126s, learning 0.105s)
             Mean action noise std: 3.17
          Mean value_function loss: 78.2770
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.7607
                       Mean reward: 700.46
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 0.9688
    Episode_Reward/rotating_object: 137.0417
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.23s
                      Time elapsed: 00:39:27
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 46587 steps/s (collection: 1.996s, learning 0.114s)
             Mean action noise std: 3.17
          Mean value_function loss: 82.9872
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.7762
                       Mean reward: 643.36
               Mean episode length: 229.96
    Episode_Reward/reaching_object: 0.9590
    Episode_Reward/rotating_object: 135.8721
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0488
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.11s
                      Time elapsed: 00:39:29
                               ETA: 00:19:01

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 45813 steps/s (collection: 1.999s, learning 0.147s)
             Mean action noise std: 3.18
          Mean value_function loss: 80.1415
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 55.7961
                       Mean reward: 673.31
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 0.9642
    Episode_Reward/rotating_object: 137.3306
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.15s
                      Time elapsed: 00:39:31
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 45846 steps/s (collection: 2.011s, learning 0.133s)
             Mean action noise std: 3.18
          Mean value_function loss: 86.4782
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.8149
                       Mean reward: 680.37
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 0.9579
    Episode_Reward/rotating_object: 134.2302
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.14s
                      Time elapsed: 00:39:34
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 44926 steps/s (collection: 2.076s, learning 0.113s)
             Mean action noise std: 3.18
          Mean value_function loss: 78.0718
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.8414
                       Mean reward: 664.50
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 0.9774
    Episode_Reward/rotating_object: 138.1815
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.19s
                      Time elapsed: 00:39:36
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 47954 steps/s (collection: 1.950s, learning 0.100s)
             Mean action noise std: 3.19
          Mean value_function loss: 77.0299
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.8611
                       Mean reward: 694.58
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.9688
    Episode_Reward/rotating_object: 137.5661
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.05s
                      Time elapsed: 00:39:38
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 46015 steps/s (collection: 2.027s, learning 0.109s)
             Mean action noise std: 3.19
          Mean value_function loss: 68.1396
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.8769
                       Mean reward: 684.85
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 0.9758
    Episode_Reward/rotating_object: 139.2020
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.14s
                      Time elapsed: 00:39:40
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 42582 steps/s (collection: 2.178s, learning 0.131s)
             Mean action noise std: 3.19
          Mean value_function loss: 72.0287
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.8897
                       Mean reward: 678.11
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.9774
    Episode_Reward/rotating_object: 140.4563
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.31s
                      Time elapsed: 00:39:42
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 40129 steps/s (collection: 2.265s, learning 0.185s)
             Mean action noise std: 3.19
          Mean value_function loss: 71.0016
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.9062
                       Mean reward: 665.10
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 0.9496
    Episode_Reward/rotating_object: 132.0089
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.45s
                      Time elapsed: 00:39:45
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 42835 steps/s (collection: 2.205s, learning 0.090s)
             Mean action noise std: 3.20
          Mean value_function loss: 86.3007
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.9241
                       Mean reward: 711.68
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 0.9735
    Episode_Reward/rotating_object: 136.3451
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.29s
                      Time elapsed: 00:39:47
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 46596 steps/s (collection: 2.019s, learning 0.091s)
             Mean action noise std: 3.20
          Mean value_function loss: 73.2732
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.9421
                       Mean reward: 699.20
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 0.9817
    Episode_Reward/rotating_object: 139.2393
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.11s
                      Time elapsed: 00:39:49
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 46949 steps/s (collection: 1.986s, learning 0.108s)
             Mean action noise std: 3.20
          Mean value_function loss: 68.6745
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.9686
                       Mean reward: 675.11
               Mean episode length: 231.13
    Episode_Reward/reaching_object: 0.9743
    Episode_Reward/rotating_object: 138.6866
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.09s
                      Time elapsed: 00:39:51
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 46124 steps/s (collection: 1.985s, learning 0.146s)
             Mean action noise std: 3.21
          Mean value_function loss: 73.7971
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.9849
                       Mean reward: 653.20
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 0.9707
    Episode_Reward/rotating_object: 135.6118
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.13s
                      Time elapsed: 00:39:53
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 42624 steps/s (collection: 2.159s, learning 0.147s)
             Mean action noise std: 3.21
          Mean value_function loss: 84.5748
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.0000
                       Mean reward: 663.63
               Mean episode length: 233.73
    Episode_Reward/reaching_object: 0.9511
    Episode_Reward/rotating_object: 132.4408
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.31s
                      Time elapsed: 00:39:56
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 44952 steps/s (collection: 2.081s, learning 0.106s)
             Mean action noise std: 3.21
          Mean value_function loss: 78.9382
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.0209
                       Mean reward: 682.26
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 0.9504
    Episode_Reward/rotating_object: 137.1917
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.19s
                      Time elapsed: 00:39:58
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 44210 steps/s (collection: 2.091s, learning 0.132s)
             Mean action noise std: 3.21
          Mean value_function loss: 67.1287
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.0373
                       Mean reward: 704.72
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 0.9755
    Episode_Reward/rotating_object: 139.0466
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.22s
                      Time elapsed: 00:40:00
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 46731 steps/s (collection: 1.992s, learning 0.112s)
             Mean action noise std: 3.22
          Mean value_function loss: 78.2714
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.0526
                       Mean reward: 673.16
               Mean episode length: 227.25
    Episode_Reward/reaching_object: 0.9468
    Episode_Reward/rotating_object: 134.3633
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.10s
                      Time elapsed: 00:40:02
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 47870 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 3.22
          Mean value_function loss: 74.6541
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.0683
                       Mean reward: 638.79
               Mean episode length: 229.59
    Episode_Reward/reaching_object: 0.9646
    Episode_Reward/rotating_object: 136.7920
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.05s
                      Time elapsed: 00:40:04
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 47648 steps/s (collection: 1.969s, learning 0.094s)
             Mean action noise std: 3.22
          Mean value_function loss: 73.9020
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.0817
                       Mean reward: 690.75
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 0.9676
    Episode_Reward/rotating_object: 135.7580
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.06s
                      Time elapsed: 00:40:06
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 47266 steps/s (collection: 1.980s, learning 0.100s)
             Mean action noise std: 3.22
          Mean value_function loss: 79.1858
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.1026
                       Mean reward: 623.84
               Mean episode length: 225.00
    Episode_Reward/reaching_object: 0.9518
    Episode_Reward/rotating_object: 134.8430
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.08s
                      Time elapsed: 00:40:08
                               ETA: 00:18:18

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 47506 steps/s (collection: 1.941s, learning 0.128s)
             Mean action noise std: 3.23
          Mean value_function loss: 71.9033
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.1206
                       Mean reward: 730.51
               Mean episode length: 242.90
    Episode_Reward/reaching_object: 0.9634
    Episode_Reward/rotating_object: 137.4903
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.07s
                      Time elapsed: 00:40:10
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 46572 steps/s (collection: 1.985s, learning 0.126s)
             Mean action noise std: 3.23
          Mean value_function loss: 69.6682
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.1353
                       Mean reward: 697.92
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 0.9747
    Episode_Reward/rotating_object: 137.3257
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.11s
                      Time elapsed: 00:40:13
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 46529 steps/s (collection: 1.972s, learning 0.141s)
             Mean action noise std: 3.23
          Mean value_function loss: 73.1232
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.1505
                       Mean reward: 735.98
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 0.9660
    Episode_Reward/rotating_object: 136.6230
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.11s
                      Time elapsed: 00:40:15
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 38946 steps/s (collection: 2.310s, learning 0.214s)
             Mean action noise std: 3.23
          Mean value_function loss: 70.1915
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.1709
                       Mean reward: 652.77
               Mean episode length: 231.20
    Episode_Reward/reaching_object: 0.9796
    Episode_Reward/rotating_object: 134.2714
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.52s
                      Time elapsed: 00:40:17
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 29797 steps/s (collection: 3.059s, learning 0.240s)
             Mean action noise std: 3.24
          Mean value_function loss: 77.0886
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.1900
                       Mean reward: 706.47
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 0.9806
    Episode_Reward/rotating_object: 138.5293
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 3.30s
                      Time elapsed: 00:40:20
                               ETA: 00:18:06

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 39090 steps/s (collection: 2.423s, learning 0.092s)
             Mean action noise std: 3.24
          Mean value_function loss: 63.7603
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.2122
                       Mean reward: 688.90
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.9842
    Episode_Reward/rotating_object: 135.5891
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.51s
                      Time elapsed: 00:40:23
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 44762 steps/s (collection: 2.104s, learning 0.092s)
             Mean action noise std: 3.24
          Mean value_function loss: 84.8096
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.2299
                       Mean reward: 678.61
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 0.9759
    Episode_Reward/rotating_object: 138.2433
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.20s
                      Time elapsed: 00:40:25
                               ETA: 00:18:01

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 40526 steps/s (collection: 2.322s, learning 0.103s)
             Mean action noise std: 3.25
          Mean value_function loss: 71.0224
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.2485
                       Mean reward: 695.63
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 0.9680
    Episode_Reward/rotating_object: 136.5211
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.43s
                      Time elapsed: 00:40:28
                               ETA: 00:17:59

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 40760 steps/s (collection: 2.240s, learning 0.172s)
             Mean action noise std: 3.25
          Mean value_function loss: 70.4532
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 56.2661
                       Mean reward: 680.16
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 0.9749
    Episode_Reward/rotating_object: 137.8559
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.41s
                      Time elapsed: 00:40:30
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 42769 steps/s (collection: 2.195s, learning 0.104s)
             Mean action noise std: 3.25
          Mean value_function loss: 87.8842
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 56.2777
                       Mean reward: 638.74
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 0.9455
    Episode_Reward/rotating_object: 131.5254
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.30s
                      Time elapsed: 00:40:32
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 47016 steps/s (collection: 1.992s, learning 0.099s)
             Mean action noise std: 3.25
          Mean value_function loss: 73.7137
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.2884
                       Mean reward: 737.84
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 0.9788
    Episode_Reward/rotating_object: 139.8881
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.09s
                      Time elapsed: 00:40:34
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 44470 steps/s (collection: 2.013s, learning 0.197s)
             Mean action noise std: 3.25
          Mean value_function loss: 79.2925
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.3018
                       Mean reward: 667.73
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 0.9659
    Episode_Reward/rotating_object: 137.0515
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.21s
                      Time elapsed: 00:40:37
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 45840 steps/s (collection: 1.976s, learning 0.169s)
             Mean action noise std: 3.26
          Mean value_function loss: 79.7355
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.3143
                       Mean reward: 717.82
               Mean episode length: 238.67
    Episode_Reward/reaching_object: 0.9665
    Episode_Reward/rotating_object: 137.7587
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.14s
                      Time elapsed: 00:40:39
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 46714 steps/s (collection: 1.997s, learning 0.107s)
             Mean action noise std: 3.26
          Mean value_function loss: 73.6998
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.3328
                       Mean reward: 679.25
               Mean episode length: 240.46
    Episode_Reward/reaching_object: 0.9840
    Episode_Reward/rotating_object: 138.4216
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.10s
                      Time elapsed: 00:40:41
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 38850 steps/s (collection: 2.376s, learning 0.155s)
             Mean action noise std: 3.26
          Mean value_function loss: 74.4966
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.3531
                       Mean reward: 727.84
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 0.9767
    Episode_Reward/rotating_object: 136.2758
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.53s
                      Time elapsed: 00:40:43
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 38012 steps/s (collection: 2.434s, learning 0.153s)
             Mean action noise std: 3.27
          Mean value_function loss: 80.6042
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.3767
                       Mean reward: 682.80
               Mean episode length: 230.31
    Episode_Reward/reaching_object: 0.9533
    Episode_Reward/rotating_object: 133.0448
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.59s
                      Time elapsed: 00:40:46
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 39394 steps/s (collection: 2.400s, learning 0.096s)
             Mean action noise std: 3.27
          Mean value_function loss: 72.9327
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.3954
                       Mean reward: 704.11
               Mean episode length: 243.95
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 140.8960
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.50s
                      Time elapsed: 00:40:48
                               ETA: 00:17:38

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 43209 steps/s (collection: 2.103s, learning 0.172s)
             Mean action noise std: 3.27
          Mean value_function loss: 78.7555
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.4095
                       Mean reward: 721.39
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 0.9800
    Episode_Reward/rotating_object: 138.2680
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.28s
                      Time elapsed: 00:40:51
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 45971 steps/s (collection: 2.039s, learning 0.100s)
             Mean action noise std: 3.27
          Mean value_function loss: 66.3734
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.4280
                       Mean reward: 718.06
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 0.9652
    Episode_Reward/rotating_object: 138.4410
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.14s
                      Time elapsed: 00:40:53
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 43061 steps/s (collection: 2.125s, learning 0.158s)
             Mean action noise std: 3.27
          Mean value_function loss: 56.5274
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.4416
                       Mean reward: 697.77
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 0.9861
    Episode_Reward/rotating_object: 139.5682
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.28s
                      Time elapsed: 00:40:55
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 43045 steps/s (collection: 2.147s, learning 0.137s)
             Mean action noise std: 3.28
          Mean value_function loss: 79.6545
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.4545
                       Mean reward: 695.58
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 137.3731
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.28s
                      Time elapsed: 00:40:57
                               ETA: 00:17:29

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 45185 steps/s (collection: 2.004s, learning 0.171s)
             Mean action noise std: 3.28
          Mean value_function loss: 69.3916
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.4694
                       Mean reward: 733.88
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 0.9595
    Episode_Reward/rotating_object: 138.3486
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.18s
                      Time elapsed: 00:41:00
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 47448 steps/s (collection: 1.957s, learning 0.115s)
             Mean action noise std: 3.28
          Mean value_function loss: 53.0847
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.4848
                       Mean reward: 683.45
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 138.9450
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.07s
                      Time elapsed: 00:41:02
                               ETA: 00:17:24

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 46911 steps/s (collection: 1.940s, learning 0.156s)
             Mean action noise std: 3.28
          Mean value_function loss: 63.9836
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.5003
                       Mean reward: 690.29
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 0.9586
    Episode_Reward/rotating_object: 136.2161
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.10s
                      Time elapsed: 00:41:04
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 45554 steps/s (collection: 1.992s, learning 0.166s)
             Mean action noise std: 3.29
          Mean value_function loss: 77.6433
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.5132
                       Mean reward: 700.39
               Mean episode length: 235.49
    Episode_Reward/reaching_object: 0.9570
    Episode_Reward/rotating_object: 136.2906
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.16s
                      Time elapsed: 00:41:06
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 45047 steps/s (collection: 2.084s, learning 0.098s)
             Mean action noise std: 3.29
          Mean value_function loss: 65.6616
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.5379
                       Mean reward: 745.25
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 0.9831
    Episode_Reward/rotating_object: 139.8274
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.18s
                      Time elapsed: 00:41:08
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 45039 steps/s (collection: 2.077s, learning 0.106s)
             Mean action noise std: 3.29
          Mean value_function loss: 83.0995
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.5584
                       Mean reward: 663.95
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 0.9577
    Episode_Reward/rotating_object: 136.1246
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.18s
                      Time elapsed: 00:41:10
                               ETA: 00:17:14

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 44877 steps/s (collection: 2.074s, learning 0.117s)
             Mean action noise std: 3.30
          Mean value_function loss: 81.6444
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.5730
                       Mean reward: 692.84
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 0.9458
    Episode_Reward/rotating_object: 135.5260
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.19s
                      Time elapsed: 00:41:13
                               ETA: 00:17:12

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 44363 steps/s (collection: 2.096s, learning 0.120s)
             Mean action noise std: 3.30
          Mean value_function loss: 90.1767
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.5929
                       Mean reward: 696.92
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 0.9536
    Episode_Reward/rotating_object: 137.8923
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.22s
                      Time elapsed: 00:41:15
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 43977 steps/s (collection: 2.033s, learning 0.202s)
             Mean action noise std: 3.30
          Mean value_function loss: 81.0322
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.6163
                       Mean reward: 630.51
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 0.9436
    Episode_Reward/rotating_object: 131.5044
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.24s
                      Time elapsed: 00:41:17
                               ETA: 00:17:07

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 41731 steps/s (collection: 2.251s, learning 0.105s)
             Mean action noise std: 3.31
          Mean value_function loss: 78.0907
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.6408
                       Mean reward: 705.49
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 0.9696
    Episode_Reward/rotating_object: 137.6048
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.36s
                      Time elapsed: 00:41:19
                               ETA: 00:17:05

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 46547 steps/s (collection: 2.016s, learning 0.096s)
             Mean action noise std: 3.31
          Mean value_function loss: 86.8008
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.6675
                       Mean reward: 647.22
               Mean episode length: 222.17
    Episode_Reward/reaching_object: 0.9550
    Episode_Reward/rotating_object: 135.5793
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.11s
                      Time elapsed: 00:41:21
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 42304 steps/s (collection: 2.132s, learning 0.192s)
             Mean action noise std: 3.31
          Mean value_function loss: 74.8376
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.6873
                       Mean reward: 670.37
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 0.9439
    Episode_Reward/rotating_object: 134.9169
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.32s
                      Time elapsed: 00:41:24
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 42536 steps/s (collection: 2.219s, learning 0.092s)
             Mean action noise std: 3.32
          Mean value_function loss: 80.7110
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.7016
                       Mean reward: 697.99
               Mean episode length: 242.63
    Episode_Reward/reaching_object: 0.9635
    Episode_Reward/rotating_object: 136.7217
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.31s
                      Time elapsed: 00:41:26
                               ETA: 00:16:57

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 44683 steps/s (collection: 2.097s, learning 0.103s)
             Mean action noise std: 3.32
          Mean value_function loss: 85.5407
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.7212
                       Mean reward: 735.57
               Mean episode length: 246.78
    Episode_Reward/reaching_object: 0.9459
    Episode_Reward/rotating_object: 133.7260
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.20s
                      Time elapsed: 00:41:28
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 45799 steps/s (collection: 2.043s, learning 0.104s)
             Mean action noise std: 3.32
          Mean value_function loss: 75.8887
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.7423
                       Mean reward: 674.28
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 0.9639
    Episode_Reward/rotating_object: 137.5247
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.15s
                      Time elapsed: 00:41:30
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 45684 steps/s (collection: 2.036s, learning 0.116s)
             Mean action noise std: 3.32
          Mean value_function loss: 79.5824
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.7571
                       Mean reward: 671.32
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 0.9623
    Episode_Reward/rotating_object: 135.1442
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.15s
                      Time elapsed: 00:41:33
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 45538 steps/s (collection: 2.038s, learning 0.121s)
             Mean action noise std: 3.33
          Mean value_function loss: 82.7973
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.7753
                       Mean reward: 693.15
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 0.9755
    Episode_Reward/rotating_object: 140.8536
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.16s
                      Time elapsed: 00:41:35
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 44115 steps/s (collection: 2.106s, learning 0.122s)
             Mean action noise std: 3.33
          Mean value_function loss: 92.9459
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.8002
                       Mean reward: 660.69
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 0.9499
    Episode_Reward/rotating_object: 132.6492
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.23s
                      Time elapsed: 00:41:37
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 47441 steps/s (collection: 1.972s, learning 0.101s)
             Mean action noise std: 3.33
          Mean value_function loss: 87.4945
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.8178
                       Mean reward: 676.11
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 0.9542
    Episode_Reward/rotating_object: 132.7143
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.07s
                      Time elapsed: 00:41:39
                               ETA: 00:16:43

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 46034 steps/s (collection: 2.021s, learning 0.114s)
             Mean action noise std: 3.34
          Mean value_function loss: 91.0661
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.8304
                       Mean reward: 681.03
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 0.9510
    Episode_Reward/rotating_object: 135.6829
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.14s
                      Time elapsed: 00:41:41
                               ETA: 00:16:41

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 46779 steps/s (collection: 2.002s, learning 0.099s)
             Mean action noise std: 3.34
          Mean value_function loss: 76.1440
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.8418
                       Mean reward: 748.46
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.9837
    Episode_Reward/rotating_object: 140.3013
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.10s
                      Time elapsed: 00:41:43
                               ETA: 00:16:38

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 47481 steps/s (collection: 1.974s, learning 0.096s)
             Mean action noise std: 3.34
          Mean value_function loss: 81.9267
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.8593
                       Mean reward: 685.05
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 0.9637
    Episode_Reward/rotating_object: 137.7169
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.07s
                      Time elapsed: 00:41:45
                               ETA: 00:16:36

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 46577 steps/s (collection: 2.003s, learning 0.108s)
             Mean action noise std: 3.34
          Mean value_function loss: 71.8135
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.8803
                       Mean reward: 650.12
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 0.9625
    Episode_Reward/rotating_object: 134.4669
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.11s
                      Time elapsed: 00:41:47
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 46197 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 3.35
          Mean value_function loss: 89.9505
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.8913
                       Mean reward: 672.24
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 0.9598
    Episode_Reward/rotating_object: 134.8498
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.13s
                      Time elapsed: 00:41:50
                               ETA: 00:16:31

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 44752 steps/s (collection: 2.076s, learning 0.121s)
             Mean action noise std: 3.35
          Mean value_function loss: 76.7821
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.9055
                       Mean reward: 678.35
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 0.9595
    Episode_Reward/rotating_object: 134.7357
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.20s
                      Time elapsed: 00:41:52
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 46104 steps/s (collection: 2.000s, learning 0.132s)
             Mean action noise std: 3.35
          Mean value_function loss: 70.6104
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.9236
                       Mean reward: 686.43
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 0.9825
    Episode_Reward/rotating_object: 139.4553
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.13s
                      Time elapsed: 00:41:54
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 46256 steps/s (collection: 2.020s, learning 0.105s)
             Mean action noise std: 3.35
          Mean value_function loss: 72.4464
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.9406
                       Mean reward: 665.71
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 0.9737
    Episode_Reward/rotating_object: 136.9121
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.13s
                      Time elapsed: 00:41:56
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 43811 steps/s (collection: 2.135s, learning 0.109s)
             Mean action noise std: 3.36
          Mean value_function loss: 73.8461
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.9544
                       Mean reward: 665.28
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 0.9641
    Episode_Reward/rotating_object: 135.4566
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.24s
                      Time elapsed: 00:41:58
                               ETA: 00:16:21

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 44574 steps/s (collection: 2.080s, learning 0.125s)
             Mean action noise std: 3.36
          Mean value_function loss: 80.9826
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.9682
                       Mean reward: 680.01
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 0.9563
    Episode_Reward/rotating_object: 134.1233
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.21s
                      Time elapsed: 00:42:00
                               ETA: 00:16:19

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 45453 steps/s (collection: 2.068s, learning 0.095s)
             Mean action noise std: 3.36
          Mean value_function loss: 69.3264
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.9844
                       Mean reward: 678.11
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.9806
    Episode_Reward/rotating_object: 136.7759
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.16s
                      Time elapsed: 00:42:03
                               ETA: 00:16:17

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 47646 steps/s (collection: 1.964s, learning 0.099s)
             Mean action noise std: 3.36
          Mean value_function loss: 89.4114
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.9994
                       Mean reward: 695.71
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 134.5630
        Episode_Reward/action_rate: -0.0597
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.06s
                      Time elapsed: 00:42:05
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 45874 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 3.37
          Mean value_function loss: 69.0566
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.0197
                       Mean reward: 647.29
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.9645
    Episode_Reward/rotating_object: 134.9051
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.14s
                      Time elapsed: 00:42:07
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 47108 steps/s (collection: 1.967s, learning 0.120s)
             Mean action noise std: 3.37
          Mean value_function loss: 71.5781
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.0312
                       Mean reward: 693.79
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 0.9815
    Episode_Reward/rotating_object: 139.8000
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.09s
                      Time elapsed: 00:42:09
                               ETA: 00:16:09

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 47230 steps/s (collection: 1.955s, learning 0.127s)
             Mean action noise std: 3.37
          Mean value_function loss: 68.3399
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.0412
                       Mean reward: 701.00
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 1.0011
    Episode_Reward/rotating_object: 141.1773
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.08s
                      Time elapsed: 00:42:11
                               ETA: 00:16:07

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 46347 steps/s (collection: 1.993s, learning 0.128s)
             Mean action noise std: 3.37
          Mean value_function loss: 78.5708
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.0573
                       Mean reward: 677.93
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 0.9732
    Episode_Reward/rotating_object: 136.3100
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.12s
                      Time elapsed: 00:42:13
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 47184 steps/s (collection: 1.966s, learning 0.117s)
             Mean action noise std: 3.38
          Mean value_function loss: 84.1748
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.0767
                       Mean reward: 694.12
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 138.9807
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.08s
                      Time elapsed: 00:42:15
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 46211 steps/s (collection: 2.014s, learning 0.113s)
             Mean action noise std: 3.38
          Mean value_function loss: 74.5226
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.0941
                       Mean reward: 730.05
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 0.9678
    Episode_Reward/rotating_object: 138.0164
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.13s
                      Time elapsed: 00:42:17
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 44396 steps/s (collection: 2.107s, learning 0.108s)
             Mean action noise std: 3.38
          Mean value_function loss: 82.8433
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.1150
                       Mean reward: 695.48
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 0.9717
    Episode_Reward/rotating_object: 137.8624
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.21s
                      Time elapsed: 00:42:20
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 46095 steps/s (collection: 2.031s, learning 0.102s)
             Mean action noise std: 3.39
          Mean value_function loss: 71.0745
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.1304
                       Mean reward: 731.39
               Mean episode length: 239.14
    Episode_Reward/reaching_object: 0.9873
    Episode_Reward/rotating_object: 138.9665
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.13s
                      Time elapsed: 00:42:22
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 47294 steps/s (collection: 1.972s, learning 0.107s)
             Mean action noise std: 3.39
          Mean value_function loss: 79.4138
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.1476
                       Mean reward: 686.57
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 0.9595
    Episode_Reward/rotating_object: 134.7350
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.08s
                      Time elapsed: 00:42:24
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 47369 steps/s (collection: 1.965s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 104.5293
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.1681
                       Mean reward: 628.88
               Mean episode length: 221.65
    Episode_Reward/reaching_object: 0.9619
    Episode_Reward/rotating_object: 134.0817
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.08s
                      Time elapsed: 00:42:26
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 46932 steps/s (collection: 1.982s, learning 0.113s)
             Mean action noise std: 3.39
          Mean value_function loss: 73.4987
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.1896
                       Mean reward: 678.59
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 0.9795
    Episode_Reward/rotating_object: 137.1270
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.09s
                      Time elapsed: 00:42:28
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 47287 steps/s (collection: 1.974s, learning 0.105s)
             Mean action noise std: 3.40
          Mean value_function loss: 74.9516
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.2114
                       Mean reward: 701.75
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 0.9767
    Episode_Reward/rotating_object: 137.6827
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.08s
                      Time elapsed: 00:42:30
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 46786 steps/s (collection: 1.994s, learning 0.107s)
             Mean action noise std: 3.40
          Mean value_function loss: 70.2674
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.2316
                       Mean reward: 709.55
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 0.9603
    Episode_Reward/rotating_object: 135.6698
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.10s
                      Time elapsed: 00:42:32
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 47475 steps/s (collection: 1.962s, learning 0.109s)
             Mean action noise std: 3.40
          Mean value_function loss: 69.4455
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.2495
                       Mean reward: 692.95
               Mean episode length: 238.30
    Episode_Reward/reaching_object: 0.9891
    Episode_Reward/rotating_object: 140.4204
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.07s
                      Time elapsed: 00:42:34
                               ETA: 00:15:40

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 48475 steps/s (collection: 1.926s, learning 0.102s)
             Mean action noise std: 3.41
          Mean value_function loss: 75.4698
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.2737
                       Mean reward: 658.00
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 0.9742
    Episode_Reward/rotating_object: 138.0832
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.03s
                      Time elapsed: 00:42:36
                               ETA: 00:15:38

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 47072 steps/s (collection: 1.975s, learning 0.113s)
             Mean action noise std: 3.41
          Mean value_function loss: 65.8040
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.2929
                       Mean reward: 726.66
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.9725
    Episode_Reward/rotating_object: 137.7660
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.09s
                      Time elapsed: 00:42:38
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 46047 steps/s (collection: 2.027s, learning 0.108s)
             Mean action noise std: 3.41
          Mean value_function loss: 70.6190
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 57.3063
                       Mean reward: 659.26
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.9687
    Episode_Reward/rotating_object: 137.3023
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.13s
                      Time elapsed: 00:42:40
                               ETA: 00:15:33

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 46913 steps/s (collection: 2.005s, learning 0.090s)
             Mean action noise std: 3.41
          Mean value_function loss: 71.2086
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 57.3105
                       Mean reward: 714.77
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 0.9740
    Episode_Reward/rotating_object: 139.7978
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.10s
                      Time elapsed: 00:42:43
                               ETA: 00:15:31

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 47112 steps/s (collection: 1.981s, learning 0.106s)
             Mean action noise std: 3.41
          Mean value_function loss: 78.9238
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.3162
                       Mean reward: 644.75
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 0.9644
    Episode_Reward/rotating_object: 135.1714
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.09s
                      Time elapsed: 00:42:45
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 45646 steps/s (collection: 2.039s, learning 0.115s)
             Mean action noise std: 3.42
          Mean value_function loss: 66.3263
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.3258
                       Mean reward: 703.08
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.9744
    Episode_Reward/rotating_object: 137.1750
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.15s
                      Time elapsed: 00:42:47
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 44423 steps/s (collection: 2.102s, learning 0.111s)
             Mean action noise std: 3.42
          Mean value_function loss: 96.6273
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.3351
                       Mean reward: 685.78
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 0.9550
    Episode_Reward/rotating_object: 134.8698
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.21s
                      Time elapsed: 00:42:49
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 46632 steps/s (collection: 1.991s, learning 0.117s)
             Mean action noise std: 3.42
          Mean value_function loss: 78.1046
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.3449
                       Mean reward: 671.77
               Mean episode length: 228.05
    Episode_Reward/reaching_object: 0.9601
    Episode_Reward/rotating_object: 135.0827
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.11s
                      Time elapsed: 00:42:51
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 47724 steps/s (collection: 1.948s, learning 0.112s)
             Mean action noise std: 3.42
          Mean value_function loss: 72.3460
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.3574
                       Mean reward: 667.06
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 0.9610
    Episode_Reward/rotating_object: 133.5697
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.06s
                      Time elapsed: 00:42:53
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 48434 steps/s (collection: 1.923s, learning 0.106s)
             Mean action noise std: 3.42
          Mean value_function loss: 85.2707
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.3697
                       Mean reward: 690.43
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 0.9581
    Episode_Reward/rotating_object: 135.1485
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.03s
                      Time elapsed: 00:42:55
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 46121 steps/s (collection: 2.027s, learning 0.105s)
             Mean action noise std: 3.43
          Mean value_function loss: 86.8418
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.3880
                       Mean reward: 688.14
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 0.9364
    Episode_Reward/rotating_object: 131.0017
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.13s
                      Time elapsed: 00:42:57
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 46942 steps/s (collection: 1.970s, learning 0.125s)
             Mean action noise std: 3.43
          Mean value_function loss: 69.6167
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.4053
                       Mean reward: 705.22
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 0.9606
    Episode_Reward/rotating_object: 138.4702
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.09s
                      Time elapsed: 00:42:59
                               ETA: 00:15:11

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 45163 steps/s (collection: 2.056s, learning 0.121s)
             Mean action noise std: 3.43
          Mean value_function loss: 69.1949
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.4178
                       Mean reward: 649.86
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 0.9712
    Episode_Reward/rotating_object: 135.7347
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.18s
                      Time elapsed: 00:43:02
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 47006 steps/s (collection: 1.985s, learning 0.106s)
             Mean action noise std: 3.43
          Mean value_function loss: 83.0038
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.4357
                       Mean reward: 699.74
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 0.9812
    Episode_Reward/rotating_object: 137.7549
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.09s
                      Time elapsed: 00:43:04
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 47560 steps/s (collection: 1.956s, learning 0.111s)
             Mean action noise std: 3.44
          Mean value_function loss: 72.9053
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.4513
                       Mean reward: 701.08
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 0.9717
    Episode_Reward/rotating_object: 138.0469
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.07s
                      Time elapsed: 00:43:06
                               ETA: 00:15:04

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 47297 steps/s (collection: 1.972s, learning 0.107s)
             Mean action noise std: 3.44
          Mean value_function loss: 71.5248
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.4627
                       Mean reward: 701.55
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 0.9712
    Episode_Reward/rotating_object: 135.8730
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.08s
                      Time elapsed: 00:43:08
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 47744 steps/s (collection: 1.962s, learning 0.097s)
             Mean action noise std: 3.44
          Mean value_function loss: 76.2823
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.4737
                       Mean reward: 661.46
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 0.9790
    Episode_Reward/rotating_object: 137.2902
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.06s
                      Time elapsed: 00:43:10
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 47042 steps/s (collection: 1.977s, learning 0.113s)
             Mean action noise std: 3.44
          Mean value_function loss: 93.6222
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.4866
                       Mean reward: 672.62
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 0.9596
    Episode_Reward/rotating_object: 133.9782
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.09s
                      Time elapsed: 00:43:12
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 46778 steps/s (collection: 1.990s, learning 0.111s)
             Mean action noise std: 3.45
          Mean value_function loss: 79.2437
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.5061
                       Mean reward: 708.33
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 0.9743
    Episode_Reward/rotating_object: 138.0099
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.10s
                      Time elapsed: 00:43:14
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 47072 steps/s (collection: 1.960s, learning 0.129s)
             Mean action noise std: 3.45
          Mean value_function loss: 64.5615
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.5220
                       Mean reward: 759.01
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.9670
    Episode_Reward/rotating_object: 137.8431
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.09s
                      Time elapsed: 00:43:16
                               ETA: 00:14:52

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 47038 steps/s (collection: 1.963s, learning 0.127s)
             Mean action noise std: 3.45
          Mean value_function loss: 67.8334
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.5377
                       Mean reward: 704.59
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 0.9759
    Episode_Reward/rotating_object: 138.1893
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.09s
                      Time elapsed: 00:43:18
                               ETA: 00:14:50

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 47619 steps/s (collection: 1.960s, learning 0.104s)
             Mean action noise std: 3.46
          Mean value_function loss: 64.5784
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.5554
                       Mean reward: 733.52
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.9837
    Episode_Reward/rotating_object: 142.6912
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.06s
                      Time elapsed: 00:43:20
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 47550 steps/s (collection: 1.947s, learning 0.121s)
             Mean action noise std: 3.46
          Mean value_function loss: 73.8149
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.5747
                       Mean reward: 716.14
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 0.9657
    Episode_Reward/rotating_object: 135.0729
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.07s
                      Time elapsed: 00:43:22
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 45261 steps/s (collection: 2.056s, learning 0.116s)
             Mean action noise std: 3.46
          Mean value_function loss: 66.7588
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 57.5900
                       Mean reward: 733.98
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.9761
    Episode_Reward/rotating_object: 141.5385
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.17s
                      Time elapsed: 00:43:25
                               ETA: 00:14:43

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 46296 steps/s (collection: 2.016s, learning 0.107s)
             Mean action noise std: 3.47
          Mean value_function loss: 79.6389
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.6109
                       Mean reward: 673.15
               Mean episode length: 236.36
    Episode_Reward/reaching_object: 0.9689
    Episode_Reward/rotating_object: 134.0315
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.12s
                      Time elapsed: 00:43:27
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 46184 steps/s (collection: 2.014s, learning 0.114s)
             Mean action noise std: 3.47
          Mean value_function loss: 73.8549
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.6306
                       Mean reward: 715.82
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 0.9736
    Episode_Reward/rotating_object: 139.6452
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.13s
                      Time elapsed: 00:43:29
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 46252 steps/s (collection: 2.008s, learning 0.117s)
             Mean action noise std: 3.47
          Mean value_function loss: 88.0874
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.6472
                       Mean reward: 669.99
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.9624
    Episode_Reward/rotating_object: 135.5187
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.13s
                      Time elapsed: 00:43:31
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 43241 steps/s (collection: 2.160s, learning 0.113s)
             Mean action noise std: 3.47
          Mean value_function loss: 74.0059
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.6607
                       Mean reward: 668.67
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 0.9742
    Episode_Reward/rotating_object: 137.5083
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.27s
                      Time elapsed: 00:43:33
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 46006 steps/s (collection: 2.021s, learning 0.116s)
             Mean action noise std: 3.47
          Mean value_function loss: 65.5526
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.6715
                       Mean reward: 692.83
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 0.9774
    Episode_Reward/rotating_object: 137.5735
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.14s
                      Time elapsed: 00:43:35
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 44680 steps/s (collection: 2.086s, learning 0.114s)
             Mean action noise std: 3.48
          Mean value_function loss: 81.1803
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.6801
                       Mean reward: 698.31
               Mean episode length: 240.52
    Episode_Reward/reaching_object: 0.9744
    Episode_Reward/rotating_object: 137.2381
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.20s
                      Time elapsed: 00:43:38
                               ETA: 00:14:28

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 45761 steps/s (collection: 2.034s, learning 0.115s)
             Mean action noise std: 3.48
          Mean value_function loss: 65.1659
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.6911
                       Mean reward: 678.11
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 0.9714
    Episode_Reward/rotating_object: 138.3391
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.15s
                      Time elapsed: 00:43:40
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 44339 steps/s (collection: 2.116s, learning 0.102s)
             Mean action noise std: 3.48
          Mean value_function loss: 74.4220
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.7074
                       Mean reward: 665.67
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 0.9397
    Episode_Reward/rotating_object: 131.7758
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.22s
                      Time elapsed: 00:43:42
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 47547 steps/s (collection: 1.967s, learning 0.100s)
             Mean action noise std: 3.49
          Mean value_function loss: 72.4421
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.7261
                       Mean reward: 699.97
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 0.9723
    Episode_Reward/rotating_object: 139.1118
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.07s
                      Time elapsed: 00:43:44
                               ETA: 00:14:21

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 46179 steps/s (collection: 2.032s, learning 0.097s)
             Mean action noise std: 3.49
          Mean value_function loss: 84.2416
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.7456
                       Mean reward: 688.39
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 0.9593
    Episode_Reward/rotating_object: 137.6581
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.13s
                      Time elapsed: 00:43:46
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 46492 steps/s (collection: 2.008s, learning 0.107s)
             Mean action noise std: 3.49
          Mean value_function loss: 84.6715
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.7534
                       Mean reward: 691.03
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 138.4544
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.11s
                      Time elapsed: 00:43:48
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 46064 steps/s (collection: 2.009s, learning 0.125s)
             Mean action noise std: 3.49
          Mean value_function loss: 70.0674
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.7613
                       Mean reward: 681.07
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 0.9645
    Episode_Reward/rotating_object: 138.4435
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.13s
                      Time elapsed: 00:43:50
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 47704 steps/s (collection: 1.959s, learning 0.102s)
             Mean action noise std: 3.49
          Mean value_function loss: 73.7843
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.7677
                       Mean reward: 678.04
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 0.9810
    Episode_Reward/rotating_object: 138.2397
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.06s
                      Time elapsed: 00:43:52
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 47967 steps/s (collection: 1.939s, learning 0.110s)
             Mean action noise std: 3.49
          Mean value_function loss: 82.1724
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.7779
                       Mean reward: 656.37
               Mean episode length: 224.27
    Episode_Reward/reaching_object: 0.9409
    Episode_Reward/rotating_object: 134.8987
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.05s
                      Time elapsed: 00:43:54
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 46450 steps/s (collection: 1.996s, learning 0.120s)
             Mean action noise std: 3.50
          Mean value_function loss: 84.9398
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.7935
                       Mean reward: 672.14
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 0.9683
    Episode_Reward/rotating_object: 137.7833
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.12s
                      Time elapsed: 00:43:57
                               ETA: 00:14:07

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 47242 steps/s (collection: 1.967s, learning 0.114s)
             Mean action noise std: 3.50
          Mean value_function loss: 67.4597
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.8037
                       Mean reward: 676.66
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 0.9645
    Episode_Reward/rotating_object: 138.5170
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.08s
                      Time elapsed: 00:43:59
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 42661 steps/s (collection: 2.179s, learning 0.125s)
             Mean action noise std: 3.50
          Mean value_function loss: 78.0284
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 57.8205
                       Mean reward: 686.24
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 0.9528
    Episode_Reward/rotating_object: 136.1151
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.30s
                      Time elapsed: 00:44:01
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 46549 steps/s (collection: 2.001s, learning 0.111s)
             Mean action noise std: 3.50
          Mean value_function loss: 73.8546
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.8382
                       Mean reward: 702.39
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 0.9874
    Episode_Reward/rotating_object: 139.3649
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.11s
                      Time elapsed: 00:44:03
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 47768 steps/s (collection: 1.943s, learning 0.115s)
             Mean action noise std: 3.51
          Mean value_function loss: 73.3867
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.8548
                       Mean reward: 715.06
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 0.9789
    Episode_Reward/rotating_object: 138.4491
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.06s
                      Time elapsed: 00:44:05
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 47475 steps/s (collection: 1.963s, learning 0.108s)
             Mean action noise std: 3.51
          Mean value_function loss: 59.2637
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.8629
                       Mean reward: 686.35
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 0.9532
    Episode_Reward/rotating_object: 137.3141
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.07s
                      Time elapsed: 00:44:07
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 47392 steps/s (collection: 1.960s, learning 0.114s)
             Mean action noise std: 3.51
          Mean value_function loss: 78.2544
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.8703
                       Mean reward: 706.80
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 0.9809
    Episode_Reward/rotating_object: 138.4039
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.07s
                      Time elapsed: 00:44:09
                               ETA: 00:13:52

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 47412 steps/s (collection: 1.962s, learning 0.112s)
             Mean action noise std: 3.51
          Mean value_function loss: 72.4864
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.8845
                       Mean reward: 705.67
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 0.9520
    Episode_Reward/rotating_object: 136.9903
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.07s
                      Time elapsed: 00:44:11
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 46828 steps/s (collection: 1.979s, learning 0.120s)
             Mean action noise std: 3.52
          Mean value_function loss: 77.3031
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.9027
                       Mean reward: 659.20
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 0.9558
    Episode_Reward/rotating_object: 138.1492
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.10s
                      Time elapsed: 00:44:13
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 47230 steps/s (collection: 1.973s, learning 0.108s)
             Mean action noise std: 3.52
          Mean value_function loss: 81.1462
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.9219
                       Mean reward: 697.54
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 0.9738
    Episode_Reward/rotating_object: 139.2030
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.08s
                      Time elapsed: 00:44:16
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 47849 steps/s (collection: 1.928s, learning 0.127s)
             Mean action noise std: 3.52
          Mean value_function loss: 72.7642
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.9348
                       Mean reward: 729.01
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.9667
    Episode_Reward/rotating_object: 137.7712
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.05s
                      Time elapsed: 00:44:18
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 46840 steps/s (collection: 1.974s, learning 0.125s)
             Mean action noise std: 3.52
          Mean value_function loss: 87.6590
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.9510
                       Mean reward: 669.34
               Mean episode length: 232.05
    Episode_Reward/reaching_object: 0.9488
    Episode_Reward/rotating_object: 131.9053
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.10s
                      Time elapsed: 00:44:20
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 46814 steps/s (collection: 1.989s, learning 0.111s)
             Mean action noise std: 3.53
          Mean value_function loss: 75.2897
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.9704
                       Mean reward: 703.23
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 0.9464
    Episode_Reward/rotating_object: 137.9725
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.10s
                      Time elapsed: 00:44:22
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 47791 steps/s (collection: 1.964s, learning 0.093s)
             Mean action noise std: 3.53
          Mean value_function loss: 79.9593
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.9891
                       Mean reward: 659.03
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 0.9426
    Episode_Reward/rotating_object: 131.8633
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.06s
                      Time elapsed: 00:44:24
                               ETA: 00:13:36

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 46777 steps/s (collection: 1.999s, learning 0.102s)
             Mean action noise std: 3.53
          Mean value_function loss: 73.9915
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.0042
                       Mean reward: 700.87
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 0.9546
    Episode_Reward/rotating_object: 136.0302
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.10s
                      Time elapsed: 00:44:26
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 48409 steps/s (collection: 1.936s, learning 0.095s)
             Mean action noise std: 3.54
          Mean value_function loss: 65.7247
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.0284
                       Mean reward: 700.96
               Mean episode length: 237.39
    Episode_Reward/reaching_object: 0.9676
    Episode_Reward/rotating_object: 140.3738
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.03s
                      Time elapsed: 00:44:28
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 47459 steps/s (collection: 1.969s, learning 0.102s)
             Mean action noise std: 3.54
          Mean value_function loss: 76.9540
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.0446
                       Mean reward: 712.49
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.9608
    Episode_Reward/rotating_object: 139.2559
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.07s
                      Time elapsed: 00:44:30
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 47567 steps/s (collection: 1.974s, learning 0.093s)
             Mean action noise std: 3.54
          Mean value_function loss: 84.2290
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.0531
                       Mean reward: 657.98
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 0.9546
    Episode_Reward/rotating_object: 136.2060
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.07s
                      Time elapsed: 00:44:32
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 45998 steps/s (collection: 2.034s, learning 0.103s)
             Mean action noise std: 3.54
          Mean value_function loss: 80.2894
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.0650
                       Mean reward: 677.32
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 0.9535
    Episode_Reward/rotating_object: 135.5476
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.14s
                      Time elapsed: 00:44:34
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 46220 steps/s (collection: 2.014s, learning 0.113s)
             Mean action noise std: 3.54
          Mean value_function loss: 100.9895
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.0828
                       Mean reward: 681.26
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 0.9483
    Episode_Reward/rotating_object: 137.6108
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.13s
                      Time elapsed: 00:44:36
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 46910 steps/s (collection: 1.978s, learning 0.117s)
             Mean action noise std: 3.55
          Mean value_function loss: 83.2628
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.1011
                       Mean reward: 664.80
               Mean episode length: 228.30
    Episode_Reward/reaching_object: 0.9491
    Episode_Reward/rotating_object: 134.7651
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.10s
                      Time elapsed: 00:44:38
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 46640 steps/s (collection: 1.989s, learning 0.119s)
             Mean action noise std: 3.55
          Mean value_function loss: 86.4144
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.1205
                       Mean reward: 658.85
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 0.9493
    Episode_Reward/rotating_object: 133.5989
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.11s
                      Time elapsed: 00:44:41
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 43255 steps/s (collection: 2.154s, learning 0.119s)
             Mean action noise std: 3.55
          Mean value_function loss: 86.9086
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.1374
                       Mean reward: 731.85
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 0.9614
    Episode_Reward/rotating_object: 139.6150
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.27s
                      Time elapsed: 00:44:43
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 47178 steps/s (collection: 1.976s, learning 0.107s)
             Mean action noise std: 3.55
          Mean value_function loss: 83.2514
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.1484
                       Mean reward: 669.91
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 0.9596
    Episode_Reward/rotating_object: 137.5991
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.08s
                      Time elapsed: 00:44:45
                               ETA: 00:13:12

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 45468 steps/s (collection: 2.049s, learning 0.113s)
             Mean action noise std: 3.56
          Mean value_function loss: 85.0004
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.1618
                       Mean reward: 703.99
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 0.9478
    Episode_Reward/rotating_object: 132.5199
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.16s
                      Time elapsed: 00:44:47
                               ETA: 00:13:10

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 45212 steps/s (collection: 2.058s, learning 0.116s)
             Mean action noise std: 3.56
          Mean value_function loss: 90.1804
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.1814
                       Mean reward: 701.98
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 0.9419
    Episode_Reward/rotating_object: 131.6631
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.17s
                      Time elapsed: 00:44:49
                               ETA: 00:13:07

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 41222 steps/s (collection: 2.171s, learning 0.213s)
             Mean action noise std: 3.56
          Mean value_function loss: 64.9526
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.2029
                       Mean reward: 687.51
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 0.9567
    Episode_Reward/rotating_object: 135.2868
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.38s
                      Time elapsed: 00:44:52
                               ETA: 00:13:05

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 39334 steps/s (collection: 2.321s, learning 0.179s)
             Mean action noise std: 3.57
          Mean value_function loss: 72.7500
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.2186
                       Mean reward: 673.04
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 0.9705
    Episode_Reward/rotating_object: 138.1599
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.50s
                      Time elapsed: 00:44:54
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 40908 steps/s (collection: 2.252s, learning 0.151s)
             Mean action noise std: 3.57
          Mean value_function loss: 77.8789
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.2309
                       Mean reward: 680.25
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 0.9562
    Episode_Reward/rotating_object: 139.5987
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.40s
                      Time elapsed: 00:44:57
                               ETA: 00:13:00

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 44610 steps/s (collection: 2.047s, learning 0.157s)
             Mean action noise std: 3.57
          Mean value_function loss: 76.4867
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.2471
                       Mean reward: 667.41
               Mean episode length: 228.56
    Episode_Reward/reaching_object: 0.9580
    Episode_Reward/rotating_object: 138.0364
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.20s
                      Time elapsed: 00:44:59
                               ETA: 00:12:58

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 46985 steps/s (collection: 1.989s, learning 0.103s)
             Mean action noise std: 3.58
          Mean value_function loss: 80.8862
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.2670
                       Mean reward: 676.39
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 0.9590
    Episode_Reward/rotating_object: 137.5832
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.09s
                      Time elapsed: 00:45:01
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 47005 steps/s (collection: 1.999s, learning 0.093s)
             Mean action noise std: 3.58
          Mean value_function loss: 84.5068
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.2848
                       Mean reward: 685.93
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 0.9503
    Episode_Reward/rotating_object: 134.6224
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.09s
                      Time elapsed: 00:45:03
                               ETA: 00:12:53

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 46253 steps/s (collection: 2.027s, learning 0.099s)
             Mean action noise std: 3.58
          Mean value_function loss: 84.6493
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.3078
                       Mean reward: 695.37
               Mean episode length: 229.64
    Episode_Reward/reaching_object: 0.9559
    Episode_Reward/rotating_object: 135.7697
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.13s
                      Time elapsed: 00:45:05
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 46647 steps/s (collection: 1.995s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 76.3314
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.3233
                       Mean reward: 694.95
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 0.9695
    Episode_Reward/rotating_object: 137.6275
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.11s
                      Time elapsed: 00:45:07
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 45397 steps/s (collection: 2.073s, learning 0.092s)
             Mean action noise std: 3.59
          Mean value_function loss: 67.4567
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.3377
                       Mean reward: 669.92
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 0.9436
    Episode_Reward/rotating_object: 133.4104
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.17s
                      Time elapsed: 00:45:09
                               ETA: 00:12:46

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 48124 steps/s (collection: 1.946s, learning 0.097s)
             Mean action noise std: 3.59
          Mean value_function loss: 73.2346
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.3548
                       Mean reward: 674.45
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 0.9605
    Episode_Reward/rotating_object: 138.6082
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.04s
                      Time elapsed: 00:45:11
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 47331 steps/s (collection: 1.961s, learning 0.116s)
             Mean action noise std: 3.59
          Mean value_function loss: 76.5520
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.3735
                       Mean reward: 702.93
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 0.9479
    Episode_Reward/rotating_object: 136.4668
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.08s
                      Time elapsed: 00:45:13
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 42711 steps/s (collection: 2.109s, learning 0.192s)
             Mean action noise std: 3.60
          Mean value_function loss: 79.8288
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.3862
                       Mean reward: 648.97
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.9589
    Episode_Reward/rotating_object: 138.6410
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.30s
                      Time elapsed: 00:45:16
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 44249 steps/s (collection: 2.078s, learning 0.144s)
             Mean action noise std: 3.60
          Mean value_function loss: 68.9187
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.4048
                       Mean reward: 679.76
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 0.9322
    Episode_Reward/rotating_object: 137.3169
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.22s
                      Time elapsed: 00:45:18
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 44599 steps/s (collection: 2.108s, learning 0.097s)
             Mean action noise std: 3.60
          Mean value_function loss: 67.2508
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.4254
                       Mean reward: 714.33
               Mean episode length: 239.75
    Episode_Reward/reaching_object: 0.9436
    Episode_Reward/rotating_object: 138.6277
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.20s
                      Time elapsed: 00:45:20
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 45826 steps/s (collection: 2.048s, learning 0.098s)
             Mean action noise std: 3.60
          Mean value_function loss: 75.9081
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.4415
                       Mean reward: 718.22
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 0.9458
    Episode_Reward/rotating_object: 137.5581
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.15s
                      Time elapsed: 00:45:22
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 45191 steps/s (collection: 2.007s, learning 0.168s)
             Mean action noise std: 3.61
          Mean value_function loss: 80.5103
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 58.4572
                       Mean reward: 722.77
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 0.9546
    Episode_Reward/rotating_object: 140.5645
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.18s
                      Time elapsed: 00:45:25
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 43859 steps/s (collection: 2.090s, learning 0.152s)
             Mean action noise std: 3.61
          Mean value_function loss: 84.6395
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.4718
                       Mean reward: 725.08
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.9379
    Episode_Reward/rotating_object: 137.8274
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.24s
                      Time elapsed: 00:45:27
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 43788 steps/s (collection: 2.149s, learning 0.096s)
             Mean action noise std: 3.61
          Mean value_function loss: 82.6797
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.4916
                       Mean reward: 631.60
               Mean episode length: 220.98
    Episode_Reward/reaching_object: 0.9240
    Episode_Reward/rotating_object: 137.2901
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.24s
                      Time elapsed: 00:45:29
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 42349 steps/s (collection: 2.096s, learning 0.225s)
             Mean action noise std: 3.62
          Mean value_function loss: 76.7915
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.5161
                       Mean reward: 734.96
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 0.9306
    Episode_Reward/rotating_object: 135.7642
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.32s
                      Time elapsed: 00:45:31
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 44418 steps/s (collection: 2.121s, learning 0.092s)
             Mean action noise std: 3.62
          Mean value_function loss: 81.4626
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.5332
                       Mean reward: 664.18
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 0.9418
    Episode_Reward/rotating_object: 134.5324
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.21s
                      Time elapsed: 00:45:34
                               ETA: 00:12:20

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 42350 steps/s (collection: 2.159s, learning 0.162s)
             Mean action noise std: 3.62
          Mean value_function loss: 82.5721
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.5513
                       Mean reward: 687.26
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 0.9352
    Episode_Reward/rotating_object: 136.9452
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.32s
                      Time elapsed: 00:45:36
                               ETA: 00:12:18

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 45294 steps/s (collection: 2.065s, learning 0.105s)
             Mean action noise std: 3.62
          Mean value_function loss: 83.6614
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.5700
                       Mean reward: 682.64
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 0.9363
    Episode_Reward/rotating_object: 135.1876
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.17s
                      Time elapsed: 00:45:38
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 42738 steps/s (collection: 2.139s, learning 0.161s)
             Mean action noise std: 3.63
          Mean value_function loss: 79.2797
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.5863
                       Mean reward: 725.16
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 0.9461
    Episode_Reward/rotating_object: 138.8925
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.30s
                      Time elapsed: 00:45:40
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 42705 steps/s (collection: 2.209s, learning 0.093s)
             Mean action noise std: 3.63
          Mean value_function loss: 83.9980
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.6011
                       Mean reward: 714.52
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 0.9408
    Episode_Reward/rotating_object: 137.1061
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.30s
                      Time elapsed: 00:45:43
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 46005 steps/s (collection: 2.032s, learning 0.105s)
             Mean action noise std: 3.63
          Mean value_function loss: 69.6277
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.6136
                       Mean reward: 670.93
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 0.9354
    Episode_Reward/rotating_object: 134.7192
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.14s
                      Time elapsed: 00:45:45
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 45752 steps/s (collection: 2.041s, learning 0.108s)
             Mean action noise std: 3.64
          Mean value_function loss: 83.6198
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.6284
                       Mean reward: 653.59
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 0.9380
    Episode_Reward/rotating_object: 136.6668
        Episode_Reward/action_rate: -0.0707
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.15s
                      Time elapsed: 00:45:47
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 45195 steps/s (collection: 2.079s, learning 0.096s)
             Mean action noise std: 3.64
          Mean value_function loss: 83.8268
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.6467
                       Mean reward: 705.53
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 0.9557
    Episode_Reward/rotating_object: 141.0985
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.18s
                      Time elapsed: 00:45:49
                               ETA: 00:12:04

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 45005 steps/s (collection: 2.084s, learning 0.101s)
             Mean action noise std: 3.64
          Mean value_function loss: 82.4734
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 58.6637
                       Mean reward: 694.11
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 0.9516
    Episode_Reward/rotating_object: 139.4381
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.18s
                      Time elapsed: 00:45:51
                               ETA: 00:12:02

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 43928 steps/s (collection: 2.133s, learning 0.105s)
             Mean action noise std: 3.64
          Mean value_function loss: 102.3024
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.6707
                       Mean reward: 692.13
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 0.9410
    Episode_Reward/rotating_object: 134.1548
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.24s
                      Time elapsed: 00:45:54
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 46581 steps/s (collection: 2.017s, learning 0.094s)
             Mean action noise std: 3.65
          Mean value_function loss: 90.4874
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.6869
                       Mean reward: 610.44
               Mean episode length: 220.44
    Episode_Reward/reaching_object: 0.9207
    Episode_Reward/rotating_object: 131.0799
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.11s
                      Time elapsed: 00:45:56
                               ETA: 00:11:57

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 37052 steps/s (collection: 2.381s, learning 0.272s)
             Mean action noise std: 3.65
          Mean value_function loss: 93.4852
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.7093
                       Mean reward: 678.49
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 0.9240
    Episode_Reward/rotating_object: 133.2597
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.65s
                      Time elapsed: 00:45:58
                               ETA: 00:11:55

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 41910 steps/s (collection: 2.244s, learning 0.101s)
             Mean action noise std: 3.65
          Mean value_function loss: 92.5148
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.7226
                       Mean reward: 658.27
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 0.9189
    Episode_Reward/rotating_object: 131.1758
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.35s
                      Time elapsed: 00:46:01
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 46542 steps/s (collection: 2.000s, learning 0.113s)
             Mean action noise std: 3.65
          Mean value_function loss: 102.6820
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.7398
                       Mean reward: 663.76
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 0.9366
    Episode_Reward/rotating_object: 133.1306
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.11s
                      Time elapsed: 00:46:03
                               ETA: 00:11:50

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 47757 steps/s (collection: 1.933s, learning 0.125s)
             Mean action noise std: 3.66
          Mean value_function loss: 82.3401
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.7604
                       Mean reward: 665.59
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 0.9282
    Episode_Reward/rotating_object: 131.7995
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.06s
                      Time elapsed: 00:46:05
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 46163 steps/s (collection: 2.031s, learning 0.099s)
             Mean action noise std: 3.66
          Mean value_function loss: 92.1063
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.7755
                       Mean reward: 662.54
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 0.9326
    Episode_Reward/rotating_object: 133.3528
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.13s
                      Time elapsed: 00:46:07
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 46805 steps/s (collection: 1.988s, learning 0.113s)
             Mean action noise std: 3.66
          Mean value_function loss: 98.5240
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.7901
                       Mean reward: 663.73
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 0.9282
    Episode_Reward/rotating_object: 133.6977
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.10s
                      Time elapsed: 00:46:09
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 45969 steps/s (collection: 2.027s, learning 0.112s)
             Mean action noise std: 3.66
          Mean value_function loss: 100.9230
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.8012
                       Mean reward: 669.07
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 0.9421
    Episode_Reward/rotating_object: 134.1536
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.14s
                      Time elapsed: 00:46:11
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 47181 steps/s (collection: 1.969s, learning 0.115s)
             Mean action noise std: 3.67
          Mean value_function loss: 87.6362
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.8172
                       Mean reward: 673.19
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 0.9351
    Episode_Reward/rotating_object: 135.0579
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.08s
                      Time elapsed: 00:46:13
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 23170 steps/s (collection: 3.676s, learning 0.567s)
             Mean action noise std: 3.67
          Mean value_function loss: 91.8954
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.8296
                       Mean reward: 682.59
               Mean episode length: 225.28
    Episode_Reward/reaching_object: 0.9268
    Episode_Reward/rotating_object: 135.9155
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 4.24s
                      Time elapsed: 00:46:17
                               ETA: 00:11:36

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 18051 steps/s (collection: 5.083s, learning 0.362s)
             Mean action noise std: 3.67
          Mean value_function loss: 85.5705
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.8445
                       Mean reward: 698.34
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 0.9435
    Episode_Reward/rotating_object: 134.5566
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 5.45s
                      Time elapsed: 00:46:23
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 16428 steps/s (collection: 5.535s, learning 0.448s)
             Mean action noise std: 3.68
          Mean value_function loss: 101.1524
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.8679
                       Mean reward: 664.07
               Mean episode length: 225.73
    Episode_Reward/reaching_object: 0.9130
    Episode_Reward/rotating_object: 132.5372
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 5.98s
                      Time elapsed: 00:46:29
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 15659 steps/s (collection: 5.749s, learning 0.529s)
             Mean action noise std: 3.68
          Mean value_function loss: 104.2589
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.8861
                       Mean reward: 669.20
               Mean episode length: 230.80
    Episode_Reward/reaching_object: 0.9168
    Episode_Reward/rotating_object: 133.7575
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 6.28s
                      Time elapsed: 00:46:35
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 15400 steps/s (collection: 5.844s, learning 0.539s)
             Mean action noise std: 3.68
          Mean value_function loss: 90.9538
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.9054
                       Mean reward: 647.55
               Mean episode length: 226.65
    Episode_Reward/reaching_object: 0.9282
    Episode_Reward/rotating_object: 131.6072
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 6.38s
                      Time elapsed: 00:46:42
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 15101 steps/s (collection: 6.011s, learning 0.498s)
             Mean action noise std: 3.68
          Mean value_function loss: 97.2171
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.9243
                       Mean reward: 678.84
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 0.9250
    Episode_Reward/rotating_object: 134.7560
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 6.51s
                      Time elapsed: 00:46:48
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 16201 steps/s (collection: 5.628s, learning 0.439s)
             Mean action noise std: 3.69
          Mean value_function loss: 99.0130
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.9419
                       Mean reward: 664.52
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 0.9092
    Episode_Reward/rotating_object: 130.0226
        Episode_Reward/action_rate: -0.0707
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 6.07s
                      Time elapsed: 00:46:54
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 17780 steps/s (collection: 5.113s, learning 0.416s)
             Mean action noise std: 3.69
          Mean value_function loss: 96.0049
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.9623
                       Mean reward: 636.05
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 0.9244
    Episode_Reward/rotating_object: 133.3484
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 5.53s
                      Time elapsed: 00:47:00
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 18314 steps/s (collection: 4.935s, learning 0.433s)
             Mean action noise std: 3.69
          Mean value_function loss: 84.8952
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.9854
                       Mean reward: 685.81
               Mean episode length: 236.64
    Episode_Reward/reaching_object: 0.9315
    Episode_Reward/rotating_object: 134.1918
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 5.37s
                      Time elapsed: 00:47:05
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 18082 steps/s (collection: 5.024s, learning 0.413s)
             Mean action noise std: 3.70
          Mean value_function loss: 97.8764
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.0003
                       Mean reward: 674.66
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 0.9229
    Episode_Reward/rotating_object: 133.5713
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 5.44s
                      Time elapsed: 00:47:10
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 15876 steps/s (collection: 5.804s, learning 0.387s)
             Mean action noise std: 3.70
          Mean value_function loss: 88.3664
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.0139
                       Mean reward: 687.72
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 0.9465
    Episode_Reward/rotating_object: 137.6724
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 6.19s
                      Time elapsed: 00:47:17
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 16046 steps/s (collection: 5.715s, learning 0.411s)
             Mean action noise std: 3.70
          Mean value_function loss: 94.7258
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.0271
                       Mean reward: 666.04
               Mean episode length: 226.90
    Episode_Reward/reaching_object: 0.9041
    Episode_Reward/rotating_object: 129.5019
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 6.13s
                      Time elapsed: 00:47:23
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 16996 steps/s (collection: 5.337s, learning 0.446s)
             Mean action noise std: 3.71
          Mean value_function loss: 85.9769
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.0442
                       Mean reward: 678.62
               Mean episode length: 227.72
    Episode_Reward/reaching_object: 0.9213
    Episode_Reward/rotating_object: 133.3857
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 5.78s
                      Time elapsed: 00:47:29
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 39326 steps/s (collection: 2.389s, learning 0.111s)
             Mean action noise std: 3.71
          Mean value_function loss: 89.5529
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.0691
                       Mean reward: 685.57
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 0.9112
    Episode_Reward/rotating_object: 130.5398
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.50s
                      Time elapsed: 00:47:31
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 49883 steps/s (collection: 1.875s, learning 0.096s)
             Mean action noise std: 3.71
          Mean value_function loss: 82.4151
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 59.0955
                       Mean reward: 726.65
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 136.6353
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.97s
                      Time elapsed: 00:47:33
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 46099 steps/s (collection: 1.950s, learning 0.182s)
             Mean action noise std: 3.72
          Mean value_function loss: 102.6855
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.1187
                       Mean reward: 700.55
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.9336
    Episode_Reward/rotating_object: 135.3220
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.13s
                      Time elapsed: 00:47:35
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 43312 steps/s (collection: 2.143s, learning 0.127s)
             Mean action noise std: 3.72
          Mean value_function loss: 74.5468
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.1378
                       Mean reward: 671.07
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 0.9313
    Episode_Reward/rotating_object: 131.9444
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.27s
                      Time elapsed: 00:47:37
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 48286 steps/s (collection: 1.915s, learning 0.121s)
             Mean action noise std: 3.72
          Mean value_function loss: 89.7937
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.1520
                       Mean reward: 696.16
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 0.9378
    Episode_Reward/rotating_object: 136.4443
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.04s
                      Time elapsed: 00:47:40
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 48644 steps/s (collection: 1.921s, learning 0.100s)
             Mean action noise std: 3.73
          Mean value_function loss: 104.8469
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.1648
                       Mean reward: 676.15
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 0.9201
    Episode_Reward/rotating_object: 132.3684
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.02s
                      Time elapsed: 00:47:42
                               ETA: 00:11:04

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 48154 steps/s (collection: 1.953s, learning 0.089s)
             Mean action noise std: 3.73
          Mean value_function loss: 82.8645
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.1748
                       Mean reward: 677.66
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 0.9329
    Episode_Reward/rotating_object: 132.2029
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.04s
                      Time elapsed: 00:47:44
                               ETA: 00:11:02

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 49192 steps/s (collection: 1.900s, learning 0.099s)
             Mean action noise std: 3.73
          Mean value_function loss: 93.1060
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.1812
                       Mean reward: 661.19
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 0.9376
    Episode_Reward/rotating_object: 136.0115
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.00s
                      Time elapsed: 00:47:46
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 49238 steps/s (collection: 1.895s, learning 0.101s)
             Mean action noise std: 3.73
          Mean value_function loss: 101.4122
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.1951
                       Mean reward: 634.72
               Mean episode length: 222.75
    Episode_Reward/reaching_object: 0.9142
    Episode_Reward/rotating_object: 129.5913
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.00s
                      Time elapsed: 00:47:48
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 49193 steps/s (collection: 1.896s, learning 0.102s)
             Mean action noise std: 3.73
          Mean value_function loss: 89.1706
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.2121
                       Mean reward: 677.17
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 0.9345
    Episode_Reward/rotating_object: 136.9515
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.00s
                      Time elapsed: 00:47:50
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 49404 steps/s (collection: 1.884s, learning 0.106s)
             Mean action noise std: 3.74
          Mean value_function loss: 91.5710
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.2210
                       Mean reward: 696.87
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 0.9270
    Episode_Reward/rotating_object: 135.0935
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.99s
                      Time elapsed: 00:47:52
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 50345 steps/s (collection: 1.863s, learning 0.089s)
             Mean action noise std: 3.74
          Mean value_function loss: 91.3647
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.2319
                       Mean reward: 664.29
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 0.9332
    Episode_Reward/rotating_object: 136.2982
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.95s
                      Time elapsed: 00:47:54
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 43622 steps/s (collection: 2.086s, learning 0.167s)
             Mean action noise std: 3.74
          Mean value_function loss: 88.3022
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.2479
                       Mean reward: 683.63
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 0.9364
    Episode_Reward/rotating_object: 136.3185
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.25s
                      Time elapsed: 00:47:56
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 45136 steps/s (collection: 2.078s, learning 0.100s)
             Mean action noise std: 3.74
          Mean value_function loss: 92.6395
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.2619
                       Mean reward: 680.53
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 0.9281
    Episode_Reward/rotating_object: 134.4142
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.18s
                      Time elapsed: 00:47:58
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 43185 steps/s (collection: 2.083s, learning 0.193s)
             Mean action noise std: 3.74
          Mean value_function loss: 90.5942
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.2744
                       Mean reward: 709.58
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 0.9379
    Episode_Reward/rotating_object: 136.8992
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.28s
                      Time elapsed: 00:48:00
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 47261 steps/s (collection: 1.940s, learning 0.140s)
             Mean action noise std: 3.75
          Mean value_function loss: 84.9843
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.2870
                       Mean reward: 701.92
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 0.9240
    Episode_Reward/rotating_object: 133.8189
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.08s
                      Time elapsed: 00:48:02
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 46495 steps/s (collection: 1.954s, learning 0.161s)
             Mean action noise std: 3.75
          Mean value_function loss: 107.2759
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.3002
                       Mean reward: 642.89
               Mean episode length: 221.16
    Episode_Reward/reaching_object: 0.9137
    Episode_Reward/rotating_object: 133.6479
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.11s
                      Time elapsed: 00:48:04
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 49064 steps/s (collection: 1.904s, learning 0.100s)
             Mean action noise std: 3.75
          Mean value_function loss: 98.4029
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.3154
                       Mean reward: 667.11
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 0.9286
    Episode_Reward/rotating_object: 132.8446
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.00s
                      Time elapsed: 00:48:06
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 49055 steps/s (collection: 1.906s, learning 0.098s)
             Mean action noise std: 3.75
          Mean value_function loss: 92.5122
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.3274
                       Mean reward: 661.31
               Mean episode length: 231.79
    Episode_Reward/reaching_object: 0.9278
    Episode_Reward/rotating_object: 132.6893
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.00s
                      Time elapsed: 00:48:08
                               ETA: 00:10:33

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 47037 steps/s (collection: 1.960s, learning 0.130s)
             Mean action noise std: 3.76
          Mean value_function loss: 105.8392
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.3438
                       Mean reward: 649.76
               Mean episode length: 226.65
    Episode_Reward/reaching_object: 0.9272
    Episode_Reward/rotating_object: 133.4163
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.09s
                      Time elapsed: 00:48:11
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 42898 steps/s (collection: 2.151s, learning 0.141s)
             Mean action noise std: 3.76
          Mean value_function loss: 104.6188
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.3647
                       Mean reward: 658.36
               Mean episode length: 231.28
    Episode_Reward/reaching_object: 0.9384
    Episode_Reward/rotating_object: 133.8727
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.29s
                      Time elapsed: 00:48:13
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 46386 steps/s (collection: 2.011s, learning 0.108s)
             Mean action noise std: 3.76
          Mean value_function loss: 83.8779
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.3820
                       Mean reward: 671.30
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 0.9289
    Episode_Reward/rotating_object: 130.2797
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.12s
                      Time elapsed: 00:48:15
                               ETA: 00:10:26

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 49277 steps/s (collection: 1.904s, learning 0.091s)
             Mean action noise std: 3.77
          Mean value_function loss: 82.1886
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.4032
                       Mean reward: 656.31
               Mean episode length: 227.70
    Episode_Reward/reaching_object: 0.9392
    Episode_Reward/rotating_object: 134.6690
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.99s
                      Time elapsed: 00:48:17
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 49149 steps/s (collection: 1.889s, learning 0.112s)
             Mean action noise std: 3.77
          Mean value_function loss: 98.7270
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.4211
                       Mean reward: 671.22
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 0.9259
    Episode_Reward/rotating_object: 132.8342
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.00s
                      Time elapsed: 00:48:19
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 47711 steps/s (collection: 1.946s, learning 0.114s)
             Mean action noise std: 3.77
          Mean value_function loss: 111.8190
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.4315
                       Mean reward: 696.66
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 0.9268
    Episode_Reward/rotating_object: 133.5959
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.06s
                      Time elapsed: 00:48:21
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 48827 steps/s (collection: 1.909s, learning 0.104s)
             Mean action noise std: 3.77
          Mean value_function loss: 94.5024
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.4392
                       Mean reward: 636.71
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 0.9156
    Episode_Reward/rotating_object: 129.7155
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.01s
                      Time elapsed: 00:48:23
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 45967 steps/s (collection: 2.045s, learning 0.094s)
             Mean action noise std: 3.78
          Mean value_function loss: 99.1093
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 59.4507
                       Mean reward: 693.78
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 0.9339
    Episode_Reward/rotating_object: 133.9821
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.14s
                      Time elapsed: 00:48:25
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 46925 steps/s (collection: 1.977s, learning 0.118s)
             Mean action noise std: 3.78
          Mean value_function loss: 105.0154
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.4698
                       Mean reward: 650.28
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 0.9207
    Episode_Reward/rotating_object: 131.6012
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.09s
                      Time elapsed: 00:48:27
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 48340 steps/s (collection: 1.921s, learning 0.112s)
             Mean action noise std: 3.78
          Mean value_function loss: 109.5950
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.4893
                       Mean reward: 652.33
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 0.9176
    Episode_Reward/rotating_object: 128.6142
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.03s
                      Time elapsed: 00:48:29
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 48061 steps/s (collection: 1.930s, learning 0.116s)
             Mean action noise std: 3.78
          Mean value_function loss: 94.7288
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.4996
                       Mean reward: 675.16
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 0.9049
    Episode_Reward/rotating_object: 127.5187
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.05s
                      Time elapsed: 00:48:31
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 48899 steps/s (collection: 1.907s, learning 0.104s)
             Mean action noise std: 3.79
          Mean value_function loss: 99.7947
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.5084
                       Mean reward: 658.13
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 0.9350
    Episode_Reward/rotating_object: 133.8532
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.01s
                      Time elapsed: 00:48:33
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 49112 steps/s (collection: 1.895s, learning 0.107s)
             Mean action noise std: 3.79
          Mean value_function loss: 94.9721
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.5209
                       Mean reward: 692.38
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 0.9058
    Episode_Reward/rotating_object: 132.1769
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.00s
                      Time elapsed: 00:48:35
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 49023 steps/s (collection: 1.907s, learning 0.098s)
             Mean action noise std: 3.79
          Mean value_function loss: 100.0726
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.5315
                       Mean reward: 670.25
               Mean episode length: 229.54
    Episode_Reward/reaching_object: 0.9124
    Episode_Reward/rotating_object: 131.5202
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.01s
                      Time elapsed: 00:48:37
                               ETA: 00:09:59

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 49018 steps/s (collection: 1.909s, learning 0.097s)
             Mean action noise std: 3.79
          Mean value_function loss: 116.7333
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 59.5407
                       Mean reward: 656.22
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.9155
    Episode_Reward/rotating_object: 132.3898
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.01s
                      Time elapsed: 00:48:39
                               ETA: 00:09:57

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 48907 steps/s (collection: 1.913s, learning 0.097s)
             Mean action noise std: 3.79
          Mean value_function loss: 84.2524
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.5483
                       Mean reward: 713.01
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 0.9095
    Episode_Reward/rotating_object: 130.2998
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.01s
                      Time elapsed: 00:48:41
                               ETA: 00:09:55

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 49252 steps/s (collection: 1.894s, learning 0.102s)
             Mean action noise std: 3.80
          Mean value_function loss: 83.4245
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.5620
                       Mean reward: 692.17
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 0.9304
    Episode_Reward/rotating_object: 135.3468
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.00s
                      Time elapsed: 00:48:43
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 50125 steps/s (collection: 1.859s, learning 0.103s)
             Mean action noise std: 3.80
          Mean value_function loss: 84.0642
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.5745
                       Mean reward: 687.92
               Mean episode length: 229.38
    Episode_Reward/reaching_object: 0.9202
    Episode_Reward/rotating_object: 134.6245
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.96s
                      Time elapsed: 00:48:45
                               ETA: 00:09:50

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 47706 steps/s (collection: 1.956s, learning 0.105s)
             Mean action noise std: 3.80
          Mean value_function loss: 88.6615
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.5908
                       Mean reward: 674.30
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 0.9266
    Episode_Reward/rotating_object: 133.6603
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.06s
                      Time elapsed: 00:48:47
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 47006 steps/s (collection: 1.984s, learning 0.107s)
             Mean action noise std: 3.80
          Mean value_function loss: 94.7680
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.6023
                       Mean reward: 683.14
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 0.9265
    Episode_Reward/rotating_object: 135.6792
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.09s
                      Time elapsed: 00:48:49
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 48203 steps/s (collection: 1.948s, learning 0.091s)
             Mean action noise std: 3.81
          Mean value_function loss: 83.8641
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.6165
                       Mean reward: 689.74
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 0.9313
    Episode_Reward/rotating_object: 135.8671
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.04s
                      Time elapsed: 00:48:51
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 48081 steps/s (collection: 1.938s, learning 0.106s)
             Mean action noise std: 3.81
          Mean value_function loss: 73.3282
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.6302
                       Mean reward: 721.33
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 0.9511
    Episode_Reward/rotating_object: 138.0688
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.04s
                      Time elapsed: 00:48:54
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 47880 steps/s (collection: 1.952s, learning 0.101s)
             Mean action noise std: 3.81
          Mean value_function loss: 91.7504
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.6461
                       Mean reward: 688.01
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 0.9391
    Episode_Reward/rotating_object: 136.2998
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.05s
                      Time elapsed: 00:48:56
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 47715 steps/s (collection: 1.961s, learning 0.100s)
             Mean action noise std: 3.81
          Mean value_function loss: 88.8320
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.6620
                       Mean reward: 683.92
               Mean episode length: 228.86
    Episode_Reward/reaching_object: 0.9319
    Episode_Reward/rotating_object: 132.9181
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.06s
                      Time elapsed: 00:48:58
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 42281 steps/s (collection: 2.207s, learning 0.118s)
             Mean action noise std: 3.82
          Mean value_function loss: 94.6830
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.6710
                       Mean reward: 686.26
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 0.9503
    Episode_Reward/rotating_object: 137.3273
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.33s
                      Time elapsed: 00:49:00
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 44184 steps/s (collection: 2.090s, learning 0.135s)
             Mean action noise std: 3.82
          Mean value_function loss: 117.6949
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.6821
                       Mean reward: 660.02
               Mean episode length: 224.26
    Episode_Reward/reaching_object: 0.9181
    Episode_Reward/rotating_object: 134.7642
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.22s
                      Time elapsed: 00:49:02
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 46888 steps/s (collection: 2.006s, learning 0.091s)
             Mean action noise std: 3.82
          Mean value_function loss: 96.5770
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.6934
                       Mean reward: 689.86
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 0.9044
    Episode_Reward/rotating_object: 130.7318
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.10s
                      Time elapsed: 00:49:04
                               ETA: 00:09:28

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 47361 steps/s (collection: 1.955s, learning 0.121s)
             Mean action noise std: 3.82
          Mean value_function loss: 97.9165
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.7076
                       Mean reward: 678.68
               Mean episode length: 230.71
    Episode_Reward/reaching_object: 0.9123
    Episode_Reward/rotating_object: 131.3823
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.08s
                      Time elapsed: 00:49:06
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 47433 steps/s (collection: 1.956s, learning 0.117s)
             Mean action noise std: 3.83
          Mean value_function loss: 97.4251
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.7256
                       Mean reward: 681.03
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 0.9374
    Episode_Reward/rotating_object: 134.3968
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.07s
                      Time elapsed: 00:49:08
                               ETA: 00:09:24

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 46255 steps/s (collection: 1.999s, learning 0.127s)
             Mean action noise std: 3.83
          Mean value_function loss: 95.6144
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.7415
                       Mean reward: 683.84
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 0.9320
    Episode_Reward/rotating_object: 133.1366
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.13s
                      Time elapsed: 00:49:11
                               ETA: 00:09:21

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 47866 steps/s (collection: 1.913s, learning 0.141s)
             Mean action noise std: 3.83
          Mean value_function loss: 105.5772
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.7493
                       Mean reward: 656.86
               Mean episode length: 225.36
    Episode_Reward/reaching_object: 0.9259
    Episode_Reward/rotating_object: 133.8950
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.05s
                      Time elapsed: 00:49:13
                               ETA: 00:09:19

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 47440 steps/s (collection: 1.978s, learning 0.095s)
             Mean action noise std: 3.83
          Mean value_function loss: 102.5278
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.7582
                       Mean reward: 633.71
               Mean episode length: 223.16
    Episode_Reward/reaching_object: 0.9039
    Episode_Reward/rotating_object: 130.5112
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.07s
                      Time elapsed: 00:49:15
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 48172 steps/s (collection: 1.938s, learning 0.103s)
             Mean action noise std: 3.83
          Mean value_function loss: 90.1784
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.7707
                       Mean reward: 701.32
               Mean episode length: 233.60
    Episode_Reward/reaching_object: 0.9143
    Episode_Reward/rotating_object: 134.2651
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.04s
                      Time elapsed: 00:49:17
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 48471 steps/s (collection: 1.939s, learning 0.089s)
             Mean action noise std: 3.83
          Mean value_function loss: 89.5476
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.7815
                       Mean reward: 698.95
               Mean episode length: 238.53
    Episode_Reward/reaching_object: 0.9259
    Episode_Reward/rotating_object: 135.3175
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.03s
                      Time elapsed: 00:49:19
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 48848 steps/s (collection: 1.926s, learning 0.087s)
             Mean action noise std: 3.84
          Mean value_function loss: 88.9937
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.7935
                       Mean reward: 716.37
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 0.9292
    Episode_Reward/rotating_object: 133.8035
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.01s
                      Time elapsed: 00:49:21
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 40761 steps/s (collection: 2.301s, learning 0.111s)
             Mean action noise std: 3.84
          Mean value_function loss: 104.3073
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.8073
                       Mean reward: 666.98
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 0.9370
    Episode_Reward/rotating_object: 135.6975
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.41s
                      Time elapsed: 00:49:23
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 41031 steps/s (collection: 2.232s, learning 0.164s)
             Mean action noise std: 3.84
          Mean value_function loss: 94.8179
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.8174
                       Mean reward: 688.77
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 0.9340
    Episode_Reward/rotating_object: 135.7646
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.40s
                      Time elapsed: 00:49:26
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 48837 steps/s (collection: 1.922s, learning 0.091s)
             Mean action noise std: 3.84
          Mean value_function loss: 78.5871
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.8268
                       Mean reward: 722.45
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 0.9299
    Episode_Reward/rotating_object: 136.6076
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.01s
                      Time elapsed: 00:49:28
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 49144 steps/s (collection: 1.901s, learning 0.099s)
             Mean action noise std: 3.85
          Mean value_function loss: 75.1094
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.8408
                       Mean reward: 696.73
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.9216
    Episode_Reward/rotating_object: 132.7502
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.00s
                      Time elapsed: 00:49:30
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 49777 steps/s (collection: 1.878s, learning 0.097s)
             Mean action noise std: 3.85
          Mean value_function loss: 97.2668
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.8615
                       Mean reward: 669.92
               Mean episode length: 226.83
    Episode_Reward/reaching_object: 0.9183
    Episode_Reward/rotating_object: 134.3802
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.97s
                      Time elapsed: 00:49:32
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 46677 steps/s (collection: 2.014s, learning 0.092s)
             Mean action noise std: 3.85
          Mean value_function loss: 100.6958
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.8844
                       Mean reward: 639.63
               Mean episode length: 220.81
    Episode_Reward/reaching_object: 0.9245
    Episode_Reward/rotating_object: 134.0411
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.11s
                      Time elapsed: 00:49:34
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 45083 steps/s (collection: 2.052s, learning 0.128s)
             Mean action noise std: 3.86
          Mean value_function loss: 102.0963
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.9022
                       Mean reward: 647.94
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 0.9180
    Episode_Reward/rotating_object: 130.7975
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.18s
                      Time elapsed: 00:49:36
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 47116 steps/s (collection: 1.995s, learning 0.092s)
             Mean action noise std: 3.86
          Mean value_function loss: 91.8336
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.9224
                       Mean reward: 719.65
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 0.9023
    Episode_Reward/rotating_object: 133.2367
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.09s
                      Time elapsed: 00:49:38
                               ETA: 00:08:50

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 48001 steps/s (collection: 1.958s, learning 0.090s)
             Mean action noise std: 3.86
          Mean value_function loss: 76.5377
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.9421
                       Mean reward: 720.99
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 0.9457
    Episode_Reward/rotating_object: 138.1513
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.05s
                      Time elapsed: 00:49:40
                               ETA: 00:08:48

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 48087 steps/s (collection: 1.952s, learning 0.093s)
             Mean action noise std: 3.87
          Mean value_function loss: 80.6203
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.9617
                       Mean reward: 684.69
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.9332
    Episode_Reward/rotating_object: 137.5629
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.04s
                      Time elapsed: 00:49:42
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 47525 steps/s (collection: 1.970s, learning 0.098s)
             Mean action noise std: 3.87
          Mean value_function loss: 80.8675
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.9765
                       Mean reward: 659.63
               Mean episode length: 228.78
    Episode_Reward/reaching_object: 0.9517
    Episode_Reward/rotating_object: 136.9880
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.07s
                      Time elapsed: 00:49:44
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 47846 steps/s (collection: 1.961s, learning 0.093s)
             Mean action noise std: 3.87
          Mean value_function loss: 102.1917
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.9861
                       Mean reward: 635.75
               Mean episode length: 219.77
    Episode_Reward/reaching_object: 0.9141
    Episode_Reward/rotating_object: 131.7381
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.05s
                      Time elapsed: 00:49:46
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 47585 steps/s (collection: 1.962s, learning 0.104s)
             Mean action noise std: 3.87
          Mean value_function loss: 95.5136
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 59.9958
                       Mean reward: 692.90
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 0.9232
    Episode_Reward/rotating_object: 133.6599
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.07s
                      Time elapsed: 00:49:48
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 47537 steps/s (collection: 1.958s, learning 0.110s)
             Mean action noise std: 3.87
          Mean value_function loss: 96.9633
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.0065
                       Mean reward: 625.93
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 0.9194
    Episode_Reward/rotating_object: 133.9832
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.07s
                      Time elapsed: 00:49:50
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 45335 steps/s (collection: 2.077s, learning 0.091s)
             Mean action noise std: 3.88
          Mean value_function loss: 93.1950
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.0159
                       Mean reward: 682.90
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 0.9268
    Episode_Reward/rotating_object: 134.2627
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.17s
                      Time elapsed: 00:49:52
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 46129 steps/s (collection: 1.991s, learning 0.140s)
             Mean action noise std: 3.88
          Mean value_function loss: 94.6426
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.0278
                       Mean reward: 675.78
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 0.9255
    Episode_Reward/rotating_object: 134.4097
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.13s
                      Time elapsed: 00:49:55
                               ETA: 00:08:31

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 45298 steps/s (collection: 2.052s, learning 0.119s)
             Mean action noise std: 3.88
          Mean value_function loss: 88.0916
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.0408
                       Mean reward: 699.74
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 0.9373
    Episode_Reward/rotating_object: 135.1646
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.17s
                      Time elapsed: 00:49:57
                               ETA: 00:08:29

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 47115 steps/s (collection: 1.945s, learning 0.141s)
             Mean action noise std: 3.88
          Mean value_function loss: 91.4066
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.0546
                       Mean reward: 704.91
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 0.9343
    Episode_Reward/rotating_object: 134.8088
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.09s
                      Time elapsed: 00:49:59
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 44619 steps/s (collection: 2.080s, learning 0.124s)
             Mean action noise std: 3.89
          Mean value_function loss: 107.4141
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 60.0661
                       Mean reward: 666.46
               Mean episode length: 225.22
    Episode_Reward/reaching_object: 0.9110
    Episode_Reward/rotating_object: 129.1686
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.20s
                      Time elapsed: 00:50:01
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 46811 steps/s (collection: 2.009s, learning 0.091s)
             Mean action noise std: 3.89
          Mean value_function loss: 112.1909
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.0727
                       Mean reward: 604.06
               Mean episode length: 212.39
    Episode_Reward/reaching_object: 0.8941
    Episode_Reward/rotating_object: 130.0019
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.10s
                      Time elapsed: 00:50:03
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 48251 steps/s (collection: 1.944s, learning 0.094s)
             Mean action noise std: 3.89
          Mean value_function loss: 90.1104
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.0829
                       Mean reward: 697.95
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 0.9376
    Episode_Reward/rotating_object: 134.5775
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.04s
                      Time elapsed: 00:50:05
                               ETA: 00:08:19

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 48197 steps/s (collection: 1.945s, learning 0.095s)
             Mean action noise std: 3.89
          Mean value_function loss: 106.5573
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.0920
                       Mean reward: 695.87
               Mean episode length: 232.57
    Episode_Reward/reaching_object: 0.9230
    Episode_Reward/rotating_object: 134.1780
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.04s
                      Time elapsed: 00:50:07
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 48165 steps/s (collection: 1.948s, learning 0.093s)
             Mean action noise std: 3.89
          Mean value_function loss: 109.7798
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.0996
                       Mean reward: 655.02
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 0.9132
    Episode_Reward/rotating_object: 131.3215
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.04s
                      Time elapsed: 00:50:09
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 48383 steps/s (collection: 1.941s, learning 0.091s)
             Mean action noise std: 3.89
          Mean value_function loss: 80.8687
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.1094
                       Mean reward: 732.71
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 0.9491
    Episode_Reward/rotating_object: 138.8175
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.03s
                      Time elapsed: 00:50:11
                               ETA: 00:08:12

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 47566 steps/s (collection: 1.965s, learning 0.102s)
             Mean action noise std: 3.90
          Mean value_function loss: 101.6374
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.1190
                       Mean reward: 675.63
               Mean episode length: 221.69
    Episode_Reward/reaching_object: 0.9096
    Episode_Reward/rotating_object: 132.2256
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.07s
                      Time elapsed: 00:50:13
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 47964 steps/s (collection: 1.959s, learning 0.090s)
             Mean action noise std: 3.90
          Mean value_function loss: 82.6872
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.1316
                       Mean reward: 691.76
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 0.9339
    Episode_Reward/rotating_object: 135.4516
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.05s
                      Time elapsed: 00:50:15
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 46119 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 3.90
          Mean value_function loss: 88.9500
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.1455
                       Mean reward: 678.58
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 0.9370
    Episode_Reward/rotating_object: 135.9151
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.13s
                      Time elapsed: 00:50:18
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 47178 steps/s (collection: 1.977s, learning 0.107s)
             Mean action noise std: 3.91
          Mean value_function loss: 100.9397
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.1683
                       Mean reward: 653.79
               Mean episode length: 227.42
    Episode_Reward/reaching_object: 0.9114
    Episode_Reward/rotating_object: 131.7392
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.08s
                      Time elapsed: 00:50:20
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 46692 steps/s (collection: 2.008s, learning 0.097s)
             Mean action noise std: 3.91
          Mean value_function loss: 92.5528
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.1911
                       Mean reward: 695.60
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 0.9243
    Episode_Reward/rotating_object: 133.6045
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.11s
                      Time elapsed: 00:50:22
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 43716 steps/s (collection: 2.143s, learning 0.106s)
             Mean action noise std: 3.91
          Mean value_function loss: 93.0191
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 60.2091
                       Mean reward: 619.81
               Mean episode length: 214.95
    Episode_Reward/reaching_object: 0.8946
    Episode_Reward/rotating_object: 128.6340
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.25s
                      Time elapsed: 00:50:24
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 47981 steps/s (collection: 1.936s, learning 0.113s)
             Mean action noise std: 3.92
          Mean value_function loss: 95.4995
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.2241
                       Mean reward: 700.20
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 0.9376
    Episode_Reward/rotating_object: 135.6491
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.05s
                      Time elapsed: 00:50:26
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 47425 steps/s (collection: 1.981s, learning 0.092s)
             Mean action noise std: 3.92
          Mean value_function loss: 95.7686
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.2416
                       Mean reward: 663.08
               Mean episode length: 227.56
    Episode_Reward/reaching_object: 0.9334
    Episode_Reward/rotating_object: 132.9098
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.07s
                      Time elapsed: 00:50:28
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 47301 steps/s (collection: 1.954s, learning 0.125s)
             Mean action noise std: 3.92
          Mean value_function loss: 86.6556
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.2510
                       Mean reward: 685.85
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 0.9290
    Episode_Reward/rotating_object: 133.7678
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.08s
                      Time elapsed: 00:50:30
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 46816 steps/s (collection: 1.971s, learning 0.128s)
             Mean action noise std: 3.92
          Mean value_function loss: 102.2819
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.2611
                       Mean reward: 667.76
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 0.9089
    Episode_Reward/rotating_object: 130.8990
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.10s
                      Time elapsed: 00:50:32
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 47753 steps/s (collection: 1.961s, learning 0.098s)
             Mean action noise std: 3.92
          Mean value_function loss: 89.2660
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.2754
                       Mean reward: 700.74
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 0.9157
    Episode_Reward/rotating_object: 133.5339
        Episode_Reward/action_rate: -0.0808
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.06s
                      Time elapsed: 00:50:34
                               ETA: 00:07:46

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 45327 steps/s (collection: 2.074s, learning 0.095s)
             Mean action noise std: 3.93
          Mean value_function loss: 74.0923
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.2891
                       Mean reward: 683.67
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 0.9531
    Episode_Reward/rotating_object: 141.9797
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.17s
                      Time elapsed: 00:50:36
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 44366 steps/s (collection: 2.021s, learning 0.194s)
             Mean action noise std: 3.93
          Mean value_function loss: 101.4492
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3022
                       Mean reward: 615.70
               Mean episode length: 213.62
    Episode_Reward/reaching_object: 0.9113
    Episode_Reward/rotating_object: 130.5435
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.22s
                      Time elapsed: 00:50:39
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 43700 steps/s (collection: 2.014s, learning 0.235s)
             Mean action noise std: 3.93
          Mean value_function loss: 101.5946
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.3207
                       Mean reward: 647.02
               Mean episode length: 225.84
    Episode_Reward/reaching_object: 0.9105
    Episode_Reward/rotating_object: 133.7983
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.25s
                      Time elapsed: 00:50:41
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 46917 steps/s (collection: 2.002s, learning 0.093s)
             Mean action noise std: 3.94
          Mean value_function loss: 75.9036
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.3412
                       Mean reward: 698.38
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 0.9315
    Episode_Reward/rotating_object: 137.6633
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.10s
                      Time elapsed: 00:50:43
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 46661 steps/s (collection: 2.002s, learning 0.105s)
             Mean action noise std: 3.94
          Mean value_function loss: 72.3103
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.3555
                       Mean reward: 716.59
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 0.9411
    Episode_Reward/rotating_object: 139.6317
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.11s
                      Time elapsed: 00:50:45
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 47366 steps/s (collection: 1.975s, learning 0.100s)
             Mean action noise std: 3.94
          Mean value_function loss: 80.5452
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.3669
                       Mean reward: 664.79
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 0.9006
    Episode_Reward/rotating_object: 131.7303
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.08s
                      Time elapsed: 00:50:47
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 48766 steps/s (collection: 1.917s, learning 0.099s)
             Mean action noise std: 3.94
          Mean value_function loss: 76.5791
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3733
                       Mean reward: 659.61
               Mean episode length: 236.20
    Episode_Reward/reaching_object: 0.9278
    Episode_Reward/rotating_object: 135.9579
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.02s
                      Time elapsed: 00:50:49
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 49355 steps/s (collection: 1.901s, learning 0.091s)
             Mean action noise std: 3.95
          Mean value_function loss: 73.9448
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.3817
                       Mean reward: 699.75
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 0.9355
    Episode_Reward/rotating_object: 139.2392
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.99s
                      Time elapsed: 00:50:51
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 48128 steps/s (collection: 1.951s, learning 0.092s)
             Mean action noise std: 3.95
          Mean value_function loss: 92.5447
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.3984
                       Mean reward: 713.94
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 0.9312
    Episode_Reward/rotating_object: 136.7762
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.04s
                      Time elapsed: 00:50:53
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 44827 steps/s (collection: 2.029s, learning 0.164s)
             Mean action noise std: 3.95
          Mean value_function loss: 97.3519
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.4107
                       Mean reward: 656.40
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 0.8984
    Episode_Reward/rotating_object: 128.9319
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.19s
                      Time elapsed: 00:50:55
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 47962 steps/s (collection: 1.961s, learning 0.089s)
             Mean action noise std: 3.95
          Mean value_function loss: 87.5528
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.4226
                       Mean reward: 612.57
               Mean episode length: 219.18
    Episode_Reward/reaching_object: 0.8969
    Episode_Reward/rotating_object: 130.1409
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.05s
                      Time elapsed: 00:50:58
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 49056 steps/s (collection: 1.909s, learning 0.095s)
             Mean action noise std: 3.96
          Mean value_function loss: 85.1942
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.4384
                       Mean reward: 677.73
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 0.9258
    Episode_Reward/rotating_object: 136.4700
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.00s
                      Time elapsed: 00:51:00
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 48498 steps/s (collection: 1.931s, learning 0.096s)
             Mean action noise std: 3.96
          Mean value_function loss: 93.7203
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.4512
                       Mean reward: 704.43
               Mean episode length: 231.86
    Episode_Reward/reaching_object: 0.9063
    Episode_Reward/rotating_object: 135.3095
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.03s
                      Time elapsed: 00:51:02
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 48142 steps/s (collection: 1.949s, learning 0.093s)
             Mean action noise std: 3.96
          Mean value_function loss: 103.1926
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.4631
                       Mean reward: 647.14
               Mean episode length: 224.01
    Episode_Reward/reaching_object: 0.9087
    Episode_Reward/rotating_object: 135.1259
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.04s
                      Time elapsed: 00:51:04
                               ETA: 00:07:13

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 48954 steps/s (collection: 1.908s, learning 0.100s)
             Mean action noise std: 3.96
          Mean value_function loss: 84.0405
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.4746
                       Mean reward: 694.75
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 0.9331
    Episode_Reward/rotating_object: 139.2472
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.01s
                      Time elapsed: 00:51:06
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 47698 steps/s (collection: 1.962s, learning 0.099s)
             Mean action noise std: 3.97
          Mean value_function loss: 78.1885
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.4863
                       Mean reward: 683.96
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 0.9212
    Episode_Reward/rotating_object: 134.5852
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.06s
                      Time elapsed: 00:51:08
                               ETA: 00:07:08

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 47905 steps/s (collection: 1.955s, learning 0.098s)
             Mean action noise std: 3.97
          Mean value_function loss: 85.0158
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.4978
                       Mean reward: 679.91
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 0.9229
    Episode_Reward/rotating_object: 137.4203
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.05s
                      Time elapsed: 00:51:10
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 46449 steps/s (collection: 1.963s, learning 0.154s)
             Mean action noise std: 3.97
          Mean value_function loss: 91.6567
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.5104
                       Mean reward: 710.17
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 0.9133
    Episode_Reward/rotating_object: 136.6142
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.12s
                      Time elapsed: 00:51:12
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 47281 steps/s (collection: 1.966s, learning 0.113s)
             Mean action noise std: 3.97
          Mean value_function loss: 90.3695
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.5247
                       Mean reward: 701.19
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 0.9347
    Episode_Reward/rotating_object: 137.8019
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.08s
                      Time elapsed: 00:51:14
                               ETA: 00:07:01

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 47229 steps/s (collection: 1.971s, learning 0.111s)
             Mean action noise std: 3.97
          Mean value_function loss: 113.1749
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 60.5354
                       Mean reward: 677.72
               Mean episode length: 226.32
    Episode_Reward/reaching_object: 0.9148
    Episode_Reward/rotating_object: 134.5130
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.08s
                      Time elapsed: 00:51:16
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 46190 steps/s (collection: 1.982s, learning 0.146s)
             Mean action noise std: 3.98
          Mean value_function loss: 89.1151
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.5429
                       Mean reward: 702.11
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 0.9150
    Episode_Reward/rotating_object: 132.0081
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.13s
                      Time elapsed: 00:51:18
                               ETA: 00:06:56

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 44915 steps/s (collection: 2.066s, learning 0.123s)
             Mean action noise std: 3.98
          Mean value_function loss: 75.5576
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.5567
                       Mean reward: 679.71
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 0.9338
    Episode_Reward/rotating_object: 137.4389
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.19s
                      Time elapsed: 00:51:20
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 44643 steps/s (collection: 2.111s, learning 0.091s)
             Mean action noise std: 3.98
          Mean value_function loss: 100.1942
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.5690
                       Mean reward: 633.06
               Mean episode length: 216.53
    Episode_Reward/reaching_object: 0.9127
    Episode_Reward/rotating_object: 136.4989
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.20s
                      Time elapsed: 00:51:23
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 42797 steps/s (collection: 2.195s, learning 0.102s)
             Mean action noise std: 3.98
          Mean value_function loss: 78.3258
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.5786
                       Mean reward: 713.32
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 0.9358
    Episode_Reward/rotating_object: 137.8067
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.30s
                      Time elapsed: 00:51:25
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 44641 steps/s (collection: 2.109s, learning 0.093s)
             Mean action noise std: 3.99
          Mean value_function loss: 92.9086
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.5945
                       Mean reward: 655.53
               Mean episode length: 224.40
    Episode_Reward/reaching_object: 0.9356
    Episode_Reward/rotating_object: 136.4263
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.20s
                      Time elapsed: 00:51:27
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 46608 steps/s (collection: 2.000s, learning 0.109s)
             Mean action noise std: 3.99
          Mean value_function loss: 99.7008
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.6059
                       Mean reward: 632.99
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 0.9144
    Episode_Reward/rotating_object: 135.5550
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.11s
                      Time elapsed: 00:51:29
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 46141 steps/s (collection: 2.021s, learning 0.109s)
             Mean action noise std: 3.99
          Mean value_function loss: 91.9591
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.6195
                       Mean reward: 736.53
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 0.9238
    Episode_Reward/rotating_object: 136.8347
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.13s
                      Time elapsed: 00:51:31
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 46867 steps/s (collection: 1.998s, learning 0.099s)
             Mean action noise std: 4.00
          Mean value_function loss: 84.8645
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.6361
                       Mean reward: 705.93
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 0.9484
    Episode_Reward/rotating_object: 138.8929
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.10s
                      Time elapsed: 00:51:33
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 45013 steps/s (collection: 2.053s, learning 0.131s)
             Mean action noise std: 4.00
          Mean value_function loss: 81.6635
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.6519
                       Mean reward: 665.39
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 0.9445
    Episode_Reward/rotating_object: 139.3993
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.18s
                      Time elapsed: 00:51:36
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 47817 steps/s (collection: 1.953s, learning 0.103s)
             Mean action noise std: 4.00
          Mean value_function loss: 85.4890
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.6628
                       Mean reward: 707.19
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 0.9179
    Episode_Reward/rotating_object: 133.0273
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.06s
                      Time elapsed: 00:51:38
                               ETA: 00:06:35

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 46108 steps/s (collection: 2.023s, learning 0.109s)
             Mean action noise std: 4.00
          Mean value_function loss: 83.1125
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.6791
                       Mean reward: 709.27
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 0.9273
    Episode_Reward/rotating_object: 135.4080
        Episode_Reward/action_rate: -0.0862
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.13s
                      Time elapsed: 00:51:40
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 47319 steps/s (collection: 1.968s, learning 0.109s)
             Mean action noise std: 4.01
          Mean value_function loss: 84.8782
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.6964
                       Mean reward: 694.76
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 0.9343
    Episode_Reward/rotating_object: 139.0717
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.08s
                      Time elapsed: 00:51:42
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 17316 steps/s (collection: 5.572s, learning 0.105s)
             Mean action noise std: 4.01
          Mean value_function loss: 100.8248
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.7107
                       Mean reward: 683.39
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.9165
    Episode_Reward/rotating_object: 134.5102
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.68s
                      Time elapsed: 00:51:47
                               ETA: 00:06:29

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14226 steps/s (collection: 6.757s, learning 0.153s)
             Mean action noise std: 4.01
          Mean value_function loss: 89.3735
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.7226
                       Mean reward: 690.02
               Mean episode length: 231.85
    Episode_Reward/reaching_object: 0.9364
    Episode_Reward/rotating_object: 138.4671
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.91s
                      Time elapsed: 00:51:54
                               ETA: 00:06:27

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14183 steps/s (collection: 6.721s, learning 0.210s)
             Mean action noise std: 4.01
          Mean value_function loss: 91.6755
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.7367
                       Mean reward: 671.96
               Mean episode length: 219.70
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 136.7933
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.93s
                      Time elapsed: 00:52:01
                               ETA: 00:06:25

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14524 steps/s (collection: 6.652s, learning 0.117s)
             Mean action noise std: 4.02
          Mean value_function loss: 86.7802
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.7513
                       Mean reward: 644.86
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 0.9227
    Episode_Reward/rotating_object: 134.4176
        Episode_Reward/action_rate: -0.0866
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.77s
                      Time elapsed: 00:52:08
                               ETA: 00:06:23

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14767 steps/s (collection: 6.539s, learning 0.118s)
             Mean action noise std: 4.02
          Mean value_function loss: 87.2186
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.7618
                       Mean reward: 669.35
               Mean episode length: 228.23
    Episode_Reward/reaching_object: 0.9378
    Episode_Reward/rotating_object: 134.7731
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.66s
                      Time elapsed: 00:52:15
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14442 steps/s (collection: 6.655s, learning 0.152s)
             Mean action noise std: 4.02
          Mean value_function loss: 84.2595
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.7674
                       Mean reward: 692.30
               Mean episode length: 230.18
    Episode_Reward/reaching_object: 0.9103
    Episode_Reward/rotating_object: 135.2576
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.81s
                      Time elapsed: 00:52:22
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14486 steps/s (collection: 6.661s, learning 0.125s)
             Mean action noise std: 4.02
          Mean value_function loss: 75.1860
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.7805
                       Mean reward: 739.03
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.9277
    Episode_Reward/rotating_object: 135.0685
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.79s
                      Time elapsed: 00:52:28
                               ETA: 00:06:18

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14685 steps/s (collection: 6.551s, learning 0.143s)
             Mean action noise std: 4.02
          Mean value_function loss: 97.8056
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.7926
                       Mean reward: 672.27
               Mean episode length: 231.54
    Episode_Reward/reaching_object: 0.8930
    Episode_Reward/rotating_object: 131.8156
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.69s
                      Time elapsed: 00:52:35
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 13282 steps/s (collection: 7.294s, learning 0.107s)
             Mean action noise std: 4.03
          Mean value_function loss: 81.6055
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.8046
                       Mean reward: 696.42
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 0.9371
    Episode_Reward/rotating_object: 138.0763
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.40s
                      Time elapsed: 00:52:42
                               ETA: 00:06:14

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 49291 steps/s (collection: 1.891s, learning 0.103s)
             Mean action noise std: 4.03
          Mean value_function loss: 89.7322
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.8163
                       Mean reward: 697.01
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 0.9465
    Episode_Reward/rotating_object: 140.9950
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.99s
                      Time elapsed: 00:52:44
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 49030 steps/s (collection: 1.882s, learning 0.123s)
             Mean action noise std: 4.03
          Mean value_function loss: 77.3346
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.8277
                       Mean reward: 700.92
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 0.9353
    Episode_Reward/rotating_object: 137.4156
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0454
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.00s
                      Time elapsed: 00:52:46
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 48032 steps/s (collection: 1.921s, learning 0.126s)
             Mean action noise std: 4.03
          Mean value_function loss: 90.1601
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.8346
                       Mean reward: 718.77
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 0.9304
    Episode_Reward/rotating_object: 138.8298
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.05s
                      Time elapsed: 00:52:48
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 46844 steps/s (collection: 1.996s, learning 0.103s)
             Mean action noise std: 4.04
          Mean value_function loss: 86.7156
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.8445
                       Mean reward: 663.56
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 0.9230
    Episode_Reward/rotating_object: 137.3305
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.10s
                      Time elapsed: 00:52:51
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 48364 steps/s (collection: 1.927s, learning 0.105s)
             Mean action noise std: 4.04
          Mean value_function loss: 95.8680
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.8594
                       Mean reward: 674.07
               Mean episode length: 230.01
    Episode_Reward/reaching_object: 0.9167
    Episode_Reward/rotating_object: 134.2446
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.03s
                      Time elapsed: 00:52:53
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 43544 steps/s (collection: 2.137s, learning 0.121s)
             Mean action noise std: 4.04
          Mean value_function loss: 77.5003
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.8722
                       Mean reward: 699.38
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 0.9195
    Episode_Reward/rotating_object: 137.0538
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.26s
                      Time elapsed: 00:52:55
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 44708 steps/s (collection: 2.086s, learning 0.112s)
             Mean action noise std: 4.04
          Mean value_function loss: 94.4356
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.8860
                       Mean reward: 703.47
               Mean episode length: 235.90
    Episode_Reward/reaching_object: 0.9018
    Episode_Reward/rotating_object: 132.5135
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.20s
                      Time elapsed: 00:52:57
                               ETA: 00:05:58

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 48627 steps/s (collection: 1.902s, learning 0.120s)
             Mean action noise std: 4.04
          Mean value_function loss: 92.6453
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.8953
                       Mean reward: 685.77
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 0.9071
    Episode_Reward/rotating_object: 135.3354
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.02s
                      Time elapsed: 00:52:59
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 48060 steps/s (collection: 1.949s, learning 0.096s)
             Mean action noise std: 4.05
          Mean value_function loss: 100.8708
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.9034
                       Mean reward: 684.13
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 0.9217
    Episode_Reward/rotating_object: 134.2965
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.05s
                      Time elapsed: 00:53:01
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 46893 steps/s (collection: 1.971s, learning 0.125s)
             Mean action noise std: 4.05
          Mean value_function loss: 92.7641
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.9158
                       Mean reward: 689.36
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 0.9130
    Episode_Reward/rotating_object: 134.8124
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.10s
                      Time elapsed: 00:53:03
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 49215 steps/s (collection: 1.904s, learning 0.093s)
             Mean action noise std: 4.05
          Mean value_function loss: 88.4742
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.9262
                       Mean reward: 712.70
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 0.9210
    Episode_Reward/rotating_object: 136.2932
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.00s
                      Time elapsed: 00:53:05
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 48216 steps/s (collection: 1.921s, learning 0.117s)
             Mean action noise std: 4.05
          Mean value_function loss: 92.0244
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.9337
                       Mean reward: 633.71
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 0.9308
    Episode_Reward/rotating_object: 133.9068
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.04s
                      Time elapsed: 00:53:07
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 48002 steps/s (collection: 1.947s, learning 0.101s)
             Mean action noise std: 4.06
          Mean value_function loss: 104.2046
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.9436
                       Mean reward: 649.53
               Mean episode length: 223.51
    Episode_Reward/reaching_object: 0.9376
    Episode_Reward/rotating_object: 138.6433
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.05s
                      Time elapsed: 00:53:09
                               ETA: 00:05:43

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 48198 steps/s (collection: 1.919s, learning 0.121s)
             Mean action noise std: 4.06
          Mean value_function loss: 91.5062
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.9533
                       Mean reward: 709.27
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 0.9230
    Episode_Reward/rotating_object: 138.3094
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.04s
                      Time elapsed: 00:53:11
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 47216 steps/s (collection: 1.929s, learning 0.153s)
             Mean action noise std: 4.06
          Mean value_function loss: 106.4142
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.9645
                       Mean reward: 688.44
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 0.9054
    Episode_Reward/rotating_object: 134.8534
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.08s
                      Time elapsed: 00:53:13
                               ETA: 00:05:38

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 46899 steps/s (collection: 1.938s, learning 0.158s)
             Mean action noise std: 4.06
          Mean value_function loss: 105.1573
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.9801
                       Mean reward: 689.56
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 0.9059
    Episode_Reward/rotating_object: 135.3697
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.10s
                      Time elapsed: 00:53:16
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 47872 steps/s (collection: 1.911s, learning 0.142s)
             Mean action noise std: 4.07
          Mean value_function loss: 104.9636
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.9909
                       Mean reward: 685.64
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 0.8873
    Episode_Reward/rotating_object: 128.0732
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.05s
                      Time elapsed: 00:53:18
                               ETA: 00:05:34

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 48902 steps/s (collection: 1.921s, learning 0.089s)
             Mean action noise std: 4.07
          Mean value_function loss: 75.4408
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.0047
                       Mean reward: 705.10
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 0.9287
    Episode_Reward/rotating_object: 136.3142
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.01s
                      Time elapsed: 00:53:20
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 47872 steps/s (collection: 1.952s, learning 0.102s)
             Mean action noise std: 4.07
          Mean value_function loss: 98.6946
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.0195
                       Mean reward: 700.17
               Mean episode length: 233.71
    Episode_Reward/reaching_object: 0.9149
    Episode_Reward/rotating_object: 135.7165
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.05s
                      Time elapsed: 00:53:22
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 48619 steps/s (collection: 1.899s, learning 0.123s)
             Mean action noise std: 4.07
          Mean value_function loss: 90.8554
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.0356
                       Mean reward: 669.68
               Mean episode length: 223.87
    Episode_Reward/reaching_object: 0.9204
    Episode_Reward/rotating_object: 133.9280
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.02s
                      Time elapsed: 00:53:24
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 45259 steps/s (collection: 2.041s, learning 0.131s)
             Mean action noise std: 4.08
          Mean value_function loss: 82.4630
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.0477
                       Mean reward: 731.62
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 0.9298
    Episode_Reward/rotating_object: 139.0692
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.17s
                      Time elapsed: 00:53:26
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 44893 steps/s (collection: 2.074s, learning 0.116s)
             Mean action noise std: 4.08
          Mean value_function loss: 95.2693
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.0625
                       Mean reward: 711.05
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.9267
    Episode_Reward/rotating_object: 134.4153
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.19s
                      Time elapsed: 00:53:28
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 45875 steps/s (collection: 2.039s, learning 0.104s)
             Mean action noise std: 4.08
          Mean value_function loss: 100.3155
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.0724
                       Mean reward: 698.36
               Mean episode length: 231.19
    Episode_Reward/reaching_object: 0.9217
    Episode_Reward/rotating_object: 137.4664
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.14s
                      Time elapsed: 00:53:30
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 48190 steps/s (collection: 1.944s, learning 0.096s)
             Mean action noise std: 4.08
          Mean value_function loss: 94.2587
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.0789
                       Mean reward: 631.85
               Mean episode length: 218.74
    Episode_Reward/reaching_object: 0.9073
    Episode_Reward/rotating_object: 132.7271
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.04s
                      Time elapsed: 00:53:32
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 48743 steps/s (collection: 1.927s, learning 0.090s)
             Mean action noise std: 4.08
          Mean value_function loss: 94.4493
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.0875
                       Mean reward: 624.82
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 0.9143
    Episode_Reward/rotating_object: 132.2495
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.02s
                      Time elapsed: 00:53:34
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 47970 steps/s (collection: 1.938s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 90.3812
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.1002
                       Mean reward: 692.36
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 0.9140
    Episode_Reward/rotating_object: 133.3381
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.05s
                      Time elapsed: 00:53:36
                               ETA: 00:05:12

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 46793 steps/s (collection: 1.995s, learning 0.106s)
             Mean action noise std: 4.09
          Mean value_function loss: 72.5933
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.1108
                       Mean reward: 667.75
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 0.9296
    Episode_Reward/rotating_object: 137.2561
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.10s
                      Time elapsed: 00:53:38
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 43811 steps/s (collection: 2.106s, learning 0.138s)
             Mean action noise std: 4.09
          Mean value_function loss: 75.9862
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.1214
                       Mean reward: 718.89
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 0.9260
    Episode_Reward/rotating_object: 135.6563
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.24s
                      Time elapsed: 00:53:41
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 46276 steps/s (collection: 1.933s, learning 0.192s)
             Mean action noise std: 4.09
          Mean value_function loss: 77.0792
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.1322
                       Mean reward: 730.88
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 0.9413
    Episode_Reward/rotating_object: 140.4022
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.12s
                      Time elapsed: 00:53:43
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 43074 steps/s (collection: 2.104s, learning 0.179s)
             Mean action noise std: 4.10
          Mean value_function loss: 90.6231
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.1419
                       Mean reward: 711.12
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 0.9285
    Episode_Reward/rotating_object: 139.0228
        Episode_Reward/action_rate: -0.0896
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.28s
                      Time elapsed: 00:53:45
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 46395 steps/s (collection: 2.022s, learning 0.097s)
             Mean action noise std: 4.10
          Mean value_function loss: 93.7510
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.1546
                       Mean reward: 683.82
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 0.9112
    Episode_Reward/rotating_object: 135.2884
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.12s
                      Time elapsed: 00:53:47
                               ETA: 00:05:00

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 48669 steps/s (collection: 1.931s, learning 0.089s)
             Mean action noise std: 4.10
          Mean value_function loss: 86.3842
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.1687
                       Mean reward: 677.65
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 0.9283
    Episode_Reward/rotating_object: 134.6816
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.02s
                      Time elapsed: 00:53:49
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 49675 steps/s (collection: 1.883s, learning 0.096s)
             Mean action noise std: 4.11
          Mean value_function loss: 84.3922
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.1876
                       Mean reward: 672.07
               Mean episode length: 224.10
    Episode_Reward/reaching_object: 0.9397
    Episode_Reward/rotating_object: 139.5701
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.98s
                      Time elapsed: 00:53:51
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 47867 steps/s (collection: 1.922s, learning 0.132s)
             Mean action noise std: 4.11
          Mean value_function loss: 80.7536
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.2067
                       Mean reward: 684.94
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 0.9474
    Episode_Reward/rotating_object: 140.5516
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.05s
                      Time elapsed: 00:53:53
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 45650 steps/s (collection: 2.047s, learning 0.106s)
             Mean action noise std: 4.11
          Mean value_function loss: 86.8129
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.2200
                       Mean reward: 701.86
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 0.9401
    Episode_Reward/rotating_object: 138.1285
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.15s
                      Time elapsed: 00:53:55
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 48396 steps/s (collection: 1.933s, learning 0.098s)
             Mean action noise std: 4.11
          Mean value_function loss: 79.4976
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.2324
                       Mean reward: 668.66
               Mean episode length: 223.07
    Episode_Reward/reaching_object: 0.9279
    Episode_Reward/rotating_object: 139.4341
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.03s
                      Time elapsed: 00:53:57
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 49078 steps/s (collection: 1.912s, learning 0.091s)
             Mean action noise std: 4.12
          Mean value_function loss: 80.8521
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.2428
                       Mean reward: 712.37
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 0.9394
    Episode_Reward/rotating_object: 138.8649
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.00s
                      Time elapsed: 00:53:59
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 49228 steps/s (collection: 1.890s, learning 0.107s)
             Mean action noise std: 4.12
          Mean value_function loss: 108.2239
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.2534
                       Mean reward: 680.92
               Mean episode length: 226.62
    Episode_Reward/reaching_object: 0.9087
    Episode_Reward/rotating_object: 136.4780
        Episode_Reward/action_rate: -0.0892
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.00s
                      Time elapsed: 00:54:01
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 48987 steps/s (collection: 1.907s, learning 0.100s)
             Mean action noise std: 4.12
          Mean value_function loss: 83.0914
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.2640
                       Mean reward: 683.36
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 0.9161
    Episode_Reward/rotating_object: 137.5531
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.01s
                      Time elapsed: 00:54:03
                               ETA: 00:04:41

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 47867 steps/s (collection: 1.961s, learning 0.093s)
             Mean action noise std: 4.12
          Mean value_function loss: 91.8540
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.2764
                       Mean reward: 730.10
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 0.9206
    Episode_Reward/rotating_object: 136.5322
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.05s
                      Time elapsed: 00:54:05
                               ETA: 00:04:39

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 48784 steps/s (collection: 1.917s, learning 0.099s)
             Mean action noise std: 4.13
          Mean value_function loss: 88.5459
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.2931
                       Mean reward: 676.65
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 0.9123
    Episode_Reward/rotating_object: 135.7745
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.02s
                      Time elapsed: 00:54:07
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 48229 steps/s (collection: 1.923s, learning 0.115s)
             Mean action noise std: 4.13
          Mean value_function loss: 107.6714
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.3095
                       Mean reward: 678.50
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 0.9266
    Episode_Reward/rotating_object: 134.9820
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.04s
                      Time elapsed: 00:54:10
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 45077 steps/s (collection: 2.055s, learning 0.126s)
             Mean action noise std: 4.13
          Mean value_function loss: 90.4483
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.3194
                       Mean reward: 721.25
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 0.9241
    Episode_Reward/rotating_object: 136.3163
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.18s
                      Time elapsed: 00:54:12
                               ETA: 00:04:32

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 47777 steps/s (collection: 1.923s, learning 0.135s)
             Mean action noise std: 4.13
          Mean value_function loss: 104.3712
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.3304
                       Mean reward: 685.88
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 0.9100
    Episode_Reward/rotating_object: 136.7072
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.06s
                      Time elapsed: 00:54:14
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 44110 steps/s (collection: 2.056s, learning 0.173s)
             Mean action noise std: 4.14
          Mean value_function loss: 83.7783
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.3407
                       Mean reward: 723.78
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 0.9160
    Episode_Reward/rotating_object: 137.2045
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.23s
                      Time elapsed: 00:54:16
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 47900 steps/s (collection: 1.948s, learning 0.105s)
             Mean action noise std: 4.14
          Mean value_function loss: 110.3929
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 61.3502
                       Mean reward: 646.87
               Mean episode length: 216.26
    Episode_Reward/reaching_object: 0.9063
    Episode_Reward/rotating_object: 134.0407
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.05s
                      Time elapsed: 00:54:18
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 48719 steps/s (collection: 1.902s, learning 0.116s)
             Mean action noise std: 4.14
          Mean value_function loss: 93.8758
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3590
                       Mean reward: 641.21
               Mean episode length: 221.35
    Episode_Reward/reaching_object: 0.8939
    Episode_Reward/rotating_object: 131.1289
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.02s
                      Time elapsed: 00:54:20
                               ETA: 00:04:22

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 49046 steps/s (collection: 1.892s, learning 0.112s)
             Mean action noise std: 4.14
          Mean value_function loss: 82.9114
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.3685
                       Mean reward: 675.54
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 0.9180
    Episode_Reward/rotating_object: 135.7590
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.00s
                      Time elapsed: 00:54:22
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 49631 steps/s (collection: 1.889s, learning 0.092s)
             Mean action noise std: 4.14
          Mean value_function loss: 110.0551
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.3805
                       Mean reward: 673.32
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 0.9058
    Episode_Reward/rotating_object: 136.4352
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.98s
                      Time elapsed: 00:54:24
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 48543 steps/s (collection: 1.925s, learning 0.100s)
             Mean action noise std: 4.15
          Mean value_function loss: 101.6072
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.3980
                       Mean reward: 692.27
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 0.9109
    Episode_Reward/rotating_object: 133.3511
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.03s
                      Time elapsed: 00:54:26
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 49058 steps/s (collection: 1.911s, learning 0.093s)
             Mean action noise std: 4.15
          Mean value_function loss: 108.4771
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 61.4139
                       Mean reward: 682.66
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 0.9038
    Episode_Reward/rotating_object: 134.2849
        Episode_Reward/action_rate: -0.0916
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.00s
                      Time elapsed: 00:54:28
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 47306 steps/s (collection: 1.976s, learning 0.102s)
             Mean action noise std: 4.15
          Mean value_function loss: 90.1004
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.4194
                       Mean reward: 693.82
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 0.9073
    Episode_Reward/rotating_object: 135.2314
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.08s
                      Time elapsed: 00:54:30
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 47577 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 4.15
          Mean value_function loss: 83.8941
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.4277
                       Mean reward: 741.03
               Mean episode length: 238.75
    Episode_Reward/reaching_object: 0.9153
    Episode_Reward/rotating_object: 138.2065
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.07s
                      Time elapsed: 00:54:32
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 49042 steps/s (collection: 1.909s, learning 0.095s)
             Mean action noise std: 4.16
          Mean value_function loss: 87.1352
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.4403
                       Mean reward: 679.39
               Mean episode length: 223.61
    Episode_Reward/reaching_object: 0.9059
    Episode_Reward/rotating_object: 136.6848
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.00s
                      Time elapsed: 00:54:34
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 48044 steps/s (collection: 1.947s, learning 0.100s)
             Mean action noise std: 4.16
          Mean value_function loss: 79.3321
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.4494
                       Mean reward: 704.59
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 0.9079
    Episode_Reward/rotating_object: 136.2576
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.05s
                      Time elapsed: 00:54:36
                               ETA: 00:04:03

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 48027 steps/s (collection: 1.954s, learning 0.093s)
             Mean action noise std: 4.16
          Mean value_function loss: 82.3640
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.4598
                       Mean reward: 676.09
               Mean episode length: 226.07
    Episode_Reward/reaching_object: 0.9064
    Episode_Reward/rotating_object: 137.8617
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.05s
                      Time elapsed: 00:54:38
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 47660 steps/s (collection: 1.946s, learning 0.117s)
             Mean action noise std: 4.16
          Mean value_function loss: 93.4398
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.4760
                       Mean reward: 702.24
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 0.9172
    Episode_Reward/rotating_object: 137.3272
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.06s
                      Time elapsed: 00:54:40
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 48376 steps/s (collection: 1.936s, learning 0.096s)
             Mean action noise std: 4.16
          Mean value_function loss: 90.1819
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.4921
                       Mean reward: 669.76
               Mean episode length: 224.12
    Episode_Reward/reaching_object: 0.9199
    Episode_Reward/rotating_object: 138.8380
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.03s
                      Time elapsed: 00:54:42
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 48716 steps/s (collection: 1.929s, learning 0.089s)
             Mean action noise std: 4.17
          Mean value_function loss: 87.3608
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.5054
                       Mean reward: 658.83
               Mean episode length: 224.95
    Episode_Reward/reaching_object: 0.9085
    Episode_Reward/rotating_object: 135.0193
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.02s
                      Time elapsed: 00:54:44
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 46917 steps/s (collection: 1.975s, learning 0.120s)
             Mean action noise std: 4.17
          Mean value_function loss: 88.2844
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.5196
                       Mean reward: 667.52
               Mean episode length: 223.46
    Episode_Reward/reaching_object: 0.8945
    Episode_Reward/rotating_object: 132.9918
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.10s
                      Time elapsed: 00:54:47
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 47494 steps/s (collection: 1.959s, learning 0.111s)
             Mean action noise std: 4.17
          Mean value_function loss: 85.8212
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.5305
                       Mean reward: 689.98
               Mean episode length: 226.45
    Episode_Reward/reaching_object: 0.9164
    Episode_Reward/rotating_object: 139.0111
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.07s
                      Time elapsed: 00:54:49
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 46734 steps/s (collection: 2.005s, learning 0.099s)
             Mean action noise std: 4.17
          Mean value_function loss: 87.9767
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.5420
                       Mean reward: 703.47
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 0.9259
    Episode_Reward/rotating_object: 137.7458
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.10s
                      Time elapsed: 00:54:51
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 48258 steps/s (collection: 1.940s, learning 0.097s)
             Mean action noise std: 4.18
          Mean value_function loss: 100.4601
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.5592
                       Mean reward: 703.25
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 0.9262
    Episode_Reward/rotating_object: 139.7249
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.04s
                      Time elapsed: 00:54:53
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 43535 steps/s (collection: 2.081s, learning 0.177s)
             Mean action noise std: 4.18
          Mean value_function loss: 107.1140
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.5760
                       Mean reward: 692.89
               Mean episode length: 228.26
    Episode_Reward/reaching_object: 0.9012
    Episode_Reward/rotating_object: 137.1609
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.26s
                      Time elapsed: 00:54:55
                               ETA: 00:03:42

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 46344 steps/s (collection: 2.004s, learning 0.117s)
             Mean action noise std: 4.18
          Mean value_function loss: 95.2578
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.5899
                       Mean reward: 652.71
               Mean episode length: 217.17
    Episode_Reward/reaching_object: 0.8759
    Episode_Reward/rotating_object: 131.5747
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.12s
                      Time elapsed: 00:54:57
                               ETA: 00:03:40

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 47045 steps/s (collection: 1.979s, learning 0.110s)
             Mean action noise std: 4.18
          Mean value_function loss: 92.4731
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.5986
                       Mean reward: 668.79
               Mean episode length: 231.71
    Episode_Reward/reaching_object: 0.9305
    Episode_Reward/rotating_object: 139.2043
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.09s
                      Time elapsed: 00:54:59
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 48018 steps/s (collection: 1.950s, learning 0.097s)
             Mean action noise std: 4.19
          Mean value_function loss: 89.9688
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.6066
                       Mean reward: 664.92
               Mean episode length: 225.79
    Episode_Reward/reaching_object: 0.9069
    Episode_Reward/rotating_object: 134.4244
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.05s
                      Time elapsed: 00:55:01
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 42875 steps/s (collection: 2.116s, learning 0.177s)
             Mean action noise std: 4.19
          Mean value_function loss: 81.7257
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.6150
                       Mean reward: 710.75
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 0.9129
    Episode_Reward/rotating_object: 137.1405
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.29s
                      Time elapsed: 00:55:04
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 44487 steps/s (collection: 2.096s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 78.5485
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.6286
                       Mean reward: 706.59
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 0.9017
    Episode_Reward/rotating_object: 137.0209
        Episode_Reward/action_rate: -0.0942
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.21s
                      Time elapsed: 00:55:06
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 46050 steps/s (collection: 2.030s, learning 0.105s)
             Mean action noise std: 4.19
          Mean value_function loss: 88.1755
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 61.6403
                       Mean reward: 714.95
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 0.9125
    Episode_Reward/rotating_object: 139.1904
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.13s
                      Time elapsed: 00:55:08
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 48429 steps/s (collection: 1.923s, learning 0.107s)
             Mean action noise std: 4.19
          Mean value_function loss: 106.8122
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.6473
                       Mean reward: 717.42
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 0.9110
    Episode_Reward/rotating_object: 137.3963
        Episode_Reward/action_rate: -0.0941
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.03s
                      Time elapsed: 00:55:10
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 45874 steps/s (collection: 2.008s, learning 0.135s)
             Mean action noise std: 4.20
          Mean value_function loss: 102.9366
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.6566
                       Mean reward: 651.85
               Mean episode length: 214.96
    Episode_Reward/reaching_object: 0.8879
    Episode_Reward/rotating_object: 135.7567
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.14s
                      Time elapsed: 00:55:12
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 43635 steps/s (collection: 2.138s, learning 0.115s)
             Mean action noise std: 4.20
          Mean value_function loss: 86.4291
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.6674
                       Mean reward: 699.90
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 0.9114
    Episode_Reward/rotating_object: 135.2771
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.25s
                      Time elapsed: 00:55:14
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 47947 steps/s (collection: 1.952s, learning 0.098s)
             Mean action noise std: 4.20
          Mean value_function loss: 87.1822
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.6788
                       Mean reward: 704.24
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 0.9157
    Episode_Reward/rotating_object: 139.3519
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.05s
                      Time elapsed: 00:55:16
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 49078 steps/s (collection: 1.905s, learning 0.098s)
             Mean action noise std: 4.20
          Mean value_function loss: 77.8201
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.6922
                       Mean reward: 683.81
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 0.9160
    Episode_Reward/rotating_object: 137.6602
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.00s
                      Time elapsed: 00:55:18
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 48367 steps/s (collection: 1.922s, learning 0.110s)
             Mean action noise std: 4.21
          Mean value_function loss: 89.2765
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.7022
                       Mean reward: 734.62
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 0.9156
    Episode_Reward/rotating_object: 140.4331
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.03s
                      Time elapsed: 00:55:20
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 48636 steps/s (collection: 1.920s, learning 0.102s)
             Mean action noise std: 4.21
          Mean value_function loss: 84.8471
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.7139
                       Mean reward: 654.86
               Mean episode length: 228.62
    Episode_Reward/reaching_object: 0.9265
    Episode_Reward/rotating_object: 140.3390
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.02s
                      Time elapsed: 00:55:22
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 48279 steps/s (collection: 1.945s, learning 0.091s)
             Mean action noise std: 4.21
          Mean value_function loss: 78.8712
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.7280
                       Mean reward: 662.81
               Mean episode length: 223.56
    Episode_Reward/reaching_object: 0.8977
    Episode_Reward/rotating_object: 135.4500
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.04s
                      Time elapsed: 00:55:24
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 49248 steps/s (collection: 1.903s, learning 0.094s)
             Mean action noise std: 4.21
          Mean value_function loss: 79.8324
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.7381
                       Mean reward: 731.99
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 0.9103
    Episode_Reward/rotating_object: 138.8332
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.00s
                      Time elapsed: 00:55:26
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 49544 steps/s (collection: 1.884s, learning 0.101s)
             Mean action noise std: 4.21
          Mean value_function loss: 92.2477
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 61.7476
                       Mean reward: 686.33
               Mean episode length: 225.88
    Episode_Reward/reaching_object: 0.9072
    Episode_Reward/rotating_object: 139.5907
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.98s
                      Time elapsed: 00:55:28
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 46885 steps/s (collection: 1.994s, learning 0.103s)
             Mean action noise std: 4.22
          Mean value_function loss: 94.9069
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.7557
                       Mean reward: 694.36
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.9165
    Episode_Reward/rotating_object: 138.9229
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.10s
                      Time elapsed: 00:55:31
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 47924 steps/s (collection: 1.949s, learning 0.102s)
             Mean action noise std: 4.22
          Mean value_function loss: 84.5761
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.7666
                       Mean reward: 686.70
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 0.9082
    Episode_Reward/rotating_object: 136.4489
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.05s
                      Time elapsed: 00:55:33
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 47558 steps/s (collection: 1.967s, learning 0.100s)
             Mean action noise std: 4.22
          Mean value_function loss: 82.7269
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.7755
                       Mean reward: 692.16
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 0.9067
    Episode_Reward/rotating_object: 137.3076
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.07s
                      Time elapsed: 00:55:35
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 48805 steps/s (collection: 1.912s, learning 0.103s)
             Mean action noise std: 4.22
          Mean value_function loss: 83.4304
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.7850
                       Mean reward: 711.66
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 0.9089
    Episode_Reward/rotating_object: 137.3344
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.01s
                      Time elapsed: 00:55:37
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 48286 steps/s (collection: 1.930s, learning 0.106s)
             Mean action noise std: 4.23
          Mean value_function loss: 86.2701
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.7958
                       Mean reward: 692.64
               Mean episode length: 232.16
    Episode_Reward/reaching_object: 0.9102
    Episode_Reward/rotating_object: 136.5756
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.04s
                      Time elapsed: 00:55:39
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 40612 steps/s (collection: 2.243s, learning 0.177s)
             Mean action noise std: 4.23
          Mean value_function loss: 90.5392
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.8086
                       Mean reward: 665.26
               Mean episode length: 220.59
    Episode_Reward/reaching_object: 0.8984
    Episode_Reward/rotating_object: 137.0118
        Episode_Reward/action_rate: -0.0941
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.42s
                      Time elapsed: 00:55:41
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 45719 steps/s (collection: 1.927s, learning 0.223s)
             Mean action noise std: 4.23
          Mean value_function loss: 111.9455
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.8211
                       Mean reward: 699.70
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 0.8997
    Episode_Reward/rotating_object: 135.2941
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.15s
                      Time elapsed: 00:55:43
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 47883 steps/s (collection: 1.948s, learning 0.105s)
             Mean action noise std: 4.23
          Mean value_function loss: 77.5094
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.8318
                       Mean reward: 674.96
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 0.9261
    Episode_Reward/rotating_object: 139.4762
        Episode_Reward/action_rate: -0.0965
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.05s
                      Time elapsed: 00:55:45
                               ETA: 00:02:46

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 48700 steps/s (collection: 1.923s, learning 0.095s)
             Mean action noise std: 4.23
          Mean value_function loss: 77.0816
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.8440
                       Mean reward: 713.07
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 0.9058
    Episode_Reward/rotating_object: 136.0612
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.02s
                      Time elapsed: 00:55:47
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 47758 steps/s (collection: 1.957s, learning 0.101s)
             Mean action noise std: 4.24
          Mean value_function loss: 67.3785
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.8562
                       Mean reward: 677.52
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 0.9116
    Episode_Reward/rotating_object: 137.5927
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.06s
                      Time elapsed: 00:55:49
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 46218 steps/s (collection: 2.036s, learning 0.091s)
             Mean action noise std: 4.24
          Mean value_function loss: 72.6084
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.8653
                       Mean reward: 679.26
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 0.9264
    Episode_Reward/rotating_object: 138.7320
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.13s
                      Time elapsed: 00:55:52
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 47980 steps/s (collection: 1.951s, learning 0.098s)
             Mean action noise std: 4.24
          Mean value_function loss: 90.7699
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.8762
                       Mean reward: 685.39
               Mean episode length: 228.07
    Episode_Reward/reaching_object: 0.9141
    Episode_Reward/rotating_object: 138.5629
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.05s
                      Time elapsed: 00:55:54
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 44300 steps/s (collection: 2.074s, learning 0.145s)
             Mean action noise std: 4.24
          Mean value_function loss: 82.3933
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.8867
                       Mean reward: 648.93
               Mean episode length: 225.80
    Episode_Reward/reaching_object: 0.9077
    Episode_Reward/rotating_object: 134.6423
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.22s
                      Time elapsed: 00:55:56
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 45563 steps/s (collection: 2.057s, learning 0.100s)
             Mean action noise std: 4.25
          Mean value_function loss: 82.1691
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.8981
                       Mean reward: 651.92
               Mean episode length: 219.98
    Episode_Reward/reaching_object: 0.9110
    Episode_Reward/rotating_object: 136.8224
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.16s
                      Time elapsed: 00:55:58
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 42291 steps/s (collection: 2.193s, learning 0.131s)
             Mean action noise std: 4.25
          Mean value_function loss: 80.7959
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.9130
                       Mean reward: 706.65
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 0.9340
    Episode_Reward/rotating_object: 139.5688
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.32s
                      Time elapsed: 00:56:00
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 46856 steps/s (collection: 1.987s, learning 0.111s)
             Mean action noise std: 4.25
          Mean value_function loss: 83.1915
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.9277
                       Mean reward: 697.90
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 0.9356
    Episode_Reward/rotating_object: 140.2546
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.10s
                      Time elapsed: 00:56:02
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 47671 steps/s (collection: 1.971s, learning 0.091s)
             Mean action noise std: 4.25
          Mean value_function loss: 76.6114
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.9444
                       Mean reward: 721.56
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 0.9172
    Episode_Reward/rotating_object: 135.6549
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.06s
                      Time elapsed: 00:56:04
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 48778 steps/s (collection: 1.922s, learning 0.094s)
             Mean action noise std: 4.26
          Mean value_function loss: 91.3171
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.9542
                       Mean reward: 712.15
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 0.9292
    Episode_Reward/rotating_object: 140.0545
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.02s
                      Time elapsed: 00:56:06
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 47906 steps/s (collection: 1.959s, learning 0.093s)
             Mean action noise std: 4.26
          Mean value_function loss: 78.6318
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.9637
                       Mean reward: 730.08
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 0.9345
    Episode_Reward/rotating_object: 141.0750
        Episode_Reward/action_rate: -0.0979
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.05s
                      Time elapsed: 00:56:08
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 46078 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 4.26
          Mean value_function loss: 99.7285
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.9777
                       Mean reward: 697.45
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 0.9217
    Episode_Reward/rotating_object: 137.9214
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.13s
                      Time elapsed: 00:56:11
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 46842 steps/s (collection: 2.000s, learning 0.098s)
             Mean action noise std: 4.27
          Mean value_function loss: 84.9889
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.9920
                       Mean reward: 685.33
               Mean episode length: 230.88
    Episode_Reward/reaching_object: 0.9152
    Episode_Reward/rotating_object: 137.1587
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.10s
                      Time elapsed: 00:56:13
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 41105 steps/s (collection: 2.175s, learning 0.216s)
             Mean action noise std: 4.27
          Mean value_function loss: 87.0743
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.0053
                       Mean reward: 739.10
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 0.9329
    Episode_Reward/rotating_object: 140.0805
        Episode_Reward/action_rate: -0.0975
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.39s
                      Time elapsed: 00:56:15
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 42094 steps/s (collection: 2.229s, learning 0.106s)
             Mean action noise std: 4.27
          Mean value_function loss: 102.5843
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.0177
                       Mean reward: 694.42
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 0.9331
    Episode_Reward/rotating_object: 135.9866
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.34s
                      Time elapsed: 00:56:17
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 46131 steps/s (collection: 2.016s, learning 0.115s)
             Mean action noise std: 4.27
          Mean value_function loss: 92.8504
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.0310
                       Mean reward: 689.42
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 0.9245
    Episode_Reward/rotating_object: 137.9021
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.13s
                      Time elapsed: 00:56:20
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 47909 steps/s (collection: 1.953s, learning 0.099s)
             Mean action noise std: 4.28
          Mean value_function loss: 92.1205
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 62.0418
                       Mean reward: 668.37
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 0.9310
    Episode_Reward/rotating_object: 136.6638
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.05s
                      Time elapsed: 00:56:22
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 46608 steps/s (collection: 2.017s, learning 0.093s)
             Mean action noise std: 4.28
          Mean value_function loss: 90.2678
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.0537
                       Mean reward: 714.87
               Mean episode length: 236.87
    Episode_Reward/reaching_object: 0.9021
    Episode_Reward/rotating_object: 132.8655
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.11s
                      Time elapsed: 00:56:24
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 48503 steps/s (collection: 1.932s, learning 0.095s)
             Mean action noise std: 4.28
          Mean value_function loss: 96.3197
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.0661
                       Mean reward: 697.68
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 0.9267
    Episode_Reward/rotating_object: 134.8706
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.03s
                      Time elapsed: 00:56:26
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 45972 steps/s (collection: 2.001s, learning 0.137s)
             Mean action noise std: 4.28
          Mean value_function loss: 86.6204
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.0750
                       Mean reward: 689.89
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 0.9177
    Episode_Reward/rotating_object: 133.5833
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.14s
                      Time elapsed: 00:56:28
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 41328 steps/s (collection: 2.187s, learning 0.192s)
             Mean action noise std: 4.28
          Mean value_function loss: 90.4057
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.0819
                       Mean reward: 650.90
               Mean episode length: 220.26
    Episode_Reward/reaching_object: 0.9139
    Episode_Reward/rotating_object: 134.1857
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.38s
                      Time elapsed: 00:56:30
                               ETA: 00:01:56

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 42752 steps/s (collection: 2.174s, learning 0.126s)
             Mean action noise std: 4.29
          Mean value_function loss: 86.6216
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.0948
                       Mean reward: 640.97
               Mean episode length: 226.90
    Episode_Reward/reaching_object: 0.9151
    Episode_Reward/rotating_object: 132.9023
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.30s
                      Time elapsed: 00:56:33
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 39252 steps/s (collection: 2.348s, learning 0.157s)
             Mean action noise std: 4.29
          Mean value_function loss: 69.5623
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.1068
                       Mean reward: 712.60
               Mean episode length: 243.02
    Episode_Reward/reaching_object: 0.9657
    Episode_Reward/rotating_object: 143.9522
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.50s
                      Time elapsed: 00:56:35
                               ETA: 00:01:52

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 41129 steps/s (collection: 2.208s, learning 0.182s)
             Mean action noise std: 4.29
          Mean value_function loss: 103.7159
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.1224
                       Mean reward: 728.76
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 0.9143
    Episode_Reward/rotating_object: 136.3491
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.39s
                      Time elapsed: 00:56:37
                               ETA: 00:01:49

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 45333 steps/s (collection: 2.048s, learning 0.121s)
             Mean action noise std: 4.29
          Mean value_function loss: 78.5253
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.1330
                       Mean reward: 694.53
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 0.9523
    Episode_Reward/rotating_object: 139.4962
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.17s
                      Time elapsed: 00:56:40
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 38635 steps/s (collection: 2.373s, learning 0.171s)
             Mean action noise std: 4.30
          Mean value_function loss: 81.6360
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.1464
                       Mean reward: 704.90
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 0.9423
    Episode_Reward/rotating_object: 141.9974
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.54s
                      Time elapsed: 00:56:42
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 38921 steps/s (collection: 2.353s, learning 0.173s)
             Mean action noise std: 4.30
          Mean value_function loss: 88.7535
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.1631
                       Mean reward: 699.40
               Mean episode length: 229.31
    Episode_Reward/reaching_object: 0.9293
    Episode_Reward/rotating_object: 141.1226
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.53s
                      Time elapsed: 00:56:45
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 42706 steps/s (collection: 2.198s, learning 0.104s)
             Mean action noise std: 4.30
          Mean value_function loss: 76.2844
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.1768
                       Mean reward: 691.49
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 0.9371
    Episode_Reward/rotating_object: 138.5360
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.30s
                      Time elapsed: 00:56:47
                               ETA: 00:01:40

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 42309 steps/s (collection: 2.113s, learning 0.211s)
             Mean action noise std: 4.31
          Mean value_function loss: 88.4127
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.1869
                       Mean reward: 621.69
               Mean episode length: 220.24
    Episode_Reward/reaching_object: 0.9343
    Episode_Reward/rotating_object: 137.7896
        Episode_Reward/action_rate: -0.1006
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.32s
                      Time elapsed: 00:56:49
                               ETA: 00:01:38

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 46338 steps/s (collection: 1.980s, learning 0.141s)
             Mean action noise std: 4.31
          Mean value_function loss: 92.6926
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 62.1973
                       Mean reward: 715.68
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 0.9239
    Episode_Reward/rotating_object: 139.2072
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.12s
                      Time elapsed: 00:56:51
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 45311 steps/s (collection: 2.004s, learning 0.165s)
             Mean action noise std: 4.31
          Mean value_function loss: 87.0612
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.2065
                       Mean reward: 680.83
               Mean episode length: 225.10
    Episode_Reward/reaching_object: 0.9144
    Episode_Reward/rotating_object: 139.5229
        Episode_Reward/action_rate: -0.0998
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.17s
                      Time elapsed: 00:56:54
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 45714 steps/s (collection: 2.061s, learning 0.090s)
             Mean action noise std: 4.31
          Mean value_function loss: 94.9053
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.2123
                       Mean reward: 676.51
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 0.9322
    Episode_Reward/rotating_object: 140.4337
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.15s
                      Time elapsed: 00:56:56
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 48683 steps/s (collection: 1.929s, learning 0.090s)
             Mean action noise std: 4.31
          Mean value_function loss: 75.5441
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 62.2189
                       Mean reward: 732.17
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 0.9372
    Episode_Reward/rotating_object: 138.5079
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.02s
                      Time elapsed: 00:56:58
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 45260 steps/s (collection: 2.049s, learning 0.123s)
             Mean action noise std: 4.32
          Mean value_function loss: 103.9611
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.2323
                       Mean reward: 685.63
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 0.9072
    Episode_Reward/rotating_object: 133.7248
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.17s
                      Time elapsed: 00:57:00
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 47059 steps/s (collection: 1.978s, learning 0.111s)
             Mean action noise std: 4.32
          Mean value_function loss: 74.4221
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.2426
                       Mean reward: 703.97
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 0.9244
    Episode_Reward/rotating_object: 138.1197
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.09s
                      Time elapsed: 00:57:02
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 49066 steps/s (collection: 1.907s, learning 0.097s)
             Mean action noise std: 4.32
          Mean value_function loss: 81.4832
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.2527
                       Mean reward: 682.97
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.9359
    Episode_Reward/rotating_object: 140.6685
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.00s
                      Time elapsed: 00:57:04
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 49031 steps/s (collection: 1.903s, learning 0.102s)
             Mean action noise std: 4.32
          Mean value_function loss: 85.0495
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.2656
                       Mean reward: 704.75
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 0.9266
    Episode_Reward/rotating_object: 138.5021
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.00s
                      Time elapsed: 00:57:06
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 47335 steps/s (collection: 1.946s, learning 0.131s)
             Mean action noise std: 4.33
          Mean value_function loss: 86.9518
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.2785
                       Mean reward: 683.41
               Mean episode length: 226.54
    Episode_Reward/reaching_object: 0.8992
    Episode_Reward/rotating_object: 135.3635
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.08s
                      Time elapsed: 00:57:08
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 44550 steps/s (collection: 2.000s, learning 0.206s)
             Mean action noise std: 4.33
          Mean value_function loss: 103.1384
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.2972
                       Mean reward: 724.90
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 0.8940
    Episode_Reward/rotating_object: 134.1529
        Episode_Reward/action_rate: -0.0988
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.21s
                      Time elapsed: 00:57:10
                               ETA: 00:01:14

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 44091 steps/s (collection: 2.094s, learning 0.135s)
             Mean action noise std: 4.33
          Mean value_function loss: 90.0137
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.3127
                       Mean reward: 711.70
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 0.8969
    Episode_Reward/rotating_object: 134.0493
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.23s
                      Time elapsed: 00:57:13
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 45970 steps/s (collection: 2.051s, learning 0.088s)
             Mean action noise std: 4.33
          Mean value_function loss: 73.9159
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.3200
                       Mean reward: 700.23
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 0.9167
    Episode_Reward/rotating_object: 139.3025
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.14s
                      Time elapsed: 00:57:15
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 48002 steps/s (collection: 1.948s, learning 0.100s)
             Mean action noise std: 4.34
          Mean value_function loss: 106.4314
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.3297
                       Mean reward: 679.27
               Mean episode length: 224.84
    Episode_Reward/reaching_object: 0.8938
    Episode_Reward/rotating_object: 135.6952
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.05s
                      Time elapsed: 00:57:17
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 46421 steps/s (collection: 2.014s, learning 0.104s)
             Mean action noise std: 4.34
          Mean value_function loss: 87.6876
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.3392
                       Mean reward: 651.27
               Mean episode length: 221.33
    Episode_Reward/reaching_object: 0.9092
    Episode_Reward/rotating_object: 138.3874
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.12s
                      Time elapsed: 00:57:19
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 48286 steps/s (collection: 1.934s, learning 0.102s)
             Mean action noise std: 4.34
          Mean value_function loss: 78.7036
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.3495
                       Mean reward: 727.10
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 0.9228
    Episode_Reward/rotating_object: 141.8811
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.04s
                      Time elapsed: 00:57:21
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 46794 steps/s (collection: 1.987s, learning 0.114s)
             Mean action noise std: 4.34
          Mean value_function loss: 71.8278
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.3636
                       Mean reward: 682.02
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 0.9292
    Episode_Reward/rotating_object: 141.7589
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.10s
                      Time elapsed: 00:57:23
                               ETA: 00:01:00

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 47668 steps/s (collection: 1.973s, learning 0.090s)
             Mean action noise std: 4.35
          Mean value_function loss: 86.7883
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.3766
                       Mean reward: 675.20
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 0.8957
    Episode_Reward/rotating_object: 134.1036
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.06s
                      Time elapsed: 00:57:25
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 46791 steps/s (collection: 2.005s, learning 0.096s)
             Mean action noise std: 4.35
          Mean value_function loss: 86.8017
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.3896
                       Mean reward: 673.52
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 0.9231
    Episode_Reward/rotating_object: 138.7850
        Episode_Reward/action_rate: -0.1020
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.10s
                      Time elapsed: 00:57:27
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 47564 steps/s (collection: 1.961s, learning 0.106s)
             Mean action noise std: 4.35
          Mean value_function loss: 70.3314
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.4034
                       Mean reward: 713.99
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 0.9432
    Episode_Reward/rotating_object: 143.3892
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.07s
                      Time elapsed: 00:57:29
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 48530 steps/s (collection: 1.930s, learning 0.096s)
             Mean action noise std: 4.35
          Mean value_function loss: 84.6234
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.4124
                       Mean reward: 701.73
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 0.9373
    Episode_Reward/rotating_object: 141.4638
        Episode_Reward/action_rate: -0.1046
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.03s
                      Time elapsed: 00:57:31
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 47609 steps/s (collection: 1.973s, learning 0.092s)
             Mean action noise std: 4.36
          Mean value_function loss: 80.2496
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.4236
                       Mean reward: 718.43
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 0.9249
    Episode_Reward/rotating_object: 140.6346
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.06s
                      Time elapsed: 00:57:33
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 47739 steps/s (collection: 1.963s, learning 0.097s)
             Mean action noise std: 4.36
          Mean value_function loss: 72.4523
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.4364
                       Mean reward: 678.69
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 0.9572
    Episode_Reward/rotating_object: 142.1204
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.06s
                      Time elapsed: 00:57:35
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 47267 steps/s (collection: 1.948s, learning 0.132s)
             Mean action noise std: 4.36
          Mean value_function loss: 80.8757
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 62.4473
                       Mean reward: 702.39
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 0.9290
    Episode_Reward/rotating_object: 141.4409
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.08s
                      Time elapsed: 00:57:37
                               ETA: 00:00:44

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 47571 steps/s (collection: 1.952s, learning 0.115s)
             Mean action noise std: 4.36
          Mean value_function loss: 92.8480
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.4615
                       Mean reward: 695.68
               Mean episode length: 226.31
    Episode_Reward/reaching_object: 0.9208
    Episode_Reward/rotating_object: 138.1938
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.07s
                      Time elapsed: 00:57:40
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 44952 steps/s (collection: 2.049s, learning 0.138s)
             Mean action noise std: 4.37
          Mean value_function loss: 110.9154
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.4757
                       Mean reward: 692.64
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 0.8965
    Episode_Reward/rotating_object: 134.9055
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.19s
                      Time elapsed: 00:57:42
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 46478 steps/s (collection: 1.994s, learning 0.122s)
             Mean action noise std: 4.37
          Mean value_function loss: 92.3297
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.4864
                       Mean reward: 679.86
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 0.9299
    Episode_Reward/rotating_object: 136.8382
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.12s
                      Time elapsed: 00:57:44
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 46132 steps/s (collection: 2.030s, learning 0.101s)
             Mean action noise std: 4.37
          Mean value_function loss: 84.6643
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.4979
                       Mean reward: 670.21
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 0.9189
    Episode_Reward/rotating_object: 135.2039
        Episode_Reward/action_rate: -0.1027
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.13s
                      Time elapsed: 00:57:46
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 41706 steps/s (collection: 2.189s, learning 0.168s)
             Mean action noise std: 4.37
          Mean value_function loss: 91.3097
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.5102
                       Mean reward: 663.67
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 0.9086
    Episode_Reward/rotating_object: 134.6399
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.36s
                      Time elapsed: 00:57:48
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 42503 steps/s (collection: 2.164s, learning 0.149s)
             Mean action noise std: 4.38
          Mean value_function loss: 95.9114
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.5219
                       Mean reward: 667.46
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 0.9066
    Episode_Reward/rotating_object: 133.7244
        Episode_Reward/action_rate: -0.1016
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.31s
                      Time elapsed: 00:57:51
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 42841 steps/s (collection: 2.185s, learning 0.110s)
             Mean action noise std: 4.38
          Mean value_function loss: 91.5637
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.5314
                       Mean reward: 694.95
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 0.9235
    Episode_Reward/rotating_object: 137.4925
        Episode_Reward/action_rate: -0.1038
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.29s
                      Time elapsed: 00:57:53
                               ETA: 00:00:27

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 45027 steps/s (collection: 2.060s, learning 0.124s)
             Mean action noise std: 4.38
          Mean value_function loss: 77.9609
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.5408
                       Mean reward: 700.48
               Mean episode length: 230.28
    Episode_Reward/reaching_object: 0.9197
    Episode_Reward/rotating_object: 137.4950
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.18s
                      Time elapsed: 00:57:55
                               ETA: 00:00:25

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 44564 steps/s (collection: 2.093s, learning 0.113s)
             Mean action noise std: 4.38
          Mean value_function loss: 68.6286
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.5551
                       Mean reward: 695.76
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 0.9414
    Episode_Reward/rotating_object: 142.8787
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.21s
                      Time elapsed: 00:57:57
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 43927 steps/s (collection: 2.118s, learning 0.120s)
             Mean action noise std: 4.39
          Mean value_function loss: 75.0472
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 62.5672
                       Mean reward: 707.51
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.9366
    Episode_Reward/rotating_object: 140.8252
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.24s
                      Time elapsed: 00:58:00
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 44627 steps/s (collection: 2.100s, learning 0.103s)
             Mean action noise std: 4.39
          Mean value_function loss: 75.0320
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.5792
                       Mean reward: 676.54
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 0.9398
    Episode_Reward/rotating_object: 141.5199
        Episode_Reward/action_rate: -0.1054
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.20s
                      Time elapsed: 00:58:02
                               ETA: 00:00:18

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 48088 steps/s (collection: 1.943s, learning 0.102s)
             Mean action noise std: 4.39
          Mean value_function loss: 108.9415
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.5910
                       Mean reward: 685.58
               Mean episode length: 224.00
    Episode_Reward/reaching_object: 0.9129
    Episode_Reward/rotating_object: 137.9925
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.04s
                      Time elapsed: 00:58:04
                               ETA: 00:00:16

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 47428 steps/s (collection: 1.982s, learning 0.091s)
             Mean action noise std: 4.39
          Mean value_function loss: 90.0035
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.5994
                       Mean reward: 716.24
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 0.9476
    Episode_Reward/rotating_object: 141.8072
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.07s
                      Time elapsed: 00:58:06
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 42037 steps/s (collection: 2.190s, learning 0.148s)
             Mean action noise std: 4.39
          Mean value_function loss: 89.9226
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.6067
                       Mean reward: 713.45
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 0.9129
    Episode_Reward/rotating_object: 138.0668
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.34s
                      Time elapsed: 00:58:08
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 43016 steps/s (collection: 2.155s, learning 0.131s)
             Mean action noise std: 4.40
          Mean value_function loss: 97.8251
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 62.6188
                       Mean reward: 698.76
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 0.9009
    Episode_Reward/rotating_object: 132.1194
        Episode_Reward/action_rate: -0.1022
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.29s
                      Time elapsed: 00:58:11
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 43000 steps/s (collection: 2.152s, learning 0.134s)
             Mean action noise std: 4.40
          Mean value_function loss: 83.5954
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.6359
                       Mean reward: 719.61
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.9239
    Episode_Reward/rotating_object: 139.4433
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.29s
                      Time elapsed: 00:58:13
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 44136 steps/s (collection: 2.122s, learning 0.106s)
             Mean action noise std: 4.40
          Mean value_function loss: 92.8818
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.6490
                       Mean reward: 680.79
               Mean episode length: 222.91
    Episode_Reward/reaching_object: 0.9285
    Episode_Reward/rotating_object: 140.1844
        Episode_Reward/action_rate: -0.1046
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.23s
                      Time elapsed: 00:58:15
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 45845 steps/s (collection: 2.037s, learning 0.107s)
             Mean action noise std: 4.41
          Mean value_function loss: 75.5593
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.6601
                       Mean reward: 758.53
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 0.9344
    Episode_Reward/rotating_object: 141.2679
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.14s
                      Time elapsed: 00:58:17
                               ETA: 00:00:02

