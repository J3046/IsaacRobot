################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 4132 steps/s (collection: 22.843s, learning 0.943s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0016
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 31.2515
                       Mean reward: 0.00
               Mean episode length: 21.21
    Episode_Reward/reaching_object: 0.0007
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0003
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 23.79s
                      Time elapsed: 00:00:23
                               ETA: 09:54:37

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 5784 steps/s (collection: 16.559s, learning 0.435s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.3476
                       Mean reward: 0.00
               Mean episode length: 45.83
    Episode_Reward/reaching_object: 0.0019
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0006
          Episode_Reward/joint_vel: -0.0008
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 16.99s
                      Time elapsed: 00:00:40
                               ETA: 08:29:24

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 5954 steps/s (collection: 16.082s, learning 0.427s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 31.3745
                       Mean reward: 0.00
               Mean episode length: 69.78
    Episode_Reward/reaching_object: 0.0028
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0011
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 16.51s
                      Time elapsed: 00:00:57
                               ETA: 07:56:45

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 5689 steps/s (collection: 17.024s, learning 0.255s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 31.4072
                       Mean reward: 0.00
               Mean episode length: 93.42
    Episode_Reward/reaching_object: 0.0040
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0019
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 17.28s
                      Time elapsed: 00:01:14
                               ETA: 07:45:06

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 5597 steps/s (collection: 17.142s, learning 0.420s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 31.4333
                       Mean reward: 0.01
               Mean episode length: 117.74
    Episode_Reward/reaching_object: 0.0052
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 17.56s
                      Time elapsed: 00:01:32
                               ETA: 07:39:24

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 5634 steps/s (collection: 16.892s, learning 0.554s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 31.4361
                       Mean reward: 0.01
               Mean episode length: 141.96
    Episode_Reward/reaching_object: 0.0068
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0024
          Episode_Reward/joint_vel: -0.0030
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 17.45s
                      Time elapsed: 00:01:49
                               ETA: 07:35:02

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 5847 steps/s (collection: 16.432s, learning 0.381s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 31.4371
                       Mean reward: 0.01
               Mean episode length: 165.77
    Episode_Reward/reaching_object: 0.0083
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0036
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 16.81s
                      Time elapsed: 00:02:06
                               ETA: 07:29:34

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 5706 steps/s (collection: 16.749s, learning 0.477s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 31.4425
                       Mean reward: 0.01
               Mean episode length: 189.36
    Episode_Reward/reaching_object: 0.0096
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0032
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 17.23s
                      Time elapsed: 00:02:23
                               ETA: 07:26:41

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 6241 steps/s (collection: 15.536s, learning 0.214s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 31.4508
                       Mean reward: 0.01
               Mean episode length: 213.10
    Episode_Reward/reaching_object: 0.0117
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 15.75s
                      Time elapsed: 00:02:39
                               ETA: 07:20:18

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 22538 steps/s (collection: 4.053s, learning 0.309s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 31.4649
                       Mean reward: 0.03
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.0142
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 4.36s
                      Time elapsed: 00:02:43
                               ETA: 06:46:51

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 20337 steps/s (collection: 4.443s, learning 0.391s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 31.4483
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0168
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 4.83s
                      Time elapsed: 00:02:48
                               ETA: 06:20:32

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 21011 steps/s (collection: 4.309s, learning 0.370s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 31.4734
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0194
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 4.68s
                      Time elapsed: 00:02:53
                               ETA: 05:58:15

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 19347 steps/s (collection: 4.708s, learning 0.372s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 31.4998
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0249
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 5.08s
                      Time elapsed: 00:02:58
                               ETA: 05:40:10

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 22117 steps/s (collection: 4.164s, learning 0.281s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 31.5153
                       Mean reward: 0.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0298
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 4.44s
                      Time elapsed: 00:03:02
                               ETA: 05:23:32

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 20901 steps/s (collection: 4.364s, learning 0.339s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 31.5010
                       Mean reward: 0.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0355
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 4.70s
                      Time elapsed: 00:03:07
                               ETA: 05:09:31

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 21800 steps/s (collection: 4.250s, learning 0.260s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 31.5250
                       Mean reward: 0.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0512
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 4.51s
                      Time elapsed: 00:03:11
                               ETA: 04:56:57

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 23532 steps/s (collection: 3.814s, learning 0.364s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 31.5470
                       Mean reward: 0.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0652
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 4.18s
                      Time elapsed: 00:03:16
                               ETA: 04:45:22

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 19396 steps/s (collection: 4.678s, learning 0.390s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0013
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 31.5670
                       Mean reward: 0.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0852
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 5.07s
                      Time elapsed: 00:03:21
                               ETA: 04:36:18

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 19224 steps/s (collection: 4.739s, learning 0.374s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0011
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 31.5980
                       Mean reward: 0.51
               Mean episode length: 249.57
    Episode_Reward/reaching_object: 0.1141
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 5.11s
                      Time elapsed: 00:03:26
                               ETA: 04:28:14

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 18093 steps/s (collection: 5.097s, learning 0.336s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0020
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 31.6485
                       Mean reward: 0.66
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.1377
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 5.43s
                      Time elapsed: 00:03:31
                               ETA: 04:21:21

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 19371 steps/s (collection: 4.583s, learning 0.491s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0039
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 31.6764
                       Mean reward: 0.96
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 0.1726
    Episode_Reward/rotating_object: 0.0007
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 5.07s
                      Time elapsed: 00:03:36
                               ETA: 04:14:42

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 18359 steps/s (collection: 5.028s, learning 0.327s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0086
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 31.7154
                       Mean reward: 1.12
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 0.2218
    Episode_Reward/rotating_object: 0.0035
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 5.35s
                      Time elapsed: 00:03:42
                               ETA: 04:08:57

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 17782 steps/s (collection: 5.041s, learning 0.487s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0097
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 31.7650
                       Mean reward: 1.38
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 0.2556
    Episode_Reward/rotating_object: 0.0082
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.5833
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 5.53s
                      Time elapsed: 00:03:47
                               ETA: 04:03:53

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 18093 steps/s (collection: 5.128s, learning 0.305s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0069
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 31.8327
                       Mean reward: 1.60
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 0.2946
    Episode_Reward/rotating_object: 0.0124
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 9.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 5.43s
                      Time elapsed: 00:03:53
                               ETA: 03:59:08

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 19454 steps/s (collection: 4.674s, learning 0.379s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0146
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 31.9022
                       Mean reward: 1.56
               Mean episode length: 217.32
    Episode_Reward/reaching_object: 0.3225
    Episode_Reward/rotating_object: 0.0147
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 5.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 15.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 5.05s
                      Time elapsed: 00:03:58
                               ETA: 03:54:23

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 21217 steps/s (collection: 4.210s, learning 0.423s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 32.0114
                       Mean reward: 1.77
               Mean episode length: 214.64
    Episode_Reward/reaching_object: 0.3428
    Episode_Reward/rotating_object: 0.0217
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 4.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.8750
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 4.63s
                      Time elapsed: 00:04:02
                               ETA: 03:49:36

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 22337 steps/s (collection: 4.089s, learning 0.312s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0149
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 32.0924
                       Mean reward: 2.31
               Mean episode length: 215.84
    Episode_Reward/reaching_object: 0.3684
    Episode_Reward/rotating_object: 0.0396
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 3.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 4.40s
                      Time elapsed: 00:04:07
                               ETA: 03:44:57

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 20468 steps/s (collection: 4.414s, learning 0.389s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0175
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 32.1850
                       Mean reward: 2.59
               Mean episode length: 210.74
    Episode_Reward/reaching_object: 0.3823
    Episode_Reward/rotating_object: 0.0503
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 3.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 4.80s
                      Time elapsed: 00:04:12
                               ETA: 03:40:59

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 18986 steps/s (collection: 4.841s, learning 0.336s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0200
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 32.2795
                       Mean reward: 2.21
               Mean episode length: 208.70
    Episode_Reward/reaching_object: 0.4010
    Episode_Reward/rotating_object: 0.0452
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 3.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 5.18s
                      Time elapsed: 00:04:17
                               ETA: 03:37:36

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 19968 steps/s (collection: 4.542s, learning 0.381s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0322
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 32.4015
                       Mean reward: 2.21
               Mean episode length: 211.38
    Episode_Reward/reaching_object: 0.4251
    Episode_Reward/rotating_object: 0.0617
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 4.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 4.92s
                      Time elapsed: 00:04:22
                               ETA: 03:34:13

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 19903 steps/s (collection: 4.515s, learning 0.424s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0823
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 32.5520
                       Mean reward: 2.95
               Mean episode length: 216.25
    Episode_Reward/reaching_object: 0.4489
    Episode_Reward/rotating_object: 0.0722
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 5.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 4.94s
                      Time elapsed: 00:04:27
                               ETA: 03:31:05

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 22513 steps/s (collection: 4.024s, learning 0.343s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1880
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.7352
                       Mean reward: 3.16
               Mean episode length: 220.19
    Episode_Reward/reaching_object: 0.4841
    Episode_Reward/rotating_object: 0.0925
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 7.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 4.37s
                      Time elapsed: 00:04:31
                               ETA: 03:27:41

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 22117 steps/s (collection: 4.133s, learning 0.312s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.4741
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.8854
                       Mean reward: 4.15
               Mean episode length: 222.23
    Episode_Reward/reaching_object: 0.5221
    Episode_Reward/rotating_object: 0.1475
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 9.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 4.44s
                      Time elapsed: 00:04:35
                               ETA: 03:24:33

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 20362 steps/s (collection: 4.476s, learning 0.352s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.8445
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.9514
                       Mean reward: 3.48
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 0.5462
    Episode_Reward/rotating_object: 0.1395
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 4.83s
                      Time elapsed: 00:04:40
                               ETA: 03:21:52

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 21233 steps/s (collection: 4.372s, learning 0.258s)
             Mean action noise std: 1.10
          Mean value_function loss: 1.0374
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.1531
                       Mean reward: 4.18
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 0.5958
    Episode_Reward/rotating_object: 0.2905
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 4.63s
                      Time elapsed: 00:04:45
                               ETA: 03:19:12

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 21516 steps/s (collection: 4.179s, learning 0.389s)
             Mean action noise std: 1.10
          Mean value_function loss: 1.2547
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.3102
                       Mean reward: 4.00
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 0.5914
    Episode_Reward/rotating_object: 0.3262
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 4.57s
                      Time elapsed: 00:04:49
                               ETA: 03:16:38

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 20528 steps/s (collection: 4.422s, learning 0.367s)
             Mean action noise std: 1.11
          Mean value_function loss: 1.1221
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.3637
                       Mean reward: 9.36
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 0.6129
    Episode_Reward/rotating_object: 0.8783
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 4.79s
                      Time elapsed: 00:04:54
                               ETA: 03:14:21

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 20811 steps/s (collection: 4.388s, learning 0.336s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.9048
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.5101
                       Mean reward: 5.01
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 0.6438
    Episode_Reward/rotating_object: 0.4026
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 4.72s
                      Time elapsed: 00:04:59
                               ETA: 03:12:08

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 20356 steps/s (collection: 4.415s, learning 0.414s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.1122
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.6345
                       Mean reward: 9.06
               Mean episode length: 227.95
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 0.7557
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 4.83s
                      Time elapsed: 00:05:04
                               ETA: 03:10:06

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 20597 steps/s (collection: 4.454s, learning 0.319s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.8102
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.7193
                       Mean reward: 8.71
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 0.6805
    Episode_Reward/rotating_object: 0.7036
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 4.77s
                      Time elapsed: 00:05:09
                               ETA: 03:08:07

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 19771 steps/s (collection: 4.486s, learning 0.486s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.9711
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.8333
                       Mean reward: 4.71
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 0.6688
    Episode_Reward/rotating_object: 0.6021
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 4.97s
                      Time elapsed: 00:05:14
                               ETA: 03:06:21

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 18950 steps/s (collection: 4.809s, learning 0.378s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.9717
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.9405
                       Mean reward: 6.97
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 0.7013
    Episode_Reward/rotating_object: 0.8822
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 5.19s
                      Time elapsed: 00:05:19
                               ETA: 03:04:48

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 23590 steps/s (collection: 3.902s, learning 0.266s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.0854
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 34.0488
                       Mean reward: 6.92
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 0.7176
    Episode_Reward/rotating_object: 0.7770
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 4.17s
                      Time elapsed: 00:05:23
                               ETA: 03:02:44

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 21646 steps/s (collection: 4.231s, learning 0.310s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.3211
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.1958
                       Mean reward: 9.91
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 0.7357
    Episode_Reward/rotating_object: 1.1417
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 4.54s
                      Time elapsed: 00:05:27
                               ETA: 03:00:58

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 18619 steps/s (collection: 4.789s, learning 0.491s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.1102
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.2781
                       Mean reward: 7.31
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 0.9645
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 5.28s
                      Time elapsed: 00:05:33
                               ETA: 02:59:40

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 21565 steps/s (collection: 4.144s, learning 0.414s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.5673
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.3665
                       Mean reward: 10.00
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 0.7488
    Episode_Reward/rotating_object: 0.9373
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 4.56s
                      Time elapsed: 00:05:37
                               ETA: 02:58:02

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 21958 steps/s (collection: 4.054s, learning 0.423s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.9112
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 34.4233
                       Mean reward: 6.74
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 0.7784
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 4.48s
                      Time elapsed: 00:05:42
                               ETA: 02:56:26

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 20270 steps/s (collection: 4.469s, learning 0.381s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.8818
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.4832
                       Mean reward: 11.48
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 1.2563
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 4.85s
                      Time elapsed: 00:05:47
                               ETA: 02:55:06

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 18613 steps/s (collection: 4.881s, learning 0.400s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.1708
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 34.5729
                       Mean reward: 9.06
               Mean episode length: 241.27
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 1.6587
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 5.28s
                      Time elapsed: 00:05:52
                               ETA: 02:54:01

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 18704 steps/s (collection: 4.807s, learning 0.449s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.4690
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.6381
                       Mean reward: 11.95
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 0.6917
    Episode_Reward/rotating_object: 1.2648
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 5.26s
                      Time elapsed: 00:05:57
                               ETA: 02:52:57

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 18018 steps/s (collection: 5.126s, learning 0.330s)
             Mean action noise std: 1.17
          Mean value_function loss: 3.6716
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 34.7158
                       Mean reward: 13.05
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 0.7294
    Episode_Reward/rotating_object: 1.6278
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 5.46s
                      Time elapsed: 00:06:03
                               ETA: 02:52:02

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 18248 steps/s (collection: 4.997s, learning 0.390s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.9438
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 34.7541
                       Mean reward: 11.50
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 2.3483
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 5.39s
                      Time elapsed: 00:06:08
                               ETA: 02:51:06

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 19634 steps/s (collection: 4.679s, learning 0.328s)
             Mean action noise std: 1.18
          Mean value_function loss: 3.6529
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.8103
                       Mean reward: 12.82
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 0.7053
    Episode_Reward/rotating_object: 2.2385
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 5.01s
                      Time elapsed: 00:06:13
                               ETA: 02:50:03

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 19523 steps/s (collection: 4.751s, learning 0.284s)
             Mean action noise std: 1.18
          Mean value_function loss: 4.8599
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 34.8919
                       Mean reward: 17.34
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 0.7549
    Episode_Reward/rotating_object: 1.8358
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 5.04s
                      Time elapsed: 00:06:18
                               ETA: 02:49:02

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 18973 steps/s (collection: 4.800s, learning 0.381s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.2880
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 34.9256
                       Mean reward: 17.90
               Mean episode length: 247.23
    Episode_Reward/reaching_object: 0.7352
    Episode_Reward/rotating_object: 2.3728
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 5.18s
                      Time elapsed: 00:06:23
                               ETA: 02:48:07

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 20121 steps/s (collection: 4.511s, learning 0.375s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.2389
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 34.9762
                       Mean reward: 17.19
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.7529
    Episode_Reward/rotating_object: 3.2243
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 4.89s
                      Time elapsed: 00:06:28
                               ETA: 02:47:06

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 20397 steps/s (collection: 4.476s, learning 0.343s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.8279
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 35.0402
                       Mean reward: 16.54
               Mean episode length: 246.79
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 2.7556
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 4.82s
                      Time elapsed: 00:06:33
                               ETA: 02:46:05

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 20802 steps/s (collection: 4.456s, learning 0.270s)
             Mean action noise std: 1.19
          Mean value_function loss: 5.4542
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 35.0830
                       Mean reward: 16.93
               Mean episode length: 242.58
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 3.2676
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 4.73s
                      Time elapsed: 00:06:38
                               ETA: 02:45:04

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 20964 steps/s (collection: 4.387s, learning 0.302s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.8104
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 35.1690
                       Mean reward: 32.13
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 0.7157
    Episode_Reward/rotating_object: 3.5423
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 4.69s
                      Time elapsed: 00:06:42
                               ETA: 02:44:04

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 21586 steps/s (collection: 4.241s, learning 0.313s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.9213
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 35.2207
                       Mean reward: 18.58
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 3.5824
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 4.55s
                      Time elapsed: 00:06:47
                               ETA: 02:43:03

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 19373 steps/s (collection: 4.716s, learning 0.358s)
             Mean action noise std: 1.21
          Mean value_function loss: 6.2518
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 35.3119
                       Mean reward: 19.57
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 2.9937
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 5.07s
                      Time elapsed: 00:06:52
                               ETA: 02:42:15

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 18641 steps/s (collection: 4.986s, learning 0.288s)
             Mean action noise std: 1.21
          Mean value_function loss: 6.0303
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.4060
                       Mean reward: 18.82
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.7168
    Episode_Reward/rotating_object: 3.0061
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 5.27s
                      Time elapsed: 00:06:57
                               ETA: 02:41:34

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 19131 steps/s (collection: 4.748s, learning 0.391s)
             Mean action noise std: 1.22
          Mean value_function loss: 6.9434
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 35.4976
                       Mean reward: 30.40
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 0.7367
    Episode_Reward/rotating_object: 4.3096
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 5.14s
                      Time elapsed: 00:07:02
                               ETA: 02:40:51

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 19168 steps/s (collection: 4.765s, learning 0.363s)
             Mean action noise std: 1.22
          Mean value_function loss: 6.6408
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.6098
                       Mean reward: 24.35
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 0.7392
    Episode_Reward/rotating_object: 4.2887
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 5.13s
                      Time elapsed: 00:07:07
                               ETA: 02:40:09

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 18318 steps/s (collection: 5.069s, learning 0.298s)
             Mean action noise std: 1.22
          Mean value_function loss: 6.9014
               Mean surrogate loss: 0.0049
                 Mean entropy loss: 35.6570
                       Mean reward: 21.89
               Mean episode length: 240.65
    Episode_Reward/reaching_object: 0.7310
    Episode_Reward/rotating_object: 3.1908
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 5.37s
                      Time elapsed: 00:07:13
                               ETA: 02:39:33

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 20304 steps/s (collection: 4.442s, learning 0.399s)
             Mean action noise std: 1.23
          Mean value_function loss: 6.6416
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 35.6860
                       Mean reward: 26.91
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 4.3228
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 4.84s
                      Time elapsed: 00:07:18
                               ETA: 02:38:46

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 20088 steps/s (collection: 4.563s, learning 0.331s)
             Mean action noise std: 1.23
          Mean value_function loss: 6.7569
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 35.7516
                       Mean reward: 18.84
               Mean episode length: 248.64
    Episode_Reward/reaching_object: 0.7396
    Episode_Reward/rotating_object: 4.2867
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 4.89s
                      Time elapsed: 00:07:23
                               ETA: 02:38:02

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 17823 steps/s (collection: 5.136s, learning 0.379s)
             Mean action noise std: 1.23
          Mean value_function loss: 7.3602
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.8039
                       Mean reward: 27.14
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.7368
    Episode_Reward/rotating_object: 4.0165
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 5.52s
                      Time elapsed: 00:07:28
                               ETA: 02:37:33

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 17973 steps/s (collection: 5.110s, learning 0.360s)
             Mean action noise std: 1.24
          Mean value_function loss: 6.8818
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 35.9073
                       Mean reward: 26.72
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.7562
    Episode_Reward/rotating_object: 6.0344
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 5.47s
                      Time elapsed: 00:07:34
                               ETA: 02:37:03

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 19240 steps/s (collection: 4.786s, learning 0.323s)
             Mean action noise std: 1.24
          Mean value_function loss: 6.6503
               Mean surrogate loss: 0.0092
                 Mean entropy loss: 35.9589
                       Mean reward: 26.90
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.7151
    Episode_Reward/rotating_object: 4.6990
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 5.11s
                      Time elapsed: 00:07:39
                               ETA: 02:36:26

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 17810 steps/s (collection: 5.119s, learning 0.401s)
             Mean action noise std: 1.24
          Mean value_function loss: 6.4055
               Mean surrogate loss: 0.0040
                 Mean entropy loss: 35.9659
                       Mean reward: 28.89
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 4.1927
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 5.52s
                      Time elapsed: 00:07:44
                               ETA: 02:35:58

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 17200 steps/s (collection: 5.341s, learning 0.374s)
             Mean action noise std: 1.24
          Mean value_function loss: 6.7377
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 35.9736
                       Mean reward: 23.76
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 0.6986
    Episode_Reward/rotating_object: 4.2753
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 5.72s
                      Time elapsed: 00:07:50
                               ETA: 02:35:35

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 17892 steps/s (collection: 5.159s, learning 0.335s)
             Mean action noise std: 1.25
          Mean value_function loss: 5.4895
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 36.0108
                       Mean reward: 26.05
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 0.7425
    Episode_Reward/rotating_object: 5.0112
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 5.49s
                      Time elapsed: 00:07:55
                               ETA: 02:35:09

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 18365 steps/s (collection: 4.888s, learning 0.464s)
             Mean action noise std: 1.25
          Mean value_function loss: 5.2632
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.0793
                       Mean reward: 17.19
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 4.3416
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 5.35s
                      Time elapsed: 00:08:01
                               ETA: 02:34:40

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 17672 steps/s (collection: 5.222s, learning 0.341s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.0545
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 36.1692
                       Mean reward: 21.01
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7126
    Episode_Reward/rotating_object: 3.7164
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 5.56s
                      Time elapsed: 00:08:06
                               ETA: 02:34:15

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 17319 steps/s (collection: 5.261s, learning 0.415s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.0723
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 36.2345
                       Mean reward: 26.29
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 4.4094
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 5.68s
                      Time elapsed: 00:08:12
                               ETA: 02:33:53

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 18579 steps/s (collection: 4.974s, learning 0.317s)
             Mean action noise std: 1.26
          Mean value_function loss: 5.8648
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 36.3090
                       Mean reward: 32.29
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.7202
    Episode_Reward/rotating_object: 5.2168
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 5.29s
                      Time elapsed: 00:08:17
                               ETA: 02:33:25

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 18344 steps/s (collection: 4.923s, learning 0.435s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.8429
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.3910
                       Mean reward: 32.22
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 0.7108
    Episode_Reward/rotating_object: 4.1377
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 5.36s
                      Time elapsed: 00:08:23
                               ETA: 02:32:58

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 21832 steps/s (collection: 4.172s, learning 0.330s)
             Mean action noise std: 1.27
          Mean value_function loss: 6.0049
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 36.4602
                       Mean reward: 25.38
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 0.7012
    Episode_Reward/rotating_object: 4.1987
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 4.50s
                      Time elapsed: 00:08:27
                               ETA: 02:32:17

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 19958 steps/s (collection: 4.560s, learning 0.365s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.0726
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 36.5121
                       Mean reward: 20.05
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 0.7019
    Episode_Reward/rotating_object: 4.0526
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 4.93s
                      Time elapsed: 00:08:32
                               ETA: 02:31:44

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 21216 steps/s (collection: 4.309s, learning 0.324s)
             Mean action noise std: 1.28
          Mean value_function loss: 5.9769
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.6064
                       Mean reward: 26.73
               Mean episode length: 244.78
    Episode_Reward/reaching_object: 0.6994
    Episode_Reward/rotating_object: 4.2311
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 4.63s
                      Time elapsed: 00:08:37
                               ETA: 02:31:06

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 19010 steps/s (collection: 4.780s, learning 0.391s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.3496
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.6521
                       Mean reward: 21.02
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.6909
    Episode_Reward/rotating_object: 3.8746
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 5.17s
                      Time elapsed: 00:08:42
                               ETA: 02:30:39

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 19532 steps/s (collection: 4.747s, learning 0.286s)
             Mean action noise std: 1.29
          Mean value_function loss: 6.6867
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 36.7050
                       Mean reward: 27.18
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 0.6899
    Episode_Reward/rotating_object: 4.3057
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 5.03s
                      Time elapsed: 00:08:47
                               ETA: 02:30:10

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 20571 steps/s (collection: 4.481s, learning 0.298s)
             Mean action noise std: 1.29
          Mean value_function loss: 6.7650
               Mean surrogate loss: 0.0036
                 Mean entropy loss: 36.7400
                       Mean reward: 26.80
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 5.1878
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 4.78s
                      Time elapsed: 00:08:52
                               ETA: 02:29:37

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 19898 steps/s (collection: 4.626s, learning 0.314s)
             Mean action noise std: 1.29
          Mean value_function loss: 6.9052
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 36.7572
                       Mean reward: 21.85
               Mean episode length: 244.96
    Episode_Reward/reaching_object: 0.6795
    Episode_Reward/rotating_object: 3.3517
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 4.94s
                      Time elapsed: 00:08:57
                               ETA: 02:29:07

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 20346 steps/s (collection: 4.487s, learning 0.345s)
             Mean action noise std: 1.29
          Mean value_function loss: 7.0875
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.7999
                       Mean reward: 16.82
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 0.6856
    Episode_Reward/rotating_object: 4.1760
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 4.83s
                      Time elapsed: 00:09:01
                               ETA: 02:28:36

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 20682 steps/s (collection: 4.386s, learning 0.367s)
             Mean action noise std: 1.29
          Mean value_function loss: 7.5786
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 36.8375
                       Mean reward: 26.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7061
    Episode_Reward/rotating_object: 5.0687
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 4.75s
                      Time elapsed: 00:09:06
                               ETA: 02:28:05

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 20465 steps/s (collection: 4.420s, learning 0.384s)
             Mean action noise std: 1.30
          Mean value_function loss: 7.2320
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.8899
                       Mean reward: 28.87
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 4.6439
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 4.80s
                      Time elapsed: 00:09:11
                               ETA: 02:27:35

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 19624 steps/s (collection: 4.667s, learning 0.342s)
             Mean action noise std: 1.30
          Mean value_function loss: 8.5655
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 36.9558
                       Mean reward: 42.33
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 0.6923
    Episode_Reward/rotating_object: 5.7803
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 5.01s
                      Time elapsed: 00:09:16
                               ETA: 02:27:09

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 18135 steps/s (collection: 5.015s, learning 0.405s)
             Mean action noise std: 1.30
          Mean value_function loss: 8.9829
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.0072
                       Mean reward: 24.02
               Mean episode length: 245.20
    Episode_Reward/reaching_object: 0.6755
    Episode_Reward/rotating_object: 4.6022
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 5.42s
                      Time elapsed: 00:09:21
                               ETA: 02:26:49

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 18516 steps/s (collection: 5.012s, learning 0.297s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.0868
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.0596
                       Mean reward: 39.55
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 0.6734
    Episode_Reward/rotating_object: 5.8641
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 5.31s
                      Time elapsed: 00:09:27
                               ETA: 02:26:29

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 21729 steps/s (collection: 4.153s, learning 0.371s)
             Mean action noise std: 1.31
          Mean value_function loss: 11.2957
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.1230
                       Mean reward: 31.53
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.6707
    Episode_Reward/rotating_object: 4.7125
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 4.52s
                      Time elapsed: 00:09:31
                               ETA: 02:25:56

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 19345 steps/s (collection: 4.757s, learning 0.325s)
             Mean action noise std: 1.32
          Mean value_function loss: 9.6987
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 37.1871
                       Mean reward: 22.25
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.6543
    Episode_Reward/rotating_object: 4.7229
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 5.08s
                      Time elapsed: 00:09:36
                               ETA: 02:25:33

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 19312 steps/s (collection: 4.792s, learning 0.298s)
             Mean action noise std: 1.32
          Mean value_function loss: 10.1945
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.2389
                       Mean reward: 38.39
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 5.9066
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 5.09s
                      Time elapsed: 00:09:41
                               ETA: 02:25:10

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 18696 steps/s (collection: 4.965s, learning 0.293s)
             Mean action noise std: 1.32
          Mean value_function loss: 12.1975
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.2898
                       Mean reward: 26.60
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.6801
    Episode_Reward/rotating_object: 4.7216
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 5.26s
                      Time elapsed: 00:09:47
                               ETA: 02:24:50

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 18289 steps/s (collection: 4.977s, learning 0.398s)
             Mean action noise std: 1.32
          Mean value_function loss: 13.9410
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.3299
                       Mean reward: 40.81
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.6681
    Episode_Reward/rotating_object: 5.9499
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 5.37s
                      Time elapsed: 00:09:52
                               ETA: 02:24:32

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 22534 steps/s (collection: 4.143s, learning 0.219s)
             Mean action noise std: 1.33
          Mean value_function loss: 10.9563
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.3795
                       Mean reward: 30.34
               Mean episode length: 248.80
    Episode_Reward/reaching_object: 0.6847
    Episode_Reward/rotating_object: 6.2440
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 4.36s
                      Time elapsed: 00:09:56
                               ETA: 02:24:00

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 22863 steps/s (collection: 3.969s, learning 0.331s)
             Mean action noise std: 1.33
          Mean value_function loss: 11.7897
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.4414
                       Mean reward: 32.63
               Mean episode length: 245.18
    Episode_Reward/reaching_object: 0.6728
    Episode_Reward/rotating_object: 5.4631
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 4.30s
                      Time elapsed: 00:10:01
                               ETA: 02:23:27

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 20511 steps/s (collection: 4.323s, learning 0.470s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.4709
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.4931
                       Mean reward: 32.90
               Mean episode length: 246.70
    Episode_Reward/reaching_object: 0.6809
    Episode_Reward/rotating_object: 6.3890
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 4.79s
                      Time elapsed: 00:10:06
                               ETA: 02:23:02

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 20177 steps/s (collection: 4.548s, learning 0.324s)
             Mean action noise std: 1.34
          Mean value_function loss: 12.2241
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 37.5423
                       Mean reward: 32.73
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.6770
    Episode_Reward/rotating_object: 5.2567
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 4.87s
                      Time elapsed: 00:10:10
                               ETA: 02:22:38

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 20624 steps/s (collection: 4.417s, learning 0.350s)
             Mean action noise std: 1.34
          Mean value_function loss: 13.0852
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 37.6034
                       Mean reward: 21.46
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 0.6456
    Episode_Reward/rotating_object: 5.4955
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 4.77s
                      Time elapsed: 00:10:15
                               ETA: 02:22:13

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 24300 steps/s (collection: 3.775s, learning 0.270s)
             Mean action noise std: 1.34
          Mean value_function loss: 17.4156
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 37.6535
                       Mean reward: 41.38
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 0.6669
    Episode_Reward/rotating_object: 5.5161
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 4.05s
                      Time elapsed: 00:10:19
                               ETA: 02:21:39

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 20849 steps/s (collection: 4.238s, learning 0.477s)
             Mean action noise std: 1.35
          Mean value_function loss: 17.8052
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 37.7059
                       Mean reward: 27.42
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 0.6483
    Episode_Reward/rotating_object: 5.9734
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 4.71s
                      Time elapsed: 00:10:24
                               ETA: 02:21:15

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 18377 steps/s (collection: 4.960s, learning 0.390s)
             Mean action noise std: 1.35
          Mean value_function loss: 17.9681
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.7579
                       Mean reward: 30.60
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 0.6217
    Episode_Reward/rotating_object: 5.6685
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 5.35s
                      Time elapsed: 00:10:29
                               ETA: 02:20:59

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 19783 steps/s (collection: 4.629s, learning 0.340s)
             Mean action noise std: 1.35
          Mean value_function loss: 15.1982
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.7922
                       Mean reward: 40.93
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 0.6428
    Episode_Reward/rotating_object: 6.1995
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 4.97s
                      Time elapsed: 00:10:34
                               ETA: 02:20:38

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 20439 steps/s (collection: 4.498s, learning 0.311s)
             Mean action noise std: 1.36
          Mean value_function loss: 17.2950
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.8427
                       Mean reward: 54.94
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 0.6288
    Episode_Reward/rotating_object: 7.1425
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 4.81s
                      Time elapsed: 00:10:39
                               ETA: 02:20:16

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 19319 steps/s (collection: 4.723s, learning 0.365s)
             Mean action noise std: 1.36
          Mean value_function loss: 17.2416
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.8907
                       Mean reward: 32.98
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.6573
    Episode_Reward/rotating_object: 7.6989
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 5.09s
                      Time elapsed: 00:10:44
                               ETA: 02:19:58

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 20638 steps/s (collection: 4.390s, learning 0.373s)
             Mean action noise std: 1.36
          Mean value_function loss: 15.1883
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.9417
                       Mean reward: 44.58
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 0.6153
    Episode_Reward/rotating_object: 6.2743
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 4.76s
                      Time elapsed: 00:10:49
                               ETA: 02:19:36

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 18543 steps/s (collection: 4.989s, learning 0.312s)
             Mean action noise std: 1.36
          Mean value_function loss: 13.2005
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.9779
                       Mean reward: 47.38
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 0.6315
    Episode_Reward/rotating_object: 6.7944
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 5.30s
                      Time elapsed: 00:10:54
                               ETA: 02:19:20

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 19744 steps/s (collection: 4.667s, learning 0.312s)
             Mean action noise std: 1.37
          Mean value_function loss: 12.0170
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.0131
                       Mean reward: 35.25
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 0.5899
    Episode_Reward/rotating_object: 6.5036
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 4.98s
                      Time elapsed: 00:10:59
                               ETA: 02:19:01

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 19263 steps/s (collection: 4.773s, learning 0.330s)
             Mean action noise std: 1.37
          Mean value_function loss: 12.6698
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.0644
                       Mean reward: 37.63
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 0.6188
    Episode_Reward/rotating_object: 6.4181
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 5.10s
                      Time elapsed: 00:11:04
                               ETA: 02:18:44

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 18889 steps/s (collection: 4.825s, learning 0.379s)
             Mean action noise std: 1.37
          Mean value_function loss: 12.4684
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 38.1178
                       Mean reward: 30.93
               Mean episode length: 229.42
    Episode_Reward/reaching_object: 0.6114
    Episode_Reward/rotating_object: 6.7924
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 5.20s
                      Time elapsed: 00:11:09
                               ETA: 02:18:29

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 19840 steps/s (collection: 4.585s, learning 0.370s)
             Mean action noise std: 1.38
          Mean value_function loss: 15.9772
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.1818
                       Mean reward: 32.45
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 0.5999
    Episode_Reward/rotating_object: 7.2790
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 4.95s
                      Time elapsed: 00:11:14
                               ETA: 02:18:10

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 19150 steps/s (collection: 4.840s, learning 0.293s)
             Mean action noise std: 1.38
          Mean value_function loss: 16.4534
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.2345
                       Mean reward: 27.76
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 0.5941
    Episode_Reward/rotating_object: 5.5801
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 5.13s
                      Time elapsed: 00:11:20
                               ETA: 02:17:54

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 19764 steps/s (collection: 4.615s, learning 0.359s)
             Mean action noise std: 1.38
          Mean value_function loss: 14.6342
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 38.2905
                       Mean reward: 32.07
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.5836
    Episode_Reward/rotating_object: 5.3449
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 4.97s
                      Time elapsed: 00:11:25
                               ETA: 02:17:36

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 18593 steps/s (collection: 4.885s, learning 0.402s)
             Mean action noise std: 1.39
          Mean value_function loss: 15.4717
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.3448
                       Mean reward: 43.47
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 0.5880
    Episode_Reward/rotating_object: 6.9829
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 5.29s
                      Time elapsed: 00:11:30
                               ETA: 02:17:22

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 17887 steps/s (collection: 5.178s, learning 0.317s)
             Mean action noise std: 1.39
          Mean value_function loss: 15.7183
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.3773
                       Mean reward: 28.40
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 0.5876
    Episode_Reward/rotating_object: 5.8478
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 5.50s
                      Time elapsed: 00:11:35
                               ETA: 02:17:10

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 19293 steps/s (collection: 4.771s, learning 0.325s)
             Mean action noise std: 1.39
          Mean value_function loss: 15.6409
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 38.4095
                       Mean reward: 27.15
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 0.5949
    Episode_Reward/rotating_object: 6.8598
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 5.10s
                      Time elapsed: 00:11:40
                               ETA: 02:16:55

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 18422 steps/s (collection: 4.928s, learning 0.408s)
             Mean action noise std: 1.39
          Mean value_function loss: 15.7629
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.4374
                       Mean reward: 40.27
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 0.5572
    Episode_Reward/rotating_object: 6.5480
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 5.34s
                      Time elapsed: 00:11:46
                               ETA: 02:16:42

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 18489 steps/s (collection: 4.989s, learning 0.328s)
             Mean action noise std: 1.40
          Mean value_function loss: 16.2736
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.4784
                       Mean reward: 30.87
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 0.5693
    Episode_Reward/rotating_object: 5.4214
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 5.32s
                      Time elapsed: 00:11:51
                               ETA: 02:16:29

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 20282 steps/s (collection: 4.581s, learning 0.266s)
             Mean action noise std: 1.40
          Mean value_function loss: 17.2092
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.5271
                       Mean reward: 28.87
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 0.5540
    Episode_Reward/rotating_object: 5.7864
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 4.85s
                      Time elapsed: 00:11:56
                               ETA: 02:16:10

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 19539 steps/s (collection: 4.718s, learning 0.313s)
             Mean action noise std: 1.40
          Mean value_function loss: 15.5529
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.5633
                       Mean reward: 30.59
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.5802
    Episode_Reward/rotating_object: 7.1608
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 5.03s
                      Time elapsed: 00:12:01
                               ETA: 02:15:54

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 19811 steps/s (collection: 4.544s, learning 0.418s)
             Mean action noise std: 1.40
          Mean value_function loss: 17.3222
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 38.6063
                       Mean reward: 47.55
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 0.5822
    Episode_Reward/rotating_object: 7.1756
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 4.96s
                      Time elapsed: 00:12:06
                               ETA: 02:15:38

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 18492 steps/s (collection: 5.001s, learning 0.315s)
             Mean action noise std: 1.40
          Mean value_function loss: 17.8487
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.6389
                       Mean reward: 57.62
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 0.6067
    Episode_Reward/rotating_object: 7.9863
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 5.32s
                      Time elapsed: 00:12:11
                               ETA: 02:15:25

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 17925 steps/s (collection: 5.206s, learning 0.278s)
             Mean action noise std: 1.41
          Mean value_function loss: 21.0084
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.6701
                       Mean reward: 25.31
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 0.5574
    Episode_Reward/rotating_object: 5.6057
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 5.48s
                      Time elapsed: 00:12:17
                               ETA: 02:15:15

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 20720 steps/s (collection: 4.355s, learning 0.389s)
             Mean action noise std: 1.41
          Mean value_function loss: 21.4800
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.7117
                       Mean reward: 26.42
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 0.5906
    Episode_Reward/rotating_object: 6.9333
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 4.74s
                      Time elapsed: 00:12:21
                               ETA: 02:14:56

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 19966 steps/s (collection: 4.571s, learning 0.353s)
             Mean action noise std: 1.41
          Mean value_function loss: 21.0586
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.7622
                       Mean reward: 33.78
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 0.5667
    Episode_Reward/rotating_object: 6.4851
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 4.92s
                      Time elapsed: 00:12:26
                               ETA: 02:14:40

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 21112 steps/s (collection: 4.302s, learning 0.354s)
             Mean action noise std: 1.42
          Mean value_function loss: 22.1057
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 38.8024
                       Mean reward: 45.45
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 0.5779
    Episode_Reward/rotating_object: 6.8719
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 4.66s
                      Time elapsed: 00:12:31
                               ETA: 02:14:21

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 21873 steps/s (collection: 4.176s, learning 0.318s)
             Mean action noise std: 1.42
          Mean value_function loss: 20.8701
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 38.8517
                       Mean reward: 45.38
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 0.6078
    Episode_Reward/rotating_object: 8.6195
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 4.49s
                      Time elapsed: 00:12:36
                               ETA: 02:14:00

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 21960 steps/s (collection: 4.091s, learning 0.386s)
             Mean action noise std: 1.42
          Mean value_function loss: 20.6148
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 38.9097
                       Mean reward: 31.78
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 0.5863
    Episode_Reward/rotating_object: 8.0524
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 4.48s
                      Time elapsed: 00:12:40
                               ETA: 02:13:40

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 19502 steps/s (collection: 4.608s, learning 0.433s)
             Mean action noise std: 1.43
          Mean value_function loss: 18.6854
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 38.9578
                       Mean reward: 44.56
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 0.5880
    Episode_Reward/rotating_object: 8.4899
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 5.04s
                      Time elapsed: 00:12:45
                               ETA: 02:13:26

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 18953 steps/s (collection: 4.836s, learning 0.351s)
             Mean action noise std: 1.43
          Mean value_function loss: 21.2667
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 39.0008
                       Mean reward: 39.51
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.6058
    Episode_Reward/rotating_object: 7.1937
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 5.19s
                      Time elapsed: 00:12:50
                               ETA: 02:13:13

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 19702 steps/s (collection: 4.647s, learning 0.343s)
             Mean action noise std: 1.43
          Mean value_function loss: 17.4026
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 39.0424
                       Mean reward: 38.34
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 0.6327
    Episode_Reward/rotating_object: 8.9282
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 4.99s
                      Time elapsed: 00:12:55
                               ETA: 02:12:58

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 19015 steps/s (collection: 4.779s, learning 0.391s)
             Mean action noise std: 1.43
          Mean value_function loss: 19.5867
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.0824
                       Mean reward: 46.25
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 0.6139
    Episode_Reward/rotating_object: 8.1136
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 5.17s
                      Time elapsed: 00:13:00
                               ETA: 02:12:46

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 20174 steps/s (collection: 4.480s, learning 0.393s)
             Mean action noise std: 1.44
          Mean value_function loss: 19.1896
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 39.1205
                       Mean reward: 47.03
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 0.6478
    Episode_Reward/rotating_object: 8.6179
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 4.87s
                      Time elapsed: 00:13:05
                               ETA: 02:12:30

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 18298 steps/s (collection: 5.028s, learning 0.344s)
             Mean action noise std: 1.44
          Mean value_function loss: 18.8894
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.1647
                       Mean reward: 55.48
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 0.6028
    Episode_Reward/rotating_object: 8.9727
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 5.37s
                      Time elapsed: 00:13:11
                               ETA: 02:12:20

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 18910 steps/s (collection: 4.886s, learning 0.313s)
             Mean action noise std: 1.44
          Mean value_function loss: 20.1202
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.2078
                       Mean reward: 47.02
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.6282
    Episode_Reward/rotating_object: 8.6809
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 5.20s
                      Time elapsed: 00:13:16
                               ETA: 02:12:08

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 22318 steps/s (collection: 4.090s, learning 0.314s)
             Mean action noise std: 1.45
          Mean value_function loss: 19.6269
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.2475
                       Mean reward: 57.03
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 0.6277
    Episode_Reward/rotating_object: 10.0835
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 4.40s
                      Time elapsed: 00:13:20
                               ETA: 02:11:48

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 21908 steps/s (collection: 4.213s, learning 0.274s)
             Mean action noise std: 1.45
          Mean value_function loss: 17.9200
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.2877
                       Mean reward: 48.62
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 0.6273
    Episode_Reward/rotating_object: 8.5170
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 4.49s
                      Time elapsed: 00:13:25
                               ETA: 02:11:30

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 20641 steps/s (collection: 4.336s, learning 0.426s)
             Mean action noise std: 1.45
          Mean value_function loss: 22.0199
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 39.3233
                       Mean reward: 34.26
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 0.6311
    Episode_Reward/rotating_object: 8.8608
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 4.76s
                      Time elapsed: 00:13:29
                               ETA: 02:11:14

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 19887 steps/s (collection: 4.574s, learning 0.369s)
             Mean action noise std: 1.45
          Mean value_function loss: 19.7946
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 39.3546
                       Mean reward: 43.03
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 0.6137
    Episode_Reward/rotating_object: 8.8638
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 4.94s
                      Time elapsed: 00:13:34
                               ETA: 02:11:00

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 20329 steps/s (collection: 4.520s, learning 0.316s)
             Mean action noise std: 1.45
          Mean value_function loss: 15.9888
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 39.3854
                       Mean reward: 78.40
               Mean episode length: 234.19
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 11.1333
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 4.84s
                      Time elapsed: 00:13:39
                               ETA: 02:10:45

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 18901 steps/s (collection: 4.880s, learning 0.321s)
             Mean action noise std: 1.46
          Mean value_function loss: 20.0713
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 39.4133
                       Mean reward: 38.72
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 0.6310
    Episode_Reward/rotating_object: 8.8877
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 5.20s
                      Time elapsed: 00:13:44
                               ETA: 02:10:34

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 18725 steps/s (collection: 4.931s, learning 0.319s)
             Mean action noise std: 1.46
          Mean value_function loss: 22.6129
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.4606
                       Mean reward: 67.60
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 0.6399
    Episode_Reward/rotating_object: 10.1005
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 5.25s
                      Time elapsed: 00:13:50
                               ETA: 02:10:23

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 20080 steps/s (collection: 4.640s, learning 0.256s)
             Mean action noise std: 1.46
          Mean value_function loss: 23.6721
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.5091
                       Mean reward: 51.04
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 0.6425
    Episode_Reward/rotating_object: 9.5400
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 4.90s
                      Time elapsed: 00:13:55
                               ETA: 02:10:09

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 21161 steps/s (collection: 4.298s, learning 0.347s)
             Mean action noise std: 1.47
          Mean value_function loss: 25.4769
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.5539
                       Mean reward: 54.84
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 0.6451
    Episode_Reward/rotating_object: 10.1852
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 4.65s
                      Time elapsed: 00:13:59
                               ETA: 02:09:53

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 19009 steps/s (collection: 4.785s, learning 0.386s)
             Mean action noise std: 1.47
          Mean value_function loss: 25.3520
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 39.5967
                       Mean reward: 64.11
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 0.6416
    Episode_Reward/rotating_object: 10.3581
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 5.17s
                      Time elapsed: 00:14:04
                               ETA: 02:09:42

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 21010 steps/s (collection: 4.294s, learning 0.384s)
             Mean action noise std: 1.47
          Mean value_function loss: 26.3671
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 39.6532
                       Mean reward: 49.88
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 0.6616
    Episode_Reward/rotating_object: 9.9846
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 4.68s
                      Time elapsed: 00:14:09
                               ETA: 02:09:27

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 18230 steps/s (collection: 5.042s, learning 0.350s)
             Mean action noise std: 1.48
          Mean value_function loss: 30.4323
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.7080
                       Mean reward: 74.80
               Mean episode length: 227.72
    Episode_Reward/reaching_object: 0.6713
    Episode_Reward/rotating_object: 11.8569
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 5.39s
                      Time elapsed: 00:14:15
                               ETA: 02:09:18

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 18125 steps/s (collection: 5.139s, learning 0.285s)
             Mean action noise std: 1.48
          Mean value_function loss: 32.8519
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 39.7545
                       Mean reward: 67.04
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 0.6838
    Episode_Reward/rotating_object: 11.0719
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 5.42s
                      Time elapsed: 00:14:20
                               ETA: 02:09:09

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 18397 steps/s (collection: 4.990s, learning 0.353s)
             Mean action noise std: 1.48
          Mean value_function loss: 32.9128
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.7871
                       Mean reward: 70.77
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 0.6910
    Episode_Reward/rotating_object: 11.9518
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 5.34s
                      Time elapsed: 00:14:25
                               ETA: 02:09:00

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 18784 steps/s (collection: 4.904s, learning 0.330s)
             Mean action noise std: 1.48
          Mean value_function loss: 31.3484
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 39.8311
                       Mean reward: 54.22
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 0.6867
    Episode_Reward/rotating_object: 11.4404
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 5.23s
                      Time elapsed: 00:14:31
                               ETA: 02:08:50

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 17815 steps/s (collection: 5.200s, learning 0.318s)
             Mean action noise std: 1.49
          Mean value_function loss: 36.8473
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.8695
                       Mean reward: 65.43
               Mean episode length: 223.65
    Episode_Reward/reaching_object: 0.6726
    Episode_Reward/rotating_object: 13.0868
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 5.52s
                      Time elapsed: 00:14:36
                               ETA: 02:08:42

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 18133 steps/s (collection: 4.966s, learning 0.455s)
             Mean action noise std: 1.49
          Mean value_function loss: 34.2766
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 39.9198
                       Mean reward: 67.80
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 0.6769
    Episode_Reward/rotating_object: 11.9689
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 5.42s
                      Time elapsed: 00:14:41
                               ETA: 02:08:34

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 20711 steps/s (collection: 4.386s, learning 0.361s)
             Mean action noise std: 1.49
          Mean value_function loss: 39.3940
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.9562
                       Mean reward: 53.75
               Mean episode length: 229.34
    Episode_Reward/reaching_object: 0.6744
    Episode_Reward/rotating_object: 10.7555
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 4.75s
                      Time elapsed: 00:14:46
                               ETA: 02:08:19

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 18784 steps/s (collection: 4.875s, learning 0.359s)
             Mean action noise std: 1.50
          Mean value_function loss: 36.8748
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 39.9934
                       Mean reward: 59.61
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 11.8936
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 5.23s
                      Time elapsed: 00:14:51
                               ETA: 02:08:10

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 18996 steps/s (collection: 4.793s, learning 0.382s)
             Mean action noise std: 1.50
          Mean value_function loss: 33.2377
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.0379
                       Mean reward: 63.22
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 0.6888
    Episode_Reward/rotating_object: 12.3776
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 5.17s
                      Time elapsed: 00:14:57
                               ETA: 02:07:59

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 17844 steps/s (collection: 5.122s, learning 0.387s)
             Mean action noise std: 1.50
          Mean value_function loss: 39.2377
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.0760
                       Mean reward: 64.69
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 0.6604
    Episode_Reward/rotating_object: 10.9003
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 5.51s
                      Time elapsed: 00:15:02
                               ETA: 02:07:52

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 18924 steps/s (collection: 4.763s, learning 0.432s)
             Mean action noise std: 1.50
          Mean value_function loss: 36.6435
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 40.1123
                       Mean reward: 83.62
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 0.6924
    Episode_Reward/rotating_object: 12.9881
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 5.19s
                      Time elapsed: 00:15:07
                               ETA: 02:07:42

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 18059 steps/s (collection: 5.124s, learning 0.319s)
             Mean action noise std: 1.51
          Mean value_function loss: 40.0677
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 40.1484
                       Mean reward: 78.98
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 0.7023
    Episode_Reward/rotating_object: 14.5409
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 5.44s
                      Time elapsed: 00:15:13
                               ETA: 02:07:34

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 17774 steps/s (collection: 5.154s, learning 0.376s)
             Mean action noise std: 1.51
          Mean value_function loss: 38.0900
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.1752
                       Mean reward: 77.33
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 0.6921
    Episode_Reward/rotating_object: 12.1447
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 5.53s
                      Time elapsed: 00:15:18
                               ETA: 02:07:26

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 17551 steps/s (collection: 5.314s, learning 0.287s)
             Mean action noise std: 1.51
          Mean value_function loss: 37.2683
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 40.2106
                       Mean reward: 84.29
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 0.7038
    Episode_Reward/rotating_object: 13.6909
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 5.60s
                      Time elapsed: 00:15:24
                               ETA: 02:07:20

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 17276 steps/s (collection: 5.289s, learning 0.401s)
             Mean action noise std: 1.51
          Mean value_function loss: 37.7710
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.2409
                       Mean reward: 62.02
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 15.1582
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 5.69s
                      Time elapsed: 00:15:30
                               ETA: 02:07:14

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 17572 steps/s (collection: 5.204s, learning 0.391s)
             Mean action noise std: 1.51
          Mean value_function loss: 35.7540
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.2679
                       Mean reward: 58.21
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 0.6851
    Episode_Reward/rotating_object: 13.1129
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 5.59s
                      Time elapsed: 00:15:35
                               ETA: 02:07:07

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 16695 steps/s (collection: 5.524s, learning 0.364s)
             Mean action noise std: 1.52
          Mean value_function loss: 35.2244
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 40.2945
                       Mean reward: 60.45
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 0.7083
    Episode_Reward/rotating_object: 11.8004
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 5.89s
                      Time elapsed: 00:15:41
                               ETA: 02:07:03

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 18926 steps/s (collection: 4.786s, learning 0.408s)
             Mean action noise std: 1.52
          Mean value_function loss: 37.2296
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.3194
                       Mean reward: 71.27
               Mean episode length: 237.21
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 12.3686
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 5.19s
                      Time elapsed: 00:15:46
                               ETA: 02:06:53

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 17915 steps/s (collection: 5.105s, learning 0.382s)
             Mean action noise std: 1.52
          Mean value_function loss: 38.4378
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 40.3448
                       Mean reward: 73.53
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 0.6901
    Episode_Reward/rotating_object: 13.6992
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 5.49s
                      Time elapsed: 00:15:52
                               ETA: 02:06:46

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 19899 steps/s (collection: 4.587s, learning 0.353s)
             Mean action noise std: 1.52
          Mean value_function loss: 39.5959
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 40.3662
                       Mean reward: 75.48
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 0.7014
    Episode_Reward/rotating_object: 15.1832
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 4.94s
                      Time elapsed: 00:15:57
                               ETA: 02:06:34

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 19363 steps/s (collection: 4.710s, learning 0.367s)
             Mean action noise std: 1.52
          Mean value_function loss: 35.7075
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.3781
                       Mean reward: 69.90
               Mean episode length: 228.52
    Episode_Reward/reaching_object: 0.6843
    Episode_Reward/rotating_object: 15.3210
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 5.08s
                      Time elapsed: 00:16:02
                               ETA: 02:06:24

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 19746 steps/s (collection: 4.576s, learning 0.402s)
             Mean action noise std: 1.53
          Mean value_function loss: 40.7842
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 40.4101
                       Mean reward: 79.08
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 0.6781
    Episode_Reward/rotating_object: 15.2641
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 4.98s
                      Time elapsed: 00:16:07
                               ETA: 02:06:12

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 18444 steps/s (collection: 4.955s, learning 0.375s)
             Mean action noise std: 1.53
          Mean value_function loss: 43.9447
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 40.4611
                       Mean reward: 88.79
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 0.6672
    Episode_Reward/rotating_object: 14.0125
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 5.33s
                      Time elapsed: 00:16:12
                               ETA: 02:06:04

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 20641 steps/s (collection: 4.405s, learning 0.357s)
             Mean action noise std: 1.53
          Mean value_function loss: 40.3425
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.4974
                       Mean reward: 78.88
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.6764
    Episode_Reward/rotating_object: 15.2111
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 4.76s
                      Time elapsed: 00:16:17
                               ETA: 02:05:51

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 20687 steps/s (collection: 4.419s, learning 0.333s)
             Mean action noise std: 1.53
          Mean value_function loss: 42.5244
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.5290
                       Mean reward: 64.73
               Mean episode length: 222.84
    Episode_Reward/reaching_object: 0.6682
    Episode_Reward/rotating_object: 14.6584
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 4.75s
                      Time elapsed: 00:16:22
                               ETA: 02:05:38

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 17964 steps/s (collection: 5.049s, learning 0.423s)
             Mean action noise std: 1.54
          Mean value_function loss: 39.8777
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 40.5596
                       Mean reward: 90.90
               Mean episode length: 233.48
    Episode_Reward/reaching_object: 0.6626
    Episode_Reward/rotating_object: 16.9732
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 5.47s
                      Time elapsed: 00:16:27
                               ETA: 02:05:31

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 18659 steps/s (collection: 4.936s, learning 0.333s)
             Mean action noise std: 1.54
          Mean value_function loss: 39.1494
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.6038
                       Mean reward: 73.79
               Mean episode length: 234.14
    Episode_Reward/reaching_object: 0.6249
    Episode_Reward/rotating_object: 15.5628
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 5.27s
                      Time elapsed: 00:16:32
                               ETA: 02:05:22

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 19752 steps/s (collection: 4.713s, learning 0.263s)
             Mean action noise std: 1.54
          Mean value_function loss: 37.7050
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.6480
                       Mean reward: 91.34
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 0.6377
    Episode_Reward/rotating_object: 15.0707
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 4.98s
                      Time elapsed: 00:16:37
                               ETA: 02:05:11

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 24300 steps/s (collection: 3.681s, learning 0.364s)
             Mean action noise std: 1.54
          Mean value_function loss: 40.0109
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 40.6805
                       Mean reward: 90.40
               Mean episode length: 229.33
    Episode_Reward/reaching_object: 0.6512
    Episode_Reward/rotating_object: 16.8782
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 4.05s
                      Time elapsed: 00:16:41
                               ETA: 02:04:53

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 22494 steps/s (collection: 4.002s, learning 0.368s)
             Mean action noise std: 1.55
          Mean value_function loss: 40.4346
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 40.7122
                       Mean reward: 89.63
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 0.6546
    Episode_Reward/rotating_object: 19.1748
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 4.37s
                      Time elapsed: 00:16:46
                               ETA: 02:04:38

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 18013 steps/s (collection: 5.044s, learning 0.414s)
             Mean action noise std: 1.55
          Mean value_function loss: 41.9120
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.7429
                       Mean reward: 108.25
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 0.6570
    Episode_Reward/rotating_object: 17.6799
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 5.46s
                      Time elapsed: 00:16:51
                               ETA: 02:04:31

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 19335 steps/s (collection: 4.696s, learning 0.388s)
             Mean action noise std: 1.55
          Mean value_function loss: 40.3268
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 40.7805
                       Mean reward: 67.92
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 0.6018
    Episode_Reward/rotating_object: 16.3834
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 5.08s
                      Time elapsed: 00:16:56
                               ETA: 02:04:21

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 19028 steps/s (collection: 4.796s, learning 0.370s)
             Mean action noise std: 1.55
          Mean value_function loss: 48.6242
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.8184
                       Mean reward: 67.17
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 0.5951
    Episode_Reward/rotating_object: 13.1848
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 5.17s
                      Time elapsed: 00:17:01
                               ETA: 02:04:12

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 18441 steps/s (collection: 5.049s, learning 0.282s)
             Mean action noise std: 1.56
          Mean value_function loss: 49.0152
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.8535
                       Mean reward: 73.04
               Mean episode length: 228.31
    Episode_Reward/reaching_object: 0.5814
    Episode_Reward/rotating_object: 14.5351
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 5.33s
                      Time elapsed: 00:17:07
                               ETA: 02:04:04

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 19997 steps/s (collection: 4.631s, learning 0.285s)
             Mean action noise std: 1.56
          Mean value_function loss: 52.5611
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.8892
                       Mean reward: 79.79
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 0.6377
    Episode_Reward/rotating_object: 16.7840
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 4.92s
                      Time elapsed: 00:17:12
                               ETA: 02:03:53

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 18768 steps/s (collection: 4.896s, learning 0.342s)
             Mean action noise std: 1.56
          Mean value_function loss: 45.7233
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 40.9202
                       Mean reward: 107.04
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 0.6302
    Episode_Reward/rotating_object: 18.4343
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 5.24s
                      Time elapsed: 00:17:17
                               ETA: 02:03:45

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 18603 steps/s (collection: 4.891s, learning 0.393s)
             Mean action noise std: 1.56
          Mean value_function loss: 53.2322
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.9515
                       Mean reward: 88.17
               Mean episode length: 220.74
    Episode_Reward/reaching_object: 0.6121
    Episode_Reward/rotating_object: 16.5801
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 5.28s
                      Time elapsed: 00:17:22
                               ETA: 02:03:37

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 19193 steps/s (collection: 4.759s, learning 0.363s)
             Mean action noise std: 1.56
          Mean value_function loss: 64.6740
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 40.9802
                       Mean reward: 103.73
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 0.6296
    Episode_Reward/rotating_object: 19.3574
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 5.12s
                      Time elapsed: 00:17:27
                               ETA: 02:03:27

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 21095 steps/s (collection: 4.287s, learning 0.373s)
             Mean action noise std: 1.57
          Mean value_function loss: 69.4723
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 41.0063
                       Mean reward: 88.83
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 0.6523
    Episode_Reward/rotating_object: 18.7389
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 4.66s
                      Time elapsed: 00:17:32
                               ETA: 02:03:15

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 21235 steps/s (collection: 4.273s, learning 0.357s)
             Mean action noise std: 1.57
          Mean value_function loss: 54.8173
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 41.0346
                       Mean reward: 100.01
               Mean episode length: 225.78
    Episode_Reward/reaching_object: 0.6700
    Episode_Reward/rotating_object: 18.7316
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 4.63s
                      Time elapsed: 00:17:37
                               ETA: 02:03:02

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 21091 steps/s (collection: 4.369s, learning 0.292s)
             Mean action noise std: 1.57
          Mean value_function loss: 50.8774
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.0669
                       Mean reward: 123.50
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 0.6615
    Episode_Reward/rotating_object: 21.0896
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 4.66s
                      Time elapsed: 00:17:41
                               ETA: 02:02:50

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 19728 steps/s (collection: 4.576s, learning 0.407s)
             Mean action noise std: 1.57
          Mean value_function loss: 55.5087
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 41.1005
                       Mean reward: 91.00
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 0.6741
    Episode_Reward/rotating_object: 19.2573
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 4.98s
                      Time elapsed: 00:17:46
                               ETA: 02:02:40

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 19594 steps/s (collection: 4.702s, learning 0.315s)
             Mean action noise std: 1.58
          Mean value_function loss: 52.2538
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 41.1406
                       Mean reward: 103.44
               Mean episode length: 228.55
    Episode_Reward/reaching_object: 0.6712
    Episode_Reward/rotating_object: 19.4945
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 5.02s
                      Time elapsed: 00:17:51
                               ETA: 02:02:30

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 20878 steps/s (collection: 4.374s, learning 0.335s)
             Mean action noise std: 1.58
          Mean value_function loss: 49.9323
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 41.1689
                       Mean reward: 91.38
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 0.6919
    Episode_Reward/rotating_object: 19.6653
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 4.71s
                      Time elapsed: 00:17:56
                               ETA: 02:02:18

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 19453 steps/s (collection: 4.737s, learning 0.316s)
             Mean action noise std: 1.58
          Mean value_function loss: 50.4936
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 41.1901
                       Mean reward: 77.92
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 18.2391
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 5.05s
                      Time elapsed: 00:18:01
                               ETA: 02:02:09

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 19899 steps/s (collection: 4.597s, learning 0.343s)
             Mean action noise std: 1.58
          Mean value_function loss: 53.5631
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 41.2133
                       Mean reward: 95.07
               Mean episode length: 233.33
    Episode_Reward/reaching_object: 0.6472
    Episode_Reward/rotating_object: 17.7855
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 4.94s
                      Time elapsed: 00:18:06
                               ETA: 02:01:59

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 17696 steps/s (collection: 5.105s, learning 0.450s)
             Mean action noise std: 1.58
          Mean value_function loss: 57.4722
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 41.2526
                       Mean reward: 114.57
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 19.9466
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 5.55s
                      Time elapsed: 00:18:12
                               ETA: 02:01:53

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 19177 steps/s (collection: 4.786s, learning 0.340s)
             Mean action noise std: 1.59
          Mean value_function loss: 65.2432
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 41.2796
                       Mean reward: 101.84
               Mean episode length: 226.92
    Episode_Reward/reaching_object: 0.6486
    Episode_Reward/rotating_object: 18.8062
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 5.13s
                      Time elapsed: 00:18:17
                               ETA: 02:01:44

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 18734 steps/s (collection: 4.908s, learning 0.339s)
             Mean action noise std: 1.59
          Mean value_function loss: 59.9338
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 41.3133
                       Mean reward: 103.52
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 0.6822
    Episode_Reward/rotating_object: 20.6485
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 5.25s
                      Time elapsed: 00:18:22
                               ETA: 02:01:36

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 20452 steps/s (collection: 4.413s, learning 0.393s)
             Mean action noise std: 1.59
          Mean value_function loss: 63.8298
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 41.3534
                       Mean reward: 101.55
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 0.6376
    Episode_Reward/rotating_object: 19.0830
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 4.81s
                      Time elapsed: 00:18:27
                               ETA: 02:01:26

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 19644 steps/s (collection: 4.619s, learning 0.385s)
             Mean action noise std: 1.59
          Mean value_function loss: 62.9082
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 41.3822
                       Mean reward: 122.46
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 0.6868
    Episode_Reward/rotating_object: 22.3665
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 5.00s
                      Time elapsed: 00:18:32
                               ETA: 02:01:16

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 21261 steps/s (collection: 4.264s, learning 0.359s)
             Mean action noise std: 1.60
          Mean value_function loss: 59.8297
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 41.4063
                       Mean reward: 89.95
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 0.6711
    Episode_Reward/rotating_object: 20.4827
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 4.62s
                      Time elapsed: 00:18:36
                               ETA: 02:01:04

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 20590 steps/s (collection: 4.428s, learning 0.346s)
             Mean action noise std: 1.60
          Mean value_function loss: 54.8818
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 41.4300
                       Mean reward: 131.92
               Mean episode length: 226.77
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 21.6624
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 4.77s
                      Time elapsed: 00:18:41
                               ETA: 02:00:54

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 18869 steps/s (collection: 4.881s, learning 0.329s)
             Mean action noise std: 1.60
          Mean value_function loss: 52.9210
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 41.4610
                       Mean reward: 118.23
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 22.2866
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 5.21s
                      Time elapsed: 00:18:46
                               ETA: 02:00:46

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 19544 steps/s (collection: 4.642s, learning 0.388s)
             Mean action noise std: 1.60
          Mean value_function loss: 51.7670
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 41.4929
                       Mean reward: 118.21
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 0.7025
    Episode_Reward/rotating_object: 23.7308
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 5.03s
                      Time elapsed: 00:18:51
                               ETA: 02:00:37

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 19203 steps/s (collection: 4.743s, learning 0.376s)
             Mean action noise std: 1.61
          Mean value_function loss: 59.1124
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.5298
                       Mean reward: 105.12
               Mean episode length: 223.62
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 21.2020
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 5.12s
                      Time elapsed: 00:18:56
                               ETA: 02:00:28

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 18715 steps/s (collection: 4.851s, learning 0.402s)
             Mean action noise std: 1.61
          Mean value_function loss: 56.5654
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.5663
                       Mean reward: 145.16
               Mean episode length: 220.76
    Episode_Reward/reaching_object: 0.6774
    Episode_Reward/rotating_object: 23.7659
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 5.25s
                      Time elapsed: 00:19:02
                               ETA: 02:00:20

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 18498 steps/s (collection: 4.974s, learning 0.340s)
             Mean action noise std: 1.61
          Mean value_function loss: 64.0581
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.5975
                       Mean reward: 135.97
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 0.6907
    Episode_Reward/rotating_object: 24.2606
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 5.31s
                      Time elapsed: 00:19:07
                               ETA: 02:00:13

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 20365 steps/s (collection: 4.416s, learning 0.411s)
             Mean action noise std: 1.61
          Mean value_function loss: 61.6556
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 41.6257
                       Mean reward: 115.82
               Mean episode length: 224.12
    Episode_Reward/reaching_object: 0.6900
    Episode_Reward/rotating_object: 26.6317
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 4.83s
                      Time elapsed: 00:19:12
                               ETA: 02:00:03

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 17493 steps/s (collection: 5.212s, learning 0.408s)
             Mean action noise std: 1.61
          Mean value_function loss: 56.0748
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.6546
                       Mean reward: 114.66
               Mean episode length: 225.29
    Episode_Reward/reaching_object: 0.6929
    Episode_Reward/rotating_object: 22.8428
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 5.62s
                      Time elapsed: 00:19:17
                               ETA: 01:59:58

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 18899 steps/s (collection: 4.912s, learning 0.289s)
             Mean action noise std: 1.62
          Mean value_function loss: 56.2400
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 41.6908
                       Mean reward: 139.69
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 0.6825
    Episode_Reward/rotating_object: 22.2943
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 5.20s
                      Time elapsed: 00:19:23
                               ETA: 01:59:50

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 18747 steps/s (collection: 4.906s, learning 0.338s)
             Mean action noise std: 1.62
          Mean value_function loss: 61.6077
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 41.7225
                       Mean reward: 163.43
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 0.7103
    Episode_Reward/rotating_object: 25.6002
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 5.24s
                      Time elapsed: 00:19:28
                               ETA: 01:59:42

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 17362 steps/s (collection: 5.305s, learning 0.357s)
             Mean action noise std: 1.62
          Mean value_function loss: 59.1732
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 41.7468
                       Mean reward: 129.78
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 0.6982
    Episode_Reward/rotating_object: 25.2697
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 5.66s
                      Time elapsed: 00:19:34
                               ETA: 01:59:37

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 18186 steps/s (collection: 5.075s, learning 0.331s)
             Mean action noise std: 1.62
          Mean value_function loss: 68.4786
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.7656
                       Mean reward: 111.39
               Mean episode length: 222.28
    Episode_Reward/reaching_object: 0.7010
    Episode_Reward/rotating_object: 25.9606
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 5.41s
                      Time elapsed: 00:19:39
                               ETA: 01:59:31

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 18172 steps/s (collection: 5.031s, learning 0.378s)
             Mean action noise std: 1.63
          Mean value_function loss: 58.0619
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 41.7967
                       Mean reward: 120.18
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 24.0683
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 5.41s
                      Time elapsed: 00:19:44
                               ETA: 01:59:24

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 17584 steps/s (collection: 5.310s, learning 0.281s)
             Mean action noise std: 1.63
          Mean value_function loss: 65.0092
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 41.8292
                       Mean reward: 112.66
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 0.6995
    Episode_Reward/rotating_object: 23.8126
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 5.59s
                      Time elapsed: 00:19:50
                               ETA: 01:59:19

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 19421 steps/s (collection: 4.651s, learning 0.410s)
             Mean action noise std: 1.63
          Mean value_function loss: 66.6978
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 41.8558
                       Mean reward: 125.64
               Mean episode length: 220.88
    Episode_Reward/reaching_object: 0.7032
    Episode_Reward/rotating_object: 26.1041
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 5.06s
                      Time elapsed: 00:19:55
                               ETA: 01:59:10

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 17422 steps/s (collection: 5.230s, learning 0.413s)
             Mean action noise std: 1.63
          Mean value_function loss: 69.1328
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 41.8782
                       Mean reward: 135.79
               Mean episode length: 217.28
    Episode_Reward/reaching_object: 0.6637
    Episode_Reward/rotating_object: 24.9974
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 5.64s
                      Time elapsed: 00:20:01
                               ETA: 01:59:05

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 17361 steps/s (collection: 5.270s, learning 0.392s)
             Mean action noise std: 1.63
          Mean value_function loss: 65.0267
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.8996
                       Mean reward: 103.43
               Mean episode length: 221.91
    Episode_Reward/reaching_object: 0.6913
    Episode_Reward/rotating_object: 22.8196
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 5.66s
                      Time elapsed: 00:20:06
                               ETA: 01:59:00

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 17569 steps/s (collection: 5.281s, learning 0.314s)
             Mean action noise std: 1.64
          Mean value_function loss: 62.3421
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 41.9295
                       Mean reward: 122.78
               Mean episode length: 218.32
    Episode_Reward/reaching_object: 0.7121
    Episode_Reward/rotating_object: 27.9701
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 5.60s
                      Time elapsed: 00:20:12
                               ETA: 01:58:55

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 18113 steps/s (collection: 5.078s, learning 0.349s)
             Mean action noise std: 1.64
          Mean value_function loss: 62.4688
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 41.9507
                       Mean reward: 144.30
               Mean episode length: 220.89
    Episode_Reward/reaching_object: 0.6926
    Episode_Reward/rotating_object: 25.5787
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 5.43s
                      Time elapsed: 00:20:17
                               ETA: 01:58:49

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 21016 steps/s (collection: 4.334s, learning 0.344s)
             Mean action noise std: 1.64
          Mean value_function loss: 70.2479
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 41.9641
                       Mean reward: 157.64
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 0.7343
    Episode_Reward/rotating_object: 30.2917
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 4.68s
                      Time elapsed: 00:20:22
                               ETA: 01:58:38

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 19447 steps/s (collection: 4.630s, learning 0.425s)
             Mean action noise std: 1.64
          Mean value_function loss: 64.7016
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 41.9796
                       Mean reward: 158.06
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.7270
    Episode_Reward/rotating_object: 30.4810
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 5.05s
                      Time elapsed: 00:20:27
                               ETA: 01:58:30

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 19271 steps/s (collection: 4.708s, learning 0.393s)
             Mean action noise std: 1.64
          Mean value_function loss: 62.8592
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 41.9961
                       Mean reward: 156.16
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 0.7117
    Episode_Reward/rotating_object: 29.5081
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 5.10s
                      Time elapsed: 00:20:32
                               ETA: 01:58:21

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 20909 steps/s (collection: 4.342s, learning 0.360s)
             Mean action noise std: 1.64
          Mean value_function loss: 68.1104
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.0141
                       Mean reward: 139.63
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 0.7399
    Episode_Reward/rotating_object: 31.1588
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 4.70s
                      Time elapsed: 00:20:37
                               ETA: 01:58:11

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 19546 steps/s (collection: 4.655s, learning 0.374s)
             Mean action noise std: 1.64
          Mean value_function loss: 73.3244
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.0334
                       Mean reward: 145.75
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 0.7119
    Episode_Reward/rotating_object: 27.0998
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 5.03s
                      Time elapsed: 00:20:42
                               ETA: 01:58:02

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 18294 steps/s (collection: 4.978s, learning 0.396s)
             Mean action noise std: 1.64
          Mean value_function loss: 77.2893
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.0547
                       Mean reward: 190.90
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 34.6073
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 5.37s
                      Time elapsed: 00:20:47
                               ETA: 01:57:56

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 19134 steps/s (collection: 4.801s, learning 0.337s)
             Mean action noise std: 1.65
          Mean value_function loss: 68.1149
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 42.0831
                       Mean reward: 197.42
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 0.7636
    Episode_Reward/rotating_object: 34.3244
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 5.14s
                      Time elapsed: 00:20:52
                               ETA: 01:57:48

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 18418 steps/s (collection: 4.890s, learning 0.447s)
             Mean action noise std: 1.65
          Mean value_function loss: 64.4206
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.1072
                       Mean reward: 189.24
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 0.7354
    Episode_Reward/rotating_object: 34.5949
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 5.34s
                      Time elapsed: 00:20:58
                               ETA: 01:57:41

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 17753 steps/s (collection: 5.215s, learning 0.322s)
             Mean action noise std: 1.65
          Mean value_function loss: 70.9961
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.1200
                       Mean reward: 163.33
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 32.9549
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 5.54s
                      Time elapsed: 00:21:03
                               ETA: 01:57:36

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 17606 steps/s (collection: 5.238s, learning 0.345s)
             Mean action noise std: 1.65
          Mean value_function loss: 79.3357
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 42.1269
                       Mean reward: 158.69
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 32.9695
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 5.58s
                      Time elapsed: 00:21:09
                               ETA: 01:57:30

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 18936 steps/s (collection: 4.891s, learning 0.301s)
             Mean action noise std: 1.65
          Mean value_function loss: 92.4300
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.1424
                       Mean reward: 193.85
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 0.7548
    Episode_Reward/rotating_object: 33.7098
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 5.19s
                      Time elapsed: 00:21:14
                               ETA: 01:57:23

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 17688 steps/s (collection: 5.195s, learning 0.362s)
             Mean action noise std: 1.65
          Mean value_function loss: 96.3021
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.1543
                       Mean reward: 176.08
               Mean episode length: 223.58
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 32.8121
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 5.56s
                      Time elapsed: 00:21:20
                               ETA: 01:57:18

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 18952 steps/s (collection: 4.877s, learning 0.310s)
             Mean action noise std: 1.65
          Mean value_function loss: 90.8581
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.1750
                       Mean reward: 182.29
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 0.7772
    Episode_Reward/rotating_object: 34.6402
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 5.19s
                      Time elapsed: 00:21:25
                               ETA: 01:57:10

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 17297 steps/s (collection: 5.327s, learning 0.357s)
             Mean action noise std: 1.66
          Mean value_function loss: 75.1279
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.1927
                       Mean reward: 173.45
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 0.7675
    Episode_Reward/rotating_object: 37.4314
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 5.68s
                      Time elapsed: 00:21:31
                               ETA: 01:57:05

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 20323 steps/s (collection: 4.447s, learning 0.390s)
             Mean action noise std: 1.66
          Mean value_function loss: 80.6128
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.2029
                       Mean reward: 156.37
               Mean episode length: 219.65
    Episode_Reward/reaching_object: 0.7429
    Episode_Reward/rotating_object: 33.5161
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 4.84s
                      Time elapsed: 00:21:35
                               ETA: 01:56:56

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 19414 steps/s (collection: 4.759s, learning 0.304s)
             Mean action noise std: 1.66
          Mean value_function loss: 73.5567
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.2159
                       Mean reward: 156.45
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 0.7583
    Episode_Reward/rotating_object: 34.0703
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 5.06s
                      Time elapsed: 00:21:40
                               ETA: 01:56:48

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 18648 steps/s (collection: 4.868s, learning 0.404s)
             Mean action noise std: 1.66
          Mean value_function loss: 71.7480
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.2318
                       Mean reward: 132.12
               Mean episode length: 214.02
    Episode_Reward/reaching_object: 0.7548
    Episode_Reward/rotating_object: 33.2173
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 5.27s
                      Time elapsed: 00:21:46
                               ETA: 01:56:41

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 18247 steps/s (collection: 5.143s, learning 0.245s)
             Mean action noise std: 1.66
          Mean value_function loss: 72.1508
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.2494
                       Mean reward: 178.18
               Mean episode length: 219.87
    Episode_Reward/reaching_object: 0.7762
    Episode_Reward/rotating_object: 33.6923
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 5.39s
                      Time elapsed: 00:21:51
                               ETA: 01:56:35

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 20710 steps/s (collection: 4.299s, learning 0.447s)
             Mean action noise std: 1.66
          Mean value_function loss: 76.1446
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 42.2639
                       Mean reward: 205.14
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 0.7644
    Episode_Reward/rotating_object: 33.2961
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 4.75s
                      Time elapsed: 00:21:56
                               ETA: 01:56:25

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 19559 steps/s (collection: 4.688s, learning 0.338s)
             Mean action noise std: 1.66
          Mean value_function loss: 75.1888
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 42.2794
                       Mean reward: 174.21
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 0.7864
    Episode_Reward/rotating_object: 35.4887
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 5.03s
                      Time elapsed: 00:22:01
                               ETA: 01:56:17

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 19120 steps/s (collection: 4.864s, learning 0.278s)
             Mean action noise std: 1.66
          Mean value_function loss: 79.0849
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.2993
                       Mean reward: 179.19
               Mean episode length: 226.79
    Episode_Reward/reaching_object: 0.7942
    Episode_Reward/rotating_object: 38.1045
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 5.14s
                      Time elapsed: 00:22:06
                               ETA: 01:56:09

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 19391 steps/s (collection: 4.771s, learning 0.298s)
             Mean action noise std: 1.67
          Mean value_function loss: 70.3115
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.3186
                       Mean reward: 177.27
               Mean episode length: 228.62
    Episode_Reward/reaching_object: 0.7839
    Episode_Reward/rotating_object: 36.7966
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 5.07s
                      Time elapsed: 00:22:11
                               ETA: 01:56:01

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 22139 steps/s (collection: 4.157s, learning 0.283s)
             Mean action noise std: 1.67
          Mean value_function loss: 70.2111
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.3345
                       Mean reward: 204.83
               Mean episode length: 221.16
    Episode_Reward/reaching_object: 0.7776
    Episode_Reward/rotating_object: 36.9942
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 4.44s
                      Time elapsed: 00:22:15
                               ETA: 01:55:50

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 21699 steps/s (collection: 4.209s, learning 0.321s)
             Mean action noise std: 1.67
          Mean value_function loss: 78.8365
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.3536
                       Mean reward: 165.44
               Mean episode length: 216.64
    Episode_Reward/reaching_object: 0.7782
    Episode_Reward/rotating_object: 37.2284
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 4.53s
                      Time elapsed: 00:22:20
                               ETA: 01:55:39

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 18367 steps/s (collection: 4.946s, learning 0.406s)
             Mean action noise std: 1.67
          Mean value_function loss: 76.2069
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.3722
                       Mean reward: 172.16
               Mean episode length: 222.33
    Episode_Reward/reaching_object: 0.7988
    Episode_Reward/rotating_object: 38.9566
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 5.35s
                      Time elapsed: 00:22:25
                               ETA: 01:55:33

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 18800 steps/s (collection: 4.833s, learning 0.396s)
             Mean action noise std: 1.67
          Mean value_function loss: 73.9033
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.3776
                       Mean reward: 183.17
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 0.7954
    Episode_Reward/rotating_object: 38.4202
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 5.23s
                      Time elapsed: 00:22:31
                               ETA: 01:55:26

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 18221 steps/s (collection: 5.033s, learning 0.362s)
             Mean action noise std: 1.67
          Mean value_function loss: 69.6598
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 42.3875
                       Mean reward: 198.72
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 0.7903
    Episode_Reward/rotating_object: 40.1473
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 5.39s
                      Time elapsed: 00:22:36
                               ETA: 01:55:20

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 19771 steps/s (collection: 4.686s, learning 0.286s)
             Mean action noise std: 1.67
          Mean value_function loss: 72.1862
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.4033
                       Mean reward: 197.21
               Mean episode length: 213.79
    Episode_Reward/reaching_object: 0.7780
    Episode_Reward/rotating_object: 39.7627
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 4.97s
                      Time elapsed: 00:22:41
                               ETA: 01:55:12

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 23862 steps/s (collection: 3.791s, learning 0.329s)
             Mean action noise std: 1.67
          Mean value_function loss: 67.8058
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 42.4190
                       Mean reward: 172.86
               Mean episode length: 217.03
    Episode_Reward/reaching_object: 0.7758
    Episode_Reward/rotating_object: 38.2294
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 4.12s
                      Time elapsed: 00:22:45
                               ETA: 01:54:59

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 20948 steps/s (collection: 4.346s, learning 0.346s)
             Mean action noise std: 1.67
          Mean value_function loss: 73.9604
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.4296
                       Mean reward: 236.82
               Mean episode length: 230.83
    Episode_Reward/reaching_object: 0.7681
    Episode_Reward/rotating_object: 38.3860
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 4.69s
                      Time elapsed: 00:22:50
                               ETA: 01:54:49

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 20591 steps/s (collection: 4.368s, learning 0.406s)
             Mean action noise std: 1.68
          Mean value_function loss: 77.4107
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.4428
                       Mean reward: 219.22
               Mean episode length: 224.22
    Episode_Reward/reaching_object: 0.7774
    Episode_Reward/rotating_object: 39.0282
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 4.77s
                      Time elapsed: 00:22:55
                               ETA: 01:54:40

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 20419 steps/s (collection: 4.575s, learning 0.240s)
             Mean action noise std: 1.68
          Mean value_function loss: 83.5184
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.4563
                       Mean reward: 209.32
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 0.7987
    Episode_Reward/rotating_object: 40.2445
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 4.81s
                      Time elapsed: 00:22:59
                               ETA: 01:54:31

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 21161 steps/s (collection: 4.323s, learning 0.323s)
             Mean action noise std: 1.68
          Mean value_function loss: 74.0069
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.4695
                       Mean reward: 211.62
               Mean episode length: 221.95
    Episode_Reward/reaching_object: 0.7908
    Episode_Reward/rotating_object: 41.0960
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 4.65s
                      Time elapsed: 00:23:04
                               ETA: 01:54:22

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 19495 steps/s (collection: 4.724s, learning 0.318s)
             Mean action noise std: 1.68
          Mean value_function loss: 70.5400
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.4778
                       Mean reward: 199.24
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 0.8186
    Episode_Reward/rotating_object: 45.9786
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 5.04s
                      Time elapsed: 00:23:09
                               ETA: 01:54:14

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 18412 steps/s (collection: 4.880s, learning 0.459s)
             Mean action noise std: 1.68
          Mean value_function loss: 67.5413
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.4896
                       Mean reward: 238.24
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 0.8052
    Episode_Reward/rotating_object: 45.7108
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 5.34s
                      Time elapsed: 00:23:14
                               ETA: 01:54:08

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 16116 steps/s (collection: 5.664s, learning 0.436s)
             Mean action noise std: 1.68
          Mean value_function loss: 76.2974
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.5122
                       Mean reward: 217.96
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 0.7868
    Episode_Reward/rotating_object: 41.0436
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 6.10s
                      Time elapsed: 00:23:21
                               ETA: 01:54:05

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 16939 steps/s (collection: 5.427s, learning 0.376s)
             Mean action noise std: 1.68
          Mean value_function loss: 78.9827
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 42.5286
                       Mean reward: 219.67
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 0.8155
    Episode_Reward/rotating_object: 43.4569
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0213
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 5.80s
                      Time elapsed: 00:23:26
                               ETA: 01:54:01

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 17029 steps/s (collection: 5.509s, learning 0.264s)
             Mean action noise std: 1.68
          Mean value_function loss: 75.3996
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 42.5352
                       Mean reward: 265.40
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 0.8192
    Episode_Reward/rotating_object: 47.7412
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 5.77s
                      Time elapsed: 00:23:32
                               ETA: 01:53:57

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 17729 steps/s (collection: 5.149s, learning 0.396s)
             Mean action noise std: 1.68
          Mean value_function loss: 72.1076
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 42.5498
                       Mean reward: 248.81
               Mean episode length: 222.05
    Episode_Reward/reaching_object: 0.7870
    Episode_Reward/rotating_object: 46.0446
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 5.54s
                      Time elapsed: 00:23:38
                               ETA: 01:53:52

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 16956 steps/s (collection: 5.402s, learning 0.395s)
             Mean action noise std: 1.68
          Mean value_function loss: 80.9763
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 42.5623
                       Mean reward: 239.96
               Mean episode length: 219.00
    Episode_Reward/reaching_object: 0.7937
    Episode_Reward/rotating_object: 45.0919
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 5.80s
                      Time elapsed: 00:23:43
                               ETA: 01:53:48

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 16958 steps/s (collection: 5.313s, learning 0.484s)
             Mean action noise std: 1.69
          Mean value_function loss: 70.6326
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.5758
                       Mean reward: 192.56
               Mean episode length: 222.20
    Episode_Reward/reaching_object: 0.7839
    Episode_Reward/rotating_object: 43.5917
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 5.80s
                      Time elapsed: 00:23:49
                               ETA: 01:53:44

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 19293 steps/s (collection: 4.730s, learning 0.366s)
             Mean action noise std: 1.69
          Mean value_function loss: 70.3628
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.5942
                       Mean reward: 213.63
               Mean episode length: 228.20
    Episode_Reward/reaching_object: 0.8025
    Episode_Reward/rotating_object: 46.3584
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 5.10s
                      Time elapsed: 00:23:54
                               ETA: 01:53:36

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 19037 steps/s (collection: 4.744s, learning 0.419s)
             Mean action noise std: 1.69
          Mean value_function loss: 70.2511
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.6110
                       Mean reward: 193.73
               Mean episode length: 213.00
    Episode_Reward/reaching_object: 0.7772
    Episode_Reward/rotating_object: 43.2757
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 5.16s
                      Time elapsed: 00:23:59
                               ETA: 01:53:29

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 19257 steps/s (collection: 4.743s, learning 0.362s)
             Mean action noise std: 1.69
          Mean value_function loss: 79.9365
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.6234
                       Mean reward: 225.25
               Mean episode length: 228.46
    Episode_Reward/reaching_object: 0.7795
    Episode_Reward/rotating_object: 44.3784
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 5.10s
                      Time elapsed: 00:24:05
                               ETA: 01:53:22

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 19380 steps/s (collection: 4.624s, learning 0.448s)
             Mean action noise std: 1.69
          Mean value_function loss: 74.4032
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 42.6366
                       Mean reward: 216.43
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 0.7873
    Episode_Reward/rotating_object: 45.2191
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 5.07s
                      Time elapsed: 00:24:10
                               ETA: 01:53:14

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 19824 steps/s (collection: 4.587s, learning 0.372s)
             Mean action noise std: 1.69
          Mean value_function loss: 77.9101
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 42.6514
                       Mean reward: 211.43
               Mean episode length: 220.35
    Episode_Reward/reaching_object: 0.7770
    Episode_Reward/rotating_object: 42.2641
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 4.96s
                      Time elapsed: 00:24:15
                               ETA: 01:53:06

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 18876 steps/s (collection: 4.820s, learning 0.388s)
             Mean action noise std: 1.69
          Mean value_function loss: 75.1862
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 42.6716
                       Mean reward: 231.58
               Mean episode length: 224.15
    Episode_Reward/reaching_object: 0.7951
    Episode_Reward/rotating_object: 48.9402
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 5.21s
                      Time elapsed: 00:24:20
                               ETA: 01:53:00

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 18765 steps/s (collection: 4.893s, learning 0.346s)
             Mean action noise std: 1.69
          Mean value_function loss: 77.0215
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 42.6889
                       Mean reward: 234.12
               Mean episode length: 214.99
    Episode_Reward/reaching_object: 0.7918
    Episode_Reward/rotating_object: 47.3622
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 5.24s
                      Time elapsed: 00:24:25
                               ETA: 01:52:53

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 19551 steps/s (collection: 4.715s, learning 0.313s)
             Mean action noise std: 1.70
          Mean value_function loss: 73.1320
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 42.6995
                       Mean reward: 199.32
               Mean episode length: 219.79
    Episode_Reward/reaching_object: 0.7760
    Episode_Reward/rotating_object: 45.7428
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 5.03s
                      Time elapsed: 00:24:30
                               ETA: 01:52:45

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 18900 steps/s (collection: 4.850s, learning 0.351s)
             Mean action noise std: 1.70
          Mean value_function loss: 78.6561
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.7189
                       Mean reward: 244.68
               Mean episode length: 222.81
    Episode_Reward/reaching_object: 0.8071
    Episode_Reward/rotating_object: 48.2432
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 5.20s
                      Time elapsed: 00:24:35
                               ETA: 01:52:38

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 18358 steps/s (collection: 5.030s, learning 0.325s)
             Mean action noise std: 1.70
          Mean value_function loss: 76.6671
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.7429
                       Mean reward: 231.36
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 0.7998
    Episode_Reward/rotating_object: 45.7272
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 5.35s
                      Time elapsed: 00:24:41
                               ETA: 01:52:32

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 18063 steps/s (collection: 5.103s, learning 0.339s)
             Mean action noise std: 1.70
          Mean value_function loss: 76.9594
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.7643
                       Mean reward: 277.81
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 0.7916
    Episode_Reward/rotating_object: 51.3884
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 5.44s
                      Time elapsed: 00:24:46
                               ETA: 01:52:27

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 19406 steps/s (collection: 4.734s, learning 0.331s)
             Mean action noise std: 1.70
          Mean value_function loss: 69.1210
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.7826
                       Mean reward: 230.67
               Mean episode length: 221.82
    Episode_Reward/reaching_object: 0.7816
    Episode_Reward/rotating_object: 44.1708
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 5.07s
                      Time elapsed: 00:24:51
                               ETA: 01:52:19

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 20767 steps/s (collection: 4.399s, learning 0.334s)
             Mean action noise std: 1.70
          Mean value_function loss: 69.3650
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 42.7927
                       Mean reward: 226.62
               Mean episode length: 222.46
    Episode_Reward/reaching_object: 0.8295
    Episode_Reward/rotating_object: 50.6995
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 4.73s
                      Time elapsed: 00:24:56
                               ETA: 01:52:10

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 18606 steps/s (collection: 4.809s, learning 0.474s)
             Mean action noise std: 1.70
          Mean value_function loss: 75.7464
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 42.8114
                       Mean reward: 219.43
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 0.8020
    Episode_Reward/rotating_object: 44.9337
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 5.28s
                      Time elapsed: 00:25:01
                               ETA: 01:52:04

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 19184 steps/s (collection: 4.774s, learning 0.350s)
             Mean action noise std: 1.71
          Mean value_function loss: 76.6852
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.8315
                       Mean reward: 240.72
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 0.8174
    Episode_Reward/rotating_object: 48.5113
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 5.12s
                      Time elapsed: 00:25:06
                               ETA: 01:51:57

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 19006 steps/s (collection: 4.858s, learning 0.314s)
             Mean action noise std: 1.71
          Mean value_function loss: 78.1852
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.8446
                       Mean reward: 241.15
               Mean episode length: 218.84
    Episode_Reward/reaching_object: 0.8218
    Episode_Reward/rotating_object: 50.1358
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 5.17s
                      Time elapsed: 00:25:11
                               ETA: 01:51:50

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 19315 steps/s (collection: 4.717s, learning 0.372s)
             Mean action noise std: 1.71
          Mean value_function loss: 80.4428
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 42.8660
                       Mean reward: 226.92
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 0.8333
    Episode_Reward/rotating_object: 46.9345
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 5.09s
                      Time elapsed: 00:25:17
                               ETA: 01:51:43

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 19255 steps/s (collection: 4.724s, learning 0.381s)
             Mean action noise std: 1.71
          Mean value_function loss: 88.1694
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 42.8799
                       Mean reward: 285.85
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 0.8303
    Episode_Reward/rotating_object: 51.9001
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 5.11s
                      Time elapsed: 00:25:22
                               ETA: 01:51:36

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 20498 steps/s (collection: 4.495s, learning 0.301s)
             Mean action noise std: 1.71
          Mean value_function loss: 100.8465
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 42.8976
                       Mean reward: 203.51
               Mean episode length: 223.64
    Episode_Reward/reaching_object: 0.8195
    Episode_Reward/rotating_object: 48.1890
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 4.80s
                      Time elapsed: 00:25:26
                               ETA: 01:51:27

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 20164 steps/s (collection: 4.571s, learning 0.304s)
             Mean action noise std: 1.71
          Mean value_function loss: 85.0596
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.9194
                       Mean reward: 258.33
               Mean episode length: 220.42
    Episode_Reward/reaching_object: 0.8019
    Episode_Reward/rotating_object: 49.1682
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 4.88s
                      Time elapsed: 00:25:31
                               ETA: 01:51:19

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 19464 steps/s (collection: 4.668s, learning 0.382s)
             Mean action noise std: 1.71
          Mean value_function loss: 77.7211
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.9391
                       Mean reward: 273.96
               Mean episode length: 224.26
    Episode_Reward/reaching_object: 0.8292
    Episode_Reward/rotating_object: 50.3757
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 5.05s
                      Time elapsed: 00:25:36
                               ETA: 01:51:12

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 20161 steps/s (collection: 4.560s, learning 0.316s)
             Mean action noise std: 1.72
          Mean value_function loss: 82.4612
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.9498
                       Mean reward: 237.39
               Mean episode length: 222.00
    Episode_Reward/reaching_object: 0.8258
    Episode_Reward/rotating_object: 48.7116
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 4.88s
                      Time elapsed: 00:25:41
                               ETA: 01:51:04

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 18911 steps/s (collection: 4.879s, learning 0.319s)
             Mean action noise std: 1.72
          Mean value_function loss: 78.7088
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.9590
                       Mean reward: 285.44
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 0.8532
    Episode_Reward/rotating_object: 51.7615
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 5.20s
                      Time elapsed: 00:25:46
                               ETA: 01:50:57

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 20441 steps/s (collection: 4.528s, learning 0.281s)
             Mean action noise std: 1.72
          Mean value_function loss: 84.4519
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 42.9724
                       Mean reward: 262.83
               Mean episode length: 224.95
    Episode_Reward/reaching_object: 0.8474
    Episode_Reward/rotating_object: 51.5616
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 4.81s
                      Time elapsed: 00:25:51
                               ETA: 01:50:49

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 20122 steps/s (collection: 4.410s, learning 0.475s)
             Mean action noise std: 1.72
          Mean value_function loss: 70.5363
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 42.9842
                       Mean reward: 243.93
               Mean episode length: 229.53
    Episode_Reward/reaching_object: 0.8419
    Episode_Reward/rotating_object: 53.3754
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 4.89s
                      Time elapsed: 00:25:56
                               ETA: 01:50:41

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 17880 steps/s (collection: 5.148s, learning 0.349s)
             Mean action noise std: 1.72
          Mean value_function loss: 72.8950
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.9973
                       Mean reward: 270.63
               Mean episode length: 222.59
    Episode_Reward/reaching_object: 0.8326
    Episode_Reward/rotating_object: 51.9244
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 5.50s
                      Time elapsed: 00:26:02
                               ETA: 01:50:36

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 17562 steps/s (collection: 5.181s, learning 0.416s)
             Mean action noise std: 1.72
          Mean value_function loss: 73.9123
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.0113
                       Mean reward: 297.47
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 0.8512
    Episode_Reward/rotating_object: 56.3419
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 5.60s
                      Time elapsed: 00:26:07
                               ETA: 01:50:31

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 20831 steps/s (collection: 4.381s, learning 0.338s)
             Mean action noise std: 1.72
          Mean value_function loss: 73.4970
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.0213
                       Mean reward: 286.37
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 0.8224
    Episode_Reward/rotating_object: 53.8512
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 4.72s
                      Time elapsed: 00:26:12
                               ETA: 01:50:22

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 18341 steps/s (collection: 4.937s, learning 0.423s)
             Mean action noise std: 1.72
          Mean value_function loss: 71.0748
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.0374
                       Mean reward: 265.43
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 0.8246
    Episode_Reward/rotating_object: 52.2889
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 5.36s
                      Time elapsed: 00:26:17
                               ETA: 01:50:17

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 19280 steps/s (collection: 4.758s, learning 0.341s)
             Mean action noise std: 1.72
          Mean value_function loss: 78.5929
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 43.0509
                       Mean reward: 201.56
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 0.8193
    Episode_Reward/rotating_object: 50.3739
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 5.10s
                      Time elapsed: 00:26:22
                               ETA: 01:50:10

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 19017 steps/s (collection: 4.742s, learning 0.427s)
             Mean action noise std: 1.72
          Mean value_function loss: 84.4964
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.0605
                       Mean reward: 316.95
               Mean episode length: 226.52
    Episode_Reward/reaching_object: 0.8254
    Episode_Reward/rotating_object: 53.8400
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 5.17s
                      Time elapsed: 00:26:28
                               ETA: 01:50:03

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 20560 steps/s (collection: 4.452s, learning 0.329s)
             Mean action noise std: 1.73
          Mean value_function loss: 84.1944
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.0794
                       Mean reward: 269.52
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 0.8688
    Episode_Reward/rotating_object: 59.0967
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 4.78s
                      Time elapsed: 00:26:32
                               ETA: 01:49:55

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 20424 steps/s (collection: 4.462s, learning 0.351s)
             Mean action noise std: 1.73
          Mean value_function loss: 77.5012
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.0960
                       Mean reward: 278.43
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 0.8490
    Episode_Reward/rotating_object: 56.1479
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 4.81s
                      Time elapsed: 00:26:37
                               ETA: 01:49:47

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 20924 steps/s (collection: 4.344s, learning 0.354s)
             Mean action noise std: 1.73
          Mean value_function loss: 80.1872
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.1075
                       Mean reward: 299.86
               Mean episode length: 239.45
    Episode_Reward/reaching_object: 0.8480
    Episode_Reward/rotating_object: 55.2240
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 4.70s
                      Time elapsed: 00:26:42
                               ETA: 01:49:38

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 18544 steps/s (collection: 4.939s, learning 0.362s)
             Mean action noise std: 1.73
          Mean value_function loss: 87.0236
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.1221
                       Mean reward: 314.05
               Mean episode length: 229.78
    Episode_Reward/reaching_object: 0.8668
    Episode_Reward/rotating_object: 57.2650
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 5.30s
                      Time elapsed: 00:26:47
                               ETA: 01:49:32

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 21435 steps/s (collection: 4.306s, learning 0.280s)
             Mean action noise std: 1.73
          Mean value_function loss: 85.2566
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.1357
                       Mean reward: 272.65
               Mean episode length: 224.32
    Episode_Reward/reaching_object: 0.8818
    Episode_Reward/rotating_object: 57.5976
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 4.59s
                      Time elapsed: 00:26:52
                               ETA: 01:49:23

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 18672 steps/s (collection: 4.828s, learning 0.436s)
             Mean action noise std: 1.73
          Mean value_function loss: 84.8326
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.1503
                       Mean reward: 312.70
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 0.8370
    Episode_Reward/rotating_object: 53.3450
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 5.26s
                      Time elapsed: 00:26:57
                               ETA: 01:49:17

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 18139 steps/s (collection: 5.018s, learning 0.401s)
             Mean action noise std: 1.73
          Mean value_function loss: 87.6699
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.1715
                       Mean reward: 256.12
               Mean episode length: 222.14
    Episode_Reward/reaching_object: 0.8314
    Episode_Reward/rotating_object: 55.0692
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 5.42s
                      Time elapsed: 00:27:02
                               ETA: 01:49:11

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 19279 steps/s (collection: 4.718s, learning 0.381s)
             Mean action noise std: 1.74
          Mean value_function loss: 88.6656
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 43.1892
                       Mean reward: 264.40
               Mean episode length: 217.96
    Episode_Reward/reaching_object: 0.8535
    Episode_Reward/rotating_object: 58.3071
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 5.10s
                      Time elapsed: 00:27:08
                               ETA: 01:49:04

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 19319 steps/s (collection: 4.770s, learning 0.319s)
             Mean action noise std: 1.74
          Mean value_function loss: 83.1616
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.2037
                       Mean reward: 290.26
               Mean episode length: 230.18
    Episode_Reward/reaching_object: 0.8712
    Episode_Reward/rotating_object: 54.8699
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 5.09s
                      Time elapsed: 00:27:13
                               ETA: 01:48:57

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 18439 steps/s (collection: 4.888s, learning 0.443s)
             Mean action noise std: 1.74
          Mean value_function loss: 72.9076
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 43.2162
                       Mean reward: 300.27
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 0.8785
    Episode_Reward/rotating_object: 58.7143
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 5.33s
                      Time elapsed: 00:27:18
                               ETA: 01:48:52

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 16691 steps/s (collection: 5.481s, learning 0.409s)
             Mean action noise std: 1.74
          Mean value_function loss: 78.1637
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.2247
                       Mean reward: 301.03
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 0.8740
    Episode_Reward/rotating_object: 61.5747
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 5.89s
                      Time elapsed: 00:27:24
                               ETA: 01:48:48

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 18333 steps/s (collection: 4.961s, learning 0.401s)
             Mean action noise std: 1.74
          Mean value_function loss: 82.5756
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.2363
                       Mean reward: 292.63
               Mean episode length: 223.66
    Episode_Reward/reaching_object: 0.8478
    Episode_Reward/rotating_object: 59.5939
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 5.36s
                      Time elapsed: 00:27:29
                               ETA: 01:48:42

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 20255 steps/s (collection: 4.464s, learning 0.389s)
             Mean action noise std: 1.74
          Mean value_function loss: 76.6279
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 43.2556
                       Mean reward: 244.39
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 0.8525
    Episode_Reward/rotating_object: 57.4380
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 4.85s
                      Time elapsed: 00:27:34
                               ETA: 01:48:34

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 19656 steps/s (collection: 4.626s, learning 0.375s)
             Mean action noise std: 1.74
          Mean value_function loss: 76.8227
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.2735
                       Mean reward: 315.12
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 0.8929
    Episode_Reward/rotating_object: 64.9264
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 5.00s
                      Time elapsed: 00:27:39
                               ETA: 01:48:27

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 18626 steps/s (collection: 4.885s, learning 0.392s)
             Mean action noise std: 1.74
          Mean value_function loss: 76.9616
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.2916
                       Mean reward: 288.03
               Mean episode length: 228.51
    Episode_Reward/reaching_object: 0.8823
    Episode_Reward/rotating_object: 58.6726
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 5.28s
                      Time elapsed: 00:27:44
                               ETA: 01:48:21

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 18066 steps/s (collection: 5.066s, learning 0.375s)
             Mean action noise std: 1.74
          Mean value_function loss: 79.7129
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.3006
                       Mean reward: 366.51
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 0.8913
    Episode_Reward/rotating_object: 64.1904
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 5.44s
                      Time elapsed: 00:27:50
                               ETA: 01:48:16

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 17673 steps/s (collection: 5.037s, learning 0.525s)
             Mean action noise std: 1.75
          Mean value_function loss: 86.7326
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.3123
                       Mean reward: 339.24
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 0.8860
    Episode_Reward/rotating_object: 62.5258
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 5.56s
                      Time elapsed: 00:27:55
                               ETA: 01:48:11

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 18167 steps/s (collection: 5.070s, learning 0.341s)
             Mean action noise std: 1.75
          Mean value_function loss: 91.0130
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.3277
                       Mean reward: 353.91
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 0.8850
    Episode_Reward/rotating_object: 63.9034
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 5.41s
                      Time elapsed: 00:28:01
                               ETA: 01:48:05

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 18350 steps/s (collection: 4.891s, learning 0.466s)
             Mean action noise std: 1.75
          Mean value_function loss: 93.0248
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.3417
                       Mean reward: 297.49
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 0.8772
    Episode_Reward/rotating_object: 58.4355
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 5.36s
                      Time elapsed: 00:28:06
                               ETA: 01:47:59

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 17720 steps/s (collection: 5.190s, learning 0.357s)
             Mean action noise std: 1.75
          Mean value_function loss: 100.5132
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.3608
                       Mean reward: 292.32
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 0.8821
    Episode_Reward/rotating_object: 62.0338
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 5.55s
                      Time elapsed: 00:28:12
                               ETA: 01:47:54

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 20247 steps/s (collection: 4.535s, learning 0.320s)
             Mean action noise std: 1.75
          Mean value_function loss: 96.2272
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.3763
                       Mean reward: 314.57
               Mean episode length: 221.04
    Episode_Reward/reaching_object: 0.8789
    Episode_Reward/rotating_object: 61.5334
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 4.86s
                      Time elapsed: 00:28:17
                               ETA: 01:47:47

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 19746 steps/s (collection: 4.602s, learning 0.376s)
             Mean action noise std: 1.75
          Mean value_function loss: 86.2165
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.3806
                       Mean reward: 341.20
               Mean episode length: 222.54
    Episode_Reward/reaching_object: 0.8892
    Episode_Reward/rotating_object: 69.6469
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 4.98s
                      Time elapsed: 00:28:22
                               ETA: 01:47:40

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 20383 steps/s (collection: 4.428s, learning 0.395s)
             Mean action noise std: 1.75
          Mean value_function loss: 88.1351
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.3924
                       Mean reward: 314.92
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 0.8569
    Episode_Reward/rotating_object: 61.7780
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 4.82s
                      Time elapsed: 00:28:26
                               ETA: 01:47:32

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 20412 steps/s (collection: 4.495s, learning 0.321s)
             Mean action noise std: 1.75
          Mean value_function loss: 77.4575
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.4131
                       Mean reward: 361.90
               Mean episode length: 230.65
    Episode_Reward/reaching_object: 0.8911
    Episode_Reward/rotating_object: 65.4464
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 4.82s
                      Time elapsed: 00:28:31
                               ETA: 01:47:24

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 20453 steps/s (collection: 4.333s, learning 0.473s)
             Mean action noise std: 1.75
          Mean value_function loss: 80.8746
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.4277
                       Mean reward: 308.09
               Mean episode length: 224.87
    Episode_Reward/reaching_object: 0.8956
    Episode_Reward/rotating_object: 61.7725
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 4.81s
                      Time elapsed: 00:28:36
                               ETA: 01:47:16

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 17404 steps/s (collection: 5.193s, learning 0.456s)
             Mean action noise std: 1.76
          Mean value_function loss: 84.7286
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.4426
                       Mean reward: 300.90
               Mean episode length: 219.38
    Episode_Reward/reaching_object: 0.8518
    Episode_Reward/rotating_object: 59.8951
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 5.65s
                      Time elapsed: 00:28:42
                               ETA: 01:47:12

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 18747 steps/s (collection: 4.883s, learning 0.360s)
             Mean action noise std: 1.76
          Mean value_function loss: 90.9640
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.4547
                       Mean reward: 311.22
               Mean episode length: 213.99
    Episode_Reward/reaching_object: 0.8730
    Episode_Reward/rotating_object: 65.0333
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 5.24s
                      Time elapsed: 00:28:47
                               ETA: 01:47:05

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 16989 steps/s (collection: 5.313s, learning 0.473s)
             Mean action noise std: 1.76
          Mean value_function loss: 85.3139
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.4643
                       Mean reward: 306.93
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 0.8721
    Episode_Reward/rotating_object: 61.8490
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 5.79s
                      Time elapsed: 00:28:53
                               ETA: 01:47:01

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 15712 steps/s (collection: 5.850s, learning 0.406s)
             Mean action noise std: 1.76
          Mean value_function loss: 91.9872
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.4748
                       Mean reward: 359.57
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 0.9134
    Episode_Reward/rotating_object: 70.6982
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 6.26s
                      Time elapsed: 00:28:59
                               ETA: 01:46:59

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 20162 steps/s (collection: 4.754s, learning 0.122s)
             Mean action noise std: 1.76
          Mean value_function loss: 88.9578
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.4862
                       Mean reward: 309.67
               Mean episode length: 211.14
    Episode_Reward/reaching_object: 0.8686
    Episode_Reward/rotating_object: 66.5099
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 4.88s
                      Time elapsed: 00:29:04
                               ETA: 01:46:51

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 44396 steps/s (collection: 2.118s, learning 0.097s)
             Mean action noise std: 1.76
          Mean value_function loss: 89.0157
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.4982
                       Mean reward: 316.45
               Mean episode length: 225.85
    Episode_Reward/reaching_object: 0.8772
    Episode_Reward/rotating_object: 65.6636
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.21s
                      Time elapsed: 00:29:06
                               ETA: 01:46:34

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 48440 steps/s (collection: 1.919s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 86.9120
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.5053
                       Mean reward: 333.37
               Mean episode length: 221.94
    Episode_Reward/reaching_object: 0.8991
    Episode_Reward/rotating_object: 69.1478
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.03s
                      Time elapsed: 00:29:08
                               ETA: 01:46:16

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 48332 steps/s (collection: 1.921s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 89.8692
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.5162
                       Mean reward: 366.35
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 0.9117
    Episode_Reward/rotating_object: 71.9457
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.03s
                      Time elapsed: 00:29:10
                               ETA: 01:45:59

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 47139 steps/s (collection: 1.975s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 78.3559
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.5304
                       Mean reward: 347.38
               Mean episode length: 225.22
    Episode_Reward/reaching_object: 0.9023
    Episode_Reward/rotating_object: 68.9981
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.09s
                      Time elapsed: 00:29:12
                               ETA: 01:45:41

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 48677 steps/s (collection: 1.921s, learning 0.099s)
             Mean action noise std: 1.77
          Mean value_function loss: 78.9129
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.5464
                       Mean reward: 371.82
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 0.9069
    Episode_Reward/rotating_object: 67.0292
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.02s
                      Time elapsed: 00:29:14
                               ETA: 01:45:24

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 45897 steps/s (collection: 2.034s, learning 0.108s)
             Mean action noise std: 1.77
          Mean value_function loss: 80.2099
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.5586
                       Mean reward: 344.58
               Mean episode length: 222.59
    Episode_Reward/reaching_object: 0.9001
    Episode_Reward/rotating_object: 66.4532
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.14s
                      Time elapsed: 00:29:16
                               ETA: 01:45:07

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 48562 steps/s (collection: 1.923s, learning 0.102s)
             Mean action noise std: 1.77
          Mean value_function loss: 77.4561
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 43.5635
                       Mean reward: 370.34
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 0.9072
    Episode_Reward/rotating_object: 69.1572
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.02s
                      Time elapsed: 00:29:18
                               ETA: 01:44:49

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 48500 steps/s (collection: 1.910s, learning 0.117s)
             Mean action noise std: 1.77
          Mean value_function loss: 86.6780
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.5701
                       Mean reward: 359.50
               Mean episode length: 227.98
    Episode_Reward/reaching_object: 0.8989
    Episode_Reward/rotating_object: 69.5209
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.03s
                      Time elapsed: 00:29:20
                               ETA: 01:44:32

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 44190 steps/s (collection: 2.105s, learning 0.120s)
             Mean action noise std: 1.77
          Mean value_function loss: 86.1328
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 43.5798
                       Mean reward: 327.19
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 0.9027
    Episode_Reward/rotating_object: 73.4539
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.22s
                      Time elapsed: 00:29:23
                               ETA: 01:44:16

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 46988 steps/s (collection: 1.972s, learning 0.120s)
             Mean action noise std: 1.77
          Mean value_function loss: 88.3440
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.5947
                       Mean reward: 353.76
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 0.9146
    Episode_Reward/rotating_object: 70.8676
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.09s
                      Time elapsed: 00:29:25
                               ETA: 01:43:59

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 42150 steps/s (collection: 2.129s, learning 0.203s)
             Mean action noise std: 1.77
          Mean value_function loss: 80.3556
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.6052
                       Mean reward: 325.85
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 0.9142
    Episode_Reward/rotating_object: 68.7145
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.33s
                      Time elapsed: 00:29:27
                               ETA: 01:43:43

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 44590 steps/s (collection: 2.065s, learning 0.140s)
             Mean action noise std: 1.77
          Mean value_function loss: 93.6883
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 43.6158
                       Mean reward: 317.68
               Mean episode length: 214.55
    Episode_Reward/reaching_object: 0.8717
    Episode_Reward/rotating_object: 68.0928
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.20s
                      Time elapsed: 00:29:29
                               ETA: 01:43:27

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 16973 steps/s (collection: 5.530s, learning 0.262s)
             Mean action noise std: 1.77
          Mean value_function loss: 98.6886
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.6221
                       Mean reward: 327.02
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 0.9205
    Episode_Reward/rotating_object: 69.0440
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.79s
                      Time elapsed: 00:29:35
                               ETA: 01:43:23

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14363 steps/s (collection: 6.696s, learning 0.148s)
             Mean action noise std: 1.77
          Mean value_function loss: 87.3824
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 43.6316
                       Mean reward: 330.61
               Mean episode length: 212.87
    Episode_Reward/reaching_object: 0.8996
    Episode_Reward/rotating_object: 71.6685
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.84s
                      Time elapsed: 00:29:42
                               ETA: 01:43:23

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14891 steps/s (collection: 6.461s, learning 0.141s)
             Mean action noise std: 1.77
          Mean value_function loss: 95.1239
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.6436
                       Mean reward: 382.46
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 0.9109
    Episode_Reward/rotating_object: 72.7787
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.60s
                      Time elapsed: 00:29:48
                               ETA: 01:43:22

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14615 steps/s (collection: 6.600s, learning 0.126s)
             Mean action noise std: 1.77
          Mean value_function loss: 95.8226
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.6568
                       Mean reward: 369.29
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 0.9272
    Episode_Reward/rotating_object: 71.2321
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.73s
                      Time elapsed: 00:29:55
                               ETA: 01:43:22

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14903 steps/s (collection: 6.465s, learning 0.132s)
             Mean action noise std: 1.78
          Mean value_function loss: 83.9060
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 43.6709
                       Mean reward: 346.47
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 0.9105
    Episode_Reward/rotating_object: 69.1978
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.60s
                      Time elapsed: 00:30:02
                               ETA: 01:43:21

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14927 steps/s (collection: 6.464s, learning 0.121s)
             Mean action noise std: 1.78
          Mean value_function loss: 82.7502
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.6884
                       Mean reward: 355.37
               Mean episode length: 224.93
    Episode_Reward/reaching_object: 0.9265
    Episode_Reward/rotating_object: 72.3069
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.59s
                      Time elapsed: 00:30:08
                               ETA: 01:43:20

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 15011 steps/s (collection: 6.418s, learning 0.130s)
             Mean action noise std: 1.78
          Mean value_function loss: 80.9055
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.7033
                       Mean reward: 381.92
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 0.9377
    Episode_Reward/rotating_object: 77.2317
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.55s
                      Time elapsed: 00:30:15
                               ETA: 01:43:18

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 15165 steps/s (collection: 6.350s, learning 0.133s)
             Mean action noise std: 1.78
          Mean value_function loss: 74.8435
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.7156
                       Mean reward: 387.95
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 0.9051
    Episode_Reward/rotating_object: 74.0767
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.48s
                      Time elapsed: 00:30:21
                               ETA: 01:43:17

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 14573 steps/s (collection: 6.624s, learning 0.121s)
             Mean action noise std: 1.78
          Mean value_function loss: 72.7509
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.7239
                       Mean reward: 341.16
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 0.8959
    Episode_Reward/rotating_object: 70.4173
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 6.75s
                      Time elapsed: 00:30:28
                               ETA: 01:43:16

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 50744 steps/s (collection: 1.822s, learning 0.115s)
             Mean action noise std: 1.78
          Mean value_function loss: 82.0729
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.7348
                       Mean reward: 353.33
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 0.9126
    Episode_Reward/rotating_object: 74.5018
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.94s
                      Time elapsed: 00:30:30
                               ETA: 01:43:00

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 51292 steps/s (collection: 1.820s, learning 0.097s)
             Mean action noise std: 1.78
          Mean value_function loss: 80.9139
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.7468
                       Mean reward: 394.78
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 0.9107
    Episode_Reward/rotating_object: 77.0541
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.92s
                      Time elapsed: 00:30:32
                               ETA: 01:42:43

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 51968 steps/s (collection: 1.798s, learning 0.094s)
             Mean action noise std: 1.78
          Mean value_function loss: 88.8592
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.7571
                       Mean reward: 370.39
               Mean episode length: 225.76
    Episode_Reward/reaching_object: 0.9221
    Episode_Reward/rotating_object: 74.7758
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.89s
                      Time elapsed: 00:30:34
                               ETA: 01:42:26

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 49072 steps/s (collection: 1.881s, learning 0.122s)
             Mean action noise std: 1.78
          Mean value_function loss: 83.2735
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.7665
                       Mean reward: 359.50
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 0.9099
    Episode_Reward/rotating_object: 75.3746
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.00s
                      Time elapsed: 00:30:36
                               ETA: 01:42:10

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 50951 steps/s (collection: 1.813s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 95.4121
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.7793
                       Mean reward: 352.54
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 0.9182
    Episode_Reward/rotating_object: 74.5030
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.93s
                      Time elapsed: 00:30:38
                               ETA: 01:41:53

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 50261 steps/s (collection: 1.837s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 83.0886
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.7908
                       Mean reward: 381.75
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 0.9399
    Episode_Reward/rotating_object: 77.4609
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.96s
                      Time elapsed: 00:30:40
                               ETA: 01:41:37

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 49872 steps/s (collection: 1.860s, learning 0.112s)
             Mean action noise std: 1.79
          Mean value_function loss: 83.5710
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.7988
                       Mean reward: 396.28
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 0.9461
    Episode_Reward/rotating_object: 81.1910
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.97s
                      Time elapsed: 00:30:42
                               ETA: 01:41:20

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 50662 steps/s (collection: 1.833s, learning 0.108s)
             Mean action noise std: 1.79
          Mean value_function loss: 73.6628
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 43.8051
                       Mean reward: 365.95
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 0.9506
    Episode_Reward/rotating_object: 75.5745
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.94s
                      Time elapsed: 00:30:44
                               ETA: 01:41:04

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 51232 steps/s (collection: 1.802s, learning 0.117s)
             Mean action noise std: 1.79
          Mean value_function loss: 83.5886
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 43.8129
                       Mean reward: 462.88
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.9348
    Episode_Reward/rotating_object: 78.2774
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.92s
                      Time elapsed: 00:30:46
                               ETA: 01:40:48

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 48036 steps/s (collection: 1.938s, learning 0.108s)
             Mean action noise std: 1.79
          Mean value_function loss: 80.9908
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.8248
                       Mean reward: 332.89
               Mean episode length: 230.14
    Episode_Reward/reaching_object: 0.9363
    Episode_Reward/rotating_object: 73.2204
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.05s
                      Time elapsed: 00:30:48
                               ETA: 01:40:32

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 50099 steps/s (collection: 1.852s, learning 0.110s)
             Mean action noise std: 1.79
          Mean value_function loss: 82.8004
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 43.8372
                       Mean reward: 371.48
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 0.9421
    Episode_Reward/rotating_object: 80.0847
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.96s
                      Time elapsed: 00:30:50
                               ETA: 01:40:16

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 50585 steps/s (collection: 1.826s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 83.6584
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 43.8503
                       Mean reward: 396.85
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 0.9516
    Episode_Reward/rotating_object: 82.3137
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.94s
                      Time elapsed: 00:30:52
                               ETA: 01:40:00

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 46964 steps/s (collection: 1.970s, learning 0.124s)
             Mean action noise std: 1.79
          Mean value_function loss: 85.9505
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.8654
                       Mean reward: 386.41
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 0.9319
    Episode_Reward/rotating_object: 77.5321
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.09s
                      Time elapsed: 00:30:54
                               ETA: 01:39:45

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 50087 steps/s (collection: 1.840s, learning 0.123s)
             Mean action noise std: 1.79
          Mean value_function loss: 89.4129
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.8762
                       Mean reward: 349.74
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 0.9256
    Episode_Reward/rotating_object: 74.7262
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.96s
                      Time elapsed: 00:30:56
                               ETA: 01:39:29

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 48485 steps/s (collection: 1.914s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 80.1710
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 43.8889
                       Mean reward: 417.15
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.9228
    Episode_Reward/rotating_object: 76.5797
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.03s
                      Time elapsed: 00:30:58
                               ETA: 01:39:14

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 49580 steps/s (collection: 1.871s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 80.3269
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.8990
                       Mean reward: 390.04
               Mean episode length: 222.52
    Episode_Reward/reaching_object: 0.9183
    Episode_Reward/rotating_object: 79.1048
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.98s
                      Time elapsed: 00:31:00
                               ETA: 01:38:58

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 50328 steps/s (collection: 1.847s, learning 0.106s)
             Mean action noise std: 1.80
          Mean value_function loss: 85.8002
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 43.9101
                       Mean reward: 420.62
               Mean episode length: 228.96
    Episode_Reward/reaching_object: 0.9118
    Episode_Reward/rotating_object: 77.4466
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.95s
                      Time elapsed: 00:31:02
                               ETA: 01:38:43

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 48151 steps/s (collection: 1.929s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 84.9581
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.9193
                       Mean reward: 342.86
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 0.9214
    Episode_Reward/rotating_object: 78.4773
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.04s
                      Time elapsed: 00:31:04
                               ETA: 01:38:28

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 49853 steps/s (collection: 1.832s, learning 0.140s)
             Mean action noise std: 1.80
          Mean value_function loss: 85.3104
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.9310
                       Mean reward: 415.41
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 0.9428
    Episode_Reward/rotating_object: 84.5144
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.97s
                      Time elapsed: 00:31:06
                               ETA: 01:38:12

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 49220 steps/s (collection: 1.884s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 84.3057
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.9353
                       Mean reward: 435.64
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 0.9198
    Episode_Reward/rotating_object: 82.3813
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.00s
                      Time elapsed: 00:31:08
                               ETA: 01:37:57

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 48694 steps/s (collection: 1.896s, learning 0.123s)
             Mean action noise std: 1.80
          Mean value_function loss: 84.8524
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 43.9461
                       Mean reward: 387.09
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 0.9390
    Episode_Reward/rotating_object: 81.8542
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.02s
                      Time elapsed: 00:31:10
                               ETA: 01:37:42

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 49805 steps/s (collection: 1.865s, learning 0.109s)
             Mean action noise std: 1.80
          Mean value_function loss: 88.5635
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.9610
                       Mean reward: 398.68
               Mean episode length: 228.95
    Episode_Reward/reaching_object: 0.9233
    Episode_Reward/rotating_object: 79.3573
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.97s
                      Time elapsed: 00:31:12
                               ETA: 01:37:27

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 51146 steps/s (collection: 1.811s, learning 0.111s)
             Mean action noise std: 1.80
          Mean value_function loss: 93.8555
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.9709
                       Mean reward: 450.23
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 0.9304
    Episode_Reward/rotating_object: 81.5594
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.92s
                      Time elapsed: 00:31:13
                               ETA: 01:37:12

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 50649 steps/s (collection: 1.832s, learning 0.109s)
             Mean action noise std: 1.80
          Mean value_function loss: 79.4133
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.9815
                       Mean reward: 412.92
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 0.9269
    Episode_Reward/rotating_object: 79.3122
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.94s
                      Time elapsed: 00:31:15
                               ETA: 01:36:57

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 51033 steps/s (collection: 1.823s, learning 0.103s)
             Mean action noise std: 1.80
          Mean value_function loss: 77.6631
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 43.9939
                       Mean reward: 441.17
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.9584
    Episode_Reward/rotating_object: 85.8517
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.93s
                      Time elapsed: 00:31:17
                               ETA: 01:36:42

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 51586 steps/s (collection: 1.818s, learning 0.088s)
             Mean action noise std: 1.81
          Mean value_function loss: 76.3335
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.0087
                       Mean reward: 393.90
               Mean episode length: 230.75
    Episode_Reward/reaching_object: 0.9327
    Episode_Reward/rotating_object: 79.5608
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.91s
                      Time elapsed: 00:31:19
                               ETA: 01:36:27

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 50859 steps/s (collection: 1.810s, learning 0.123s)
             Mean action noise std: 1.81
          Mean value_function loss: 75.8373
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.0205
                       Mean reward: 386.58
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 0.9147
    Episode_Reward/rotating_object: 81.4466
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.93s
                      Time elapsed: 00:31:21
                               ETA: 01:36:12

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 51403 steps/s (collection: 1.792s, learning 0.121s)
             Mean action noise std: 1.81
          Mean value_function loss: 72.4158
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.0313
                       Mean reward: 443.87
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 0.9337
    Episode_Reward/rotating_object: 83.6321
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.91s
                      Time elapsed: 00:31:23
                               ETA: 01:35:57

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 49378 steps/s (collection: 1.871s, learning 0.120s)
             Mean action noise std: 1.81
          Mean value_function loss: 77.3999
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.0485
                       Mean reward: 431.00
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 0.9248
    Episode_Reward/rotating_object: 82.6929
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.99s
                      Time elapsed: 00:31:25
                               ETA: 01:35:43

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 51132 steps/s (collection: 1.799s, learning 0.124s)
             Mean action noise std: 1.81
          Mean value_function loss: 87.9861
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.0637
                       Mean reward: 435.11
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 0.9286
    Episode_Reward/rotating_object: 83.2282
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.92s
                      Time elapsed: 00:31:27
                               ETA: 01:35:28

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 50911 steps/s (collection: 1.809s, learning 0.122s)
             Mean action noise std: 1.81
          Mean value_function loss: 79.3801
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.0753
                       Mean reward: 371.97
               Mean episode length: 227.72
    Episode_Reward/reaching_object: 0.9348
    Episode_Reward/rotating_object: 85.6729
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.93s
                      Time elapsed: 00:31:29
                               ETA: 01:35:13

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 47330 steps/s (collection: 1.952s, learning 0.125s)
             Mean action noise std: 1.81
          Mean value_function loss: 80.4168
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.0879
                       Mean reward: 416.49
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 0.9131
    Episode_Reward/rotating_object: 80.8932
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.08s
                      Time elapsed: 00:31:31
                               ETA: 01:34:59

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 50664 steps/s (collection: 1.819s, learning 0.121s)
             Mean action noise std: 1.81
          Mean value_function loss: 78.7491
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.0981
                       Mean reward: 417.77
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 0.9028
    Episode_Reward/rotating_object: 80.8359
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.94s
                      Time elapsed: 00:31:33
                               ETA: 01:34:45

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 51333 steps/s (collection: 1.799s, learning 0.116s)
             Mean action noise std: 1.81
          Mean value_function loss: 76.9679
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.1123
                       Mean reward: 497.59
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 0.9464
    Episode_Reward/rotating_object: 87.9606
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.91s
                      Time elapsed: 00:31:35
                               ETA: 01:34:30

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 50068 steps/s (collection: 1.853s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 83.2063
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.1368
                       Mean reward: 414.21
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 0.9409
    Episode_Reward/rotating_object: 87.2386
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.96s
                      Time elapsed: 00:31:37
                               ETA: 01:34:16

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 51158 steps/s (collection: 1.811s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 74.5868
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.1484
                       Mean reward: 449.93
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 0.9329
    Episode_Reward/rotating_object: 87.2415
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.92s
                      Time elapsed: 00:31:39
                               ETA: 01:34:02

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 50630 steps/s (collection: 1.830s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 83.8451
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.1595
                       Mean reward: 392.89
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 0.9249
    Episode_Reward/rotating_object: 82.7645
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.94s
                      Time elapsed: 00:31:41
                               ETA: 01:33:48

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 50887 steps/s (collection: 1.821s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 85.9661
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.1758
                       Mean reward: 452.81
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 0.9605
    Episode_Reward/rotating_object: 89.6261
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.93s
                      Time elapsed: 00:31:43
                               ETA: 01:33:34

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 51275 steps/s (collection: 1.828s, learning 0.090s)
             Mean action noise std: 1.82
          Mean value_function loss: 76.5312
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.1918
                       Mean reward: 431.18
               Mean episode length: 237.74
    Episode_Reward/reaching_object: 0.9422
    Episode_Reward/rotating_object: 86.9008
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.92s
                      Time elapsed: 00:31:45
                               ETA: 01:33:20

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 51077 steps/s (collection: 1.804s, learning 0.120s)
             Mean action noise std: 1.82
          Mean value_function loss: 79.3234
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.2002
                       Mean reward: 440.15
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 0.9248
    Episode_Reward/rotating_object: 85.9671
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.92s
                      Time elapsed: 00:31:46
                               ETA: 01:33:06

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 51881 steps/s (collection: 1.781s, learning 0.114s)
             Mean action noise std: 1.82
          Mean value_function loss: 82.2427
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.2049
                       Mean reward: 468.83
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 0.9299
    Episode_Reward/rotating_object: 87.3549
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.89s
                      Time elapsed: 00:31:48
                               ETA: 01:32:52

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 48262 steps/s (collection: 1.914s, learning 0.123s)
             Mean action noise std: 1.82
          Mean value_function loss: 67.7846
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.2148
                       Mean reward: 455.35
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 0.9424
    Episode_Reward/rotating_object: 88.7549
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.04s
                      Time elapsed: 00:31:50
                               ETA: 01:32:38

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 48691 steps/s (collection: 1.913s, learning 0.106s)
             Mean action noise std: 1.82
          Mean value_function loss: 83.4760
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.2273
                       Mean reward: 445.08
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 0.9328
    Episode_Reward/rotating_object: 86.9710
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.02s
                      Time elapsed: 00:31:52
                               ETA: 01:32:24

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 47678 steps/s (collection: 1.957s, learning 0.105s)
             Mean action noise std: 1.82
          Mean value_function loss: 84.9434
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.2353
                       Mean reward: 409.27
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 0.9324
    Episode_Reward/rotating_object: 87.4512
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.06s
                      Time elapsed: 00:31:54
                               ETA: 01:32:11

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 49321 steps/s (collection: 1.897s, learning 0.097s)
             Mean action noise std: 1.83
          Mean value_function loss: 88.3579
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.2456
                       Mean reward: 453.10
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 0.9437
    Episode_Reward/rotating_object: 87.0222
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.99s
                      Time elapsed: 00:31:56
                               ETA: 01:31:58

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 46092 steps/s (collection: 2.011s, learning 0.122s)
             Mean action noise std: 1.83
          Mean value_function loss: 78.4990
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.2539
                       Mean reward: 438.19
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 0.9322
    Episode_Reward/rotating_object: 80.6476
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.13s
                      Time elapsed: 00:31:59
                               ETA: 01:31:45

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 45591 steps/s (collection: 2.028s, learning 0.129s)
             Mean action noise std: 1.83
          Mean value_function loss: 81.0796
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.2659
                       Mean reward: 422.90
               Mean episode length: 229.11
    Episode_Reward/reaching_object: 0.9423
    Episode_Reward/rotating_object: 82.8113
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.16s
                      Time elapsed: 00:32:01
                               ETA: 01:31:32

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 48110 steps/s (collection: 1.903s, learning 0.141s)
             Mean action noise std: 1.83
          Mean value_function loss: 71.3434
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.2789
                       Mean reward: 420.44
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 0.9554
    Episode_Reward/rotating_object: 84.4764
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.04s
                      Time elapsed: 00:32:03
                               ETA: 01:31:18

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 45638 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 76.8390
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.2907
                       Mean reward: 451.02
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 0.9480
    Episode_Reward/rotating_object: 83.9186
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.15s
                      Time elapsed: 00:32:05
                               ETA: 01:31:06

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 50916 steps/s (collection: 1.813s, learning 0.118s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.7718
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.3088
                       Mean reward: 402.67
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 0.9605
    Episode_Reward/rotating_object: 85.1184
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.93s
                      Time elapsed: 00:32:07
                               ETA: 01:30:52

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 46716 steps/s (collection: 1.974s, learning 0.130s)
             Mean action noise std: 1.83
          Mean value_function loss: 83.4296
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.3216
                       Mean reward: 464.76
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.9655
    Episode_Reward/rotating_object: 88.4267
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.10s
                      Time elapsed: 00:32:09
                               ETA: 01:30:39

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 49697 steps/s (collection: 1.855s, learning 0.124s)
             Mean action noise std: 1.83
          Mean value_function loss: 82.2878
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.3343
                       Mean reward: 446.96
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 0.9481
    Episode_Reward/rotating_object: 88.1954
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.98s
                      Time elapsed: 00:32:11
                               ETA: 01:30:26

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 51023 steps/s (collection: 1.809s, learning 0.118s)
             Mean action noise std: 1.84
          Mean value_function loss: 81.9308
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.3505
                       Mean reward: 449.55
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 0.9535
    Episode_Reward/rotating_object: 87.1504
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.93s
                      Time elapsed: 00:32:13
                               ETA: 01:30:13

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 51378 steps/s (collection: 1.802s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 82.2481
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.3614
                       Mean reward: 426.63
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 0.9619
    Episode_Reward/rotating_object: 88.6575
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.91s
                      Time elapsed: 00:32:15
                               ETA: 01:30:00

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 51431 steps/s (collection: 1.803s, learning 0.108s)
             Mean action noise std: 1.84
          Mean value_function loss: 82.9549
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.3683
                       Mean reward: 446.36
               Mean episode length: 233.96
    Episode_Reward/reaching_object: 0.9702
    Episode_Reward/rotating_object: 87.4194
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.91s
                      Time elapsed: 00:32:17
                               ETA: 01:29:47

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 50952 steps/s (collection: 1.818s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 74.2138
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.3823
                       Mean reward: 513.62
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.9692
    Episode_Reward/rotating_object: 94.7195
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.93s
                      Time elapsed: 00:32:19
                               ETA: 01:29:34

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 50393 steps/s (collection: 1.839s, learning 0.112s)
             Mean action noise std: 1.84
          Mean value_function loss: 70.4135
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3912
                       Mean reward: 513.43
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 0.9690
    Episode_Reward/rotating_object: 90.6450
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.95s
                      Time elapsed: 00:32:21
                               ETA: 01:29:21

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 50654 steps/s (collection: 1.842s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 79.7409
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.4010
                       Mean reward: 456.21
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 0.9553
    Episode_Reward/rotating_object: 88.4503
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.94s
                      Time elapsed: 00:32:23
                               ETA: 01:29:08

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 51256 steps/s (collection: 1.818s, learning 0.100s)
             Mean action noise std: 1.84
          Mean value_function loss: 77.3849
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 44.4153
                       Mean reward: 465.86
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 0.9768
    Episode_Reward/rotating_object: 92.3250
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.92s
                      Time elapsed: 00:32:24
                               ETA: 01:28:55

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 50026 steps/s (collection: 1.858s, learning 0.108s)
             Mean action noise std: 1.84
          Mean value_function loss: 78.9873
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.4259
                       Mean reward: 482.32
               Mean episode length: 240.49
    Episode_Reward/reaching_object: 0.9895
    Episode_Reward/rotating_object: 89.3371
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.97s
                      Time elapsed: 00:32:26
                               ETA: 01:28:42

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 49718 steps/s (collection: 1.847s, learning 0.131s)
             Mean action noise std: 1.84
          Mean value_function loss: 75.1409
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.4417
                       Mean reward: 413.60
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.9582
    Episode_Reward/rotating_object: 88.2374
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.98s
                      Time elapsed: 00:32:28
                               ETA: 01:28:29

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 50237 steps/s (collection: 1.836s, learning 0.121s)
             Mean action noise std: 1.84
          Mean value_function loss: 77.2773
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.4537
                       Mean reward: 434.05
               Mean episode length: 231.14
    Episode_Reward/reaching_object: 0.9735
    Episode_Reward/rotating_object: 88.2266
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.96s
                      Time elapsed: 00:32:30
                               ETA: 01:28:17

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 51272 steps/s (collection: 1.802s, learning 0.116s)
             Mean action noise std: 1.85
          Mean value_function loss: 74.2585
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.4612
                       Mean reward: 466.61
               Mean episode length: 238.31
    Episode_Reward/reaching_object: 0.9638
    Episode_Reward/rotating_object: 86.9950
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.92s
                      Time elapsed: 00:32:32
                               ETA: 01:28:04

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 50915 steps/s (collection: 1.811s, learning 0.120s)
             Mean action noise std: 1.85
          Mean value_function loss: 75.1943
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.4725
                       Mean reward: 469.51
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 0.9766
    Episode_Reward/rotating_object: 92.7062
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.93s
                      Time elapsed: 00:32:34
                               ETA: 01:27:51

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 50642 steps/s (collection: 1.824s, learning 0.118s)
             Mean action noise std: 1.85
          Mean value_function loss: 84.1945
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.4897
                       Mean reward: 448.06
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 0.9625
    Episode_Reward/rotating_object: 90.0702
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.94s
                      Time elapsed: 00:32:36
                               ETA: 01:27:39

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 50701 steps/s (collection: 1.827s, learning 0.112s)
             Mean action noise std: 1.85
          Mean value_function loss: 78.6410
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.5037
                       Mean reward: 456.67
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 0.9559
    Episode_Reward/rotating_object: 89.8271
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.94s
                      Time elapsed: 00:32:38
                               ETA: 01:27:26

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 50254 steps/s (collection: 1.850s, learning 0.107s)
             Mean action noise std: 1.85
          Mean value_function loss: 75.9296
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.5146
                       Mean reward: 446.52
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.9741
    Episode_Reward/rotating_object: 88.4733
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.96s
                      Time elapsed: 00:32:40
                               ETA: 01:27:14

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 51506 steps/s (collection: 1.813s, learning 0.096s)
             Mean action noise std: 1.85
          Mean value_function loss: 67.0871
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.5277
                       Mean reward: 477.54
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 0.9553
    Episode_Reward/rotating_object: 89.1125
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.91s
                      Time elapsed: 00:32:42
                               ETA: 01:27:02

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 50477 steps/s (collection: 1.837s, learning 0.110s)
             Mean action noise std: 1.85
          Mean value_function loss: 78.7385
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.5451
                       Mean reward: 462.49
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 0.9249
    Episode_Reward/rotating_object: 85.3844
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.95s
                      Time elapsed: 00:32:44
                               ETA: 01:26:49

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 51649 steps/s (collection: 1.789s, learning 0.114s)
             Mean action noise std: 1.85
          Mean value_function loss: 79.7436
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.5604
                       Mean reward: 470.88
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 0.9759
    Episode_Reward/rotating_object: 91.1093
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.90s
                      Time elapsed: 00:32:46
                               ETA: 01:26:37

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 51550 steps/s (collection: 1.798s, learning 0.109s)
             Mean action noise std: 1.86
          Mean value_function loss: 78.8366
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.5735
                       Mean reward: 464.68
               Mean episode length: 233.71
    Episode_Reward/reaching_object: 0.9437
    Episode_Reward/rotating_object: 88.1167
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.91s
                      Time elapsed: 00:32:48
                               ETA: 01:26:25

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 49918 steps/s (collection: 1.857s, learning 0.112s)
             Mean action noise std: 1.86
          Mean value_function loss: 87.6846
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.5881
                       Mean reward: 494.33
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 0.9632
    Episode_Reward/rotating_object: 93.2906
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.97s
                      Time elapsed: 00:32:50
                               ETA: 01:26:12

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 51071 steps/s (collection: 1.815s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 79.8459
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.6014
                       Mean reward: 464.26
               Mean episode length: 238.97
    Episode_Reward/reaching_object: 0.9704
    Episode_Reward/rotating_object: 92.5513
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.92s
                      Time elapsed: 00:32:52
                               ETA: 01:26:00

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 51733 steps/s (collection: 1.789s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 88.3878
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.6114
                       Mean reward: 478.72
               Mean episode length: 230.18
    Episode_Reward/reaching_object: 0.9656
    Episode_Reward/rotating_object: 96.9805
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.90s
                      Time elapsed: 00:32:54
                               ETA: 01:25:48

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 50543 steps/s (collection: 1.819s, learning 0.126s)
             Mean action noise std: 1.86
          Mean value_function loss: 87.0081
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.6214
                       Mean reward: 491.43
               Mean episode length: 238.96
    Episode_Reward/reaching_object: 0.9729
    Episode_Reward/rotating_object: 90.9604
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.94s
                      Time elapsed: 00:32:55
                               ETA: 01:25:36

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 51355 steps/s (collection: 1.809s, learning 0.106s)
             Mean action noise std: 1.86
          Mean value_function loss: 85.1842
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 44.6323
                       Mean reward: 470.42
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 0.9664
    Episode_Reward/rotating_object: 92.7917
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.91s
                      Time elapsed: 00:32:57
                               ETA: 01:25:24

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 51209 steps/s (collection: 1.795s, learning 0.125s)
             Mean action noise std: 1.86
          Mean value_function loss: 76.8715
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.6492
                       Mean reward: 488.26
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 0.9633
    Episode_Reward/rotating_object: 91.3642
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.92s
                      Time elapsed: 00:32:59
                               ETA: 01:25:12

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 50387 steps/s (collection: 1.828s, learning 0.123s)
             Mean action noise std: 1.86
          Mean value_function loss: 72.4189
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.6649
                       Mean reward: 507.73
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 0.9893
    Episode_Reward/rotating_object: 96.5133
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.95s
                      Time elapsed: 00:33:01
                               ETA: 01:25:00

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 49525 steps/s (collection: 1.869s, learning 0.116s)
             Mean action noise std: 1.87
          Mean value_function loss: 81.0765
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 44.6859
                       Mean reward: 495.73
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 0.9762
    Episode_Reward/rotating_object: 97.4871
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.98s
                      Time elapsed: 00:33:03
                               ETA: 01:24:48

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 50768 steps/s (collection: 1.822s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 73.1227
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.7030
                       Mean reward: 447.88
               Mean episode length: 237.05
    Episode_Reward/reaching_object: 0.9821
    Episode_Reward/rotating_object: 91.9948
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.94s
                      Time elapsed: 00:33:05
                               ETA: 01:24:37

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 49844 steps/s (collection: 1.855s, learning 0.118s)
             Mean action noise std: 1.87
          Mean value_function loss: 76.9707
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 44.7259
                       Mean reward: 458.59
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 0.9802
    Episode_Reward/rotating_object: 93.1605
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.97s
                      Time elapsed: 00:33:07
                               ETA: 01:24:25

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 48179 steps/s (collection: 1.927s, learning 0.113s)
             Mean action noise std: 1.87
          Mean value_function loss: 71.8601
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.7464
                       Mean reward: 490.33
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 0.9650
    Episode_Reward/rotating_object: 95.5031
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.04s
                      Time elapsed: 00:33:09
                               ETA: 01:24:13

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 50976 steps/s (collection: 1.815s, learning 0.113s)
             Mean action noise std: 1.87
          Mean value_function loss: 76.8900
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 44.7639
                       Mean reward: 447.25
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 0.9603
    Episode_Reward/rotating_object: 91.2785
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.93s
                      Time elapsed: 00:33:11
                               ETA: 01:24:02

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 50404 steps/s (collection: 1.837s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 84.0329
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.7820
                       Mean reward: 501.13
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 0.9739
    Episode_Reward/rotating_object: 98.3428
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.95s
                      Time elapsed: 00:33:13
                               ETA: 01:23:50

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 51548 steps/s (collection: 1.808s, learning 0.099s)
             Mean action noise std: 1.88
          Mean value_function loss: 80.8434
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.7980
                       Mean reward: 484.64
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 0.9534
    Episode_Reward/rotating_object: 92.2062
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.91s
                      Time elapsed: 00:33:15
                               ETA: 01:23:39

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 50722 steps/s (collection: 1.824s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 81.2822
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.8115
                       Mean reward: 488.27
               Mean episode length: 227.87
    Episode_Reward/reaching_object: 0.9637
    Episode_Reward/rotating_object: 93.8140
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.94s
                      Time elapsed: 00:33:17
                               ETA: 01:23:27

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 51155 steps/s (collection: 1.816s, learning 0.106s)
             Mean action noise std: 1.88
          Mean value_function loss: 82.2392
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.8267
                       Mean reward: 472.11
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 0.9644
    Episode_Reward/rotating_object: 91.7854
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.92s
                      Time elapsed: 00:33:19
                               ETA: 01:23:15

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 50879 steps/s (collection: 1.811s, learning 0.122s)
             Mean action noise std: 1.88
          Mean value_function loss: 73.2364
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.8373
                       Mean reward: 455.01
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 92.5644
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.93s
                      Time elapsed: 00:33:21
                               ETA: 01:23:04

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 51110 steps/s (collection: 1.809s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 75.1842
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.8495
                       Mean reward: 477.35
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 0.9784
    Episode_Reward/rotating_object: 98.2226
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.92s
                      Time elapsed: 00:33:23
                               ETA: 01:22:53

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 51158 steps/s (collection: 1.799s, learning 0.123s)
             Mean action noise std: 1.88
          Mean value_function loss: 73.9775
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.8659
                       Mean reward: 474.10
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 0.9693
    Episode_Reward/rotating_object: 92.4610
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.92s
                      Time elapsed: 00:33:25
                               ETA: 01:22:41

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 51297 steps/s (collection: 1.798s, learning 0.119s)
             Mean action noise std: 1.88
          Mean value_function loss: 73.2607
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.8841
                       Mean reward: 486.24
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 0.9788
    Episode_Reward/rotating_object: 94.1516
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.92s
                      Time elapsed: 00:33:27
                               ETA: 01:22:30

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 49801 steps/s (collection: 1.856s, learning 0.118s)
             Mean action noise std: 1.89
          Mean value_function loss: 72.9319
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.9014
                       Mean reward: 489.61
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 0.9711
    Episode_Reward/rotating_object: 96.3820
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.97s
                      Time elapsed: 00:33:28
                               ETA: 01:22:19

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 50685 steps/s (collection: 1.820s, learning 0.119s)
             Mean action noise std: 1.89
          Mean value_function loss: 70.7925
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.9108
                       Mean reward: 447.24
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 0.9682
    Episode_Reward/rotating_object: 89.2076
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.94s
                      Time elapsed: 00:33:30
                               ETA: 01:22:07

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 50947 steps/s (collection: 1.809s, learning 0.121s)
             Mean action noise std: 1.89
          Mean value_function loss: 76.8182
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 44.9245
                       Mean reward: 491.14
               Mean episode length: 238.97
    Episode_Reward/reaching_object: 0.9726
    Episode_Reward/rotating_object: 97.1745
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.93s
                      Time elapsed: 00:33:32
                               ETA: 01:21:56

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 49017 steps/s (collection: 1.889s, learning 0.116s)
             Mean action noise std: 1.89
          Mean value_function loss: 79.5838
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.9555
                       Mean reward: 433.77
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 0.9501
    Episode_Reward/rotating_object: 91.9066
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.01s
                      Time elapsed: 00:33:34
                               ETA: 01:21:45

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 50415 steps/s (collection: 1.836s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 78.7641
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.9806
                       Mean reward: 465.75
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 0.9610
    Episode_Reward/rotating_object: 92.7248
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.95s
                      Time elapsed: 00:33:36
                               ETA: 01:21:34

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 51375 steps/s (collection: 1.809s, learning 0.104s)
             Mean action noise std: 1.89
          Mean value_function loss: 86.7844
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.0058
                       Mean reward: 501.02
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 0.9694
    Episode_Reward/rotating_object: 98.6890
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.91s
                      Time elapsed: 00:33:38
                               ETA: 01:21:23

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 50526 steps/s (collection: 1.829s, learning 0.117s)
             Mean action noise std: 1.90
          Mean value_function loss: 79.4955
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.0240
                       Mean reward: 466.28
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 0.9652
    Episode_Reward/rotating_object: 93.5241
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.95s
                      Time elapsed: 00:33:40
                               ETA: 01:21:12

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 50710 steps/s (collection: 1.824s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 71.1173
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.0421
                       Mean reward: 466.43
               Mean episode length: 233.68
    Episode_Reward/reaching_object: 0.9641
    Episode_Reward/rotating_object: 92.1655
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.94s
                      Time elapsed: 00:33:42
                               ETA: 01:21:01

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 50963 steps/s (collection: 1.816s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 76.3077
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.0603
                       Mean reward: 487.90
               Mean episode length: 236.47
    Episode_Reward/reaching_object: 0.9784
    Episode_Reward/rotating_object: 95.7497
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.93s
                      Time elapsed: 00:33:44
                               ETA: 01:20:50

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 49935 steps/s (collection: 1.875s, learning 0.094s)
             Mean action noise std: 1.90
          Mean value_function loss: 79.1781
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.0720
                       Mean reward: 503.24
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 0.9883
    Episode_Reward/rotating_object: 101.6438
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.97s
                      Time elapsed: 00:33:46
                               ETA: 01:20:39

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 49903 steps/s (collection: 1.879s, learning 0.091s)
             Mean action noise std: 1.90
          Mean value_function loss: 79.3761
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.0841
                       Mean reward: 453.14
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 0.9695
    Episode_Reward/rotating_object: 91.9936
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.97s
                      Time elapsed: 00:33:48
                               ETA: 01:20:29

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 50651 steps/s (collection: 1.848s, learning 0.093s)
             Mean action noise std: 1.90
          Mean value_function loss: 84.1946
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.1053
                       Mean reward: 499.31
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 0.9613
    Episode_Reward/rotating_object: 94.6877
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.94s
                      Time elapsed: 00:33:50
                               ETA: 01:20:18

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 50417 steps/s (collection: 1.857s, learning 0.093s)
             Mean action noise std: 1.91
          Mean value_function loss: 79.1681
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.1325
                       Mean reward: 454.46
               Mean episode length: 225.77
    Episode_Reward/reaching_object: 0.9730
    Episode_Reward/rotating_object: 94.5641
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.95s
                      Time elapsed: 00:33:52
                               ETA: 01:20:07

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 51010 steps/s (collection: 1.826s, learning 0.102s)
             Mean action noise std: 1.91
          Mean value_function loss: 73.3040
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.1531
                       Mean reward: 489.49
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.0031
    Episode_Reward/rotating_object: 101.6542
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.93s
                      Time elapsed: 00:33:54
                               ETA: 01:19:56

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 50583 steps/s (collection: 1.842s, learning 0.102s)
             Mean action noise std: 1.91
          Mean value_function loss: 76.3209
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.1746
                       Mean reward: 512.99
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 0.9840
    Episode_Reward/rotating_object: 97.8611
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.94s
                      Time elapsed: 00:33:56
                               ETA: 01:19:46

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 50331 steps/s (collection: 1.846s, learning 0.107s)
             Mean action noise std: 1.91
          Mean value_function loss: 80.9129
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.1907
                       Mean reward: 476.84
               Mean episode length: 229.92
    Episode_Reward/reaching_object: 0.9912
    Episode_Reward/rotating_object: 98.3913
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.95s
                      Time elapsed: 00:33:58
                               ETA: 01:19:35

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 49910 steps/s (collection: 1.867s, learning 0.103s)
             Mean action noise std: 1.91
          Mean value_function loss: 81.0489
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.2082
                       Mean reward: 519.83
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.0054
    Episode_Reward/rotating_object: 99.8998
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.97s
                      Time elapsed: 00:34:00
                               ETA: 01:19:24

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 50359 steps/s (collection: 1.843s, learning 0.109s)
             Mean action noise std: 1.91
          Mean value_function loss: 76.6993
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.2281
                       Mean reward: 474.38
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.0018
    Episode_Reward/rotating_object: 97.3427
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.95s
                      Time elapsed: 00:34:02
                               ETA: 01:19:14

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 49921 steps/s (collection: 1.860s, learning 0.109s)
             Mean action noise std: 1.92
          Mean value_function loss: 81.4093
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.2485
                       Mean reward: 513.95
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.0004
    Episode_Reward/rotating_object: 101.5516
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.97s
                      Time elapsed: 00:34:04
                               ETA: 01:19:03

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 50956 steps/s (collection: 1.821s, learning 0.109s)
             Mean action noise std: 1.92
          Mean value_function loss: 81.5689
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.2679
                       Mean reward: 505.51
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 0.9831
    Episode_Reward/rotating_object: 96.1662
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.93s
                      Time elapsed: 00:34:06
                               ETA: 01:18:53

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 51446 steps/s (collection: 1.818s, learning 0.093s)
             Mean action noise std: 1.92
          Mean value_function loss: 75.3092
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.2835
                       Mean reward: 513.25
               Mean episode length: 230.31
    Episode_Reward/reaching_object: 0.9954
    Episode_Reward/rotating_object: 97.9396
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.91s
                      Time elapsed: 00:34:07
                               ETA: 01:18:42

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 51241 steps/s (collection: 1.816s, learning 0.103s)
             Mean action noise std: 1.92
          Mean value_function loss: 69.7716
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.2928
                       Mean reward: 499.61
               Mean episode length: 231.26
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 100.7313
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.92s
                      Time elapsed: 00:34:09
                               ETA: 01:18:32

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 49563 steps/s (collection: 1.888s, learning 0.095s)
             Mean action noise std: 1.92
          Mean value_function loss: 77.1084
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.3078
                       Mean reward: 443.24
               Mean episode length: 230.42
    Episode_Reward/reaching_object: 0.9868
    Episode_Reward/rotating_object: 97.8594
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.98s
                      Time elapsed: 00:34:11
                               ETA: 01:18:22

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 49969 steps/s (collection: 1.869s, learning 0.098s)
             Mean action noise std: 1.92
          Mean value_function loss: 65.9364
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.3342
                       Mean reward: 480.36
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 99.5182
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.97s
                      Time elapsed: 00:34:13
                               ETA: 01:18:11

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 51419 steps/s (collection: 1.809s, learning 0.103s)
             Mean action noise std: 1.93
          Mean value_function loss: 70.3926
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.3526
                       Mean reward: 516.85
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.0120
    Episode_Reward/rotating_object: 102.0601
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.91s
                      Time elapsed: 00:34:15
                               ETA: 01:18:01

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 51660 steps/s (collection: 1.793s, learning 0.110s)
             Mean action noise std: 1.93
          Mean value_function loss: 68.9465
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.3757
                       Mean reward: 500.73
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 1.0175
    Episode_Reward/rotating_object: 104.8361
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.90s
                      Time elapsed: 00:34:17
                               ETA: 01:17:51

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 50595 steps/s (collection: 1.828s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 75.3052
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.3938
                       Mean reward: 533.04
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 0.9727
    Episode_Reward/rotating_object: 99.4406
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.94s
                      Time elapsed: 00:34:19
                               ETA: 01:17:40

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 49731 steps/s (collection: 1.863s, learning 0.114s)
             Mean action noise std: 1.93
          Mean value_function loss: 77.4256
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.4079
                       Mean reward: 507.89
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 0.9881
    Episode_Reward/rotating_object: 100.0750
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.98s
                      Time elapsed: 00:34:21
                               ETA: 01:17:30

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 50563 steps/s (collection: 1.830s, learning 0.115s)
             Mean action noise std: 1.93
          Mean value_function loss: 79.6748
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.4247
                       Mean reward: 468.96
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 0.9786
    Episode_Reward/rotating_object: 99.4407
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.94s
                      Time elapsed: 00:34:23
                               ETA: 01:17:20

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 50991 steps/s (collection: 1.811s, learning 0.117s)
             Mean action noise std: 1.93
          Mean value_function loss: 72.0713
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.4428
                       Mean reward: 539.79
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 0.9818
    Episode_Reward/rotating_object: 96.2272
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.93s
                      Time elapsed: 00:34:25
                               ETA: 01:17:10

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 49903 steps/s (collection: 1.854s, learning 0.116s)
             Mean action noise std: 1.94
          Mean value_function loss: 70.6640
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.4616
                       Mean reward: 466.17
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 94.3904
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.97s
                      Time elapsed: 00:34:27
                               ETA: 01:17:00

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 49963 steps/s (collection: 1.847s, learning 0.121s)
             Mean action noise std: 1.94
          Mean value_function loss: 64.9395
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.4799
                       Mean reward: 525.46
               Mean episode length: 238.41
    Episode_Reward/reaching_object: 0.9995
    Episode_Reward/rotating_object: 99.2015
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.97s
                      Time elapsed: 00:34:29
                               ETA: 01:16:50

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 51249 steps/s (collection: 1.796s, learning 0.123s)
             Mean action noise std: 1.94
          Mean value_function loss: 69.6683
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.4965
                       Mean reward: 507.38
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.0034
    Episode_Reward/rotating_object: 102.7223
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.92s
                      Time elapsed: 00:34:31
                               ETA: 01:16:40

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 50082 steps/s (collection: 1.850s, learning 0.113s)
             Mean action noise std: 1.94
          Mean value_function loss: 70.5620
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.5226
                       Mean reward: 518.16
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.0037
    Episode_Reward/rotating_object: 102.9706
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.96s
                      Time elapsed: 00:34:33
                               ETA: 01:16:30

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 50566 steps/s (collection: 1.833s, learning 0.112s)
             Mean action noise std: 1.94
          Mean value_function loss: 69.9056
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.5525
                       Mean reward: 499.14
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 100.9919
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.94s
                      Time elapsed: 00:34:35
                               ETA: 01:16:20

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 49628 steps/s (collection: 1.864s, learning 0.117s)
             Mean action noise std: 1.95
          Mean value_function loss: 68.2827
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.5760
                       Mean reward: 513.24
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.0158
    Episode_Reward/rotating_object: 104.6315
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.98s
                      Time elapsed: 00:34:37
                               ETA: 01:16:10

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 50394 steps/s (collection: 1.820s, learning 0.131s)
             Mean action noise std: 1.95
          Mean value_function loss: 87.7692
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.5864
                       Mean reward: 473.05
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 0.9966
    Episode_Reward/rotating_object: 100.1861
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.95s
                      Time elapsed: 00:34:39
                               ETA: 01:16:00

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 50995 steps/s (collection: 1.819s, learning 0.109s)
             Mean action noise std: 1.95
          Mean value_function loss: 76.8554
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.5959
                       Mean reward: 509.62
               Mean episode length: 234.33
    Episode_Reward/reaching_object: 1.0095
    Episode_Reward/rotating_object: 102.2909
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.93s
                      Time elapsed: 00:34:41
                               ETA: 01:15:50

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 50341 steps/s (collection: 1.839s, learning 0.114s)
             Mean action noise std: 1.95
          Mean value_function loss: 75.8584
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.6161
                       Mean reward: 477.74
               Mean episode length: 226.17
    Episode_Reward/reaching_object: 0.9704
    Episode_Reward/rotating_object: 96.1535
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.95s
                      Time elapsed: 00:34:42
                               ETA: 01:15:41

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 50299 steps/s (collection: 1.850s, learning 0.104s)
             Mean action noise std: 1.95
          Mean value_function loss: 73.1929
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 45.6354
                       Mean reward: 552.53
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.0109
    Episode_Reward/rotating_object: 106.1687
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.95s
                      Time elapsed: 00:34:44
                               ETA: 01:15:31

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 49806 steps/s (collection: 1.859s, learning 0.115s)
             Mean action noise std: 1.96
          Mean value_function loss: 72.8390
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.6600
                       Mean reward: 540.68
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.0135
    Episode_Reward/rotating_object: 104.4282
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.97s
                      Time elapsed: 00:34:46
                               ETA: 01:15:21

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 50814 steps/s (collection: 1.823s, learning 0.112s)
             Mean action noise std: 1.96
          Mean value_function loss: 72.5990
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.6862
                       Mean reward: 484.71
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 0.9942
    Episode_Reward/rotating_object: 99.3302
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.93s
                      Time elapsed: 00:34:48
                               ETA: 01:15:11

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 50728 steps/s (collection: 1.827s, learning 0.111s)
             Mean action noise std: 1.96
          Mean value_function loss: 73.8701
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.7120
                       Mean reward: 530.36
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 0.9919
    Episode_Reward/rotating_object: 103.2086
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.94s
                      Time elapsed: 00:34:50
                               ETA: 01:15:02

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 50731 steps/s (collection: 1.829s, learning 0.109s)
             Mean action noise std: 1.96
          Mean value_function loss: 70.5035
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.7370
                       Mean reward: 587.88
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 1.0147
    Episode_Reward/rotating_object: 106.5042
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.94s
                      Time elapsed: 00:34:52
                               ETA: 01:14:52

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 51584 steps/s (collection: 1.803s, learning 0.103s)
             Mean action noise std: 1.96
          Mean value_function loss: 75.2623
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.7581
                       Mean reward: 500.22
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 1.0067
    Episode_Reward/rotating_object: 102.9851
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.91s
                      Time elapsed: 00:34:54
                               ETA: 01:14:42

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 51012 steps/s (collection: 1.796s, learning 0.131s)
             Mean action noise std: 1.97
          Mean value_function loss: 70.8588
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.7745
                       Mean reward: 506.00
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 0.9700
    Episode_Reward/rotating_object: 96.0167
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.93s
                      Time elapsed: 00:34:56
                               ETA: 01:14:33

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 51201 steps/s (collection: 1.797s, learning 0.123s)
             Mean action noise std: 1.97
          Mean value_function loss: 69.1793
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.7938
                       Mean reward: 512.70
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.0040
    Episode_Reward/rotating_object: 99.7329
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.92s
                      Time elapsed: 00:34:58
                               ETA: 01:14:23

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 50813 steps/s (collection: 1.817s, learning 0.118s)
             Mean action noise std: 1.97
          Mean value_function loss: 82.1683
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.8182
                       Mean reward: 537.34
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.0088
    Episode_Reward/rotating_object: 103.4557
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.93s
                      Time elapsed: 00:35:00
                               ETA: 01:14:14

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 50936 steps/s (collection: 1.816s, learning 0.114s)
             Mean action noise std: 1.97
          Mean value_function loss: 68.6841
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.8414
                       Mean reward: 506.23
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 0.9844
    Episode_Reward/rotating_object: 101.6500
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.93s
                      Time elapsed: 00:35:02
                               ETA: 01:14:04

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 49928 steps/s (collection: 1.848s, learning 0.121s)
             Mean action noise std: 1.98
          Mean value_function loss: 65.9525
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.8721
                       Mean reward: 498.53
               Mean episode length: 231.24
    Episode_Reward/reaching_object: 0.9895
    Episode_Reward/rotating_object: 104.1179
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.97s
                      Time elapsed: 00:35:04
                               ETA: 01:13:55

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 49918 steps/s (collection: 1.851s, learning 0.119s)
             Mean action noise std: 1.98
          Mean value_function loss: 76.6515
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.8881
                       Mean reward: 540.37
               Mean episode length: 237.45
    Episode_Reward/reaching_object: 0.9986
    Episode_Reward/rotating_object: 103.4018
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.97s
                      Time elapsed: 00:35:06
                               ETA: 01:13:45

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 50184 steps/s (collection: 1.831s, learning 0.128s)
             Mean action noise std: 1.98
          Mean value_function loss: 77.5970
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.9007
                       Mean reward: 546.63
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.0052
    Episode_Reward/rotating_object: 110.5561
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.96s
                      Time elapsed: 00:35:08
                               ETA: 01:13:36

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 49736 steps/s (collection: 1.857s, learning 0.120s)
             Mean action noise std: 1.98
          Mean value_function loss: 73.8833
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.9285
                       Mean reward: 553.63
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 1.0019
    Episode_Reward/rotating_object: 105.6287
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.98s
                      Time elapsed: 00:35:10
                               ETA: 01:13:27

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 50191 steps/s (collection: 1.838s, learning 0.120s)
             Mean action noise std: 1.98
          Mean value_function loss: 75.4815
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.9607
                       Mean reward: 533.64
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 0.9798
    Episode_Reward/rotating_object: 100.4494
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.96s
                      Time elapsed: 00:35:12
                               ETA: 01:13:17

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 47607 steps/s (collection: 1.945s, learning 0.120s)
             Mean action noise std: 1.99
          Mean value_function loss: 71.7619
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.9860
                       Mean reward: 521.33
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 1.0067
    Episode_Reward/rotating_object: 104.9100
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.06s
                      Time elapsed: 00:35:14
                               ETA: 01:13:08

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 49874 steps/s (collection: 1.862s, learning 0.109s)
             Mean action noise std: 1.99
          Mean value_function loss: 71.6695
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.0008
                       Mean reward: 540.80
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.0319
    Episode_Reward/rotating_object: 108.2833
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.97s
                      Time elapsed: 00:35:16
                               ETA: 01:12:59

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 50706 steps/s (collection: 1.830s, learning 0.109s)
             Mean action noise std: 1.99
          Mean value_function loss: 77.1922
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.0233
                       Mean reward: 500.35
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 0.9975
    Episode_Reward/rotating_object: 99.6379
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.94s
                      Time elapsed: 00:35:18
                               ETA: 01:12:50

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 50307 steps/s (collection: 1.841s, learning 0.113s)
             Mean action noise std: 1.99
          Mean value_function loss: 69.5064
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.0507
                       Mean reward: 551.12
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.0168
    Episode_Reward/rotating_object: 109.4745
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.95s
                      Time elapsed: 00:35:20
                               ETA: 01:12:41

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 50789 steps/s (collection: 1.827s, learning 0.109s)
             Mean action noise std: 1.99
          Mean value_function loss: 70.8549
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 46.0741
                       Mean reward: 534.08
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.0367
    Episode_Reward/rotating_object: 112.0170
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.94s
                      Time elapsed: 00:35:22
                               ETA: 01:12:31

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 50730 steps/s (collection: 1.830s, learning 0.108s)
             Mean action noise std: 2.00
          Mean value_function loss: 68.5770
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.1059
                       Mean reward: 500.07
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 1.0028
    Episode_Reward/rotating_object: 108.8017
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.94s
                      Time elapsed: 00:35:23
                               ETA: 01:12:22

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 49431 steps/s (collection: 1.873s, learning 0.116s)
             Mean action noise std: 2.00
          Mean value_function loss: 77.1616
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.1301
                       Mean reward: 531.28
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 0.9885
    Episode_Reward/rotating_object: 102.3040
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.99s
                      Time elapsed: 00:35:25
                               ETA: 01:12:13

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 48598 steps/s (collection: 1.896s, learning 0.127s)
             Mean action noise std: 2.00
          Mean value_function loss: 70.9640
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 46.1503
                       Mean reward: 553.47
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 1.0060
    Episode_Reward/rotating_object: 103.9415
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.02s
                      Time elapsed: 00:35:27
                               ETA: 01:12:04

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 49573 steps/s (collection: 1.865s, learning 0.118s)
             Mean action noise std: 2.00
          Mean value_function loss: 70.3534
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.1632
                       Mean reward: 528.65
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.0043
    Episode_Reward/rotating_object: 104.9127
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.98s
                      Time elapsed: 00:35:29
                               ETA: 01:11:55

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 49973 steps/s (collection: 1.857s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 67.4200
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.1769
                       Mean reward: 565.99
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.0106
    Episode_Reward/rotating_object: 106.7297
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.97s
                      Time elapsed: 00:35:31
                               ETA: 01:11:46

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 50164 steps/s (collection: 1.842s, learning 0.118s)
             Mean action noise std: 2.01
          Mean value_function loss: 67.1597
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.1874
                       Mean reward: 504.87
               Mean episode length: 235.17
    Episode_Reward/reaching_object: 0.9962
    Episode_Reward/rotating_object: 104.4443
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.96s
                      Time elapsed: 00:35:33
                               ETA: 01:11:37

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 48990 steps/s (collection: 1.901s, learning 0.106s)
             Mean action noise std: 2.01
          Mean value_function loss: 70.8293
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.2063
                       Mean reward: 523.11
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.0075
    Episode_Reward/rotating_object: 102.4162
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.01s
                      Time elapsed: 00:35:35
                               ETA: 01:11:28

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 49848 steps/s (collection: 1.861s, learning 0.111s)
             Mean action noise std: 2.01
          Mean value_function loss: 68.5254
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 46.2305
                       Mean reward: 503.54
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.0183
    Episode_Reward/rotating_object: 106.7921
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.97s
                      Time elapsed: 00:35:37
                               ETA: 01:11:19

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 50678 steps/s (collection: 1.833s, learning 0.107s)
             Mean action noise std: 2.01
          Mean value_function loss: 71.5524
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.2526
                       Mean reward: 550.55
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 1.0252
    Episode_Reward/rotating_object: 108.2812
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.94s
                      Time elapsed: 00:35:39
                               ETA: 01:11:11

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 49897 steps/s (collection: 1.863s, learning 0.107s)
             Mean action noise std: 2.02
          Mean value_function loss: 66.7386
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.2809
                       Mean reward: 521.80
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0106
    Episode_Reward/rotating_object: 104.9311
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.97s
                      Time elapsed: 00:35:41
                               ETA: 01:11:02

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 48634 steps/s (collection: 1.924s, learning 0.098s)
             Mean action noise std: 2.02
          Mean value_function loss: 67.4288
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.3170
                       Mean reward: 495.98
               Mean episode length: 222.18
    Episode_Reward/reaching_object: 0.9974
    Episode_Reward/rotating_object: 102.6107
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.02s
                      Time elapsed: 00:35:43
                               ETA: 01:10:53

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 50235 steps/s (collection: 1.831s, learning 0.126s)
             Mean action noise std: 2.02
          Mean value_function loss: 71.8287
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 46.3352
                       Mean reward: 512.58
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 1.0195
    Episode_Reward/rotating_object: 107.0217
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.96s
                      Time elapsed: 00:35:45
                               ETA: 01:10:44

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 47026 steps/s (collection: 1.970s, learning 0.121s)
             Mean action noise std: 2.02
          Mean value_function loss: 76.1800
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 46.3564
                       Mean reward: 549.23
               Mean episode length: 233.13
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 107.9899
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.09s
                      Time elapsed: 00:35:47
                               ETA: 01:10:36

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 48485 steps/s (collection: 1.908s, learning 0.119s)
             Mean action noise std: 2.03
          Mean value_function loss: 69.8030
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.3931
                       Mean reward: 554.82
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 112.0378
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.03s
                      Time elapsed: 00:35:49
                               ETA: 01:10:27

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 50272 steps/s (collection: 1.858s, learning 0.098s)
             Mean action noise std: 2.03
          Mean value_function loss: 70.9478
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.4238
                       Mean reward: 534.09
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 0.9774
    Episode_Reward/rotating_object: 105.2597
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.96s
                      Time elapsed: 00:35:51
                               ETA: 01:10:18

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 50431 steps/s (collection: 1.834s, learning 0.115s)
             Mean action noise std: 2.03
          Mean value_function loss: 68.6910
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.4478
                       Mean reward: 529.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0291
    Episode_Reward/rotating_object: 106.0913
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.95s
                      Time elapsed: 00:35:53
                               ETA: 01:10:10

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 49920 steps/s (collection: 1.858s, learning 0.112s)
             Mean action noise std: 2.03
          Mean value_function loss: 68.1565
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.4763
                       Mean reward: 546.15
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 0.9990
    Episode_Reward/rotating_object: 104.4231
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.97s
                      Time elapsed: 00:35:55
                               ETA: 01:10:01

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 50052 steps/s (collection: 1.850s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 72.3952
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.5071
                       Mean reward: 545.20
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.9948
    Episode_Reward/rotating_object: 103.9305
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.96s
                      Time elapsed: 00:35:57
                               ETA: 01:09:52

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 50074 steps/s (collection: 1.849s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 68.6670
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.5207
                       Mean reward: 523.20
               Mean episode length: 239.66
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 103.0009
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.96s
                      Time elapsed: 00:35:59
                               ETA: 01:09:44

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 49382 steps/s (collection: 1.863s, learning 0.128s)
             Mean action noise std: 2.04
          Mean value_function loss: 74.4736
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.5308
                       Mean reward: 503.68
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.0106
    Episode_Reward/rotating_object: 104.0495
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.99s
                      Time elapsed: 00:36:01
                               ETA: 01:09:35

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 49732 steps/s (collection: 1.859s, learning 0.118s)
             Mean action noise std: 2.04
          Mean value_function loss: 73.2800
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 46.5550
                       Mean reward: 507.00
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 0.9907
    Episode_Reward/rotating_object: 103.0925
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.98s
                      Time elapsed: 00:36:03
                               ETA: 01:09:26

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 48294 steps/s (collection: 1.913s, learning 0.122s)
             Mean action noise std: 2.05
          Mean value_function loss: 63.9871
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 46.5799
                       Mean reward: 524.76
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.0074
    Episode_Reward/rotating_object: 104.1243
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.04s
                      Time elapsed: 00:36:05
                               ETA: 01:09:18

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 48788 steps/s (collection: 1.890s, learning 0.125s)
             Mean action noise std: 2.05
          Mean value_function loss: 68.8056
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.6093
                       Mean reward: 507.51
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.0178
    Episode_Reward/rotating_object: 106.9783
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.01s
                      Time elapsed: 00:36:07
                               ETA: 01:09:10

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 50325 steps/s (collection: 1.836s, learning 0.118s)
             Mean action noise std: 2.05
          Mean value_function loss: 71.6024
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.6351
                       Mean reward: 585.03
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 1.0150
    Episode_Reward/rotating_object: 108.8762
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.95s
                      Time elapsed: 00:36:09
                               ETA: 01:09:01

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 50165 steps/s (collection: 1.839s, learning 0.121s)
             Mean action noise std: 2.05
          Mean value_function loss: 65.5137
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.6588
                       Mean reward: 614.63
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 1.0568
    Episode_Reward/rotating_object: 117.6289
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.96s
                      Time elapsed: 00:36:11
                               ETA: 01:08:53

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 50815 steps/s (collection: 1.839s, learning 0.095s)
             Mean action noise std: 2.06
          Mean value_function loss: 66.8493
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.6843
                       Mean reward: 535.32
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 1.0253
    Episode_Reward/rotating_object: 109.9815
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.93s
                      Time elapsed: 00:36:13
                               ETA: 01:08:44

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 50564 steps/s (collection: 1.835s, learning 0.109s)
             Mean action noise std: 2.06
          Mean value_function loss: 64.5951
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.7097
                       Mean reward: 568.88
               Mean episode length: 246.81
    Episode_Reward/reaching_object: 1.0202
    Episode_Reward/rotating_object: 108.6269
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.94s
                      Time elapsed: 00:36:15
                               ETA: 01:08:36

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 50294 steps/s (collection: 1.840s, learning 0.115s)
             Mean action noise std: 2.06
          Mean value_function loss: 77.1595
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.7307
                       Mean reward: 613.07
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.0277
    Episode_Reward/rotating_object: 112.8350
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.95s
                      Time elapsed: 00:36:17
                               ETA: 01:08:27

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 48534 steps/s (collection: 1.897s, learning 0.128s)
             Mean action noise std: 2.06
          Mean value_function loss: 78.8805
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 46.7476
                       Mean reward: 611.11
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 1.0414
    Episode_Reward/rotating_object: 112.9853
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.03s
                      Time elapsed: 00:36:19
                               ETA: 01:08:19

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 49936 steps/s (collection: 1.859s, learning 0.110s)
             Mean action noise std: 2.06
          Mean value_function loss: 61.7253
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.7650
                       Mean reward: 546.97
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0218
    Episode_Reward/rotating_object: 109.8075
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.97s
                      Time elapsed: 00:36:21
                               ETA: 01:08:11

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 49834 steps/s (collection: 1.860s, learning 0.113s)
             Mean action noise std: 2.07
          Mean value_function loss: 56.1922
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.8013
                       Mean reward: 586.07
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 1.0462
    Episode_Reward/rotating_object: 112.9747
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.97s
                      Time elapsed: 00:36:23
                               ETA: 01:08:02

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 50682 steps/s (collection: 1.832s, learning 0.108s)
             Mean action noise std: 2.07
          Mean value_function loss: 61.9371
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 46.8261
                       Mean reward: 591.20
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.0456
    Episode_Reward/rotating_object: 113.6615
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.94s
                      Time elapsed: 00:36:25
                               ETA: 01:07:54

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 47709 steps/s (collection: 1.940s, learning 0.120s)
             Mean action noise std: 2.07
          Mean value_function loss: 76.9530
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.8468
                       Mean reward: 557.93
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 1.0379
    Episode_Reward/rotating_object: 111.2565
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.06s
                      Time elapsed: 00:36:27
                               ETA: 01:07:46

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 49978 steps/s (collection: 1.848s, learning 0.119s)
             Mean action noise std: 2.08
          Mean value_function loss: 69.9284
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.8750
                       Mean reward: 531.71
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.0139
    Episode_Reward/rotating_object: 107.4459
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.97s
                      Time elapsed: 00:36:29
                               ETA: 01:07:38

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 48474 steps/s (collection: 1.901s, learning 0.127s)
             Mean action noise std: 2.08
          Mean value_function loss: 63.5604
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.9187
                       Mean reward: 518.94
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.0137
    Episode_Reward/rotating_object: 109.8847
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.03s
                      Time elapsed: 00:36:31
                               ETA: 01:07:30

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 49532 steps/s (collection: 1.869s, learning 0.116s)
             Mean action noise std: 2.08
          Mean value_function loss: 67.6868
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.9451
                       Mean reward: 558.37
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.0298
    Episode_Reward/rotating_object: 112.8203
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.98s
                      Time elapsed: 00:36:33
                               ETA: 01:07:21

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 50689 steps/s (collection: 1.832s, learning 0.107s)
             Mean action noise std: 2.08
          Mean value_function loss: 64.5597
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 46.9637
                       Mean reward: 549.81
               Mean episode length: 237.96
    Episode_Reward/reaching_object: 1.0345
    Episode_Reward/rotating_object: 114.5484
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.94s
                      Time elapsed: 00:36:35
                               ETA: 01:07:13

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 49050 steps/s (collection: 1.897s, learning 0.107s)
             Mean action noise std: 2.09
          Mean value_function loss: 66.8512
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.9931
                       Mean reward: 554.80
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.0299
    Episode_Reward/rotating_object: 112.6872
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.00s
                      Time elapsed: 00:36:37
                               ETA: 01:07:05

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 49815 steps/s (collection: 1.866s, learning 0.108s)
             Mean action noise std: 2.09
          Mean value_function loss: 65.4455
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 47.0239
                       Mean reward: 571.29
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 1.0415
    Episode_Reward/rotating_object: 116.2851
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.97s
                      Time elapsed: 00:36:39
                               ETA: 01:06:57

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 50216 steps/s (collection: 1.857s, learning 0.101s)
             Mean action noise std: 2.09
          Mean value_function loss: 73.1254
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.0426
                       Mean reward: 572.64
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.0337
    Episode_Reward/rotating_object: 112.7702
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.96s
                      Time elapsed: 00:36:41
                               ETA: 01:06:49

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 49727 steps/s (collection: 1.874s, learning 0.103s)
             Mean action noise std: 2.09
          Mean value_function loss: 63.7635
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.0520
                       Mean reward: 585.24
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.0153
    Episode_Reward/rotating_object: 109.2216
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.98s
                      Time elapsed: 00:36:43
                               ETA: 01:06:41

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 50469 steps/s (collection: 1.838s, learning 0.110s)
             Mean action noise std: 2.09
          Mean value_function loss: 62.6182
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.0673
                       Mean reward: 541.36
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.0144
    Episode_Reward/rotating_object: 107.7277
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.95s
                      Time elapsed: 00:36:45
                               ETA: 01:06:33

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 50410 steps/s (collection: 1.833s, learning 0.118s)
             Mean action noise std: 2.10
          Mean value_function loss: 61.1953
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.0841
                       Mean reward: 590.91
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.0188
    Episode_Reward/rotating_object: 112.4775
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.95s
                      Time elapsed: 00:36:47
                               ETA: 01:06:25

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 49720 steps/s (collection: 1.863s, learning 0.114s)
             Mean action noise std: 2.10
          Mean value_function loss: 74.7163
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.1038
                       Mean reward: 565.66
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.0300
    Episode_Reward/rotating_object: 115.3262
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.98s
                      Time elapsed: 00:36:49
                               ETA: 01:06:17

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 48503 steps/s (collection: 1.914s, learning 0.113s)
             Mean action noise std: 2.10
          Mean value_function loss: 58.9964
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.1340
                       Mean reward: 569.38
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 1.0390
    Episode_Reward/rotating_object: 115.7491
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.03s
                      Time elapsed: 00:36:51
                               ETA: 01:06:09

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 48696 steps/s (collection: 1.909s, learning 0.110s)
             Mean action noise std: 2.10
          Mean value_function loss: 68.1890
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.1640
                       Mean reward: 597.40
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 1.0240
    Episode_Reward/rotating_object: 113.3134
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.02s
                      Time elapsed: 00:36:53
                               ETA: 01:06:01

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 45919 steps/s (collection: 2.009s, learning 0.131s)
             Mean action noise std: 2.11
          Mean value_function loss: 66.0140
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.1836
                       Mean reward: 601.16
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 1.0407
    Episode_Reward/rotating_object: 119.3883
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.14s
                      Time elapsed: 00:36:55
                               ETA: 01:05:53

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 48111 steps/s (collection: 1.924s, learning 0.119s)
             Mean action noise std: 2.11
          Mean value_function loss: 68.6199
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.2035
                       Mean reward: 607.99
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 117.0798
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.04s
                      Time elapsed: 00:36:57
                               ETA: 01:05:46

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 44767 steps/s (collection: 1.996s, learning 0.200s)
             Mean action noise std: 2.11
          Mean value_function loss: 64.4762
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.2350
                       Mean reward: 568.93
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 1.0353
    Episode_Reward/rotating_object: 111.7165
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.20s
                      Time elapsed: 00:36:59
                               ETA: 01:05:38

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 39822 steps/s (collection: 2.271s, learning 0.197s)
             Mean action noise std: 2.11
          Mean value_function loss: 62.5419
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.2627
                       Mean reward: 546.31
               Mean episode length: 245.08
    Episode_Reward/reaching_object: 1.0199
    Episode_Reward/rotating_object: 112.3180
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.47s
                      Time elapsed: 00:37:01
                               ETA: 01:05:31

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 43870 steps/s (collection: 2.114s, learning 0.127s)
             Mean action noise std: 2.12
          Mean value_function loss: 60.6742
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.2847
                       Mean reward: 600.93
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.0069
    Episode_Reward/rotating_object: 111.3950
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.24s
                      Time elapsed: 00:37:04
                               ETA: 01:05:24

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 41711 steps/s (collection: 2.106s, learning 0.251s)
             Mean action noise std: 2.12
          Mean value_function loss: 59.4447
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.3011
                       Mean reward: 559.86
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 1.0200
    Episode_Reward/rotating_object: 114.5702
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.36s
                      Time elapsed: 00:37:06
                               ETA: 01:05:16

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 40521 steps/s (collection: 2.298s, learning 0.128s)
             Mean action noise std: 2.12
          Mean value_function loss: 61.8612
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 47.3333
                       Mean reward: 552.12
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.0190
    Episode_Reward/rotating_object: 110.9831
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.43s
                      Time elapsed: 00:37:09
                               ETA: 01:05:09

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 45084 steps/s (collection: 2.068s, learning 0.112s)
             Mean action noise std: 2.12
          Mean value_function loss: 65.1176
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.3641
                       Mean reward: 550.32
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 112.1271
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.18s
                      Time elapsed: 00:37:11
                               ETA: 01:05:02

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 46733 steps/s (collection: 1.976s, learning 0.128s)
             Mean action noise std: 2.12
          Mean value_function loss: 67.2187
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.3787
                       Mean reward: 619.00
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.0198
    Episode_Reward/rotating_object: 114.8635
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.10s
                      Time elapsed: 00:37:13
                               ETA: 01:04:54

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 47593 steps/s (collection: 1.948s, learning 0.118s)
             Mean action noise std: 2.13
          Mean value_function loss: 69.2082
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 47.3985
                       Mean reward: 550.75
               Mean episode length: 239.68
    Episode_Reward/reaching_object: 1.0153
    Episode_Reward/rotating_object: 112.8235
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.07s
                      Time elapsed: 00:37:15
                               ETA: 01:04:47

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 45005 steps/s (collection: 2.058s, learning 0.126s)
             Mean action noise std: 2.13
          Mean value_function loss: 67.6811
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.4253
                       Mean reward: 559.24
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 1.0133
    Episode_Reward/rotating_object: 113.2114
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.18s
                      Time elapsed: 00:37:17
                               ETA: 01:04:40

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 47042 steps/s (collection: 1.969s, learning 0.121s)
             Mean action noise std: 2.13
          Mean value_function loss: 58.1584
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.4490
                       Mean reward: 592.27
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 115.9546
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.09s
                      Time elapsed: 00:37:19
                               ETA: 01:04:32

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 46052 steps/s (collection: 1.956s, learning 0.179s)
             Mean action noise std: 2.14
          Mean value_function loss: 63.2576
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.4798
                       Mean reward: 592.63
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 1.0305
    Episode_Reward/rotating_object: 114.4505
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.13s
                      Time elapsed: 00:37:21
                               ETA: 01:04:25

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 41331 steps/s (collection: 2.243s, learning 0.135s)
             Mean action noise std: 2.14
          Mean value_function loss: 60.9239
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.5147
                       Mean reward: 577.44
               Mean episode length: 239.61
    Episode_Reward/reaching_object: 1.0235
    Episode_Reward/rotating_object: 115.8810
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.38s
                      Time elapsed: 00:37:24
                               ETA: 01:04:18

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 45478 steps/s (collection: 2.063s, learning 0.099s)
             Mean action noise std: 2.14
          Mean value_function loss: 63.9244
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 47.5482
                       Mean reward: 592.46
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.0382
    Episode_Reward/rotating_object: 119.7371
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.16s
                      Time elapsed: 00:37:26
                               ETA: 01:04:10

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 44396 steps/s (collection: 2.111s, learning 0.103s)
             Mean action noise std: 2.14
          Mean value_function loss: 63.4386
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.5651
                       Mean reward: 560.32
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.0091
    Episode_Reward/rotating_object: 112.3255
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.21s
                      Time elapsed: 00:37:28
                               ETA: 01:04:03

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 46636 steps/s (collection: 1.993s, learning 0.115s)
             Mean action noise std: 2.15
          Mean value_function loss: 58.4420
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.5782
                       Mean reward: 626.37
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 1.0323
    Episode_Reward/rotating_object: 117.3498
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.11s
                      Time elapsed: 00:37:30
                               ETA: 01:03:56

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 40757 steps/s (collection: 2.209s, learning 0.203s)
             Mean action noise std: 2.15
          Mean value_function loss: 53.9433
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.6021
                       Mean reward: 575.31
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.0407
    Episode_Reward/rotating_object: 117.7927
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.41s
                      Time elapsed: 00:37:33
                               ETA: 01:03:49

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 39697 steps/s (collection: 2.269s, learning 0.207s)
             Mean action noise std: 2.15
          Mean value_function loss: 70.3034
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.6259
                       Mean reward: 564.91
               Mean episode length: 240.28
    Episode_Reward/reaching_object: 1.0377
    Episode_Reward/rotating_object: 118.2334
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.48s
                      Time elapsed: 00:37:35
                               ETA: 01:03:42

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 43237 steps/s (collection: 2.168s, learning 0.105s)
             Mean action noise std: 2.15
          Mean value_function loss: 70.3881
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.6484
                       Mean reward: 603.92
               Mean episode length: 244.12
    Episode_Reward/reaching_object: 1.0293
    Episode_Reward/rotating_object: 118.2713
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.27s
                      Time elapsed: 00:37:37
                               ETA: 01:03:35

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 47131 steps/s (collection: 1.963s, learning 0.123s)
             Mean action noise std: 2.15
          Mean value_function loss: 60.5464
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.6632
                       Mean reward: 620.97
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 1.0193
    Episode_Reward/rotating_object: 113.3428
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.09s
                      Time elapsed: 00:37:39
                               ETA: 01:03:28

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 44532 steps/s (collection: 2.063s, learning 0.144s)
             Mean action noise std: 2.16
          Mean value_function loss: 57.4084
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.6922
                       Mean reward: 615.13
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 119.1175
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.21s
                      Time elapsed: 00:37:42
                               ETA: 01:03:21

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 44470 steps/s (collection: 2.075s, learning 0.135s)
             Mean action noise std: 2.16
          Mean value_function loss: 64.0516
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.7306
                       Mean reward: 587.99
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 1.0295
    Episode_Reward/rotating_object: 118.5862
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.21s
                      Time elapsed: 00:37:44
                               ETA: 01:03:14

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 44548 steps/s (collection: 2.041s, learning 0.166s)
             Mean action noise std: 2.16
          Mean value_function loss: 62.4005
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.7548
                       Mean reward: 608.19
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 1.0328
    Episode_Reward/rotating_object: 118.5249
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.21s
                      Time elapsed: 00:37:46
                               ETA: 01:03:06

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 31173 steps/s (collection: 2.887s, learning 0.266s)
             Mean action noise std: 2.17
          Mean value_function loss: 56.3359
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.7771
                       Mean reward: 604.73
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.0444
    Episode_Reward/rotating_object: 116.5967
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 3.15s
                      Time elapsed: 00:37:49
                               ETA: 01:03:01

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 31749 steps/s (collection: 2.749s, learning 0.348s)
             Mean action noise std: 2.17
          Mean value_function loss: 61.4716
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.8007
                       Mean reward: 563.71
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.0179
    Episode_Reward/rotating_object: 114.7392
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 3.10s
                      Time elapsed: 00:37:52
                               ETA: 01:02:55

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 38230 steps/s (collection: 2.361s, learning 0.210s)
             Mean action noise std: 2.17
          Mean value_function loss: 63.8454
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.8264
                       Mean reward: 565.95
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 1.0090
    Episode_Reward/rotating_object: 113.8858
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.57s
                      Time elapsed: 00:37:55
                               ETA: 01:02:49

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 37705 steps/s (collection: 2.389s, learning 0.218s)
             Mean action noise std: 2.18
          Mean value_function loss: 65.9224
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 47.8592
                       Mean reward: 601.28
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.0284
    Episode_Reward/rotating_object: 117.2350
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.61s
                      Time elapsed: 00:37:57
                               ETA: 01:02:43

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 38187 steps/s (collection: 2.434s, learning 0.141s)
             Mean action noise std: 2.18
          Mean value_function loss: 66.4746
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.8845
                       Mean reward: 581.21
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.0259
    Episode_Reward/rotating_object: 115.6254
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.57s
                      Time elapsed: 00:38:00
                               ETA: 01:02:36

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 33819 steps/s (collection: 2.631s, learning 0.276s)
             Mean action noise std: 2.18
          Mean value_function loss: 63.4243
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.9093
                       Mean reward: 608.98
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.0417
    Episode_Reward/rotating_object: 120.8149
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.91s
                      Time elapsed: 00:38:03
                               ETA: 01:02:30

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 37558 steps/s (collection: 2.396s, learning 0.222s)
             Mean action noise std: 2.18
          Mean value_function loss: 57.1258
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.9411
                       Mean reward: 567.16
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.0238
    Episode_Reward/rotating_object: 115.6948
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.62s
                      Time elapsed: 00:38:06
                               ETA: 01:02:24

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 36721 steps/s (collection: 2.535s, learning 0.142s)
             Mean action noise std: 2.19
          Mean value_function loss: 67.2731
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 47.9662
                       Mean reward: 602.15
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.0314
    Episode_Reward/rotating_object: 118.8965
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.68s
                      Time elapsed: 00:38:08
                               ETA: 01:02:18

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 37290 steps/s (collection: 2.465s, learning 0.171s)
             Mean action noise std: 2.19
          Mean value_function loss: 60.6203
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.9888
                       Mean reward: 582.24
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.0255
    Episode_Reward/rotating_object: 115.4153
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.64s
                      Time elapsed: 00:38:11
                               ETA: 01:02:11

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 36615 steps/s (collection: 2.562s, learning 0.123s)
             Mean action noise std: 2.19
          Mean value_function loss: 65.6458
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.0161
                       Mean reward: 578.28
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.0359
    Episode_Reward/rotating_object: 119.0221
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.68s
                      Time elapsed: 00:38:14
                               ETA: 01:02:05

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 46550 steps/s (collection: 2.006s, learning 0.106s)
             Mean action noise std: 2.20
          Mean value_function loss: 69.4664
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.0462
                       Mean reward: 564.76
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.0257
    Episode_Reward/rotating_object: 117.5216
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.11s
                      Time elapsed: 00:38:16
                               ETA: 01:01:58

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 32742 steps/s (collection: 2.785s, learning 0.218s)
             Mean action noise std: 2.20
          Mean value_function loss: 68.3348
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.0844
                       Mean reward: 536.06
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 1.0070
    Episode_Reward/rotating_object: 111.0343
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 3.00s
                      Time elapsed: 00:38:19
                               ETA: 01:01:53

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 33867 steps/s (collection: 2.804s, learning 0.099s)
             Mean action noise std: 2.20
          Mean value_function loss: 67.0969
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.1210
                       Mean reward: 578.53
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 1.0323
    Episode_Reward/rotating_object: 115.6820
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.90s
                      Time elapsed: 00:38:22
                               ETA: 01:01:47

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 42297 steps/s (collection: 2.140s, learning 0.184s)
             Mean action noise std: 2.21
          Mean value_function loss: 63.2031
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.1525
                       Mean reward: 588.30
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.0177
    Episode_Reward/rotating_object: 111.9542
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.32s
                      Time elapsed: 00:38:24
                               ETA: 01:01:40

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 47694 steps/s (collection: 1.962s, learning 0.099s)
             Mean action noise std: 2.21
          Mean value_function loss: 56.7105
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.1847
                       Mean reward: 635.62
               Mean episode length: 246.50
    Episode_Reward/reaching_object: 1.0515
    Episode_Reward/rotating_object: 121.8133
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.06s
                      Time elapsed: 00:38:26
                               ETA: 01:01:33

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 46344 steps/s (collection: 2.020s, learning 0.102s)
             Mean action noise std: 2.21
          Mean value_function loss: 66.9406
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.2133
                       Mean reward: 555.93
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 1.0362
    Episode_Reward/rotating_object: 116.2201
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.12s
                      Time elapsed: 00:38:28
                               ETA: 01:01:26

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 45792 steps/s (collection: 2.034s, learning 0.113s)
             Mean action noise std: 2.22
          Mean value_function loss: 71.2959
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.2408
                       Mean reward: 585.15
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.0325
    Episode_Reward/rotating_object: 117.3468
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.15s
                      Time elapsed: 00:38:30
                               ETA: 01:01:19

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 35331 steps/s (collection: 2.564s, learning 0.219s)
             Mean action noise std: 2.22
          Mean value_function loss: 69.5673
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.2576
                       Mean reward: 579.50
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.0396
    Episode_Reward/rotating_object: 116.4018
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.78s
                      Time elapsed: 00:38:33
                               ETA: 01:01:13

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 39163 steps/s (collection: 2.237s, learning 0.273s)
             Mean action noise std: 2.22
          Mean value_function loss: 61.7187
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.2826
                       Mean reward: 611.11
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 1.0299
    Episode_Reward/rotating_object: 114.4157
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.51s
                      Time elapsed: 00:38:35
                               ETA: 01:01:07

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 36235 steps/s (collection: 2.520s, learning 0.193s)
             Mean action noise std: 2.22
          Mean value_function loss: 70.3274
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.3043
                       Mean reward: 563.37
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 1.0226
    Episode_Reward/rotating_object: 115.5922
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.71s
                      Time elapsed: 00:38:38
                               ETA: 01:01:01

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 42046 steps/s (collection: 2.163s, learning 0.175s)
             Mean action noise std: 2.22
          Mean value_function loss: 65.8052
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.3151
                       Mean reward: 617.70
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 1.0257
    Episode_Reward/rotating_object: 115.1194
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.34s
                      Time elapsed: 00:38:41
                               ETA: 01:00:54

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 38560 steps/s (collection: 2.355s, learning 0.195s)
             Mean action noise std: 2.23
          Mean value_function loss: 67.1259
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.3435
                       Mean reward: 551.13
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0290
    Episode_Reward/rotating_object: 116.2151
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.55s
                      Time elapsed: 00:38:43
                               ETA: 01:00:48

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 40629 steps/s (collection: 2.175s, learning 0.244s)
             Mean action noise std: 2.23
          Mean value_function loss: 66.2620
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 48.3712
                       Mean reward: 623.10
               Mean episode length: 241.67
    Episode_Reward/reaching_object: 1.0299
    Episode_Reward/rotating_object: 117.8862
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.42s
                      Time elapsed: 00:38:46
                               ETA: 01:00:42

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 38502 steps/s (collection: 2.385s, learning 0.169s)
             Mean action noise std: 2.23
          Mean value_function loss: 60.1263
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 48.3938
                       Mean reward: 596.16
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.0435
    Episode_Reward/rotating_object: 118.3926
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.55s
                      Time elapsed: 00:38:48
                               ETA: 01:00:35

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 38869 steps/s (collection: 2.347s, learning 0.182s)
             Mean action noise std: 2.24
          Mean value_function loss: 66.9757
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.4196
                       Mean reward: 619.52
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 120.3356
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.53s
                      Time elapsed: 00:38:51
                               ETA: 01:00:29

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 33252 steps/s (collection: 2.767s, learning 0.190s)
             Mean action noise std: 2.24
          Mean value_function loss: 70.0198
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.4358
                       Mean reward: 621.98
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.0308
    Episode_Reward/rotating_object: 115.7343
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.96s
                      Time elapsed: 00:38:54
                               ETA: 01:00:24

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 39453 steps/s (collection: 2.192s, learning 0.300s)
             Mean action noise std: 2.24
          Mean value_function loss: 62.9393
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 48.4490
                       Mean reward: 615.68
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.0471
    Episode_Reward/rotating_object: 119.5839
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.49s
                      Time elapsed: 00:38:56
                               ETA: 01:00:17

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 32479 steps/s (collection: 2.822s, learning 0.205s)
             Mean action noise std: 2.24
          Mean value_function loss: 58.3522
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.4549
                       Mean reward: 612.23
               Mean episode length: 240.48
    Episode_Reward/reaching_object: 1.0465
    Episode_Reward/rotating_object: 119.1960
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 3.03s
                      Time elapsed: 00:38:59
                               ETA: 01:00:12

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 30889 steps/s (collection: 2.952s, learning 0.230s)
             Mean action noise std: 2.24
          Mean value_function loss: 67.8692
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.4696
                       Mean reward: 608.92
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.0307
    Episode_Reward/rotating_object: 118.9535
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 3.18s
                      Time elapsed: 00:39:02
                               ETA: 01:00:07

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 34184 steps/s (collection: 2.599s, learning 0.277s)
             Mean action noise std: 2.25
          Mean value_function loss: 66.0446
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.5005
                       Mean reward: 596.23
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 1.0356
    Episode_Reward/rotating_object: 119.5066
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.88s
                      Time elapsed: 00:39:05
                               ETA: 01:00:01

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 30731 steps/s (collection: 2.916s, learning 0.283s)
             Mean action noise std: 2.25
          Mean value_function loss: 63.9547
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.5290
                       Mean reward: 622.29
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.0264
    Episode_Reward/rotating_object: 117.5323
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 3.20s
                      Time elapsed: 00:39:08
                               ETA: 00:59:56

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 32403 steps/s (collection: 2.807s, learning 0.227s)
             Mean action noise std: 2.25
          Mean value_function loss: 65.1705
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.5580
                       Mean reward: 562.35
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.0281
    Episode_Reward/rotating_object: 118.2109
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 3.03s
                      Time elapsed: 00:39:11
                               ETA: 00:59:51

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 37099 steps/s (collection: 2.447s, learning 0.203s)
             Mean action noise std: 2.25
          Mean value_function loss: 60.0978
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.5788
                       Mean reward: 594.52
               Mean episode length: 242.39
    Episode_Reward/reaching_object: 1.0107
    Episode_Reward/rotating_object: 115.7452
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.65s
                      Time elapsed: 00:39:14
                               ETA: 00:59:45

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 31521 steps/s (collection: 2.889s, learning 0.229s)
             Mean action noise std: 2.26
          Mean value_function loss: 60.0293
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.6167
                       Mean reward: 596.80
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 1.0213
    Episode_Reward/rotating_object: 116.8301
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 3.12s
                      Time elapsed: 00:39:17
                               ETA: 00:59:39

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 34758 steps/s (collection: 2.584s, learning 0.244s)
             Mean action noise std: 2.26
          Mean value_function loss: 49.6303
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.6476
                       Mean reward: 586.20
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 118.4101
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.83s
                      Time elapsed: 00:39:20
                               ETA: 00:59:34

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 35379 steps/s (collection: 2.554s, learning 0.225s)
             Mean action noise std: 2.26
          Mean value_function loss: 64.0042
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 48.6692
                       Mean reward: 586.32
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.0154
    Episode_Reward/rotating_object: 114.5894
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.78s
                      Time elapsed: 00:39:23
                               ETA: 00:59:28

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 32359 steps/s (collection: 2.733s, learning 0.305s)
             Mean action noise std: 2.27
          Mean value_function loss: 58.2255
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.6998
                       Mean reward: 623.57
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 1.0302
    Episode_Reward/rotating_object: 120.2395
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 3.04s
                      Time elapsed: 00:39:26
                               ETA: 00:59:23

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 32808 steps/s (collection: 2.781s, learning 0.215s)
             Mean action noise std: 2.27
          Mean value_function loss: 59.9143
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 48.7231
                       Mean reward: 595.81
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 1.0318
    Episode_Reward/rotating_object: 115.3175
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 3.00s
                      Time elapsed: 00:39:29
                               ETA: 00:59:17

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 33765 steps/s (collection: 2.682s, learning 0.229s)
             Mean action noise std: 2.27
          Mean value_function loss: 55.1295
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.7488
                       Mean reward: 604.58
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 1.0154
    Episode_Reward/rotating_object: 116.1527
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.91s
                      Time elapsed: 00:39:32
                               ETA: 00:59:12

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 31859 steps/s (collection: 2.941s, learning 0.145s)
             Mean action noise std: 2.27
          Mean value_function loss: 56.4426
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.7748
                       Mean reward: 631.55
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 122.0312
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 3.09s
                      Time elapsed: 00:39:35
                               ETA: 00:59:07

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 46742 steps/s (collection: 1.983s, learning 0.120s)
             Mean action noise std: 2.28
          Mean value_function loss: 67.7901
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.7993
                       Mean reward: 587.49
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 1.0349
    Episode_Reward/rotating_object: 120.3246
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.10s
                      Time elapsed: 00:39:37
                               ETA: 00:59:00

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 48082 steps/s (collection: 1.921s, learning 0.124s)
             Mean action noise std: 2.28
          Mean value_function loss: 62.7938
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.8255
                       Mean reward: 626.80
               Mean episode length: 247.59
    Episode_Reward/reaching_object: 1.0482
    Episode_Reward/rotating_object: 120.0603
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.04s
                      Time elapsed: 00:39:39
                               ETA: 00:58:53

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 48663 steps/s (collection: 1.900s, learning 0.121s)
             Mean action noise std: 2.28
          Mean value_function loss: 57.4116
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.8441
                       Mean reward: 578.93
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 1.0330
    Episode_Reward/rotating_object: 120.1241
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.02s
                      Time elapsed: 00:39:41
                               ETA: 00:58:46

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 49105 steps/s (collection: 1.899s, learning 0.103s)
             Mean action noise std: 2.28
          Mean value_function loss: 61.3073
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.8639
                       Mean reward: 585.45
               Mean episode length: 238.26
    Episode_Reward/reaching_object: 1.0255
    Episode_Reward/rotating_object: 118.4010
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.00s
                      Time elapsed: 00:39:43
                               ETA: 00:58:40

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 48238 steps/s (collection: 1.931s, learning 0.107s)
             Mean action noise std: 2.29
          Mean value_function loss: 65.9574
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.8832
                       Mean reward: 580.77
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.0416
    Episode_Reward/rotating_object: 119.5401
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.04s
                      Time elapsed: 00:39:45
                               ETA: 00:58:33

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 49725 steps/s (collection: 1.880s, learning 0.097s)
             Mean action noise std: 2.29
          Mean value_function loss: 56.3946
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 48.9059
                       Mean reward: 561.37
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.0425
    Episode_Reward/rotating_object: 118.6659
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.98s
                      Time elapsed: 00:39:47
                               ETA: 00:58:26

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 47426 steps/s (collection: 1.970s, learning 0.102s)
             Mean action noise std: 2.29
          Mean value_function loss: 62.4814
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.9275
                       Mean reward: 601.98
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 1.0431
    Episode_Reward/rotating_object: 120.8334
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.07s
                      Time elapsed: 00:39:49
                               ETA: 00:58:19

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 49057 steps/s (collection: 1.905s, learning 0.099s)
             Mean action noise std: 2.29
          Mean value_function loss: 68.2713
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.9452
                       Mean reward: 626.54
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 1.0414
    Episode_Reward/rotating_object: 122.9541
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.00s
                      Time elapsed: 00:39:51
                               ETA: 00:58:13

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 49799 steps/s (collection: 1.883s, learning 0.091s)
             Mean action noise std: 2.30
          Mean value_function loss: 54.7383
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.9579
                       Mean reward: 612.06
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 1.0547
    Episode_Reward/rotating_object: 124.7286
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.97s
                      Time elapsed: 00:39:53
                               ETA: 00:58:06

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 47617 steps/s (collection: 1.957s, learning 0.107s)
             Mean action noise std: 2.30
          Mean value_function loss: 57.4082
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.9805
                       Mean reward: 588.47
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.0484
    Episode_Reward/rotating_object: 120.0085
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.06s
                      Time elapsed: 00:39:55
                               ETA: 00:57:59

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 49117 steps/s (collection: 1.905s, learning 0.097s)
             Mean action noise std: 2.30
          Mean value_function loss: 61.7160
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.0025
                       Mean reward: 632.87
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.0324
    Episode_Reward/rotating_object: 119.3236
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.00s
                      Time elapsed: 00:39:57
                               ETA: 00:57:53

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 46968 steps/s (collection: 1.995s, learning 0.098s)
             Mean action noise std: 2.30
          Mean value_function loss: 57.8932
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.0187
                       Mean reward: 585.36
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.0474
    Episode_Reward/rotating_object: 122.4005
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.09s
                      Time elapsed: 00:39:59
                               ETA: 00:57:46

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 49921 steps/s (collection: 1.879s, learning 0.090s)
             Mean action noise std: 2.31
          Mean value_function loss: 62.3400
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.0426
                       Mean reward: 562.65
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.0416
    Episode_Reward/rotating_object: 121.2361
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.97s
                      Time elapsed: 00:40:01
                               ETA: 00:57:39

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 49801 steps/s (collection: 1.882s, learning 0.092s)
             Mean action noise std: 2.31
          Mean value_function loss: 57.9027
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.0686
                       Mean reward: 580.34
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.0404
    Episode_Reward/rotating_object: 120.7617
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.97s
                      Time elapsed: 00:40:03
                               ETA: 00:57:33

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 49042 steps/s (collection: 1.912s, learning 0.092s)
             Mean action noise std: 2.31
          Mean value_function loss: 62.2029
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 49.0890
                       Mean reward: 601.01
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.0521
    Episode_Reward/rotating_object: 120.8768
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.00s
                      Time elapsed: 00:40:05
                               ETA: 00:57:26

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 49281 steps/s (collection: 1.905s, learning 0.090s)
             Mean action noise std: 2.31
          Mean value_function loss: 55.1615
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.1034
                       Mean reward: 610.54
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 1.0463
    Episode_Reward/rotating_object: 120.7740
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.99s
                      Time elapsed: 00:40:07
                               ETA: 00:57:19

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 48250 steps/s (collection: 1.937s, learning 0.101s)
             Mean action noise std: 2.32
          Mean value_function loss: 54.8526
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.1226
                       Mean reward: 606.46
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 1.0463
    Episode_Reward/rotating_object: 115.4476
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.04s
                      Time elapsed: 00:40:09
                               ETA: 00:57:13

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 48342 steps/s (collection: 1.933s, learning 0.101s)
             Mean action noise std: 2.32
          Mean value_function loss: 58.9088
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.1430
                       Mean reward: 634.62
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 1.0491
    Episode_Reward/rotating_object: 120.8065
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.03s
                      Time elapsed: 00:40:11
                               ETA: 00:57:06

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 48765 steps/s (collection: 1.908s, learning 0.108s)
             Mean action noise std: 2.32
          Mean value_function loss: 55.1405
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 49.1640
                       Mean reward: 641.85
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 1.0415
    Episode_Reward/rotating_object: 120.1756
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.02s
                      Time elapsed: 00:40:13
                               ETA: 00:57:00

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 48991 steps/s (collection: 1.900s, learning 0.107s)
             Mean action noise std: 2.32
          Mean value_function loss: 56.8134
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.1875
                       Mean reward: 592.09
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 118.6645
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.01s
                      Time elapsed: 00:40:15
                               ETA: 00:56:53

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 48963 steps/s (collection: 1.902s, learning 0.106s)
             Mean action noise std: 2.33
          Mean value_function loss: 51.6411
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.2098
                       Mean reward: 616.66
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.0528
    Episode_Reward/rotating_object: 122.4050
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.01s
                      Time elapsed: 00:40:17
                               ETA: 00:56:47

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 48564 steps/s (collection: 1.909s, learning 0.115s)
             Mean action noise std: 2.33
          Mean value_function loss: 56.0062
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.2522
                       Mean reward: 603.93
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.0459
    Episode_Reward/rotating_object: 120.2221
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.02s
                      Time elapsed: 00:40:19
                               ETA: 00:56:40

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 48078 steps/s (collection: 1.938s, learning 0.107s)
             Mean action noise std: 2.34
          Mean value_function loss: 55.9396
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 49.2993
                       Mean reward: 619.73
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 122.9653
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.04s
                      Time elapsed: 00:40:21
                               ETA: 00:56:34

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 49078 steps/s (collection: 1.905s, learning 0.098s)
             Mean action noise std: 2.34
          Mean value_function loss: 58.8465
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.3256
                       Mean reward: 616.83
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.0482
    Episode_Reward/rotating_object: 121.3475
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.00s
                      Time elapsed: 00:40:23
                               ETA: 00:56:27

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 49387 steps/s (collection: 1.898s, learning 0.093s)
             Mean action noise std: 2.34
          Mean value_function loss: 55.0113
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.3420
                       Mean reward: 610.58
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.0445
    Episode_Reward/rotating_object: 118.8560
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.99s
                      Time elapsed: 00:40:25
                               ETA: 00:56:21

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 49503 steps/s (collection: 1.892s, learning 0.094s)
             Mean action noise std: 2.34
          Mean value_function loss: 58.0922
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.3698
                       Mean reward: 625.38
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.0627
    Episode_Reward/rotating_object: 124.3094
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.99s
                      Time elapsed: 00:40:27
                               ETA: 00:56:14

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 48856 steps/s (collection: 1.917s, learning 0.096s)
             Mean action noise std: 2.35
          Mean value_function loss: 55.8215
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.3949
                       Mean reward: 633.80
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.0486
    Episode_Reward/rotating_object: 120.8172
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.01s
                      Time elapsed: 00:40:29
                               ETA: 00:56:08

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 48189 steps/s (collection: 1.929s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 63.3677
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 49.4109
                       Mean reward: 583.61
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 1.0492
    Episode_Reward/rotating_object: 122.1460
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.04s
                      Time elapsed: 00:40:31
                               ETA: 00:56:02

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 48654 steps/s (collection: 1.904s, learning 0.116s)
             Mean action noise std: 2.35
          Mean value_function loss: 65.1321
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 49.4356
                       Mean reward: 660.71
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.0656
    Episode_Reward/rotating_object: 124.3758
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.02s
                      Time elapsed: 00:40:33
                               ETA: 00:55:55

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 48852 steps/s (collection: 1.897s, learning 0.116s)
             Mean action noise std: 2.35
          Mean value_function loss: 57.0529
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.4649
                       Mean reward: 661.40
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 123.4261
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.01s
                      Time elapsed: 00:40:35
                               ETA: 00:55:49

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 48605 steps/s (collection: 1.908s, learning 0.114s)
             Mean action noise std: 2.36
          Mean value_function loss: 63.8297
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.4942
                       Mean reward: 621.99
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 119.8054
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.02s
                      Time elapsed: 00:40:37
                               ETA: 00:55:42

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 47526 steps/s (collection: 1.955s, learning 0.113s)
             Mean action noise std: 2.36
          Mean value_function loss: 57.2026
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.5217
                       Mean reward: 630.34
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 1.0495
    Episode_Reward/rotating_object: 120.4192
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.07s
                      Time elapsed: 00:40:39
                               ETA: 00:55:36

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 48469 steps/s (collection: 1.896s, learning 0.132s)
             Mean action noise std: 2.36
          Mean value_function loss: 52.6544
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.5500
                       Mean reward: 608.74
               Mean episode length: 243.84
    Episode_Reward/reaching_object: 1.0591
    Episode_Reward/rotating_object: 124.5598
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.03s
                      Time elapsed: 00:40:41
                               ETA: 00:55:30

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 49202 steps/s (collection: 1.888s, learning 0.110s)
             Mean action noise std: 2.37
          Mean value_function loss: 59.6039
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.5793
                       Mean reward: 616.19
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 1.0548
    Episode_Reward/rotating_object: 123.0464
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.00s
                      Time elapsed: 00:40:43
                               ETA: 00:55:23

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 48801 steps/s (collection: 1.903s, learning 0.112s)
             Mean action noise std: 2.37
          Mean value_function loss: 60.0358
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.6090
                       Mean reward: 591.41
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.0436
    Episode_Reward/rotating_object: 122.1443
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.01s
                      Time elapsed: 00:40:45
                               ETA: 00:55:17

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 48449 steps/s (collection: 1.913s, learning 0.116s)
             Mean action noise std: 2.37
          Mean value_function loss: 61.9602
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.6341
                       Mean reward: 597.29
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 1.0383
    Episode_Reward/rotating_object: 121.4645
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.03s
                      Time elapsed: 00:40:47
                               ETA: 00:55:11

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 47840 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 2.38
          Mean value_function loss: 64.0265
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.6548
                       Mean reward: 596.66
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.0512
    Episode_Reward/rotating_object: 123.6068
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.05s
                      Time elapsed: 00:40:50
                               ETA: 00:55:05

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 47853 steps/s (collection: 1.932s, learning 0.122s)
             Mean action noise std: 2.38
          Mean value_function loss: 54.4117
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.6906
                       Mean reward: 556.32
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.0420
    Episode_Reward/rotating_object: 117.8257
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.05s
                      Time elapsed: 00:40:52
                               ETA: 00:54:58

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 47840 steps/s (collection: 1.944s, learning 0.111s)
             Mean action noise std: 2.38
          Mean value_function loss: 51.7657
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.7236
                       Mean reward: 589.72
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 124.4204
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.05s
                      Time elapsed: 00:40:54
                               ETA: 00:54:52

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 47557 steps/s (collection: 1.947s, learning 0.120s)
             Mean action noise std: 2.39
          Mean value_function loss: 60.0695
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.7468
                       Mean reward: 636.45
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 121.3256
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.07s
                      Time elapsed: 00:40:56
                               ETA: 00:54:46

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 47329 steps/s (collection: 1.951s, learning 0.126s)
             Mean action noise std: 2.39
          Mean value_function loss: 63.1532
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.7658
                       Mean reward: 674.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 126.8509
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.08s
                      Time elapsed: 00:40:58
                               ETA: 00:54:40

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 48293 steps/s (collection: 1.907s, learning 0.129s)
             Mean action noise std: 2.39
          Mean value_function loss: 55.1088
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.7792
                       Mean reward: 638.17
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 123.1738
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.04s
                      Time elapsed: 00:41:00
                               ETA: 00:54:34

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 48839 steps/s (collection: 1.889s, learning 0.124s)
             Mean action noise std: 2.39
          Mean value_function loss: 59.9929
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.8088
                       Mean reward: 623.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0370
    Episode_Reward/rotating_object: 119.5558
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.01s
                      Time elapsed: 00:41:02
                               ETA: 00:54:27

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 47857 steps/s (collection: 1.926s, learning 0.128s)
             Mean action noise std: 2.40
          Mean value_function loss: 59.4096
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.8414
                       Mean reward: 624.88
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 124.5661
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.05s
                      Time elapsed: 00:41:04
                               ETA: 00:54:21

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 48369 steps/s (collection: 1.903s, learning 0.129s)
             Mean action noise std: 2.40
          Mean value_function loss: 59.0898
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.8773
                       Mean reward: 657.01
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 127.5043
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.03s
                      Time elapsed: 00:41:06
                               ETA: 00:54:15

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 49135 steps/s (collection: 1.871s, learning 0.130s)
             Mean action noise std: 2.40
          Mean value_function loss: 66.5170
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.9005
                       Mean reward: 578.79
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.0549
    Episode_Reward/rotating_object: 124.0723
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.00s
                      Time elapsed: 00:41:08
                               ETA: 00:54:09

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 47990 steps/s (collection: 1.933s, learning 0.116s)
             Mean action noise std: 2.41
          Mean value_function loss: 50.6198
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.9210
                       Mean reward: 591.97
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.0398
    Episode_Reward/rotating_object: 122.3335
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.05s
                      Time elapsed: 00:41:10
                               ETA: 00:54:03

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 47042 steps/s (collection: 1.964s, learning 0.126s)
             Mean action noise std: 2.41
          Mean value_function loss: 68.0023
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.9406
                       Mean reward: 588.21
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.0413
    Episode_Reward/rotating_object: 123.1319
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.09s
                      Time elapsed: 00:41:12
                               ETA: 00:53:57

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 48072 steps/s (collection: 1.917s, learning 0.128s)
             Mean action noise std: 2.41
          Mean value_function loss: 49.8722
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.9574
                       Mean reward: 594.36
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 1.0481
    Episode_Reward/rotating_object: 119.0015
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.04s
                      Time elapsed: 00:41:14
                               ETA: 00:53:51

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 46371 steps/s (collection: 2.001s, learning 0.119s)
             Mean action noise std: 2.42
          Mean value_function loss: 59.7982
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.9944
                       Mean reward: 622.67
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 1.0507
    Episode_Reward/rotating_object: 124.6263
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.12s
                      Time elapsed: 00:41:16
                               ETA: 00:53:45

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 47804 steps/s (collection: 1.923s, learning 0.133s)
             Mean action noise std: 2.42
          Mean value_function loss: 58.3513
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 50.0321
                       Mean reward: 616.38
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.0444
    Episode_Reward/rotating_object: 122.5276
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.06s
                      Time elapsed: 00:41:18
                               ETA: 00:53:39

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 47201 steps/s (collection: 1.951s, learning 0.132s)
             Mean action noise std: 2.42
          Mean value_function loss: 60.3386
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.0425
                       Mean reward: 618.35
               Mean episode length: 239.79
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 124.0997
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.08s
                      Time elapsed: 00:41:20
                               ETA: 00:53:33

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 47429 steps/s (collection: 1.973s, learning 0.100s)
             Mean action noise std: 2.42
          Mean value_function loss: 55.7877
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.0548
                       Mean reward: 619.65
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 124.0493
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.07s
                      Time elapsed: 00:41:22
                               ETA: 00:53:26

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 47625 steps/s (collection: 1.945s, learning 0.119s)
             Mean action noise std: 2.43
          Mean value_function loss: 59.1082
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.0829
                       Mean reward: 630.87
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.0592
    Episode_Reward/rotating_object: 123.8461
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.06s
                      Time elapsed: 00:41:25
                               ETA: 00:53:20

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 48535 steps/s (collection: 1.894s, learning 0.132s)
             Mean action noise std: 2.43
          Mean value_function loss: 56.6750
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.1087
                       Mean reward: 620.74
               Mean episode length: 244.20
    Episode_Reward/reaching_object: 1.0569
    Episode_Reward/rotating_object: 124.3478
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.03s
                      Time elapsed: 00:41:27
                               ETA: 00:53:14

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 48206 steps/s (collection: 1.912s, learning 0.128s)
             Mean action noise std: 2.43
          Mean value_function loss: 55.8460
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.1370
                       Mean reward: 612.10
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 123.0510
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.04s
                      Time elapsed: 00:41:29
                               ETA: 00:53:08

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 47904 steps/s (collection: 1.937s, learning 0.116s)
             Mean action noise std: 2.44
          Mean value_function loss: 55.4204
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.1696
                       Mean reward: 615.69
               Mean episode length: 241.63
    Episode_Reward/reaching_object: 1.0589
    Episode_Reward/rotating_object: 126.2991
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.05s
                      Time elapsed: 00:41:31
                               ETA: 00:53:02

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 48755 steps/s (collection: 1.897s, learning 0.120s)
             Mean action noise std: 2.44
          Mean value_function loss: 52.7928
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.1875
                       Mean reward: 661.79
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 124.4266
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.02s
                      Time elapsed: 00:41:33
                               ETA: 00:52:56

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 48433 steps/s (collection: 1.908s, learning 0.122s)
             Mean action noise std: 2.44
          Mean value_function loss: 55.7349
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.2131
                       Mean reward: 625.88
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.0512
    Episode_Reward/rotating_object: 122.8132
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.03s
                      Time elapsed: 00:41:35
                               ETA: 00:52:50

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 48333 steps/s (collection: 1.912s, learning 0.122s)
             Mean action noise std: 2.45
          Mean value_function loss: 50.2265
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.2476
                       Mean reward: 594.94
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 1.0578
    Episode_Reward/rotating_object: 124.5915
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.03s
                      Time elapsed: 00:41:37
                               ETA: 00:52:44

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 48179 steps/s (collection: 1.920s, learning 0.120s)
             Mean action noise std: 2.45
          Mean value_function loss: 50.6540
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.2742
                       Mean reward: 650.05
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 1.0523
    Episode_Reward/rotating_object: 122.9829
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.04s
                      Time elapsed: 00:41:39
                               ETA: 00:52:38

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 48088 steps/s (collection: 1.921s, learning 0.123s)
             Mean action noise std: 2.45
          Mean value_function loss: 56.2428
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.2980
                       Mean reward: 610.48
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 122.6484
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.04s
                      Time elapsed: 00:41:41
                               ETA: 00:52:32

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 47983 steps/s (collection: 1.921s, learning 0.128s)
             Mean action noise std: 2.45
          Mean value_function loss: 57.2315
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.3259
                       Mean reward: 589.63
               Mean episode length: 244.47
    Episode_Reward/reaching_object: 1.0684
    Episode_Reward/rotating_object: 123.1750
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.05s
                      Time elapsed: 00:41:43
                               ETA: 00:52:27

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 47126 steps/s (collection: 1.953s, learning 0.133s)
             Mean action noise std: 2.46
          Mean value_function loss: 53.1189
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.3484
                       Mean reward: 608.03
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.0511
    Episode_Reward/rotating_object: 121.6726
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.09s
                      Time elapsed: 00:41:45
                               ETA: 00:52:21

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 29536 steps/s (collection: 3.202s, learning 0.126s)
             Mean action noise std: 2.46
          Mean value_function loss: 56.3258
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.3733
                       Mean reward: 668.67
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 125.2291
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.33s
                      Time elapsed: 00:41:48
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 15063 steps/s (collection: 6.405s, learning 0.121s)
             Mean action noise std: 2.46
          Mean value_function loss: 62.4153
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.3978
                       Mean reward: 610.84
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.0364
    Episode_Reward/rotating_object: 120.2345
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.53s
                      Time elapsed: 00:41:55
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 15046 steps/s (collection: 6.387s, learning 0.147s)
             Mean action noise std: 2.47
          Mean value_function loss: 68.4638
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.4218
                       Mean reward: 611.80
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 124.8578
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.53s
                      Time elapsed: 00:42:01
                               ETA: 00:52:16

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 15315 steps/s (collection: 6.283s, learning 0.136s)
             Mean action noise std: 2.47
          Mean value_function loss: 59.3781
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.4530
                       Mean reward: 627.12
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 1.0427
    Episode_Reward/rotating_object: 120.4731
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.42s
                      Time elapsed: 00:42:08
                               ETA: 00:52:15

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14935 steps/s (collection: 6.451s, learning 0.131s)
             Mean action noise std: 2.47
          Mean value_function loss: 59.2781
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.4770
                       Mean reward: 652.06
               Mean episode length: 241.97
    Episode_Reward/reaching_object: 1.0465
    Episode_Reward/rotating_object: 123.6476
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.58s
                      Time elapsed: 00:42:14
                               ETA: 00:52:15

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14774 steps/s (collection: 6.522s, learning 0.132s)
             Mean action noise std: 2.48
          Mean value_function loss: 63.7841
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.4927
                       Mean reward: 575.33
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.0563
    Episode_Reward/rotating_object: 121.9484
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.65s
                      Time elapsed: 00:42:21
                               ETA: 00:52:15

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 14660 steps/s (collection: 6.583s, learning 0.123s)
             Mean action noise std: 2.48
          Mean value_function loss: 53.4420
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.5224
                       Mean reward: 668.99
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 128.6850
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.71s
                      Time elapsed: 00:42:28
                               ETA: 00:52:15

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14957 steps/s (collection: 6.435s, learning 0.137s)
             Mean action noise std: 2.48
          Mean value_function loss: 50.9569
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.5616
                       Mean reward: 610.29
               Mean episode length: 242.43
    Episode_Reward/reaching_object: 1.0694
    Episode_Reward/rotating_object: 124.7151
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.57s
                      Time elapsed: 00:42:34
                               ETA: 00:52:14

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14981 steps/s (collection: 6.414s, learning 0.147s)
             Mean action noise std: 2.49
          Mean value_function loss: 64.9573
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.5900
                       Mean reward: 575.73
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 1.0359
    Episode_Reward/rotating_object: 120.3556
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.56s
                      Time elapsed: 00:42:41
                               ETA: 00:52:14

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 23349 steps/s (collection: 4.074s, learning 0.136s)
             Mean action noise std: 2.49
          Mean value_function loss: 56.8413
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.6137
                       Mean reward: 635.62
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 1.0647
    Episode_Reward/rotating_object: 124.4255
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.21s
                      Time elapsed: 00:42:45
                               ETA: 00:52:11

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 45614 steps/s (collection: 2.034s, learning 0.122s)
             Mean action noise std: 2.49
          Mean value_function loss: 59.7455
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.6368
                       Mean reward: 591.28
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.0393
    Episode_Reward/rotating_object: 120.8773
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.16s
                      Time elapsed: 00:42:47
                               ETA: 00:52:05

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 45854 steps/s (collection: 2.020s, learning 0.124s)
             Mean action noise std: 2.50
          Mean value_function loss: 59.5301
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.6558
                       Mean reward: 612.01
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 1.0592
    Episode_Reward/rotating_object: 124.2769
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.14s
                      Time elapsed: 00:42:49
                               ETA: 00:51:59

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 48104 steps/s (collection: 1.914s, learning 0.129s)
             Mean action noise std: 2.50
          Mean value_function loss: 59.5015
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.6795
                       Mean reward: 663.05
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.0470
    Episode_Reward/rotating_object: 121.6202
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.04s
                      Time elapsed: 00:42:51
                               ETA: 00:51:53

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 43468 steps/s (collection: 2.125s, learning 0.137s)
             Mean action noise std: 2.50
          Mean value_function loss: 60.3792
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.7047
                       Mean reward: 665.99
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 1.0612
    Episode_Reward/rotating_object: 122.1915
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.26s
                      Time elapsed: 00:42:54
                               ETA: 00:51:47

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 47704 steps/s (collection: 1.966s, learning 0.095s)
             Mean action noise std: 2.51
          Mean value_function loss: 58.1927
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.7353
                       Mean reward: 683.06
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 128.8345
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.06s
                      Time elapsed: 00:42:56
                               ETA: 00:51:42

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 48825 steps/s (collection: 1.891s, learning 0.122s)
             Mean action noise std: 2.51
          Mean value_function loss: 63.1697
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.7685
                       Mean reward: 612.43
               Mean episode length: 245.12
    Episode_Reward/reaching_object: 1.0570
    Episode_Reward/rotating_object: 121.3630
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.01s
                      Time elapsed: 00:42:58
                               ETA: 00:51:36

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 49337 steps/s (collection: 1.874s, learning 0.118s)
             Mean action noise std: 2.51
          Mean value_function loss: 47.6401
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.7946
                       Mean reward: 656.52
               Mean episode length: 248.38
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 126.2490
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.99s
                      Time elapsed: 00:43:00
                               ETA: 00:51:30

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 49844 steps/s (collection: 1.845s, learning 0.127s)
             Mean action noise std: 2.52
          Mean value_function loss: 63.2058
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.8191
                       Mean reward: 591.36
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.0491
    Episode_Reward/rotating_object: 120.1385
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.97s
                      Time elapsed: 00:43:02
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 47829 steps/s (collection: 1.913s, learning 0.143s)
             Mean action noise std: 2.52
          Mean value_function loss: 60.8014
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.8542
                       Mean reward: 647.99
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.0431
    Episode_Reward/rotating_object: 123.2590
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.06s
                      Time elapsed: 00:43:04
                               ETA: 00:51:18

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 49400 steps/s (collection: 1.856s, learning 0.134s)
             Mean action noise std: 2.52
          Mean value_function loss: 54.8843
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.8934
                       Mean reward: 646.30
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 1.0647
    Episode_Reward/rotating_object: 123.9896
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.99s
                      Time elapsed: 00:43:06
                               ETA: 00:51:12

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 49229 steps/s (collection: 1.872s, learning 0.125s)
             Mean action noise std: 2.53
          Mean value_function loss: 60.7591
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.9211
                       Mean reward: 660.08
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.0508
    Episode_Reward/rotating_object: 121.2669
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.00s
                      Time elapsed: 00:43:08
                               ETA: 00:51:06

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 49792 steps/s (collection: 1.854s, learning 0.121s)
             Mean action noise std: 2.53
          Mean value_function loss: 58.8750
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.9419
                       Mean reward: 608.20
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 119.4184
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.97s
                      Time elapsed: 00:43:10
                               ETA: 00:51:00

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 49281 steps/s (collection: 1.865s, learning 0.130s)
             Mean action noise std: 2.53
          Mean value_function loss: 62.6845
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 50.9614
                       Mean reward: 658.50
               Mean episode length: 244.68
    Episode_Reward/reaching_object: 1.0596
    Episode_Reward/rotating_object: 121.4702
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.99s
                      Time elapsed: 00:43:12
                               ETA: 00:50:54

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 50040 steps/s (collection: 1.841s, learning 0.123s)
             Mean action noise std: 2.53
          Mean value_function loss: 64.5703
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 50.9761
                       Mean reward: 644.63
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.0690
    Episode_Reward/rotating_object: 126.6409
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.96s
                      Time elapsed: 00:43:14
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 47461 steps/s (collection: 1.955s, learning 0.116s)
             Mean action noise std: 2.54
          Mean value_function loss: 66.4736
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.9952
                       Mean reward: 635.04
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 124.5901
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.07s
                      Time elapsed: 00:43:16
                               ETA: 00:50:43

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 50504 steps/s (collection: 1.828s, learning 0.119s)
             Mean action noise std: 2.54
          Mean value_function loss: 61.2497
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.0130
                       Mean reward: 630.16
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.0279
    Episode_Reward/rotating_object: 121.2973
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.95s
                      Time elapsed: 00:43:18
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 49167 steps/s (collection: 1.891s, learning 0.109s)
             Mean action noise std: 2.54
          Mean value_function loss: 57.0925
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.0356
                       Mean reward: 656.81
               Mean episode length: 246.62
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 124.1118
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.00s
                      Time elapsed: 00:43:20
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 50286 steps/s (collection: 1.836s, learning 0.119s)
             Mean action noise std: 2.55
          Mean value_function loss: 54.5320
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.0715
                       Mean reward: 629.77
               Mean episode length: 239.39
    Episode_Reward/reaching_object: 1.0766
    Episode_Reward/rotating_object: 126.4328
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.95s
                      Time elapsed: 00:43:22
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 50217 steps/s (collection: 1.837s, learning 0.121s)
             Mean action noise std: 2.55
          Mean value_function loss: 48.4410
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.0920
                       Mean reward: 635.43
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 126.1501
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.96s
                      Time elapsed: 00:43:24
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 49616 steps/s (collection: 1.857s, learning 0.124s)
             Mean action noise std: 2.55
          Mean value_function loss: 56.2805
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.1159
                       Mean reward: 666.58
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 129.8446
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.98s
                      Time elapsed: 00:43:26
                               ETA: 00:50:14

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 50245 steps/s (collection: 1.833s, learning 0.124s)
             Mean action noise std: 2.55
          Mean value_function loss: 59.7446
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.1384
                       Mean reward: 605.51
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 122.8750
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.96s
                      Time elapsed: 00:43:28
                               ETA: 00:50:08

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 50032 steps/s (collection: 1.860s, learning 0.105s)
             Mean action noise std: 2.56
          Mean value_function loss: 63.6660
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.1616
                       Mean reward: 637.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0606
    Episode_Reward/rotating_object: 122.2738
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.96s
                      Time elapsed: 00:43:29
                               ETA: 00:50:02

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 49698 steps/s (collection: 1.869s, learning 0.109s)
             Mean action noise std: 2.56
          Mean value_function loss: 55.3493
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.1805
                       Mean reward: 625.28
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 125.0674
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.98s
                      Time elapsed: 00:43:31
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 49817 steps/s (collection: 1.865s, learning 0.109s)
             Mean action noise std: 2.56
          Mean value_function loss: 63.1639
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.2018
                       Mean reward: 626.84
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 123.4970
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.97s
                      Time elapsed: 00:43:33
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 50003 steps/s (collection: 1.846s, learning 0.120s)
             Mean action noise std: 2.57
          Mean value_function loss: 52.2076
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.2405
                       Mean reward: 664.27
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 1.0784
    Episode_Reward/rotating_object: 126.8549
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.97s
                      Time elapsed: 00:43:35
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 49381 steps/s (collection: 1.881s, learning 0.110s)
             Mean action noise std: 2.57
          Mean value_function loss: 52.5811
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.2719
                       Mean reward: 668.67
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 127.4649
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.99s
                      Time elapsed: 00:43:37
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 49020 steps/s (collection: 1.897s, learning 0.109s)
             Mean action noise std: 2.58
          Mean value_function loss: 67.1881
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.3038
                       Mean reward: 613.94
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.0641
    Episode_Reward/rotating_object: 119.3094
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.01s
                      Time elapsed: 00:43:39
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 49468 steps/s (collection: 1.879s, learning 0.108s)
             Mean action noise std: 2.58
          Mean value_function loss: 47.7041
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.3345
                       Mean reward: 653.40
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 1.0695
    Episode_Reward/rotating_object: 126.0121
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.99s
                      Time elapsed: 00:43:41
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 49683 steps/s (collection: 1.866s, learning 0.113s)
             Mean action noise std: 2.58
          Mean value_function loss: 45.5035
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.3585
                       Mean reward: 654.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 124.3767
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.98s
                      Time elapsed: 00:43:43
                               ETA: 00:49:22

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 45565 steps/s (collection: 2.049s, learning 0.108s)
             Mean action noise std: 2.59
          Mean value_function loss: 57.1953
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.3879
                       Mean reward: 639.20
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 126.3285
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.16s
                      Time elapsed: 00:43:46
                               ETA: 00:49:17

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 47896 steps/s (collection: 1.934s, learning 0.119s)
             Mean action noise std: 2.59
          Mean value_function loss: 62.5178
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.4121
                       Mean reward: 636.26
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0554
    Episode_Reward/rotating_object: 122.7332
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.05s
                      Time elapsed: 00:43:48
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 49207 steps/s (collection: 1.881s, learning 0.117s)
             Mean action noise std: 2.59
          Mean value_function loss: 63.7343
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.4384
                       Mean reward: 605.02
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.0719
    Episode_Reward/rotating_object: 124.8080
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.00s
                      Time elapsed: 00:43:50
                               ETA: 00:49:05

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 49009 steps/s (collection: 1.895s, learning 0.111s)
             Mean action noise std: 2.60
          Mean value_function loss: 55.7089
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.4642
                       Mean reward: 607.30
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 1.0481
    Episode_Reward/rotating_object: 120.0844
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.01s
                      Time elapsed: 00:43:52
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 50648 steps/s (collection: 1.829s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 51.5428
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.4868
                       Mean reward: 654.77
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 126.2989
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.94s
                      Time elapsed: 00:43:54
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 49953 steps/s (collection: 1.856s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 54.0024
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.5023
                       Mean reward: 673.55
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 128.6429
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.97s
                      Time elapsed: 00:43:55
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 50072 steps/s (collection: 1.851s, learning 0.113s)
             Mean action noise std: 2.61
          Mean value_function loss: 47.6990
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.5355
                       Mean reward: 603.71
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 125.2907
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.96s
                      Time elapsed: 00:43:57
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 49898 steps/s (collection: 1.859s, learning 0.112s)
             Mean action noise std: 2.61
          Mean value_function loss: 53.7453
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.5724
                       Mean reward: 625.16
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 124.6428
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.97s
                      Time elapsed: 00:43:59
                               ETA: 00:48:37

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 48950 steps/s (collection: 1.892s, learning 0.116s)
             Mean action noise std: 2.61
          Mean value_function loss: 54.8415
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.6042
                       Mean reward: 612.84
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.0746
    Episode_Reward/rotating_object: 128.8109
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.01s
                      Time elapsed: 00:44:01
                               ETA: 00:48:32

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 49257 steps/s (collection: 1.888s, learning 0.108s)
             Mean action noise std: 2.61
          Mean value_function loss: 48.3700
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 51.6188
                       Mean reward: 650.70
               Mean episode length: 245.07
    Episode_Reward/reaching_object: 1.0739
    Episode_Reward/rotating_object: 123.9944
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.00s
                      Time elapsed: 00:44:03
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 48802 steps/s (collection: 1.905s, learning 0.109s)
             Mean action noise std: 2.62
          Mean value_function loss: 52.9367
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.6342
                       Mean reward: 633.15
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 124.4139
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.01s
                      Time elapsed: 00:44:05
                               ETA: 00:48:20

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 50722 steps/s (collection: 1.838s, learning 0.101s)
             Mean action noise std: 2.62
          Mean value_function loss: 55.4858
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.6573
                       Mean reward: 680.95
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 1.0807
    Episode_Reward/rotating_object: 127.5692
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.94s
                      Time elapsed: 00:44:07
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 50534 steps/s (collection: 1.847s, learning 0.099s)
             Mean action noise std: 2.62
          Mean value_function loss: 50.5904
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.6823
                       Mean reward: 645.54
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.0719
    Episode_Reward/rotating_object: 126.1225
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.95s
                      Time elapsed: 00:44:09
                               ETA: 00:48:09

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 49787 steps/s (collection: 1.857s, learning 0.118s)
             Mean action noise std: 2.63
          Mean value_function loss: 50.6790
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.7060
                       Mean reward: 649.66
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.0977
    Episode_Reward/rotating_object: 131.7121
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.97s
                      Time elapsed: 00:44:11
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 49084 steps/s (collection: 1.885s, learning 0.118s)
             Mean action noise std: 2.63
          Mean value_function loss: 53.7484
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 51.7284
                       Mean reward: 659.01
               Mean episode length: 244.19
    Episode_Reward/reaching_object: 1.0784
    Episode_Reward/rotating_object: 127.3484
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.00s
                      Time elapsed: 00:44:13
                               ETA: 00:47:58

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 49406 steps/s (collection: 1.878s, learning 0.112s)
             Mean action noise std: 2.63
          Mean value_function loss: 58.1395
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.7540
                       Mean reward: 613.35
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.0549
    Episode_Reward/rotating_object: 124.6368
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.99s
                      Time elapsed: 00:44:15
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 49195 steps/s (collection: 1.890s, learning 0.108s)
             Mean action noise std: 2.64
          Mean value_function loss: 64.7222
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.7899
                       Mean reward: 661.67
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 129.8235
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.00s
                      Time elapsed: 00:44:17
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 49493 steps/s (collection: 1.880s, learning 0.106s)
             Mean action noise std: 2.64
          Mean value_function loss: 61.5771
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.8091
                       Mean reward: 661.83
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 1.0909
    Episode_Reward/rotating_object: 128.8356
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.99s
                      Time elapsed: 00:44:19
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 50166 steps/s (collection: 1.864s, learning 0.096s)
             Mean action noise std: 2.64
          Mean value_function loss: 55.7404
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.8285
                       Mean reward: 671.64
               Mean episode length: 249.26
    Episode_Reward/reaching_object: 1.1022
    Episode_Reward/rotating_object: 132.3149
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.96s
                      Time elapsed: 00:44:21
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 49589 steps/s (collection: 1.868s, learning 0.114s)
             Mean action noise std: 2.64
          Mean value_function loss: 60.7147
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 51.8487
                       Mean reward: 632.33
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.0848
    Episode_Reward/rotating_object: 126.2009
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.98s
                      Time elapsed: 00:44:23
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 49451 steps/s (collection: 1.865s, learning 0.123s)
             Mean action noise std: 2.65
          Mean value_function loss: 52.7129
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.8743
                       Mean reward: 649.73
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 1.0780
    Episode_Reward/rotating_object: 125.9944
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.99s
                      Time elapsed: 00:44:25
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 49391 steps/s (collection: 1.870s, learning 0.120s)
             Mean action noise std: 2.65
          Mean value_function loss: 59.1020
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.8926
                       Mean reward: 632.88
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.0711
    Episode_Reward/rotating_object: 124.3355
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.99s
                      Time elapsed: 00:44:27
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 49458 steps/s (collection: 1.875s, learning 0.113s)
             Mean action noise std: 2.65
          Mean value_function loss: 47.4743
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.9183
                       Mean reward: 656.48
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 125.9275
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.99s
                      Time elapsed: 00:44:29
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 49291 steps/s (collection: 1.883s, learning 0.111s)
             Mean action noise std: 2.66
          Mean value_function loss: 58.6679
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.9369
                       Mean reward: 664.97
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 128.6507
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.99s
                      Time elapsed: 00:44:31
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 49617 steps/s (collection: 1.868s, learning 0.113s)
             Mean action noise std: 2.66
          Mean value_function loss: 56.3876
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.9599
                       Mean reward: 630.80
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 125.9223
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.98s
                      Time elapsed: 00:44:33
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 49247 steps/s (collection: 1.882s, learning 0.114s)
             Mean action noise std: 2.66
          Mean value_function loss: 63.9720
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.9751
                       Mean reward: 634.01
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 126.9318
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.00s
                      Time elapsed: 00:44:35
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 50126 steps/s (collection: 1.860s, learning 0.101s)
             Mean action noise std: 2.66
          Mean value_function loss: 55.6475
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.0069
                       Mean reward: 605.79
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 124.2994
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.96s
                      Time elapsed: 00:44:37
                               ETA: 00:46:52

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 49477 steps/s (collection: 1.885s, learning 0.102s)
             Mean action noise std: 2.67
          Mean value_function loss: 56.1234
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.0283
                       Mean reward: 664.29
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 1.0937
    Episode_Reward/rotating_object: 129.7440
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.99s
                      Time elapsed: 00:44:39
                               ETA: 00:46:47

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 49108 steps/s (collection: 1.909s, learning 0.093s)
             Mean action noise std: 2.67
          Mean value_function loss: 61.0420
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.0507
                       Mean reward: 627.91
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 1.0720
    Episode_Reward/rotating_object: 121.7721
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.00s
                      Time elapsed: 00:44:41
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 49535 steps/s (collection: 1.879s, learning 0.106s)
             Mean action noise std: 2.67
          Mean value_function loss: 61.4796
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.0760
                       Mean reward: 644.72
               Mean episode length: 240.73
    Episode_Reward/reaching_object: 1.0822
    Episode_Reward/rotating_object: 129.5548
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.98s
                      Time elapsed: 00:44:43
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 48698 steps/s (collection: 1.905s, learning 0.114s)
             Mean action noise std: 2.67
          Mean value_function loss: 50.8236
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.0947
                       Mean reward: 569.22
               Mean episode length: 236.23
    Episode_Reward/reaching_object: 1.0660
    Episode_Reward/rotating_object: 123.3796
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.02s
                      Time elapsed: 00:44:45
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 48125 steps/s (collection: 1.913s, learning 0.130s)
             Mean action noise std: 2.68
          Mean value_function loss: 57.0298
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 52.1157
                       Mean reward: 651.38
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 1.0804
    Episode_Reward/rotating_object: 127.5163
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.04s
                      Time elapsed: 00:44:47
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 49109 steps/s (collection: 1.875s, learning 0.126s)
             Mean action noise std: 2.68
          Mean value_function loss: 51.4376
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.1355
                       Mean reward: 651.91
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 126.4861
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.00s
                      Time elapsed: 00:44:49
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 48439 steps/s (collection: 1.910s, learning 0.119s)
             Mean action noise std: 2.68
          Mean value_function loss: 53.4221
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.1619
                       Mean reward: 665.68
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 127.1754
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.03s
                      Time elapsed: 00:44:51
                               ETA: 00:46:15

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 48203 steps/s (collection: 1.915s, learning 0.124s)
             Mean action noise std: 2.69
          Mean value_function loss: 49.5165
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.2006
                       Mean reward: 630.57
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 124.5756
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.04s
                      Time elapsed: 00:44:53
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 49647 steps/s (collection: 1.859s, learning 0.121s)
             Mean action noise std: 2.69
          Mean value_function loss: 59.4676
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 52.2288
                       Mean reward: 608.81
               Mean episode length: 240.90
    Episode_Reward/reaching_object: 1.0654
    Episode_Reward/rotating_object: 123.0452
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.98s
                      Time elapsed: 00:44:55
                               ETA: 00:46:04

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 49730 steps/s (collection: 1.853s, learning 0.124s)
             Mean action noise std: 2.69
          Mean value_function loss: 52.6378
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.2433
                       Mean reward: 659.72
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.0846
    Episode_Reward/rotating_object: 126.8281
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.98s
                      Time elapsed: 00:44:57
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 49289 steps/s (collection: 1.869s, learning 0.126s)
             Mean action noise std: 2.70
          Mean value_function loss: 50.4919
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.2641
                       Mean reward: 645.23
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 125.9968
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.99s
                      Time elapsed: 00:44:59
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 48748 steps/s (collection: 1.898s, learning 0.119s)
             Mean action noise std: 2.70
          Mean value_function loss: 57.6433
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.2894
                       Mean reward: 660.72
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.0850
    Episode_Reward/rotating_object: 128.2145
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.02s
                      Time elapsed: 00:45:01
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 48546 steps/s (collection: 1.911s, learning 0.114s)
             Mean action noise std: 2.70
          Mean value_function loss: 51.1001
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.3150
                       Mean reward: 616.06
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.0786
    Episode_Reward/rotating_object: 124.4711
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.02s
                      Time elapsed: 00:45:03
                               ETA: 00:45:43

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 49235 steps/s (collection: 1.874s, learning 0.123s)
             Mean action noise std: 2.71
          Mean value_function loss: 53.8437
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.3263
                       Mean reward: 657.41
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 124.9613
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.00s
                      Time elapsed: 00:45:05
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 49283 steps/s (collection: 1.878s, learning 0.117s)
             Mean action noise std: 2.71
          Mean value_function loss: 55.3904
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.3358
                       Mean reward: 637.17
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.0748
    Episode_Reward/rotating_object: 125.0281
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.99s
                      Time elapsed: 00:45:07
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 49167 steps/s (collection: 1.874s, learning 0.125s)
             Mean action noise std: 2.71
          Mean value_function loss: 51.1963
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.3472
                       Mean reward: 675.94
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.0940
    Episode_Reward/rotating_object: 128.2082
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.00s
                      Time elapsed: 00:45:09
                               ETA: 00:45:27

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 49347 steps/s (collection: 1.877s, learning 0.115s)
             Mean action noise std: 2.71
          Mean value_function loss: 56.7599
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.3662
                       Mean reward: 661.59
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.0850
    Episode_Reward/rotating_object: 127.5529
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.99s
                      Time elapsed: 00:45:11
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 48952 steps/s (collection: 1.878s, learning 0.130s)
             Mean action noise std: 2.71
          Mean value_function loss: 51.3022
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.3871
                       Mean reward: 666.75
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 1.0818
    Episode_Reward/rotating_object: 125.0696
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.01s
                      Time elapsed: 00:45:13
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 49467 steps/s (collection: 1.868s, learning 0.120s)
             Mean action noise std: 2.72
          Mean value_function loss: 61.0871
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.4006
                       Mean reward: 656.61
               Mean episode length: 243.70
    Episode_Reward/reaching_object: 1.0888
    Episode_Reward/rotating_object: 129.1036
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.99s
                      Time elapsed: 00:45:15
                               ETA: 00:45:12

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 47799 steps/s (collection: 1.929s, learning 0.128s)
             Mean action noise std: 2.72
          Mean value_function loss: 51.7844
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.4127
                       Mean reward: 647.16
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.0985
    Episode_Reward/rotating_object: 130.5583
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.06s
                      Time elapsed: 00:45:17
                               ETA: 00:45:06

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 49302 steps/s (collection: 1.872s, learning 0.122s)
             Mean action noise std: 2.72
          Mean value_function loss: 59.2790
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.4230
                       Mean reward: 644.19
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 124.2724
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.99s
                      Time elapsed: 00:45:19
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 50411 steps/s (collection: 1.849s, learning 0.101s)
             Mean action noise std: 2.72
          Mean value_function loss: 68.7376
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.4394
                       Mean reward: 649.46
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.0767
    Episode_Reward/rotating_object: 128.6246
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.95s
                      Time elapsed: 00:45:21
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 49396 steps/s (collection: 1.881s, learning 0.109s)
             Mean action noise std: 2.73
          Mean value_function loss: 64.1117
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.4690
                       Mean reward: 616.14
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 126.5603
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.99s
                      Time elapsed: 00:45:23
                               ETA: 00:44:51

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 50042 steps/s (collection: 1.863s, learning 0.101s)
             Mean action noise std: 2.73
          Mean value_function loss: 47.9533
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.4952
                       Mean reward: 656.43
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 127.5558
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.96s
                      Time elapsed: 00:45:25
                               ETA: 00:44:45

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 49151 steps/s (collection: 1.876s, learning 0.124s)
             Mean action noise std: 2.73
          Mean value_function loss: 60.1388
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.5159
                       Mean reward: 669.00
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 125.5412
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.00s
                      Time elapsed: 00:45:27
                               ETA: 00:44:40

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 50214 steps/s (collection: 1.841s, learning 0.117s)
             Mean action noise std: 2.73
          Mean value_function loss: 57.4854
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 52.5285
                       Mean reward: 628.08
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 1.0878
    Episode_Reward/rotating_object: 126.8346
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.96s
                      Time elapsed: 00:45:29
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 49664 steps/s (collection: 1.863s, learning 0.117s)
             Mean action noise std: 2.74
          Mean value_function loss: 53.5196
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.5515
                       Mean reward: 636.12
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.0735
    Episode_Reward/rotating_object: 125.1708
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.98s
                      Time elapsed: 00:45:31
                               ETA: 00:44:30

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 49616 steps/s (collection: 1.860s, learning 0.121s)
             Mean action noise std: 2.74
          Mean value_function loss: 46.6683
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.5727
                       Mean reward: 645.84
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 1.0811
    Episode_Reward/rotating_object: 128.7046
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.98s
                      Time elapsed: 00:45:33
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 49044 steps/s (collection: 1.885s, learning 0.119s)
             Mean action noise std: 2.74
          Mean value_function loss: 49.6293
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.5928
                       Mean reward: 671.60
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 1.0825
    Episode_Reward/rotating_object: 128.0353
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.00s
                      Time elapsed: 00:45:35
                               ETA: 00:44:20

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 48695 steps/s (collection: 1.896s, learning 0.123s)
             Mean action noise std: 2.75
          Mean value_function loss: 53.4475
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.6159
                       Mean reward: 633.37
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.0811
    Episode_Reward/rotating_object: 127.0440
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.02s
                      Time elapsed: 00:45:37
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 48812 steps/s (collection: 1.904s, learning 0.110s)
             Mean action noise std: 2.75
          Mean value_function loss: 46.8999
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 52.6419
                       Mean reward: 630.07
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 123.5945
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.01s
                      Time elapsed: 00:45:39
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 49403 steps/s (collection: 1.869s, learning 0.121s)
             Mean action noise std: 2.75
          Mean value_function loss: 53.3160
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.6583
                       Mean reward: 637.78
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 128.0905
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.99s
                      Time elapsed: 00:45:41
                               ETA: 00:44:04

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 49617 steps/s (collection: 1.883s, learning 0.099s)
             Mean action noise std: 2.75
          Mean value_function loss: 50.1004
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.6812
                       Mean reward: 663.94
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.0791
    Episode_Reward/rotating_object: 127.2316
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.98s
                      Time elapsed: 00:45:43
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 49572 steps/s (collection: 1.884s, learning 0.099s)
             Mean action noise std: 2.76
          Mean value_function loss: 53.5555
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.6973
                       Mean reward: 625.89
               Mean episode length: 239.80
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 125.5049
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.98s
                      Time elapsed: 00:45:45
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 48327 steps/s (collection: 1.934s, learning 0.101s)
             Mean action noise std: 2.76
          Mean value_function loss: 46.2467
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.7118
                       Mean reward: 606.45
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 124.8745
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.03s
                      Time elapsed: 00:45:47
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 49218 steps/s (collection: 1.905s, learning 0.092s)
             Mean action noise std: 2.76
          Mean value_function loss: 59.2258
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.7325
                       Mean reward: 609.05
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 126.1523
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.00s
                      Time elapsed: 00:45:49
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 49692 steps/s (collection: 1.879s, learning 0.100s)
             Mean action noise std: 2.76
          Mean value_function loss: 57.7722
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.7525
                       Mean reward: 637.48
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 1.0718
    Episode_Reward/rotating_object: 127.9692
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.98s
                      Time elapsed: 00:45:51
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 49404 steps/s (collection: 1.886s, learning 0.104s)
             Mean action noise std: 2.77
          Mean value_function loss: 68.4186
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.7767
                       Mean reward: 607.89
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.0603
    Episode_Reward/rotating_object: 125.3511
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.99s
                      Time elapsed: 00:45:53
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 49354 steps/s (collection: 1.893s, learning 0.099s)
             Mean action noise std: 2.77
          Mean value_function loss: 45.7665
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.8005
                       Mean reward: 637.81
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 127.1398
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.99s
                      Time elapsed: 00:45:55
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 50249 steps/s (collection: 1.859s, learning 0.098s)
             Mean action noise std: 2.77
          Mean value_function loss: 52.9343
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 52.8233
                       Mean reward: 662.09
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 1.0769
    Episode_Reward/rotating_object: 127.7946
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.96s
                      Time elapsed: 00:45:57
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 49344 steps/s (collection: 1.895s, learning 0.097s)
             Mean action noise std: 2.78
          Mean value_function loss: 52.9975
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.8516
                       Mean reward: 633.33
               Mean episode length: 244.38
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 127.1034
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.99s
                      Time elapsed: 00:45:59
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 49069 steps/s (collection: 1.904s, learning 0.099s)
             Mean action noise std: 2.78
          Mean value_function loss: 55.4263
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.8825
                       Mean reward: 635.15
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 129.6778
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.00s
                      Time elapsed: 00:46:01
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 49370 steps/s (collection: 1.890s, learning 0.101s)
             Mean action noise std: 2.78
          Mean value_function loss: 52.4271
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.9034
                       Mean reward: 624.39
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 127.6946
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.99s
                      Time elapsed: 00:46:03
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 49047 steps/s (collection: 1.899s, learning 0.105s)
             Mean action noise std: 2.79
          Mean value_function loss: 59.3037
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.9207
                       Mean reward: 653.67
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 130.1107
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.00s
                      Time elapsed: 00:46:05
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 48580 steps/s (collection: 1.918s, learning 0.105s)
             Mean action noise std: 2.79
          Mean value_function loss: 57.4485
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.9461
                       Mean reward: 676.15
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 129.2102
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.02s
                      Time elapsed: 00:46:07
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 48296 steps/s (collection: 1.926s, learning 0.110s)
             Mean action noise std: 2.79
          Mean value_function loss: 54.2943
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.9677
                       Mean reward: 634.65
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 1.0693
    Episode_Reward/rotating_object: 125.2289
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.04s
                      Time elapsed: 00:46:09
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 48234 steps/s (collection: 1.928s, learning 0.110s)
             Mean action noise std: 2.79
          Mean value_function loss: 50.2811
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.9759
                       Mean reward: 650.55
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 1.0735
    Episode_Reward/rotating_object: 125.5080
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.04s
                      Time elapsed: 00:46:11
                               ETA: 00:42:48

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 48628 steps/s (collection: 1.900s, learning 0.122s)
             Mean action noise std: 2.80
          Mean value_function loss: 56.2816
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.9944
                       Mean reward: 657.38
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.0670
    Episode_Reward/rotating_object: 129.0494
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.02s
                      Time elapsed: 00:46:13
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 48971 steps/s (collection: 1.893s, learning 0.114s)
             Mean action noise std: 2.80
          Mean value_function loss: 55.5468
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.0173
                       Mean reward: 669.27
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 130.7309
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.01s
                      Time elapsed: 00:46:15
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 48988 steps/s (collection: 1.893s, learning 0.114s)
             Mean action noise std: 2.80
          Mean value_function loss: 55.5600
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.0473
                       Mean reward: 623.15
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.0857
    Episode_Reward/rotating_object: 129.7198
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.01s
                      Time elapsed: 00:46:17
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 48798 steps/s (collection: 1.899s, learning 0.115s)
             Mean action noise std: 2.81
          Mean value_function loss: 58.5659
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.0743
                       Mean reward: 644.25
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.0829
    Episode_Reward/rotating_object: 128.9744
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.01s
                      Time elapsed: 00:46:19
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 49199 steps/s (collection: 1.884s, learning 0.114s)
             Mean action noise std: 2.81
          Mean value_function loss: 53.5796
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0967
                       Mean reward: 666.32
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 1.0927
    Episode_Reward/rotating_object: 133.0271
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.00s
                      Time elapsed: 00:46:21
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 49472 steps/s (collection: 1.880s, learning 0.107s)
             Mean action noise std: 2.81
          Mean value_function loss: 48.7223
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.1127
                       Mean reward: 663.52
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.0838
    Episode_Reward/rotating_object: 127.8377
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.99s
                      Time elapsed: 00:46:23
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 49534 steps/s (collection: 1.873s, learning 0.112s)
             Mean action noise std: 2.82
          Mean value_function loss: 52.9605
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.1293
                       Mean reward: 644.81
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 126.0956
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.98s
                      Time elapsed: 00:46:25
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 48450 steps/s (collection: 1.911s, learning 0.118s)
             Mean action noise std: 2.82
          Mean value_function loss: 58.9804
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.1466
                       Mean reward: 620.36
               Mean episode length: 239.80
    Episode_Reward/reaching_object: 1.0768
    Episode_Reward/rotating_object: 127.0608
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.03s
                      Time elapsed: 00:46:27
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 48227 steps/s (collection: 1.920s, learning 0.119s)
             Mean action noise std: 2.82
          Mean value_function loss: 49.0546
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.1681
                       Mean reward: 635.85
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 1.0787
    Episode_Reward/rotating_object: 127.9480
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.04s
                      Time elapsed: 00:46:29
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 48016 steps/s (collection: 1.917s, learning 0.130s)
             Mean action noise std: 2.83
          Mean value_function loss: 51.9582
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.1923
                       Mean reward: 656.29
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 131.8853
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.05s
                      Time elapsed: 00:46:31
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 48709 steps/s (collection: 1.901s, learning 0.118s)
             Mean action noise std: 2.83
          Mean value_function loss: 51.9238
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.2202
                       Mean reward: 627.05
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.0671
    Episode_Reward/rotating_object: 123.6608
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.02s
                      Time elapsed: 00:46:33
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 48694 steps/s (collection: 1.894s, learning 0.125s)
             Mean action noise std: 2.83
          Mean value_function loss: 56.1981
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.2353
                       Mean reward: 629.72
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 1.0774
    Episode_Reward/rotating_object: 129.4163
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.02s
                      Time elapsed: 00:46:35
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 48000 steps/s (collection: 1.919s, learning 0.129s)
             Mean action noise std: 2.83
          Mean value_function loss: 50.4377
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.2472
                       Mean reward: 618.36
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 126.3860
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.05s
                      Time elapsed: 00:46:37
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 48769 steps/s (collection: 1.887s, learning 0.128s)
             Mean action noise std: 2.83
          Mean value_function loss: 57.9101
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.2560
                       Mean reward: 665.71
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 1.0714
    Episode_Reward/rotating_object: 130.1807
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.02s
                      Time elapsed: 00:46:39
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 48069 steps/s (collection: 1.921s, learning 0.124s)
             Mean action noise std: 2.83
          Mean value_function loss: 44.0277
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.2640
                       Mean reward: 658.00
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 129.8111
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.05s
                      Time elapsed: 00:46:41
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 48804 steps/s (collection: 1.894s, learning 0.120s)
             Mean action noise std: 2.84
          Mean value_function loss: 48.2450
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.2744
                       Mean reward: 661.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0819
    Episode_Reward/rotating_object: 126.6221
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.01s
                      Time elapsed: 00:46:43
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 48627 steps/s (collection: 1.900s, learning 0.122s)
             Mean action noise std: 2.84
          Mean value_function loss: 60.2708
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.2810
                       Mean reward: 637.95
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 127.6248
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.02s
                      Time elapsed: 00:46:45
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 48866 steps/s (collection: 1.886s, learning 0.126s)
             Mean action noise std: 2.84
          Mean value_function loss: 65.3785
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.2881
                       Mean reward: 650.19
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 126.6998
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.01s
                      Time elapsed: 00:46:47
                               ETA: 00:41:20

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 48623 steps/s (collection: 1.905s, learning 0.117s)
             Mean action noise std: 2.84
          Mean value_function loss: 56.7900
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 53.3009
                       Mean reward: 681.72
               Mean episode length: 246.88
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 132.4320
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.02s
                      Time elapsed: 00:46:49
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 49106 steps/s (collection: 1.887s, learning 0.115s)
             Mean action noise std: 2.84
          Mean value_function loss: 56.9131
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 53.3069
                       Mean reward: 673.18
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 128.6224
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.00s
                      Time elapsed: 00:46:51
                               ETA: 00:41:10

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 48505 steps/s (collection: 1.900s, learning 0.127s)
             Mean action noise std: 2.84
          Mean value_function loss: 49.5708
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.3129
                       Mean reward: 618.37
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 127.2576
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.03s
                      Time elapsed: 00:46:53
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 49046 steps/s (collection: 1.900s, learning 0.104s)
             Mean action noise std: 2.84
          Mean value_function loss: 53.8047
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 53.3246
                       Mean reward: 622.18
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 126.4728
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.00s
                      Time elapsed: 00:46:55
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 47649 steps/s (collection: 1.936s, learning 0.128s)
             Mean action noise std: 2.85
          Mean value_function loss: 52.4189
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.3444
                       Mean reward: 700.58
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.0823
    Episode_Reward/rotating_object: 130.8862
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.06s
                      Time elapsed: 00:46:58
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 48395 steps/s (collection: 1.896s, learning 0.136s)
             Mean action noise std: 2.85
          Mean value_function loss: 60.0509
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.3682
                       Mean reward: 655.18
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 132.0386
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.03s
                      Time elapsed: 00:47:00
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 48364 steps/s (collection: 1.901s, learning 0.132s)
             Mean action noise std: 2.85
          Mean value_function loss: 50.3577
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.3967
                       Mean reward: 651.89
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 130.6644
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.03s
                      Time elapsed: 00:47:02
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 48251 steps/s (collection: 1.881s, learning 0.156s)
             Mean action noise std: 2.86
          Mean value_function loss: 49.8070
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.4163
                       Mean reward: 654.65
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 1.0719
    Episode_Reward/rotating_object: 127.3140
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.04s
                      Time elapsed: 00:47:04
                               ETA: 00:40:41

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 47608 steps/s (collection: 1.937s, learning 0.128s)
             Mean action noise std: 2.86
          Mean value_function loss: 54.2278
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.4343
                       Mean reward: 628.63
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 125.7212
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.06s
                      Time elapsed: 00:47:06
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 47853 steps/s (collection: 1.934s, learning 0.121s)
             Mean action noise std: 2.86
          Mean value_function loss: 49.9888
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.4570
                       Mean reward: 660.87
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.0808
    Episode_Reward/rotating_object: 128.7462
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.05s
                      Time elapsed: 00:47:08
                               ETA: 00:40:32

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 47772 steps/s (collection: 1.937s, learning 0.121s)
             Mean action noise std: 2.87
          Mean value_function loss: 46.4133
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 53.4823
                       Mean reward: 641.78
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.0842
    Episode_Reward/rotating_object: 129.0309
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.06s
                      Time elapsed: 00:47:10
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 49558 steps/s (collection: 1.883s, learning 0.101s)
             Mean action noise std: 2.87
          Mean value_function loss: 56.5702
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.5050
                       Mean reward: 663.34
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 128.0925
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.98s
                      Time elapsed: 00:47:12
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 47836 steps/s (collection: 1.948s, learning 0.107s)
             Mean action noise std: 2.87
          Mean value_function loss: 57.4927
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.5246
                       Mean reward: 636.03
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 127.3463
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.06s
                      Time elapsed: 00:47:14
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 49217 steps/s (collection: 1.900s, learning 0.097s)
             Mean action noise std: 2.87
          Mean value_function loss: 74.2305
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.5477
                       Mean reward: 627.37
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.0646
    Episode_Reward/rotating_object: 126.5969
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.00s
                      Time elapsed: 00:47:16
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 49291 steps/s (collection: 1.887s, learning 0.108s)
             Mean action noise std: 2.88
          Mean value_function loss: 53.6248
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.5725
                       Mean reward: 624.43
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 125.1623
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.99s
                      Time elapsed: 00:47:18
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 49034 steps/s (collection: 1.902s, learning 0.103s)
             Mean action noise std: 2.88
          Mean value_function loss: 45.7476
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.5916
                       Mean reward: 624.68
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.0868
    Episode_Reward/rotating_object: 131.7064
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.00s
                      Time elapsed: 00:47:20
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 49452 steps/s (collection: 1.892s, learning 0.096s)
             Mean action noise std: 2.88
          Mean value_function loss: 53.6922
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.6105
                       Mean reward: 601.20
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 1.0842
    Episode_Reward/rotating_object: 128.5874
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.99s
                      Time elapsed: 00:47:22
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 48303 steps/s (collection: 1.933s, learning 0.102s)
             Mean action noise std: 2.89
          Mean value_function loss: 58.3396
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.6279
                       Mean reward: 674.36
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 1.0784
    Episode_Reward/rotating_object: 129.6349
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.04s
                      Time elapsed: 00:47:24
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 47779 steps/s (collection: 1.941s, learning 0.116s)
             Mean action noise std: 2.89
          Mean value_function loss: 52.9164
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.6427
                       Mean reward: 675.28
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 1.0845
    Episode_Reward/rotating_object: 130.8636
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.06s
                      Time elapsed: 00:47:26
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 48259 steps/s (collection: 1.936s, learning 0.101s)
             Mean action noise std: 2.89
          Mean value_function loss: 60.9897
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.6629
                       Mean reward: 660.93
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 125.6813
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.04s
                      Time elapsed: 00:47:28
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 48425 steps/s (collection: 1.898s, learning 0.132s)
             Mean action noise std: 2.90
          Mean value_function loss: 52.5773
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.6908
                       Mean reward: 651.26
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 125.9119
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.03s
                      Time elapsed: 00:47:30
                               ETA: 00:39:40

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 48691 steps/s (collection: 1.920s, learning 0.099s)
             Mean action noise std: 2.90
          Mean value_function loss: 60.2932
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.7205
                       Mean reward: 658.37
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 1.0776
    Episode_Reward/rotating_object: 129.5767
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.02s
                      Time elapsed: 00:47:32
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 48380 steps/s (collection: 1.921s, learning 0.111s)
             Mean action noise std: 2.90
          Mean value_function loss: 61.7308
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.7385
                       Mean reward: 649.45
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 130.1635
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.03s
                      Time elapsed: 00:47:34
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 48577 steps/s (collection: 1.894s, learning 0.130s)
             Mean action noise std: 2.90
          Mean value_function loss: 58.3442
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.7540
                       Mean reward: 662.52
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 129.1020
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.02s
                      Time elapsed: 00:47:36
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 47786 steps/s (collection: 1.928s, learning 0.129s)
             Mean action noise std: 2.91
          Mean value_function loss: 54.1182
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.7686
                       Mean reward: 663.31
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.0799
    Episode_Reward/rotating_object: 127.0418
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.06s
                      Time elapsed: 00:47:38
                               ETA: 00:39:21

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 47942 steps/s (collection: 1.921s, learning 0.129s)
             Mean action noise std: 2.91
          Mean value_function loss: 54.3717
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.7898
                       Mean reward: 665.76
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 131.7549
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.05s
                      Time elapsed: 00:47:40
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 48260 steps/s (collection: 1.915s, learning 0.122s)
             Mean action noise std: 2.91
          Mean value_function loss: 44.8500
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 53.8073
                       Mean reward: 654.04
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 1.0705
    Episode_Reward/rotating_object: 126.2044
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.04s
                      Time elapsed: 00:47:42
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 48084 steps/s (collection: 1.921s, learning 0.124s)
             Mean action noise std: 2.91
          Mean value_function loss: 56.7926
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.8244
                       Mean reward: 620.92
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 1.0750
    Episode_Reward/rotating_object: 126.7190
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.04s
                      Time elapsed: 00:47:44
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 47667 steps/s (collection: 1.931s, learning 0.131s)
             Mean action noise std: 2.92
          Mean value_function loss: 54.7597
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.8507
                       Mean reward: 670.00
               Mean episode length: 246.67
    Episode_Reward/reaching_object: 1.0710
    Episode_Reward/rotating_object: 125.0454
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.06s
                      Time elapsed: 00:47:46
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 48339 steps/s (collection: 1.917s, learning 0.117s)
             Mean action noise std: 2.92
          Mean value_function loss: 65.2036
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.8718
                       Mean reward: 633.10
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 1.0641
    Episode_Reward/rotating_object: 124.7160
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.03s
                      Time elapsed: 00:47:48
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 47427 steps/s (collection: 1.943s, learning 0.130s)
             Mean action noise std: 2.92
          Mean value_function loss: 49.3535
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.8816
                       Mean reward: 605.55
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 127.2833
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.07s
                      Time elapsed: 00:47:50
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 47821 steps/s (collection: 1.934s, learning 0.122s)
             Mean action noise std: 2.92
          Mean value_function loss: 59.6489
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.8988
                       Mean reward: 614.59
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 123.8804
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.06s
                      Time elapsed: 00:47:52
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 47873 steps/s (collection: 1.945s, learning 0.108s)
             Mean action noise std: 2.93
          Mean value_function loss: 50.5074
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.9200
                       Mean reward: 659.53
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.0822
    Episode_Reward/rotating_object: 130.4216
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.05s
                      Time elapsed: 00:47:55
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 47597 steps/s (collection: 1.950s, learning 0.115s)
             Mean action noise std: 2.93
          Mean value_function loss: 55.8364
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.9382
                       Mean reward: 670.31
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 1.0805
    Episode_Reward/rotating_object: 131.7277
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.07s
                      Time elapsed: 00:47:57
                               ETA: 00:38:39

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 47557 steps/s (collection: 1.943s, learning 0.124s)
             Mean action noise std: 2.93
          Mean value_function loss: 54.4031
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.9566
                       Mean reward: 682.13
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 1.0912
    Episode_Reward/rotating_object: 132.0895
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.07s
                      Time elapsed: 00:47:59
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 47691 steps/s (collection: 1.935s, learning 0.126s)
             Mean action noise std: 2.94
          Mean value_function loss: 56.8373
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.9836
                       Mean reward: 656.54
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 1.1005
    Episode_Reward/rotating_object: 135.4715
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.06s
                      Time elapsed: 00:48:01
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 48076 steps/s (collection: 1.942s, learning 0.103s)
             Mean action noise std: 2.94
          Mean value_function loss: 58.3167
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 54.0113
                       Mean reward: 661.01
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 129.8815
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.04s
                      Time elapsed: 00:48:03
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 47756 steps/s (collection: 1.938s, learning 0.120s)
             Mean action noise std: 2.94
          Mean value_function loss: 57.2650
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.0199
                       Mean reward: 677.79
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 127.3215
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.06s
                      Time elapsed: 00:48:05
                               ETA: 00:38:21

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 47959 steps/s (collection: 1.930s, learning 0.120s)
             Mean action noise std: 2.94
          Mean value_function loss: 60.1715
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.0302
                       Mean reward: 606.20
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.0597
    Episode_Reward/rotating_object: 123.6676
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.05s
                      Time elapsed: 00:48:07
                               ETA: 00:38:16

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 47053 steps/s (collection: 1.969s, learning 0.120s)
             Mean action noise std: 2.95
          Mean value_function loss: 59.4646
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.0610
                       Mean reward: 642.74
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.0755
    Episode_Reward/rotating_object: 126.9891
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.09s
                      Time elapsed: 00:48:09
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 48443 steps/s (collection: 1.920s, learning 0.110s)
             Mean action noise std: 2.95
          Mean value_function loss: 57.4946
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 54.0905
                       Mean reward: 672.33
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.0885
    Episode_Reward/rotating_object: 133.5270
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.03s
                      Time elapsed: 00:48:11
                               ETA: 00:38:07

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 47755 steps/s (collection: 1.935s, learning 0.124s)
             Mean action noise std: 2.95
          Mean value_function loss: 55.7743
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.1087
                       Mean reward: 673.60
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 126.4186
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.06s
                      Time elapsed: 00:48:13
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 47767 steps/s (collection: 1.927s, learning 0.131s)
             Mean action noise std: 2.96
          Mean value_function loss: 53.7911
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 54.1285
                       Mean reward: 640.32
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.0966
    Episode_Reward/rotating_object: 133.4774
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.06s
                      Time elapsed: 00:48:15
                               ETA: 00:37:58

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 48116 steps/s (collection: 1.920s, learning 0.123s)
             Mean action noise std: 2.96
          Mean value_function loss: 56.2328
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 54.1467
                       Mean reward: 640.29
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.0790
    Episode_Reward/rotating_object: 127.0145
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.04s
                      Time elapsed: 00:48:17
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 48086 steps/s (collection: 1.945s, learning 0.099s)
             Mean action noise std: 2.96
          Mean value_function loss: 57.8885
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.1654
                       Mean reward: 653.46
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 128.1726
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.04s
                      Time elapsed: 00:48:19
                               ETA: 00:37:49

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 48126 steps/s (collection: 1.942s, learning 0.101s)
             Mean action noise std: 2.97
          Mean value_function loss: 51.6999
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.1902
                       Mean reward: 672.73
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 1.0803
    Episode_Reward/rotating_object: 129.1495
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.04s
                      Time elapsed: 00:48:21
                               ETA: 00:37:44

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 47994 steps/s (collection: 1.950s, learning 0.098s)
             Mean action noise std: 2.97
          Mean value_function loss: 59.8418
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.2112
                       Mean reward: 591.00
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 130.9597
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.05s
                      Time elapsed: 00:48:23
                               ETA: 00:37:40

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 47958 steps/s (collection: 1.939s, learning 0.111s)
             Mean action noise std: 2.97
          Mean value_function loss: 55.9762
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.2232
                       Mean reward: 614.33
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 129.8623
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.05s
                      Time elapsed: 00:48:25
                               ETA: 00:37:35

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 47737 steps/s (collection: 1.933s, learning 0.126s)
             Mean action noise std: 2.97
          Mean value_function loss: 50.0208
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.2310
                       Mean reward: 671.25
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 129.0252
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.06s
                      Time elapsed: 00:48:27
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 47200 steps/s (collection: 1.982s, learning 0.101s)
             Mean action noise std: 2.97
          Mean value_function loss: 50.2173
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.2444
                       Mean reward: 670.89
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.0889
    Episode_Reward/rotating_object: 129.2542
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.08s
                      Time elapsed: 00:48:29
                               ETA: 00:37:26

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 47467 steps/s (collection: 1.965s, learning 0.106s)
             Mean action noise std: 2.98
          Mean value_function loss: 51.4120
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.2684
                       Mean reward: 662.54
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 1.0670
    Episode_Reward/rotating_object: 127.0367
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.07s
                      Time elapsed: 00:48:32
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 48039 steps/s (collection: 1.930s, learning 0.116s)
             Mean action noise std: 2.98
          Mean value_function loss: 56.3198
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.2912
                       Mean reward: 660.01
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 1.0803
    Episode_Reward/rotating_object: 129.0260
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.05s
                      Time elapsed: 00:48:34
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 47685 steps/s (collection: 1.942s, learning 0.120s)
             Mean action noise std: 2.98
          Mean value_function loss: 47.5299
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.3139
                       Mean reward: 606.77
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.0911
    Episode_Reward/rotating_object: 133.0254
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.06s
                      Time elapsed: 00:48:36
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 47622 steps/s (collection: 1.938s, learning 0.127s)
             Mean action noise std: 2.99
          Mean value_function loss: 55.4965
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.3309
                       Mean reward: 656.22
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 1.0815
    Episode_Reward/rotating_object: 128.7367
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.06s
                      Time elapsed: 00:48:38
                               ETA: 00:37:08

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 45800 steps/s (collection: 2.009s, learning 0.137s)
             Mean action noise std: 2.99
          Mean value_function loss: 66.3240
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.3457
                       Mean reward: 674.04
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 132.1599
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.15s
                      Time elapsed: 00:48:40
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 46458 steps/s (collection: 1.986s, learning 0.130s)
             Mean action noise std: 2.99
          Mean value_function loss: 59.5354
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.3594
                       Mean reward: 675.35
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.0883
    Episode_Reward/rotating_object: 132.7043
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.12s
                      Time elapsed: 00:48:42
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 47672 steps/s (collection: 1.932s, learning 0.130s)
             Mean action noise std: 3.00
          Mean value_function loss: 58.7737
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.3903
                       Mean reward: 691.41
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.0828
    Episode_Reward/rotating_object: 130.0022
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.06s
                      Time elapsed: 00:48:44
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 47380 steps/s (collection: 1.949s, learning 0.126s)
             Mean action noise std: 3.00
          Mean value_function loss: 58.8295
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.4155
                       Mean reward: 649.49
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 1.0821
    Episode_Reward/rotating_object: 128.9122
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.07s
                      Time elapsed: 00:48:46
                               ETA: 00:36:51

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 47354 steps/s (collection: 1.978s, learning 0.098s)
             Mean action noise std: 3.00
          Mean value_function loss: 55.3089
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.4318
                       Mean reward: 664.45
               Mean episode length: 246.28
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 129.4474
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.08s
                      Time elapsed: 00:48:48
                               ETA: 00:36:46

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 47300 steps/s (collection: 1.954s, learning 0.124s)
             Mean action noise std: 3.00
          Mean value_function loss: 65.6173
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.4497
                       Mean reward: 621.79
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.0635
    Episode_Reward/rotating_object: 128.3846
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.08s
                      Time elapsed: 00:48:50
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 47825 steps/s (collection: 1.933s, learning 0.122s)
             Mean action noise std: 3.01
          Mean value_function loss: 54.0133
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.4772
                       Mean reward: 648.10
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 1.0935
    Episode_Reward/rotating_object: 133.8934
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.06s
                      Time elapsed: 00:48:52
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 47762 steps/s (collection: 1.939s, learning 0.120s)
             Mean action noise std: 3.01
          Mean value_function loss: 53.4462
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.4996
                       Mean reward: 650.69
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 1.0816
    Episode_Reward/rotating_object: 129.1427
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.06s
                      Time elapsed: 00:48:54
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 47136 steps/s (collection: 1.961s, learning 0.125s)
             Mean action noise std: 3.01
          Mean value_function loss: 59.5964
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.5187
                       Mean reward: 659.66
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.0630
    Episode_Reward/rotating_object: 126.6592
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.09s
                      Time elapsed: 00:48:56
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 47554 steps/s (collection: 1.938s, learning 0.130s)
             Mean action noise std: 3.02
          Mean value_function loss: 55.0568
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.5440
                       Mean reward: 620.13
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.0760
    Episode_Reward/rotating_object: 128.3636
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.07s
                      Time elapsed: 00:48:59
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 47374 steps/s (collection: 1.943s, learning 0.132s)
             Mean action noise std: 3.02
          Mean value_function loss: 74.0328
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.5779
                       Mean reward: 634.18
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 1.0748
    Episode_Reward/rotating_object: 130.9875
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.08s
                      Time elapsed: 00:49:01
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 47533 steps/s (collection: 1.947s, learning 0.121s)
             Mean action noise std: 3.02
          Mean value_function loss: 59.4354
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.5986
                       Mean reward: 638.10
               Mean episode length: 239.22
    Episode_Reward/reaching_object: 1.0459
    Episode_Reward/rotating_object: 123.8787
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.07s
                      Time elapsed: 00:49:03
                               ETA: 00:36:15

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 46666 steps/s (collection: 1.982s, learning 0.125s)
             Mean action noise std: 3.02
          Mean value_function loss: 57.1283
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.6099
                       Mean reward: 646.41
               Mean episode length: 242.39
    Episode_Reward/reaching_object: 1.0706
    Episode_Reward/rotating_object: 127.0339
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.11s
                      Time elapsed: 00:49:05
                               ETA: 00:36:11

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 47081 steps/s (collection: 1.966s, learning 0.122s)
             Mean action noise std: 3.03
          Mean value_function loss: 64.0254
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.6229
                       Mean reward: 649.08
               Mean episode length: 243.07
    Episode_Reward/reaching_object: 1.0651
    Episode_Reward/rotating_object: 128.9960
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.09s
                      Time elapsed: 00:49:07
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 46961 steps/s (collection: 1.969s, learning 0.125s)
             Mean action noise std: 3.03
          Mean value_function loss: 60.5306
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.6399
                       Mean reward: 636.48
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 125.3627
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.09s
                      Time elapsed: 00:49:09
                               ETA: 00:36:02

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 47527 steps/s (collection: 1.934s, learning 0.134s)
             Mean action noise std: 3.03
          Mean value_function loss: 65.1396
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.6580
                       Mean reward: 646.55
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 126.0197
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.07s
                      Time elapsed: 00:49:11
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 47716 steps/s (collection: 1.922s, learning 0.138s)
             Mean action noise std: 3.03
          Mean value_function loss: 63.4624
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 54.6767
                       Mean reward: 648.02
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 124.7998
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.06s
                      Time elapsed: 00:49:13
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 44915 steps/s (collection: 2.049s, learning 0.140s)
             Mean action noise std: 3.04
          Mean value_function loss: 63.1878
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.6917
                       Mean reward: 629.75
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 1.0611
    Episode_Reward/rotating_object: 125.6597
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.19s
                      Time elapsed: 00:49:15
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 45833 steps/s (collection: 2.014s, learning 0.130s)
             Mean action noise std: 3.04
          Mean value_function loss: 60.0474
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.7084
                       Mean reward: 662.78
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.0931
    Episode_Reward/rotating_object: 131.3537
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.14s
                      Time elapsed: 00:49:17
                               ETA: 00:35:45

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 46876 steps/s (collection: 1.967s, learning 0.131s)
             Mean action noise std: 3.04
          Mean value_function loss: 66.9047
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.7276
                       Mean reward: 639.51
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 128.1543
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.10s
                      Time elapsed: 00:49:20
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 46982 steps/s (collection: 1.967s, learning 0.125s)
             Mean action noise std: 3.05
          Mean value_function loss: 56.8548
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.7585
                       Mean reward: 660.86
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.0780
    Episode_Reward/rotating_object: 130.8865
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.09s
                      Time elapsed: 00:49:22
                               ETA: 00:35:36

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 47916 steps/s (collection: 1.941s, learning 0.111s)
             Mean action noise std: 3.05
          Mean value_function loss: 63.6640
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 54.7874
                       Mean reward: 618.25
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.0651
    Episode_Reward/rotating_object: 125.3210
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.05s
                      Time elapsed: 00:49:24
                               ETA: 00:35:32

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 47399 steps/s (collection: 1.975s, learning 0.099s)
             Mean action noise std: 3.05
          Mean value_function loss: 62.8848
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.8068
                       Mean reward: 626.17
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 129.1053
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.07s
                      Time elapsed: 00:49:26
                               ETA: 00:35:27

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 47227 steps/s (collection: 1.968s, learning 0.113s)
             Mean action noise std: 3.06
          Mean value_function loss: 70.3974
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.8300
                       Mean reward: 650.24
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 128.9448
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.08s
                      Time elapsed: 00:49:28
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 46894 steps/s (collection: 1.972s, learning 0.124s)
             Mean action noise std: 3.06
          Mean value_function loss: 58.6434
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.8548
                       Mean reward: 614.81
               Mean episode length: 229.96
    Episode_Reward/reaching_object: 1.0642
    Episode_Reward/rotating_object: 125.8498
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.10s
                      Time elapsed: 00:49:30
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 45889 steps/s (collection: 2.027s, learning 0.115s)
             Mean action noise std: 3.06
          Mean value_function loss: 55.1111
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.8753
                       Mean reward: 653.23
               Mean episode length: 244.78
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 126.9760
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.14s
                      Time elapsed: 00:49:32
                               ETA: 00:35:15

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 46910 steps/s (collection: 1.967s, learning 0.129s)
             Mean action noise std: 3.07
          Mean value_function loss: 59.5105
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.9031
                       Mean reward: 646.64
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 127.6013
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.10s
                      Time elapsed: 00:49:34
                               ETA: 00:35:10

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 47452 steps/s (collection: 1.947s, learning 0.125s)
             Mean action noise std: 3.07
          Mean value_function loss: 56.3891
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.9307
                       Mean reward: 619.51
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.0682
    Episode_Reward/rotating_object: 127.0172
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.07s
                      Time elapsed: 00:49:36
                               ETA: 00:35:06

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 46791 steps/s (collection: 1.980s, learning 0.121s)
             Mean action noise std: 3.07
          Mean value_function loss: 64.7420
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.9494
                       Mean reward: 616.37
               Mean episode length: 240.75
    Episode_Reward/reaching_object: 1.0620
    Episode_Reward/rotating_object: 125.4224
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.10s
                      Time elapsed: 00:49:38
                               ETA: 00:35:02

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 47788 steps/s (collection: 1.930s, learning 0.127s)
             Mean action noise std: 3.07
          Mean value_function loss: 55.8481
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 54.9609
                       Mean reward: 631.45
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.0580
    Episode_Reward/rotating_object: 125.8131
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.06s
                      Time elapsed: 00:49:40
                               ETA: 00:34:57

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 46813 steps/s (collection: 1.970s, learning 0.130s)
             Mean action noise std: 3.08
          Mean value_function loss: 51.7374
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.9732
                       Mean reward: 625.80
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 127.2766
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.10s
                      Time elapsed: 00:49:42
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 47069 steps/s (collection: 1.966s, learning 0.122s)
             Mean action noise std: 3.08
          Mean value_function loss: 69.3598
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 54.9863
                       Mean reward: 641.39
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.0523
    Episode_Reward/rotating_object: 124.4791
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.09s
                      Time elapsed: 00:49:45
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 46349 steps/s (collection: 1.994s, learning 0.127s)
             Mean action noise std: 3.08
          Mean value_function loss: 75.4232
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 54.9954
                       Mean reward: 658.07
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 129.4330
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.12s
                      Time elapsed: 00:49:47
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 46515 steps/s (collection: 1.989s, learning 0.124s)
             Mean action noise std: 3.08
          Mean value_function loss: 61.2870
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.0185
                       Mean reward: 629.41
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0399
    Episode_Reward/rotating_object: 123.1860
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.11s
                      Time elapsed: 00:49:49
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 47073 steps/s (collection: 1.963s, learning 0.126s)
             Mean action noise std: 3.09
          Mean value_function loss: 49.4483
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.0460
                       Mean reward: 655.01
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 127.3906
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.09s
                      Time elapsed: 00:49:51
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 47313 steps/s (collection: 1.954s, learning 0.124s)
             Mean action noise std: 3.09
          Mean value_function loss: 57.4026
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.0740
                       Mean reward: 674.57
               Mean episode length: 241.05
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 126.2323
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.08s
                      Time elapsed: 00:49:53
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 47319 steps/s (collection: 1.948s, learning 0.130s)
             Mean action noise std: 3.10
          Mean value_function loss: 60.0570
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.0986
                       Mean reward: 622.26
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 1.0577
    Episode_Reward/rotating_object: 125.4033
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.08s
                      Time elapsed: 00:49:55
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 46744 steps/s (collection: 1.979s, learning 0.125s)
             Mean action noise std: 3.10
          Mean value_function loss: 60.6123
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.1225
                       Mean reward: 630.84
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.0695
    Episode_Reward/rotating_object: 127.7661
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.10s
                      Time elapsed: 00:49:57
                               ETA: 00:34:23

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 46468 steps/s (collection: 1.976s, learning 0.139s)
             Mean action noise std: 3.10
          Mean value_function loss: 55.2408
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.1438
                       Mean reward: 658.57
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.0591
    Episode_Reward/rotating_object: 125.3437
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.12s
                      Time elapsed: 00:49:59
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 46475 steps/s (collection: 2.010s, learning 0.105s)
             Mean action noise std: 3.11
          Mean value_function loss: 66.2220
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.1675
                       Mean reward: 615.50
               Mean episode length: 229.02
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 127.8067
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.12s
                      Time elapsed: 00:50:01
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 46824 steps/s (collection: 1.969s, learning 0.131s)
             Mean action noise std: 3.11
          Mean value_function loss: 48.1310
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.1887
                       Mean reward: 646.47
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.0861
    Episode_Reward/rotating_object: 130.2112
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.10s
                      Time elapsed: 00:50:03
                               ETA: 00:34:10

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 47152 steps/s (collection: 1.964s, learning 0.121s)
             Mean action noise std: 3.11
          Mean value_function loss: 56.8161
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.2144
                       Mean reward: 645.23
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 124.0924
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.08s
                      Time elapsed: 00:50:06
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 46286 steps/s (collection: 1.999s, learning 0.125s)
             Mean action noise std: 3.12
          Mean value_function loss: 55.9538
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.2434
                       Mean reward: 682.53
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 130.6547
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.12s
                      Time elapsed: 00:50:08
                               ETA: 00:34:02

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 46127 steps/s (collection: 1.998s, learning 0.134s)
             Mean action noise std: 3.12
          Mean value_function loss: 58.4053
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.2753
                       Mean reward: 647.38
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 128.0905
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.13s
                      Time elapsed: 00:50:10
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 46435 steps/s (collection: 1.996s, learning 0.121s)
             Mean action noise std: 3.12
          Mean value_function loss: 58.5479
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.2998
                       Mean reward: 659.50
               Mean episode length: 244.35
    Episode_Reward/reaching_object: 1.0758
    Episode_Reward/rotating_object: 129.1932
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.12s
                      Time elapsed: 00:50:12
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 47697 steps/s (collection: 1.947s, learning 0.114s)
             Mean action noise std: 3.13
          Mean value_function loss: 62.1090
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.3138
                       Mean reward: 626.39
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.0853
    Episode_Reward/rotating_object: 131.6524
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.06s
                      Time elapsed: 00:50:14
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 46811 steps/s (collection: 1.987s, learning 0.113s)
             Mean action noise std: 3.13
          Mean value_function loss: 55.3566
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 55.3259
                       Mean reward: 671.57
               Mean episode length: 244.03
    Episode_Reward/reaching_object: 1.0875
    Episode_Reward/rotating_object: 129.6502
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.10s
                      Time elapsed: 00:50:16
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 45906 steps/s (collection: 2.005s, learning 0.136s)
             Mean action noise std: 3.13
          Mean value_function loss: 56.0260
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.3416
                       Mean reward: 659.44
               Mean episode length: 246.78
    Episode_Reward/reaching_object: 1.0736
    Episode_Reward/rotating_object: 128.6866
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.14s
                      Time elapsed: 00:50:18
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 46572 steps/s (collection: 1.970s, learning 0.141s)
             Mean action noise std: 3.13
          Mean value_function loss: 65.5271
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.3560
                       Mean reward: 639.62
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.0607
    Episode_Reward/rotating_object: 127.3059
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.11s
                      Time elapsed: 00:50:20
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 46684 steps/s (collection: 2.000s, learning 0.106s)
             Mean action noise std: 3.14
          Mean value_function loss: 53.6712
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.3725
                       Mean reward: 646.08
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 1.0586
    Episode_Reward/rotating_object: 125.2759
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.11s
                      Time elapsed: 00:50:22
                               ETA: 00:33:33

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 46199 steps/s (collection: 2.004s, learning 0.124s)
             Mean action noise std: 3.14
          Mean value_function loss: 59.3669
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.3914
                       Mean reward: 658.55
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 1.0604
    Episode_Reward/rotating_object: 124.5274
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.13s
                      Time elapsed: 00:50:25
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 46342 steps/s (collection: 1.979s, learning 0.143s)
             Mean action noise std: 3.14
          Mean value_function loss: 63.3270
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.4197
                       Mean reward: 613.73
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 127.4312
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.12s
                      Time elapsed: 00:50:27
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 47128 steps/s (collection: 1.963s, learning 0.123s)
             Mean action noise std: 3.15
          Mean value_function loss: 64.2773
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.4428
                       Mean reward: 625.83
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.0821
    Episode_Reward/rotating_object: 130.7559
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.09s
                      Time elapsed: 00:50:29
                               ETA: 00:33:20

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 46583 steps/s (collection: 1.980s, learning 0.131s)
             Mean action noise std: 3.15
          Mean value_function loss: 56.3259
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.4653
                       Mean reward: 632.18
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 128.1524
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.11s
                      Time elapsed: 00:50:31
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 46657 steps/s (collection: 1.979s, learning 0.128s)
             Mean action noise std: 3.15
          Mean value_function loss: 69.5568
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.4864
                       Mean reward: 637.79
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 1.0745
    Episode_Reward/rotating_object: 128.7986
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.11s
                      Time elapsed: 00:50:33
                               ETA: 00:33:12

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 46628 steps/s (collection: 1.977s, learning 0.131s)
             Mean action noise std: 3.16
          Mean value_function loss: 55.7550
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.5140
                       Mean reward: 665.66
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 1.0584
    Episode_Reward/rotating_object: 125.5934
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.11s
                      Time elapsed: 00:50:35
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 47080 steps/s (collection: 1.970s, learning 0.118s)
             Mean action noise std: 3.16
          Mean value_function loss: 54.8343
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.5391
                       Mean reward: 681.81
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 128.3616
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.09s
                      Time elapsed: 00:50:37
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 47285 steps/s (collection: 1.949s, learning 0.130s)
             Mean action noise std: 3.16
          Mean value_function loss: 63.8146
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.5497
                       Mean reward: 614.58
               Mean episode length: 239.06
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 125.6430
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.08s
                      Time elapsed: 00:50:39
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 47524 steps/s (collection: 1.938s, learning 0.130s)
             Mean action noise std: 3.17
          Mean value_function loss: 53.1764
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.5604
                       Mean reward: 616.04
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.0599
    Episode_Reward/rotating_object: 127.4378
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.07s
                      Time elapsed: 00:50:41
                               ETA: 00:32:55

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 47330 steps/s (collection: 1.953s, learning 0.124s)
             Mean action noise std: 3.17
          Mean value_function loss: 62.3461
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.5775
                       Mean reward: 593.92
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.0686
    Episode_Reward/rotating_object: 125.9249
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.08s
                      Time elapsed: 00:50:43
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 46327 steps/s (collection: 2.000s, learning 0.122s)
             Mean action noise std: 3.17
          Mean value_function loss: 59.5326
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.6044
                       Mean reward: 648.79
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.0305
    Episode_Reward/rotating_object: 120.6077
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.12s
                      Time elapsed: 00:50:46
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 47558 steps/s (collection: 1.942s, learning 0.125s)
             Mean action noise std: 3.18
          Mean value_function loss: 58.2094
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.6315
                       Mean reward: 643.89
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0577
    Episode_Reward/rotating_object: 125.4239
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.07s
                      Time elapsed: 00:50:48
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 47902 steps/s (collection: 1.946s, learning 0.107s)
             Mean action noise std: 3.18
          Mean value_function loss: 59.3411
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.6496
                       Mean reward: 629.16
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.0522
    Episode_Reward/rotating_object: 124.5462
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.05s
                      Time elapsed: 00:50:50
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 46092 steps/s (collection: 2.004s, learning 0.129s)
             Mean action noise std: 3.18
          Mean value_function loss: 58.7755
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.6713
                       Mean reward: 669.30
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 130.6040
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.13s
                      Time elapsed: 00:50:52
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 47013 steps/s (collection: 1.958s, learning 0.133s)
             Mean action noise std: 3.19
          Mean value_function loss: 59.3305
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.6915
                       Mean reward: 667.30
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 125.0379
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.09s
                      Time elapsed: 00:50:54
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 48052 steps/s (collection: 1.919s, learning 0.127s)
             Mean action noise std: 3.19
          Mean value_function loss: 58.9349
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.7145
                       Mean reward: 629.99
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 130.6984
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.05s
                      Time elapsed: 00:50:56
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 47498 steps/s (collection: 1.957s, learning 0.113s)
             Mean action noise std: 3.19
          Mean value_function loss: 55.6436
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.7315
                       Mean reward: 640.24
               Mean episode length: 244.58
    Episode_Reward/reaching_object: 1.0606
    Episode_Reward/rotating_object: 122.7900
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.07s
                      Time elapsed: 00:50:58
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 46751 steps/s (collection: 1.985s, learning 0.118s)
             Mean action noise std: 3.20
          Mean value_function loss: 56.7490
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 55.7483
                       Mean reward: 662.50
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 1.0724
    Episode_Reward/rotating_object: 130.9286
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.10s
                      Time elapsed: 00:51:00
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 39690 steps/s (collection: 2.326s, learning 0.151s)
             Mean action noise std: 3.20
          Mean value_function loss: 56.8721
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.7627
                       Mean reward: 664.21
               Mean episode length: 239.80
    Episode_Reward/reaching_object: 1.0470
    Episode_Reward/rotating_object: 125.3029
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.48s
                      Time elapsed: 00:51:03
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 43908 steps/s (collection: 2.124s, learning 0.115s)
             Mean action noise std: 3.20
          Mean value_function loss: 51.7492
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.7810
                       Mean reward: 701.26
               Mean episode length: 246.35
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 130.0082
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.24s
                      Time elapsed: 00:51:05
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 45852 steps/s (collection: 2.027s, learning 0.117s)
             Mean action noise std: 3.20
          Mean value_function loss: 57.6568
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.7970
                       Mean reward: 664.09
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.0669
    Episode_Reward/rotating_object: 126.9248
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.14s
                      Time elapsed: 00:51:07
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 44065 steps/s (collection: 2.089s, learning 0.142s)
             Mean action noise std: 3.21
          Mean value_function loss: 56.9315
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.8235
                       Mean reward: 581.40
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 1.0736
    Episode_Reward/rotating_object: 128.7523
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.23s
                      Time elapsed: 00:51:09
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 45830 steps/s (collection: 2.023s, learning 0.122s)
             Mean action noise std: 3.21
          Mean value_function loss: 54.8206
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.8517
                       Mean reward: 655.85
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 1.0730
    Episode_Reward/rotating_object: 128.3792
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.14s
                      Time elapsed: 00:51:11
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 46941 steps/s (collection: 1.967s, learning 0.128s)
             Mean action noise std: 3.21
          Mean value_function loss: 51.9387
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.8672
                       Mean reward: 660.24
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 129.7697
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.09s
                      Time elapsed: 00:51:13
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 45562 steps/s (collection: 2.001s, learning 0.157s)
             Mean action noise std: 3.21
          Mean value_function loss: 59.1155
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.8754
                       Mean reward: 676.55
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 130.4471
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.16s
                      Time elapsed: 00:51:16
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 47584 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 3.22
          Mean value_function loss: 66.8616
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 55.8964
                       Mean reward: 625.99
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 128.7609
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.07s
                      Time elapsed: 00:51:18
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 45528 steps/s (collection: 2.033s, learning 0.126s)
             Mean action noise std: 3.22
          Mean value_function loss: 61.3087
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.9238
                       Mean reward: 665.42
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.0567
    Episode_Reward/rotating_object: 129.7930
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.16s
                      Time elapsed: 00:51:20
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 46986 steps/s (collection: 1.991s, learning 0.102s)
             Mean action noise std: 3.23
          Mean value_function loss: 63.5519
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.9531
                       Mean reward: 654.92
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.0707
    Episode_Reward/rotating_object: 129.7263
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.09s
                      Time elapsed: 00:51:22
                               ETA: 00:31:37

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 48063 steps/s (collection: 1.952s, learning 0.094s)
             Mean action noise std: 3.23
          Mean value_function loss: 62.4255
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.9845
                       Mean reward: 655.32
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 127.8168
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.05s
                      Time elapsed: 00:51:24
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 46974 steps/s (collection: 1.977s, learning 0.116s)
             Mean action noise std: 3.23
          Mean value_function loss: 60.0476
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.0051
                       Mean reward: 643.83
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 130.6228
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.09s
                      Time elapsed: 00:51:26
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 46949 steps/s (collection: 1.984s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 59.2524
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.0287
                       Mean reward: 571.69
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 1.0634
    Episode_Reward/rotating_object: 125.3791
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.09s
                      Time elapsed: 00:51:28
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 47290 steps/s (collection: 1.974s, learning 0.105s)
             Mean action noise std: 3.24
          Mean value_function loss: 69.5401
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.0488
                       Mean reward: 657.91
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 1.0507
    Episode_Reward/rotating_object: 122.7020
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.08s
                      Time elapsed: 00:51:30
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 47519 steps/s (collection: 1.950s, learning 0.119s)
             Mean action noise std: 3.24
          Mean value_function loss: 58.9422
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.0647
                       Mean reward: 656.57
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 129.5511
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.07s
                      Time elapsed: 00:51:32
                               ETA: 00:31:17

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 46531 steps/s (collection: 1.986s, learning 0.127s)
             Mean action noise std: 3.25
          Mean value_function loss: 68.0202
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 56.0816
                       Mean reward: 652.95
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.0426
    Episode_Reward/rotating_object: 124.7385
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.11s
                      Time elapsed: 00:51:34
                               ETA: 00:31:13

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 46964 steps/s (collection: 1.939s, learning 0.155s)
             Mean action noise std: 3.25
          Mean value_function loss: 54.0567
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.1038
                       Mean reward: 632.18
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 1.0654
    Episode_Reward/rotating_object: 124.7070
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.09s
                      Time elapsed: 00:51:37
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 47848 steps/s (collection: 1.948s, learning 0.106s)
             Mean action noise std: 3.25
          Mean value_function loss: 65.8670
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.1308
                       Mean reward: 672.33
               Mean episode length: 246.75
    Episode_Reward/reaching_object: 1.0530
    Episode_Reward/rotating_object: 124.5043
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.05s
                      Time elapsed: 00:51:39
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 47392 steps/s (collection: 1.963s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 59.9797
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.1555
                       Mean reward: 601.14
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 127.0096
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.07s
                      Time elapsed: 00:51:41
                               ETA: 00:31:01

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 47323 steps/s (collection: 1.953s, learning 0.124s)
             Mean action noise std: 3.26
          Mean value_function loss: 52.7839
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 56.1836
                       Mean reward: 603.83
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.0673
    Episode_Reward/rotating_object: 128.5103
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.08s
                      Time elapsed: 00:51:43
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 44404 steps/s (collection: 2.056s, learning 0.158s)
             Mean action noise std: 3.27
          Mean value_function loss: 60.4272
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.2185
                       Mean reward: 639.70
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 126.0033
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.21s
                      Time elapsed: 00:51:45
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 45467 steps/s (collection: 2.053s, learning 0.109s)
             Mean action noise std: 3.27
          Mean value_function loss: 66.7078
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 56.2444
                       Mean reward: 687.12
               Mean episode length: 249.22
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 129.6378
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.16s
                      Time elapsed: 00:51:47
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 47597 steps/s (collection: 1.965s, learning 0.101s)
             Mean action noise std: 3.27
          Mean value_function loss: 58.9912
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.2642
                       Mean reward: 580.38
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.0453
    Episode_Reward/rotating_object: 119.6542
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.07s
                      Time elapsed: 00:51:49
                               ETA: 00:30:45

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 44940 steps/s (collection: 2.063s, learning 0.124s)
             Mean action noise std: 3.28
          Mean value_function loss: 60.0984
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 56.2896
                       Mean reward: 614.44
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 126.5080
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.19s
                      Time elapsed: 00:51:51
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 47464 steps/s (collection: 1.956s, learning 0.115s)
             Mean action noise std: 3.28
          Mean value_function loss: 51.8123
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.3144
                       Mean reward: 658.60
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 130.6233
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.07s
                      Time elapsed: 00:51:53
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 47096 steps/s (collection: 1.962s, learning 0.126s)
             Mean action noise std: 3.29
          Mean value_function loss: 60.4622
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.3409
                       Mean reward: 611.99
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.0725
    Episode_Reward/rotating_object: 127.9723
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.09s
                      Time elapsed: 00:51:56
                               ETA: 00:30:33

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 47193 steps/s (collection: 1.950s, learning 0.133s)
             Mean action noise std: 3.29
          Mean value_function loss: 58.0954
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 56.3645
                       Mean reward: 693.78
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 128.9142
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.08s
                      Time elapsed: 00:51:58
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 47527 steps/s (collection: 1.961s, learning 0.107s)
             Mean action noise std: 3.29
          Mean value_function loss: 59.1834
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 56.3799
                       Mean reward: 618.75
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.0676
    Episode_Reward/rotating_object: 126.6230
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.07s
                      Time elapsed: 00:52:00
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 44856 steps/s (collection: 2.038s, learning 0.154s)
             Mean action noise std: 3.29
          Mean value_function loss: 63.7936
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.3947
                       Mean reward: 686.62
               Mean episode length: 245.04
    Episode_Reward/reaching_object: 1.0449
    Episode_Reward/rotating_object: 124.5356
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.19s
                      Time elapsed: 00:52:02
                               ETA: 00:30:21

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 47324 steps/s (collection: 1.961s, learning 0.117s)
             Mean action noise std: 3.30
          Mean value_function loss: 68.1331
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 56.4144
                       Mean reward: 648.67
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 130.9405
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.08s
                      Time elapsed: 00:52:04
                               ETA: 00:30:17

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 47196 steps/s (collection: 1.970s, learning 0.113s)
             Mean action noise std: 3.30
          Mean value_function loss: 58.8717
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.4394
                       Mean reward: 594.21
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 125.4388
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.08s
                      Time elapsed: 00:52:06
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 47710 steps/s (collection: 1.963s, learning 0.098s)
             Mean action noise std: 3.30
          Mean value_function loss: 60.1615
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.4620
                       Mean reward: 682.42
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.0639
    Episode_Reward/rotating_object: 126.7540
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.06s
                      Time elapsed: 00:52:08
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 46064 steps/s (collection: 2.032s, learning 0.102s)
             Mean action noise std: 3.31
          Mean value_function loss: 70.7253
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.4831
                       Mean reward: 648.21
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 1.0512
    Episode_Reward/rotating_object: 125.1269
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.13s
                      Time elapsed: 00:52:10
                               ETA: 00:30:05

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 47217 steps/s (collection: 1.970s, learning 0.112s)
             Mean action noise std: 3.31
          Mean value_function loss: 66.4433
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.5125
                       Mean reward: 598.65
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.0351
    Episode_Reward/rotating_object: 122.7925
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.08s
                      Time elapsed: 00:52:12
                               ETA: 00:30:01

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 48051 steps/s (collection: 1.944s, learning 0.102s)
             Mean action noise std: 3.32
          Mean value_function loss: 60.2083
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.5474
                       Mean reward: 676.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 129.8488
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.05s
                      Time elapsed: 00:52:14
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 47946 steps/s (collection: 1.951s, learning 0.099s)
             Mean action noise std: 3.32
          Mean value_function loss: 66.1851
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.5708
                       Mean reward: 667.37
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 127.7043
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.05s
                      Time elapsed: 00:52:16
                               ETA: 00:29:53

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 47128 steps/s (collection: 1.984s, learning 0.102s)
             Mean action noise std: 3.32
          Mean value_function loss: 52.3080
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 56.5878
                       Mean reward: 639.69
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.0675
    Episode_Reward/rotating_object: 128.2540
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.09s
                      Time elapsed: 00:52:18
                               ETA: 00:29:49

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 47309 steps/s (collection: 1.982s, learning 0.096s)
             Mean action noise std: 3.33
          Mean value_function loss: 57.8386
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.6021
                       Mean reward: 638.42
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 129.6834
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.08s
                      Time elapsed: 00:52:21
                               ETA: 00:29:45

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 47375 steps/s (collection: 1.977s, learning 0.098s)
             Mean action noise std: 3.33
          Mean value_function loss: 68.0925
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.6232
                       Mean reward: 647.63
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.0583
    Episode_Reward/rotating_object: 127.9125
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.08s
                      Time elapsed: 00:52:23
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 45978 steps/s (collection: 1.983s, learning 0.155s)
             Mean action noise std: 3.33
          Mean value_function loss: 70.3277
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.6334
                       Mean reward: 610.41
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.0496
    Episode_Reward/rotating_object: 123.8764
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.14s
                      Time elapsed: 00:52:25
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 43520 steps/s (collection: 2.087s, learning 0.171s)
             Mean action noise std: 3.33
          Mean value_function loss: 63.0489
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.6530
                       Mean reward: 655.32
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 130.8895
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.26s
                      Time elapsed: 00:52:27
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 46877 steps/s (collection: 1.998s, learning 0.099s)
             Mean action noise std: 3.34
          Mean value_function loss: 71.0786
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.6722
                       Mean reward: 592.84
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.0239
    Episode_Reward/rotating_object: 120.3027
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.10s
                      Time elapsed: 00:52:29
                               ETA: 00:29:29

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 47536 steps/s (collection: 1.961s, learning 0.107s)
             Mean action noise std: 3.34
          Mean value_function loss: 59.1428
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.6955
                       Mean reward: 669.47
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 1.0585
    Episode_Reward/rotating_object: 125.7378
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.07s
                      Time elapsed: 00:52:31
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 47452 steps/s (collection: 1.952s, learning 0.120s)
             Mean action noise std: 3.34
          Mean value_function loss: 61.8756
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.7131
                       Mean reward: 645.72
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 1.0715
    Episode_Reward/rotating_object: 128.0574
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.07s
                      Time elapsed: 00:52:33
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 47435 steps/s (collection: 1.975s, learning 0.098s)
             Mean action noise std: 3.35
          Mean value_function loss: 68.4461
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.7323
                       Mean reward: 637.45
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 1.0580
    Episode_Reward/rotating_object: 124.7384
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.07s
                      Time elapsed: 00:52:35
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 47092 steps/s (collection: 1.978s, learning 0.110s)
             Mean action noise std: 3.35
          Mean value_function loss: 68.4971
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.7465
                       Mean reward: 682.81
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 125.4227
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.09s
                      Time elapsed: 00:52:37
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 46467 steps/s (collection: 2.011s, learning 0.105s)
             Mean action noise std: 3.35
          Mean value_function loss: 69.9771
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.7616
                       Mean reward: 644.05
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.0750
    Episode_Reward/rotating_object: 129.4388
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.12s
                      Time elapsed: 00:52:40
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 46923 steps/s (collection: 1.971s, learning 0.124s)
             Mean action noise std: 3.35
          Mean value_function loss: 63.7090
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.7788
                       Mean reward: 647.97
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 128.7628
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.09s
                      Time elapsed: 00:52:42
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 46219 steps/s (collection: 1.995s, learning 0.132s)
             Mean action noise std: 3.36
          Mean value_function loss: 62.1261
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.7918
                       Mean reward: 654.20
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 1.0854
    Episode_Reward/rotating_object: 129.8028
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.13s
                      Time elapsed: 00:52:44
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 44774 steps/s (collection: 2.058s, learning 0.138s)
             Mean action noise std: 3.36
          Mean value_function loss: 73.6536
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.8117
                       Mean reward: 627.87
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.0629
    Episode_Reward/rotating_object: 122.5413
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.20s
                      Time elapsed: 00:52:46
                               ETA: 00:28:58

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 46303 steps/s (collection: 1.969s, learning 0.154s)
             Mean action noise std: 3.36
          Mean value_function loss: 60.4718
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.8342
                       Mean reward: 683.79
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 131.8518
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.12s
                      Time elapsed: 00:52:48
                               ETA: 00:28:54

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 46793 steps/s (collection: 1.991s, learning 0.110s)
             Mean action noise std: 3.37
          Mean value_function loss: 70.1985
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.8625
                       Mean reward: 611.31
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 1.0366
    Episode_Reward/rotating_object: 119.7266
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.10s
                      Time elapsed: 00:52:50
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 46948 steps/s (collection: 1.998s, learning 0.096s)
             Mean action noise std: 3.37
          Mean value_function loss: 81.6363
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.8915
                       Mean reward: 650.60
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 1.0624
    Episode_Reward/rotating_object: 126.6842
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.09s
                      Time elapsed: 00:52:52
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 47774 steps/s (collection: 1.961s, learning 0.097s)
             Mean action noise std: 3.37
          Mean value_function loss: 72.5031
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.9041
                       Mean reward: 590.40
               Mean episode length: 230.29
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 126.1381
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.06s
                      Time elapsed: 00:52:54
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 47302 steps/s (collection: 1.960s, learning 0.118s)
             Mean action noise std: 3.38
          Mean value_function loss: 72.4329
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.9216
                       Mean reward: 611.62
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.0416
    Episode_Reward/rotating_object: 122.8374
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.08s
                      Time elapsed: 00:52:56
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 47461 steps/s (collection: 1.975s, learning 0.096s)
             Mean action noise std: 3.38
          Mean value_function loss: 69.8761
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.9462
                       Mean reward: 581.54
               Mean episode length: 231.14
    Episode_Reward/reaching_object: 1.0447
    Episode_Reward/rotating_object: 121.2989
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.07s
                      Time elapsed: 00:52:58
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 47226 steps/s (collection: 1.978s, learning 0.104s)
             Mean action noise std: 3.38
          Mean value_function loss: 72.8660
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 56.9651
                       Mean reward: 606.17
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.0478
    Episode_Reward/rotating_object: 124.1997
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.08s
                      Time elapsed: 00:53:01
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 47316 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 3.39
          Mean value_function loss: 78.1040
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.9865
                       Mean reward: 612.92
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 125.3236
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.08s
                      Time elapsed: 00:53:03
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 46798 steps/s (collection: 1.980s, learning 0.121s)
             Mean action noise std: 3.39
          Mean value_function loss: 73.6345
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.0032
                       Mean reward: 606.31
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.0519
    Episode_Reward/rotating_object: 124.9673
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.10s
                      Time elapsed: 00:53:05
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 46380 steps/s (collection: 1.976s, learning 0.144s)
             Mean action noise std: 3.39
          Mean value_function loss: 84.7435
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.0238
                       Mean reward: 615.39
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.0325
    Episode_Reward/rotating_object: 121.6717
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.12s
                      Time elapsed: 00:53:07
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 46507 steps/s (collection: 1.979s, learning 0.135s)
             Mean action noise std: 3.40
          Mean value_function loss: 80.6134
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.0482
                       Mean reward: 603.24
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.0456
    Episode_Reward/rotating_object: 124.4594
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.11s
                      Time elapsed: 00:53:09
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 46631 steps/s (collection: 1.975s, learning 0.133s)
             Mean action noise std: 3.40
          Mean value_function loss: 71.6350
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.0668
                       Mean reward: 629.14
               Mean episode length: 245.15
    Episode_Reward/reaching_object: 1.0526
    Episode_Reward/rotating_object: 124.6931
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.11s
                      Time elapsed: 00:53:11
                               ETA: 00:28:11

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 46678 steps/s (collection: 2.006s, learning 0.100s)
             Mean action noise std: 3.40
          Mean value_function loss: 64.5870
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.0790
                       Mean reward: 627.56
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 1.0672
    Episode_Reward/rotating_object: 124.3175
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.11s
                      Time elapsed: 00:53:13
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 46364 steps/s (collection: 2.003s, learning 0.118s)
             Mean action noise std: 3.40
          Mean value_function loss: 79.8305
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.0866
                       Mean reward: 602.74
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 1.0438
    Episode_Reward/rotating_object: 123.0606
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.12s
                      Time elapsed: 00:53:15
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 47848 steps/s (collection: 1.959s, learning 0.095s)
             Mean action noise std: 3.41
          Mean value_function loss: 75.0897
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.1032
                       Mean reward: 671.83
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.0411
    Episode_Reward/rotating_object: 125.2792
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.05s
                      Time elapsed: 00:53:17
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 47239 steps/s (collection: 1.988s, learning 0.093s)
             Mean action noise std: 3.41
          Mean value_function loss: 73.5822
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.1286
                       Mean reward: 617.78
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.0554
    Episode_Reward/rotating_object: 123.1375
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.08s
                      Time elapsed: 00:53:19
                               ETA: 00:27:56

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 46841 steps/s (collection: 1.977s, learning 0.122s)
             Mean action noise std: 3.41
          Mean value_function loss: 61.0696
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.1540
                       Mean reward: 621.02
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 123.9975
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.10s
                      Time elapsed: 00:53:22
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 47111 steps/s (collection: 1.986s, learning 0.101s)
             Mean action noise std: 3.42
          Mean value_function loss: 63.0179
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.1731
                       Mean reward: 651.57
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 129.1767
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.09s
                      Time elapsed: 00:53:24
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 45676 steps/s (collection: 2.045s, learning 0.107s)
             Mean action noise std: 3.42
          Mean value_function loss: 71.4108
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.1997
                       Mean reward: 624.85
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.0579
    Episode_Reward/rotating_object: 125.4852
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.15s
                      Time elapsed: 00:53:26
                               ETA: 00:27:44

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 43131 steps/s (collection: 2.150s, learning 0.129s)
             Mean action noise std: 3.42
          Mean value_function loss: 70.6743
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.2275
                       Mean reward: 604.06
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 1.0563
    Episode_Reward/rotating_object: 121.3985
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.28s
                      Time elapsed: 00:53:28
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 45676 steps/s (collection: 2.056s, learning 0.096s)
             Mean action noise std: 3.43
          Mean value_function loss: 76.5830
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.2441
                       Mean reward: 618.17
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 1.0458
    Episode_Reward/rotating_object: 123.5738
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.15s
                      Time elapsed: 00:53:30
                               ETA: 00:27:37

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 43696 steps/s (collection: 2.089s, learning 0.161s)
             Mean action noise std: 3.43
          Mean value_function loss: 64.6458
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.2632
                       Mean reward: 659.19
               Mean episode length: 238.68
    Episode_Reward/reaching_object: 1.0615
    Episode_Reward/rotating_object: 128.7610
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.25s
                      Time elapsed: 00:53:32
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 45968 steps/s (collection: 2.039s, learning 0.099s)
             Mean action noise std: 3.43
          Mean value_function loss: 64.0866
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.2816
                       Mean reward: 675.82
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 131.8214
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.14s
                      Time elapsed: 00:53:35
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 43322 steps/s (collection: 2.104s, learning 0.165s)
             Mean action noise std: 3.44
          Mean value_function loss: 78.0203
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.2996
                       Mean reward: 620.71
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 126.9223
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.27s
                      Time elapsed: 00:53:37
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 44393 steps/s (collection: 2.092s, learning 0.122s)
             Mean action noise std: 3.44
          Mean value_function loss: 71.9349
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 57.3164
                       Mean reward: 625.48
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.0723
    Episode_Reward/rotating_object: 127.6261
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.21s
                      Time elapsed: 00:53:39
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 44160 steps/s (collection: 2.110s, learning 0.116s)
             Mean action noise std: 3.44
          Mean value_function loss: 77.0786
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.3246
                       Mean reward: 644.93
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 129.3403
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.23s
                      Time elapsed: 00:53:41
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 46629 steps/s (collection: 2.014s, learning 0.094s)
             Mean action noise std: 3.44
          Mean value_function loss: 83.8984
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.3336
                       Mean reward: 611.82
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 1.0611
    Episode_Reward/rotating_object: 129.8520
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.11s
                      Time elapsed: 00:53:43
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 45543 steps/s (collection: 2.052s, learning 0.107s)
             Mean action noise std: 3.44
          Mean value_function loss: 87.1416
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.3517
                       Mean reward: 636.80
               Mean episode length: 235.61
    Episode_Reward/reaching_object: 1.0688
    Episode_Reward/rotating_object: 128.9746
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.16s
                      Time elapsed: 00:53:46
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 46480 steps/s (collection: 2.020s, learning 0.095s)
             Mean action noise std: 3.45
          Mean value_function loss: 74.6027
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.3708
                       Mean reward: 679.47
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.0748
    Episode_Reward/rotating_object: 128.7598
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.11s
                      Time elapsed: 00:53:48
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 45419 steps/s (collection: 2.049s, learning 0.116s)
             Mean action noise std: 3.45
          Mean value_function loss: 69.4975
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.3878
                       Mean reward: 671.99
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 1.0720
    Episode_Reward/rotating_object: 127.3978
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.16s
                      Time elapsed: 00:53:50
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 45654 steps/s (collection: 2.020s, learning 0.134s)
             Mean action noise std: 3.45
          Mean value_function loss: 74.0569
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.4048
                       Mean reward: 708.07
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.0759
    Episode_Reward/rotating_object: 132.7235
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.15s
                      Time elapsed: 00:53:52
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14606 steps/s (collection: 6.590s, learning 0.140s)
             Mean action noise std: 3.46
          Mean value_function loss: 84.5019
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 57.4199
                       Mean reward: 636.50
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.0555
    Episode_Reward/rotating_object: 128.4559
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.73s
                      Time elapsed: 00:53:59
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14642 steps/s (collection: 6.593s, learning 0.120s)
             Mean action noise std: 3.46
          Mean value_function loss: 92.8592
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.4308
                       Mean reward: 687.16
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 129.9989
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.71s
                      Time elapsed: 00:54:05
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14750 steps/s (collection: 6.525s, learning 0.140s)
             Mean action noise std: 3.46
          Mean value_function loss: 95.5936
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.4367
                       Mean reward: 673.78
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 127.3050
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.66s
                      Time elapsed: 00:54:12
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14550 steps/s (collection: 6.636s, learning 0.120s)
             Mean action noise std: 3.46
          Mean value_function loss: 76.0940
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.4433
                       Mean reward: 691.93
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 130.5999
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.76s
                      Time elapsed: 00:54:19
                               ETA: 00:26:53

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14758 steps/s (collection: 6.510s, learning 0.151s)
             Mean action noise std: 3.46
          Mean value_function loss: 83.1616
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 57.4496
                       Mean reward: 630.21
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 128.8476
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.66s
                      Time elapsed: 00:54:26
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14686 steps/s (collection: 6.566s, learning 0.128s)
             Mean action noise std: 3.46
          Mean value_function loss: 87.1964
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.4566
                       Mean reward: 640.87
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.0575
    Episode_Reward/rotating_object: 127.4301
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.69s
                      Time elapsed: 00:54:32
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 14647 steps/s (collection: 6.570s, learning 0.141s)
             Mean action noise std: 3.47
          Mean value_function loss: 77.4944
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.4674
                       Mean reward: 637.94
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 130.0622
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.71s
                      Time elapsed: 00:54:39
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 15082 steps/s (collection: 6.386s, learning 0.132s)
             Mean action noise std: 3.47
          Mean value_function loss: 86.5704
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.4793
                       Mean reward: 661.78
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.0773
    Episode_Reward/rotating_object: 131.1315
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.52s
                      Time elapsed: 00:54:45
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 16020 steps/s (collection: 5.948s, learning 0.188s)
             Mean action noise std: 3.47
          Mean value_function loss: 74.8370
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.4902
                       Mean reward: 709.74
               Mean episode length: 249.55
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 133.2802
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 6.14s
                      Time elapsed: 00:54:52
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 46880 steps/s (collection: 1.953s, learning 0.144s)
             Mean action noise std: 3.47
          Mean value_function loss: 81.1183
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.5118
                       Mean reward: 617.81
               Mean episode length: 227.98
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 123.9054
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.10s
                      Time elapsed: 00:54:54
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 49106 steps/s (collection: 1.888s, learning 0.114s)
             Mean action noise std: 3.48
          Mean value_function loss: 66.1563
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.5340
                       Mean reward: 624.35
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 130.0418
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.00s
                      Time elapsed: 00:54:56
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 47854 steps/s (collection: 1.938s, learning 0.117s)
             Mean action noise std: 3.48
          Mean value_function loss: 77.4721
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.5508
                       Mean reward: 647.25
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 128.7045
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.05s
                      Time elapsed: 00:54:58
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 49471 steps/s (collection: 1.900s, learning 0.087s)
             Mean action noise std: 3.48
          Mean value_function loss: 82.9606
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.5680
                       Mean reward: 628.03
               Mean episode length: 233.44
    Episode_Reward/reaching_object: 1.0665
    Episode_Reward/rotating_object: 130.0397
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.99s
                      Time elapsed: 00:55:00
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 47441 steps/s (collection: 1.973s, learning 0.100s)
             Mean action noise std: 3.49
          Mean value_function loss: 81.1834
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.5852
                       Mean reward: 623.80
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 125.0747
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.07s
                      Time elapsed: 00:55:02
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 49353 steps/s (collection: 1.903s, learning 0.089s)
             Mean action noise std: 3.49
          Mean value_function loss: 81.3184
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.6035
                       Mean reward: 684.31
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.0645
    Episode_Reward/rotating_object: 129.1873
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.99s
                      Time elapsed: 00:55:04
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 48531 steps/s (collection: 1.936s, learning 0.090s)
             Mean action noise std: 3.49
          Mean value_function loss: 82.0667
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.6180
                       Mean reward: 674.46
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 1.0726
    Episode_Reward/rotating_object: 129.3888
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.03s
                      Time elapsed: 00:55:06
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 49110 steps/s (collection: 1.913s, learning 0.089s)
             Mean action noise std: 3.49
          Mean value_function loss: 85.6938
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.6340
                       Mean reward: 606.77
               Mean episode length: 223.67
    Episode_Reward/reaching_object: 1.0400
    Episode_Reward/rotating_object: 128.4627
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.00s
                      Time elapsed: 00:55:08
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 48003 steps/s (collection: 1.934s, learning 0.114s)
             Mean action noise std: 3.50
          Mean value_function loss: 82.9490
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 57.6485
                       Mean reward: 647.52
               Mean episode length: 236.56
    Episode_Reward/reaching_object: 1.0647
    Episode_Reward/rotating_object: 129.3454
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.05s
                      Time elapsed: 00:55:10
                               ETA: 00:26:10

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 48397 steps/s (collection: 1.925s, learning 0.107s)
             Mean action noise std: 3.50
          Mean value_function loss: 81.8386
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.6723
                       Mean reward: 672.16
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.0502
    Episode_Reward/rotating_object: 126.0221
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.03s
                      Time elapsed: 00:55:12
                               ETA: 00:26:06

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 48194 steps/s (collection: 1.950s, learning 0.090s)
             Mean action noise std: 3.50
          Mean value_function loss: 87.3442
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.6926
                       Mean reward: 614.29
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 1.0301
    Episode_Reward/rotating_object: 125.1131
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.04s
                      Time elapsed: 00:55:14
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 45458 steps/s (collection: 2.005s, learning 0.158s)
             Mean action noise std: 3.51
          Mean value_function loss: 72.8913
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.7052
                       Mean reward: 680.14
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.0583
    Episode_Reward/rotating_object: 128.7439
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.16s
                      Time elapsed: 00:55:16
                               ETA: 00:25:59

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 48675 steps/s (collection: 1.924s, learning 0.096s)
             Mean action noise std: 3.51
          Mean value_function loss: 87.9986
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.7176
                       Mean reward: 687.71
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 1.0436
    Episode_Reward/rotating_object: 127.2479
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.02s
                      Time elapsed: 00:55:18
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 48914 steps/s (collection: 1.919s, learning 0.091s)
             Mean action noise std: 3.51
          Mean value_function loss: 80.2305
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.7318
                       Mean reward: 680.08
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.0700
    Episode_Reward/rotating_object: 133.1489
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.01s
                      Time elapsed: 00:55:20
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 48982 steps/s (collection: 1.912s, learning 0.095s)
             Mean action noise std: 3.51
          Mean value_function loss: 79.5148
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.7424
                       Mean reward: 612.33
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.0464
    Episode_Reward/rotating_object: 125.6313
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.01s
                      Time elapsed: 00:55:22
                               ETA: 00:25:47

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 49922 steps/s (collection: 1.874s, learning 0.096s)
             Mean action noise std: 3.52
          Mean value_function loss: 93.0372
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.7536
                       Mean reward: 633.48
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 1.0437
    Episode_Reward/rotating_object: 128.8034
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.97s
                      Time elapsed: 00:55:24
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 48949 steps/s (collection: 1.911s, learning 0.097s)
             Mean action noise std: 3.52
          Mean value_function loss: 94.8605
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.7671
                       Mean reward: 663.51
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.0612
    Episode_Reward/rotating_object: 132.0981
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.01s
                      Time elapsed: 00:55:26
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 48355 steps/s (collection: 1.914s, learning 0.119s)
             Mean action noise std: 3.52
          Mean value_function loss: 80.0149
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.7850
                       Mean reward: 663.79
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0265
    Episode_Reward/rotating_object: 126.3742
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.03s
                      Time elapsed: 00:55:28
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 47366 steps/s (collection: 1.956s, learning 0.120s)
             Mean action noise std: 3.52
          Mean value_function loss: 81.6294
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.8031
                       Mean reward: 642.19
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.0689
    Episode_Reward/rotating_object: 129.6602
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.08s
                      Time elapsed: 00:55:30
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 48488 steps/s (collection: 1.936s, learning 0.092s)
             Mean action noise std: 3.53
          Mean value_function loss: 86.9221
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 57.8190
                       Mean reward: 623.82
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 128.8739
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.03s
                      Time elapsed: 00:55:32
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 48451 steps/s (collection: 1.918s, learning 0.111s)
             Mean action noise std: 3.53
          Mean value_function loss: 75.0813
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.8299
                       Mean reward: 692.81
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 127.2398
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.03s
                      Time elapsed: 00:55:34
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 48922 steps/s (collection: 1.903s, learning 0.106s)
             Mean action noise std: 3.53
          Mean value_function loss: 76.1488
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.8414
                       Mean reward: 677.90
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 129.9888
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.01s
                      Time elapsed: 00:55:36
                               ETA: 00:25:21

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 48619 steps/s (collection: 1.910s, learning 0.112s)
             Mean action noise std: 3.53
          Mean value_function loss: 76.1373
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.8544
                       Mean reward: 637.85
               Mean episode length: 233.73
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 128.7514
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.02s
                      Time elapsed: 00:55:38
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 48537 steps/s (collection: 1.912s, learning 0.114s)
             Mean action noise std: 3.54
          Mean value_function loss: 74.3989
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 57.8645
                       Mean reward: 646.35
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 129.3344
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.03s
                      Time elapsed: 00:55:40
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 49370 steps/s (collection: 1.900s, learning 0.092s)
             Mean action noise std: 3.54
          Mean value_function loss: 73.3671
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.8730
                       Mean reward: 665.38
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.0480
    Episode_Reward/rotating_object: 129.2380
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.99s
                      Time elapsed: 00:55:42
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 47202 steps/s (collection: 1.968s, learning 0.115s)
             Mean action noise std: 3.54
          Mean value_function loss: 74.4645
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.8812
                       Mean reward: 669.80
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0704
    Episode_Reward/rotating_object: 132.1511
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.08s
                      Time elapsed: 00:55:44
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 49003 steps/s (collection: 1.909s, learning 0.098s)
             Mean action noise std: 3.54
          Mean value_function loss: 88.7369
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.8928
                       Mean reward: 704.43
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 132.0010
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.01s
                      Time elapsed: 00:55:46
                               ETA: 00:25:02

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 49570 steps/s (collection: 1.881s, learning 0.103s)
             Mean action noise std: 3.54
          Mean value_function loss: 70.9326
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 57.9062
                       Mean reward: 668.33
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.0497
    Episode_Reward/rotating_object: 128.9917
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.98s
                      Time elapsed: 00:55:48
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 48004 steps/s (collection: 1.930s, learning 0.118s)
             Mean action noise std: 3.55
          Mean value_function loss: 74.7771
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.9254
                       Mean reward: 641.65
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.0574
    Episode_Reward/rotating_object: 128.8585
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.05s
                      Time elapsed: 00:55:50
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 47717 steps/s (collection: 1.949s, learning 0.112s)
             Mean action noise std: 3.55
          Mean value_function loss: 71.3104
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.9482
                       Mean reward: 689.98
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.0539
    Episode_Reward/rotating_object: 129.7633
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.06s
                      Time elapsed: 00:55:53
                               ETA: 00:24:50

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 48175 steps/s (collection: 1.938s, learning 0.103s)
             Mean action noise std: 3.55
          Mean value_function loss: 62.9584
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 57.9616
                       Mean reward: 687.82
               Mean episode length: 240.96
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 133.3257
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.04s
                      Time elapsed: 00:55:55
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 48921 steps/s (collection: 1.893s, learning 0.117s)
             Mean action noise std: 3.56
          Mean value_function loss: 76.7728
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.9784
                       Mean reward: 671.95
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.0741
    Episode_Reward/rotating_object: 132.4460
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.01s
                      Time elapsed: 00:55:57
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 47931 steps/s (collection: 1.920s, learning 0.131s)
             Mean action noise std: 3.56
          Mean value_function loss: 67.2355
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 57.9959
                       Mean reward: 706.04
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 133.4855
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.05s
                      Time elapsed: 00:55:59
                               ETA: 00:24:39

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 48410 steps/s (collection: 1.909s, learning 0.122s)
             Mean action noise std: 3.56
          Mean value_function loss: 75.1071
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.0019
                       Mean reward: 698.47
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 1.0736
    Episode_Reward/rotating_object: 135.3630
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.03s
                      Time elapsed: 00:56:01
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 47427 steps/s (collection: 1.930s, learning 0.143s)
             Mean action noise std: 3.56
          Mean value_function loss: 75.6070
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.0124
                       Mean reward: 658.86
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.0439
    Episode_Reward/rotating_object: 129.9982
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.07s
                      Time elapsed: 00:56:03
                               ETA: 00:24:32

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 48221 steps/s (collection: 1.916s, learning 0.122s)
             Mean action noise std: 3.57
          Mean value_function loss: 77.3673
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.0280
                       Mean reward: 701.63
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 1.0684
    Episode_Reward/rotating_object: 133.1529
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.04s
                      Time elapsed: 00:56:05
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 48795 steps/s (collection: 1.903s, learning 0.112s)
             Mean action noise std: 3.57
          Mean value_function loss: 74.2614
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.0464
                       Mean reward: 728.23
               Mean episode length: 245.22
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 134.1464
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.01s
                      Time elapsed: 00:56:07
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 48806 steps/s (collection: 1.909s, learning 0.105s)
             Mean action noise std: 3.57
          Mean value_function loss: 77.1501
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 58.0587
                       Mean reward: 671.83
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 134.3467
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.01s
                      Time elapsed: 00:56:09
                               ETA: 00:24:20

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 47967 steps/s (collection: 1.922s, learning 0.128s)
             Mean action noise std: 3.57
          Mean value_function loss: 80.4684
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.0653
                       Mean reward: 676.71
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.0494
    Episode_Reward/rotating_object: 129.2803
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.05s
                      Time elapsed: 00:56:11
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 47062 steps/s (collection: 1.976s, learning 0.113s)
             Mean action noise std: 3.57
          Mean value_function loss: 80.2687
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.0775
                       Mean reward: 664.22
               Mean episode length: 232.49
    Episode_Reward/reaching_object: 1.0634
    Episode_Reward/rotating_object: 133.4520
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.09s
                      Time elapsed: 00:56:13
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 47923 steps/s (collection: 1.950s, learning 0.101s)
             Mean action noise std: 3.58
          Mean value_function loss: 80.5367
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.0955
                       Mean reward: 688.73
               Mean episode length: 238.12
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 133.6928
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.05s
                      Time elapsed: 00:56:15
                               ETA: 00:24:09

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 48090 steps/s (collection: 1.930s, learning 0.115s)
             Mean action noise std: 3.58
          Mean value_function loss: 64.5330
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.1211
                       Mean reward: 638.89
               Mean episode length: 227.53
    Episode_Reward/reaching_object: 1.0489
    Episode_Reward/rotating_object: 130.4313
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.04s
                      Time elapsed: 00:56:17
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 41644 steps/s (collection: 2.202s, learning 0.159s)
             Mean action noise std: 3.58
          Mean value_function loss: 78.6028
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 58.1340
                       Mean reward: 607.06
               Mean episode length: 218.51
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 132.6715
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.36s
                      Time elapsed: 00:56:19
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 47257 steps/s (collection: 1.928s, learning 0.153s)
             Mean action noise std: 3.59
          Mean value_function loss: 76.1761
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.1425
                       Mean reward: 694.12
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 1.0628
    Episode_Reward/rotating_object: 132.1799
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.08s
                      Time elapsed: 00:56:21
                               ETA: 00:23:58

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 45712 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 3.59
          Mean value_function loss: 80.9163
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.1637
                       Mean reward: 685.85
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.0438
    Episode_Reward/rotating_object: 126.9356
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.15s
                      Time elapsed: 00:56:24
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 47749 steps/s (collection: 1.951s, learning 0.108s)
             Mean action noise std: 3.59
          Mean value_function loss: 80.3018
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.1822
                       Mean reward: 668.09
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 132.6521
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.06s
                      Time elapsed: 00:56:26
                               ETA: 00:23:51

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 44173 steps/s (collection: 2.041s, learning 0.184s)
             Mean action noise std: 3.59
          Mean value_function loss: 76.1022
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.1917
                       Mean reward: 697.85
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 1.0712
    Episode_Reward/rotating_object: 134.4892
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.23s
                      Time elapsed: 00:56:28
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 47092 steps/s (collection: 1.928s, learning 0.159s)
             Mean action noise std: 3.60
          Mean value_function loss: 80.4795
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.1980
                       Mean reward: 618.97
               Mean episode length: 225.71
    Episode_Reward/reaching_object: 1.0748
    Episode_Reward/rotating_object: 132.7633
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.09s
                      Time elapsed: 00:56:30
                               ETA: 00:23:44

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 48237 steps/s (collection: 1.931s, learning 0.107s)
             Mean action noise std: 3.60
          Mean value_function loss: 84.4743
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.2089
                       Mean reward: 682.59
               Mean episode length: 239.41
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 132.6635
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.04s
                      Time elapsed: 00:56:32
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 48157 steps/s (collection: 1.924s, learning 0.118s)
             Mean action noise std: 3.60
          Mean value_function loss: 78.9647
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.2229
                       Mean reward: 675.73
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 133.9953
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.04s
                      Time elapsed: 00:56:34
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 49176 steps/s (collection: 1.907s, learning 0.092s)
             Mean action noise std: 3.61
          Mean value_function loss: 87.7145
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.2411
                       Mean reward: 665.71
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.0465
    Episode_Reward/rotating_object: 128.6450
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.00s
                      Time elapsed: 00:56:36
                               ETA: 00:23:33

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 49580 steps/s (collection: 1.884s, learning 0.099s)
             Mean action noise std: 3.61
          Mean value_function loss: 86.6089
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.2585
                       Mean reward: 658.49
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.0500
    Episode_Reward/rotating_object: 130.6279
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.98s
                      Time elapsed: 00:56:38
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 47126 steps/s (collection: 1.984s, learning 0.102s)
             Mean action noise std: 3.61
          Mean value_function loss: 84.8037
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.2672
                       Mean reward: 605.82
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 1.0312
    Episode_Reward/rotating_object: 126.9242
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.09s
                      Time elapsed: 00:56:40
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 47356 steps/s (collection: 1.943s, learning 0.133s)
             Mean action noise std: 3.61
          Mean value_function loss: 77.9159
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.2803
                       Mean reward: 635.69
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 1.0441
    Episode_Reward/rotating_object: 130.3815
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.08s
                      Time elapsed: 00:56:42
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 46906 steps/s (collection: 1.996s, learning 0.100s)
             Mean action noise std: 3.61
          Mean value_function loss: 72.5166
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.2989
                       Mean reward: 647.83
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.0387
    Episode_Reward/rotating_object: 127.4525
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.10s
                      Time elapsed: 00:56:44
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 47423 steps/s (collection: 1.950s, learning 0.123s)
             Mean action noise std: 3.62
          Mean value_function loss: 77.5314
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 58.3074
                       Mean reward: 685.87
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.0551
    Episode_Reward/rotating_object: 132.3108
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.07s
                      Time elapsed: 00:56:46
                               ETA: 00:23:14

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 48412 steps/s (collection: 1.929s, learning 0.101s)
             Mean action noise std: 3.62
          Mean value_function loss: 88.5892
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.3107
                       Mean reward: 671.84
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.0561
    Episode_Reward/rotating_object: 130.1024
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.03s
                      Time elapsed: 00:56:48
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 44621 steps/s (collection: 2.103s, learning 0.101s)
             Mean action noise std: 3.62
          Mean value_function loss: 83.6634
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 58.3197
                       Mean reward: 661.33
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.0510
    Episode_Reward/rotating_object: 130.2461
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.20s
                      Time elapsed: 00:56:51
                               ETA: 00:23:07

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 44597 steps/s (collection: 2.113s, learning 0.091s)
             Mean action noise std: 3.62
          Mean value_function loss: 70.7220
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.3356
                       Mean reward: 692.70
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 133.4510
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.20s
                      Time elapsed: 00:56:53
                               ETA: 00:23:03

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 46858 steps/s (collection: 1.946s, learning 0.152s)
             Mean action noise std: 3.63
          Mean value_function loss: 89.1567
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.3502
                       Mean reward: 697.50
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.0440
    Episode_Reward/rotating_object: 132.2480
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.10s
                      Time elapsed: 00:56:55
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 45407 steps/s (collection: 2.026s, learning 0.139s)
             Mean action noise std: 3.63
          Mean value_function loss: 78.9678
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.3640
                       Mean reward: 649.38
               Mean episode length: 229.56
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 133.8398
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.16s
                      Time elapsed: 00:56:57
                               ETA: 00:22:56

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 46926 steps/s (collection: 1.982s, learning 0.113s)
             Mean action noise std: 3.63
          Mean value_function loss: 77.3909
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.3751
                       Mean reward: 679.38
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 132.5711
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.09s
                      Time elapsed: 00:56:59
                               ETA: 00:22:52

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 47232 steps/s (collection: 1.982s, learning 0.099s)
             Mean action noise std: 3.63
          Mean value_function loss: 63.1114
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.3936
                       Mean reward: 671.46
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.0664
    Episode_Reward/rotating_object: 133.3428
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.08s
                      Time elapsed: 00:57:01
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 47525 steps/s (collection: 1.943s, learning 0.125s)
             Mean action noise std: 3.64
          Mean value_function loss: 77.3993
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 58.4144
                       Mean reward: 678.40
               Mean episode length: 234.23
    Episode_Reward/reaching_object: 1.0357
    Episode_Reward/rotating_object: 129.3998
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.07s
                      Time elapsed: 00:57:03
                               ETA: 00:22:45

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 47504 steps/s (collection: 1.957s, learning 0.112s)
             Mean action noise std: 3.64
          Mean value_function loss: 65.6742
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.4253
                       Mean reward: 699.30
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 131.6631
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.07s
                      Time elapsed: 00:57:05
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 48195 steps/s (collection: 1.940s, learning 0.100s)
             Mean action noise std: 3.64
          Mean value_function loss: 67.9871
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.4414
                       Mean reward: 704.16
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 1.0772
    Episode_Reward/rotating_object: 135.2671
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.04s
                      Time elapsed: 00:57:07
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 46011 steps/s (collection: 2.001s, learning 0.135s)
             Mean action noise std: 3.64
          Mean value_function loss: 77.0830
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 58.4633
                       Mean reward: 666.12
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.0334
    Episode_Reward/rotating_object: 128.8005
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.14s
                      Time elapsed: 00:57:10
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 46544 steps/s (collection: 1.995s, learning 0.117s)
             Mean action noise std: 3.65
          Mean value_function loss: 78.2110
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.4835
                       Mean reward: 672.41
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.0575
    Episode_Reward/rotating_object: 133.9246
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.11s
                      Time elapsed: 00:57:12
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 47970 steps/s (collection: 1.941s, learning 0.108s)
             Mean action noise std: 3.65
          Mean value_function loss: 85.4657
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 58.4949
                       Mean reward: 703.42
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 135.7212
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.05s
                      Time elapsed: 00:57:14
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 40813 steps/s (collection: 2.189s, learning 0.219s)
             Mean action noise std: 3.65
          Mean value_function loss: 85.0313
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.5032
                       Mean reward: 630.96
               Mean episode length: 225.92
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 129.7942
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.41s
                      Time elapsed: 00:57:16
                               ETA: 00:22:24

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 46917 steps/s (collection: 2.006s, learning 0.089s)
             Mean action noise std: 3.65
          Mean value_function loss: 69.5991
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.5136
                       Mean reward: 703.44
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 1.0577
    Episode_Reward/rotating_object: 131.6424
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.10s
                      Time elapsed: 00:57:18
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 48139 steps/s (collection: 1.935s, learning 0.107s)
             Mean action noise std: 3.66
          Mean value_function loss: 68.8369
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.5244
                       Mean reward: 676.92
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.0749
    Episode_Reward/rotating_object: 137.2104
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.04s
                      Time elapsed: 00:57:20
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 48062 steps/s (collection: 1.949s, learning 0.097s)
             Mean action noise std: 3.66
          Mean value_function loss: 80.0971
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.5416
                       Mean reward: 696.80
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.0612
    Episode_Reward/rotating_object: 134.2146
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.05s
                      Time elapsed: 00:57:22
                               ETA: 00:22:13

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 48074 steps/s (collection: 1.944s, learning 0.100s)
             Mean action noise std: 3.66
          Mean value_function loss: 63.3165
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 58.5548
                       Mean reward: 633.36
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 131.8531
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.04s
                      Time elapsed: 00:57:24
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 49279 steps/s (collection: 1.905s, learning 0.090s)
             Mean action noise std: 3.66
          Mean value_function loss: 77.4008
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.5657
                       Mean reward: 676.09
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 132.7798
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.99s
                      Time elapsed: 00:57:26
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 46429 steps/s (collection: 2.019s, learning 0.099s)
             Mean action noise std: 3.67
          Mean value_function loss: 90.3368
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.5806
                       Mean reward: 679.02
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 1.0564
    Episode_Reward/rotating_object: 132.1836
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.12s
                      Time elapsed: 00:57:28
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 47276 steps/s (collection: 1.977s, learning 0.103s)
             Mean action noise std: 3.67
          Mean value_function loss: 73.8525
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 58.5981
                       Mean reward: 699.11
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 135.7284
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.08s
                      Time elapsed: 00:57:31
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 47595 steps/s (collection: 1.962s, learning 0.103s)
             Mean action noise std: 3.67
          Mean value_function loss: 73.1352
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.6091
                       Mean reward: 653.83
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.0631
    Episode_Reward/rotating_object: 132.2886
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.07s
                      Time elapsed: 00:57:33
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 49006 steps/s (collection: 1.907s, learning 0.099s)
             Mean action noise std: 3.67
          Mean value_function loss: 80.5805
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.6195
                       Mean reward: 691.25
               Mean episode length: 234.46
    Episode_Reward/reaching_object: 1.0544
    Episode_Reward/rotating_object: 132.6774
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.01s
                      Time elapsed: 00:57:35
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 47256 steps/s (collection: 1.989s, learning 0.091s)
             Mean action noise std: 3.68
          Mean value_function loss: 82.4915
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.6390
                       Mean reward: 701.54
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 137.6930
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.08s
                      Time elapsed: 00:57:37
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 46715 steps/s (collection: 2.003s, learning 0.101s)
             Mean action noise std: 3.68
          Mean value_function loss: 71.1332
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.6625
                       Mean reward: 684.44
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 133.7636
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.10s
                      Time elapsed: 00:57:39
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 47960 steps/s (collection: 1.955s, learning 0.095s)
             Mean action noise std: 3.68
          Mean value_function loss: 82.9297
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.6793
                       Mean reward: 646.04
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.0503
    Episode_Reward/rotating_object: 132.4026
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.05s
                      Time elapsed: 00:57:41
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 47382 steps/s (collection: 1.960s, learning 0.115s)
             Mean action noise std: 3.69
          Mean value_function loss: 74.8685
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.6957
                       Mean reward: 656.28
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 1.0301
    Episode_Reward/rotating_object: 129.6825
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.07s
                      Time elapsed: 00:57:43
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 46662 steps/s (collection: 1.984s, learning 0.123s)
             Mean action noise std: 3.69
          Mean value_function loss: 75.5260
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.7071
                       Mean reward: 664.32
               Mean episode length: 229.00
    Episode_Reward/reaching_object: 1.0570
    Episode_Reward/rotating_object: 133.6140
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.11s
                      Time elapsed: 00:57:45
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 48103 steps/s (collection: 1.946s, learning 0.098s)
             Mean action noise std: 3.69
          Mean value_function loss: 76.0513
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.7199
                       Mean reward: 675.51
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 1.0590
    Episode_Reward/rotating_object: 131.0784
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.04s
                      Time elapsed: 00:57:47
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 46494 steps/s (collection: 1.983s, learning 0.132s)
             Mean action noise std: 3.70
          Mean value_function loss: 83.6060
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.7434
                       Mean reward: 693.87
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.0334
    Episode_Reward/rotating_object: 129.0277
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.11s
                      Time elapsed: 00:57:49
                               ETA: 00:21:26

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 47158 steps/s (collection: 1.953s, learning 0.132s)
             Mean action noise std: 3.70
          Mean value_function loss: 69.6412
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.7601
                       Mean reward: 643.26
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 133.7604
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.08s
                      Time elapsed: 00:57:51
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 47307 steps/s (collection: 1.952s, learning 0.126s)
             Mean action noise std: 3.70
          Mean value_function loss: 86.4709
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.7693
                       Mean reward: 690.62
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.0697
    Episode_Reward/rotating_object: 136.6646
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.08s
                      Time elapsed: 00:57:53
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 45789 steps/s (collection: 2.035s, learning 0.112s)
             Mean action noise std: 3.70
          Mean value_function loss: 73.4319
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.7902
                       Mean reward: 625.27
               Mean episode length: 226.22
    Episode_Reward/reaching_object: 1.0506
    Episode_Reward/rotating_object: 133.0483
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.15s
                      Time elapsed: 00:57:55
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 46353 steps/s (collection: 2.022s, learning 0.098s)
             Mean action noise std: 3.71
          Mean value_function loss: 93.9280
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.8188
                       Mean reward: 669.80
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.0409
    Episode_Reward/rotating_object: 129.8126
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.12s
                      Time elapsed: 00:57:58
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 46024 steps/s (collection: 2.024s, learning 0.112s)
             Mean action noise std: 3.71
          Mean value_function loss: 75.5563
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.8415
                       Mean reward: 636.55
               Mean episode length: 226.19
    Episode_Reward/reaching_object: 1.0480
    Episode_Reward/rotating_object: 132.5079
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.14s
                      Time elapsed: 00:58:00
                               ETA: 00:21:08

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 46835 steps/s (collection: 1.987s, learning 0.112s)
             Mean action noise std: 3.72
          Mean value_function loss: 70.6475
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.8559
                       Mean reward: 657.81
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.0470
    Episode_Reward/rotating_object: 133.1009
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.10s
                      Time elapsed: 00:58:02
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 45740 steps/s (collection: 2.037s, learning 0.112s)
             Mean action noise std: 3.72
          Mean value_function loss: 80.6969
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.8663
                       Mean reward: 665.41
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 1.0472
    Episode_Reward/rotating_object: 132.4844
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.15s
                      Time elapsed: 00:58:04
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 46927 steps/s (collection: 1.981s, learning 0.114s)
             Mean action noise std: 3.72
          Mean value_function loss: 71.7585
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 58.8803
                       Mean reward: 697.11
               Mean episode length: 236.19
    Episode_Reward/reaching_object: 1.0553
    Episode_Reward/rotating_object: 135.0310
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.09s
                      Time elapsed: 00:58:06
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 45766 steps/s (collection: 1.981s, learning 0.167s)
             Mean action noise std: 3.72
          Mean value_function loss: 69.5907
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 58.8977
                       Mean reward: 631.49
               Mean episode length: 224.11
    Episode_Reward/reaching_object: 1.0338
    Episode_Reward/rotating_object: 129.9263
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.15s
                      Time elapsed: 00:58:08
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 46726 steps/s (collection: 1.980s, learning 0.124s)
             Mean action noise std: 3.73
          Mean value_function loss: 82.2511
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.9128
                       Mean reward: 687.33
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 136.3190
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.10s
                      Time elapsed: 00:58:10
                               ETA: 00:20:51

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 46891 steps/s (collection: 1.985s, learning 0.111s)
             Mean action noise std: 3.73
          Mean value_function loss: 70.7707
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.9359
                       Mean reward: 664.94
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 1.0458
    Episode_Reward/rotating_object: 132.4547
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.10s
                      Time elapsed: 00:58:12
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 47292 steps/s (collection: 1.911s, learning 0.168s)
             Mean action noise std: 3.73
          Mean value_function loss: 66.7854
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.9510
                       Mean reward: 690.31
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.0563
    Episode_Reward/rotating_object: 133.8293
        Episode_Reward/action_rate: -0.0694
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.08s
                      Time elapsed: 00:58:15
                               ETA: 00:20:43

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 48071 steps/s (collection: 1.953s, learning 0.092s)
             Mean action noise std: 3.74
          Mean value_function loss: 66.9668
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.9659
                       Mean reward: 691.92
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 134.2407
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.04s
                      Time elapsed: 00:58:17
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 46650 steps/s (collection: 1.987s, learning 0.120s)
             Mean action noise std: 3.74
          Mean value_function loss: 76.4175
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.9802
                       Mean reward: 683.72
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 135.1459
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.11s
                      Time elapsed: 00:58:19
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 43940 steps/s (collection: 2.092s, learning 0.146s)
             Mean action noise std: 3.74
          Mean value_function loss: 73.6943
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.9902
                       Mean reward: 685.98
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 136.7721
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.24s
                      Time elapsed: 00:58:21
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 46147 steps/s (collection: 2.016s, learning 0.114s)
             Mean action noise std: 3.74
          Mean value_function loss: 68.2818
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.0002
                       Mean reward: 676.89
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.0589
    Episode_Reward/rotating_object: 134.1152
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.13s
                      Time elapsed: 00:58:23
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 46816 steps/s (collection: 1.951s, learning 0.149s)
             Mean action noise std: 3.75
          Mean value_function loss: 80.8447
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.0128
                       Mean reward: 671.30
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 134.7661
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.10s
                      Time elapsed: 00:58:25
                               ETA: 00:20:26

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 46000 steps/s (collection: 2.008s, learning 0.129s)
             Mean action noise std: 3.75
          Mean value_function loss: 77.5217
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.0292
                       Mean reward: 696.39
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 1.0554
    Episode_Reward/rotating_object: 135.7654
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.14s
                      Time elapsed: 00:58:27
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 45505 steps/s (collection: 2.045s, learning 0.116s)
             Mean action noise std: 3.75
          Mean value_function loss: 77.3076
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.0456
                       Mean reward: 617.62
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.0290
    Episode_Reward/rotating_object: 129.3796
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.16s
                      Time elapsed: 00:58:29
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 46593 steps/s (collection: 2.000s, learning 0.110s)
             Mean action noise std: 3.76
          Mean value_function loss: 78.3831
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.0579
                       Mean reward: 658.83
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 1.0668
    Episode_Reward/rotating_object: 137.1001
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.11s
                      Time elapsed: 00:58:32
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 47508 steps/s (collection: 1.973s, learning 0.097s)
             Mean action noise std: 3.76
          Mean value_function loss: 76.9433
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 59.0721
                       Mean reward: 694.29
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 1.0432
    Episode_Reward/rotating_object: 130.5276
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.07s
                      Time elapsed: 00:58:34
                               ETA: 00:20:12

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 45496 steps/s (collection: 1.992s, learning 0.169s)
             Mean action noise std: 3.76
          Mean value_function loss: 67.9299
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.0853
                       Mean reward: 707.54
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 135.2779
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.16s
                      Time elapsed: 00:58:36
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 45629 steps/s (collection: 2.054s, learning 0.100s)
             Mean action noise std: 3.76
          Mean value_function loss: 70.5768
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.1000
                       Mean reward: 652.30
               Mean episode length: 227.74
    Episode_Reward/reaching_object: 1.0617
    Episode_Reward/rotating_object: 134.0879
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.15s
                      Time elapsed: 00:58:38
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 46508 steps/s (collection: 2.012s, learning 0.102s)
             Mean action noise std: 3.77
          Mean value_function loss: 66.0855
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.1114
                       Mean reward: 669.56
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 136.7296
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.11s
                      Time elapsed: 00:58:40
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 42289 steps/s (collection: 2.154s, learning 0.170s)
             Mean action noise std: 3.77
          Mean value_function loss: 69.3416
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.1244
                       Mean reward: 703.98
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.0625
    Episode_Reward/rotating_object: 136.6771
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.32s
                      Time elapsed: 00:58:42
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 44838 steps/s (collection: 2.074s, learning 0.118s)
             Mean action noise std: 3.77
          Mean value_function loss: 69.8992
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.1383
                       Mean reward: 719.76
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.0630
    Episode_Reward/rotating_object: 135.5493
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.19s
                      Time elapsed: 00:58:45
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 43450 steps/s (collection: 2.142s, learning 0.120s)
             Mean action noise std: 3.78
          Mean value_function loss: 75.8285
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.1576
                       Mean reward: 656.15
               Mean episode length: 225.03
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 138.3509
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.26s
                      Time elapsed: 00:58:47
                               ETA: 00:19:51

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 44982 steps/s (collection: 2.066s, learning 0.120s)
             Mean action noise std: 3.78
          Mean value_function loss: 61.3326
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.1756
                       Mean reward: 727.35
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 140.4914
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.19s
                      Time elapsed: 00:58:49
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 47667 steps/s (collection: 1.963s, learning 0.100s)
             Mean action noise std: 3.78
          Mean value_function loss: 70.7610
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 59.1925
                       Mean reward: 691.57
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 1.0766
    Episode_Reward/rotating_object: 137.4765
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.06s
                      Time elapsed: 00:58:51
                               ETA: 00:19:44

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 46805 steps/s (collection: 1.976s, learning 0.124s)
             Mean action noise std: 3.78
          Mean value_function loss: 75.0003
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.2075
                       Mean reward: 685.85
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 135.7120
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.10s
                      Time elapsed: 00:58:53
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 45766 steps/s (collection: 2.018s, learning 0.130s)
             Mean action noise std: 3.79
          Mean value_function loss: 62.7948
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.2276
                       Mean reward: 677.35
               Mean episode length: 232.23
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 136.9648
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.15s
                      Time elapsed: 00:58:55
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 46979 steps/s (collection: 1.943s, learning 0.150s)
             Mean action noise std: 3.79
          Mean value_function loss: 70.4910
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 59.2463
                       Mean reward: 718.67
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 1.0731
    Episode_Reward/rotating_object: 139.0877
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.09s
                      Time elapsed: 00:58:57
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 45121 steps/s (collection: 2.028s, learning 0.151s)
             Mean action noise std: 3.80
          Mean value_function loss: 61.0095
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.2604
                       Mean reward: 633.29
               Mean episode length: 227.19
    Episode_Reward/reaching_object: 1.0512
    Episode_Reward/rotating_object: 132.6600
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.18s
                      Time elapsed: 00:59:00
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 46830 steps/s (collection: 1.992s, learning 0.107s)
             Mean action noise std: 3.80
          Mean value_function loss: 68.0212
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 59.2764
                       Mean reward: 695.38
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 136.8040
        Episode_Reward/action_rate: -0.0728
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.10s
                      Time elapsed: 00:59:02
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 47922 steps/s (collection: 1.960s, learning 0.092s)
             Mean action noise std: 3.80
          Mean value_function loss: 67.0811
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.2883
                       Mean reward: 662.10
               Mean episode length: 232.66
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 136.5035
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.05s
                      Time elapsed: 00:59:04
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 47012 steps/s (collection: 1.971s, learning 0.120s)
             Mean action noise std: 3.80
          Mean value_function loss: 70.9381
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.3012
                       Mean reward: 678.67
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 136.6156
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.09s
                      Time elapsed: 00:59:06
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 46445 steps/s (collection: 2.022s, learning 0.095s)
             Mean action noise std: 3.80
          Mean value_function loss: 70.9750
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.3096
                       Mean reward: 673.15
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 138.0215
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.12s
                      Time elapsed: 00:59:08
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 47197 steps/s (collection: 1.986s, learning 0.097s)
             Mean action noise std: 3.81
          Mean value_function loss: 57.0971
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 59.3222
                       Mean reward: 698.46
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.0826
    Episode_Reward/rotating_object: 138.8207
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.08s
                      Time elapsed: 00:59:10
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 48211 steps/s (collection: 1.938s, learning 0.101s)
             Mean action noise std: 3.81
          Mean value_function loss: 77.9577
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.3360
                       Mean reward: 701.41
               Mean episode length: 237.80
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 136.9743
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.04s
                      Time elapsed: 00:59:12
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 46938 steps/s (collection: 1.987s, learning 0.107s)
             Mean action noise std: 3.81
          Mean value_function loss: 71.4577
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 59.3565
                       Mean reward: 683.86
               Mean episode length: 230.76
    Episode_Reward/reaching_object: 1.0536
    Episode_Reward/rotating_object: 134.8603
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.09s
                      Time elapsed: 00:59:14
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 46496 steps/s (collection: 2.002s, learning 0.112s)
             Mean action noise std: 3.82
          Mean value_function loss: 78.1038
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.3724
                       Mean reward: 650.59
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.0440
    Episode_Reward/rotating_object: 130.8937
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.11s
                      Time elapsed: 00:59:16
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 44884 steps/s (collection: 2.011s, learning 0.179s)
             Mean action noise std: 3.82
          Mean value_function loss: 74.9974
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 59.3853
                       Mean reward: 646.45
               Mean episode length: 225.44
    Episode_Reward/reaching_object: 1.0583
    Episode_Reward/rotating_object: 134.2025
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.19s
                      Time elapsed: 00:59:18
                               ETA: 00:18:59

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 49059 steps/s (collection: 1.908s, learning 0.096s)
             Mean action noise std: 3.82
          Mean value_function loss: 65.1305
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.3889
                       Mean reward: 682.18
               Mean episode length: 234.59
    Episode_Reward/reaching_object: 1.0653
    Episode_Reward/rotating_object: 135.7931
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.00s
                      Time elapsed: 00:59:20
                               ETA: 00:18:55

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 46828 steps/s (collection: 1.951s, learning 0.149s)
             Mean action noise std: 3.82
          Mean value_function loss: 74.7490
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.4008
                       Mean reward: 710.49
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 1.0760
    Episode_Reward/rotating_object: 136.7647
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.10s
                      Time elapsed: 00:59:23
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 45487 steps/s (collection: 2.042s, learning 0.119s)
             Mean action noise std: 3.83
          Mean value_function loss: 68.3579
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 59.4151
                       Mean reward: 680.66
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 1.0814
    Episode_Reward/rotating_object: 139.2964
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.16s
                      Time elapsed: 00:59:25
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 47941 steps/s (collection: 1.944s, learning 0.107s)
             Mean action noise std: 3.83
          Mean value_function loss: 67.1412
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 59.4321
                       Mean reward: 644.92
               Mean episode length: 222.68
    Episode_Reward/reaching_object: 1.0573
    Episode_Reward/rotating_object: 135.5020
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.05s
                      Time elapsed: 00:59:27
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 48087 steps/s (collection: 1.948s, learning 0.096s)
             Mean action noise std: 3.83
          Mean value_function loss: 51.8121
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.4419
                       Mean reward: 687.29
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.0891
    Episode_Reward/rotating_object: 140.0034
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.04s
                      Time elapsed: 00:59:29
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 46824 steps/s (collection: 1.987s, learning 0.113s)
             Mean action noise std: 3.83
          Mean value_function loss: 60.2993
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.4553
                       Mean reward: 674.92
               Mean episode length: 232.48
    Episode_Reward/reaching_object: 1.0794
    Episode_Reward/rotating_object: 138.8072
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.10s
                      Time elapsed: 00:59:31
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 48115 steps/s (collection: 1.948s, learning 0.095s)
             Mean action noise std: 3.84
          Mean value_function loss: 64.9154
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.4743
                       Mean reward: 705.52
               Mean episode length: 238.22
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 139.2534
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.04s
                      Time elapsed: 00:59:33
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 47850 steps/s (collection: 1.947s, learning 0.107s)
             Mean action noise std: 3.84
          Mean value_function loss: 69.1771
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.4930
                       Mean reward: 700.97
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.0844
    Episode_Reward/rotating_object: 140.0710
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.05s
                      Time elapsed: 00:59:35
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 47468 steps/s (collection: 1.953s, learning 0.118s)
             Mean action noise std: 3.84
          Mean value_function loss: 85.4369
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.5021
                       Mean reward: 686.61
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 136.8999
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.07s
                      Time elapsed: 00:59:37
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 47405 steps/s (collection: 1.952s, learning 0.122s)
             Mean action noise std: 3.84
          Mean value_function loss: 63.6285
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.5080
                       Mean reward: 696.50
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 1.0532
    Episode_Reward/rotating_object: 135.0986
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.07s
                      Time elapsed: 00:59:39
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 48751 steps/s (collection: 1.904s, learning 0.113s)
             Mean action noise std: 3.85
          Mean value_function loss: 57.2768
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.5221
                       Mean reward: 677.09
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 133.9548
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.02s
                      Time elapsed: 00:59:41
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 48208 steps/s (collection: 1.924s, learning 0.116s)
             Mean action noise std: 3.85
          Mean value_function loss: 73.4971
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 59.5389
                       Mean reward: 698.95
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 135.9728
        Episode_Reward/action_rate: -0.0735
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.04s
                      Time elapsed: 00:59:43
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 48010 steps/s (collection: 1.933s, learning 0.115s)
             Mean action noise std: 3.85
          Mean value_function loss: 61.2185
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.5495
                       Mean reward: 706.08
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 1.0624
    Episode_Reward/rotating_object: 135.8255
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.05s
                      Time elapsed: 00:59:45
                               ETA: 00:18:14

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 47690 steps/s (collection: 1.950s, learning 0.112s)
             Mean action noise std: 3.86
          Mean value_function loss: 68.6179
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.5631
                       Mean reward: 701.18
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.0979
    Episode_Reward/rotating_object: 142.4272
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.06s
                      Time elapsed: 00:59:47
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 46102 steps/s (collection: 2.016s, learning 0.116s)
             Mean action noise std: 3.86
          Mean value_function loss: 68.7731
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 59.5803
                       Mean reward: 706.59
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 136.4650
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.13s
                      Time elapsed: 00:59:49
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 46903 steps/s (collection: 1.951s, learning 0.145s)
             Mean action noise std: 3.86
          Mean value_function loss: 61.4561
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.5932
                       Mean reward: 698.10
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.0536
    Episode_Reward/rotating_object: 136.6758
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.10s
                      Time elapsed: 00:59:52
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 48204 steps/s (collection: 1.920s, learning 0.119s)
             Mean action noise std: 3.86
          Mean value_function loss: 62.6514
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 59.6074
                       Mean reward: 684.73
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.0725
    Episode_Reward/rotating_object: 136.3874
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.04s
                      Time elapsed: 00:59:54
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 48233 steps/s (collection: 1.914s, learning 0.125s)
             Mean action noise std: 3.87
          Mean value_function loss: 62.7507
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 59.6211
                       Mean reward: 703.44
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.0669
    Episode_Reward/rotating_object: 135.8766
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.04s
                      Time elapsed: 00:59:56
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 47906 steps/s (collection: 1.948s, learning 0.104s)
             Mean action noise std: 3.87
          Mean value_function loss: 60.0315
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.6318
                       Mean reward: 709.85
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 142.0114
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.05s
                      Time elapsed: 00:59:58
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 46885 steps/s (collection: 1.958s, learning 0.139s)
             Mean action noise std: 3.87
          Mean value_function loss: 66.6772
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.6405
                       Mean reward: 711.09
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.0663
    Episode_Reward/rotating_object: 138.3780
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.10s
                      Time elapsed: 01:00:00
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 47596 steps/s (collection: 1.944s, learning 0.121s)
             Mean action noise std: 3.87
          Mean value_function loss: 57.2140
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 59.6498
                       Mean reward: 706.10
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 137.6044
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.07s
                      Time elapsed: 01:00:02
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 48090 steps/s (collection: 1.946s, learning 0.098s)
             Mean action noise std: 3.87
          Mean value_function loss: 72.6978
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 59.6549
                       Mean reward: 686.02
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 136.4899
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.04s
                      Time elapsed: 01:00:04
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 48428 steps/s (collection: 1.923s, learning 0.107s)
             Mean action noise std: 3.88
          Mean value_function loss: 65.0988
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.6627
                       Mean reward: 709.54
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.0823
    Episode_Reward/rotating_object: 139.9589
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.03s
                      Time elapsed: 01:00:06
                               ETA: 00:17:40

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 48035 steps/s (collection: 1.951s, learning 0.095s)
             Mean action noise std: 3.88
          Mean value_function loss: 66.9217
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.6707
                       Mean reward: 694.38
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.0903
    Episode_Reward/rotating_object: 141.3865
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.05s
                      Time elapsed: 01:00:08
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 48754 steps/s (collection: 1.916s, learning 0.100s)
             Mean action noise std: 3.88
          Mean value_function loss: 62.4715
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.6802
                       Mean reward: 686.15
               Mean episode length: 231.40
    Episode_Reward/reaching_object: 1.0967
    Episode_Reward/rotating_object: 141.5141
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.02s
                      Time elapsed: 01:00:10
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 48219 steps/s (collection: 1.925s, learning 0.114s)
             Mean action noise std: 3.88
          Mean value_function loss: 61.5395
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.6926
                       Mean reward: 714.59
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.0781
    Episode_Reward/rotating_object: 139.2133
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.04s
                      Time elapsed: 01:00:12
                               ETA: 00:17:29

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 48412 steps/s (collection: 1.921s, learning 0.109s)
             Mean action noise std: 3.89
          Mean value_function loss: 70.3147
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.7060
                       Mean reward: 694.18
               Mean episode length: 233.21
    Episode_Reward/reaching_object: 1.0558
    Episode_Reward/rotating_object: 134.8166
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.03s
                      Time elapsed: 01:00:14
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 48845 steps/s (collection: 1.923s, learning 0.090s)
             Mean action noise std: 3.89
          Mean value_function loss: 67.4434
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 59.7262
                       Mean reward: 705.97
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.0640
    Episode_Reward/rotating_object: 136.1309
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.01s
                      Time elapsed: 01:00:16
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 47908 steps/s (collection: 1.956s, learning 0.096s)
             Mean action noise std: 3.89
          Mean value_function loss: 62.6650
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.7382
                       Mean reward: 684.26
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 1.0485
    Episode_Reward/rotating_object: 134.2851
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.05s
                      Time elapsed: 01:00:18
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 48073 steps/s (collection: 1.954s, learning 0.091s)
             Mean action noise std: 3.89
          Mean value_function loss: 66.7685
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 59.7500
                       Mean reward: 692.77
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.0401
    Episode_Reward/rotating_object: 134.3295
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.04s
                      Time elapsed: 01:00:20
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 48418 steps/s (collection: 1.922s, learning 0.109s)
             Mean action noise std: 3.90
          Mean value_function loss: 55.1872
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 59.7646
                       Mean reward: 692.01
               Mean episode length: 234.73
    Episode_Reward/reaching_object: 1.0803
    Episode_Reward/rotating_object: 139.9662
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.03s
                      Time elapsed: 01:00:22
                               ETA: 00:17:12

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 48112 steps/s (collection: 1.951s, learning 0.092s)
             Mean action noise std: 3.90
          Mean value_function loss: 74.1478
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 59.7749
                       Mean reward: 682.84
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.0681
    Episode_Reward/rotating_object: 139.4321
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.04s
                      Time elapsed: 01:00:24
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 46051 steps/s (collection: 2.047s, learning 0.088s)
             Mean action noise std: 3.90
          Mean value_function loss: 73.2588
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 59.7824
                       Mean reward: 714.44
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.0856
    Episode_Reward/rotating_object: 139.9626
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.13s
                      Time elapsed: 01:00:26
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 47606 steps/s (collection: 1.966s, learning 0.099s)
             Mean action noise std: 3.90
          Mean value_function loss: 76.4048
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 59.7876
                       Mean reward: 665.19
               Mean episode length: 227.90
    Episode_Reward/reaching_object: 1.0609
    Episode_Reward/rotating_object: 136.8915
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.06s
                      Time elapsed: 01:00:28
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 47095 steps/s (collection: 1.974s, learning 0.114s)
             Mean action noise std: 3.90
          Mean value_function loss: 65.8783
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.7957
                       Mean reward: 668.82
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 137.4189
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.09s
                      Time elapsed: 01:00:31
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 46472 steps/s (collection: 2.010s, learning 0.105s)
             Mean action noise std: 3.91
          Mean value_function loss: 70.2589
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.8130
                       Mean reward: 715.62
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.0805
    Episode_Reward/rotating_object: 139.6731
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.12s
                      Time elapsed: 01:00:33
                               ETA: 00:16:55

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 47715 steps/s (collection: 1.945s, learning 0.116s)
             Mean action noise std: 3.91
          Mean value_function loss: 70.8897
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.8292
                       Mean reward: 689.13
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.0366
    Episode_Reward/rotating_object: 132.1712
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.06s
                      Time elapsed: 01:00:35
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 45292 steps/s (collection: 2.065s, learning 0.106s)
             Mean action noise std: 3.91
          Mean value_function loss: 66.1123
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.8447
                       Mean reward: 691.15
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.0523
    Episode_Reward/rotating_object: 134.3853
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.17s
                      Time elapsed: 01:00:37
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 47750 steps/s (collection: 1.952s, learning 0.107s)
             Mean action noise std: 3.92
          Mean value_function loss: 68.0256
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.8652
                       Mean reward: 678.26
               Mean episode length: 229.50
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 139.6931
        Episode_Reward/action_rate: -0.0772
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.06s
                      Time elapsed: 01:00:39
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 45500 steps/s (collection: 2.051s, learning 0.109s)
             Mean action noise std: 3.92
          Mean value_function loss: 64.3199
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.8845
                       Mean reward: 679.61
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 136.1248
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.16s
                      Time elapsed: 01:00:41
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 46307 steps/s (collection: 1.997s, learning 0.126s)
             Mean action noise std: 3.92
          Mean value_function loss: 68.2034
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.8967
                       Mean reward: 703.82
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.0795
    Episode_Reward/rotating_object: 139.0227
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.12s
                      Time elapsed: 01:00:43
                               ETA: 00:16:39

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 47230 steps/s (collection: 1.986s, learning 0.096s)
             Mean action noise std: 3.93
          Mean value_function loss: 60.6625
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 59.9075
                       Mean reward: 713.01
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.0713
    Episode_Reward/rotating_object: 138.6778
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.08s
                      Time elapsed: 01:00:45
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 48594 steps/s (collection: 1.923s, learning 0.100s)
             Mean action noise std: 3.93
          Mean value_function loss: 67.5325
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 59.9226
                       Mean reward: 692.75
               Mean episode length: 235.38
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 137.8520
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.02s
                      Time elapsed: 01:00:47
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 46910 steps/s (collection: 2.004s, learning 0.092s)
             Mean action noise std: 3.93
          Mean value_function loss: 78.2807
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 59.9357
                       Mean reward: 710.63
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.0864
    Episode_Reward/rotating_object: 141.3811
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.10s
                      Time elapsed: 01:00:49
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 48272 steps/s (collection: 1.938s, learning 0.098s)
             Mean action noise std: 3.93
          Mean value_function loss: 72.8274
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 59.9435
                       Mean reward: 681.86
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 138.4191
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.04s
                      Time elapsed: 01:00:51
                               ETA: 00:16:25

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 48450 steps/s (collection: 1.911s, learning 0.118s)
             Mean action noise std: 3.94
          Mean value_function loss: 68.5048
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.9522
                       Mean reward: 657.48
               Mean episode length: 225.40
    Episode_Reward/reaching_object: 1.0522
    Episode_Reward/rotating_object: 135.2597
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.03s
                      Time elapsed: 01:00:53
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 48266 steps/s (collection: 1.943s, learning 0.093s)
             Mean action noise std: 3.94
          Mean value_function loss: 69.9214
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 59.9658
                       Mean reward: 732.86
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.0905
    Episode_Reward/rotating_object: 141.4619
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.04s
                      Time elapsed: 01:00:56
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 48785 steps/s (collection: 1.919s, learning 0.096s)
             Mean action noise std: 3.94
          Mean value_function loss: 63.7707
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 59.9794
                       Mean reward: 708.67
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.0792
    Episode_Reward/rotating_object: 139.5607
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.02s
                      Time elapsed: 01:00:58
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 48762 steps/s (collection: 1.918s, learning 0.098s)
             Mean action noise std: 3.94
          Mean value_function loss: 67.7821
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.9936
                       Mean reward: 715.74
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 137.7072
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.02s
                      Time elapsed: 01:01:00
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 48513 steps/s (collection: 1.919s, learning 0.108s)
             Mean action noise std: 3.95
          Mean value_function loss: 57.5799
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.0209
                       Mean reward: 731.09
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 142.6881
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.03s
                      Time elapsed: 01:01:02
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 47383 steps/s (collection: 1.951s, learning 0.124s)
             Mean action noise std: 3.95
          Mean value_function loss: 59.1690
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 60.0426
                       Mean reward: 714.44
               Mean episode length: 240.07
    Episode_Reward/reaching_object: 1.0859
    Episode_Reward/rotating_object: 140.4718
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.07s
                      Time elapsed: 01:01:04
                               ETA: 00:16:05

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 46793 steps/s (collection: 1.956s, learning 0.145s)
             Mean action noise std: 3.96
          Mean value_function loss: 57.5584
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.0542
                       Mean reward: 706.91
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 138.8650
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.10s
                      Time elapsed: 01:01:06
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 47378 steps/s (collection: 1.978s, learning 0.097s)
             Mean action noise std: 3.96
          Mean value_function loss: 59.3100
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.0728
                       Mean reward: 695.39
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0777
    Episode_Reward/rotating_object: 139.7901
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.07s
                      Time elapsed: 01:01:08
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 46638 steps/s (collection: 1.992s, learning 0.116s)
             Mean action noise std: 3.96
          Mean value_function loss: 78.0918
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.0884
                       Mean reward: 713.15
               Mean episode length: 240.53
    Episode_Reward/reaching_object: 1.0766
    Episode_Reward/rotating_object: 138.6898
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.11s
                      Time elapsed: 01:01:10
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 47423 steps/s (collection: 1.935s, learning 0.138s)
             Mean action noise std: 3.97
          Mean value_function loss: 71.3671
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.1047
                       Mean reward: 711.46
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.0916
    Episode_Reward/rotating_object: 140.7310
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.07s
                      Time elapsed: 01:01:12
                               ETA: 00:15:52

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 45808 steps/s (collection: 1.999s, learning 0.147s)
             Mean action noise std: 3.97
          Mean value_function loss: 69.1340
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.1229
                       Mean reward: 654.07
               Mean episode length: 224.98
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 135.4219
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.15s
                      Time elapsed: 01:01:14
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 47116 steps/s (collection: 1.992s, learning 0.095s)
             Mean action noise std: 3.97
          Mean value_function loss: 68.8786
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.1394
                       Mean reward: 713.19
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 1.0810
    Episode_Reward/rotating_object: 140.9008
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.09s
                      Time elapsed: 01:01:16
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 46743 steps/s (collection: 1.959s, learning 0.144s)
             Mean action noise std: 3.98
          Mean value_function loss: 64.5904
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 60.1586
                       Mean reward: 701.31
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 136.2310
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.10s
                      Time elapsed: 01:01:18
                               ETA: 00:15:42

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 42674 steps/s (collection: 2.172s, learning 0.132s)
             Mean action noise std: 3.98
          Mean value_function loss: 63.6281
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.1798
                       Mean reward: 676.75
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.0651
    Episode_Reward/rotating_object: 135.5397
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.30s
                      Time elapsed: 01:01:21
                               ETA: 00:15:38

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 47187 steps/s (collection: 1.985s, learning 0.099s)
             Mean action noise std: 3.98
          Mean value_function loss: 63.6394
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.1930
                       Mean reward: 739.10
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.0786
    Episode_Reward/rotating_object: 139.4750
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.08s
                      Time elapsed: 01:01:23
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 47276 steps/s (collection: 1.959s, learning 0.120s)
             Mean action noise std: 3.98
          Mean value_function loss: 71.0128
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 60.2033
                       Mean reward: 678.37
               Mean episode length: 232.09
    Episode_Reward/reaching_object: 1.0464
    Episode_Reward/rotating_object: 134.7026
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.08s
                      Time elapsed: 01:01:25
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 48342 steps/s (collection: 1.942s, learning 0.092s)
             Mean action noise std: 3.99
          Mean value_function loss: 71.0345
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 60.2161
                       Mean reward: 669.53
               Mean episode length: 228.40
    Episode_Reward/reaching_object: 1.0545
    Episode_Reward/rotating_object: 137.3437
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.03s
                      Time elapsed: 01:01:27
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 47599 steps/s (collection: 1.958s, learning 0.107s)
             Mean action noise std: 3.99
          Mean value_function loss: 63.1700
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 60.2350
                       Mean reward: 688.36
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.0790
    Episode_Reward/rotating_object: 139.7683
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.07s
                      Time elapsed: 01:01:29
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 47875 steps/s (collection: 1.934s, learning 0.119s)
             Mean action noise std: 3.99
          Mean value_function loss: 68.6769
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.2503
                       Mean reward: 699.39
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 139.4108
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.05s
                      Time elapsed: 01:01:31
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 46861 steps/s (collection: 1.963s, learning 0.135s)
             Mean action noise std: 4.00
          Mean value_function loss: 62.3816
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 60.2641
                       Mean reward: 692.38
               Mean episode length: 233.56
    Episode_Reward/reaching_object: 1.0630
    Episode_Reward/rotating_object: 136.9962
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.10s
                      Time elapsed: 01:01:33
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 46599 steps/s (collection: 1.970s, learning 0.140s)
             Mean action noise std: 4.00
          Mean value_function loss: 70.8483
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.2749
                       Mean reward: 699.75
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 138.3803
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.11s
                      Time elapsed: 01:01:35
                               ETA: 00:15:15

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 46753 steps/s (collection: 1.971s, learning 0.132s)
             Mean action noise std: 4.00
          Mean value_function loss: 66.7561
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.2910
                       Mean reward: 670.20
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 136.8317
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.10s
                      Time elapsed: 01:01:37
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 47024 steps/s (collection: 1.947s, learning 0.143s)
             Mean action noise std: 4.01
          Mean value_function loss: 54.9600
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.3079
                       Mean reward: 707.09
               Mean episode length: 239.77
    Episode_Reward/reaching_object: 1.0725
    Episode_Reward/rotating_object: 139.6098
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.09s
                      Time elapsed: 01:01:39
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 45949 steps/s (collection: 2.020s, learning 0.119s)
             Mean action noise std: 4.01
          Mean value_function loss: 74.1824
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.3242
                       Mean reward: 676.36
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.0473
    Episode_Reward/rotating_object: 134.7121
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.14s
                      Time elapsed: 01:01:42
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 45560 steps/s (collection: 2.038s, learning 0.120s)
             Mean action noise std: 4.01
          Mean value_function loss: 75.4001
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.3428
                       Mean reward: 667.57
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.0525
    Episode_Reward/rotating_object: 135.7540
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.16s
                      Time elapsed: 01:01:44
                               ETA: 00:15:02

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 47070 steps/s (collection: 1.962s, learning 0.126s)
             Mean action noise std: 4.02
          Mean value_function loss: 78.2865
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.3562
                       Mean reward: 696.60
               Mean episode length: 233.35
    Episode_Reward/reaching_object: 1.0574
    Episode_Reward/rotating_object: 135.8846
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.09s
                      Time elapsed: 01:01:46
                               ETA: 00:14:58

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 46146 steps/s (collection: 2.012s, learning 0.119s)
             Mean action noise std: 4.02
          Mean value_function loss: 68.5144
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.3658
                       Mean reward: 723.37
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 1.0885
    Episode_Reward/rotating_object: 142.0919
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.13s
                      Time elapsed: 01:01:48
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 46815 steps/s (collection: 2.005s, learning 0.095s)
             Mean action noise std: 4.02
          Mean value_function loss: 50.1280
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.3755
                       Mean reward: 713.97
               Mean episode length: 237.86
    Episode_Reward/reaching_object: 1.0645
    Episode_Reward/rotating_object: 137.7206
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.10s
                      Time elapsed: 01:01:50
                               ETA: 00:14:52

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 47051 steps/s (collection: 1.975s, learning 0.115s)
             Mean action noise std: 4.02
          Mean value_function loss: 53.1984
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.3863
                       Mean reward: 711.07
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 1.0912
    Episode_Reward/rotating_object: 141.9733
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.09s
                      Time elapsed: 01:01:52
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 45200 steps/s (collection: 2.032s, learning 0.143s)
             Mean action noise std: 4.03
          Mean value_function loss: 64.3484
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.3970
                       Mean reward: 692.44
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 1.0791
    Episode_Reward/rotating_object: 140.6292
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.17s
                      Time elapsed: 01:01:54
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 45264 steps/s (collection: 1.988s, learning 0.184s)
             Mean action noise std: 4.03
          Mean value_function loss: 74.4293
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.4163
                       Mean reward: 686.24
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.0614
    Episode_Reward/rotating_object: 137.6939
        Episode_Reward/action_rate: -0.0808
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.17s
                      Time elapsed: 01:01:56
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 46665 steps/s (collection: 1.994s, learning 0.113s)
             Mean action noise std: 4.03
          Mean value_function loss: 58.5894
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.4266
                       Mean reward: 712.17
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 139.5581
        Episode_Reward/action_rate: -0.0812
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.11s
                      Time elapsed: 01:01:59
                               ETA: 00:14:39

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 48041 steps/s (collection: 1.946s, learning 0.100s)
             Mean action noise std: 4.03
          Mean value_function loss: 63.1253
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.4386
                       Mean reward: 699.35
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 1.0644
    Episode_Reward/rotating_object: 138.0067
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.05s
                      Time elapsed: 01:02:01
                               ETA: 00:14:35

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 46510 steps/s (collection: 2.010s, learning 0.104s)
             Mean action noise std: 4.04
          Mean value_function loss: 63.5093
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 60.4520
                       Mean reward: 682.26
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 141.8857
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.11s
                      Time elapsed: 01:02:03
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 46994 steps/s (collection: 1.994s, learning 0.098s)
             Mean action noise std: 4.04
          Mean value_function loss: 67.0323
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.4582
                       Mean reward: 705.83
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 139.3852
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.09s
                      Time elapsed: 01:02:05
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 46251 steps/s (collection: 2.018s, learning 0.108s)
             Mean action noise std: 4.04
          Mean value_function loss: 66.8464
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.4690
                       Mean reward: 730.07
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.0842
    Episode_Reward/rotating_object: 142.1119
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.13s
                      Time elapsed: 01:02:07
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 46862 steps/s (collection: 1.996s, learning 0.102s)
             Mean action noise std: 4.05
          Mean value_function loss: 69.7470
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 60.4904
                       Mean reward: 668.85
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.0486
    Episode_Reward/rotating_object: 135.3425
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.10s
                      Time elapsed: 01:02:09
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 45980 steps/s (collection: 2.011s, learning 0.127s)
             Mean action noise std: 4.05
          Mean value_function loss: 72.6080
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 60.5004
                       Mean reward: 699.39
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 1.0607
    Episode_Reward/rotating_object: 137.0515
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.14s
                      Time elapsed: 01:02:11
                               ETA: 00:14:19

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 46366 steps/s (collection: 1.986s, learning 0.134s)
             Mean action noise std: 4.05
          Mean value_function loss: 70.6646
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 60.5104
                       Mean reward: 673.35
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 136.7604
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.12s
                      Time elapsed: 01:02:13
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 45333 steps/s (collection: 2.005s, learning 0.163s)
             Mean action noise std: 4.05
          Mean value_function loss: 57.4799
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.5178
                       Mean reward: 734.03
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.0786
    Episode_Reward/rotating_object: 142.0104
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.17s
                      Time elapsed: 01:02:15
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 46611 steps/s (collection: 1.990s, learning 0.119s)
             Mean action noise std: 4.05
          Mean value_function loss: 56.1220
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.5298
                       Mean reward: 652.47
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.0595
    Episode_Reward/rotating_object: 136.4096
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.11s
                      Time elapsed: 01:02:18
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 46199 steps/s (collection: 2.018s, learning 0.110s)
             Mean action noise std: 4.06
          Mean value_function loss: 71.5991
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.5432
                       Mean reward: 681.01
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.0776
    Episode_Reward/rotating_object: 141.0691
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.13s
                      Time elapsed: 01:02:20
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 47602 steps/s (collection: 1.952s, learning 0.114s)
             Mean action noise std: 4.06
          Mean value_function loss: 63.3477
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.5547
                       Mean reward: 687.67
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.0527
    Episode_Reward/rotating_object: 136.7718
        Episode_Reward/action_rate: -0.0811
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.07s
                      Time elapsed: 01:02:22
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 47389 steps/s (collection: 1.964s, learning 0.110s)
             Mean action noise std: 4.06
          Mean value_function loss: 45.5423
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.5637
                       Mean reward: 754.87
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 1.0870
    Episode_Reward/rotating_object: 141.7921
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.07s
                      Time elapsed: 01:02:24
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 47009 steps/s (collection: 1.984s, learning 0.107s)
             Mean action noise std: 4.07
          Mean value_function loss: 59.3790
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.5800
                       Mean reward: 703.89
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 1.0864
    Episode_Reward/rotating_object: 142.7521
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.09s
                      Time elapsed: 01:02:26
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 45998 steps/s (collection: 2.007s, learning 0.131s)
             Mean action noise std: 4.07
          Mean value_function loss: 64.5424
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.5989
                       Mean reward: 694.22
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.0748
    Episode_Reward/rotating_object: 141.4235
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.14s
                      Time elapsed: 01:02:28
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 47353 steps/s (collection: 1.982s, learning 0.094s)
             Mean action noise std: 4.07
          Mean value_function loss: 63.2446
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.6198
                       Mean reward: 690.21
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 1.0760
    Episode_Reward/rotating_object: 140.4443
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.08s
                      Time elapsed: 01:02:30
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 47019 steps/s (collection: 1.953s, learning 0.138s)
             Mean action noise std: 4.08
          Mean value_function loss: 59.2132
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 60.6341
                       Mean reward: 701.98
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.0774
    Episode_Reward/rotating_object: 140.8512
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.09s
                      Time elapsed: 01:02:32
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 42647 steps/s (collection: 2.093s, learning 0.212s)
             Mean action noise std: 4.08
          Mean value_function loss: 62.0199
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 60.6505
                       Mean reward: 695.83
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.0801
    Episode_Reward/rotating_object: 140.6331
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.31s
                      Time elapsed: 01:02:34
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 46376 steps/s (collection: 2.023s, learning 0.097s)
             Mean action noise std: 4.08
          Mean value_function loss: 67.5857
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 60.6640
                       Mean reward: 691.25
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 138.3554
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.12s
                      Time elapsed: 01:02:37
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 46326 steps/s (collection: 2.007s, learning 0.115s)
             Mean action noise std: 4.08
          Mean value_function loss: 65.9739
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.6789
                       Mean reward: 711.40
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 137.0216
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.12s
                      Time elapsed: 01:02:39
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 46779 steps/s (collection: 1.995s, learning 0.106s)
             Mean action noise std: 4.09
          Mean value_function loss: 53.4758
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.6896
                       Mean reward: 707.89
               Mean episode length: 236.64
    Episode_Reward/reaching_object: 1.0622
    Episode_Reward/rotating_object: 137.6817
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.10s
                      Time elapsed: 01:02:41
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 44469 steps/s (collection: 2.081s, learning 0.130s)
             Mean action noise std: 4.09
          Mean value_function loss: 69.7580
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.7012
                       Mean reward: 709.72
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 1.0629
    Episode_Reward/rotating_object: 137.2592
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.21s
                      Time elapsed: 01:02:43
                               ETA: 00:13:30

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 47573 steps/s (collection: 1.950s, learning 0.116s)
             Mean action noise std: 4.09
          Mean value_function loss: 64.2935
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 60.7183
                       Mean reward: 688.53
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 1.0521
    Episode_Reward/rotating_object: 137.1019
        Episode_Reward/action_rate: -0.0819
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.07s
                      Time elapsed: 01:02:45
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 47169 steps/s (collection: 1.952s, learning 0.132s)
             Mean action noise std: 4.10
          Mean value_function loss: 52.4927
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.7347
                       Mean reward: 715.61
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.0719
    Episode_Reward/rotating_object: 138.6922
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.08s
                      Time elapsed: 01:02:47
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 45864 steps/s (collection: 1.971s, learning 0.172s)
             Mean action noise std: 4.10
          Mean value_function loss: 55.8938
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 60.7454
                       Mean reward: 729.45
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 143.4638
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.14s
                      Time elapsed: 01:02:49
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 45911 steps/s (collection: 2.009s, learning 0.132s)
             Mean action noise std: 4.10
          Mean value_function loss: 54.6448
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 60.7548
                       Mean reward: 733.05
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.1023
    Episode_Reward/rotating_object: 145.4588
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.14s
                      Time elapsed: 01:02:51
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 47011 steps/s (collection: 1.989s, learning 0.102s)
             Mean action noise std: 4.10
          Mean value_function loss: 65.5310
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.7684
                       Mean reward: 723.29
               Mean episode length: 238.88
    Episode_Reward/reaching_object: 1.0899
    Episode_Reward/rotating_object: 143.9398
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.09s
                      Time elapsed: 01:02:54
                               ETA: 00:13:14

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 47446 steps/s (collection: 1.961s, learning 0.111s)
             Mean action noise std: 4.11
          Mean value_function loss: 62.7209
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 60.7808
                       Mean reward: 662.78
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.0573
    Episode_Reward/rotating_object: 137.8469
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.07s
                      Time elapsed: 01:02:56
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 46324 steps/s (collection: 2.027s, learning 0.095s)
             Mean action noise std: 4.11
          Mean value_function loss: 77.8948
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.7937
                       Mean reward: 726.59
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 140.5187
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.12s
                      Time elapsed: 01:02:58
                               ETA: 00:13:07

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 46775 steps/s (collection: 2.000s, learning 0.102s)
             Mean action noise std: 4.11
          Mean value_function loss: 68.9229
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 60.8055
                       Mean reward: 687.30
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.0557
    Episode_Reward/rotating_object: 135.8583
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.10s
                      Time elapsed: 01:03:00
                               ETA: 00:13:04

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 44764 steps/s (collection: 2.018s, learning 0.178s)
             Mean action noise std: 4.11
          Mean value_function loss: 65.8303
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 60.8139
                       Mean reward: 702.43
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.0629
    Episode_Reward/rotating_object: 138.3880
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.20s
                      Time elapsed: 01:03:02
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 46629 steps/s (collection: 2.004s, learning 0.104s)
             Mean action noise std: 4.12
          Mean value_function loss: 63.8155
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.8279
                       Mean reward: 682.31
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.0624
    Episode_Reward/rotating_object: 139.4280
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.11s
                      Time elapsed: 01:03:04
                               ETA: 00:12:58

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 45213 steps/s (collection: 2.010s, learning 0.165s)
             Mean action noise std: 4.12
          Mean value_function loss: 62.5115
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 60.8394
                       Mean reward: 705.82
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 139.1453
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.17s
                      Time elapsed: 01:03:06
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 46128 steps/s (collection: 1.966s, learning 0.165s)
             Mean action noise std: 4.12
          Mean value_function loss: 73.1232
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.8529
                       Mean reward: 695.44
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.0395
    Episode_Reward/rotating_object: 134.8197
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.13s
                      Time elapsed: 01:03:08
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 47606 steps/s (collection: 1.967s, learning 0.098s)
             Mean action noise std: 4.12
          Mean value_function loss: 67.3853
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.8683
                       Mean reward: 719.73
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.0573
    Episode_Reward/rotating_object: 137.9636
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.06s
                      Time elapsed: 01:03:11
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 45978 steps/s (collection: 2.040s, learning 0.098s)
             Mean action noise std: 4.13
          Mean value_function loss: 47.1931
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 60.8807
                       Mean reward: 702.22
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0804
    Episode_Reward/rotating_object: 140.8714
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.14s
                      Time elapsed: 01:03:13
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 46259 steps/s (collection: 2.017s, learning 0.109s)
             Mean action noise std: 4.13
          Mean value_function loss: 65.3853
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 60.8969
                       Mean reward: 698.14
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 141.1981
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.13s
                      Time elapsed: 01:03:15
                               ETA: 00:12:42

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 45972 steps/s (collection: 2.030s, learning 0.108s)
             Mean action noise std: 4.13
          Mean value_function loss: 67.2899
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 60.9119
                       Mean reward: 669.39
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 1.0626
    Episode_Reward/rotating_object: 139.1367
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.14s
                      Time elapsed: 01:03:17
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 44907 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 4.13
          Mean value_function loss: 65.6051
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 60.9251
                       Mean reward: 693.42
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 1.0854
    Episode_Reward/rotating_object: 142.8476
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.19s
                      Time elapsed: 01:03:19
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 46034 steps/s (collection: 2.013s, learning 0.122s)
             Mean action noise std: 4.14
          Mean value_function loss: 69.3704
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 60.9363
                       Mean reward: 698.69
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 141.2523
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.14s
                      Time elapsed: 01:03:21
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 45206 steps/s (collection: 2.014s, learning 0.161s)
             Mean action noise std: 4.14
          Mean value_function loss: 89.2666
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.9471
                       Mean reward: 664.37
               Mean episode length: 224.16
    Episode_Reward/reaching_object: 1.0425
    Episode_Reward/rotating_object: 135.7647
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.17s
                      Time elapsed: 01:03:23
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 45427 steps/s (collection: 2.003s, learning 0.161s)
             Mean action noise std: 4.14
          Mean value_function loss: 86.6553
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.9583
                       Mean reward: 694.13
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 1.0562
    Episode_Reward/rotating_object: 137.0855
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.16s
                      Time elapsed: 01:03:26
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 44861 steps/s (collection: 2.049s, learning 0.142s)
             Mean action noise std: 4.15
          Mean value_function loss: 55.9348
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 60.9740
                       Mean reward: 713.99
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.0489
    Episode_Reward/rotating_object: 136.1085
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.19s
                      Time elapsed: 01:03:28
                               ETA: 00:12:22

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 45926 steps/s (collection: 2.016s, learning 0.124s)
             Mean action noise std: 4.15
          Mean value_function loss: 67.2422
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 60.9855
                       Mean reward: 663.69
               Mean episode length: 222.60
    Episode_Reward/reaching_object: 1.0717
    Episode_Reward/rotating_object: 139.7638
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.14s
                      Time elapsed: 01:03:30
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 46438 steps/s (collection: 2.021s, learning 0.096s)
             Mean action noise std: 4.15
          Mean value_function loss: 70.4710
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 61.0033
                       Mean reward: 733.89
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 140.1610
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.12s
                      Time elapsed: 01:03:32
                               ETA: 00:12:16

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 46244 steps/s (collection: 1.998s, learning 0.128s)
             Mean action noise std: 4.15
          Mean value_function loss: 63.0809
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 61.0101
                       Mean reward: 742.10
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 1.0650
    Episode_Reward/rotating_object: 138.8764
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.13s
                      Time elapsed: 01:03:34
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 46526 steps/s (collection: 2.008s, learning 0.105s)
             Mean action noise std: 4.15
          Mean value_function loss: 53.3972
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 61.0109
                       Mean reward: 724.37
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 1.0691
    Episode_Reward/rotating_object: 139.2710
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.11s
                      Time elapsed: 01:03:36
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 46593 steps/s (collection: 1.996s, learning 0.114s)
             Mean action noise std: 4.16
          Mean value_function loss: 64.2033
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.0131
                       Mean reward: 707.89
               Mean episode length: 238.35
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 139.3907
        Episode_Reward/action_rate: -0.0868
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.11s
                      Time elapsed: 01:03:38
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 45954 steps/s (collection: 2.024s, learning 0.115s)
             Mean action noise std: 4.16
          Mean value_function loss: 65.0456
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.0224
                       Mean reward: 641.77
               Mean episode length: 221.09
    Episode_Reward/reaching_object: 1.0515
    Episode_Reward/rotating_object: 137.2526
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.14s
                      Time elapsed: 01:03:41
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 45476 steps/s (collection: 2.056s, learning 0.105s)
             Mean action noise std: 4.16
          Mean value_function loss: 62.5572
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.0371
                       Mean reward: 696.93
               Mean episode length: 232.70
    Episode_Reward/reaching_object: 1.0671
    Episode_Reward/rotating_object: 138.8976
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.16s
                      Time elapsed: 01:03:43
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 44841 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 4.16
          Mean value_function loss: 65.4585
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.0540
                       Mean reward: 719.99
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.0707
    Episode_Reward/rotating_object: 140.7037
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.19s
                      Time elapsed: 01:03:45
                               ETA: 00:11:57

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 43387 steps/s (collection: 2.148s, learning 0.118s)
             Mean action noise std: 4.17
          Mean value_function loss: 72.1620
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.0669
                       Mean reward: 687.34
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 1.0815
    Episode_Reward/rotating_object: 143.4152
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.27s
                      Time elapsed: 01:03:47
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 44468 steps/s (collection: 2.111s, learning 0.099s)
             Mean action noise std: 4.17
          Mean value_function loss: 70.1548
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.0778
                       Mean reward: 680.02
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 137.6039
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.21s
                      Time elapsed: 01:03:49
                               ETA: 00:11:50

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 44271 steps/s (collection: 2.111s, learning 0.109s)
             Mean action noise std: 4.17
          Mean value_function loss: 66.2694
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.0884
                       Mean reward: 685.41
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 1.0396
    Episode_Reward/rotating_object: 136.0241
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.22s
                      Time elapsed: 01:03:52
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 43626 steps/s (collection: 2.126s, learning 0.127s)
             Mean action noise std: 4.17
          Mean value_function loss: 63.7156
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.0947
                       Mean reward: 704.63
               Mean episode length: 236.26
    Episode_Reward/reaching_object: 1.0949
    Episode_Reward/rotating_object: 144.8204
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.25s
                      Time elapsed: 01:03:54
                               ETA: 00:11:44

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 45414 steps/s (collection: 2.044s, learning 0.121s)
             Mean action noise std: 4.18
          Mean value_function loss: 70.1302
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.1040
                       Mean reward: 689.71
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.0664
    Episode_Reward/rotating_object: 140.2497
        Episode_Reward/action_rate: -0.0866
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.16s
                      Time elapsed: 01:03:56
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 45325 steps/s (collection: 2.042s, learning 0.127s)
             Mean action noise std: 4.18
          Mean value_function loss: 72.0864
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 61.1172
                       Mean reward: 685.55
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.0555
    Episode_Reward/rotating_object: 138.2320
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.17s
                      Time elapsed: 01:03:58
                               ETA: 00:11:38

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 44462 steps/s (collection: 2.076s, learning 0.135s)
             Mean action noise std: 4.18
          Mean value_function loss: 59.2426
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.1343
                       Mean reward: 703.90
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 139.2429
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.21s
                      Time elapsed: 01:04:00
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 45227 steps/s (collection: 2.059s, learning 0.114s)
             Mean action noise std: 4.18
          Mean value_function loss: 63.4395
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 61.1471
                       Mean reward: 675.52
               Mean episode length: 226.27
    Episode_Reward/reaching_object: 1.0637
    Episode_Reward/rotating_object: 139.8429
        Episode_Reward/action_rate: -0.0867
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.17s
                      Time elapsed: 01:04:03
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 44264 steps/s (collection: 2.052s, learning 0.169s)
             Mean action noise std: 4.19
          Mean value_function loss: 63.3171
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 61.1542
                       Mean reward: 716.28
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.0862
    Episode_Reward/rotating_object: 142.2573
        Episode_Reward/action_rate: -0.0889
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.22s
                      Time elapsed: 01:04:05
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 44160 steps/s (collection: 2.099s, learning 0.127s)
             Mean action noise std: 4.19
          Mean value_function loss: 72.5153
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.1620
                       Mean reward: 704.99
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.0836
    Episode_Reward/rotating_object: 142.3475
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.23s
                      Time elapsed: 01:04:07
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 46811 steps/s (collection: 1.998s, learning 0.102s)
             Mean action noise std: 4.19
          Mean value_function loss: 71.8067
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.1794
                       Mean reward: 698.11
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.0710
    Episode_Reward/rotating_object: 139.3732
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.10s
                      Time elapsed: 01:04:09
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 46804 steps/s (collection: 1.987s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 59.0559
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 61.1994
                       Mean reward: 689.29
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 138.2328
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.10s
                      Time elapsed: 01:04:11
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 44093 steps/s (collection: 2.128s, learning 0.102s)
             Mean action noise std: 4.20
          Mean value_function loss: 87.6945
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.2117
                       Mean reward: 687.93
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 139.6283
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.23s
                      Time elapsed: 01:04:13
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 46589 steps/s (collection: 1.996s, learning 0.114s)
             Mean action noise std: 4.20
          Mean value_function loss: 75.4504
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 61.2250
                       Mean reward: 636.35
               Mean episode length: 219.14
    Episode_Reward/reaching_object: 1.0352
    Episode_Reward/rotating_object: 133.9614
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.11s
                      Time elapsed: 01:04:16
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 46319 steps/s (collection: 2.018s, learning 0.105s)
             Mean action noise std: 4.20
          Mean value_function loss: 70.1176
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.2366
                       Mean reward: 713.47
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.0631
    Episode_Reward/rotating_object: 138.5289
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.12s
                      Time elapsed: 01:04:18
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 45624 steps/s (collection: 2.041s, learning 0.114s)
             Mean action noise std: 4.21
          Mean value_function loss: 58.3326
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.2582
                       Mean reward: 713.87
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.0810
    Episode_Reward/rotating_object: 142.5312
        Episode_Reward/action_rate: -0.0893
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.15s
                      Time elapsed: 01:04:20
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 46397 steps/s (collection: 2.020s, learning 0.099s)
             Mean action noise std: 4.21
          Mean value_function loss: 65.1758
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.2743
                       Mean reward: 702.98
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.0570
    Episode_Reward/rotating_object: 138.1118
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.12s
                      Time elapsed: 01:04:22
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 46499 steps/s (collection: 2.001s, learning 0.114s)
             Mean action noise std: 4.21
          Mean value_function loss: 56.0832
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.2835
                       Mean reward: 736.71
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.0895
    Episode_Reward/rotating_object: 143.2637
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.11s
                      Time elapsed: 01:04:24
                               ETA: 00:11:00

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 46124 steps/s (collection: 2.023s, learning 0.109s)
             Mean action noise std: 4.22
          Mean value_function loss: 62.2075
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 61.2930
                       Mean reward: 755.24
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 1.0890
    Episode_Reward/rotating_object: 143.8149
        Episode_Reward/action_rate: -0.0897
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.13s
                      Time elapsed: 01:04:26
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 45907 steps/s (collection: 2.038s, learning 0.103s)
             Mean action noise std: 4.22
          Mean value_function loss: 67.1501
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.3001
                       Mean reward: 677.23
               Mean episode length: 225.42
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 142.2188
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.14s
                      Time elapsed: 01:04:28
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 45908 steps/s (collection: 2.041s, learning 0.100s)
             Mean action noise std: 4.22
          Mean value_function loss: 56.1830
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.3086
                       Mean reward: 711.93
               Mean episode length: 234.99
    Episode_Reward/reaching_object: 1.0641
    Episode_Reward/rotating_object: 139.0364
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.14s
                      Time elapsed: 01:04:30
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 46569 steps/s (collection: 1.986s, learning 0.125s)
             Mean action noise std: 4.22
          Mean value_function loss: 62.0537
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 61.3168
                       Mean reward: 712.02
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 1.0973
    Episode_Reward/rotating_object: 144.5670
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.11s
                      Time elapsed: 01:04:33
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 45429 steps/s (collection: 2.013s, learning 0.151s)
             Mean action noise std: 4.22
          Mean value_function loss: 61.7610
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 61.3266
                       Mean reward: 734.63
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.0757
    Episode_Reward/rotating_object: 140.8075
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.16s
                      Time elapsed: 01:04:35
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 44590 steps/s (collection: 2.086s, learning 0.119s)
             Mean action noise std: 4.23
          Mean value_function loss: 64.9389
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 61.3406
                       Mean reward: 700.36
               Mean episode length: 234.55
    Episode_Reward/reaching_object: 1.0900
    Episode_Reward/rotating_object: 143.3354
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.20s
                      Time elapsed: 01:04:37
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 45487 steps/s (collection: 2.033s, learning 0.129s)
             Mean action noise std: 4.23
          Mean value_function loss: 63.7527
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.3481
                       Mean reward: 700.59
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0842
    Episode_Reward/rotating_object: 141.3222
        Episode_Reward/action_rate: -0.0913
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.16s
                      Time elapsed: 01:04:39
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 44190 steps/s (collection: 2.088s, learning 0.136s)
             Mean action noise std: 4.23
          Mean value_function loss: 71.8004
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.3549
                       Mean reward: 691.88
               Mean episode length: 231.87
    Episode_Reward/reaching_object: 1.0692
    Episode_Reward/rotating_object: 138.7107
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.22s
                      Time elapsed: 01:04:41
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 44885 steps/s (collection: 2.075s, learning 0.115s)
             Mean action noise std: 4.23
          Mean value_function loss: 68.0155
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.3620
                       Mean reward: 707.79
               Mean episode length: 233.14
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 141.6557
        Episode_Reward/action_rate: -0.0912
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.19s
                      Time elapsed: 01:04:44
                               ETA: 00:10:31

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 44807 steps/s (collection: 2.045s, learning 0.149s)
             Mean action noise std: 4.23
          Mean value_function loss: 71.4028
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.3685
                       Mean reward: 700.39
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.0713
    Episode_Reward/rotating_object: 140.0135
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.19s
                      Time elapsed: 01:04:46
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 45055 steps/s (collection: 2.035s, learning 0.147s)
             Mean action noise std: 4.24
          Mean value_function loss: 58.9564
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.3802
                       Mean reward: 715.99
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 143.0824
        Episode_Reward/action_rate: -0.0919
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.18s
                      Time elapsed: 01:04:48
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 43248 steps/s (collection: 2.111s, learning 0.162s)
             Mean action noise std: 4.24
          Mean value_function loss: 67.1222
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.3896
                       Mean reward: 713.47
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 1.0598
    Episode_Reward/rotating_object: 139.1532
        Episode_Reward/action_rate: -0.0896
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.27s
                      Time elapsed: 01:04:50
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 45128 steps/s (collection: 2.061s, learning 0.117s)
             Mean action noise std: 4.24
          Mean value_function loss: 67.1119
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.3943
                       Mean reward: 684.45
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.0563
    Episode_Reward/rotating_object: 137.3632
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.18s
                      Time elapsed: 01:04:52
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 45849 steps/s (collection: 2.014s, learning 0.131s)
             Mean action noise std: 4.24
          Mean value_function loss: 54.4918
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.4055
                       Mean reward: 747.01
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 140.2125
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.14s
                      Time elapsed: 01:04:55
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 44620 steps/s (collection: 2.018s, learning 0.185s)
             Mean action noise std: 4.25
          Mean value_function loss: 54.8587
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.4200
                       Mean reward: 694.31
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 1.0851
    Episode_Reward/rotating_object: 143.7057
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.20s
                      Time elapsed: 01:04:57
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 45040 steps/s (collection: 2.012s, learning 0.171s)
             Mean action noise std: 4.25
          Mean value_function loss: 66.0815
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 61.4341
                       Mean reward: 690.76
               Mean episode length: 229.47
    Episode_Reward/reaching_object: 1.0702
    Episode_Reward/rotating_object: 140.9536
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.18s
                      Time elapsed: 01:04:59
                               ETA: 00:10:09

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 45421 steps/s (collection: 2.056s, learning 0.108s)
             Mean action noise std: 4.25
          Mean value_function loss: 73.6416
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.4453
                       Mean reward: 684.23
               Mean episode length: 226.59
    Episode_Reward/reaching_object: 1.0565
    Episode_Reward/rotating_object: 137.3960
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.16s
                      Time elapsed: 01:05:01
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 44985 steps/s (collection: 2.083s, learning 0.103s)
             Mean action noise std: 4.25
          Mean value_function loss: 56.2839
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.4550
                       Mean reward: 730.07
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.0933
    Episode_Reward/rotating_object: 143.5062
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.19s
                      Time elapsed: 01:05:03
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 44008 steps/s (collection: 2.071s, learning 0.163s)
             Mean action noise std: 4.26
          Mean value_function loss: 58.3206
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 61.4654
                       Mean reward: 738.69
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.0932
    Episode_Reward/rotating_object: 143.5711
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.23s
                      Time elapsed: 01:05:05
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 42330 steps/s (collection: 2.175s, learning 0.148s)
             Mean action noise std: 4.26
          Mean value_function loss: 61.3717
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.4721
                       Mean reward: 699.47
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.0674
    Episode_Reward/rotating_object: 140.2847
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.32s
                      Time elapsed: 01:05:08
                               ETA: 00:09:57

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 43418 steps/s (collection: 2.107s, learning 0.157s)
             Mean action noise std: 4.26
          Mean value_function loss: 62.5048
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 61.4810
                       Mean reward: 701.01
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 141.9415
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.26s
                      Time elapsed: 01:05:10
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 42905 steps/s (collection: 2.148s, learning 0.143s)
             Mean action noise std: 4.26
          Mean value_function loss: 65.6740
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.4935
                       Mean reward: 734.52
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.0938
    Episode_Reward/rotating_object: 144.2498
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.29s
                      Time elapsed: 01:05:12
                               ETA: 00:09:51

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 43790 steps/s (collection: 2.076s, learning 0.169s)
             Mean action noise std: 4.26
          Mean value_function loss: 66.9871
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.5057
                       Mean reward: 706.26
               Mean episode length: 233.24
    Episode_Reward/reaching_object: 1.0756
    Episode_Reward/rotating_object: 140.0444
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.24s
                      Time elapsed: 01:05:15
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 40739 steps/s (collection: 2.236s, learning 0.177s)
             Mean action noise std: 4.27
          Mean value_function loss: 56.9228
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.5170
                       Mean reward: 674.42
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.0625
    Episode_Reward/rotating_object: 139.3395
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.41s
                      Time elapsed: 01:05:17
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 40478 steps/s (collection: 2.267s, learning 0.162s)
             Mean action noise std: 4.27
          Mean value_function loss: 67.5236
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.5248
                       Mean reward: 760.97
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.1016
    Episode_Reward/rotating_object: 145.0093
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.43s
                      Time elapsed: 01:05:19
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 44848 steps/s (collection: 2.076s, learning 0.116s)
             Mean action noise std: 4.27
          Mean value_function loss: 69.2827
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.5385
                       Mean reward: 716.57
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 1.0789
    Episode_Reward/rotating_object: 141.5721
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.19s
                      Time elapsed: 01:05:22
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 42401 steps/s (collection: 2.155s, learning 0.164s)
             Mean action noise std: 4.28
          Mean value_function loss: 58.4035
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.5520
                       Mean reward: 695.12
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 141.4283
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.32s
                      Time elapsed: 01:05:24
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 44231 steps/s (collection: 2.096s, learning 0.127s)
             Mean action noise std: 4.28
          Mean value_function loss: 76.5750
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.5632
                       Mean reward: 658.86
               Mean episode length: 223.62
    Episode_Reward/reaching_object: 1.0540
    Episode_Reward/rotating_object: 137.0115
        Episode_Reward/action_rate: -0.0908
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.22s
                      Time elapsed: 01:05:26
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 43991 steps/s (collection: 2.098s, learning 0.136s)
             Mean action noise std: 4.28
          Mean value_function loss: 62.7348
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.5771
                       Mean reward: 674.53
               Mean episode length: 224.28
    Episode_Reward/reaching_object: 1.0448
    Episode_Reward/rotating_object: 135.9861
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.23s
                      Time elapsed: 01:05:28
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 45257 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 4.28
          Mean value_function loss: 62.1906
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.5986
                       Mean reward: 729.83
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.0856
    Episode_Reward/rotating_object: 143.5861
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.17s
                      Time elapsed: 01:05:31
                               ETA: 00:09:26

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 44163 steps/s (collection: 2.059s, learning 0.167s)
             Mean action noise std: 4.29
          Mean value_function loss: 71.8521
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.6104
                       Mean reward: 694.27
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 1.0656
    Episode_Reward/rotating_object: 139.5131
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.23s
                      Time elapsed: 01:05:33
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 44259 steps/s (collection: 2.036s, learning 0.186s)
             Mean action noise std: 4.29
          Mean value_function loss: 64.1014
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 61.6260
                       Mean reward: 722.75
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 1.0699
    Episode_Reward/rotating_object: 141.8582
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.22s
                      Time elapsed: 01:05:35
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 42787 steps/s (collection: 2.169s, learning 0.129s)
             Mean action noise std: 4.29
          Mean value_function loss: 74.4884
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.6437
                       Mean reward: 690.95
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.0697
    Episode_Reward/rotating_object: 140.3240
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.30s
                      Time elapsed: 01:05:37
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 45911 steps/s (collection: 2.039s, learning 0.102s)
             Mean action noise std: 4.30
          Mean value_function loss: 71.0162
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.6553
                       Mean reward: 683.59
               Mean episode length: 227.83
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 138.8899
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.14s
                      Time elapsed: 01:05:39
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 43636 steps/s (collection: 2.100s, learning 0.153s)
             Mean action noise std: 4.30
          Mean value_function loss: 66.7736
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.6686
                       Mean reward: 706.50
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 140.6572
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.25s
                      Time elapsed: 01:05:42
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 45107 steps/s (collection: 2.045s, learning 0.135s)
             Mean action noise std: 4.30
          Mean value_function loss: 61.0600
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.6804
                       Mean reward: 720.23
               Mean episode length: 238.74
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 139.3370
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.18s
                      Time elapsed: 01:05:44
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 45303 steps/s (collection: 2.068s, learning 0.102s)
             Mean action noise std: 4.31
          Mean value_function loss: 59.5160
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.6971
                       Mean reward: 723.64
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 143.5388
        Episode_Reward/action_rate: -0.0945
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.17s
                      Time elapsed: 01:05:46
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 45958 steps/s (collection: 2.035s, learning 0.104s)
             Mean action noise std: 4.31
          Mean value_function loss: 70.5626
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.7075
                       Mean reward: 699.16
               Mean episode length: 229.78
    Episode_Reward/reaching_object: 1.0625
    Episode_Reward/rotating_object: 140.5544
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.14s
                      Time elapsed: 01:05:48
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 45471 steps/s (collection: 2.039s, learning 0.123s)
             Mean action noise std: 4.31
          Mean value_function loss: 73.0583
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 61.7215
                       Mean reward: 708.32
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 141.3495
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.16s
                      Time elapsed: 01:05:50
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 46439 steps/s (collection: 2.010s, learning 0.107s)
             Mean action noise std: 4.31
          Mean value_function loss: 54.5237
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 61.7363
                       Mean reward: 704.88
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 142.7154
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.12s
                      Time elapsed: 01:05:52
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 45455 steps/s (collection: 2.043s, learning 0.119s)
             Mean action noise std: 4.32
          Mean value_function loss: 83.5980
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 61.7441
                       Mean reward: 689.57
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 1.0617
    Episode_Reward/rotating_object: 140.4144
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.16s
                      Time elapsed: 01:05:55
                               ETA: 00:08:52

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 45208 steps/s (collection: 2.022s, learning 0.152s)
             Mean action noise std: 4.32
          Mean value_function loss: 84.1212
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 61.7598
                       Mean reward: 686.49
               Mean episode length: 229.45
    Episode_Reward/reaching_object: 1.0415
    Episode_Reward/rotating_object: 135.2941
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.17s
                      Time elapsed: 01:05:57
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 44960 steps/s (collection: 2.055s, learning 0.131s)
             Mean action noise std: 4.32
          Mean value_function loss: 54.0721
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 61.7795
                       Mean reward: 748.27
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 1.0650
    Episode_Reward/rotating_object: 139.9734
        Episode_Reward/action_rate: -0.0941
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.19s
                      Time elapsed: 01:05:59
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 45221 steps/s (collection: 2.044s, learning 0.129s)
             Mean action noise std: 4.32
          Mean value_function loss: 75.0002
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 61.7874
                       Mean reward: 720.92
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.0764
    Episode_Reward/rotating_object: 142.6089
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.17s
                      Time elapsed: 01:06:01
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 45980 steps/s (collection: 2.020s, learning 0.118s)
             Mean action noise std: 4.33
          Mean value_function loss: 66.3062
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.7952
                       Mean reward: 766.50
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 1.0887
    Episode_Reward/rotating_object: 144.1542
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.14s
                      Time elapsed: 01:06:03
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 45359 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 4.33
          Mean value_function loss: 55.9953
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 61.8078
                       Mean reward: 673.73
               Mean episode length: 225.71
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 140.6962
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.17s
                      Time elapsed: 01:06:05
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 45588 steps/s (collection: 2.036s, learning 0.120s)
             Mean action noise std: 4.33
          Mean value_function loss: 54.7605
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.8198
                       Mean reward: 710.46
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.0675
    Episode_Reward/rotating_object: 139.2844
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.16s
                      Time elapsed: 01:06:08
                               ETA: 00:08:33

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 44546 steps/s (collection: 2.018s, learning 0.189s)
             Mean action noise std: 4.34
          Mean value_function loss: 60.7298
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.8336
                       Mean reward: 679.07
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.0689
    Episode_Reward/rotating_object: 140.8297
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.21s
                      Time elapsed: 01:06:10
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 43974 steps/s (collection: 2.131s, learning 0.105s)
             Mean action noise std: 4.34
          Mean value_function loss: 60.0824
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 61.8512
                       Mean reward: 744.92
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.0863
    Episode_Reward/rotating_object: 144.9254
        Episode_Reward/action_rate: -0.0963
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.24s
                      Time elapsed: 01:06:12
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 45746 steps/s (collection: 2.030s, learning 0.119s)
             Mean action noise std: 4.34
          Mean value_function loss: 67.6812
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 61.8652
                       Mean reward: 689.22
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 1.0575
    Episode_Reward/rotating_object: 139.8199
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.15s
                      Time elapsed: 01:06:14
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 46240 steps/s (collection: 1.998s, learning 0.127s)
             Mean action noise std: 4.34
          Mean value_function loss: 67.4313
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 61.8746
                       Mean reward: 709.09
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 142.1034
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.13s
                      Time elapsed: 01:06:16
                               ETA: 00:08:21

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 19380 steps/s (collection: 4.950s, learning 0.122s)
             Mean action noise std: 4.35
          Mean value_function loss: 57.1908
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.8898
                       Mean reward: 706.21
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.0753
    Episode_Reward/rotating_object: 141.3477
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.07s
                      Time elapsed: 01:06:21
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14274 steps/s (collection: 6.764s, learning 0.123s)
             Mean action noise std: 4.35
          Mean value_function loss: 78.3234
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 61.9051
                       Mean reward: 738.74
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.0515
    Episode_Reward/rotating_object: 138.8244
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.89s
                      Time elapsed: 01:06:28
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14319 steps/s (collection: 6.709s, learning 0.156s)
             Mean action noise std: 4.35
          Mean value_function loss: 61.7344
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.9205
                       Mean reward: 719.59
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.0531
    Episode_Reward/rotating_object: 138.5680
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.87s
                      Time elapsed: 01:06:35
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14776 steps/s (collection: 6.530s, learning 0.123s)
             Mean action noise std: 4.36
          Mean value_function loss: 72.3062
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 61.9330
                       Mean reward: 680.35
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.0525
    Episode_Reward/rotating_object: 138.4398
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.65s
                      Time elapsed: 01:06:42
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14683 steps/s (collection: 6.577s, learning 0.118s)
             Mean action noise std: 4.36
          Mean value_function loss: 56.7138
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 61.9425
                       Mean reward: 730.17
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 1.0774
    Episode_Reward/rotating_object: 143.0365
        Episode_Reward/action_rate: -0.0968
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.69s
                      Time elapsed: 01:06:49
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14368 steps/s (collection: 6.695s, learning 0.147s)
             Mean action noise std: 4.36
          Mean value_function loss: 54.3020
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 61.9567
                       Mean reward: 699.67
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.0607
    Episode_Reward/rotating_object: 140.4164
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.84s
                      Time elapsed: 01:06:55
                               ETA: 00:08:05

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14545 steps/s (collection: 6.635s, learning 0.123s)
             Mean action noise std: 4.37
          Mean value_function loss: 64.4251
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 61.9730
                       Mean reward: 757.81
               Mean episode length: 243.32
    Episode_Reward/reaching_object: 1.0764
    Episode_Reward/rotating_object: 143.1882
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.76s
                      Time elapsed: 01:07:02
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14380 steps/s (collection: 6.710s, learning 0.126s)
             Mean action noise std: 4.37
          Mean value_function loss: 63.7297
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 61.9895
                       Mean reward: 699.53
               Mean episode length: 229.75
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 138.6740
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.84s
                      Time elapsed: 01:07:09
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 13428 steps/s (collection: 7.218s, learning 0.103s)
             Mean action noise std: 4.37
          Mean value_function loss: 67.2794
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 62.0077
                       Mean reward: 707.11
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.0494
    Episode_Reward/rotating_object: 137.8011
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.32s
                      Time elapsed: 01:07:16
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 48628 steps/s (collection: 1.903s, learning 0.119s)
             Mean action noise std: 4.37
          Mean value_function loss: 66.0702
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.0200
                       Mean reward: 670.77
               Mean episode length: 226.20
    Episode_Reward/reaching_object: 1.0646
    Episode_Reward/rotating_object: 140.3728
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.02s
                      Time elapsed: 01:07:18
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 49948 steps/s (collection: 1.870s, learning 0.098s)
             Mean action noise std: 4.38
          Mean value_function loss: 77.7991
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.0314
                       Mean reward: 705.25
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.0618
    Episode_Reward/rotating_object: 139.4741
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.97s
                      Time elapsed: 01:07:20
                               ETA: 00:07:52

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 40929 steps/s (collection: 2.197s, learning 0.205s)
             Mean action noise std: 4.38
          Mean value_function loss: 57.4165
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.0439
                       Mean reward: 728.80
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.0727
    Episode_Reward/rotating_object: 140.9021
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.40s
                      Time elapsed: 01:07:23
                               ETA: 00:07:48

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 48388 steps/s (collection: 1.909s, learning 0.122s)
             Mean action noise std: 4.38
          Mean value_function loss: 67.3273
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 62.0574
                       Mean reward: 721.61
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 138.7821
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.03s
                      Time elapsed: 01:07:25
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 47485 steps/s (collection: 1.964s, learning 0.106s)
             Mean action noise std: 4.38
          Mean value_function loss: 57.2185
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.0688
                       Mean reward: 724.86
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.0576
    Episode_Reward/rotating_object: 139.4332
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.07s
                      Time elapsed: 01:07:27
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 48787 steps/s (collection: 1.907s, learning 0.108s)
             Mean action noise std: 4.39
          Mean value_function loss: 57.0000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.0812
                       Mean reward: 706.22
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 1.0898
    Episode_Reward/rotating_object: 143.0090
        Episode_Reward/action_rate: -0.0987
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.01s
                      Time elapsed: 01:07:29
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 49600 steps/s (collection: 1.892s, learning 0.090s)
             Mean action noise std: 4.39
          Mean value_function loss: 64.0375
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.0946
                       Mean reward: 724.09
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 1.0757
    Episode_Reward/rotating_object: 141.9640
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.98s
                      Time elapsed: 01:07:31
                               ETA: 00:07:36

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 48582 steps/s (collection: 1.922s, learning 0.101s)
             Mean action noise std: 4.39
          Mean value_function loss: 54.5426
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.1149
                       Mean reward: 709.05
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 1.0607
    Episode_Reward/rotating_object: 139.5517
        Episode_Reward/action_rate: -0.0965
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.02s
                      Time elapsed: 01:07:33
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 50194 steps/s (collection: 1.857s, learning 0.101s)
             Mean action noise std: 4.40
          Mean value_function loss: 73.3537
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.1345
                       Mean reward: 688.17
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.0684
    Episode_Reward/rotating_object: 141.9892
        Episode_Reward/action_rate: -0.0967
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.96s
                      Time elapsed: 01:07:35
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 48919 steps/s (collection: 1.921s, learning 0.088s)
             Mean action noise std: 4.40
          Mean value_function loss: 61.0095
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.1474
                       Mean reward: 672.55
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 1.0657
    Episode_Reward/rotating_object: 139.9471
        Episode_Reward/action_rate: -0.0968
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.01s
                      Time elapsed: 01:07:37
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 49030 steps/s (collection: 1.911s, learning 0.094s)
             Mean action noise std: 4.40
          Mean value_function loss: 79.8241
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 62.1547
                       Mean reward: 639.35
               Mean episode length: 217.76
    Episode_Reward/reaching_object: 1.0669
    Episode_Reward/rotating_object: 139.9664
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.00s
                      Time elapsed: 01:07:39
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 49022 steps/s (collection: 1.896s, learning 0.110s)
             Mean action noise std: 4.40
          Mean value_function loss: 71.4362
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.1621
                       Mean reward: 683.86
               Mean episode length: 229.15
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 140.5146
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.01s
                      Time elapsed: 01:07:41
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 49354 steps/s (collection: 1.894s, learning 0.098s)
             Mean action noise std: 4.41
          Mean value_function loss: 72.1703
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.1755
                       Mean reward: 723.70
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.0670
    Episode_Reward/rotating_object: 139.5138
        Episode_Reward/action_rate: -0.0973
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.99s
                      Time elapsed: 01:07:43
                               ETA: 00:07:17

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 48422 steps/s (collection: 1.940s, learning 0.090s)
             Mean action noise std: 4.41
          Mean value_function loss: 63.0217
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.1897
                       Mean reward: 695.58
               Mean episode length: 230.94
    Episode_Reward/reaching_object: 1.0435
    Episode_Reward/rotating_object: 135.8159
        Episode_Reward/action_rate: -0.0951
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.03s
                      Time elapsed: 01:07:45
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 49141 steps/s (collection: 1.890s, learning 0.111s)
             Mean action noise std: 4.41
          Mean value_function loss: 60.5897
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.2013
                       Mean reward: 721.56
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.0971
    Episode_Reward/rotating_object: 145.7422
        Episode_Reward/action_rate: -0.0994
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.00s
                      Time elapsed: 01:07:47
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 48886 steps/s (collection: 1.900s, learning 0.111s)
             Mean action noise std: 4.41
          Mean value_function loss: 76.1551
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.2092
                       Mean reward: 687.79
               Mean episode length: 229.68
    Episode_Reward/reaching_object: 1.0591
    Episode_Reward/rotating_object: 137.4147
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.01s
                      Time elapsed: 01:07:49
                               ETA: 00:07:08

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 48587 steps/s (collection: 1.930s, learning 0.094s)
             Mean action noise std: 4.41
          Mean value_function loss: 70.5044
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.2128
                       Mean reward: 706.49
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 1.0708
    Episode_Reward/rotating_object: 141.5240
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.02s
                      Time elapsed: 01:07:51
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 50159 steps/s (collection: 1.856s, learning 0.104s)
             Mean action noise std: 4.42
          Mean value_function loss: 65.4932
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.2212
                       Mean reward: 668.17
               Mean episode length: 226.46
    Episode_Reward/reaching_object: 1.0666
    Episode_Reward/rotating_object: 139.0649
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.96s
                      Time elapsed: 01:07:53
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 48582 steps/s (collection: 1.915s, learning 0.108s)
             Mean action noise std: 4.42
          Mean value_function loss: 57.9157
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.2334
                       Mean reward: 721.68
               Mean episode length: 238.33
    Episode_Reward/reaching_object: 1.0825
    Episode_Reward/rotating_object: 143.0985
        Episode_Reward/action_rate: -0.0994
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.02s
                      Time elapsed: 01:07:55
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 49050 steps/s (collection: 1.881s, learning 0.124s)
             Mean action noise std: 4.42
          Mean value_function loss: 65.5445
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.2456
                       Mean reward: 720.36
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.0823
    Episode_Reward/rotating_object: 143.0623
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.00s
                      Time elapsed: 01:07:57
                               ETA: 00:06:56

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 49588 steps/s (collection: 1.889s, learning 0.094s)
             Mean action noise std: 4.42
          Mean value_function loss: 71.1199
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 62.2552
                       Mean reward: 706.68
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.0652
    Episode_Reward/rotating_object: 141.1751
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.98s
                      Time elapsed: 01:07:59
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 49156 steps/s (collection: 1.884s, learning 0.116s)
             Mean action noise std: 4.43
          Mean value_function loss: 84.0574
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.2627
                       Mean reward: 693.59
               Mean episode length: 231.42
    Episode_Reward/reaching_object: 1.0554
    Episode_Reward/rotating_object: 138.4307
        Episode_Reward/action_rate: -0.0973
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.00s
                      Time elapsed: 01:08:01
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 49120 steps/s (collection: 1.861s, learning 0.140s)
             Mean action noise std: 4.43
          Mean value_function loss: 71.3134
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 62.2750
                       Mean reward: 687.31
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 1.0494
    Episode_Reward/rotating_object: 137.1585
        Episode_Reward/action_rate: -0.0970
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.00s
                      Time elapsed: 01:08:03
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 45975 steps/s (collection: 1.989s, learning 0.150s)
             Mean action noise std: 4.43
          Mean value_function loss: 75.2902
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 62.2823
                       Mean reward: 710.04
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 138.8859
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.14s
                      Time elapsed: 01:08:05
                               ETA: 00:06:43

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 46990 steps/s (collection: 1.967s, learning 0.125s)
             Mean action noise std: 4.43
          Mean value_function loss: 63.3500
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.2907
                       Mean reward: 721.10
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.0899
    Episode_Reward/rotating_object: 143.9941
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.09s
                      Time elapsed: 01:08:07
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 49163 steps/s (collection: 1.881s, learning 0.118s)
             Mean action noise std: 4.43
          Mean value_function loss: 69.1815
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 62.3017
                       Mean reward: 654.96
               Mean episode length: 218.62
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 137.1423
        Episode_Reward/action_rate: -0.0966
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.00s
                      Time elapsed: 01:08:09
                               ETA: 00:06:37

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 48818 steps/s (collection: 1.897s, learning 0.117s)
             Mean action noise std: 4.44
          Mean value_function loss: 76.8142
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.3144
                       Mean reward: 666.81
               Mean episode length: 220.79
    Episode_Reward/reaching_object: 1.0485
    Episode_Reward/rotating_object: 137.2379
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.01s
                      Time elapsed: 01:08:11
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 49155 steps/s (collection: 1.903s, learning 0.097s)
             Mean action noise std: 4.44
          Mean value_function loss: 64.5596
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.3358
                       Mean reward: 717.01
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 141.9073
        Episode_Reward/action_rate: -0.0994
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.00s
                      Time elapsed: 01:08:13
                               ETA: 00:06:31

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 49170 steps/s (collection: 1.893s, learning 0.106s)
             Mean action noise std: 4.44
          Mean value_function loss: 59.8888
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.3472
                       Mean reward: 744.25
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 1.0779
    Episode_Reward/rotating_object: 141.8084
        Episode_Reward/action_rate: -0.0992
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.00s
                      Time elapsed: 01:08:15
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 48806 steps/s (collection: 1.906s, learning 0.108s)
             Mean action noise std: 4.45
          Mean value_function loss: 56.0642
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 62.3560
                       Mean reward: 725.97
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 143.3269
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.01s
                      Time elapsed: 01:08:17
                               ETA: 00:06:25

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 49501 steps/s (collection: 1.886s, learning 0.100s)
             Mean action noise std: 4.45
          Mean value_function loss: 55.0743
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.3660
                       Mean reward: 730.05
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.0847
    Episode_Reward/rotating_object: 142.4752
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.99s
                      Time elapsed: 01:08:19
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 49021 steps/s (collection: 1.902s, learning 0.103s)
             Mean action noise std: 4.45
          Mean value_function loss: 79.3209
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.3768
                       Mean reward: 709.75
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.0633
    Episode_Reward/rotating_object: 139.2102
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.01s
                      Time elapsed: 01:08:21
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 49682 steps/s (collection: 1.882s, learning 0.097s)
             Mean action noise std: 4.45
          Mean value_function loss: 70.1743
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.3908
                       Mean reward: 734.19
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.0887
    Episode_Reward/rotating_object: 145.0131
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.98s
                      Time elapsed: 01:08:23
                               ETA: 00:06:16

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 49166 steps/s (collection: 1.909s, learning 0.091s)
             Mean action noise std: 4.46
          Mean value_function loss: 64.7903
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.3984
                       Mean reward: 708.79
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.0809
    Episode_Reward/rotating_object: 142.5417
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.00s
                      Time elapsed: 01:08:25
                               ETA: 00:06:12

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 48913 steps/s (collection: 1.908s, learning 0.102s)
             Mean action noise std: 4.46
          Mean value_function loss: 69.3981
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.4057
                       Mean reward: 729.76
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 142.6668
        Episode_Reward/action_rate: -0.1004
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.01s
                      Time elapsed: 01:08:27
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 48879 steps/s (collection: 1.923s, learning 0.089s)
             Mean action noise std: 4.46
          Mean value_function loss: 74.1692
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 62.4159
                       Mean reward: 686.41
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 1.0743
    Episode_Reward/rotating_object: 141.4632
        Episode_Reward/action_rate: -0.0997
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.01s
                      Time elapsed: 01:08:29
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 48846 steps/s (collection: 1.904s, learning 0.108s)
             Mean action noise std: 4.46
          Mean value_function loss: 58.6693
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.4289
                       Mean reward: 688.31
               Mean episode length: 230.24
    Episode_Reward/reaching_object: 1.0711
    Episode_Reward/rotating_object: 139.8107
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.01s
                      Time elapsed: 01:08:31
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 48429 steps/s (collection: 1.904s, learning 0.126s)
             Mean action noise std: 4.47
          Mean value_function loss: 61.9822
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.4393
                       Mean reward: 725.77
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.0647
    Episode_Reward/rotating_object: 138.9772
        Episode_Reward/action_rate: -0.0993
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.03s
                      Time elapsed: 01:08:33
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 48829 steps/s (collection: 1.906s, learning 0.108s)
             Mean action noise std: 4.47
          Mean value_function loss: 56.7274
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 62.4521
                       Mean reward: 720.37
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 140.9913
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.01s
                      Time elapsed: 01:08:35
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 48297 steps/s (collection: 1.926s, learning 0.109s)
             Mean action noise std: 4.47
          Mean value_function loss: 66.6627
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.4638
                       Mean reward: 734.78
               Mean episode length: 238.20
    Episode_Reward/reaching_object: 1.0697
    Episode_Reward/rotating_object: 140.0956
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.04s
                      Time elapsed: 01:08:37
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 46758 steps/s (collection: 1.980s, learning 0.122s)
             Mean action noise std: 4.48
          Mean value_function loss: 59.1219
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.4784
                       Mean reward: 700.03
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 1.0739
    Episode_Reward/rotating_object: 140.5101
        Episode_Reward/action_rate: -0.1006
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.10s
                      Time elapsed: 01:08:39
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 46983 steps/s (collection: 1.964s, learning 0.128s)
             Mean action noise std: 4.48
          Mean value_function loss: 58.3000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.4918
                       Mean reward: 706.14
               Mean episode length: 229.90
    Episode_Reward/reaching_object: 1.0653
    Episode_Reward/rotating_object: 139.9512
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.09s
                      Time elapsed: 01:08:41
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 47788 steps/s (collection: 1.956s, learning 0.102s)
             Mean action noise std: 4.48
          Mean value_function loss: 64.8875
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.5040
                       Mean reward: 747.88
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.0947
    Episode_Reward/rotating_object: 144.1979
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.06s
                      Time elapsed: 01:08:43
                               ETA: 00:05:45

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 49271 steps/s (collection: 1.888s, learning 0.107s)
             Mean action noise std: 4.48
          Mean value_function loss: 62.0773
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 62.5161
                       Mean reward: 697.18
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 142.8066
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.00s
                      Time elapsed: 01:08:45
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 48506 steps/s (collection: 1.913s, learning 0.114s)
             Mean action noise std: 4.49
          Mean value_function loss: 63.6156
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 62.5225
                       Mean reward: 714.45
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.0796
    Episode_Reward/rotating_object: 142.6753
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.03s
                      Time elapsed: 01:08:47
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 46449 steps/s (collection: 2.022s, learning 0.095s)
             Mean action noise std: 4.49
          Mean value_function loss: 78.1098
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 62.5276
                       Mean reward: 676.49
               Mean episode length: 223.46
    Episode_Reward/reaching_object: 1.0613
    Episode_Reward/rotating_object: 138.8661
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.12s
                      Time elapsed: 01:08:50
                               ETA: 00:05:36

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 48046 steps/s (collection: 1.938s, learning 0.108s)
             Mean action noise std: 4.49
          Mean value_function loss: 65.6934
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.5310
                       Mean reward: 723.25
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.0781
    Episode_Reward/rotating_object: 142.2709
        Episode_Reward/action_rate: -0.1013
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.05s
                      Time elapsed: 01:08:52
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 49537 steps/s (collection: 1.893s, learning 0.092s)
             Mean action noise std: 4.49
          Mean value_function loss: 67.8083
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 62.5354
                       Mean reward: 745.46
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.0916
    Episode_Reward/rotating_object: 144.0441
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.98s
                      Time elapsed: 01:08:54
                               ETA: 00:05:30

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 48859 steps/s (collection: 1.920s, learning 0.092s)
             Mean action noise std: 4.49
          Mean value_function loss: 73.4155
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.5407
                       Mean reward: 695.31
               Mean episode length: 227.97
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 140.7465
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.01s
                      Time elapsed: 01:08:56
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 46550 steps/s (collection: 2.019s, learning 0.093s)
             Mean action noise std: 4.49
          Mean value_function loss: 55.7037
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.5557
                       Mean reward: 724.57
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 140.1671
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.11s
                      Time elapsed: 01:08:58
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 48150 steps/s (collection: 1.934s, learning 0.108s)
             Mean action noise std: 4.50
          Mean value_function loss: 69.0742
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 62.5744
                       Mean reward: 697.41
               Mean episode length: 234.23
    Episode_Reward/reaching_object: 1.0844
    Episode_Reward/rotating_object: 142.5905
        Episode_Reward/action_rate: -0.1019
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.04s
                      Time elapsed: 01:09:00
                               ETA: 00:05:20

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 49776 steps/s (collection: 1.885s, learning 0.090s)
             Mean action noise std: 4.50
          Mean value_function loss: 63.8742
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 62.5825
                       Mean reward: 727.02
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.0813
    Episode_Reward/rotating_object: 142.0102
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.97s
                      Time elapsed: 01:09:02
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 49940 steps/s (collection: 1.872s, learning 0.097s)
             Mean action noise std: 4.50
          Mean value_function loss: 71.9974
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.5886
                       Mean reward: 694.99
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 1.0785
    Episode_Reward/rotating_object: 141.5741
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.97s
                      Time elapsed: 01:09:04
                               ETA: 00:05:14

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 49202 steps/s (collection: 1.898s, learning 0.100s)
             Mean action noise std: 4.50
          Mean value_function loss: 66.2868
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.5993
                       Mean reward: 686.83
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 139.8508
        Episode_Reward/action_rate: -0.1011
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.00s
                      Time elapsed: 01:09:06
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 47217 steps/s (collection: 1.988s, learning 0.094s)
             Mean action noise std: 4.50
          Mean value_function loss: 67.3649
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.6086
                       Mean reward: 731.17
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.0915
    Episode_Reward/rotating_object: 143.8239
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.08s
                      Time elapsed: 01:09:08
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 45438 steps/s (collection: 2.047s, learning 0.117s)
             Mean action noise std: 4.51
          Mean value_function loss: 70.5757
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.6125
                       Mean reward: 714.74
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 1.0645
    Episode_Reward/rotating_object: 139.4997
        Episode_Reward/action_rate: -0.1010
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.16s
                      Time elapsed: 01:09:10
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 44395 steps/s (collection: 2.030s, learning 0.185s)
             Mean action noise std: 4.51
          Mean value_function loss: 64.2140
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.6193
                       Mean reward: 731.34
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.0771
    Episode_Reward/rotating_object: 141.8301
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.21s
                      Time elapsed: 01:09:12
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 45624 steps/s (collection: 1.990s, learning 0.164s)
             Mean action noise std: 4.51
          Mean value_function loss: 63.2708
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.6295
                       Mean reward: 741.32
               Mean episode length: 242.37
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 141.6450
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.15s
                      Time elapsed: 01:09:14
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 48028 steps/s (collection: 1.952s, learning 0.095s)
             Mean action noise std: 4.51
          Mean value_function loss: 63.2564
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 62.6410
                       Mean reward: 730.31
               Mean episode length: 237.58
    Episode_Reward/reaching_object: 1.0885
    Episode_Reward/rotating_object: 143.0746
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.05s
                      Time elapsed: 01:09:16
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 45525 steps/s (collection: 2.063s, learning 0.096s)
             Mean action noise std: 4.52
          Mean value_function loss: 49.6230
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 62.6528
                       Mean reward: 704.08
               Mean episode length: 230.70
    Episode_Reward/reaching_object: 1.0715
    Episode_Reward/rotating_object: 140.5237
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.16s
                      Time elapsed: 01:09:18
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 48289 steps/s (collection: 1.919s, learning 0.117s)
             Mean action noise std: 4.52
          Mean value_function loss: 55.9296
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.6620
                       Mean reward: 714.25
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0768
    Episode_Reward/rotating_object: 141.2955
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.04s
                      Time elapsed: 01:09:21
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 48369 steps/s (collection: 1.916s, learning 0.117s)
             Mean action noise std: 4.52
          Mean value_function loss: 53.6087
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 62.6743
                       Mean reward: 722.06
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.1087
    Episode_Reward/rotating_object: 145.8960
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.03s
                      Time elapsed: 01:09:23
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 48326 steps/s (collection: 1.930s, learning 0.104s)
             Mean action noise std: 4.52
          Mean value_function loss: 51.5724
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.6856
                       Mean reward: 724.85
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.0989
    Episode_Reward/rotating_object: 144.7932
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.03s
                      Time elapsed: 01:09:25
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 48523 steps/s (collection: 1.929s, learning 0.097s)
             Mean action noise std: 4.52
          Mean value_function loss: 54.4664
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.6906
                       Mean reward: 740.43
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 1.1117
    Episode_Reward/rotating_object: 147.3366
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.03s
                      Time elapsed: 01:09:27
                               ETA: 00:04:41

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 49446 steps/s (collection: 1.890s, learning 0.098s)
             Mean action noise std: 4.53
          Mean value_function loss: 70.5344
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.6981
                       Mean reward: 742.87
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 1.0884
    Episode_Reward/rotating_object: 143.6486
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.99s
                      Time elapsed: 01:09:29
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 48414 steps/s (collection: 1.939s, learning 0.091s)
             Mean action noise std: 4.53
          Mean value_function loss: 54.8781
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 62.7064
                       Mean reward: 715.69
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.0701
    Episode_Reward/rotating_object: 140.5497
        Episode_Reward/action_rate: -0.1022
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.03s
                      Time elapsed: 01:09:31
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 49076 steps/s (collection: 1.908s, learning 0.095s)
             Mean action noise std: 4.53
          Mean value_function loss: 56.7267
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.7145
                       Mean reward: 744.56
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.0866
    Episode_Reward/rotating_object: 142.7373
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.00s
                      Time elapsed: 01:09:33
                               ETA: 00:04:32

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 48249 steps/s (collection: 1.925s, learning 0.113s)
             Mean action noise std: 4.53
          Mean value_function loss: 61.5455
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.7244
                       Mean reward: 699.70
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 139.3365
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.04s
                      Time elapsed: 01:09:35
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 48984 steps/s (collection: 1.909s, learning 0.098s)
             Mean action noise std: 4.53
          Mean value_function loss: 63.8090
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.7352
                       Mean reward: 725.20
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 142.9570
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.01s
                      Time elapsed: 01:09:37
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 47014 steps/s (collection: 1.967s, learning 0.124s)
             Mean action noise std: 4.54
          Mean value_function loss: 65.7853
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 62.7412
                       Mean reward: 731.07
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.0742
    Episode_Reward/rotating_object: 142.1902
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.09s
                      Time elapsed: 01:09:39
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 44743 steps/s (collection: 2.045s, learning 0.152s)
             Mean action noise std: 4.54
          Mean value_function loss: 55.6130
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.7487
                       Mean reward: 645.64
               Mean episode length: 217.79
    Episode_Reward/reaching_object: 1.0679
    Episode_Reward/rotating_object: 140.3642
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.20s
                      Time elapsed: 01:09:41
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 48280 steps/s (collection: 1.932s, learning 0.104s)
             Mean action noise std: 4.54
          Mean value_function loss: 56.0285
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.7588
                       Mean reward: 720.67
               Mean episode length: 235.84
    Episode_Reward/reaching_object: 1.0789
    Episode_Reward/rotating_object: 142.4425
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.04s
                      Time elapsed: 01:09:43
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 47853 steps/s (collection: 1.964s, learning 0.091s)
             Mean action noise std: 4.54
          Mean value_function loss: 65.0183
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 62.7661
                       Mean reward: 724.18
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.0810
    Episode_Reward/rotating_object: 143.0980
        Episode_Reward/action_rate: -0.1040
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.05s
                      Time elapsed: 01:09:45
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 47863 steps/s (collection: 1.962s, learning 0.092s)
             Mean action noise std: 4.54
          Mean value_function loss: 58.5243
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 62.7728
                       Mean reward: 707.84
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.0732
    Episode_Reward/rotating_object: 142.1280
        Episode_Reward/action_rate: -0.1033
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.05s
                      Time elapsed: 01:09:47
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 48470 steps/s (collection: 1.924s, learning 0.104s)
             Mean action noise std: 4.55
          Mean value_function loss: 58.7053
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.7790
                       Mean reward: 737.22
               Mean episode length: 240.33
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 144.9072
        Episode_Reward/action_rate: -0.1056
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.03s
                      Time elapsed: 01:09:49
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 47500 steps/s (collection: 1.980s, learning 0.090s)
             Mean action noise std: 4.55
          Mean value_function loss: 69.2029
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.7840
                       Mean reward: 712.21
               Mean episode length: 233.72
    Episode_Reward/reaching_object: 1.0671
    Episode_Reward/rotating_object: 140.2014
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.07s
                      Time elapsed: 01:09:51
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 48147 steps/s (collection: 1.931s, learning 0.111s)
             Mean action noise std: 4.55
          Mean value_function loss: 64.1830
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.7959
                       Mean reward: 730.18
               Mean episode length: 237.39
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 139.0457
        Episode_Reward/action_rate: -0.1033
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.04s
                      Time elapsed: 01:09:53
                               ETA: 00:04:02

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 46219 steps/s (collection: 2.000s, learning 0.127s)
             Mean action noise std: 4.55
          Mean value_function loss: 61.3462
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 62.8085
                       Mean reward: 669.19
               Mean episode length: 224.28
    Episode_Reward/reaching_object: 1.0502
    Episode_Reward/rotating_object: 137.9016
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.13s
                      Time elapsed: 01:09:55
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 45715 steps/s (collection: 1.972s, learning 0.178s)
             Mean action noise std: 4.55
          Mean value_function loss: 51.7975
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 62.8109
                       Mean reward: 733.71
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.0923
    Episode_Reward/rotating_object: 145.5083
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.15s
                      Time elapsed: 01:09:58
                               ETA: 00:03:56

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 47664 steps/s (collection: 1.938s, learning 0.124s)
             Mean action noise std: 4.55
          Mean value_function loss: 66.7883
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 62.8144
                       Mean reward: 718.09
               Mean episode length: 233.80
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 144.7613
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.06s
                      Time elapsed: 01:10:00
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 47436 steps/s (collection: 1.970s, learning 0.103s)
             Mean action noise std: 4.56
          Mean value_function loss: 50.2663
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.8247
                       Mean reward: 758.66
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.0955
    Episode_Reward/rotating_object: 145.6049
        Episode_Reward/action_rate: -0.1062
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.07s
                      Time elapsed: 01:10:02
                               ETA: 00:03:50

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 49308 steps/s (collection: 1.889s, learning 0.105s)
             Mean action noise std: 4.56
          Mean value_function loss: 55.1052
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.8374
                       Mean reward: 724.56
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.0821
    Episode_Reward/rotating_object: 142.4067
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.99s
                      Time elapsed: 01:10:04
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 47912 steps/s (collection: 1.954s, learning 0.098s)
             Mean action noise std: 4.56
          Mean value_function loss: 54.1975
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 62.8483
                       Mean reward: 756.97
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 1.0889
    Episode_Reward/rotating_object: 144.0235
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.05s
                      Time elapsed: 01:10:06
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 49158 steps/s (collection: 1.897s, learning 0.103s)
             Mean action noise std: 4.56
          Mean value_function loss: 52.6953
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 62.8568
                       Mean reward: 720.74
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.0899
    Episode_Reward/rotating_object: 144.4253
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.00s
                      Time elapsed: 01:10:08
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 48297 steps/s (collection: 1.930s, learning 0.105s)
             Mean action noise std: 4.57
          Mean value_function loss: 54.1399
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.8635
                       Mean reward: 722.46
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.0966
    Episode_Reward/rotating_object: 145.2577
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.04s
                      Time elapsed: 01:10:10
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 45804 steps/s (collection: 1.961s, learning 0.185s)
             Mean action noise std: 4.57
          Mean value_function loss: 57.2283
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.8724
                       Mean reward: 729.90
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.0929
    Episode_Reward/rotating_object: 145.6491
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.15s
                      Time elapsed: 01:10:12
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 47621 steps/s (collection: 1.963s, learning 0.101s)
             Mean action noise std: 4.57
          Mean value_function loss: 44.7199
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 62.8827
                       Mean reward: 724.75
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.0911
    Episode_Reward/rotating_object: 145.1281
        Episode_Reward/action_rate: -0.1066
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.06s
                      Time elapsed: 01:10:14
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 48577 steps/s (collection: 1.913s, learning 0.111s)
             Mean action noise std: 4.57
          Mean value_function loss: 50.8813
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.8864
                       Mean reward: 744.84
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 1.0812
    Episode_Reward/rotating_object: 144.1293
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.02s
                      Time elapsed: 01:10:16
                               ETA: 00:03:29

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 47366 steps/s (collection: 1.978s, learning 0.097s)
             Mean action noise std: 4.57
          Mean value_function loss: 52.5090
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 62.8951
                       Mean reward: 750.56
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.0979
    Episode_Reward/rotating_object: 146.9394
        Episode_Reward/action_rate: -0.1076
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.08s
                      Time elapsed: 01:10:18
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 47660 steps/s (collection: 1.949s, learning 0.114s)
             Mean action noise std: 4.58
          Mean value_function loss: 66.5885
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.9085
                       Mean reward: 726.31
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.0740
    Episode_Reward/rotating_object: 142.7553
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.06s
                      Time elapsed: 01:10:20
                               ETA: 00:03:23

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 49443 steps/s (collection: 1.896s, learning 0.092s)
             Mean action noise std: 4.58
          Mean value_function loss: 55.4073
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 62.9210
                       Mean reward: 700.95
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 145.0901
        Episode_Reward/action_rate: -0.1068
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.99s
                      Time elapsed: 01:10:22
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 48141 steps/s (collection: 1.943s, learning 0.099s)
             Mean action noise std: 4.58
          Mean value_function loss: 44.8781
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 62.9291
                       Mean reward: 732.06
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 1.0880
    Episode_Reward/rotating_object: 145.3731
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.04s
                      Time elapsed: 01:10:24
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 48691 steps/s (collection: 1.918s, learning 0.101s)
             Mean action noise std: 4.58
          Mean value_function loss: 44.2549
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 62.9431
                       Mean reward: 709.25
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.0892
    Episode_Reward/rotating_object: 144.6619
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.02s
                      Time elapsed: 01:10:26
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 49125 steps/s (collection: 1.905s, learning 0.097s)
             Mean action noise std: 4.59
          Mean value_function loss: 52.9806
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 62.9549
                       Mean reward: 725.97
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.0914
    Episode_Reward/rotating_object: 145.8153
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.00s
                      Time elapsed: 01:10:28
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 46176 steps/s (collection: 1.961s, learning 0.168s)
             Mean action noise std: 4.59
          Mean value_function loss: 60.4746
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.9632
                       Mean reward: 746.72
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 1.0883
    Episode_Reward/rotating_object: 145.1301
        Episode_Reward/action_rate: -0.1070
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.13s
                      Time elapsed: 01:10:30
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 44698 steps/s (collection: 2.049s, learning 0.150s)
             Mean action noise std: 4.59
          Mean value_function loss: 60.7495
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.9807
                       Mean reward: 733.97
               Mean episode length: 236.99
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 142.8019
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.20s
                      Time elapsed: 01:10:33
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 43005 steps/s (collection: 2.168s, learning 0.118s)
             Mean action noise std: 4.60
          Mean value_function loss: 73.2730
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 62.9981
                       Mean reward: 682.28
               Mean episode length: 224.94
    Episode_Reward/reaching_object: 1.0660
    Episode_Reward/rotating_object: 141.2180
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.29s
                      Time elapsed: 01:10:35
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 44066 steps/s (collection: 2.122s, learning 0.109s)
             Mean action noise std: 4.60
          Mean value_function loss: 57.8544
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 63.0151
                       Mean reward: 706.76
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.0837
    Episode_Reward/rotating_object: 145.2101
        Episode_Reward/action_rate: -0.1072
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.23s
                      Time elapsed: 01:10:37
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 47159 steps/s (collection: 1.967s, learning 0.118s)
             Mean action noise std: 4.60
          Mean value_function loss: 56.3224
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 63.0290
                       Mean reward: 716.93
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.0869
    Episode_Reward/rotating_object: 144.2223
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.08s
                      Time elapsed: 01:10:39
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 45355 steps/s (collection: 2.061s, learning 0.106s)
             Mean action noise std: 4.60
          Mean value_function loss: 64.6505
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 63.0383
                       Mean reward: 692.01
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 1.0487
    Episode_Reward/rotating_object: 138.6057
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.17s
                      Time elapsed: 01:10:41
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 45469 steps/s (collection: 2.032s, learning 0.130s)
             Mean action noise std: 4.61
          Mean value_function loss: 65.2539
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 63.0472
                       Mean reward: 736.39
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0658
    Episode_Reward/rotating_object: 142.4670
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.16s
                      Time elapsed: 01:10:43
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 44987 steps/s (collection: 1.986s, learning 0.199s)
             Mean action noise std: 4.61
          Mean value_function loss: 53.6849
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 63.0568
                       Mean reward: 730.06
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 146.0524
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.19s
                      Time elapsed: 01:10:46
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 45825 steps/s (collection: 2.000s, learning 0.145s)
             Mean action noise std: 4.61
          Mean value_function loss: 64.3555
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 63.0662
                       Mean reward: 719.62
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 142.4812
        Episode_Reward/action_rate: -0.1074
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.15s
                      Time elapsed: 01:10:48
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 46902 steps/s (collection: 1.962s, learning 0.134s)
             Mean action noise std: 4.61
          Mean value_function loss: 65.5318
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 63.0803
                       Mean reward: 693.23
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 138.7537
        Episode_Reward/action_rate: -0.1052
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.10s
                      Time elapsed: 01:10:50
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 47662 steps/s (collection: 1.959s, learning 0.104s)
             Mean action noise std: 4.62
          Mean value_function loss: 67.6350
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.0929
                       Mean reward: 704.67
               Mean episode length: 227.49
    Episode_Reward/reaching_object: 1.0546
    Episode_Reward/rotating_object: 140.2219
        Episode_Reward/action_rate: -0.1051
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.06s
                      Time elapsed: 01:10:52
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 47792 steps/s (collection: 1.944s, learning 0.113s)
             Mean action noise std: 4.62
          Mean value_function loss: 62.3410
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.1096
                       Mean reward: 732.79
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.0785
    Episode_Reward/rotating_object: 144.1499
        Episode_Reward/action_rate: -0.1075
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.06s
                      Time elapsed: 01:10:54
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 45082 steps/s (collection: 2.065s, learning 0.115s)
             Mean action noise std: 4.62
          Mean value_function loss: 65.5339
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.1256
                       Mean reward: 725.68
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 1.0697
    Episode_Reward/rotating_object: 142.3129
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.18s
                      Time elapsed: 01:10:56
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 46688 steps/s (collection: 2.006s, learning 0.099s)
             Mean action noise std: 4.62
          Mean value_function loss: 66.7093
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.1366
                       Mean reward: 727.94
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.0761
    Episode_Reward/rotating_object: 142.8241
        Episode_Reward/action_rate: -0.1074
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.11s
                      Time elapsed: 01:10:58
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 45113 steps/s (collection: 2.017s, learning 0.162s)
             Mean action noise std: 4.63
          Mean value_function loss: 58.2467
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 63.1477
                       Mean reward: 738.03
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.0657
    Episode_Reward/rotating_object: 142.6676
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.18s
                      Time elapsed: 01:11:00
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 43052 steps/s (collection: 2.193s, learning 0.090s)
             Mean action noise std: 4.63
          Mean value_function loss: 55.7339
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.1579
                       Mean reward: 746.12
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.0762
    Episode_Reward/rotating_object: 143.5494
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.28s
                      Time elapsed: 01:11:03
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 47326 steps/s (collection: 1.982s, learning 0.096s)
             Mean action noise std: 4.63
          Mean value_function loss: 67.8459
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 63.1661
                       Mean reward: 755.38
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.0991
    Episode_Reward/rotating_object: 146.7884
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.08s
                      Time elapsed: 01:11:05
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 48168 steps/s (collection: 1.948s, learning 0.093s)
             Mean action noise std: 4.63
          Mean value_function loss: 65.2357
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 63.1725
                       Mean reward: 722.16
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.0840
    Episode_Reward/rotating_object: 144.7330
        Episode_Reward/action_rate: -0.1085
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.04s
                      Time elapsed: 01:11:07
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 47662 steps/s (collection: 1.969s, learning 0.094s)
             Mean action noise std: 4.63
          Mean value_function loss: 62.9161
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 63.1766
                       Mean reward: 709.10
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 141.2470
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.06s
                      Time elapsed: 01:11:09
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 48007 steps/s (collection: 1.953s, learning 0.095s)
             Mean action noise std: 4.64
          Mean value_function loss: 64.1105
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 63.1850
                       Mean reward: 689.43
               Mean episode length: 225.07
    Episode_Reward/reaching_object: 1.0760
    Episode_Reward/rotating_object: 142.4130
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.05s
                      Time elapsed: 01:11:11
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 48214 steps/s (collection: 1.934s, learning 0.104s)
             Mean action noise std: 4.64
          Mean value_function loss: 61.3811
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 63.1984
                       Mean reward: 709.18
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.0575
    Episode_Reward/rotating_object: 139.8293
        Episode_Reward/action_rate: -0.1067
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.04s
                      Time elapsed: 01:11:13
                               ETA: 00:02:09

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 46554 steps/s (collection: 2.004s, learning 0.108s)
             Mean action noise std: 4.64
          Mean value_function loss: 70.5463
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 63.2077
                       Mean reward: 702.17
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.0680
    Episode_Reward/rotating_object: 141.9644
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.11s
                      Time elapsed: 01:11:15
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 41763 steps/s (collection: 2.186s, learning 0.168s)
             Mean action noise std: 4.65
          Mean value_function loss: 67.6153
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 63.2215
                       Mean reward: 737.89
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.0807
    Episode_Reward/rotating_object: 144.3240
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.35s
                      Time elapsed: 01:11:17
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 47325 steps/s (collection: 1.977s, learning 0.100s)
             Mean action noise std: 4.65
          Mean value_function loss: 54.0145
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 63.2306
                       Mean reward: 706.45
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.0498
    Episode_Reward/rotating_object: 138.8257
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.08s
                      Time elapsed: 01:11:20
                               ETA: 00:02:00

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 41731 steps/s (collection: 2.147s, learning 0.209s)
             Mean action noise std: 4.65
          Mean value_function loss: 66.1467
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 63.2422
                       Mean reward: 725.44
               Mean episode length: 234.87
    Episode_Reward/reaching_object: 1.0716
    Episode_Reward/rotating_object: 142.7669
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.36s
                      Time elapsed: 01:11:22
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 44132 steps/s (collection: 2.108s, learning 0.119s)
             Mean action noise std: 4.65
          Mean value_function loss: 67.0452
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 63.2558
                       Mean reward: 720.69
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.0886
    Episode_Reward/rotating_object: 145.3838
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.23s
                      Time elapsed: 01:11:24
                               ETA: 00:01:54

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 42327 steps/s (collection: 2.177s, learning 0.146s)
             Mean action noise std: 4.66
          Mean value_function loss: 63.5747
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.2655
                       Mean reward: 702.85
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 1.0804
    Episode_Reward/rotating_object: 144.1487
        Episode_Reward/action_rate: -0.1095
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.32s
                      Time elapsed: 01:11:26
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 44799 steps/s (collection: 2.054s, learning 0.140s)
             Mean action noise std: 4.66
          Mean value_function loss: 59.5395
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 63.2740
                       Mean reward: 690.16
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.0602
    Episode_Reward/rotating_object: 140.6784
        Episode_Reward/action_rate: -0.1076
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.19s
                      Time elapsed: 01:11:29
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 47518 steps/s (collection: 1.979s, learning 0.090s)
             Mean action noise std: 4.66
          Mean value_function loss: 53.6099
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 63.2844
                       Mean reward: 722.20
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 140.5883
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.07s
                      Time elapsed: 01:11:31
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 44814 steps/s (collection: 2.004s, learning 0.190s)
             Mean action noise std: 4.66
          Mean value_function loss: 54.9909
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.2921
                       Mean reward: 699.28
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.0755
    Episode_Reward/rotating_object: 142.5502
        Episode_Reward/action_rate: -0.1093
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.19s
                      Time elapsed: 01:11:33
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 44907 steps/s (collection: 2.075s, learning 0.114s)
             Mean action noise std: 4.66
          Mean value_function loss: 47.7055
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 63.3005
                       Mean reward: 749.87
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.1031
    Episode_Reward/rotating_object: 148.3404
        Episode_Reward/action_rate: -0.1115
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.19s
                      Time elapsed: 01:11:35
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 46185 steps/s (collection: 2.013s, learning 0.116s)
             Mean action noise std: 4.67
          Mean value_function loss: 60.7506
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 63.3077
                       Mean reward: 701.46
               Mean episode length: 230.44
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 142.6726
        Episode_Reward/action_rate: -0.1094
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.13s
                      Time elapsed: 01:11:37
                               ETA: 00:01:36

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 47616 steps/s (collection: 1.968s, learning 0.096s)
             Mean action noise std: 4.67
          Mean value_function loss: 60.5358
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 63.3161
                       Mean reward: 728.08
               Mean episode length: 235.49
    Episode_Reward/reaching_object: 1.0864
    Episode_Reward/rotating_object: 144.0430
        Episode_Reward/action_rate: -0.1103
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.06s
                      Time elapsed: 01:11:39
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 47107 steps/s (collection: 1.974s, learning 0.113s)
             Mean action noise std: 4.67
          Mean value_function loss: 58.8720
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.3308
                       Mean reward: 745.56
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.0790
    Episode_Reward/rotating_object: 141.9242
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.09s
                      Time elapsed: 01:11:41
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 48006 steps/s (collection: 1.958s, learning 0.090s)
             Mean action noise std: 4.67
          Mean value_function loss: 70.9748
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 63.3399
                       Mean reward: 720.01
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.0659
    Episode_Reward/rotating_object: 141.8027
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.05s
                      Time elapsed: 01:11:43
                               ETA: 00:01:27

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 48060 steps/s (collection: 1.947s, learning 0.099s)
             Mean action noise std: 4.67
          Mean value_function loss: 65.4063
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 63.3507
                       Mean reward: 735.21
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.0921
    Episode_Reward/rotating_object: 145.6063
        Episode_Reward/action_rate: -0.1111
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.05s
                      Time elapsed: 01:11:45
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 41113 steps/s (collection: 2.193s, learning 0.198s)
             Mean action noise std: 4.68
          Mean value_function loss: 56.7898
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.3578
                       Mean reward: 711.47
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.0707
    Episode_Reward/rotating_object: 140.7829
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.39s
                      Time elapsed: 01:11:48
                               ETA: 00:01:21

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 46136 steps/s (collection: 1.965s, learning 0.166s)
             Mean action noise std: 4.68
          Mean value_function loss: 62.3284
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.3686
                       Mean reward: 715.15
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.0933
    Episode_Reward/rotating_object: 145.2640
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.13s
                      Time elapsed: 01:11:50
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 46378 steps/s (collection: 2.017s, learning 0.103s)
             Mean action noise std: 4.68
          Mean value_function loss: 69.4609
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 63.3793
                       Mean reward: 705.39
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 138.2525
        Episode_Reward/action_rate: -0.1094
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.12s
                      Time elapsed: 01:11:52
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 45597 steps/s (collection: 1.975s, learning 0.181s)
             Mean action noise std: 4.68
          Mean value_function loss: 56.0790
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 63.3881
                       Mean reward: 729.66
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.0885
    Episode_Reward/rotating_object: 144.0390
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.16s
                      Time elapsed: 01:11:54
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 48638 steps/s (collection: 1.927s, learning 0.094s)
             Mean action noise std: 4.69
          Mean value_function loss: 63.6627
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.3961
                       Mean reward: 682.60
               Mean episode length: 224.95
    Episode_Reward/reaching_object: 1.0677
    Episode_Reward/rotating_object: 141.4989
        Episode_Reward/action_rate: -0.1095
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.02s
                      Time elapsed: 01:11:56
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 48702 steps/s (collection: 1.916s, learning 0.102s)
             Mean action noise std: 4.69
          Mean value_function loss: 49.0039
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 63.4075
                       Mean reward: 746.03
               Mean episode length: 240.82
    Episode_Reward/reaching_object: 1.0839
    Episode_Reward/rotating_object: 144.1831
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.02s
                      Time elapsed: 01:11:58
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 48874 steps/s (collection: 1.912s, learning 0.100s)
             Mean action noise std: 4.69
          Mean value_function loss: 54.7564
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 63.4206
                       Mean reward: 727.64
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.0783
    Episode_Reward/rotating_object: 142.6244
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.01s
                      Time elapsed: 01:12:00
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 47564 steps/s (collection: 1.961s, learning 0.105s)
             Mean action noise std: 4.69
          Mean value_function loss: 65.5454
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 63.4317
                       Mean reward: 717.24
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.0833
    Episode_Reward/rotating_object: 144.2346
        Episode_Reward/action_rate: -0.1107
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.07s
                      Time elapsed: 01:12:02
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 48635 steps/s (collection: 1.927s, learning 0.095s)
             Mean action noise std: 4.70
          Mean value_function loss: 53.0924
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 63.4445
                       Mean reward: 717.14
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 1.0765
    Episode_Reward/rotating_object: 143.0979
        Episode_Reward/action_rate: -0.1105
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.02s
                      Time elapsed: 01:12:04
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 48619 steps/s (collection: 1.902s, learning 0.120s)
             Mean action noise std: 4.70
          Mean value_function loss: 64.8196
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 63.4552
                       Mean reward: 748.80
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 144.7710
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.02s
                      Time elapsed: 01:12:06
                               ETA: 00:00:55

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 48619 steps/s (collection: 1.915s, learning 0.107s)
             Mean action noise std: 4.70
          Mean value_function loss: 59.0535
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 63.4626
                       Mean reward: 717.81
               Mean episode length: 234.14
    Episode_Reward/reaching_object: 1.0919
    Episode_Reward/rotating_object: 143.9580
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.02s
                      Time elapsed: 01:12:08
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 48650 steps/s (collection: 1.929s, learning 0.092s)
             Mean action noise std: 4.70
          Mean value_function loss: 56.2808
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.4694
                       Mean reward: 693.92
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.0883
    Episode_Reward/rotating_object: 144.5544
        Episode_Reward/action_rate: -0.1123
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.02s
                      Time elapsed: 01:12:10
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 48704 steps/s (collection: 1.903s, learning 0.116s)
             Mean action noise std: 4.71
          Mean value_function loss: 70.6515
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 63.4794
                       Mean reward: 711.69
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.0891
    Episode_Reward/rotating_object: 143.9559
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.02s
                      Time elapsed: 01:12:12
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 49364 steps/s (collection: 1.894s, learning 0.097s)
             Mean action noise std: 4.71
          Mean value_function loss: 66.1694
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 63.4923
                       Mean reward: 698.85
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 1.0770
    Episode_Reward/rotating_object: 142.7282
        Episode_Reward/action_rate: -0.1113
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.99s
                      Time elapsed: 01:12:14
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 48868 steps/s (collection: 1.919s, learning 0.092s)
             Mean action noise std: 4.71
          Mean value_function loss: 60.0133
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 63.5041
                       Mean reward: 709.41
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.0605
    Episode_Reward/rotating_object: 139.1645
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.01s
                      Time elapsed: 01:12:16
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 49861 steps/s (collection: 1.866s, learning 0.106s)
             Mean action noise std: 4.71
          Mean value_function loss: 60.5086
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.5094
                       Mean reward: 742.43
               Mean episode length: 240.63
    Episode_Reward/reaching_object: 1.0722
    Episode_Reward/rotating_object: 140.7170
        Episode_Reward/action_rate: -0.1108
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.97s
                      Time elapsed: 01:12:18
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 49293 steps/s (collection: 1.897s, learning 0.097s)
             Mean action noise std: 4.72
          Mean value_function loss: 43.6990
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 63.5173
                       Mean reward: 748.03
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.0972
    Episode_Reward/rotating_object: 145.5318
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.99s
                      Time elapsed: 01:12:20
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 48461 steps/s (collection: 1.908s, learning 0.121s)
             Mean action noise std: 4.72
          Mean value_function loss: 54.7182
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.5235
                       Mean reward: 732.09
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 1.0955
    Episode_Reward/rotating_object: 146.2367
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.03s
                      Time elapsed: 01:12:22
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 48436 steps/s (collection: 1.925s, learning 0.105s)
             Mean action noise std: 4.72
          Mean value_function loss: 52.5006
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 63.5301
                       Mean reward: 734.14
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.0877
    Episode_Reward/rotating_object: 144.0144
        Episode_Reward/action_rate: -0.1129
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.03s
                      Time elapsed: 01:12:25
                               ETA: 00:00:29

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 48795 steps/s (collection: 1.901s, learning 0.113s)
             Mean action noise std: 4.72
          Mean value_function loss: 75.2366
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 63.5394
                       Mean reward: 694.75
               Mean episode length: 226.18
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 144.7868
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.01s
                      Time elapsed: 01:12:27
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 48481 steps/s (collection: 1.933s, learning 0.095s)
             Mean action noise std: 4.73
          Mean value_function loss: 64.0419
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 63.5515
                       Mean reward: 742.62
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.0943
    Episode_Reward/rotating_object: 145.7629
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.03s
                      Time elapsed: 01:12:29
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 49165 steps/s (collection: 1.907s, learning 0.092s)
             Mean action noise std: 4.73
          Mean value_function loss: 68.7539
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 63.5661
                       Mean reward: 683.98
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 1.0568
    Episode_Reward/rotating_object: 138.6949
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.00s
                      Time elapsed: 01:12:31
                               ETA: 00:00:20

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 48338 steps/s (collection: 1.917s, learning 0.117s)
             Mean action noise std: 4.73
          Mean value_function loss: 66.6866
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 63.5802
                       Mean reward: 741.49
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.0940
    Episode_Reward/rotating_object: 144.2793
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.03s
                      Time elapsed: 01:12:33
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 44446 steps/s (collection: 2.038s, learning 0.174s)
             Mean action noise std: 4.73
          Mean value_function loss: 64.8768
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 63.5968
                       Mean reward: 728.96
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.0841
    Episode_Reward/rotating_object: 144.5531
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.21s
                      Time elapsed: 01:12:35
                               ETA: 00:00:14

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 45078 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 4.74
          Mean value_function loss: 47.4674
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 63.6051
                       Mean reward: 701.59
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.0830
    Episode_Reward/rotating_object: 142.4855
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.18s
                      Time elapsed: 01:12:37
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 48037 steps/s (collection: 1.939s, learning 0.108s)
             Mean action noise std: 4.74
          Mean value_function loss: 71.7048
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.6098
                       Mean reward: 697.48
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 142.9065
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.05s
                      Time elapsed: 01:12:39
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 46520 steps/s (collection: 1.984s, learning 0.129s)
             Mean action noise std: 4.74
          Mean value_function loss: 75.2995
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 63.6125
                       Mean reward: 732.60
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.0797
    Episode_Reward/rotating_object: 143.0059
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.11s
                      Time elapsed: 01:12:41
                               ETA: 00:00:05

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 47869 steps/s (collection: 1.943s, learning 0.111s)
             Mean action noise std: 4.74
          Mean value_function loss: 60.5831
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 63.6180
                       Mean reward: 694.80
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 142.1311
        Episode_Reward/action_rate: -0.1127
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.05s
                      Time elapsed: 01:12:43
                               ETA: 00:00:02

