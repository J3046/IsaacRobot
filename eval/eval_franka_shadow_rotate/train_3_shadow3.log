################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10727 steps/s (collection: 8.912s, learning 0.252s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0035
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.2461
                       Mean reward: 0.00
               Mean episode length: 21.31
    Episode_Reward/reaching_object: 0.0006
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0003
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.16s
                      Time elapsed: 00:00:09
                               ETA: 03:49:05

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14230 steps/s (collection: 6.737s, learning 0.171s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.3372
                       Mean reward: 0.00
               Mean episode length: 45.35
    Episode_Reward/reaching_object: 0.0017
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0006
          Episode_Reward/joint_vel: -0.0009
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.91s
                      Time elapsed: 00:00:16
                               ETA: 03:20:45

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14680 steps/s (collection: 6.546s, learning 0.150s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 31.3914
                       Mean reward: 0.00
               Mean episode length: 69.71
    Episode_Reward/reaching_object: 0.0028
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0011
          Episode_Reward/joint_vel: -0.0014
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.70s
                      Time elapsed: 00:00:22
                               ETA: 03:09:28

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14343 steps/s (collection: 6.676s, learning 0.178s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 31.3986
                       Mean reward: -0.00
               Mean episode length: 93.33
    Episode_Reward/reaching_object: 0.0037
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0020
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.85s
                      Time elapsed: 00:00:29
                               ETA: 03:04:45

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14572 steps/s (collection: 6.589s, learning 0.157s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 31.4295
                       Mean reward: 0.00
               Mean episode length: 117.98
    Episode_Reward/reaching_object: 0.0048
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0026
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.75s
                      Time elapsed: 00:00:36
                               ETA: 03:01:21

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14820 steps/s (collection: 6.484s, learning 0.149s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 31.4772
                       Mean reward: -0.00
               Mean episode length: 141.18
    Episode_Reward/reaching_object: 0.0055
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0024
          Episode_Reward/joint_vel: -0.0032
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.63s
                      Time elapsed: 00:00:43
                               ETA: 02:58:34

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 13750 steps/s (collection: 6.966s, learning 0.183s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.5160
                       Mean reward: -0.00
               Mean episode length: 165.30
    Episode_Reward/reaching_object: 0.0064
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0037
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 7.15s
                      Time elapsed: 00:00:50
                               ETA: 02:58:23

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14211 steps/s (collection: 6.773s, learning 0.144s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.4961
                       Mean reward: 0.00
               Mean episode length: 189.28
    Episode_Reward/reaching_object: 0.0074
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0032
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.92s
                      Time elapsed: 00:00:57
                               ETA: 02:57:30

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 16716 steps/s (collection: 5.712s, learning 0.169s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.4812
                       Mean reward: -0.00
               Mean episode length: 213.34
    Episode_Reward/reaching_object: 0.0079
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.88s
                      Time elapsed: 00:01:02
                               ETA: 02:53:55

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 56847 steps/s (collection: 1.582s, learning 0.148s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 31.4402
                       Mean reward: 0.00
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.0098
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.73s
                      Time elapsed: 00:01:04
                               ETA: 02:40:43

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 61596 steps/s (collection: 1.484s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 31.4318
                       Mean reward: 0.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0104
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.60s
                      Time elapsed: 00:01:06
                               ETA: 02:29:36

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 62598 steps/s (collection: 1.449s, learning 0.121s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 31.4031
                       Mean reward: 0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0114
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.57s
                      Time elapsed: 00:01:07
                               ETA: 02:20:18

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 63265 steps/s (collection: 1.464s, learning 0.090s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 31.3942
                       Mean reward: 0.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0125
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.55s
                      Time elapsed: 00:01:09
                               ETA: 02:12:23

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 62957 steps/s (collection: 1.469s, learning 0.093s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 31.3895
                       Mean reward: 0.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0148
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.56s
                      Time elapsed: 00:01:10
                               ETA: 02:05:36

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 62870 steps/s (collection: 1.461s, learning 0.103s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 31.3964
                       Mean reward: 0.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0172
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.56s
                      Time elapsed: 00:01:12
                               ETA: 01:59:44

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 61328 steps/s (collection: 1.455s, learning 0.148s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 31.4072
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0218
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.60s
                      Time elapsed: 00:01:14
                               ETA: 01:54:39

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 58875 steps/s (collection: 1.523s, learning 0.146s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 31.3984
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0286
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.67s
                      Time elapsed: 00:01:15
                               ETA: 01:50:16

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 58787 steps/s (collection: 1.545s, learning 0.127s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 31.3970
                       Mean reward: 0.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0366
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.67s
                      Time elapsed: 00:01:17
                               ETA: 01:46:22

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 61984 steps/s (collection: 1.489s, learning 0.097s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 31.4340
                       Mean reward: 0.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0477
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.59s
                      Time elapsed: 00:01:19
                               ETA: 01:42:46

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 63131 steps/s (collection: 1.463s, learning 0.095s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0450
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 31.4593
                       Mean reward: 0.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0618
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.56s
                      Time elapsed: 00:01:20
                               ETA: 01:39:29

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 59314 steps/s (collection: 1.555s, learning 0.102s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0167
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 31.5130
                       Mean reward: 0.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0823
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.66s
                      Time elapsed: 00:01:22
                               ETA: 01:36:37

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 58368 steps/s (collection: 1.579s, learning 0.105s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0020
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 31.5750
                       Mean reward: 0.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1145
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.68s
                      Time elapsed: 00:01:23
                               ETA: 01:34:03

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 57805 steps/s (collection: 1.604s, learning 0.096s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0021
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 31.6163
                       Mean reward: 0.66
               Mean episode length: 249.83
    Episode_Reward/reaching_object: 0.1332
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.70s
                      Time elapsed: 00:01:25
                               ETA: 01:31:44

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 57750 steps/s (collection: 1.603s, learning 0.099s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0031
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 31.6412
                       Mean reward: 0.87
               Mean episode length: 249.63
    Episode_Reward/reaching_object: 0.1744
    Episode_Reward/rotating_object: 0.0003
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.70s
                      Time elapsed: 00:01:27
                               ETA: 01:29:35

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 54389 steps/s (collection: 1.657s, learning 0.151s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0036
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 31.6761
                       Mean reward: 0.98
               Mean episode length: 248.70
    Episode_Reward/reaching_object: 0.2030
    Episode_Reward/rotating_object: 0.0020
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.81s
                      Time elapsed: 00:01:29
                               ETA: 01:27:44

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 53449 steps/s (collection: 1.727s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0044
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.7352
                       Mean reward: 1.15
               Mean episode length: 247.07
    Episode_Reward/reaching_object: 0.2378
    Episode_Reward/rotating_object: 0.0085
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.84s
                      Time elapsed: 00:01:31
                               ETA: 01:26:02

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 54240 steps/s (collection: 1.720s, learning 0.092s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0121
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 31.8222
                       Mean reward: 1.44
               Mean episode length: 244.84
    Episode_Reward/reaching_object: 0.2758
    Episode_Reward/rotating_object: 0.0143
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.81s
                      Time elapsed: 00:01:32
                               ETA: 01:24:26

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 53402 steps/s (collection: 1.730s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0056
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 31.9292
                       Mean reward: 1.44
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 0.2847
    Episode_Reward/rotating_object: 0.0101
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.84s
                      Time elapsed: 00:01:34
                               ETA: 01:22:59

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 53650 steps/s (collection: 1.735s, learning 0.098s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0053
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.9487
                       Mean reward: 1.56
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 0.3188
    Episode_Reward/rotating_object: 0.0188
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.83s
                      Time elapsed: 00:01:36
                               ETA: 01:21:37

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 52783 steps/s (collection: 1.750s, learning 0.113s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0065
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.9791
                       Mean reward: 1.80
               Mean episode length: 237.90
    Episode_Reward/reaching_object: 0.3180
    Episode_Reward/rotating_object: 0.0158
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 10.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.86s
                      Time elapsed: 00:01:38
                               ETA: 01:20:22

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 53465 steps/s (collection: 1.742s, learning 0.097s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0096
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 32.0572
                       Mean reward: 1.95
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 0.3366
    Episode_Reward/rotating_object: 0.0270
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 9.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.84s
                      Time elapsed: 00:01:40
                               ETA: 01:19:10

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 53236 steps/s (collection: 1.755s, learning 0.091s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0166
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.1142
                       Mean reward: 1.88
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.3515
    Episode_Reward/rotating_object: 0.0147
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 8.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.85s
                      Time elapsed: 00:01:42
                               ETA: 01:18:03

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 46746 steps/s (collection: 1.922s, learning 0.181s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0200
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 32.2029
                       Mean reward: 2.06
               Mean episode length: 234.16
    Episode_Reward/reaching_object: 0.3656
    Episode_Reward/rotating_object: 0.0311
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 9.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.10s
                      Time elapsed: 00:01:44
                               ETA: 01:17:12

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 50380 steps/s (collection: 1.808s, learning 0.144s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0224
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 32.3222
                       Mean reward: 2.72
               Mean episode length: 235.60
    Episode_Reward/reaching_object: 0.3834
    Episode_Reward/rotating_object: 0.0793
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 9.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.95s
                      Time elapsed: 00:01:46
                               ETA: 01:16:17

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 48574 steps/s (collection: 1.896s, learning 0.128s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0227
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 32.4078
                       Mean reward: 2.06
               Mean episode length: 235.02
    Episode_Reward/reaching_object: 0.3882
    Episode_Reward/rotating_object: 0.0582
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 9.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.02s
                      Time elapsed: 00:01:48
                               ETA: 01:15:28

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 51525 steps/s (collection: 1.764s, learning 0.144s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0304
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 32.5528
                       Mean reward: 2.30
               Mean episode length: 232.37
    Episode_Reward/reaching_object: 0.4036
    Episode_Reward/rotating_object: 0.0534
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 7.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.91s
                      Time elapsed: 00:01:50
                               ETA: 01:14:37

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 52696 steps/s (collection: 1.748s, learning 0.118s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0262
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 32.6716
                       Mean reward: 2.44
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 0.4134
    Episode_Reward/rotating_object: 0.1025
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 8.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.87s
                      Time elapsed: 00:01:51
                               ETA: 01:13:47

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 51735 steps/s (collection: 1.792s, learning 0.108s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0814
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.7201
                       Mean reward: 2.43
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 0.4229
    Episode_Reward/rotating_object: 0.0682
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 7.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.90s
                      Time elapsed: 00:01:53
                               ETA: 01:13:00

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 51452 steps/s (collection: 1.823s, learning 0.088s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.2224
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 32.9046
                       Mean reward: 2.35
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 0.4270
    Episode_Reward/rotating_object: 0.0556
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 8.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.91s
                      Time elapsed: 00:01:55
                               ETA: 01:12:17

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 49139 steps/s (collection: 1.894s, learning 0.106s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.5510
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.9720
                       Mean reward: 2.79
               Mean episode length: 230.40
    Episode_Reward/reaching_object: 0.4574
    Episode_Reward/rotating_object: 0.1394
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 8.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.00s
                      Time elapsed: 00:01:57
                               ETA: 01:11:38

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 50164 steps/s (collection: 1.845s, learning 0.115s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.9379
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.0843
                       Mean reward: 4.02
               Mean episode length: 230.51
    Episode_Reward/reaching_object: 0.4729
    Episode_Reward/rotating_object: 0.2415
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 9.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.96s
                      Time elapsed: 00:01:59
                               ETA: 01:11:00

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 48251 steps/s (collection: 1.901s, learning 0.136s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.7293
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.1621
                       Mean reward: 4.73
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 0.4908
    Episode_Reward/rotating_object: 0.2552
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 9.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.04s
                      Time elapsed: 00:02:01
                               ETA: 01:10:27

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 48692 steps/s (collection: 1.898s, learning 0.121s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5333
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.3021
                       Mean reward: 6.98
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 0.5123
    Episode_Reward/rotating_object: 0.6292
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 10.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.02s
                      Time elapsed: 00:02:03
                               ETA: 01:09:54

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 50994 steps/s (collection: 1.821s, learning 0.107s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.6881
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.4289
                       Mean reward: 5.72
               Mean episode length: 225.01
    Episode_Reward/reaching_object: 0.5186
    Episode_Reward/rotating_object: 0.3204
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.93s
                      Time elapsed: 00:02:05
                               ETA: 01:09:20

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 49183 steps/s (collection: 1.900s, learning 0.099s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.0085
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.6209
                       Mean reward: 4.00
               Mean episode length: 228.21
    Episode_Reward/reaching_object: 0.5414
    Episode_Reward/rotating_object: 0.2188
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.00s
                      Time elapsed: 00:02:07
                               ETA: 01:08:49

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 50706 steps/s (collection: 1.833s, learning 0.106s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.1108
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.7195
                       Mean reward: 5.46
               Mean episode length: 232.46
    Episode_Reward/reaching_object: 0.5652
    Episode_Reward/rotating_object: 0.5688
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.94s
                      Time elapsed: 00:02:09
                               ETA: 01:08:18

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 50250 steps/s (collection: 1.845s, learning 0.112s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.1508
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.7907
                       Mean reward: 4.70
               Mean episode length: 232.35
    Episode_Reward/reaching_object: 0.5755
    Episode_Reward/rotating_object: 0.4959
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.96s
                      Time elapsed: 00:02:11
                               ETA: 01:07:49

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 49416 steps/s (collection: 1.881s, learning 0.109s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.5672
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.9442
                       Mean reward: 5.99
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 0.5915
    Episode_Reward/rotating_object: 0.5697
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.99s
                      Time elapsed: 00:02:13
                               ETA: 01:07:21

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 49152 steps/s (collection: 1.903s, learning 0.097s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.3876
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 34.0233
                       Mean reward: 5.90
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 0.5779
    Episode_Reward/rotating_object: 0.9862
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.00s
                      Time elapsed: 00:02:15
                               ETA: 01:06:55

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 49964 steps/s (collection: 1.870s, learning 0.098s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.0313
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.0604
                       Mean reward: 12.15
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 0.5655
    Episode_Reward/rotating_object: 0.9921
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.97s
                      Time elapsed: 00:02:17
                               ETA: 01:06:29

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 50396 steps/s (collection: 1.834s, learning 0.117s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.2567
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 34.1220
                       Mean reward: 4.97
               Mean episode length: 216.02
    Episode_Reward/reaching_object: 0.5777
    Episode_Reward/rotating_object: 0.8290
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 11.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.95s
                      Time elapsed: 00:02:19
                               ETA: 01:06:04

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 47560 steps/s (collection: 1.944s, learning 0.123s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.5006
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.1581
                       Mean reward: 7.11
               Mean episode length: 221.44
    Episode_Reward/reaching_object: 0.5804
    Episode_Reward/rotating_object: 0.7059
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.07s
                      Time elapsed: 00:02:21
                               ETA: 01:05:43

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 50112 steps/s (collection: 1.861s, learning 0.101s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.2687
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 34.2503
                       Mean reward: 6.91
               Mean episode length: 221.92
    Episode_Reward/reaching_object: 0.5749
    Episode_Reward/rotating_object: 1.2512
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.96s
                      Time elapsed: 00:02:23
                               ETA: 01:05:19

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 50108 steps/s (collection: 1.850s, learning 0.112s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.0524
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 34.3297
                       Mean reward: 5.43
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 0.6057
    Episode_Reward/rotating_object: 0.9654
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.96s
                      Time elapsed: 00:02:25
                               ETA: 01:04:57

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 51184 steps/s (collection: 1.829s, learning 0.092s)
             Mean action noise std: 1.16
          Mean value_function loss: 2.3147
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.4867
                       Mean reward: 9.99
               Mean episode length: 234.89
    Episode_Reward/reaching_object: 0.6421
    Episode_Reward/rotating_object: 0.9080
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 1.92s
                      Time elapsed: 00:02:27
                               ETA: 01:04:34

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 50848 steps/s (collection: 1.842s, learning 0.091s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.2841
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.6066
                       Mean reward: 10.77
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 0.6258
    Episode_Reward/rotating_object: 1.7880
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 1.93s
                      Time elapsed: 00:02:29
                               ETA: 01:04:12

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 50459 steps/s (collection: 1.820s, learning 0.128s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.1040
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.6998
                       Mean reward: 9.95
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 1.7352
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 1.95s
                      Time elapsed: 00:02:31
                               ETA: 01:03:51

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 49363 steps/s (collection: 1.832s, learning 0.160s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.8617
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.7454
                       Mean reward: 8.89
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 0.6415
    Episode_Reward/rotating_object: 1.5111
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.99s
                      Time elapsed: 00:02:33
                               ETA: 01:03:32

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 51239 steps/s (collection: 1.813s, learning 0.106s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.9812
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.8010
                       Mean reward: 11.65
               Mean episode length: 228.93
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 1.2912
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.92s
                      Time elapsed: 00:02:35
                               ETA: 01:03:11

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 50623 steps/s (collection: 1.802s, learning 0.140s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.3210
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.8667
                       Mean reward: 9.04
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 0.6473
    Episode_Reward/rotating_object: 1.7248
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.94s
                      Time elapsed: 00:02:37
                               ETA: 01:02:52

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 51115 steps/s (collection: 1.832s, learning 0.091s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.9513
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 34.9230
                       Mean reward: 10.94
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 0.6538
    Episode_Reward/rotating_object: 1.3143
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.92s
                      Time elapsed: 00:02:39
                               ETA: 01:02:33

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 51279 steps/s (collection: 1.808s, learning 0.109s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.8731
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 34.9648
                       Mean reward: 10.97
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 0.6427
    Episode_Reward/rotating_object: 1.9423
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.92s
                      Time elapsed: 00:02:40
                               ETA: 01:02:15

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 50570 steps/s (collection: 1.832s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.8556
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 35.0306
                       Mean reward: 13.81
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 0.6678
    Episode_Reward/rotating_object: 1.8120
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.94s
                      Time elapsed: 00:02:42
                               ETA: 01:01:57

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 51224 steps/s (collection: 1.817s, learning 0.102s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.6539
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.0765
                       Mean reward: 11.39
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 1.8775
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.92s
                      Time elapsed: 00:02:44
                               ETA: 01:01:40

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 51604 steps/s (collection: 1.817s, learning 0.088s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.0980
               Mean surrogate loss: 0.0065
                 Mean entropy loss: 35.1236
                       Mean reward: 15.07
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 2.0235
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.90s
                      Time elapsed: 00:02:46
                               ETA: 01:01:22

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 51360 steps/s (collection: 1.818s, learning 0.096s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.3115
               Mean surrogate loss: 0.0062
                 Mean entropy loss: 35.1359
                       Mean reward: 18.31
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 0.6735
    Episode_Reward/rotating_object: 2.7635
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.91s
                      Time elapsed: 00:02:48
                               ETA: 01:01:05

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 50786 steps/s (collection: 1.843s, learning 0.093s)
             Mean action noise std: 1.20
          Mean value_function loss: 3.3520
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 35.1459
                       Mean reward: 15.91
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 0.6452
    Episode_Reward/rotating_object: 2.0866
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.94s
                      Time elapsed: 00:02:50
                               ETA: 01:00:50

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 50241 steps/s (collection: 1.869s, learning 0.088s)
             Mean action noise std: 1.20
          Mean value_function loss: 4.3832
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 35.1977
                       Mean reward: 14.86
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 0.6897
    Episode_Reward/rotating_object: 2.5266
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.96s
                      Time elapsed: 00:02:52
                               ETA: 01:00:35

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 50461 steps/s (collection: 1.848s, learning 0.100s)
             Mean action noise std: 1.20
          Mean value_function loss: 5.6202
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 35.2546
                       Mean reward: 13.84
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 0.6642
    Episode_Reward/rotating_object: 2.3238
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.95s
                      Time elapsed: 00:02:54
                               ETA: 01:00:20

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 50045 steps/s (collection: 1.858s, learning 0.107s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.7809
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 35.2961
                       Mean reward: 18.71
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 0.6897
    Episode_Reward/rotating_object: 3.2403
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.96s
                      Time elapsed: 00:02:56
                               ETA: 01:00:06

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 50516 steps/s (collection: 1.848s, learning 0.098s)
             Mean action noise std: 1.21
          Mean value_function loss: 4.4285
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.3182
                       Mean reward: 24.17
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 0.6639
    Episode_Reward/rotating_object: 3.0606
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.95s
                      Time elapsed: 00:02:58
                               ETA: 00:59:52

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 49084 steps/s (collection: 1.884s, learning 0.119s)
             Mean action noise std: 1.21
          Mean value_function loss: 5.1650
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.4047
                       Mean reward: 24.60
               Mean episode length: 238.45
    Episode_Reward/reaching_object: 0.6581
    Episode_Reward/rotating_object: 2.8577
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.00s
                      Time elapsed: 00:03:00
                               ETA: 00:59:39

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 48096 steps/s (collection: 1.941s, learning 0.103s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.6628
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 35.5046
                       Mean reward: 16.60
               Mean episode length: 225.97
    Episode_Reward/reaching_object: 0.6457
    Episode_Reward/rotating_object: 2.5635
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.04s
                      Time elapsed: 00:03:02
                               ETA: 00:59:28

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 50552 steps/s (collection: 1.817s, learning 0.128s)
             Mean action noise std: 1.22
          Mean value_function loss: 4.9851
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 35.5522
                       Mean reward: 23.64
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 0.6620
    Episode_Reward/rotating_object: 3.1068
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0116
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.94s
                      Time elapsed: 00:03:04
                               ETA: 00:59:14

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 50569 steps/s (collection: 1.823s, learning 0.121s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.2629
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.5824
                       Mean reward: 19.96
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 0.6467
    Episode_Reward/rotating_object: 2.9595
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.94s
                      Time elapsed: 00:03:06
                               ETA: 00:59:02

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 49103 steps/s (collection: 1.873s, learning 0.129s)
             Mean action noise std: 1.22
          Mean value_function loss: 5.7035
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 35.6433
                       Mean reward: 14.83
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 0.6347
    Episode_Reward/rotating_object: 3.1622
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0117
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.00s
                      Time elapsed: 00:03:08
                               ETA: 00:58:50

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 49962 steps/s (collection: 1.843s, learning 0.125s)
             Mean action noise std: 1.23
          Mean value_function loss: 4.9821
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.6677
                       Mean reward: 19.76
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 0.6540
    Episode_Reward/rotating_object: 3.0793
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.97s
                      Time elapsed: 00:03:10
                               ETA: 00:58:38

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 49785 steps/s (collection: 1.853s, learning 0.121s)
             Mean action noise std: 1.23
          Mean value_function loss: 5.1849
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.7329
                       Mean reward: 13.97
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 0.6487
    Episode_Reward/rotating_object: 2.8107
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.97s
                      Time elapsed: 00:03:12
                               ETA: 00:58:27

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 50072 steps/s (collection: 1.827s, learning 0.137s)
             Mean action noise std: 1.23
          Mean value_function loss: 5.3407
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.7918
                       Mean reward: 28.53
               Mean episode length: 232.08
    Episode_Reward/reaching_object: 0.6484
    Episode_Reward/rotating_object: 4.1497
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0120
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.96s
                      Time elapsed: 00:03:14
                               ETA: 00:58:15

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 50793 steps/s (collection: 1.841s, learning 0.094s)
             Mean action noise std: 1.24
          Mean value_function loss: 7.8649
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.8603
                       Mean reward: 24.20
               Mean episode length: 233.62
    Episode_Reward/reaching_object: 0.6659
    Episode_Reward/rotating_object: 3.3905
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.94s
                      Time elapsed: 00:03:16
                               ETA: 00:58:03

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 49413 steps/s (collection: 1.877s, learning 0.112s)
             Mean action noise std: 1.24
          Mean value_function loss: 6.6261
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 35.9188
                       Mean reward: 20.04
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.6755
    Episode_Reward/rotating_object: 3.5112
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0128
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.99s
                      Time elapsed: 00:03:18
                               ETA: 00:57:53

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 49487 steps/s (collection: 1.864s, learning 0.123s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.6138
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 35.9932
                       Mean reward: 17.12
               Mean episode length: 242.75
    Episode_Reward/reaching_object: 0.6951
    Episode_Reward/rotating_object: 3.0511
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.99s
                      Time elapsed: 00:03:20
                               ETA: 00:57:42

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 50275 steps/s (collection: 1.859s, learning 0.097s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.5171
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 36.0455
                       Mean reward: 17.55
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 0.6623
    Episode_Reward/rotating_object: 2.6388
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0131
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.96s
                      Time elapsed: 00:03:22
                               ETA: 00:57:32

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 49864 steps/s (collection: 1.859s, learning 0.113s)
             Mean action noise std: 1.25
          Mean value_function loss: 7.4501
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 36.1017
                       Mean reward: 17.90
               Mean episode length: 235.54
    Episode_Reward/reaching_object: 0.6590
    Episode_Reward/rotating_object: 3.2169
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.97s
                      Time elapsed: 00:03:24
                               ETA: 00:57:21

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 49872 steps/s (collection: 1.853s, learning 0.118s)
             Mean action noise std: 1.25
          Mean value_function loss: 6.7901
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.1212
                       Mean reward: 23.95
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 0.6700
    Episode_Reward/rotating_object: 3.7588
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.97s
                      Time elapsed: 00:03:26
                               ETA: 00:57:11

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 50244 steps/s (collection: 1.842s, learning 0.114s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.0448
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.1773
                       Mean reward: 16.37
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 0.6677
    Episode_Reward/rotating_object: 3.1779
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.96s
                      Time elapsed: 00:03:27
                               ETA: 00:57:01

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 49753 steps/s (collection: 1.863s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.8690
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.2534
                       Mean reward: 14.09
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 0.6546
    Episode_Reward/rotating_object: 2.2740
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.98s
                      Time elapsed: 00:03:29
                               ETA: 00:56:52

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 49637 steps/s (collection: 1.873s, learning 0.108s)
             Mean action noise std: 1.26
          Mean value_function loss: 6.6162
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 36.3124
                       Mean reward: 28.48
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 0.6760
    Episode_Reward/rotating_object: 4.1301
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0133
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.98s
                      Time elapsed: 00:03:31
                               ETA: 00:56:42

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 46717 steps/s (collection: 2.003s, learning 0.102s)
             Mean action noise std: 1.27
          Mean value_function loss: 7.4822
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 36.3841
                       Mean reward: 20.67
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 2.8258
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.10s
                      Time elapsed: 00:03:34
                               ETA: 00:56:35

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 49997 steps/s (collection: 1.857s, learning 0.109s)
             Mean action noise std: 1.27
          Mean value_function loss: 8.9307
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 36.4430
                       Mean reward: 24.57
               Mean episode length: 235.51
    Episode_Reward/reaching_object: 0.6674
    Episode_Reward/rotating_object: 3.4784
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.97s
                      Time elapsed: 00:03:35
                               ETA: 00:56:26

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 49569 steps/s (collection: 1.864s, learning 0.119s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.0165
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 36.5121
                       Mean reward: 19.87
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 0.6318
    Episode_Reward/rotating_object: 3.3623
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.98s
                      Time elapsed: 00:03:37
                               ETA: 00:56:17

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 48813 steps/s (collection: 1.895s, learning 0.119s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.3422
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 36.6093
                       Mean reward: 19.22
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 0.6320
    Episode_Reward/rotating_object: 3.7042
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.01s
                      Time elapsed: 00:03:39
                               ETA: 00:56:09

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 49960 steps/s (collection: 1.855s, learning 0.113s)
             Mean action noise std: 1.28
          Mean value_function loss: 7.7259
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.6533
                       Mean reward: 18.68
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 0.6303
    Episode_Reward/rotating_object: 3.2556
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.97s
                      Time elapsed: 00:03:41
                               ETA: 00:56:00

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 50216 steps/s (collection: 1.860s, learning 0.098s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.5701
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 36.6757
                       Mean reward: 17.03
               Mean episode length: 240.13
    Episode_Reward/reaching_object: 0.6408
    Episode_Reward/rotating_object: 3.5053
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.96s
                      Time elapsed: 00:03:43
                               ETA: 00:55:51

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 49443 steps/s (collection: 1.889s, learning 0.099s)
             Mean action noise std: 1.29
          Mean value_function loss: 8.1327
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.7222
                       Mean reward: 22.11
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 0.6422
    Episode_Reward/rotating_object: 3.2002
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.99s
                      Time elapsed: 00:03:45
                               ETA: 00:55:43

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 50489 steps/s (collection: 1.850s, learning 0.097s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.0518
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 36.7783
                       Mean reward: 21.29
               Mean episode length: 237.96
    Episode_Reward/reaching_object: 0.6154
    Episode_Reward/rotating_object: 3.5398
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.95s
                      Time elapsed: 00:03:47
                               ETA: 00:55:34

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 50422 steps/s (collection: 1.855s, learning 0.094s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.9814
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 36.8437
                       Mean reward: 23.22
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 0.6110
    Episode_Reward/rotating_object: 3.8980
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.95s
                      Time elapsed: 00:03:49
                               ETA: 00:55:26

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 50347 steps/s (collection: 1.845s, learning 0.107s)
             Mean action noise std: 1.30
          Mean value_function loss: 8.8290
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 36.8873
                       Mean reward: 18.02
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 0.5953
    Episode_Reward/rotating_object: 3.9616
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.95s
                      Time elapsed: 00:03:51
                               ETA: 00:55:17

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 49740 steps/s (collection: 1.881s, learning 0.095s)
             Mean action noise std: 1.30
          Mean value_function loss: 11.1208
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.9378
                       Mean reward: 35.31
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 0.6031
    Episode_Reward/rotating_object: 4.4418
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.98s
                      Time elapsed: 00:03:53
                               ETA: 00:55:09

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 49491 steps/s (collection: 1.862s, learning 0.124s)
             Mean action noise std: 1.30
          Mean value_function loss: 8.7901
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 36.9689
                       Mean reward: 19.69
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.5913
    Episode_Reward/rotating_object: 4.3910
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.99s
                      Time elapsed: 00:03:55
                               ETA: 00:55:02

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 48791 steps/s (collection: 1.920s, learning 0.095s)
             Mean action noise std: 1.30
          Mean value_function loss: 8.5450
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 37.0085
                       Mean reward: 26.01
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 0.5998
    Episode_Reward/rotating_object: 4.1887
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.01s
                      Time elapsed: 00:03:57
                               ETA: 00:54:55

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 48487 steps/s (collection: 1.927s, learning 0.101s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.3483
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.0548
                       Mean reward: 18.45
               Mean episode length: 237.12
    Episode_Reward/reaching_object: 0.6036
    Episode_Reward/rotating_object: 4.2626
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.03s
                      Time elapsed: 00:03:59
                               ETA: 00:54:48

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 48880 steps/s (collection: 1.902s, learning 0.110s)
             Mean action noise std: 1.31
          Mean value_function loss: 8.4790
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 37.0975
                       Mean reward: 22.35
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 0.5776
    Episode_Reward/rotating_object: 4.4208
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.01s
                      Time elapsed: 00:04:01
                               ETA: 00:54:41

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 50827 steps/s (collection: 1.823s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 8.3497
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 37.1466
                       Mean reward: 28.72
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 0.6022
    Episode_Reward/rotating_object: 4.5206
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.93s
                      Time elapsed: 00:04:03
                               ETA: 00:54:33

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 50807 steps/s (collection: 1.826s, learning 0.109s)
             Mean action noise std: 1.32
          Mean value_function loss: 7.8219
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.2283
                       Mean reward: 24.04
               Mean episode length: 247.08
    Episode_Reward/reaching_object: 0.6157
    Episode_Reward/rotating_object: 4.2530
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.93s
                      Time elapsed: 00:04:05
                               ETA: 00:54:25

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 50839 steps/s (collection: 1.818s, learning 0.116s)
             Mean action noise std: 1.32
          Mean value_function loss: 7.8697
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 37.2827
                       Mean reward: 32.11
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 0.6251
    Episode_Reward/rotating_object: 5.1335
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.93s
                      Time elapsed: 00:04:07
                               ETA: 00:54:18

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 50995 steps/s (collection: 1.807s, learning 0.120s)
             Mean action noise std: 1.33
          Mean value_function loss: 8.8896
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 37.3716
                       Mean reward: 14.62
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 0.5961
    Episode_Reward/rotating_object: 3.2083
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.93s
                      Time elapsed: 00:04:09
                               ETA: 00:54:10

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 49301 steps/s (collection: 1.849s, learning 0.145s)
             Mean action noise std: 1.33
          Mean value_function loss: 10.1353
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.4840
                       Mean reward: 27.84
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 0.6048
    Episode_Reward/rotating_object: 4.1728
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.99s
                      Time elapsed: 00:04:11
                               ETA: 00:54:03

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 50726 steps/s (collection: 1.840s, learning 0.098s)
             Mean action noise std: 1.34
          Mean value_function loss: 9.3505
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 37.5592
                       Mean reward: 21.41
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.6173
    Episode_Reward/rotating_object: 3.9666
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.94s
                      Time elapsed: 00:04:13
                               ETA: 00:53:56

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 51502 steps/s (collection: 1.796s, learning 0.113s)
             Mean action noise std: 1.34
          Mean value_function loss: 10.4027
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 37.6159
                       Mean reward: 34.28
               Mean episode length: 242.40
    Episode_Reward/reaching_object: 0.6311
    Episode_Reward/rotating_object: 3.6688
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.91s
                      Time elapsed: 00:04:15
                               ETA: 00:53:48

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 51027 steps/s (collection: 1.834s, learning 0.093s)
             Mean action noise std: 1.35
          Mean value_function loss: 10.1718
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 37.7044
                       Mean reward: 29.28
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 0.6112
    Episode_Reward/rotating_object: 4.1065
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.93s
                      Time elapsed: 00:04:17
                               ETA: 00:53:41

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 51861 steps/s (collection: 1.798s, learning 0.098s)
             Mean action noise std: 1.35
          Mean value_function loss: 10.6202
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.7671
                       Mean reward: 22.85
               Mean episode length: 242.99
    Episode_Reward/reaching_object: 0.6362
    Episode_Reward/rotating_object: 4.5159
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.90s
                      Time elapsed: 00:04:19
                               ETA: 00:53:34

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 50523 steps/s (collection: 1.843s, learning 0.103s)
             Mean action noise std: 1.35
          Mean value_function loss: 10.9458
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.8161
                       Mean reward: 15.89
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.6156
    Episode_Reward/rotating_object: 3.4941
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.95s
                      Time elapsed: 00:04:21
                               ETA: 00:53:27

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 51070 steps/s (collection: 1.817s, learning 0.108s)
             Mean action noise std: 1.36
          Mean value_function loss: 10.2991
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 37.8541
                       Mean reward: 26.08
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 0.6421
    Episode_Reward/rotating_object: 4.6676
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.92s
                      Time elapsed: 00:04:23
                               ETA: 00:53:20

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 48733 steps/s (collection: 1.898s, learning 0.120s)
             Mean action noise std: 1.36
          Mean value_function loss: 10.0763
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.8916
                       Mean reward: 27.98
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 0.6243
    Episode_Reward/rotating_object: 4.8186
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.02s
                      Time elapsed: 00:04:25
                               ETA: 00:53:14

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 50407 steps/s (collection: 1.841s, learning 0.110s)
             Mean action noise std: 1.36
          Mean value_function loss: 13.3251
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 37.9308
                       Mean reward: 19.38
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 0.6079
    Episode_Reward/rotating_object: 3.6439
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.95s
                      Time elapsed: 00:04:26
                               ETA: 00:53:07

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 50951 steps/s (collection: 1.821s, learning 0.109s)
             Mean action noise std: 1.36
          Mean value_function loss: 14.4769
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 37.9811
                       Mean reward: 25.46
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 0.6289
    Episode_Reward/rotating_object: 4.3277
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.93s
                      Time elapsed: 00:04:28
                               ETA: 00:53:01

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 50319 steps/s (collection: 1.832s, learning 0.121s)
             Mean action noise std: 1.37
          Mean value_function loss: 12.9200
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 38.0201
                       Mean reward: 28.21
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 0.6354
    Episode_Reward/rotating_object: 4.8689
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.95s
                      Time elapsed: 00:04:30
                               ETA: 00:52:54

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 50141 steps/s (collection: 1.842s, learning 0.118s)
             Mean action noise std: 1.37
          Mean value_function loss: 12.8839
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 38.0553
                       Mean reward: 25.34
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 0.6055
    Episode_Reward/rotating_object: 4.2040
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.96s
                      Time elapsed: 00:04:32
                               ETA: 00:52:48

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 50231 steps/s (collection: 1.866s, learning 0.091s)
             Mean action noise std: 1.37
          Mean value_function loss: 12.4383
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 38.1115
                       Mean reward: 41.33
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 0.6244
    Episode_Reward/rotating_object: 5.1876
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.96s
                      Time elapsed: 00:04:34
                               ETA: 00:52:42

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 50023 steps/s (collection: 1.847s, learning 0.118s)
             Mean action noise std: 1.38
          Mean value_function loss: 15.2388
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 38.1755
                       Mean reward: 37.63
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 0.6179
    Episode_Reward/rotating_object: 5.7764
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.97s
                      Time elapsed: 00:04:36
                               ETA: 00:52:36

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 50778 steps/s (collection: 1.846s, learning 0.090s)
             Mean action noise std: 1.38
          Mean value_function loss: 13.7303
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 38.2332
                       Mean reward: 28.85
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 0.6050
    Episode_Reward/rotating_object: 4.0927
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.94s
                      Time elapsed: 00:04:38
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 49449 steps/s (collection: 1.858s, learning 0.130s)
             Mean action noise std: 1.38
          Mean value_function loss: 12.5088
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.2744
                       Mean reward: 25.25
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 0.5993
    Episode_Reward/rotating_object: 3.6682
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.99s
                      Time elapsed: 00:04:40
                               ETA: 00:52:24

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 49485 steps/s (collection: 1.856s, learning 0.130s)
             Mean action noise std: 1.39
          Mean value_function loss: 12.5669
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 38.3373
                       Mean reward: 29.31
               Mean episode length: 231.00
    Episode_Reward/reaching_object: 0.5890
    Episode_Reward/rotating_object: 5.1908
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.99s
                      Time elapsed: 00:04:42
                               ETA: 00:52:19

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 49539 steps/s (collection: 1.868s, learning 0.116s)
             Mean action noise std: 1.39
          Mean value_function loss: 14.8836
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 38.3981
                       Mean reward: 45.71
               Mean episode length: 236.77
    Episode_Reward/reaching_object: 0.6267
    Episode_Reward/rotating_object: 5.6575
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.98s
                      Time elapsed: 00:04:44
                               ETA: 00:52:13

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 46788 steps/s (collection: 1.914s, learning 0.187s)
             Mean action noise std: 1.39
          Mean value_function loss: 15.0343
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 38.4689
                       Mean reward: 53.97
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.6317
    Episode_Reward/rotating_object: 7.1646
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.10s
                      Time elapsed: 00:04:46
                               ETA: 00:52:09

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 49693 steps/s (collection: 1.860s, learning 0.118s)
             Mean action noise std: 1.40
          Mean value_function loss: 12.7616
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.5214
                       Mean reward: 31.06
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 0.6417
    Episode_Reward/rotating_object: 5.5513
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.98s
                      Time elapsed: 00:04:48
                               ETA: 00:52:03

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 51255 steps/s (collection: 1.816s, learning 0.102s)
             Mean action noise std: 1.40
          Mean value_function loss: 12.2835
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.5938
                       Mean reward: 21.12
               Mean episode length: 223.74
    Episode_Reward/reaching_object: 0.5996
    Episode_Reward/rotating_object: 4.7848
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.92s
                      Time elapsed: 00:04:50
                               ETA: 00:51:57

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 50873 steps/s (collection: 1.804s, learning 0.129s)
             Mean action noise std: 1.41
          Mean value_function loss: 13.1000
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 38.6337
                       Mean reward: 30.67
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 0.6266
    Episode_Reward/rotating_object: 5.8152
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.93s
                      Time elapsed: 00:04:52
                               ETA: 00:51:51

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 51709 steps/s (collection: 1.787s, learning 0.114s)
             Mean action noise std: 1.41
          Mean value_function loss: 15.1483
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.6859
                       Mean reward: 41.61
               Mean episode length: 233.82
    Episode_Reward/reaching_object: 0.6252
    Episode_Reward/rotating_object: 5.6426
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.90s
                      Time elapsed: 00:04:54
                               ETA: 00:51:45

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 51806 steps/s (collection: 1.794s, learning 0.103s)
             Mean action noise std: 1.41
          Mean value_function loss: 13.3401
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 38.7333
                       Mean reward: 31.28
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 0.6069
    Episode_Reward/rotating_object: 5.0782
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.90s
                      Time elapsed: 00:04:56
                               ETA: 00:51:39

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 51671 steps/s (collection: 1.812s, learning 0.090s)
             Mean action noise std: 1.41
          Mean value_function loss: 11.9041
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 38.7866
                       Mean reward: 30.02
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 0.6212
    Episode_Reward/rotating_object: 5.7527
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.90s
                      Time elapsed: 00:04:58
                               ETA: 00:51:33

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 47978 steps/s (collection: 1.908s, learning 0.141s)
             Mean action noise std: 1.42
          Mean value_function loss: 15.2645
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.8272
                       Mean reward: 29.89
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 0.6289
    Episode_Reward/rotating_object: 6.2866
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.05s
                      Time elapsed: 00:05:00
                               ETA: 00:51:29

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 48577 steps/s (collection: 1.910s, learning 0.114s)
             Mean action noise std: 1.42
          Mean value_function loss: 14.5300
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 38.8621
                       Mean reward: 36.88
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 0.6243
    Episode_Reward/rotating_object: 5.6130
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.02s
                      Time elapsed: 00:05:02
                               ETA: 00:51:24

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 50408 steps/s (collection: 1.851s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 12.9686
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 38.8774
                       Mean reward: 32.84
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 0.6021
    Episode_Reward/rotating_object: 5.4060
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.95s
                      Time elapsed: 00:05:04
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 49107 steps/s (collection: 1.892s, learning 0.110s)
             Mean action noise std: 1.42
          Mean value_function loss: 14.3982
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.9057
                       Mean reward: 35.48
               Mean episode length: 226.15
    Episode_Reward/reaching_object: 0.6117
    Episode_Reward/rotating_object: 5.9139
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.00s
                      Time elapsed: 00:05:06
                               ETA: 00:51:14

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 43147 steps/s (collection: 2.115s, learning 0.163s)
             Mean action noise std: 1.43
          Mean value_function loss: 12.4960
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 38.9520
                       Mean reward: 36.41
               Mean episode length: 230.00
    Episode_Reward/reaching_object: 0.5921
    Episode_Reward/rotating_object: 6.4378
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.28s
                      Time elapsed: 00:05:08
                               ETA: 00:51:12

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 43025 steps/s (collection: 2.163s, learning 0.122s)
             Mean action noise std: 1.43
          Mean value_function loss: 13.6483
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.0136
                       Mean reward: 33.80
               Mean episode length: 226.70
    Episode_Reward/reaching_object: 0.6147
    Episode_Reward/rotating_object: 6.0962
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.28s
                      Time elapsed: 00:05:10
                               ETA: 00:51:10

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 49869 steps/s (collection: 1.870s, learning 0.101s)
             Mean action noise std: 1.43
          Mean value_function loss: 15.7600
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.0494
                       Mean reward: 29.48
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 0.6237
    Episode_Reward/rotating_object: 5.8617
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.97s
                      Time elapsed: 00:05:12
                               ETA: 00:51:05

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 50429 steps/s (collection: 1.827s, learning 0.122s)
             Mean action noise std: 1.43
          Mean value_function loss: 16.6859
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.0887
                       Mean reward: 26.31
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 0.6104
    Episode_Reward/rotating_object: 6.6020
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.95s
                      Time elapsed: 00:05:14
                               ETA: 00:51:00

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 49365 steps/s (collection: 1.879s, learning 0.112s)
             Mean action noise std: 1.44
          Mean value_function loss: 14.9569
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 39.1393
                       Mean reward: 29.40
               Mean episode length: 221.57
    Episode_Reward/reaching_object: 0.6309
    Episode_Reward/rotating_object: 6.9585
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.99s
                      Time elapsed: 00:05:16
                               ETA: 00:50:55

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 47507 steps/s (collection: 1.918s, learning 0.151s)
             Mean action noise std: 1.44
          Mean value_function loss: 14.0723
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 39.2000
                       Mean reward: 33.60
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 0.6250
    Episode_Reward/rotating_object: 5.8810
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.07s
                      Time elapsed: 00:05:18
                               ETA: 00:50:51

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 49311 steps/s (collection: 1.880s, learning 0.114s)
             Mean action noise std: 1.45
          Mean value_function loss: 16.9292
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 39.2539
                       Mean reward: 32.80
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 0.6321
    Episode_Reward/rotating_object: 6.6593
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.99s
                      Time elapsed: 00:05:20
                               ETA: 00:50:46

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 47920 steps/s (collection: 1.897s, learning 0.154s)
             Mean action noise std: 1.45
          Mean value_function loss: 18.2560
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 39.3088
                       Mean reward: 36.74
               Mean episode length: 227.31
    Episode_Reward/reaching_object: 0.6454
    Episode_Reward/rotating_object: 5.7739
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.05s
                      Time elapsed: 00:05:22
                               ETA: 00:50:42

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 50395 steps/s (collection: 1.850s, learning 0.101s)
             Mean action noise std: 1.45
          Mean value_function loss: 18.4824
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.3676
                       Mean reward: 39.82
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 0.6338
    Episode_Reward/rotating_object: 6.4764
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.95s
                      Time elapsed: 00:05:24
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 49837 steps/s (collection: 1.861s, learning 0.112s)
             Mean action noise std: 1.46
          Mean value_function loss: 18.7488
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 39.4329
                       Mean reward: 42.82
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 0.6468
    Episode_Reward/rotating_object: 6.9096
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.97s
                      Time elapsed: 00:05:26
                               ETA: 00:50:33

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 48991 steps/s (collection: 1.870s, learning 0.137s)
             Mean action noise std: 1.46
          Mean value_function loss: 17.3693
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 39.4818
                       Mean reward: 52.92
               Mean episode length: 223.36
    Episode_Reward/reaching_object: 0.6499
    Episode_Reward/rotating_object: 7.5510
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.01s
                      Time elapsed: 00:05:28
                               ETA: 00:50:28

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 50534 steps/s (collection: 1.828s, learning 0.118s)
             Mean action noise std: 1.46
          Mean value_function loss: 14.8225
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 39.5155
                       Mean reward: 46.87
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 6.8007
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.95s
                      Time elapsed: 00:05:30
                               ETA: 00:50:23

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 49001 steps/s (collection: 1.908s, learning 0.099s)
             Mean action noise std: 1.47
          Mean value_function loss: 16.3498
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 39.5564
                       Mean reward: 52.74
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 0.6469
    Episode_Reward/rotating_object: 8.4646
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.01s
                      Time elapsed: 00:05:32
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 49357 steps/s (collection: 1.801s, learning 0.191s)
             Mean action noise std: 1.47
          Mean value_function loss: 14.7537
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 39.6031
                       Mean reward: 31.32
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 0.6627
    Episode_Reward/rotating_object: 6.5202
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.99s
                      Time elapsed: 00:05:34
                               ETA: 00:50:15

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 51751 steps/s (collection: 1.786s, learning 0.114s)
             Mean action noise std: 1.47
          Mean value_function loss: 13.3256
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 39.6631
                       Mean reward: 36.51
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 0.6312
    Episode_Reward/rotating_object: 7.2619
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.90s
                      Time elapsed: 00:05:36
                               ETA: 00:50:10

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 49575 steps/s (collection: 1.883s, learning 0.100s)
             Mean action noise std: 1.48
          Mean value_function loss: 13.8024
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 39.7082
                       Mean reward: 37.12
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 0.6282
    Episode_Reward/rotating_object: 6.7487
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.98s
                      Time elapsed: 00:05:38
                               ETA: 00:50:05

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 50375 steps/s (collection: 1.839s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 16.3174
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 39.7655
                       Mean reward: 40.55
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 0.6218
    Episode_Reward/rotating_object: 6.0410
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.95s
                      Time elapsed: 00:05:40
                               ETA: 00:50:00

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 50705 steps/s (collection: 1.847s, learning 0.092s)
             Mean action noise std: 1.48
          Mean value_function loss: 15.6584
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 39.8144
                       Mean reward: 29.21
               Mean episode length: 225.91
    Episode_Reward/reaching_object: 0.6139
    Episode_Reward/rotating_object: 8.0717
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.94s
                      Time elapsed: 00:05:42
                               ETA: 00:49:56

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 50636 steps/s (collection: 1.833s, learning 0.109s)
             Mean action noise std: 1.48
          Mean value_function loss: 15.8649
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 39.8409
                       Mean reward: 34.18
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 0.6169
    Episode_Reward/rotating_object: 7.5618
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.94s
                      Time elapsed: 00:05:44
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 50044 steps/s (collection: 1.844s, learning 0.121s)
             Mean action noise std: 1.49
          Mean value_function loss: 17.4311
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 39.8937
                       Mean reward: 45.90
               Mean episode length: 220.58
    Episode_Reward/reaching_object: 0.6210
    Episode_Reward/rotating_object: 6.7846
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.96s
                      Time elapsed: 00:05:46
                               ETA: 00:49:47

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 50299 steps/s (collection: 1.842s, learning 0.112s)
             Mean action noise std: 1.49
          Mean value_function loss: 16.5320
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 39.9511
                       Mean reward: 36.34
               Mean episode length: 226.95
    Episode_Reward/reaching_object: 0.6226
    Episode_Reward/rotating_object: 6.4135
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.95s
                      Time elapsed: 00:05:48
                               ETA: 00:49:42

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 50797 steps/s (collection: 1.821s, learning 0.114s)
             Mean action noise std: 1.50
          Mean value_function loss: 17.2653
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 39.9990
                       Mean reward: 35.86
               Mean episode length: 231.11
    Episode_Reward/reaching_object: 0.6332
    Episode_Reward/rotating_object: 6.6492
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.94s
                      Time elapsed: 00:05:50
                               ETA: 00:49:37

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 51518 steps/s (collection: 1.813s, learning 0.095s)
             Mean action noise std: 1.50
          Mean value_function loss: 16.4450
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 40.0597
                       Mean reward: 39.76
               Mean episode length: 225.59
    Episode_Reward/reaching_object: 0.6251
    Episode_Reward/rotating_object: 7.2987
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.91s
                      Time elapsed: 00:05:52
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 51767 steps/s (collection: 1.801s, learning 0.098s)
             Mean action noise std: 1.50
          Mean value_function loss: 14.8574
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 40.1039
                       Mean reward: 56.91
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 8.7494
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.90s
                      Time elapsed: 00:05:54
                               ETA: 00:49:28

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 51661 steps/s (collection: 1.811s, learning 0.092s)
             Mean action noise std: 1.51
          Mean value_function loss: 15.6061
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 40.1478
                       Mean reward: 25.91
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 0.6561
    Episode_Reward/rotating_object: 7.4492
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.90s
                      Time elapsed: 00:05:56
                               ETA: 00:49:23

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 52000 steps/s (collection: 1.793s, learning 0.097s)
             Mean action noise std: 1.51
          Mean value_function loss: 17.3736
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 40.1932
                       Mean reward: 33.32
               Mean episode length: 226.62
    Episode_Reward/reaching_object: 0.6391
    Episode_Reward/rotating_object: 7.5708
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.89s
                      Time elapsed: 00:05:57
                               ETA: 00:49:18

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 47710 steps/s (collection: 1.899s, learning 0.162s)
             Mean action noise std: 1.51
          Mean value_function loss: 17.5915
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.2433
                       Mean reward: 44.12
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 0.6427
    Episode_Reward/rotating_object: 7.4790
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.06s
                      Time elapsed: 00:06:00
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 48183 steps/s (collection: 1.917s, learning 0.123s)
             Mean action noise std: 1.52
          Mean value_function loss: 16.7850
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 40.2827
                       Mean reward: 48.82
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 0.6601
    Episode_Reward/rotating_object: 8.4589
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.04s
                      Time elapsed: 00:06:02
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 46776 steps/s (collection: 1.905s, learning 0.197s)
             Mean action noise std: 1.52
          Mean value_function loss: 16.6458
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.3397
                       Mean reward: 32.74
               Mean episode length: 226.40
    Episode_Reward/reaching_object: 0.6463
    Episode_Reward/rotating_object: 7.4702
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0206
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.10s
                      Time elapsed: 00:06:04
                               ETA: 00:49:08

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 46695 steps/s (collection: 1.988s, learning 0.118s)
             Mean action noise std: 1.52
          Mean value_function loss: 18.5994
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.3866
                       Mean reward: 39.10
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 0.6723
    Episode_Reward/rotating_object: 7.9183
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.11s
                      Time elapsed: 00:06:06
                               ETA: 00:49:05

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 48167 steps/s (collection: 1.870s, learning 0.171s)
             Mean action noise std: 1.52
          Mean value_function loss: 17.2068
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 40.4115
                       Mean reward: 35.93
               Mean episode length: 226.62
    Episode_Reward/reaching_object: 0.6635
    Episode_Reward/rotating_object: 7.4089
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.04s
                      Time elapsed: 00:06:08
                               ETA: 00:49:01

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 49149 steps/s (collection: 1.876s, learning 0.125s)
             Mean action noise std: 1.53
          Mean value_function loss: 18.7506
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 40.4547
                       Mean reward: 29.76
               Mean episode length: 237.16
    Episode_Reward/reaching_object: 0.6582
    Episode_Reward/rotating_object: 7.8599
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.00s
                      Time elapsed: 00:06:10
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 49973 steps/s (collection: 1.840s, learning 0.127s)
             Mean action noise std: 1.53
          Mean value_function loss: 20.6106
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 40.5060
                       Mean reward: 53.75
               Mean episode length: 233.52
    Episode_Reward/reaching_object: 0.6459
    Episode_Reward/rotating_object: 9.3198
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.97s
                      Time elapsed: 00:06:12
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 50064 steps/s (collection: 1.844s, learning 0.119s)
             Mean action noise std: 1.54
          Mean value_function loss: 20.5262
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 40.5565
                       Mean reward: 40.57
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 0.6410
    Episode_Reward/rotating_object: 8.4130
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.96s
                      Time elapsed: 00:06:14
                               ETA: 00:48:49

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 48534 steps/s (collection: 1.884s, learning 0.141s)
             Mean action noise std: 1.54
          Mean value_function loss: 19.5566
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.6090
                       Mean reward: 38.43
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 0.6515
    Episode_Reward/rotating_object: 7.3434
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.03s
                      Time elapsed: 00:06:16
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 49524 steps/s (collection: 1.858s, learning 0.127s)
             Mean action noise std: 1.54
          Mean value_function loss: 21.3805
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.6466
                       Mean reward: 49.62
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 0.6404
    Episode_Reward/rotating_object: 9.5393
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.98s
                      Time elapsed: 00:06:18
                               ETA: 00:48:42

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 49065 steps/s (collection: 1.873s, learning 0.131s)
             Mean action noise std: 1.54
          Mean value_function loss: 23.6879
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 40.6874
                       Mean reward: 36.57
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 0.6261
    Episode_Reward/rotating_object: 7.5676
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.00s
                      Time elapsed: 00:06:20
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 48260 steps/s (collection: 1.931s, learning 0.106s)
             Mean action noise std: 1.55
          Mean value_function loss: 19.8712
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 40.7254
                       Mean reward: 67.05
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 0.6492
    Episode_Reward/rotating_object: 10.6180
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.04s
                      Time elapsed: 00:06:22
                               ETA: 00:48:35

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 47874 steps/s (collection: 1.898s, learning 0.155s)
             Mean action noise std: 1.55
          Mean value_function loss: 21.3674
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 40.7696
                       Mean reward: 42.21
               Mean episode length: 230.30
    Episode_Reward/reaching_object: 0.6138
    Episode_Reward/rotating_object: 9.1775
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.05s
                      Time elapsed: 00:06:24
                               ETA: 00:48:32

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 48009 steps/s (collection: 1.915s, learning 0.133s)
             Mean action noise std: 1.55
          Mean value_function loss: 22.9637
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 40.8122
                       Mean reward: 48.73
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 0.6310
    Episode_Reward/rotating_object: 8.4224
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.05s
                      Time elapsed: 00:06:26
                               ETA: 00:48:28

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 48633 steps/s (collection: 1.902s, learning 0.119s)
             Mean action noise std: 1.56
          Mean value_function loss: 22.4448
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 40.8518
                       Mean reward: 41.85
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 0.6387
    Episode_Reward/rotating_object: 7.3746
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.02s
                      Time elapsed: 00:06:28
                               ETA: 00:48:25

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 47010 steps/s (collection: 1.928s, learning 0.163s)
             Mean action noise std: 1.56
          Mean value_function loss: 23.9113
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 40.8987
                       Mean reward: 48.70
               Mean episode length: 227.36
    Episode_Reward/reaching_object: 0.6635
    Episode_Reward/rotating_object: 10.2612
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.09s
                      Time elapsed: 00:06:30
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 46216 steps/s (collection: 1.968s, learning 0.159s)
             Mean action noise std: 1.56
          Mean value_function loss: 25.0374
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 40.9343
                       Mean reward: 43.38
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 0.6451
    Episode_Reward/rotating_object: 8.3314
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.13s
                      Time elapsed: 00:06:32
                               ETA: 00:48:19

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 48017 steps/s (collection: 1.903s, learning 0.144s)
             Mean action noise std: 1.56
          Mean value_function loss: 24.7076
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 40.9803
                       Mean reward: 35.20
               Mean episode length: 225.50
    Episode_Reward/reaching_object: 0.6542
    Episode_Reward/rotating_object: 9.5019
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.05s
                      Time elapsed: 00:06:34
                               ETA: 00:48:16

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 46882 steps/s (collection: 1.934s, learning 0.163s)
             Mean action noise std: 1.57
          Mean value_function loss: 25.5778
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 41.0076
                       Mean reward: 49.22
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 0.6529
    Episode_Reward/rotating_object: 7.8611
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.10s
                      Time elapsed: 00:06:36
                               ETA: 00:48:13

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 46106 steps/s (collection: 1.993s, learning 0.139s)
             Mean action noise std: 1.57
          Mean value_function loss: 24.6394
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 41.0502
                       Mean reward: 53.96
               Mean episode length: 229.98
    Episode_Reward/reaching_object: 0.6455
    Episode_Reward/rotating_object: 8.8294
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.13s
                      Time elapsed: 00:06:38
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 47056 steps/s (collection: 1.912s, learning 0.177s)
             Mean action noise std: 1.57
          Mean value_function loss: 25.7645
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 41.0934
                       Mean reward: 39.24
               Mean episode length: 219.33
    Episode_Reward/reaching_object: 0.6215
    Episode_Reward/rotating_object: 8.9288
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.09s
                      Time elapsed: 00:06:40
                               ETA: 00:48:07

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 47841 steps/s (collection: 1.927s, learning 0.128s)
             Mean action noise std: 1.57
          Mean value_function loss: 24.7249
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 41.1323
                       Mean reward: 46.80
               Mean episode length: 231.26
    Episode_Reward/reaching_object: 0.6270
    Episode_Reward/rotating_object: 8.5274
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.05s
                      Time elapsed: 00:06:43
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 47068 steps/s (collection: 1.892s, learning 0.197s)
             Mean action noise std: 1.58
          Mean value_function loss: 23.7818
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 41.1661
                       Mean reward: 60.65
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 0.6291
    Episode_Reward/rotating_object: 10.0058
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.09s
                      Time elapsed: 00:06:45
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 47977 steps/s (collection: 1.933s, learning 0.116s)
             Mean action noise std: 1.58
          Mean value_function loss: 22.6655
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 41.2104
                       Mean reward: 60.62
               Mean episode length: 229.24
    Episode_Reward/reaching_object: 0.6225
    Episode_Reward/rotating_object: 8.1131
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.05s
                      Time elapsed: 00:06:47
                               ETA: 00:47:58

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 50004 steps/s (collection: 1.833s, learning 0.132s)
             Mean action noise std: 1.58
          Mean value_function loss: 25.3779
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 41.2465
                       Mean reward: 48.65
               Mean episode length: 222.70
    Episode_Reward/reaching_object: 0.6435
    Episode_Reward/rotating_object: 8.9799
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.97s
                      Time elapsed: 00:06:49
                               ETA: 00:47:54

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 49032 steps/s (collection: 1.885s, learning 0.120s)
             Mean action noise std: 1.59
          Mean value_function loss: 26.4037
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 41.2827
                       Mean reward: 48.47
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 0.6260
    Episode_Reward/rotating_object: 9.1822
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.00s
                      Time elapsed: 00:06:51
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 50422 steps/s (collection: 1.837s, learning 0.113s)
             Mean action noise std: 1.59
          Mean value_function loss: 25.3544
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 41.3107
                       Mean reward: 48.02
               Mean episode length: 225.98
    Episode_Reward/reaching_object: 0.6369
    Episode_Reward/rotating_object: 8.4947
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.95s
                      Time elapsed: 00:06:53
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 50876 steps/s (collection: 1.834s, learning 0.099s)
             Mean action noise std: 1.59
          Mean value_function loss: 23.6154
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 41.3391
                       Mean reward: 54.11
               Mean episode length: 228.27
    Episode_Reward/reaching_object: 0.6308
    Episode_Reward/rotating_object: 8.7502
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.93s
                      Time elapsed: 00:06:55
                               ETA: 00:47:43

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 49903 steps/s (collection: 1.802s, learning 0.168s)
             Mean action noise std: 1.59
          Mean value_function loss: 23.2123
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 41.3801
                       Mean reward: 53.09
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 0.6301
    Episode_Reward/rotating_object: 9.7593
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.97s
                      Time elapsed: 00:06:56
                               ETA: 00:47:40

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 49842 steps/s (collection: 1.821s, learning 0.151s)
             Mean action noise std: 1.60
          Mean value_function loss: 25.6856
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 41.4145
                       Mean reward: 31.40
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 0.6322
    Episode_Reward/rotating_object: 8.5059
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.97s
                      Time elapsed: 00:06:58
                               ETA: 00:47:36

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 48447 steps/s (collection: 1.856s, learning 0.174s)
             Mean action noise std: 1.60
          Mean value_function loss: 25.2200
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 41.4434
                       Mean reward: 45.36
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 0.6286
    Episode_Reward/rotating_object: 7.8843
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.03s
                      Time elapsed: 00:07:00
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 52364 steps/s (collection: 1.754s, learning 0.123s)
             Mean action noise std: 1.60
          Mean value_function loss: 24.6781
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 41.4724
                       Mean reward: 53.82
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 9.8713
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.88s
                      Time elapsed: 00:07:02
                               ETA: 00:47:28

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 51452 steps/s (collection: 1.809s, learning 0.102s)
             Mean action noise std: 1.60
          Mean value_function loss: 21.7054
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 41.5043
                       Mean reward: 65.99
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 0.6799
    Episode_Reward/rotating_object: 11.2189
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.91s
                      Time elapsed: 00:07:04
                               ETA: 00:47:24

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 51383 steps/s (collection: 1.799s, learning 0.115s)
             Mean action noise std: 1.60
          Mean value_function loss: 25.8472
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 41.5417
                       Mean reward: 51.51
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 0.6345
    Episode_Reward/rotating_object: 10.3615
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.91s
                      Time elapsed: 00:07:06
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 49937 steps/s (collection: 1.847s, learning 0.122s)
             Mean action noise std: 1.61
          Mean value_function loss: 25.5648
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 41.5739
                       Mean reward: 54.17
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 8.9178
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.97s
                      Time elapsed: 00:07:08
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 51565 steps/s (collection: 1.799s, learning 0.108s)
             Mean action noise std: 1.61
          Mean value_function loss: 28.2833
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 41.6091
                       Mean reward: 70.00
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 0.6662
    Episode_Reward/rotating_object: 9.7315
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.91s
                      Time elapsed: 00:07:10
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 51893 steps/s (collection: 1.798s, learning 0.096s)
             Mean action noise std: 1.61
          Mean value_function loss: 26.9560
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 41.6458
                       Mean reward: 58.71
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 0.6772
    Episode_Reward/rotating_object: 10.0751
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.89s
                      Time elapsed: 00:07:12
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 51109 steps/s (collection: 1.806s, learning 0.117s)
             Mean action noise std: 1.62
          Mean value_function loss: 25.4504
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 41.6809
                       Mean reward: 55.25
               Mean episode length: 238.92
    Episode_Reward/reaching_object: 0.6789
    Episode_Reward/rotating_object: 10.4032
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.92s
                      Time elapsed: 00:07:14
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 48400 steps/s (collection: 1.907s, learning 0.124s)
             Mean action noise std: 1.62
          Mean value_function loss: 28.4026
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 41.7182
                       Mean reward: 50.81
               Mean episode length: 231.52
    Episode_Reward/reaching_object: 0.6455
    Episode_Reward/rotating_object: 8.1261
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.03s
                      Time elapsed: 00:07:16
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 49582 steps/s (collection: 1.882s, learning 0.100s)
             Mean action noise std: 1.62
          Mean value_function loss: 27.7824
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 41.7482
                       Mean reward: 65.10
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 10.0587
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.98s
                      Time elapsed: 00:07:18
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 50869 steps/s (collection: 1.834s, learning 0.099s)
             Mean action noise std: 1.62
          Mean value_function loss: 25.0597
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 41.7903
                       Mean reward: 42.73
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 0.6337
    Episode_Reward/rotating_object: 8.7044
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.93s
                      Time elapsed: 00:07:20
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 52440 steps/s (collection: 1.773s, learning 0.102s)
             Mean action noise std: 1.63
          Mean value_function loss: 26.1200
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 41.8289
                       Mean reward: 64.28
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 0.6545
    Episode_Reward/rotating_object: 10.6852
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.87s
                      Time elapsed: 00:07:22
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 46765 steps/s (collection: 2.004s, learning 0.098s)
             Mean action noise std: 1.63
          Mean value_function loss: 25.5882
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 41.8634
                       Mean reward: 55.09
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.6539
    Episode_Reward/rotating_object: 9.9654
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.10s
                      Time elapsed: 00:07:24
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 48773 steps/s (collection: 1.898s, learning 0.117s)
             Mean action noise std: 1.63
          Mean value_function loss: 27.1632
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 41.8976
                       Mean reward: 52.96
               Mean episode length: 221.29
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 9.5736
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.02s
                      Time elapsed: 00:07:26
                               ETA: 00:46:45

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 48994 steps/s (collection: 1.890s, learning 0.117s)
             Mean action noise std: 1.63
          Mean value_function loss: 26.0810
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 41.9275
                       Mean reward: 48.03
               Mean episode length: 223.23
    Episode_Reward/reaching_object: 0.6643
    Episode_Reward/rotating_object: 9.7750
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.01s
                      Time elapsed: 00:07:28
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 50182 steps/s (collection: 1.855s, learning 0.104s)
             Mean action noise std: 1.64
          Mean value_function loss: 26.6050
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 41.9584
                       Mean reward: 48.93
               Mean episode length: 219.81
    Episode_Reward/reaching_object: 0.6614
    Episode_Reward/rotating_object: 9.4564
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.96s
                      Time elapsed: 00:07:30
                               ETA: 00:46:39

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 50361 steps/s (collection: 1.846s, learning 0.106s)
             Mean action noise std: 1.64
          Mean value_function loss: 28.0733
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 41.9890
                       Mean reward: 58.95
               Mean episode length: 232.41
    Episode_Reward/reaching_object: 0.6694
    Episode_Reward/rotating_object: 9.7581
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.95s
                      Time elapsed: 00:07:32
                               ETA: 00:46:35

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 49411 steps/s (collection: 1.896s, learning 0.094s)
             Mean action noise std: 1.64
          Mean value_function loss: 26.7903
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 42.0379
                       Mean reward: 53.78
               Mean episode length: 216.54
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 11.8554
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.99s
                      Time elapsed: 00:07:34
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 49574 steps/s (collection: 1.864s, learning 0.119s)
             Mean action noise std: 1.64
          Mean value_function loss: 26.2235
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 42.0745
                       Mean reward: 46.59
               Mean episode length: 222.99
    Episode_Reward/reaching_object: 0.6442
    Episode_Reward/rotating_object: 8.7882
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.98s
                      Time elapsed: 00:07:36
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 48958 steps/s (collection: 1.868s, learning 0.140s)
             Mean action noise std: 1.65
          Mean value_function loss: 27.9962
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 42.1074
                       Mean reward: 63.90
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 0.6738
    Episode_Reward/rotating_object: 9.8187
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.01s
                      Time elapsed: 00:07:38
                               ETA: 00:46:26

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 46966 steps/s (collection: 1.958s, learning 0.135s)
             Mean action noise std: 1.65
          Mean value_function loss: 27.4427
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 42.1423
                       Mean reward: 60.65
               Mean episode length: 223.63
    Episode_Reward/reaching_object: 0.6771
    Episode_Reward/rotating_object: 10.6253
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.09s
                      Time elapsed: 00:07:40
                               ETA: 00:46:23

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 47189 steps/s (collection: 1.932s, learning 0.152s)
             Mean action noise std: 1.65
          Mean value_function loss: 27.7314
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 42.1825
                       Mean reward: 49.19
               Mean episode length: 225.17
    Episode_Reward/reaching_object: 0.6711
    Episode_Reward/rotating_object: 11.6200
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.08s
                      Time elapsed: 00:07:42
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 49487 steps/s (collection: 1.889s, learning 0.098s)
             Mean action noise std: 1.66
          Mean value_function loss: 28.6195
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 42.2245
                       Mean reward: 68.38
               Mean episode length: 234.65
    Episode_Reward/reaching_object: 0.7038
    Episode_Reward/rotating_object: 11.8095
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.99s
                      Time elapsed: 00:07:44
                               ETA: 00:46:17

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 50499 steps/s (collection: 1.832s, learning 0.115s)
             Mean action noise std: 1.66
          Mean value_function loss: 23.9590
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 42.2580
                       Mean reward: 84.16
               Mean episode length: 227.66
    Episode_Reward/reaching_object: 0.6905
    Episode_Reward/rotating_object: 11.7798
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.95s
                      Time elapsed: 00:07:46
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 50382 steps/s (collection: 1.845s, learning 0.107s)
             Mean action noise std: 1.66
          Mean value_function loss: 26.8695
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 42.3090
                       Mean reward: 57.68
               Mean episode length: 230.24
    Episode_Reward/reaching_object: 0.6832
    Episode_Reward/rotating_object: 11.0498
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.95s
                      Time elapsed: 00:07:48
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 49764 steps/s (collection: 1.850s, learning 0.125s)
             Mean action noise std: 1.67
          Mean value_function loss: 23.8577
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 42.3565
                       Mean reward: 52.63
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 0.6722
    Episode_Reward/rotating_object: 11.2974
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.98s
                      Time elapsed: 00:07:50
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 48494 steps/s (collection: 1.884s, learning 0.143s)
             Mean action noise std: 1.67
          Mean value_function loss: 24.7988
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 42.3844
                       Mean reward: 62.88
               Mean episode length: 225.61
    Episode_Reward/reaching_object: 0.6527
    Episode_Reward/rotating_object: 9.3174
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.03s
                      Time elapsed: 00:07:52
                               ETA: 00:46:04

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 48288 steps/s (collection: 1.849s, learning 0.187s)
             Mean action noise std: 1.67
          Mean value_function loss: 25.3669
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 42.4078
                       Mean reward: 46.73
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 0.6780
    Episode_Reward/rotating_object: 9.9324
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.04s
                      Time elapsed: 00:07:54
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 46361 steps/s (collection: 2.010s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 26.5395
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 42.4413
                       Mean reward: 56.47
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 0.6716
    Episode_Reward/rotating_object: 11.0923
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.12s
                      Time elapsed: 00:07:56
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 46525 steps/s (collection: 1.984s, learning 0.129s)
             Mean action noise std: 1.67
          Mean value_function loss: 27.2871
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.4639
                       Mean reward: 62.38
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 0.6962
    Episode_Reward/rotating_object: 11.1025
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.11s
                      Time elapsed: 00:07:58
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 43003 steps/s (collection: 2.116s, learning 0.170s)
             Mean action noise std: 1.68
          Mean value_function loss: 25.5448
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 42.4831
                       Mean reward: 41.86
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 0.6795
    Episode_Reward/rotating_object: 11.3211
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.29s
                      Time elapsed: 00:08:00
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 48207 steps/s (collection: 1.944s, learning 0.096s)
             Mean action noise std: 1.68
          Mean value_function loss: 29.2932
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 42.5064
                       Mean reward: 45.75
               Mean episode length: 223.68
    Episode_Reward/reaching_object: 0.6965
    Episode_Reward/rotating_object: 10.0628
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.04s
                      Time elapsed: 00:08:02
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 47631 steps/s (collection: 1.956s, learning 0.108s)
             Mean action noise std: 1.68
          Mean value_function loss: 32.6702
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 42.5315
                       Mean reward: 57.10
               Mean episode length: 220.88
    Episode_Reward/reaching_object: 0.6803
    Episode_Reward/rotating_object: 10.9465
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.06s
                      Time elapsed: 00:08:04
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 48043 steps/s (collection: 1.920s, learning 0.126s)
             Mean action noise std: 1.68
          Mean value_function loss: 32.5565
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 42.5684
                       Mean reward: 59.53
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 0.6936
    Episode_Reward/rotating_object: 11.9856
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.05s
                      Time elapsed: 00:08:06
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 46683 steps/s (collection: 1.940s, learning 0.166s)
             Mean action noise std: 1.68
          Mean value_function loss: 33.9260
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 42.6009
                       Mean reward: 63.43
               Mean episode length: 225.46
    Episode_Reward/reaching_object: 0.6828
    Episode_Reward/rotating_object: 10.9235
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.11s
                      Time elapsed: 00:08:09
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 42894 steps/s (collection: 2.105s, learning 0.187s)
             Mean action noise std: 1.69
          Mean value_function loss: 31.8015
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 42.6270
                       Mean reward: 68.81
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 13.4552
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.29s
                      Time elapsed: 00:08:11
                               ETA: 00:45:43

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 46336 steps/s (collection: 2.008s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 33.4069
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.6504
                       Mean reward: 71.25
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 12.5850
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.12s
                      Time elapsed: 00:08:13
                               ETA: 00:45:41

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 45630 steps/s (collection: 1.970s, learning 0.184s)
             Mean action noise std: 1.69
          Mean value_function loss: 32.6552
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 42.6769
                       Mean reward: 57.59
               Mean episode length: 231.53
    Episode_Reward/reaching_object: 0.7544
    Episode_Reward/rotating_object: 12.6986
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.15s
                      Time elapsed: 00:08:15
                               ETA: 00:45:39

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 44135 steps/s (collection: 2.103s, learning 0.125s)
             Mean action noise std: 1.69
          Mean value_function loss: 36.0997
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 42.7047
                       Mean reward: 75.77
               Mean episode length: 230.08
    Episode_Reward/reaching_object: 0.7589
    Episode_Reward/rotating_object: 14.1367
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.23s
                      Time elapsed: 00:08:17
                               ETA: 00:45:37

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 45496 steps/s (collection: 2.022s, learning 0.138s)
             Mean action noise std: 1.69
          Mean value_function loss: 35.5111
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 42.7262
                       Mean reward: 66.39
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 0.7643
    Episode_Reward/rotating_object: 13.0332
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.16s
                      Time elapsed: 00:08:20
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 45156 steps/s (collection: 2.026s, learning 0.151s)
             Mean action noise std: 1.70
          Mean value_function loss: 34.8344
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 42.7567
                       Mean reward: 72.01
               Mean episode length: 232.98
    Episode_Reward/reaching_object: 0.7650
    Episode_Reward/rotating_object: 12.3745
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.18s
                      Time elapsed: 00:08:22
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 46254 steps/s (collection: 1.990s, learning 0.136s)
             Mean action noise std: 1.70
          Mean value_function loss: 38.3459
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 42.7899
                       Mean reward: 72.46
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 0.7556
    Episode_Reward/rotating_object: 13.8543
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.13s
                      Time elapsed: 00:08:24
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 45868 steps/s (collection: 1.991s, learning 0.153s)
             Mean action noise std: 1.70
          Mean value_function loss: 30.8270
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 42.8159
                       Mean reward: 71.02
               Mean episode length: 238.48
    Episode_Reward/reaching_object: 0.7611
    Episode_Reward/rotating_object: 13.8633
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.14s
                      Time elapsed: 00:08:26
                               ETA: 00:45:28

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 47840 steps/s (collection: 1.926s, learning 0.129s)
             Mean action noise std: 1.70
          Mean value_function loss: 31.7802
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 42.8349
                       Mean reward: 57.68
               Mean episode length: 223.59
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 12.4599
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.05s
                      Time elapsed: 00:08:28
                               ETA: 00:45:25

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 46983 steps/s (collection: 1.976s, learning 0.116s)
             Mean action noise std: 1.71
          Mean value_function loss: 37.0185
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 42.8675
                       Mean reward: 82.53
               Mean episode length: 232.95
    Episode_Reward/reaching_object: 0.7560
    Episode_Reward/rotating_object: 15.7434
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.09s
                      Time elapsed: 00:08:30
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 48333 steps/s (collection: 1.906s, learning 0.128s)
             Mean action noise std: 1.71
          Mean value_function loss: 35.4554
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 42.8860
                       Mean reward: 82.78
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 0.7524
    Episode_Reward/rotating_object: 13.7006
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.03s
                      Time elapsed: 00:08:32
                               ETA: 00:45:20

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 48212 steps/s (collection: 1.924s, learning 0.115s)
             Mean action noise std: 1.71
          Mean value_function loss: 37.9724
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 42.9096
                       Mean reward: 83.53
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 0.7451
    Episode_Reward/rotating_object: 15.2358
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.04s
                      Time elapsed: 00:08:34
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 44432 steps/s (collection: 2.097s, learning 0.115s)
             Mean action noise std: 1.71
          Mean value_function loss: 36.5814
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 42.9435
                       Mean reward: 77.45
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 0.7372
    Episode_Reward/rotating_object: 15.8505
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.21s
                      Time elapsed: 00:08:36
                               ETA: 00:45:16

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 48031 steps/s (collection: 1.941s, learning 0.106s)
             Mean action noise std: 1.71
          Mean value_function loss: 42.6880
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 42.9697
                       Mean reward: 76.27
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 0.7258
    Episode_Reward/rotating_object: 12.5974
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.05s
                      Time elapsed: 00:08:38
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 48694 steps/s (collection: 1.922s, learning 0.097s)
             Mean action noise std: 1.72
          Mean value_function loss: 37.3944
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 42.9945
                       Mean reward: 78.73
               Mean episode length: 220.23
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 13.3798
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.02s
                      Time elapsed: 00:08:40
                               ETA: 00:45:10

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 47916 steps/s (collection: 1.938s, learning 0.113s)
             Mean action noise std: 1.72
          Mean value_function loss: 35.4593
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 43.0197
                       Mean reward: 75.83
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 0.7512
    Episode_Reward/rotating_object: 14.3343
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.05s
                      Time elapsed: 00:08:43
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 47941 steps/s (collection: 1.936s, learning 0.115s)
             Mean action noise std: 1.72
          Mean value_function loss: 43.6747
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 43.0426
                       Mean reward: 93.19
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 0.7420
    Episode_Reward/rotating_object: 15.0469
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.05s
                      Time elapsed: 00:08:45
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 48701 steps/s (collection: 1.906s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 42.7450
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 43.0612
                       Mean reward: 83.83
               Mean episode length: 228.89
    Episode_Reward/reaching_object: 0.7495
    Episode_Reward/rotating_object: 14.6010
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.02s
                      Time elapsed: 00:08:47
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 45797 steps/s (collection: 2.006s, learning 0.140s)
             Mean action noise std: 1.72
          Mean value_function loss: 50.5992
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 43.0812
                       Mean reward: 77.64
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 0.7621
    Episode_Reward/rotating_object: 16.3436
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.15s
                      Time elapsed: 00:08:49
                               ETA: 00:45:00

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 47527 steps/s (collection: 1.943s, learning 0.125s)
             Mean action noise std: 1.72
          Mean value_function loss: 47.8010
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 43.0998
                       Mean reward: 85.61
               Mean episode length: 227.05
    Episode_Reward/reaching_object: 0.7701
    Episode_Reward/rotating_object: 17.2110
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.07s
                      Time elapsed: 00:08:51
                               ETA: 00:44:57

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 46081 steps/s (collection: 1.986s, learning 0.148s)
             Mean action noise std: 1.73
          Mean value_function loss: 42.9563
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 43.1242
                       Mean reward: 88.99
               Mean episode length: 226.78
    Episode_Reward/reaching_object: 0.7674
    Episode_Reward/rotating_object: 16.1855
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.13s
                      Time elapsed: 00:08:53
                               ETA: 00:44:55

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 48012 steps/s (collection: 1.922s, learning 0.126s)
             Mean action noise std: 1.73
          Mean value_function loss: 45.3549
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.1423
                       Mean reward: 92.96
               Mean episode length: 231.50
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 15.2990
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.05s
                      Time elapsed: 00:08:55
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 46188 steps/s (collection: 2.010s, learning 0.118s)
             Mean action noise std: 1.73
          Mean value_function loss: 44.9660
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 43.1644
                       Mean reward: 73.18
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 0.8013
    Episode_Reward/rotating_object: 16.9159
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.13s
                      Time elapsed: 00:08:57
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 45889 steps/s (collection: 1.990s, learning 0.152s)
             Mean action noise std: 1.73
          Mean value_function loss: 44.3751
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 43.1846
                       Mean reward: 84.89
               Mean episode length: 223.57
    Episode_Reward/reaching_object: 0.7822
    Episode_Reward/rotating_object: 16.7386
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.14s
                      Time elapsed: 00:08:59
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 46599 steps/s (collection: 2.002s, learning 0.107s)
             Mean action noise std: 1.73
          Mean value_function loss: 43.5751
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 43.2024
                       Mean reward: 71.86
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 0.7962
    Episode_Reward/rotating_object: 15.7175
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.11s
                      Time elapsed: 00:09:01
                               ETA: 00:44:45

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 47212 steps/s (collection: 1.964s, learning 0.118s)
             Mean action noise std: 1.73
          Mean value_function loss: 50.8309
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.2165
                       Mean reward: 100.18
               Mean episode length: 221.89
    Episode_Reward/reaching_object: 0.8026
    Episode_Reward/rotating_object: 16.5131
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.08s
                      Time elapsed: 00:09:03
                               ETA: 00:44:43

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 45283 steps/s (collection: 2.050s, learning 0.121s)
             Mean action noise std: 1.73
          Mean value_function loss: 50.6100
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 43.2297
                       Mean reward: 74.88
               Mean episode length: 227.00
    Episode_Reward/reaching_object: 0.8180
    Episode_Reward/rotating_object: 15.4677
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.17s
                      Time elapsed: 00:09:06
                               ETA: 00:44:41

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 47738 steps/s (collection: 1.959s, learning 0.101s)
             Mean action noise std: 1.74
          Mean value_function loss: 44.7757
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 43.2470
                       Mean reward: 98.78
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 0.8285
    Episode_Reward/rotating_object: 21.2931
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.06s
                      Time elapsed: 00:09:08
                               ETA: 00:44:38

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 48034 steps/s (collection: 1.910s, learning 0.137s)
             Mean action noise std: 1.74
          Mean value_function loss: 57.2323
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 43.2612
                       Mean reward: 81.89
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 0.8219
    Episode_Reward/rotating_object: 17.3837
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.05s
                      Time elapsed: 00:09:10
                               ETA: 00:44:36

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 46973 steps/s (collection: 1.934s, learning 0.159s)
             Mean action noise std: 1.74
          Mean value_function loss: 49.5651
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 43.2842
                       Mean reward: 97.75
               Mean episode length: 223.09
    Episode_Reward/reaching_object: 0.8146
    Episode_Reward/rotating_object: 18.3653
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.09s
                      Time elapsed: 00:09:12
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 45730 steps/s (collection: 1.954s, learning 0.196s)
             Mean action noise std: 1.74
          Mean value_function loss: 52.2699
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 43.3070
                       Mean reward: 96.23
               Mean episode length: 222.53
    Episode_Reward/reaching_object: 0.8369
    Episode_Reward/rotating_object: 18.4264
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.15s
                      Time elapsed: 00:09:14
                               ETA: 00:44:31

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 47993 steps/s (collection: 1.902s, learning 0.146s)
             Mean action noise std: 1.74
          Mean value_function loss: 57.5826
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 43.3269
                       Mean reward: 99.26
               Mean episode length: 218.27
    Episode_Reward/reaching_object: 0.8493
    Episode_Reward/rotating_object: 21.4951
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.05s
                      Time elapsed: 00:09:16
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 47280 steps/s (collection: 1.971s, learning 0.108s)
             Mean action noise std: 1.74
          Mean value_function loss: 53.7375
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 43.3456
                       Mean reward: 114.07
               Mean episode length: 225.58
    Episode_Reward/reaching_object: 0.8458
    Episode_Reward/rotating_object: 20.1230
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.08s
                      Time elapsed: 00:09:18
                               ETA: 00:44:26

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 47795 steps/s (collection: 1.961s, learning 0.096s)
             Mean action noise std: 1.74
          Mean value_function loss: 50.8106
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 43.3581
                       Mean reward: 101.81
               Mean episode length: 227.45
    Episode_Reward/reaching_object: 0.8380
    Episode_Reward/rotating_object: 19.3787
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.06s
                      Time elapsed: 00:09:20
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 47894 steps/s (collection: 1.954s, learning 0.098s)
             Mean action noise std: 1.75
          Mean value_function loss: 48.7201
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 43.3806
                       Mean reward: 121.75
               Mean episode length: 242.68
    Episode_Reward/reaching_object: 0.8616
    Episode_Reward/rotating_object: 21.8761
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.05s
                      Time elapsed: 00:09:22
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 48215 steps/s (collection: 1.945s, learning 0.094s)
             Mean action noise std: 1.75
          Mean value_function loss: 51.3660
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 43.4095
                       Mean reward: 113.60
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 0.8715
    Episode_Reward/rotating_object: 23.8074
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.04s
                      Time elapsed: 00:09:24
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 48603 steps/s (collection: 1.919s, learning 0.104s)
             Mean action noise std: 1.75
          Mean value_function loss: 59.0233
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 43.4339
                       Mean reward: 111.15
               Mean episode length: 218.22
    Episode_Reward/reaching_object: 0.8324
    Episode_Reward/rotating_object: 19.7862
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.02s
                      Time elapsed: 00:09:26
                               ETA: 00:44:15

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 48425 steps/s (collection: 1.925s, learning 0.105s)
             Mean action noise std: 1.75
          Mean value_function loss: 60.0185
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 43.4574
                       Mean reward: 106.37
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 0.8598
    Episode_Reward/rotating_object: 21.8900
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.03s
                      Time elapsed: 00:09:28
                               ETA: 00:44:13

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 47770 steps/s (collection: 1.947s, learning 0.111s)
             Mean action noise std: 1.76
          Mean value_function loss: 59.2210
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 43.4848
                       Mean reward: 92.94
               Mean episode length: 221.44
    Episode_Reward/reaching_object: 0.8411
    Episode_Reward/rotating_object: 20.7261
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.06s
                      Time elapsed: 00:09:30
                               ETA: 00:44:10

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 47524 steps/s (collection: 1.957s, learning 0.111s)
             Mean action noise std: 1.76
          Mean value_function loss: 60.2692
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 43.5098
                       Mean reward: 125.75
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 0.8710
    Episode_Reward/rotating_object: 25.5991
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.07s
                      Time elapsed: 00:09:32
                               ETA: 00:44:08

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 47874 steps/s (collection: 1.955s, learning 0.098s)
             Mean action noise std: 1.76
          Mean value_function loss: 51.9431
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.5342
                       Mean reward: 133.39
               Mean episode length: 229.78
    Episode_Reward/reaching_object: 0.8401
    Episode_Reward/rotating_object: 22.3119
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.05s
                      Time elapsed: 00:09:35
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 48105 steps/s (collection: 1.938s, learning 0.106s)
             Mean action noise std: 1.76
          Mean value_function loss: 53.6673
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 43.5494
                       Mean reward: 164.55
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 0.8700
    Episode_Reward/rotating_object: 22.9590
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.04s
                      Time elapsed: 00:09:37
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 44974 steps/s (collection: 2.015s, learning 0.171s)
             Mean action noise std: 1.76
          Mean value_function loss: 58.1800
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 43.5660
                       Mean reward: 127.28
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 0.8748
    Episode_Reward/rotating_object: 24.5151
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.19s
                      Time elapsed: 00:09:39
                               ETA: 00:44:00

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 45361 steps/s (collection: 2.021s, learning 0.146s)
             Mean action noise std: 1.76
          Mean value_function loss: 60.8511
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 43.5786
                       Mean reward: 135.77
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 0.8844
    Episode_Reward/rotating_object: 26.1520
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.17s
                      Time elapsed: 00:09:41
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 48010 steps/s (collection: 1.928s, learning 0.119s)
             Mean action noise std: 1.77
          Mean value_function loss: 60.6776
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.5995
                       Mean reward: 119.58
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 0.8760
    Episode_Reward/rotating_object: 23.6193
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.05s
                      Time elapsed: 00:09:43
                               ETA: 00:43:56

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 46419 steps/s (collection: 1.951s, learning 0.167s)
             Mean action noise std: 1.77
          Mean value_function loss: 57.2623
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 43.6218
                       Mean reward: 119.20
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 0.8818
    Episode_Reward/rotating_object: 25.4552
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.12s
                      Time elapsed: 00:09:45
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 46621 steps/s (collection: 1.951s, learning 0.158s)
             Mean action noise std: 1.77
          Mean value_function loss: 67.1156
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.6414
                       Mean reward: 124.70
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 0.8777
    Episode_Reward/rotating_object: 24.8730
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.11s
                      Time elapsed: 00:09:47
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 47463 steps/s (collection: 1.961s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 79.7762
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 43.6627
                       Mean reward: 174.11
               Mean episode length: 238.11
    Episode_Reward/reaching_object: 0.8841
    Episode_Reward/rotating_object: 27.0097
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.07s
                      Time elapsed: 00:09:49
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 47591 steps/s (collection: 1.944s, learning 0.121s)
             Mean action noise std: 1.77
          Mean value_function loss: 73.7040
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 43.6830
                       Mean reward: 119.52
               Mean episode length: 224.42
    Episode_Reward/reaching_object: 0.8734
    Episode_Reward/rotating_object: 25.4794
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.07s
                      Time elapsed: 00:09:51
                               ETA: 00:43:46

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 47523 steps/s (collection: 1.953s, learning 0.115s)
             Mean action noise std: 1.77
          Mean value_function loss: 59.8282
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 43.7031
                       Mean reward: 144.50
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 0.8596
    Episode_Reward/rotating_object: 24.3550
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.07s
                      Time elapsed: 00:09:53
                               ETA: 00:43:44

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 48126 steps/s (collection: 1.947s, learning 0.095s)
             Mean action noise std: 1.78
          Mean value_function loss: 69.6200
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 43.7232
                       Mean reward: 172.52
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 0.8978
    Episode_Reward/rotating_object: 27.9305
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.04s
                      Time elapsed: 00:09:55
                               ETA: 00:43:41

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 47172 steps/s (collection: 1.961s, learning 0.123s)
             Mean action noise std: 1.78
          Mean value_function loss: 67.9195
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 43.7467
                       Mean reward: 124.43
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 0.8865
    Episode_Reward/rotating_object: 25.4179
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.08s
                      Time elapsed: 00:09:58
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 45269 steps/s (collection: 2.033s, learning 0.138s)
             Mean action noise std: 1.78
          Mean value_function loss: 66.8061
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 43.7696
                       Mean reward: 126.32
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 0.8993
    Episode_Reward/rotating_object: 29.7310
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.17s
                      Time elapsed: 00:10:00
                               ETA: 00:43:37

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 47699 steps/s (collection: 1.968s, learning 0.093s)
             Mean action noise std: 1.78
          Mean value_function loss: 67.3148
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 43.7903
                       Mean reward: 175.16
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 0.8757
    Episode_Reward/rotating_object: 26.5747
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.06s
                      Time elapsed: 00:10:02
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 48125 steps/s (collection: 1.946s, learning 0.096s)
             Mean action noise std: 1.78
          Mean value_function loss: 61.2409
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.8073
                       Mean reward: 167.98
               Mean episode length: 228.41
    Episode_Reward/reaching_object: 0.8882
    Episode_Reward/rotating_object: 28.4157
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.04s
                      Time elapsed: 00:10:04
                               ETA: 00:43:32

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 47764 steps/s (collection: 1.950s, learning 0.108s)
             Mean action noise std: 1.78
          Mean value_function loss: 62.7486
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 43.8234
                       Mean reward: 166.31
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 0.9026
    Episode_Reward/rotating_object: 28.2463
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.06s
                      Time elapsed: 00:10:06
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 48321 steps/s (collection: 1.930s, learning 0.105s)
             Mean action noise std: 1.79
          Mean value_function loss: 58.7403
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 43.8482
                       Mean reward: 121.07
               Mean episode length: 227.17
    Episode_Reward/reaching_object: 0.8743
    Episode_Reward/rotating_object: 24.3409
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.03s
                      Time elapsed: 00:10:08
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 47034 steps/s (collection: 1.972s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 58.8950
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 43.8698
                       Mean reward: 128.71
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 0.8600
    Episode_Reward/rotating_object: 24.7616
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.09s
                      Time elapsed: 00:10:10
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 48111 steps/s (collection: 1.947s, learning 0.096s)
             Mean action noise std: 1.79
          Mean value_function loss: 63.5821
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.8865
                       Mean reward: 152.96
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 0.8953
    Episode_Reward/rotating_object: 28.6872
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.04s
                      Time elapsed: 00:10:12
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 47130 steps/s (collection: 1.936s, learning 0.150s)
             Mean action noise std: 1.79
          Mean value_function loss: 62.1717
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 43.9013
                       Mean reward: 143.90
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 0.8823
    Episode_Reward/rotating_object: 27.6114
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.09s
                      Time elapsed: 00:10:14
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 45616 steps/s (collection: 1.982s, learning 0.173s)
             Mean action noise std: 1.79
          Mean value_function loss: 66.9302
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 43.9240
                       Mean reward: 152.58
               Mean episode length: 224.81
    Episode_Reward/reaching_object: 0.8645
    Episode_Reward/rotating_object: 30.7442
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.16s
                      Time elapsed: 00:10:16
                               ETA: 00:43:17

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 46373 steps/s (collection: 1.968s, learning 0.152s)
             Mean action noise std: 1.79
          Mean value_function loss: 69.0595
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.9406
                       Mean reward: 151.72
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 0.8800
    Episode_Reward/rotating_object: 30.0914
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.12s
                      Time elapsed: 00:10:18
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 47183 steps/s (collection: 1.975s, learning 0.108s)
             Mean action noise std: 1.79
          Mean value_function loss: 71.9297
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 43.9491
                       Mean reward: 148.12
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 0.8747
    Episode_Reward/rotating_object: 28.4557
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.08s
                      Time elapsed: 00:10:20
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 45370 steps/s (collection: 2.039s, learning 0.128s)
             Mean action noise std: 1.80
          Mean value_function loss: 75.0559
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 43.9670
                       Mean reward: 159.05
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 0.8813
    Episode_Reward/rotating_object: 30.5506
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.17s
                      Time elapsed: 00:10:23
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 47025 steps/s (collection: 1.979s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 71.8180
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 43.9836
                       Mean reward: 153.91
               Mean episode length: 232.17
    Episode_Reward/reaching_object: 0.8772
    Episode_Reward/rotating_object: 29.7017
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.09s
                      Time elapsed: 00:10:25
                               ETA: 00:43:08

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 48441 steps/s (collection: 1.929s, learning 0.100s)
             Mean action noise std: 1.80
          Mean value_function loss: 77.4312
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.0028
                       Mean reward: 177.89
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 0.9156
    Episode_Reward/rotating_object: 32.8010
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.03s
                      Time elapsed: 00:10:27
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 48252 steps/s (collection: 1.934s, learning 0.103s)
             Mean action noise std: 1.80
          Mean value_function loss: 77.3264
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.0208
                       Mean reward: 179.31
               Mean episode length: 217.40
    Episode_Reward/reaching_object: 0.9081
    Episode_Reward/rotating_object: 29.8148
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.04s
                      Time elapsed: 00:10:29
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 47706 steps/s (collection: 1.967s, learning 0.094s)
             Mean action noise std: 1.80
          Mean value_function loss: 84.6624
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.0388
                       Mean reward: 161.76
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 0.9013
    Episode_Reward/rotating_object: 31.4666
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.06s
                      Time elapsed: 00:10:31
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 46200 steps/s (collection: 2.016s, learning 0.111s)
             Mean action noise std: 1.80
          Mean value_function loss: 81.7038
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 44.0515
                       Mean reward: 159.81
               Mean episode length: 227.09
    Episode_Reward/reaching_object: 0.9004
    Episode_Reward/rotating_object: 31.2763
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.13s
                      Time elapsed: 00:10:33
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 47055 steps/s (collection: 1.970s, learning 0.119s)
             Mean action noise std: 1.80
          Mean value_function loss: 72.4682
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 44.0581
                       Mean reward: 144.57
               Mean episode length: 222.43
    Episode_Reward/reaching_object: 0.8947
    Episode_Reward/rotating_object: 30.6486
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.09s
                      Time elapsed: 00:10:35
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 48482 steps/s (collection: 1.912s, learning 0.116s)
             Mean action noise std: 1.80
          Mean value_function loss: 72.2167
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.0682
                       Mean reward: 167.33
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 0.9077
    Episode_Reward/rotating_object: 36.7377
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.03s
                      Time elapsed: 00:10:37
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 47144 steps/s (collection: 1.957s, learning 0.128s)
             Mean action noise std: 1.81
          Mean value_function loss: 81.4321
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 44.0840
                       Mean reward: 196.74
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 0.9080
    Episode_Reward/rotating_object: 36.6265
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.09s
                      Time elapsed: 00:10:39
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 47085 steps/s (collection: 1.935s, learning 0.153s)
             Mean action noise std: 1.81
          Mean value_function loss: 82.8138
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.1013
                       Mean reward: 146.31
               Mean episode length: 216.49
    Episode_Reward/reaching_object: 0.8779
    Episode_Reward/rotating_object: 29.7990
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.09s
                      Time elapsed: 00:10:41
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 47943 steps/s (collection: 1.947s, learning 0.103s)
             Mean action noise std: 1.81
          Mean value_function loss: 80.8986
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 44.1133
                       Mean reward: 190.80
               Mean episode length: 219.47
    Episode_Reward/reaching_object: 0.8841
    Episode_Reward/rotating_object: 33.8930
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.05s
                      Time elapsed: 00:10:43
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 46236 steps/s (collection: 2.021s, learning 0.105s)
             Mean action noise std: 1.81
          Mean value_function loss: 79.4903
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.1276
                       Mean reward: 170.43
               Mean episode length: 224.33
    Episode_Reward/reaching_object: 0.9255
    Episode_Reward/rotating_object: 35.5569
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.13s
                      Time elapsed: 00:10:45
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 47084 steps/s (collection: 1.982s, learning 0.106s)
             Mean action noise std: 1.81
          Mean value_function loss: 68.7786
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 44.1400
                       Mean reward: 184.59
               Mean episode length: 217.56
    Episode_Reward/reaching_object: 0.8756
    Episode_Reward/rotating_object: 35.8338
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.09s
                      Time elapsed: 00:10:48
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 47421 steps/s (collection: 1.950s, learning 0.123s)
             Mean action noise std: 1.81
          Mean value_function loss: 71.3715
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 44.1511
                       Mean reward: 188.80
               Mean episode length: 226.42
    Episode_Reward/reaching_object: 0.9185
    Episode_Reward/rotating_object: 37.1514
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.07s
                      Time elapsed: 00:10:50
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 47600 steps/s (collection: 1.948s, learning 0.118s)
             Mean action noise std: 1.81
          Mean value_function loss: 75.0606
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.1666
                       Mean reward: 204.22
               Mean episode length: 220.68
    Episode_Reward/reaching_object: 0.8941
    Episode_Reward/rotating_object: 36.3481
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.07s
                      Time elapsed: 00:10:52
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 47736 steps/s (collection: 1.950s, learning 0.110s)
             Mean action noise std: 1.81
          Mean value_function loss: 71.9452
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 44.1857
                       Mean reward: 171.78
               Mean episode length: 217.91
    Episode_Reward/reaching_object: 0.8747
    Episode_Reward/rotating_object: 33.2872
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.06s
                      Time elapsed: 00:10:54
                               ETA: 00:42:34

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 47993 steps/s (collection: 1.927s, learning 0.121s)
             Mean action noise std: 1.82
          Mean value_function loss: 77.5158
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 44.2033
                       Mean reward: 215.18
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 0.8925
    Episode_Reward/rotating_object: 35.5795
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.05s
                      Time elapsed: 00:10:56
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 47765 steps/s (collection: 1.937s, learning 0.121s)
             Mean action noise std: 1.82
          Mean value_function loss: 75.4701
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.2235
                       Mean reward: 164.59
               Mean episode length: 211.50
    Episode_Reward/reaching_object: 0.8588
    Episode_Reward/rotating_object: 31.9496
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.06s
                      Time elapsed: 00:10:58
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 44588 steps/s (collection: 2.086s, learning 0.119s)
             Mean action noise std: 1.82
          Mean value_function loss: 77.0636
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 44.2383
                       Mean reward: 209.98
               Mean episode length: 230.43
    Episode_Reward/reaching_object: 0.8992
    Episode_Reward/rotating_object: 36.5042
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.20s
                      Time elapsed: 00:11:00
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 46924 steps/s (collection: 1.971s, learning 0.124s)
             Mean action noise std: 1.82
          Mean value_function loss: 77.2656
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.2553
                       Mean reward: 144.11
               Mean episode length: 204.41
    Episode_Reward/reaching_object: 0.8549
    Episode_Reward/rotating_object: 31.2783
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.09s
                      Time elapsed: 00:11:02
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 48155 steps/s (collection: 1.921s, learning 0.120s)
             Mean action noise std: 1.82
          Mean value_function loss: 72.2567
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 44.2665
                       Mean reward: 174.74
               Mean episode length: 220.02
    Episode_Reward/reaching_object: 0.8890
    Episode_Reward/rotating_object: 34.0333
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.04s
                      Time elapsed: 00:11:04
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 47300 steps/s (collection: 1.955s, learning 0.123s)
             Mean action noise std: 1.82
          Mean value_function loss: 74.8829
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.2867
                       Mean reward: 195.69
               Mean episode length: 225.89
    Episode_Reward/reaching_object: 0.8793
    Episode_Reward/rotating_object: 32.9782
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.08s
                      Time elapsed: 00:11:06
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 47534 steps/s (collection: 1.962s, learning 0.106s)
             Mean action noise std: 1.82
          Mean value_function loss: 72.5839
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 44.3021
                       Mean reward: 180.90
               Mean episode length: 213.39
    Episode_Reward/reaching_object: 0.8920
    Episode_Reward/rotating_object: 38.9753
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.07s
                      Time elapsed: 00:11:08
                               ETA: 00:42:18

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 46407 steps/s (collection: 1.958s, learning 0.161s)
             Mean action noise std: 1.83
          Mean value_function loss: 78.9777
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.3143
                       Mean reward: 215.56
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 0.9090
    Episode_Reward/rotating_object: 41.5873
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.12s
                      Time elapsed: 00:11:10
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 46814 steps/s (collection: 1.987s, learning 0.113s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.1094
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.3231
                       Mean reward: 204.42
               Mean episode length: 215.80
    Episode_Reward/reaching_object: 0.9056
    Episode_Reward/rotating_object: 42.6035
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.10s
                      Time elapsed: 00:11:13
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 46345 steps/s (collection: 1.923s, learning 0.198s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.7162
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 44.3347
                       Mean reward: 254.65
               Mean episode length: 217.17
    Episode_Reward/reaching_object: 0.8916
    Episode_Reward/rotating_object: 41.5791
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.12s
                      Time elapsed: 00:11:15
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 48101 steps/s (collection: 1.905s, learning 0.139s)
             Mean action noise std: 1.83
          Mean value_function loss: 86.7684
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.3420
                       Mean reward: 181.56
               Mean episode length: 208.08
    Episode_Reward/reaching_object: 0.9074
    Episode_Reward/rotating_object: 39.0137
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.04s
                      Time elapsed: 00:11:17
                               ETA: 00:42:09

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 48339 steps/s (collection: 1.912s, learning 0.122s)
             Mean action noise std: 1.83
          Mean value_function loss: 84.3536
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.3535
                       Mean reward: 219.61
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 0.9233
    Episode_Reward/rotating_object: 40.9848
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.03s
                      Time elapsed: 00:11:19
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 48794 steps/s (collection: 1.914s, learning 0.101s)
             Mean action noise std: 1.83
          Mean value_function loss: 84.5741
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.3682
                       Mean reward: 217.97
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 0.8830
    Episode_Reward/rotating_object: 39.9172
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.01s
                      Time elapsed: 00:11:21
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 48289 steps/s (collection: 1.901s, learning 0.135s)
             Mean action noise std: 1.83
          Mean value_function loss: 76.2735
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 44.3792
                       Mean reward: 212.65
               Mean episode length: 216.83
    Episode_Reward/reaching_object: 0.9130
    Episode_Reward/rotating_object: 42.0840
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.04s
                      Time elapsed: 00:11:23
                               ETA: 00:42:01

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 47756 steps/s (collection: 1.937s, learning 0.121s)
             Mean action noise std: 1.83
          Mean value_function loss: 76.7041
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.3871
                       Mean reward: 222.85
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 0.8885
    Episode_Reward/rotating_object: 41.9824
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.06s
                      Time elapsed: 00:11:25
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 48506 steps/s (collection: 1.922s, learning 0.105s)
             Mean action noise std: 1.83
          Mean value_function loss: 77.2278
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.3987
                       Mean reward: 258.23
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 0.9248
    Episode_Reward/rotating_object: 43.7020
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.03s
                      Time elapsed: 00:11:27
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 46948 steps/s (collection: 1.955s, learning 0.139s)
             Mean action noise std: 1.83
          Mean value_function loss: 84.7376
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.4058
                       Mean reward: 201.62
               Mean episode length: 217.30
    Episode_Reward/reaching_object: 0.8833
    Episode_Reward/rotating_object: 39.9920
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.09s
                      Time elapsed: 00:11:29
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 48886 steps/s (collection: 1.890s, learning 0.121s)
             Mean action noise std: 1.84
          Mean value_function loss: 83.6389
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.4191
                       Mean reward: 203.39
               Mean episode length: 217.22
    Episode_Reward/reaching_object: 0.9045
    Episode_Reward/rotating_object: 41.0785
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.01s
                      Time elapsed: 00:11:31
                               ETA: 00:41:51

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 47191 steps/s (collection: 1.951s, learning 0.132s)
             Mean action noise std: 1.84
          Mean value_function loss: 74.9401
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.4353
                       Mean reward: 225.27
               Mean episode length: 222.17
    Episode_Reward/reaching_object: 0.9138
    Episode_Reward/rotating_object: 44.3570
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.08s
                      Time elapsed: 00:11:33
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 47976 steps/s (collection: 1.902s, learning 0.147s)
             Mean action noise std: 1.84
          Mean value_function loss: 79.4014
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.4480
                       Mean reward: 236.77
               Mean episode length: 225.46
    Episode_Reward/reaching_object: 0.9018
    Episode_Reward/rotating_object: 43.4344
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0211
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.05s
                      Time elapsed: 00:11:35
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 48171 steps/s (collection: 1.928s, learning 0.113s)
             Mean action noise std: 1.84
          Mean value_function loss: 73.7792
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 44.4560
                       Mean reward: 262.65
               Mean episode length: 224.81
    Episode_Reward/reaching_object: 0.9222
    Episode_Reward/rotating_object: 50.0469
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.04s
                      Time elapsed: 00:11:37
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 46164 steps/s (collection: 1.934s, learning 0.196s)
             Mean action noise std: 1.84
          Mean value_function loss: 90.6136
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 44.4631
                       Mean reward: 252.72
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 0.9301
    Episode_Reward/rotating_object: 46.6212
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.13s
                      Time elapsed: 00:11:39
                               ETA: 00:41:42

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 48669 steps/s (collection: 1.915s, learning 0.104s)
             Mean action noise std: 1.84
          Mean value_function loss: 81.4769
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.4673
                       Mean reward: 271.65
               Mean episode length: 221.87
    Episode_Reward/reaching_object: 0.9083
    Episode_Reward/rotating_object: 47.7032
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.02s
                      Time elapsed: 00:11:41
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 48470 steps/s (collection: 1.929s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 81.7349
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.4716
                       Mean reward: 240.19
               Mean episode length: 221.92
    Episode_Reward/reaching_object: 0.9244
    Episode_Reward/rotating_object: 52.3895
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.03s
                      Time elapsed: 00:11:43
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 46669 steps/s (collection: 2.011s, learning 0.096s)
             Mean action noise std: 1.84
          Mean value_function loss: 80.9722
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.4786
                       Mean reward: 219.21
               Mean episode length: 216.61
    Episode_Reward/reaching_object: 0.9273
    Episode_Reward/rotating_object: 49.1689
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.11s
                      Time elapsed: 00:11:45
                               ETA: 00:41:35

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 46376 steps/s (collection: 1.959s, learning 0.161s)
             Mean action noise std: 1.84
          Mean value_function loss: 79.5016
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.4855
                       Mean reward: 267.68
               Mean episode length: 220.43
    Episode_Reward/reaching_object: 0.9216
    Episode_Reward/rotating_object: 49.0546
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.12s
                      Time elapsed: 00:11:48
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 45368 steps/s (collection: 1.975s, learning 0.192s)
             Mean action noise std: 1.84
          Mean value_function loss: 82.3301
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 44.4910
                       Mean reward: 286.89
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 0.9277
    Episode_Reward/rotating_object: 48.9207
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.17s
                      Time elapsed: 00:11:50
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19598 steps/s (collection: 4.884s, learning 0.132s)
             Mean action noise std: 1.84
          Mean value_function loss: 83.2307
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 44.5032
                       Mean reward: 214.91
               Mean episode length: 217.46
    Episode_Reward/reaching_object: 0.9246
    Episode_Reward/rotating_object: 47.0556
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 5.02s
                      Time elapsed: 00:11:55
                               ETA: 00:41:38

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14905 steps/s (collection: 6.474s, learning 0.121s)
             Mean action noise std: 1.84
          Mean value_function loss: 85.7036
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.5165
                       Mean reward: 265.06
               Mean episode length: 216.84
    Episode_Reward/reaching_object: 0.9347
    Episode_Reward/rotating_object: 50.8482
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.60s
                      Time elapsed: 00:12:01
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 14645 steps/s (collection: 6.575s, learning 0.137s)
             Mean action noise std: 1.85
          Mean value_function loss: 87.1856
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.5321
                       Mean reward: 223.00
               Mean episode length: 224.85
    Episode_Reward/reaching_object: 0.9602
    Episode_Reward/rotating_object: 49.2969
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.71s
                      Time elapsed: 00:12:08
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14755 steps/s (collection: 6.539s, learning 0.123s)
             Mean action noise std: 1.85
          Mean value_function loss: 79.8067
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.5462
                       Mean reward: 279.47
               Mean episode length: 228.15
    Episode_Reward/reaching_object: 0.9580
    Episode_Reward/rotating_object: 55.9598
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.66s
                      Time elapsed: 00:12:15
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14793 steps/s (collection: 6.505s, learning 0.140s)
             Mean action noise std: 1.85
          Mean value_function loss: 79.0188
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.5562
                       Mean reward: 252.72
               Mean episode length: 234.62
    Episode_Reward/reaching_object: 0.9360
    Episode_Reward/rotating_object: 49.5318
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.64s
                      Time elapsed: 00:12:21
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14900 steps/s (collection: 6.477s, learning 0.121s)
             Mean action noise std: 1.85
          Mean value_function loss: 80.4694
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.5618
                       Mean reward: 275.85
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 0.9656
    Episode_Reward/rotating_object: 54.3714
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.60s
                      Time elapsed: 00:12:28
                               ETA: 00:42:45

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 15319 steps/s (collection: 6.281s, learning 0.136s)
             Mean action noise std: 1.85
          Mean value_function loss: 88.3009
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.5692
                       Mean reward: 242.01
               Mean episode length: 220.71
    Episode_Reward/reaching_object: 0.9192
    Episode_Reward/rotating_object: 49.9141
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.42s
                      Time elapsed: 00:12:34
                               ETA: 00:42:57

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 14746 steps/s (collection: 6.537s, learning 0.129s)
             Mean action noise std: 1.85
          Mean value_function loss: 83.4360
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.5781
                       Mean reward: 253.39
               Mean episode length: 227.32
    Episode_Reward/reaching_object: 0.9417
    Episode_Reward/rotating_object: 52.2994
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 6.67s
                      Time elapsed: 00:12:41
                               ETA: 00:43:10

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13052 steps/s (collection: 7.396s, learning 0.135s)
             Mean action noise std: 1.85
          Mean value_function loss: 89.8697
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 44.5880
                       Mean reward: 254.39
               Mean episode length: 224.45
    Episode_Reward/reaching_object: 0.9581
    Episode_Reward/rotating_object: 54.0303
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.53s
                      Time elapsed: 00:12:49
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 51349 steps/s (collection: 1.825s, learning 0.089s)
             Mean action noise std: 1.85
          Mean value_function loss: 94.2819
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 44.6015
                       Mean reward: 245.35
               Mean episode length: 218.51
    Episode_Reward/reaching_object: 0.9475
    Episode_Reward/rotating_object: 54.7347
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.91s
                      Time elapsed: 00:12:50
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 52203 steps/s (collection: 1.778s, learning 0.105s)
             Mean action noise std: 1.85
          Mean value_function loss: 108.0471
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.6093
                       Mean reward: 283.05
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 0.9329
    Episode_Reward/rotating_object: 52.7319
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.88s
                      Time elapsed: 00:12:52
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 49990 steps/s (collection: 1.851s, learning 0.116s)
             Mean action noise std: 1.85
          Mean value_function loss: 125.7605
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.6189
                       Mean reward: 237.12
               Mean episode length: 219.29
    Episode_Reward/reaching_object: 0.9670
    Episode_Reward/rotating_object: 53.1159
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.97s
                      Time elapsed: 00:12:54
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 50200 steps/s (collection: 1.820s, learning 0.138s)
             Mean action noise std: 1.85
          Mean value_function loss: 125.0188
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.6298
                       Mean reward: 296.89
               Mean episode length: 226.34
    Episode_Reward/reaching_object: 0.9593
    Episode_Reward/rotating_object: 53.3240
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.96s
                      Time elapsed: 00:12:56
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 49398 steps/s (collection: 1.804s, learning 0.186s)
             Mean action noise std: 1.85
          Mean value_function loss: 124.3613
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 44.6369
                       Mean reward: 272.88
               Mean episode length: 218.06
    Episode_Reward/reaching_object: 0.9558
    Episode_Reward/rotating_object: 53.0131
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.99s
                      Time elapsed: 00:12:58
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 51638 steps/s (collection: 1.806s, learning 0.098s)
             Mean action noise std: 1.86
          Mean value_function loss: 105.2042
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.6457
                       Mean reward: 308.25
               Mean episode length: 226.33
    Episode_Reward/reaching_object: 0.9625
    Episode_Reward/rotating_object: 55.0691
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.90s
                      Time elapsed: 00:13:00
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 50974 steps/s (collection: 1.824s, learning 0.105s)
             Mean action noise std: 1.86
          Mean value_function loss: 113.1422
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.6497
                       Mean reward: 268.99
               Mean episode length: 221.41
    Episode_Reward/reaching_object: 0.9832
    Episode_Reward/rotating_object: 53.3471
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.93s
                      Time elapsed: 00:13:02
                               ETA: 00:43:03

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 50659 steps/s (collection: 1.850s, learning 0.091s)
             Mean action noise std: 1.86
          Mean value_function loss: 110.3848
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.6543
                       Mean reward: 279.34
               Mean episode length: 218.88
    Episode_Reward/reaching_object: 0.9847
    Episode_Reward/rotating_object: 58.1205
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.94s
                      Time elapsed: 00:13:04
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 51181 steps/s (collection: 1.823s, learning 0.097s)
             Mean action noise std: 1.86
          Mean value_function loss: 103.2591
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 44.6597
                       Mean reward: 296.96
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 0.9858
    Episode_Reward/rotating_object: 57.0659
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.92s
                      Time elapsed: 00:13:06
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 51149 steps/s (collection: 1.825s, learning 0.097s)
             Mean action noise std: 1.86
          Mean value_function loss: 98.1281
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.6649
                       Mean reward: 312.30
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 0.9740
    Episode_Reward/rotating_object: 55.9961
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.92s
                      Time elapsed: 00:13:08
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 52187 steps/s (collection: 1.796s, learning 0.088s)
             Mean action noise std: 1.86
          Mean value_function loss: 99.9752
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 44.6720
                       Mean reward: 272.93
               Mean episode length: 203.50
    Episode_Reward/reaching_object: 0.9672
    Episode_Reward/rotating_object: 57.9179
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.88s
                      Time elapsed: 00:13:10
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 50334 steps/s (collection: 1.831s, learning 0.122s)
             Mean action noise std: 1.86
          Mean value_function loss: 100.2311
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.6769
                       Mean reward: 266.69
               Mean episode length: 204.39
    Episode_Reward/reaching_object: 0.9469
    Episode_Reward/rotating_object: 59.3937
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.95s
                      Time elapsed: 00:13:12
                               ETA: 00:42:46

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 50474 steps/s (collection: 1.851s, learning 0.097s)
             Mean action noise std: 1.86
          Mean value_function loss: 103.3500
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.6796
                       Mean reward: 316.09
               Mean episode length: 219.13
    Episode_Reward/reaching_object: 0.9732
    Episode_Reward/rotating_object: 62.0518
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.95s
                      Time elapsed: 00:13:14
                               ETA: 00:42:43

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 51405 steps/s (collection: 1.817s, learning 0.095s)
             Mean action noise std: 1.86
          Mean value_function loss: 103.8861
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.6883
                       Mean reward: 331.89
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 0.9372
    Episode_Reward/rotating_object: 61.4141
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.91s
                      Time elapsed: 00:13:16
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 52956 steps/s (collection: 1.758s, learning 0.099s)
             Mean action noise std: 1.86
          Mean value_function loss: 112.6387
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.6993
                       Mean reward: 339.40
               Mean episode length: 221.71
    Episode_Reward/reaching_object: 0.9739
    Episode_Reward/rotating_object: 61.7325
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.86s
                      Time elapsed: 00:13:17
                               ETA: 00:42:36

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 51911 steps/s (collection: 1.791s, learning 0.103s)
             Mean action noise std: 1.86
          Mean value_function loss: 115.1796
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.7034
                       Mean reward: 340.18
               Mean episode length: 228.27
    Episode_Reward/reaching_object: 0.9684
    Episode_Reward/rotating_object: 64.4020
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.89s
                      Time elapsed: 00:13:19
                               ETA: 00:42:33

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 52063 steps/s (collection: 1.755s, learning 0.134s)
             Mean action noise std: 1.86
          Mean value_function loss: 108.7515
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.7104
                       Mean reward: 295.26
               Mean episode length: 212.82
    Episode_Reward/reaching_object: 0.9463
    Episode_Reward/rotating_object: 62.5862
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.89s
                      Time elapsed: 00:13:21
                               ETA: 00:42:30

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 51854 steps/s (collection: 1.769s, learning 0.127s)
             Mean action noise std: 1.86
          Mean value_function loss: 123.1265
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.7192
                       Mean reward: 343.11
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 0.9792
    Episode_Reward/rotating_object: 63.7914
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.90s
                      Time elapsed: 00:13:23
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 49628 steps/s (collection: 1.797s, learning 0.184s)
             Mean action noise std: 1.86
          Mean value_function loss: 126.2360
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 44.7297
                       Mean reward: 321.05
               Mean episode length: 222.76
    Episode_Reward/reaching_object: 0.9577
    Episode_Reward/rotating_object: 65.2920
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.98s
                      Time elapsed: 00:13:25
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 52019 steps/s (collection: 1.795s, learning 0.095s)
             Mean action noise std: 1.86
          Mean value_function loss: 105.4511
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.7403
                       Mean reward: 346.71
               Mean episode length: 226.23
    Episode_Reward/reaching_object: 0.9567
    Episode_Reward/rotating_object: 63.4014
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.89s
                      Time elapsed: 00:13:27
                               ETA: 00:42:20

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 50511 steps/s (collection: 1.839s, learning 0.107s)
             Mean action noise std: 1.87
          Mean value_function loss: 120.5834
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.7524
                       Mean reward: 332.44
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 0.9585
    Episode_Reward/rotating_object: 64.0001
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.95s
                      Time elapsed: 00:13:29
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 51776 steps/s (collection: 1.808s, learning 0.091s)
             Mean action noise std: 1.87
          Mean value_function loss: 118.5530
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 44.7585
                       Mean reward: 354.85
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 0.9783
    Episode_Reward/rotating_object: 69.1098
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.90s
                      Time elapsed: 00:13:31
                               ETA: 00:42:14

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 50065 steps/s (collection: 1.808s, learning 0.155s)
             Mean action noise std: 1.87
          Mean value_function loss: 120.4662
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.7618
                       Mean reward: 347.34
               Mean episode length: 219.36
    Episode_Reward/reaching_object: 0.9810
    Episode_Reward/rotating_object: 68.0298
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.96s
                      Time elapsed: 00:13:33
                               ETA: 00:42:11

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 50984 steps/s (collection: 1.836s, learning 0.092s)
             Mean action noise std: 1.87
          Mean value_function loss: 123.1568
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.7629
                       Mean reward: 325.63
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 0.9828
    Episode_Reward/rotating_object: 68.8236
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.93s
                      Time elapsed: 00:13:35
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 47951 steps/s (collection: 1.954s, learning 0.096s)
             Mean action noise std: 1.87
          Mean value_function loss: 130.8697
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.7662
                       Mean reward: 374.08
               Mean episode length: 222.51
    Episode_Reward/reaching_object: 0.9817
    Episode_Reward/rotating_object: 71.0946
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.05s
                      Time elapsed: 00:13:37
                               ETA: 00:42:05

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 51584 steps/s (collection: 1.806s, learning 0.100s)
             Mean action noise std: 1.87
          Mean value_function loss: 124.0728
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 44.7749
                       Mean reward: 352.41
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 0.9688
    Episode_Reward/rotating_object: 70.1876
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.91s
                      Time elapsed: 00:13:39
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 50299 steps/s (collection: 1.844s, learning 0.110s)
             Mean action noise std: 1.87
          Mean value_function loss: 126.3095
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.7842
                       Mean reward: 351.66
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 0.9607
    Episode_Reward/rotating_object: 68.5446
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.95s
                      Time elapsed: 00:13:41
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 51898 steps/s (collection: 1.803s, learning 0.092s)
             Mean action noise std: 1.87
          Mean value_function loss: 132.9323
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.7925
                       Mean reward: 301.44
               Mean episode length: 209.87
    Episode_Reward/reaching_object: 0.9573
    Episode_Reward/rotating_object: 70.9533
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.89s
                      Time elapsed: 00:13:43
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 51472 steps/s (collection: 1.772s, learning 0.138s)
             Mean action noise std: 1.87
          Mean value_function loss: 121.9717
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.7956
                       Mean reward: 336.25
               Mean episode length: 210.95
    Episode_Reward/reaching_object: 0.9550
    Episode_Reward/rotating_object: 69.4517
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.91s
                      Time elapsed: 00:13:44
                               ETA: 00:41:52

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 50563 steps/s (collection: 1.826s, learning 0.118s)
             Mean action noise std: 1.87
          Mean value_function loss: 124.2391
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.8023
                       Mean reward: 380.46
               Mean episode length: 224.78
    Episode_Reward/reaching_object: 0.9644
    Episode_Reward/rotating_object: 69.4610
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.94s
                      Time elapsed: 00:13:46
                               ETA: 00:41:49

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 51495 steps/s (collection: 1.792s, learning 0.117s)
             Mean action noise std: 1.87
          Mean value_function loss: 116.6481
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.8084
                       Mean reward: 371.21
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 0.9931
    Episode_Reward/rotating_object: 75.2734
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.91s
                      Time elapsed: 00:13:48
                               ETA: 00:41:46

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 50726 steps/s (collection: 1.815s, learning 0.123s)
             Mean action noise std: 1.87
          Mean value_function loss: 112.4460
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.8128
                       Mean reward: 381.58
               Mean episode length: 225.94
    Episode_Reward/reaching_object: 0.9559
    Episode_Reward/rotating_object: 74.5095
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.94s
                      Time elapsed: 00:13:50
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 48887 steps/s (collection: 1.853s, learning 0.158s)
             Mean action noise std: 1.87
          Mean value_function loss: 112.2290
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.8207
                       Mean reward: 350.02
               Mean episode length: 225.10
    Episode_Reward/reaching_object: 0.9640
    Episode_Reward/rotating_object: 70.4872
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.01s
                      Time elapsed: 00:13:52
                               ETA: 00:41:40

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 50964 steps/s (collection: 1.843s, learning 0.086s)
             Mean action noise std: 1.87
          Mean value_function loss: 114.7794
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.8308
                       Mean reward: 343.85
               Mean episode length: 210.05
    Episode_Reward/reaching_object: 0.9488
    Episode_Reward/rotating_object: 70.7144
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.93s
                      Time elapsed: 00:13:54
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 51399 steps/s (collection: 1.822s, learning 0.090s)
             Mean action noise std: 1.87
          Mean value_function loss: 118.1614
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.8373
                       Mean reward: 333.33
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.0017
    Episode_Reward/rotating_object: 74.7909
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.91s
                      Time elapsed: 00:13:56
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 50249 steps/s (collection: 1.816s, learning 0.141s)
             Mean action noise std: 1.87
          Mean value_function loss: 113.8339
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.8404
                       Mean reward: 411.24
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 0.9793
    Episode_Reward/rotating_object: 77.3154
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.96s
                      Time elapsed: 00:13:58
                               ETA: 00:41:31

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 51018 steps/s (collection: 1.836s, learning 0.091s)
             Mean action noise std: 1.88
          Mean value_function loss: 115.8350
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.8497
                       Mean reward: 387.62
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 0.9778
    Episode_Reward/rotating_object: 75.7539
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.93s
                      Time elapsed: 00:14:00
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 51552 steps/s (collection: 1.801s, learning 0.105s)
             Mean action noise std: 1.88
          Mean value_function loss: 116.1525
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.8598
                       Mean reward: 407.55
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 0.9834
    Episode_Reward/rotating_object: 75.7940
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.91s
                      Time elapsed: 00:14:02
                               ETA: 00:41:24

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 51002 steps/s (collection: 1.836s, learning 0.091s)
             Mean action noise std: 1.88
          Mean value_function loss: 126.1161
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 44.8638
                       Mean reward: 365.57
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 0.9788
    Episode_Reward/rotating_object: 73.6279
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.93s
                      Time elapsed: 00:14:04
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 52032 steps/s (collection: 1.791s, learning 0.099s)
             Mean action noise std: 1.88
          Mean value_function loss: 113.6453
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 44.8701
                       Mean reward: 393.35
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 0.9885
    Episode_Reward/rotating_object: 77.4286
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.89s
                      Time elapsed: 00:14:06
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 51823 steps/s (collection: 1.809s, learning 0.088s)
             Mean action noise std: 1.88
          Mean value_function loss: 116.6031
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 44.8784
                       Mean reward: 401.16
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 0.9944
    Episode_Reward/rotating_object: 71.6701
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.90s
                      Time elapsed: 00:14:08
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 52221 steps/s (collection: 1.794s, learning 0.089s)
             Mean action noise std: 1.88
          Mean value_function loss: 104.7833
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.8838
                       Mean reward: 337.95
               Mean episode length: 215.05
    Episode_Reward/reaching_object: 0.9777
    Episode_Reward/rotating_object: 73.5853
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.88s
                      Time elapsed: 00:14:09
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 50663 steps/s (collection: 1.847s, learning 0.093s)
             Mean action noise std: 1.88
          Mean value_function loss: 122.9868
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.8872
                       Mean reward: 374.44
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 0.9754
    Episode_Reward/rotating_object: 72.1055
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.94s
                      Time elapsed: 00:14:11
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 51870 steps/s (collection: 1.781s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 118.4869
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.8891
                       Mean reward: 397.93
               Mean episode length: 226.55
    Episode_Reward/reaching_object: 0.9726
    Episode_Reward/rotating_object: 76.1561
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.90s
                      Time elapsed: 00:14:13
                               ETA: 00:41:06

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 50914 steps/s (collection: 1.807s, learning 0.124s)
             Mean action noise std: 1.88
          Mean value_function loss: 127.8049
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.8913
                       Mean reward: 415.40
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 1.0048
    Episode_Reward/rotating_object: 78.3979
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.93s
                      Time elapsed: 00:14:15
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 50872 steps/s (collection: 1.829s, learning 0.103s)
             Mean action noise std: 1.88
          Mean value_function loss: 115.1959
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.8942
                       Mean reward: 393.24
               Mean episode length: 227.07
    Episode_Reward/reaching_object: 0.9788
    Episode_Reward/rotating_object: 78.6820
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.93s
                      Time elapsed: 00:14:17
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 52007 steps/s (collection: 1.797s, learning 0.093s)
             Mean action noise std: 1.88
          Mean value_function loss: 112.2986
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.8990
                       Mean reward: 386.40
               Mean episode length: 229.02
    Episode_Reward/reaching_object: 0.9744
    Episode_Reward/rotating_object: 78.3050
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.89s
                      Time elapsed: 00:14:19
                               ETA: 00:40:57

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 50664 steps/s (collection: 1.843s, learning 0.097s)
             Mean action noise std: 1.88
          Mean value_function loss: 117.5649
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.9045
                       Mean reward: 391.46
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 0.9756
    Episode_Reward/rotating_object: 78.4205
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.94s
                      Time elapsed: 00:14:21
                               ETA: 00:40:54

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 51445 steps/s (collection: 1.823s, learning 0.088s)
             Mean action noise std: 1.88
          Mean value_function loss: 121.6131
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 44.9079
                       Mean reward: 400.18
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 0.9886
    Episode_Reward/rotating_object: 81.7153
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.91s
                      Time elapsed: 00:14:23
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 52007 steps/s (collection: 1.795s, learning 0.095s)
             Mean action noise std: 1.88
          Mean value_function loss: 126.8070
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.9127
                       Mean reward: 431.53
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 0.9874
    Episode_Reward/rotating_object: 82.9908
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.89s
                      Time elapsed: 00:14:25
                               ETA: 00:40:47

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 52411 steps/s (collection: 1.782s, learning 0.094s)
             Mean action noise std: 1.88
          Mean value_function loss: 138.1881
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.9211
                       Mean reward: 419.09
               Mean episode length: 224.52
    Episode_Reward/reaching_object: 0.9830
    Episode_Reward/rotating_object: 80.2881
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.88s
                      Time elapsed: 00:14:27
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 45372 steps/s (collection: 2.075s, learning 0.092s)
             Mean action noise std: 1.88
          Mean value_function loss: 146.5888
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.9302
                       Mean reward: 378.87
               Mean episode length: 227.26
    Episode_Reward/reaching_object: 0.9913
    Episode_Reward/rotating_object: 79.6751
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.17s
                      Time elapsed: 00:14:29
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 52348 steps/s (collection: 1.785s, learning 0.093s)
             Mean action noise std: 1.88
          Mean value_function loss: 142.8770
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 44.9373
                       Mean reward: 369.45
               Mean episode length: 217.95
    Episode_Reward/reaching_object: 0.9775
    Episode_Reward/rotating_object: 76.6581
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.88s
                      Time elapsed: 00:14:31
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 49981 steps/s (collection: 1.863s, learning 0.104s)
             Mean action noise std: 1.88
          Mean value_function loss: 144.7829
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.9406
                       Mean reward: 417.22
               Mean episode length: 224.81
    Episode_Reward/reaching_object: 1.0085
    Episode_Reward/rotating_object: 84.1166
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.97s
                      Time elapsed: 00:14:33
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 50071 steps/s (collection: 1.840s, learning 0.123s)
             Mean action noise std: 1.88
          Mean value_function loss: 131.9330
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.9427
                       Mean reward: 387.73
               Mean episode length: 223.49
    Episode_Reward/reaching_object: 1.0202
    Episode_Reward/rotating_object: 81.4669
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.96s
                      Time elapsed: 00:14:35
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 50240 steps/s (collection: 1.814s, learning 0.143s)
             Mean action noise std: 1.88
          Mean value_function loss: 130.1589
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.9459
                       Mean reward: 391.48
               Mean episode length: 214.99
    Episode_Reward/reaching_object: 0.9915
    Episode_Reward/rotating_object: 79.0076
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.96s
                      Time elapsed: 00:14:37
                               ETA: 00:40:30

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 50502 steps/s (collection: 1.799s, learning 0.148s)
             Mean action noise std: 1.89
          Mean value_function loss: 125.0616
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.9573
                       Mean reward: 422.30
               Mean episode length: 224.74
    Episode_Reward/reaching_object: 0.9900
    Episode_Reward/rotating_object: 82.8008
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.95s
                      Time elapsed: 00:14:39
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 49115 steps/s (collection: 1.892s, learning 0.110s)
             Mean action noise std: 1.89
          Mean value_function loss: 122.9456
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.9703
                       Mean reward: 431.25
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.0282
    Episode_Reward/rotating_object: 82.9827
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.00s
                      Time elapsed: 00:14:41
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 50333 steps/s (collection: 1.823s, learning 0.130s)
             Mean action noise std: 1.89
          Mean value_function loss: 124.4187
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.9760
                       Mean reward: 453.52
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.0381
    Episode_Reward/rotating_object: 86.5823
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.95s
                      Time elapsed: 00:14:42
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 49381 steps/s (collection: 1.903s, learning 0.088s)
             Mean action noise std: 1.89
          Mean value_function loss: 123.9388
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 44.9834
                       Mean reward: 429.14
               Mean episode length: 226.36
    Episode_Reward/reaching_object: 1.0255
    Episode_Reward/rotating_object: 87.5744
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.99s
                      Time elapsed: 00:14:44
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 50822 steps/s (collection: 1.808s, learning 0.126s)
             Mean action noise std: 1.89
          Mean value_function loss: 122.5073
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 44.9930
                       Mean reward: 432.80
               Mean episode length: 226.28
    Episode_Reward/reaching_object: 1.0052
    Episode_Reward/rotating_object: 87.5980
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.93s
                      Time elapsed: 00:14:46
                               ETA: 00:40:16

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 49608 steps/s (collection: 1.851s, learning 0.131s)
             Mean action noise std: 1.89
          Mean value_function loss: 110.3361
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 44.9984
                       Mean reward: 431.80
               Mean episode length: 226.72
    Episode_Reward/reaching_object: 0.9953
    Episode_Reward/rotating_object: 82.3019
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.98s
                      Time elapsed: 00:14:48
                               ETA: 00:40:13

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 49221 steps/s (collection: 1.856s, learning 0.141s)
             Mean action noise std: 1.89
          Mean value_function loss: 107.6124
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.0015
                       Mean reward: 446.37
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 0.9854
    Episode_Reward/rotating_object: 84.8895
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.00s
                      Time elapsed: 00:14:50
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 50730 steps/s (collection: 1.822s, learning 0.116s)
             Mean action noise std: 1.89
          Mean value_function loss: 122.3814
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.0080
                       Mean reward: 413.22
               Mean episode length: 226.10
    Episode_Reward/reaching_object: 0.9646
    Episode_Reward/rotating_object: 79.9803
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.94s
                      Time elapsed: 00:14:52
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 51205 steps/s (collection: 1.816s, learning 0.103s)
             Mean action noise std: 1.89
          Mean value_function loss: 129.1554
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.0165
                       Mean reward: 465.20
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 0.9859
    Episode_Reward/rotating_object: 85.6228
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.92s
                      Time elapsed: 00:14:54
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 48332 steps/s (collection: 1.884s, learning 0.150s)
             Mean action noise std: 1.89
          Mean value_function loss: 134.6263
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.0201
                       Mean reward: 474.70
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 0.9656
    Episode_Reward/rotating_object: 88.9277
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.03s
                      Time elapsed: 00:14:56
                               ETA: 00:40:02

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 49676 steps/s (collection: 1.869s, learning 0.110s)
             Mean action noise std: 1.89
          Mean value_function loss: 122.2706
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.0215
                       Mean reward: 400.84
               Mean episode length: 217.87
    Episode_Reward/reaching_object: 0.9754
    Episode_Reward/rotating_object: 81.8300
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.98s
                      Time elapsed: 00:14:58
                               ETA: 00:39:59

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 51406 steps/s (collection: 1.814s, learning 0.098s)
             Mean action noise std: 1.89
          Mean value_function loss: 123.9154
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.0239
                       Mean reward: 479.39
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 1.0142
    Episode_Reward/rotating_object: 88.3309
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.91s
                      Time elapsed: 00:15:00
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 51190 steps/s (collection: 1.816s, learning 0.104s)
             Mean action noise std: 1.89
          Mean value_function loss: 123.6030
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.0275
                       Mean reward: 403.81
               Mean episode length: 216.22
    Episode_Reward/reaching_object: 0.9752
    Episode_Reward/rotating_object: 80.6618
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.92s
                      Time elapsed: 00:15:02
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 50599 steps/s (collection: 1.842s, learning 0.101s)
             Mean action noise std: 1.89
          Mean value_function loss: 127.7470
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.0351
                       Mean reward: 447.60
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 0.9922
    Episode_Reward/rotating_object: 86.3620
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.94s
                      Time elapsed: 00:15:04
                               ETA: 00:39:50

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 51465 steps/s (collection: 1.814s, learning 0.097s)
             Mean action noise std: 1.89
          Mean value_function loss: 122.0984
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 45.0420
                       Mean reward: 485.68
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 1.0075
    Episode_Reward/rotating_object: 88.5475
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.91s
                      Time elapsed: 00:15:06
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 49793 steps/s (collection: 1.872s, learning 0.102s)
             Mean action noise std: 1.89
          Mean value_function loss: 128.2607
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.0442
                       Mean reward: 432.44
               Mean episode length: 215.26
    Episode_Reward/reaching_object: 0.9730
    Episode_Reward/rotating_object: 86.1730
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.97s
                      Time elapsed: 00:15:08
                               ETA: 00:39:45

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 50586 steps/s (collection: 1.828s, learning 0.115s)
             Mean action noise std: 1.89
          Mean value_function loss: 122.0682
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 45.0495
                       Mean reward: 465.63
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 0.9952
    Episode_Reward/rotating_object: 86.9983
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.94s
                      Time elapsed: 00:15:10
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 50604 steps/s (collection: 1.830s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 130.2407
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.0578
                       Mean reward: 433.55
               Mean episode length: 221.21
    Episode_Reward/reaching_object: 0.9778
    Episode_Reward/rotating_object: 84.7030
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.94s
                      Time elapsed: 00:15:12
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 50825 steps/s (collection: 1.846s, learning 0.089s)
             Mean action noise std: 1.90
          Mean value_function loss: 129.0514
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.0623
                       Mean reward: 445.87
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 0.9627
    Episode_Reward/rotating_object: 88.7805
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.93s
                      Time elapsed: 00:15:14
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 49586 steps/s (collection: 1.855s, learning 0.127s)
             Mean action noise std: 1.90
          Mean value_function loss: 119.2915
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 45.0664
                       Mean reward: 427.44
               Mean episode length: 227.00
    Episode_Reward/reaching_object: 1.0065
    Episode_Reward/rotating_object: 89.0535
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.98s
                      Time elapsed: 00:15:16
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 49037 steps/s (collection: 1.880s, learning 0.125s)
             Mean action noise std: 1.90
          Mean value_function loss: 115.4617
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.0729
                       Mean reward: 426.30
               Mean episode length: 220.38
    Episode_Reward/reaching_object: 0.9641
    Episode_Reward/rotating_object: 83.1614
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.00s
                      Time elapsed: 00:15:18
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 50933 steps/s (collection: 1.821s, learning 0.109s)
             Mean action noise std: 1.90
          Mean value_function loss: 126.8693
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.0790
                       Mean reward: 451.84
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 0.9767
    Episode_Reward/rotating_object: 89.1027
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.93s
                      Time elapsed: 00:15:20
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 51055 steps/s (collection: 1.822s, learning 0.104s)
             Mean action noise std: 1.90
          Mean value_function loss: 122.1177
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.0834
                       Mean reward: 380.07
               Mean episode length: 219.13
    Episode_Reward/reaching_object: 0.9728
    Episode_Reward/rotating_object: 87.4200
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.93s
                      Time elapsed: 00:15:22
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 49743 steps/s (collection: 1.841s, learning 0.135s)
             Mean action noise std: 1.90
          Mean value_function loss: 129.0205
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 45.0863
                       Mean reward: 481.68
               Mean episode length: 232.32
    Episode_Reward/reaching_object: 0.9721
    Episode_Reward/rotating_object: 85.9483
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.98s
                      Time elapsed: 00:15:24
                               ETA: 00:39:22

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 51270 steps/s (collection: 1.826s, learning 0.092s)
             Mean action noise std: 1.90
          Mean value_function loss: 120.3153
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.0899
                       Mean reward: 425.34
               Mean episode length: 214.21
    Episode_Reward/reaching_object: 0.9642
    Episode_Reward/rotating_object: 86.8382
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.92s
                      Time elapsed: 00:15:25
                               ETA: 00:39:19

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 52244 steps/s (collection: 1.779s, learning 0.103s)
             Mean action noise std: 1.90
          Mean value_function loss: 110.9554
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.0926
                       Mean reward: 440.29
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 0.9878
    Episode_Reward/rotating_object: 87.3895
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.88s
                      Time elapsed: 00:15:27
                               ETA: 00:39:16

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 52235 steps/s (collection: 1.792s, learning 0.090s)
             Mean action noise std: 1.90
          Mean value_function loss: 117.9398
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.0929
                       Mean reward: 432.73
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 0.9893
    Episode_Reward/rotating_object: 87.7926
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.88s
                      Time elapsed: 00:15:29
                               ETA: 00:39:13

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 50163 steps/s (collection: 1.841s, learning 0.119s)
             Mean action noise std: 1.90
          Mean value_function loss: 122.7631
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.0925
                       Mean reward: 431.84
               Mean episode length: 221.41
    Episode_Reward/reaching_object: 0.9713
    Episode_Reward/rotating_object: 89.8960
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.96s
                      Time elapsed: 00:15:31
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 51919 steps/s (collection: 1.797s, learning 0.096s)
             Mean action noise std: 1.90
          Mean value_function loss: 119.5669
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.0968
                       Mean reward: 470.35
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 0.9888
    Episode_Reward/rotating_object: 94.4492
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.89s
                      Time elapsed: 00:15:33
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 51313 steps/s (collection: 1.817s, learning 0.099s)
             Mean action noise std: 1.90
          Mean value_function loss: 121.0447
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.1052
                       Mean reward: 470.36
               Mean episode length: 232.68
    Episode_Reward/reaching_object: 1.0099
    Episode_Reward/rotating_object: 92.5971
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.92s
                      Time elapsed: 00:15:35
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 51896 steps/s (collection: 1.799s, learning 0.096s)
             Mean action noise std: 1.90
          Mean value_function loss: 116.1595
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.1139
                       Mean reward: 445.82
               Mean episode length: 228.75
    Episode_Reward/reaching_object: 0.9980
    Episode_Reward/rotating_object: 91.0089
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.89s
                      Time elapsed: 00:15:37
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 51555 steps/s (collection: 1.798s, learning 0.109s)
             Mean action noise std: 1.90
          Mean value_function loss: 121.7923
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.1219
                       Mean reward: 428.11
               Mean episode length: 221.77
    Episode_Reward/reaching_object: 1.0003
    Episode_Reward/rotating_object: 90.8038
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.91s
                      Time elapsed: 00:15:39
                               ETA: 00:38:59

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 50652 steps/s (collection: 1.801s, learning 0.140s)
             Mean action noise std: 1.90
          Mean value_function loss: 124.8152
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.1276
                       Mean reward: 464.71
               Mean episode length: 224.82
    Episode_Reward/reaching_object: 0.9932
    Episode_Reward/rotating_object: 92.9656
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.94s
                      Time elapsed: 00:15:41
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 51616 steps/s (collection: 1.815s, learning 0.089s)
             Mean action noise std: 1.90
          Mean value_function loss: 122.2899
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.1325
                       Mean reward: 486.60
               Mean episode length: 231.26
    Episode_Reward/reaching_object: 1.0136
    Episode_Reward/rotating_object: 96.2372
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.90s
                      Time elapsed: 00:15:43
                               ETA: 00:38:53

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 48293 steps/s (collection: 1.850s, learning 0.185s)
             Mean action noise std: 1.90
          Mean value_function loss: 115.1684
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 45.1336
                       Mean reward: 498.29
               Mean episode length: 237.04
    Episode_Reward/reaching_object: 0.9982
    Episode_Reward/rotating_object: 94.7967
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.04s
                      Time elapsed: 00:15:45
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 49903 steps/s (collection: 1.801s, learning 0.169s)
             Mean action noise std: 1.90
          Mean value_function loss: 114.5894
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.1398
                       Mean reward: 456.23
               Mean episode length: 229.32
    Episode_Reward/reaching_object: 1.0193
    Episode_Reward/rotating_object: 95.7687
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.97s
                      Time elapsed: 00:15:47
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 52053 steps/s (collection: 1.797s, learning 0.092s)
             Mean action noise std: 1.91
          Mean value_function loss: 117.0391
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.1488
                       Mean reward: 532.57
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.0148
    Episode_Reward/rotating_object: 98.7638
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.89s
                      Time elapsed: 00:15:49
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 50353 steps/s (collection: 1.847s, learning 0.106s)
             Mean action noise std: 1.91
          Mean value_function loss: 115.1073
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.1562
                       Mean reward: 481.25
               Mean episode length: 233.03
    Episode_Reward/reaching_object: 1.0325
    Episode_Reward/rotating_object: 98.7023
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.95s
                      Time elapsed: 00:15:51
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 52267 steps/s (collection: 1.784s, learning 0.097s)
             Mean action noise std: 1.91
          Mean value_function loss: 112.2117
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.1580
                       Mean reward: 503.34
               Mean episode length: 230.89
    Episode_Reward/reaching_object: 1.0345
    Episode_Reward/rotating_object: 99.1396
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.88s
                      Time elapsed: 00:15:52
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 50592 steps/s (collection: 1.816s, learning 0.128s)
             Mean action noise std: 1.91
          Mean value_function loss: 110.3123
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.1595
                       Mean reward: 506.12
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 98.6760
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.94s
                      Time elapsed: 00:15:54
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 50940 steps/s (collection: 1.822s, learning 0.107s)
             Mean action noise std: 1.91
          Mean value_function loss: 110.8048
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.1607
                       Mean reward: 493.05
               Mean episode length: 224.44
    Episode_Reward/reaching_object: 1.0132
    Episode_Reward/rotating_object: 97.9577
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.93s
                      Time elapsed: 00:15:56
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 49256 steps/s (collection: 1.891s, learning 0.105s)
             Mean action noise std: 1.91
          Mean value_function loss: 107.7986
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.1638
                       Mean reward: 491.24
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.0261
    Episode_Reward/rotating_object: 98.9906
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.00s
                      Time elapsed: 00:15:58
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 51065 steps/s (collection: 1.812s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 119.9299
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.1700
                       Mean reward: 503.29
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.0074
    Episode_Reward/rotating_object: 97.2433
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.93s
                      Time elapsed: 00:16:00
                               ETA: 00:38:29

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 50711 steps/s (collection: 1.823s, learning 0.115s)
             Mean action noise std: 1.91
          Mean value_function loss: 111.0581
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.1752
                       Mean reward: 507.75
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 1.0157
    Episode_Reward/rotating_object: 99.5517
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.94s
                      Time elapsed: 00:16:02
                               ETA: 00:38:26

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 50303 steps/s (collection: 1.856s, learning 0.099s)
             Mean action noise std: 1.91
          Mean value_function loss: 121.9031
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 45.1838
                       Mean reward: 483.25
               Mean episode length: 222.88
    Episode_Reward/reaching_object: 0.9886
    Episode_Reward/rotating_object: 98.3249
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.95s
                      Time elapsed: 00:16:04
                               ETA: 00:38:23

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 50657 steps/s (collection: 1.845s, learning 0.096s)
             Mean action noise std: 1.91
          Mean value_function loss: 122.6959
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.1929
                       Mean reward: 469.96
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 1.0223
    Episode_Reward/rotating_object: 97.9080
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.94s
                      Time elapsed: 00:16:06
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 50995 steps/s (collection: 1.811s, learning 0.117s)
             Mean action noise std: 1.91
          Mean value_function loss: 115.8261
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.2036
                       Mean reward: 517.90
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.0277
    Episode_Reward/rotating_object: 103.1241
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.93s
                      Time elapsed: 00:16:08
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 51048 steps/s (collection: 1.825s, learning 0.101s)
             Mean action noise std: 1.91
          Mean value_function loss: 112.9474
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 45.2112
                       Mean reward: 512.06
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.0256
    Episode_Reward/rotating_object: 102.1577
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.93s
                      Time elapsed: 00:16:10
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 50805 steps/s (collection: 1.812s, learning 0.123s)
             Mean action noise std: 1.91
          Mean value_function loss: 112.0837
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.2173
                       Mean reward: 535.52
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.0302
    Episode_Reward/rotating_object: 100.5327
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.93s
                      Time elapsed: 00:16:12
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 51742 steps/s (collection: 1.772s, learning 0.128s)
             Mean action noise std: 1.91
          Mean value_function loss: 107.3871
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.2207
                       Mean reward: 483.59
               Mean episode length: 215.00
    Episode_Reward/reaching_object: 1.0062
    Episode_Reward/rotating_object: 100.6197
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.90s
                      Time elapsed: 00:16:14
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 52138 steps/s (collection: 1.787s, learning 0.099s)
             Mean action noise std: 1.91
          Mean value_function loss: 111.7690
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.2256
                       Mean reward: 491.26
               Mean episode length: 226.25
    Episode_Reward/reaching_object: 0.9945
    Episode_Reward/rotating_object: 97.1612
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.89s
                      Time elapsed: 00:16:16
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 51278 steps/s (collection: 1.801s, learning 0.117s)
             Mean action noise std: 1.91
          Mean value_function loss: 99.1967
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.2282
                       Mean reward: 522.23
               Mean episode length: 236.42
    Episode_Reward/reaching_object: 1.0037
    Episode_Reward/rotating_object: 101.0325
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.92s
                      Time elapsed: 00:16:18
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 51008 steps/s (collection: 1.819s, learning 0.109s)
             Mean action noise std: 1.91
          Mean value_function loss: 108.5178
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.2350
                       Mean reward: 464.26
               Mean episode length: 227.52
    Episode_Reward/reaching_object: 1.0018
    Episode_Reward/rotating_object: 97.6344
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.93s
                      Time elapsed: 00:16:19
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 49879 steps/s (collection: 1.878s, learning 0.093s)
             Mean action noise std: 1.92
          Mean value_function loss: 101.1281
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.2431
                       Mean reward: 557.35
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.0220
    Episode_Reward/rotating_object: 102.3744
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.97s
                      Time elapsed: 00:16:21
                               ETA: 00:37:58

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 51721 steps/s (collection: 1.790s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 107.4680
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.2514
                       Mean reward: 491.93
               Mean episode length: 226.91
    Episode_Reward/reaching_object: 0.9940
    Episode_Reward/rotating_object: 102.4476
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.90s
                      Time elapsed: 00:16:23
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 52201 steps/s (collection: 1.792s, learning 0.091s)
             Mean action noise std: 1.92
          Mean value_function loss: 102.4961
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 45.2584
                       Mean reward: 526.05
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 0.9978
    Episode_Reward/rotating_object: 99.5149
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.88s
                      Time elapsed: 00:16:25
                               ETA: 00:37:53

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 51618 steps/s (collection: 1.796s, learning 0.108s)
             Mean action noise std: 1.92
          Mean value_function loss: 98.9863
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.2624
                       Mean reward: 507.90
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.0184
    Episode_Reward/rotating_object: 104.3119
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.90s
                      Time elapsed: 00:16:27
                               ETA: 00:37:50

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 50397 steps/s (collection: 1.833s, learning 0.118s)
             Mean action noise std: 1.92
          Mean value_function loss: 108.5156
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.2665
                       Mean reward: 545.53
               Mean episode length: 236.21
    Episode_Reward/reaching_object: 1.0487
    Episode_Reward/rotating_object: 106.4413
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.95s
                      Time elapsed: 00:16:29
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 51809 steps/s (collection: 1.761s, learning 0.136s)
             Mean action noise std: 1.92
          Mean value_function loss: 110.6380
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.2724
                       Mean reward: 531.70
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.0409
    Episode_Reward/rotating_object: 103.7709
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.90s
                      Time elapsed: 00:16:31
                               ETA: 00:37:44

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 50494 steps/s (collection: 1.802s, learning 0.145s)
             Mean action noise std: 1.92
          Mean value_function loss: 107.6726
               Mean surrogate loss: 0.0029
                 Mean entropy loss: 45.2748
                       Mean reward: 511.51
               Mean episode length: 231.20
    Episode_Reward/reaching_object: 1.0283
    Episode_Reward/rotating_object: 100.1770
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.95s
                      Time elapsed: 00:16:33
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 51949 steps/s (collection: 1.771s, learning 0.121s)
             Mean action noise std: 1.92
          Mean value_function loss: 99.8482
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.2759
                       Mean reward: 488.36
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 1.0368
    Episode_Reward/rotating_object: 100.9806
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.89s
                      Time elapsed: 00:16:35
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 51692 steps/s (collection: 1.803s, learning 0.099s)
             Mean action noise std: 1.92
          Mean value_function loss: 96.1821
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.2806
                       Mean reward: 527.74
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.0506
    Episode_Reward/rotating_object: 108.2492
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.90s
                      Time elapsed: 00:16:37
                               ETA: 00:37:36

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 50925 steps/s (collection: 1.823s, learning 0.107s)
             Mean action noise std: 1.92
          Mean value_function loss: 94.3159
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.2860
                       Mean reward: 519.13
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 1.0366
    Episode_Reward/rotating_object: 104.4469
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.93s
                      Time elapsed: 00:16:39
                               ETA: 00:37:33

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 51939 steps/s (collection: 1.794s, learning 0.099s)
             Mean action noise std: 1.92
          Mean value_function loss: 94.2092
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.2894
                       Mean reward: 512.04
               Mean episode length: 233.73
    Episode_Reward/reaching_object: 1.0456
    Episode_Reward/rotating_object: 105.8742
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.89s
                      Time elapsed: 00:16:41
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 51135 steps/s (collection: 1.803s, learning 0.120s)
             Mean action noise std: 1.92
          Mean value_function loss: 96.8588
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.2936
                       Mean reward: 545.01
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.0250
    Episode_Reward/rotating_object: 104.9697
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.92s
                      Time elapsed: 00:16:42
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 52453 steps/s (collection: 1.770s, learning 0.104s)
             Mean action noise std: 1.92
          Mean value_function loss: 93.6952
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.3033
                       Mean reward: 506.86
               Mean episode length: 236.00
    Episode_Reward/reaching_object: 1.0459
    Episode_Reward/rotating_object: 107.5817
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.87s
                      Time elapsed: 00:16:44
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 51666 steps/s (collection: 1.770s, learning 0.133s)
             Mean action noise std: 1.92
          Mean value_function loss: 104.8541
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.3166
                       Mean reward: 538.70
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 1.0263
    Episode_Reward/rotating_object: 107.8167
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.90s
                      Time elapsed: 00:16:46
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 51840 steps/s (collection: 1.783s, learning 0.113s)
             Mean action noise std: 1.92
          Mean value_function loss: 106.1299
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.3264
                       Mean reward: 564.81
               Mean episode length: 230.33
    Episode_Reward/reaching_object: 1.0460
    Episode_Reward/rotating_object: 112.7132
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.90s
                      Time elapsed: 00:16:48
                               ETA: 00:37:20

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 52376 steps/s (collection: 1.787s, learning 0.090s)
             Mean action noise std: 1.92
          Mean value_function loss: 107.6793
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.3271
                       Mean reward: 534.96
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.0335
    Episode_Reward/rotating_object: 108.3598
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.88s
                      Time elapsed: 00:16:50
                               ETA: 00:37:17

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 50350 steps/s (collection: 1.834s, learning 0.119s)
             Mean action noise std: 1.92
          Mean value_function loss: 99.9875
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 45.3295
                       Mean reward: 585.92
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 1.0511
    Episode_Reward/rotating_object: 110.0944
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.95s
                      Time elapsed: 00:16:52
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 51467 steps/s (collection: 1.787s, learning 0.123s)
             Mean action noise std: 1.92
          Mean value_function loss: 99.0669
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.3316
                       Mean reward: 564.05
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.0588
    Episode_Reward/rotating_object: 110.5300
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.91s
                      Time elapsed: 00:16:54
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 51317 steps/s (collection: 1.811s, learning 0.105s)
             Mean action noise std: 1.93
          Mean value_function loss: 96.4473
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.3373
                       Mean reward: 578.17
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 111.6617
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.92s
                      Time elapsed: 00:16:56
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 46973 steps/s (collection: 1.949s, learning 0.144s)
             Mean action noise std: 1.93
          Mean value_function loss: 97.5599
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 45.3442
                       Mean reward: 586.21
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 1.0760
    Episode_Reward/rotating_object: 114.6835
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.09s
                      Time elapsed: 00:16:58
                               ETA: 00:37:06

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 51638 steps/s (collection: 1.800s, learning 0.104s)
             Mean action noise std: 1.93
          Mean value_function loss: 103.6389
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.3473
                       Mean reward: 527.57
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.0473
    Episode_Reward/rotating_object: 108.3455
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.90s
                      Time elapsed: 00:17:00
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 52083 steps/s (collection: 1.779s, learning 0.108s)
             Mean action noise std: 1.93
          Mean value_function loss: 97.4528
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.3496
                       Mean reward: 589.04
               Mean episode length: 242.99
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 113.4047
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.89s
                      Time elapsed: 00:17:02
                               ETA: 00:37:01

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 52523 steps/s (collection: 1.758s, learning 0.113s)
             Mean action noise std: 1.93
          Mean value_function loss: 95.4232
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 45.3562
                       Mean reward: 621.53
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 1.0655
    Episode_Reward/rotating_object: 111.6446
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.87s
                      Time elapsed: 00:17:04
                               ETA: 00:36:58

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 51484 steps/s (collection: 1.818s, learning 0.092s)
             Mean action noise std: 1.93
          Mean value_function loss: 93.2242
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.3621
                       Mean reward: 571.86
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 114.1155
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.91s
                      Time elapsed: 00:17:05
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 51405 steps/s (collection: 1.812s, learning 0.101s)
             Mean action noise std: 1.93
          Mean value_function loss: 93.6824
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.3685
                       Mean reward: 563.90
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.0616
    Episode_Reward/rotating_object: 113.1447
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.91s
                      Time elapsed: 00:17:07
                               ETA: 00:36:53

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 51493 steps/s (collection: 1.813s, learning 0.096s)
             Mean action noise std: 1.93
          Mean value_function loss: 99.8948
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.3745
                       Mean reward: 546.49
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.0580
    Episode_Reward/rotating_object: 111.6025
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.91s
                      Time elapsed: 00:17:09
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 52579 steps/s (collection: 1.775s, learning 0.095s)
             Mean action noise std: 1.93
          Mean value_function loss: 102.7723
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.3794
                       Mean reward: 555.67
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 111.3769
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.87s
                      Time elapsed: 00:17:11
                               ETA: 00:36:47

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 50890 steps/s (collection: 1.770s, learning 0.162s)
             Mean action noise std: 1.93
          Mean value_function loss: 94.4830
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.3845
                       Mean reward: 519.23
               Mean episode length: 226.74
    Episode_Reward/reaching_object: 1.0597
    Episode_Reward/rotating_object: 111.7853
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.93s
                      Time elapsed: 00:17:13
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 50743 steps/s (collection: 1.779s, learning 0.159s)
             Mean action noise std: 1.93
          Mean value_function loss: 95.8397
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.3880
                       Mean reward: 574.04
               Mean episode length: 233.49
    Episode_Reward/reaching_object: 1.0471
    Episode_Reward/rotating_object: 113.4596
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.94s
                      Time elapsed: 00:17:15
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 51457 steps/s (collection: 1.787s, learning 0.124s)
             Mean action noise std: 1.93
          Mean value_function loss: 95.4722
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 45.3911
                       Mean reward: 585.21
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.0642
    Episode_Reward/rotating_object: 116.0727
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.91s
                      Time elapsed: 00:17:17
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 51555 steps/s (collection: 1.800s, learning 0.106s)
             Mean action noise std: 1.93
          Mean value_function loss: 95.6423
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.3939
                       Mean reward: 564.22
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 114.7291
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.91s
                      Time elapsed: 00:17:19
                               ETA: 00:36:37

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 51936 steps/s (collection: 1.790s, learning 0.102s)
             Mean action noise std: 1.93
          Mean value_function loss: 97.5520
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.3995
                       Mean reward: 545.05
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 112.2714
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.89s
                      Time elapsed: 00:17:21
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 51468 steps/s (collection: 1.808s, learning 0.102s)
             Mean action noise std: 1.93
          Mean value_function loss: 97.6173
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.4114
                       Mean reward: 600.77
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.0667
    Episode_Reward/rotating_object: 119.6282
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.91s
                      Time elapsed: 00:17:23
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 52312 steps/s (collection: 1.785s, learning 0.094s)
             Mean action noise std: 1.93
          Mean value_function loss: 93.1261
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.4211
                       Mean reward: 531.82
               Mean episode length: 224.47
    Episode_Reward/reaching_object: 1.0397
    Episode_Reward/rotating_object: 112.8548
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.88s
                      Time elapsed: 00:17:24
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 50138 steps/s (collection: 1.858s, learning 0.103s)
             Mean action noise std: 1.93
          Mean value_function loss: 88.7556
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.4252
                       Mean reward: 585.62
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 1.0649
    Episode_Reward/rotating_object: 116.5701
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.96s
                      Time elapsed: 00:17:26
                               ETA: 00:36:26

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 50839 steps/s (collection: 1.817s, learning 0.117s)
             Mean action noise std: 1.94
          Mean value_function loss: 90.9351
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 45.4295
                       Mean reward: 587.40
               Mean episode length: 239.63
    Episode_Reward/reaching_object: 1.0532
    Episode_Reward/rotating_object: 116.5756
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.93s
                      Time elapsed: 00:17:28
                               ETA: 00:36:23

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 50225 steps/s (collection: 1.859s, learning 0.098s)
             Mean action noise std: 1.94
          Mean value_function loss: 84.6603
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.4384
                       Mean reward: 583.26
               Mean episode length: 236.64
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 112.9266
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.96s
                      Time elapsed: 00:17:30
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 53125 steps/s (collection: 1.745s, learning 0.105s)
             Mean action noise std: 1.94
          Mean value_function loss: 86.2704
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 45.4490
                       Mean reward: 571.99
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 1.0529
    Episode_Reward/rotating_object: 116.5513
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.85s
                      Time elapsed: 00:17:32
                               ETA: 00:36:18

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 51121 steps/s (collection: 1.786s, learning 0.137s)
             Mean action noise std: 1.94
          Mean value_function loss: 100.6998
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.4624
                       Mean reward: 599.98
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.0451
    Episode_Reward/rotating_object: 116.9301
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.92s
                      Time elapsed: 00:17:34
                               ETA: 00:36:15

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 52124 steps/s (collection: 1.764s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 91.0669
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 45.4728
                       Mean reward: 587.68
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 1.0230
    Episode_Reward/rotating_object: 112.5343
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.89s
                      Time elapsed: 00:17:36
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 49023 steps/s (collection: 1.864s, learning 0.141s)
             Mean action noise std: 1.94
          Mean value_function loss: 91.5437
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.4788
                       Mean reward: 612.60
               Mean episode length: 236.66
    Episode_Reward/reaching_object: 1.0384
    Episode_Reward/rotating_object: 117.2616
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.01s
                      Time elapsed: 00:17:38
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 48510 steps/s (collection: 1.896s, learning 0.130s)
             Mean action noise std: 1.94
          Mean value_function loss: 91.3434
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.4821
                       Mean reward: 549.59
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.0176
    Episode_Reward/rotating_object: 112.4541
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.03s
                      Time elapsed: 00:17:40
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 46646 steps/s (collection: 1.970s, learning 0.137s)
             Mean action noise std: 1.94
          Mean value_function loss: 105.3289
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.4804
                       Mean reward: 562.96
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 0.9946
    Episode_Reward/rotating_object: 114.9629
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.11s
                      Time elapsed: 00:17:42
                               ETA: 00:36:06

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 48413 steps/s (collection: 1.913s, learning 0.117s)
             Mean action noise std: 1.94
          Mean value_function loss: 102.5565
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.4862
                       Mean reward: 577.24
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.0504
    Episode_Reward/rotating_object: 116.6076
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.03s
                      Time elapsed: 00:17:44
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 49169 steps/s (collection: 1.884s, learning 0.115s)
             Mean action noise std: 1.94
          Mean value_function loss: 96.4918
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.4974
                       Mean reward: 609.47
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 1.0417
    Episode_Reward/rotating_object: 119.4915
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.00s
                      Time elapsed: 00:17:46
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 48818 steps/s (collection: 1.875s, learning 0.139s)
             Mean action noise std: 1.94
          Mean value_function loss: 89.7859
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 45.5052
                       Mean reward: 603.08
               Mean episode length: 231.94
    Episode_Reward/reaching_object: 1.0582
    Episode_Reward/rotating_object: 114.9203
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.01s
                      Time elapsed: 00:17:48
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 50399 steps/s (collection: 1.785s, learning 0.165s)
             Mean action noise std: 1.94
          Mean value_function loss: 92.1964
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 45.5106
                       Mean reward: 594.54
               Mean episode length: 239.28
    Episode_Reward/reaching_object: 1.0570
    Episode_Reward/rotating_object: 115.2700
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.95s
                      Time elapsed: 00:17:50
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 48996 steps/s (collection: 1.867s, learning 0.140s)
             Mean action noise std: 1.95
          Mean value_function loss: 89.1923
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.5157
                       Mean reward: 592.11
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 1.0720
    Episode_Reward/rotating_object: 115.3834
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.01s
                      Time elapsed: 00:17:52
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 48677 steps/s (collection: 1.843s, learning 0.176s)
             Mean action noise std: 1.95
          Mean value_function loss: 94.3331
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.5253
                       Mean reward: 571.32
               Mean episode length: 233.59
    Episode_Reward/reaching_object: 1.0482
    Episode_Reward/rotating_object: 111.7297
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.02s
                      Time elapsed: 00:17:54
                               ETA: 00:35:51

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 50215 steps/s (collection: 1.839s, learning 0.119s)
             Mean action noise std: 1.95
          Mean value_function loss: 93.2470
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.5342
                       Mean reward: 550.48
               Mean episode length: 225.50
    Episode_Reward/reaching_object: 1.0393
    Episode_Reward/rotating_object: 118.0856
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.96s
                      Time elapsed: 00:17:56
                               ETA: 00:35:48

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 48591 steps/s (collection: 1.893s, learning 0.130s)
             Mean action noise std: 1.95
          Mean value_function loss: 102.3916
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.5355
                       Mean reward: 579.44
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.0491
    Episode_Reward/rotating_object: 115.5640
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.02s
                      Time elapsed: 00:17:58
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 50050 steps/s (collection: 1.837s, learning 0.128s)
             Mean action noise std: 1.95
          Mean value_function loss: 90.9984
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 45.5384
                       Mean reward: 605.00
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.0383
    Episode_Reward/rotating_object: 115.7040
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.96s
                      Time elapsed: 00:18:00
                               ETA: 00:35:44

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 49144 steps/s (collection: 1.837s, learning 0.163s)
             Mean action noise std: 1.95
          Mean value_function loss: 95.1190
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.5445
                       Mean reward: 588.37
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.0399
    Episode_Reward/rotating_object: 115.5732
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.00s
                      Time elapsed: 00:18:02
                               ETA: 00:35:41

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 50953 steps/s (collection: 1.805s, learning 0.124s)
             Mean action noise std: 1.95
          Mean value_function loss: 93.7656
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 45.5516
                       Mean reward: 597.38
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 115.9976
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.93s
                      Time elapsed: 00:18:04
                               ETA: 00:35:38

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 49910 steps/s (collection: 1.840s, learning 0.130s)
             Mean action noise std: 1.95
          Mean value_function loss: 86.8060
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 45.5540
                       Mean reward: 597.46
               Mean episode length: 238.01
    Episode_Reward/reaching_object: 1.0613
    Episode_Reward/rotating_object: 118.5086
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.97s
                      Time elapsed: 00:18:06
                               ETA: 00:35:36

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 50733 steps/s (collection: 1.836s, learning 0.102s)
             Mean action noise std: 1.95
          Mean value_function loss: 90.8287
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.5585
                       Mean reward: 611.61
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.0319
    Episode_Reward/rotating_object: 118.6719
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.94s
                      Time elapsed: 00:18:08
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 50433 steps/s (collection: 1.838s, learning 0.111s)
             Mean action noise std: 1.95
          Mean value_function loss: 89.3922
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.5659
                       Mean reward: 601.65
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.0310
    Episode_Reward/rotating_object: 116.3769
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.95s
                      Time elapsed: 00:18:10
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 50987 steps/s (collection: 1.816s, learning 0.112s)
             Mean action noise std: 1.95
          Mean value_function loss: 89.4044
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.5757
                       Mean reward: 628.06
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.0420
    Episode_Reward/rotating_object: 119.3594
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.93s
                      Time elapsed: 00:18:12
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 51469 steps/s (collection: 1.813s, learning 0.097s)
             Mean action noise std: 1.95
          Mean value_function loss: 94.2815
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.5794
                       Mean reward: 603.56
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 1.0319
    Episode_Reward/rotating_object: 116.7067
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.91s
                      Time elapsed: 00:18:14
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 51727 steps/s (collection: 1.787s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 89.8990
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.5791
                       Mean reward: 584.14
               Mean episode length: 235.92
    Episode_Reward/reaching_object: 1.0153
    Episode_Reward/rotating_object: 115.9667
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.90s
                      Time elapsed: 00:18:16
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 48402 steps/s (collection: 1.937s, learning 0.094s)
             Mean action noise std: 1.95
          Mean value_function loss: 89.8810
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.5799
                       Mean reward: 588.70
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.0235
    Episode_Reward/rotating_object: 116.9301
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.03s
                      Time elapsed: 00:18:18
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 50761 steps/s (collection: 1.824s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 87.8098
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.5915
                       Mean reward: 597.19
               Mean episode length: 234.04
    Episode_Reward/reaching_object: 1.0300
    Episode_Reward/rotating_object: 116.0493
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.94s
                      Time elapsed: 00:18:20
                               ETA: 00:35:18

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 51221 steps/s (collection: 1.798s, learning 0.121s)
             Mean action noise std: 1.96
          Mean value_function loss: 81.1488
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.6034
                       Mean reward: 594.64
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.0220
    Episode_Reward/rotating_object: 115.1435
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.92s
                      Time elapsed: 00:18:22
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 49910 steps/s (collection: 1.844s, learning 0.126s)
             Mean action noise std: 1.96
          Mean value_function loss: 84.4811
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 45.6175
                       Mean reward: 571.89
               Mean episode length: 232.34
    Episode_Reward/reaching_object: 1.0252
    Episode_Reward/rotating_object: 117.4662
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.97s
                      Time elapsed: 00:18:23
                               ETA: 00:35:13

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 50914 steps/s (collection: 1.816s, learning 0.115s)
             Mean action noise std: 1.96
          Mean value_function loss: 88.6373
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 45.6314
                       Mean reward: 641.37
               Mean episode length: 242.16
    Episode_Reward/reaching_object: 1.0636
    Episode_Reward/rotating_object: 122.9136
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.93s
                      Time elapsed: 00:18:25
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 50840 steps/s (collection: 1.800s, learning 0.133s)
             Mean action noise std: 1.96
          Mean value_function loss: 80.6955
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.6410
                       Mean reward: 603.49
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.0124
    Episode_Reward/rotating_object: 116.9306
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.93s
                      Time elapsed: 00:18:27
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 49941 steps/s (collection: 1.824s, learning 0.145s)
             Mean action noise std: 1.96
          Mean value_function loss: 93.4006
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 45.6453
                       Mean reward: 598.26
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.0332
    Episode_Reward/rotating_object: 118.9487
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.97s
                      Time elapsed: 00:18:29
                               ETA: 00:35:06

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 49079 steps/s (collection: 1.835s, learning 0.168s)
             Mean action noise std: 1.96
          Mean value_function loss: 88.1998
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.6498
                       Mean reward: 580.73
               Mean episode length: 233.58
    Episode_Reward/reaching_object: 1.0215
    Episode_Reward/rotating_object: 116.7317
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.00s
                      Time elapsed: 00:18:31
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 51223 steps/s (collection: 1.767s, learning 0.152s)
             Mean action noise std: 1.96
          Mean value_function loss: 87.8758
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 45.6562
                       Mean reward: 597.63
               Mean episode length: 238.18
    Episode_Reward/reaching_object: 1.0401
    Episode_Reward/rotating_object: 118.3831
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.92s
                      Time elapsed: 00:18:33
                               ETA: 00:35:01

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 51340 steps/s (collection: 1.791s, learning 0.124s)
             Mean action noise std: 1.96
          Mean value_function loss: 90.8980
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 45.6649
                       Mean reward: 600.40
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.0270
    Episode_Reward/rotating_object: 116.2138
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.91s
                      Time elapsed: 00:18:35
                               ETA: 00:34:58

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 51897 steps/s (collection: 1.792s, learning 0.102s)
             Mean action noise std: 1.96
          Mean value_function loss: 79.9147
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.6710
                       Mean reward: 630.43
               Mean episode length: 237.31
    Episode_Reward/reaching_object: 1.0559
    Episode_Reward/rotating_object: 122.8116
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.89s
                      Time elapsed: 00:18:37
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 52256 steps/s (collection: 1.772s, learning 0.109s)
             Mean action noise std: 1.96
          Mean value_function loss: 84.1406
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.6747
                       Mean reward: 585.57
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 1.0399
    Episode_Reward/rotating_object: 117.3307
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.88s
                      Time elapsed: 00:18:39
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 52189 steps/s (collection: 1.794s, learning 0.090s)
             Mean action noise std: 1.96
          Mean value_function loss: 78.3676
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 45.6792
                       Mean reward: 647.65
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 1.0582
    Episode_Reward/rotating_object: 122.5047
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.88s
                      Time elapsed: 00:18:41
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 51588 steps/s (collection: 1.784s, learning 0.122s)
             Mean action noise std: 1.97
          Mean value_function loss: 87.6928
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.6867
                       Mean reward: 632.69
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 1.0596
    Episode_Reward/rotating_object: 122.5312
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.91s
                      Time elapsed: 00:18:43
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 49799 steps/s (collection: 1.875s, learning 0.099s)
             Mean action noise std: 1.97
          Mean value_function loss: 83.1509
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 45.7005
                       Mean reward: 610.93
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.0789
    Episode_Reward/rotating_object: 125.2226
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.97s
                      Time elapsed: 00:18:45
                               ETA: 00:34:45

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 51162 steps/s (collection: 1.822s, learning 0.100s)
             Mean action noise std: 1.97
          Mean value_function loss: 83.6058
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 45.7043
                       Mean reward: 616.68
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 1.0751
    Episode_Reward/rotating_object: 122.7692
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.92s
                      Time elapsed: 00:18:47
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 52253 steps/s (collection: 1.770s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 80.5283
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 45.7059
                       Mean reward: 641.91
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.0685
    Episode_Reward/rotating_object: 123.1243
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.88s
                      Time elapsed: 00:18:48
                               ETA: 00:34:40

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 51885 steps/s (collection: 1.785s, learning 0.110s)
             Mean action noise std: 1.97
          Mean value_function loss: 84.0981
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.7103
                       Mean reward: 635.26
               Mean episode length: 244.81
    Episode_Reward/reaching_object: 1.0843
    Episode_Reward/rotating_object: 121.2985
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.89s
                      Time elapsed: 00:18:50
                               ETA: 00:34:37

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 51169 steps/s (collection: 1.825s, learning 0.096s)
             Mean action noise std: 1.97
          Mean value_function loss: 79.8707
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.7147
                       Mean reward: 630.88
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.0821
    Episode_Reward/rotating_object: 125.6168
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.92s
                      Time elapsed: 00:18:52
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 52218 steps/s (collection: 1.783s, learning 0.100s)
             Mean action noise std: 1.97
          Mean value_function loss: 82.7102
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.7239
                       Mean reward: 618.45
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.0821
    Episode_Reward/rotating_object: 125.6833
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.88s
                      Time elapsed: 00:18:54
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 52125 steps/s (collection: 1.796s, learning 0.090s)
             Mean action noise std: 1.97
          Mean value_function loss: 91.6238
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 45.7352
                       Mean reward: 641.45
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 1.0849
    Episode_Reward/rotating_object: 124.0681
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.89s
                      Time elapsed: 00:18:56
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 51174 steps/s (collection: 1.816s, learning 0.105s)
             Mean action noise std: 1.97
          Mean value_function loss: 82.0395
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.7471
                       Mean reward: 670.81
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.0871
    Episode_Reward/rotating_object: 123.8426
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.92s
                      Time elapsed: 00:18:58
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 52922 steps/s (collection: 1.748s, learning 0.110s)
             Mean action noise std: 1.98
          Mean value_function loss: 81.9782
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 45.7681
                       Mean reward: 618.62
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.0922
    Episode_Reward/rotating_object: 123.8227
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.86s
                      Time elapsed: 00:19:00
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 52318 steps/s (collection: 1.785s, learning 0.094s)
             Mean action noise std: 1.98
          Mean value_function loss: 79.2667
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.7829
                       Mean reward: 637.68
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.0945
    Episode_Reward/rotating_object: 125.3867
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.88s
                      Time elapsed: 00:19:02
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 52198 steps/s (collection: 1.793s, learning 0.091s)
             Mean action noise std: 1.98
          Mean value_function loss: 85.3564
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.7905
                       Mean reward: 629.00
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 1.1063
    Episode_Reward/rotating_object: 124.9700
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.88s
                      Time elapsed: 00:19:04
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 52149 steps/s (collection: 1.771s, learning 0.114s)
             Mean action noise std: 1.98
          Mean value_function loss: 99.6120
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 45.7982
                       Mean reward: 624.66
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 122.9659
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.89s
                      Time elapsed: 00:19:05
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 51986 steps/s (collection: 1.790s, learning 0.101s)
             Mean action noise std: 1.98
          Mean value_function loss: 84.8624
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 45.8093
                       Mean reward: 600.82
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 126.3214
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.89s
                      Time elapsed: 00:19:07
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 51090 steps/s (collection: 1.822s, learning 0.102s)
             Mean action noise std: 1.98
          Mean value_function loss: 75.0675
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.8189
                       Mean reward: 691.54
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.1319
    Episode_Reward/rotating_object: 132.3495
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.92s
                      Time elapsed: 00:19:09
                               ETA: 00:34:12

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 52093 steps/s (collection: 1.793s, learning 0.094s)
             Mean action noise std: 1.98
          Mean value_function loss: 80.7294
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.8280
                       Mean reward: 640.15
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.0748
    Episode_Reward/rotating_object: 125.8360
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.89s
                      Time elapsed: 00:19:11
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 53261 steps/s (collection: 1.751s, learning 0.095s)
             Mean action noise std: 1.98
          Mean value_function loss: 78.1739
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 45.8289
                       Mean reward: 620.88
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.1116
    Episode_Reward/rotating_object: 126.0139
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.85s
                      Time elapsed: 00:19:13
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 51403 steps/s (collection: 1.801s, learning 0.112s)
             Mean action noise std: 1.98
          Mean value_function loss: 87.0445
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.8288
                       Mean reward: 634.43
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.1024
    Episode_Reward/rotating_object: 126.8551
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.91s
                      Time elapsed: 00:19:15
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 52670 steps/s (collection: 1.763s, learning 0.103s)
             Mean action noise std: 1.98
          Mean value_function loss: 73.7458
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.8339
                       Mean reward: 636.22
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.0939
    Episode_Reward/rotating_object: 128.6201
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.87s
                      Time elapsed: 00:19:17
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 51167 steps/s (collection: 1.804s, learning 0.118s)
             Mean action noise std: 1.98
          Mean value_function loss: 70.3289
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.8431
                       Mean reward: 633.48
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.0972
    Episode_Reward/rotating_object: 126.0901
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.92s
                      Time elapsed: 00:19:19
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 50815 steps/s (collection: 1.823s, learning 0.112s)
             Mean action noise std: 1.98
          Mean value_function loss: 79.2512
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 45.8514
                       Mean reward: 647.48
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.1024
    Episode_Reward/rotating_object: 125.3919
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.93s
                      Time elapsed: 00:19:21
                               ETA: 00:33:56

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 51110 steps/s (collection: 1.829s, learning 0.094s)
             Mean action noise std: 1.99
          Mean value_function loss: 73.3069
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.8631
                       Mean reward: 614.86
               Mean episode length: 228.14
    Episode_Reward/reaching_object: 1.0983
    Episode_Reward/rotating_object: 127.3109
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.92s
                      Time elapsed: 00:19:23
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 48733 steps/s (collection: 1.893s, learning 0.124s)
             Mean action noise std: 1.99
          Mean value_function loss: 82.8435
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.8783
                       Mean reward: 654.08
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 1.0954
    Episode_Reward/rotating_object: 125.2973
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.02s
                      Time elapsed: 00:19:25
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 49692 steps/s (collection: 1.826s, learning 0.153s)
             Mean action noise std: 1.99
          Mean value_function loss: 77.2883
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.8886
                       Mean reward: 668.98
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 1.1037
    Episode_Reward/rotating_object: 129.0553
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.98s
                      Time elapsed: 00:19:27
                               ETA: 00:33:49

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 49139 steps/s (collection: 1.880s, learning 0.120s)
             Mean action noise std: 1.99
          Mean value_function loss: 80.0871
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 45.8988
                       Mean reward: 642.80
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.0970
    Episode_Reward/rotating_object: 129.8168
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.00s
                      Time elapsed: 00:19:29
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 49974 steps/s (collection: 1.824s, learning 0.143s)
             Mean action noise std: 1.99
          Mean value_function loss: 83.8890
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.9070
                       Mean reward: 624.59
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.0910
    Episode_Reward/rotating_object: 127.5218
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.97s
                      Time elapsed: 00:19:31
                               ETA: 00:33:44

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 48322 steps/s (collection: 1.885s, learning 0.150s)
             Mean action noise std: 1.99
          Mean value_function loss: 70.9430
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 45.9121
                       Mean reward: 653.29
               Mean episode length: 249.19
    Episode_Reward/reaching_object: 1.1116
    Episode_Reward/rotating_object: 128.0037
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.03s
                      Time elapsed: 00:19:33
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 49828 steps/s (collection: 1.880s, learning 0.093s)
             Mean action noise std: 1.99
          Mean value_function loss: 77.2943
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.9238
                       Mean reward: 665.09
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.0969
    Episode_Reward/rotating_object: 127.6479
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.97s
                      Time elapsed: 00:19:35
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 51471 steps/s (collection: 1.810s, learning 0.100s)
             Mean action noise std: 1.99
          Mean value_function loss: 76.3020
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.9396
                       Mean reward: 645.27
               Mean episode length: 231.99
    Episode_Reward/reaching_object: 1.0706
    Episode_Reward/rotating_object: 128.0199
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 1.91s
                      Time elapsed: 00:19:36
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 49511 steps/s (collection: 1.844s, learning 0.141s)
             Mean action noise std: 2.00
          Mean value_function loss: 70.6100
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.9502
                       Mean reward: 683.59
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.1274
    Episode_Reward/rotating_object: 134.1459
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 1.99s
                      Time elapsed: 00:19:38
                               ETA: 00:33:35

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 49802 steps/s (collection: 1.860s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 66.5637
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 45.9572
                       Mean reward: 655.51
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.1020
    Episode_Reward/rotating_object: 129.3099
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.97s
                      Time elapsed: 00:19:40
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 49882 steps/s (collection: 1.830s, learning 0.141s)
             Mean action noise std: 2.00
          Mean value_function loss: 71.2461
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.9611
                       Mean reward: 625.31
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.0959
    Episode_Reward/rotating_object: 127.3822
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 1.97s
                      Time elapsed: 00:19:42
                               ETA: 00:33:30

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 48952 steps/s (collection: 1.848s, learning 0.160s)
             Mean action noise std: 2.00
          Mean value_function loss: 71.6920
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 45.9691
                       Mean reward: 676.10
               Mean episode length: 241.79
    Episode_Reward/reaching_object: 1.1128
    Episode_Reward/rotating_object: 130.3691
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.01s
                      Time elapsed: 00:19:44
                               ETA: 00:33:28

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 46855 steps/s (collection: 1.846s, learning 0.252s)
             Mean action noise std: 2.00
          Mean value_function loss: 71.3673
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.9728
                       Mean reward: 659.83
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.1093
    Episode_Reward/rotating_object: 130.1335
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.10s
                      Time elapsed: 00:19:47
                               ETA: 00:33:26

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 49694 steps/s (collection: 1.779s, learning 0.200s)
             Mean action noise std: 2.00
          Mean value_function loss: 69.0869
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.9837
                       Mean reward: 672.19
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.1056
    Episode_Reward/rotating_object: 130.7402
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.98s
                      Time elapsed: 00:19:48
                               ETA: 00:33:23

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 48880 steps/s (collection: 1.808s, learning 0.203s)
             Mean action noise std: 2.00
          Mean value_function loss: 78.4686
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.0004
                       Mean reward: 653.02
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.1047
    Episode_Reward/rotating_object: 131.4555
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.01s
                      Time elapsed: 00:19:51
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 51270 steps/s (collection: 1.795s, learning 0.122s)
             Mean action noise std: 2.00
          Mean value_function loss: 75.2625
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.0096
                       Mean reward: 668.69
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 1.1102
    Episode_Reward/rotating_object: 131.6349
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.92s
                      Time elapsed: 00:19:52
                               ETA: 00:33:18

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 50462 steps/s (collection: 1.849s, learning 0.100s)
             Mean action noise std: 2.00
          Mean value_function loss: 68.5844
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 46.0162
                       Mean reward: 675.54
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.1027
    Episode_Reward/rotating_object: 132.3080
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.95s
                      Time elapsed: 00:19:54
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 50154 steps/s (collection: 1.836s, learning 0.124s)
             Mean action noise std: 2.00
          Mean value_function loss: 72.5942
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.0214
                       Mean reward: 677.20
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.1066
    Episode_Reward/rotating_object: 134.3866
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.96s
                      Time elapsed: 00:19:56
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 49772 steps/s (collection: 1.855s, learning 0.120s)
             Mean action noise std: 2.00
          Mean value_function loss: 63.4238
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 46.0260
                       Mean reward: 632.68
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 1.0817
    Episode_Reward/rotating_object: 130.8106
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.98s
                      Time elapsed: 00:19:58
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 50138 steps/s (collection: 1.855s, learning 0.105s)
             Mean action noise std: 2.01
          Mean value_function loss: 68.9228
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.0391
                       Mean reward: 648.54
               Mean episode length: 232.57
    Episode_Reward/reaching_object: 1.0803
    Episode_Reward/rotating_object: 130.9695
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.96s
                      Time elapsed: 00:20:00
                               ETA: 00:33:09

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 51152 steps/s (collection: 1.824s, learning 0.097s)
             Mean action noise std: 2.01
          Mean value_function loss: 69.9029
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.0617
                       Mean reward: 633.44
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.0793
    Episode_Reward/rotating_object: 130.9011
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.92s
                      Time elapsed: 00:20:02
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 49794 steps/s (collection: 1.873s, learning 0.101s)
             Mean action noise std: 2.01
          Mean value_function loss: 68.0120
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.0782
                       Mean reward: 679.49
               Mean episode length: 244.62
    Episode_Reward/reaching_object: 1.0815
    Episode_Reward/rotating_object: 130.8388
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.97s
                      Time elapsed: 00:20:04
                               ETA: 00:33:04

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 48608 steps/s (collection: 1.912s, learning 0.110s)
             Mean action noise std: 2.01
          Mean value_function loss: 75.9814
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.0892
                       Mean reward: 654.43
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.0925
    Episode_Reward/rotating_object: 131.1618
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.02s
                      Time elapsed: 00:20:06
                               ETA: 00:33:02

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 50220 steps/s (collection: 1.861s, learning 0.097s)
             Mean action noise std: 2.01
          Mean value_function loss: 70.4033
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.1040
                       Mean reward: 675.13
               Mean episode length: 242.07
    Episode_Reward/reaching_object: 1.0809
    Episode_Reward/rotating_object: 128.4438
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.96s
                      Time elapsed: 00:20:08
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 50495 steps/s (collection: 1.847s, learning 0.100s)
             Mean action noise std: 2.01
          Mean value_function loss: 69.8842
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 46.1169
                       Mean reward: 646.82
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.0919
    Episode_Reward/rotating_object: 130.4250
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.95s
                      Time elapsed: 00:20:10
                               ETA: 00:32:57

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 50282 steps/s (collection: 1.835s, learning 0.120s)
             Mean action noise std: 2.02
          Mean value_function loss: 69.2914
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 46.1241
                       Mean reward: 655.04
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 132.0692
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.96s
                      Time elapsed: 00:20:12
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 50147 steps/s (collection: 1.852s, learning 0.108s)
             Mean action noise std: 2.02
          Mean value_function loss: 69.9513
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.1327
                       Mean reward: 635.74
               Mean episode length: 232.39
    Episode_Reward/reaching_object: 1.0840
    Episode_Reward/rotating_object: 130.9467
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.96s
                      Time elapsed: 00:20:14
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 50832 steps/s (collection: 1.836s, learning 0.098s)
             Mean action noise std: 2.02
          Mean value_function loss: 65.4551
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.1418
                       Mean reward: 668.16
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.1051
    Episode_Reward/rotating_object: 132.1490
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.93s
                      Time elapsed: 00:20:16
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 50509 steps/s (collection: 1.834s, learning 0.112s)
             Mean action noise std: 2.02
          Mean value_function loss: 66.4019
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 46.1478
                       Mean reward: 666.93
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.1006
    Episode_Reward/rotating_object: 133.2247
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.95s
                      Time elapsed: 00:20:18
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 50420 steps/s (collection: 1.837s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 63.5336
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.1603
                       Mean reward: 678.33
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.0928
    Episode_Reward/rotating_object: 133.9881
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.95s
                      Time elapsed: 00:20:20
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 50672 steps/s (collection: 1.836s, learning 0.104s)
             Mean action noise std: 2.02
          Mean value_function loss: 60.8578
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.1690
                       Mean reward: 669.81
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 1.0802
    Episode_Reward/rotating_object: 130.5424
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.94s
                      Time elapsed: 00:20:22
                               ETA: 00:32:42

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 50756 steps/s (collection: 1.834s, learning 0.103s)
             Mean action noise std: 2.02
          Mean value_function loss: 61.5481
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 46.1796
                       Mean reward: 660.03
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.0795
    Episode_Reward/rotating_object: 130.4027
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.94s
                      Time elapsed: 00:20:24
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 49385 steps/s (collection: 1.830s, learning 0.161s)
             Mean action noise std: 2.02
          Mean value_function loss: 65.1543
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.1881
                       Mean reward: 646.58
               Mean episode length: 236.52
    Episode_Reward/reaching_object: 1.0835
    Episode_Reward/rotating_object: 128.0482
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.99s
                      Time elapsed: 00:20:26
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 49877 steps/s (collection: 1.812s, learning 0.159s)
             Mean action noise std: 2.02
          Mean value_function loss: 67.3172
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.1902
                       Mean reward: 666.50
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.0727
    Episode_Reward/rotating_object: 130.1673
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.97s
                      Time elapsed: 00:20:28
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 47796 steps/s (collection: 1.893s, learning 0.164s)
             Mean action noise std: 2.02
          Mean value_function loss: 61.8200
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 46.1959
                       Mean reward: 690.13
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.0849
    Episode_Reward/rotating_object: 135.2762
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.06s
                      Time elapsed: 00:20:30
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 49851 steps/s (collection: 1.845s, learning 0.127s)
             Mean action noise std: 2.03
          Mean value_function loss: 61.2939
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.2061
                       Mean reward: 696.33
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 1.0917
    Episode_Reward/rotating_object: 137.8774
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 1.97s
                      Time elapsed: 00:20:32
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 50437 steps/s (collection: 1.839s, learning 0.110s)
             Mean action noise std: 2.03
          Mean value_function loss: 60.0239
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.2218
                       Mean reward: 648.28
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.0864
    Episode_Reward/rotating_object: 134.2651
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.95s
                      Time elapsed: 00:20:34
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 50549 steps/s (collection: 1.845s, learning 0.100s)
             Mean action noise std: 2.03
          Mean value_function loss: 60.2987
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 46.2361
                       Mean reward: 688.10
               Mean episode length: 240.19
    Episode_Reward/reaching_object: 1.0989
    Episode_Reward/rotating_object: 135.6804
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.94s
                      Time elapsed: 00:20:36
                               ETA: 00:32:26

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 49806 steps/s (collection: 1.838s, learning 0.136s)
             Mean action noise std: 2.03
          Mean value_function loss: 57.9611
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 46.2490
                       Mean reward: 654.65
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.0890
    Episode_Reward/rotating_object: 133.8400
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.97s
                      Time elapsed: 00:20:38
                               ETA: 00:32:24

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 50387 steps/s (collection: 1.821s, learning 0.130s)
             Mean action noise std: 2.03
          Mean value_function loss: 54.7349
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.2582
                       Mean reward: 656.50
               Mean episode length: 232.06
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 134.5895
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.95s
                      Time elapsed: 00:20:40
                               ETA: 00:32:21

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 51510 steps/s (collection: 1.810s, learning 0.099s)
             Mean action noise std: 2.03
          Mean value_function loss: 54.3793
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.2732
                       Mean reward: 684.98
               Mean episode length: 242.65
    Episode_Reward/reaching_object: 1.0676
    Episode_Reward/rotating_object: 132.7765
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.91s
                      Time elapsed: 00:20:41
                               ETA: 00:32:19

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 51238 steps/s (collection: 1.795s, learning 0.123s)
             Mean action noise std: 2.04
          Mean value_function loss: 66.5837
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.2913
                       Mean reward: 669.77
               Mean episode length: 235.11
    Episode_Reward/reaching_object: 1.0665
    Episode_Reward/rotating_object: 136.5639
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.92s
                      Time elapsed: 00:20:43
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 49830 steps/s (collection: 1.867s, learning 0.106s)
             Mean action noise std: 2.04
          Mean value_function loss: 58.1291
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.3049
                       Mean reward: 683.48
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.0594
    Episode_Reward/rotating_object: 134.5135
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.97s
                      Time elapsed: 00:20:45
                               ETA: 00:32:14

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 50682 steps/s (collection: 1.820s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 57.8844
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.3168
                       Mean reward: 646.56
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.0598
    Episode_Reward/rotating_object: 134.9086
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.94s
                      Time elapsed: 00:20:47
                               ETA: 00:32:12

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 49247 steps/s (collection: 1.882s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 55.8104
               Mean surrogate loss: 0.0024
                 Mean entropy loss: 46.3280
                       Mean reward: 681.88
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.0688
    Episode_Reward/rotating_object: 137.3370
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.00s
                      Time elapsed: 00:20:49
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 48723 steps/s (collection: 1.897s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 61.8652
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 46.3294
                       Mean reward: 673.95
               Mean episode length: 241.98
    Episode_Reward/reaching_object: 1.0737
    Episode_Reward/rotating_object: 137.0479
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.02s
                      Time elapsed: 00:20:51
                               ETA: 00:32:07

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 47677 steps/s (collection: 1.936s, learning 0.126s)
             Mean action noise std: 2.04
          Mean value_function loss: 58.1497
               Mean surrogate loss: 0.0053
                 Mean entropy loss: 46.3314
                       Mean reward: 693.89
               Mean episode length: 245.25
    Episode_Reward/reaching_object: 1.0601
    Episode_Reward/rotating_object: 134.4762
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.06s
                      Time elapsed: 00:20:53
                               ETA: 00:32:05

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 49131 steps/s (collection: 1.876s, learning 0.125s)
             Mean action noise std: 2.04
          Mean value_function loss: 62.6733
               Mean surrogate loss: 0.0037
                 Mean entropy loss: 46.3333
                       Mean reward: 665.73
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.0631
    Episode_Reward/rotating_object: 134.1388
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.00s
                      Time elapsed: 00:20:55
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 49691 steps/s (collection: 1.860s, learning 0.119s)
             Mean action noise std: 2.04
          Mean value_function loss: 56.7446
               Mean surrogate loss: 0.0064
                 Mean entropy loss: 46.3347
                       Mean reward: 647.26
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 133.9341
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.98s
                      Time elapsed: 00:20:57
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 47749 steps/s (collection: 1.939s, learning 0.120s)
             Mean action noise std: 2.04
          Mean value_function loss: 52.5993
               Mean surrogate loss: 0.0033
                 Mean entropy loss: 46.3356
                       Mean reward: 695.16
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 1.1049
    Episode_Reward/rotating_object: 136.1707
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.06s
                      Time elapsed: 00:20:59
                               ETA: 00:31:58

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 50636 steps/s (collection: 1.821s, learning 0.121s)
             Mean action noise std: 2.04
          Mean value_function loss: 55.6236
               Mean surrogate loss: 0.0061
                 Mean entropy loss: 46.3362
                       Mean reward: 693.05
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.0967
    Episode_Reward/rotating_object: 139.3653
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.94s
                      Time elapsed: 00:21:01
                               ETA: 00:31:56

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 51177 steps/s (collection: 1.807s, learning 0.114s)
             Mean action noise std: 2.04
          Mean value_function loss: 61.1373
               Mean surrogate loss: 0.0055
                 Mean entropy loss: 46.3369
                       Mean reward: 660.20
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.0807
    Episode_Reward/rotating_object: 133.1139
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.92s
                      Time elapsed: 00:21:03
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 41862 steps/s (collection: 2.128s, learning 0.221s)
             Mean action noise std: 2.04
          Mean value_function loss: 59.3989
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 46.3379
                       Mean reward: 697.34
               Mean episode length: 246.36
    Episode_Reward/reaching_object: 1.1090
    Episode_Reward/rotating_object: 137.2044
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.35s
                      Time elapsed: 00:21:06
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 44377 steps/s (collection: 2.049s, learning 0.166s)
             Mean action noise std: 2.04
          Mean value_function loss: 60.0343
               Mean surrogate loss: 0.0070
                 Mean entropy loss: 46.3389
                       Mean reward: 684.56
               Mean episode length: 241.90
    Episode_Reward/reaching_object: 1.1209
    Episode_Reward/rotating_object: 137.1040
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.22s
                      Time elapsed: 00:21:08
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 43047 steps/s (collection: 2.141s, learning 0.143s)
             Mean action noise std: 2.04
          Mean value_function loss: 61.5501
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 46.3391
                       Mean reward: 692.58
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 1.1180
    Episode_Reward/rotating_object: 138.1185
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.28s
                      Time elapsed: 00:21:10
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 47075 steps/s (collection: 1.933s, learning 0.156s)
             Mean action noise std: 2.04
          Mean value_function loss: 68.8342
               Mean surrogate loss: 0.0052
                 Mean entropy loss: 46.3395
                       Mean reward: 697.41
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 1.1199
    Episode_Reward/rotating_object: 137.3730
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.09s
                      Time elapsed: 00:21:12
                               ETA: 00:31:45

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 47455 steps/s (collection: 1.930s, learning 0.142s)
             Mean action noise std: 2.04
          Mean value_function loss: 59.9916
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 46.3404
                       Mean reward: 689.34
               Mean episode length: 240.38
    Episode_Reward/reaching_object: 1.1181
    Episode_Reward/rotating_object: 137.4525
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.07s
                      Time elapsed: 00:21:14
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 46922 steps/s (collection: 1.973s, learning 0.122s)
             Mean action noise std: 2.04
          Mean value_function loss: 66.0525
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 46.3454
                       Mean reward: 671.21
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.1316
    Episode_Reward/rotating_object: 135.0985
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.10s
                      Time elapsed: 00:21:16
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 47622 steps/s (collection: 1.925s, learning 0.139s)
             Mean action noise std: 2.04
          Mean value_function loss: 58.8244
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.3636
                       Mean reward: 694.57
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.1273
    Episode_Reward/rotating_object: 139.6053
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0141
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.06s
                      Time elapsed: 00:21:18
                               ETA: 00:31:39

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 40129 steps/s (collection: 2.151s, learning 0.299s)
             Mean action noise std: 2.04
          Mean value_function loss: 57.4077
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 46.3774
                       Mean reward: 704.92
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.1458
    Episode_Reward/rotating_object: 139.4319
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.45s
                      Time elapsed: 00:21:21
                               ETA: 00:31:37

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 46812 steps/s (collection: 1.910s, learning 0.190s)
             Mean action noise std: 2.05
          Mean value_function loss: 63.9238
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 46.3860
                       Mean reward: 652.98
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 1.1251
    Episode_Reward/rotating_object: 133.6879
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.10s
                      Time elapsed: 00:21:23
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 42691 steps/s (collection: 2.119s, learning 0.184s)
             Mean action noise std: 2.05
          Mean value_function loss: 56.6840
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 46.4064
                       Mean reward: 665.00
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.1464
    Episode_Reward/rotating_object: 138.0272
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.30s
                      Time elapsed: 00:21:25
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 36665 steps/s (collection: 2.342s, learning 0.339s)
             Mean action noise std: 2.05
          Mean value_function loss: 64.1598
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.4165
                       Mean reward: 706.28
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.1240
    Episode_Reward/rotating_object: 136.0549
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.68s
                      Time elapsed: 00:21:28
                               ETA: 00:31:32

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 44812 steps/s (collection: 2.090s, learning 0.104s)
             Mean action noise std: 2.05
          Mean value_function loss: 64.6116
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 46.4280
                       Mean reward: 680.70
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.1315
    Episode_Reward/rotating_object: 138.8599
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.19s
                      Time elapsed: 00:21:30
                               ETA: 00:31:30

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 45346 steps/s (collection: 2.052s, learning 0.116s)
             Mean action noise std: 2.05
          Mean value_function loss: 58.6472
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.4545
                       Mean reward: 673.96
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.1383
    Episode_Reward/rotating_object: 135.0015
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.17s
                      Time elapsed: 00:21:32
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 49759 steps/s (collection: 1.869s, learning 0.107s)
             Mean action noise std: 2.06
          Mean value_function loss: 59.9137
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 46.4770
                       Mean reward: 719.63
               Mean episode length: 246.08
    Episode_Reward/reaching_object: 1.1355
    Episode_Reward/rotating_object: 138.9284
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.98s
                      Time elapsed: 00:21:34
                               ETA: 00:31:26

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 49513 steps/s (collection: 1.863s, learning 0.123s)
             Mean action noise std: 2.06
          Mean value_function loss: 57.2759
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.4970
                       Mean reward: 695.15
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 1.1445
    Episode_Reward/rotating_object: 140.5937
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.99s
                      Time elapsed: 00:21:36
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 47541 steps/s (collection: 1.926s, learning 0.142s)
             Mean action noise std: 2.06
          Mean value_function loss: 59.8631
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.5090
                       Mean reward: 718.94
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.1272
    Episode_Reward/rotating_object: 135.3161
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.07s
                      Time elapsed: 00:21:38
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 48084 steps/s (collection: 1.920s, learning 0.124s)
             Mean action noise std: 2.06
          Mean value_function loss: 58.4106
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 46.5209
                       Mean reward: 684.57
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.1193
    Episode_Reward/rotating_object: 134.6744
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.04s
                      Time elapsed: 00:21:40
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 50706 steps/s (collection: 1.822s, learning 0.117s)
             Mean action noise std: 2.06
          Mean value_function loss: 56.7630
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 46.5402
                       Mean reward: 694.04
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.1319
    Episode_Reward/rotating_object: 136.7619
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.94s
                      Time elapsed: 00:21:42
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 51255 steps/s (collection: 1.813s, learning 0.105s)
             Mean action noise std: 2.06
          Mean value_function loss: 55.9320
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.5452
                       Mean reward: 703.68
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 1.1133
    Episode_Reward/rotating_object: 139.3953
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.92s
                      Time elapsed: 00:21:44
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 50892 steps/s (collection: 1.802s, learning 0.130s)
             Mean action noise std: 2.07
          Mean value_function loss: 55.4300
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.5546
                       Mean reward: 714.69
               Mean episode length: 245.40
    Episode_Reward/reaching_object: 1.1247
    Episode_Reward/rotating_object: 139.9935
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.93s
                      Time elapsed: 00:21:46
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 50280 steps/s (collection: 1.809s, learning 0.146s)
             Mean action noise std: 2.07
          Mean value_function loss: 49.2345
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.5718
                       Mean reward: 697.59
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 1.1262
    Episode_Reward/rotating_object: 136.8265
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.96s
                      Time elapsed: 00:21:48
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 48948 steps/s (collection: 1.876s, learning 0.132s)
             Mean action noise std: 2.07
          Mean value_function loss: 53.5490
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.5870
                       Mean reward: 700.22
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 1.1431
    Episode_Reward/rotating_object: 141.6693
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.01s
                      Time elapsed: 00:21:50
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 47723 steps/s (collection: 1.929s, learning 0.131s)
             Mean action noise std: 2.07
          Mean value_function loss: 53.8030
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 46.5994
                       Mean reward: 737.83
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 1.1137
    Episode_Reward/rotating_object: 138.4405
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.06s
                      Time elapsed: 00:21:52
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 49904 steps/s (collection: 1.852s, learning 0.118s)
             Mean action noise std: 2.07
          Mean value_function loss: 58.5352
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 46.6068
                       Mean reward: 709.91
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 1.1199
    Episode_Reward/rotating_object: 139.6088
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.97s
                      Time elapsed: 00:21:54
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 49267 steps/s (collection: 1.863s, learning 0.133s)
             Mean action noise std: 2.07
          Mean value_function loss: 58.8668
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 46.6218
                       Mean reward: 677.07
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.1180
    Episode_Reward/rotating_object: 135.6905
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.00s
                      Time elapsed: 00:21:56
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 50887 steps/s (collection: 1.810s, learning 0.122s)
             Mean action noise std: 2.08
          Mean value_function loss: 59.8459
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.6409
                       Mean reward: 703.41
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.1283
    Episode_Reward/rotating_object: 141.0592
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.93s
                      Time elapsed: 00:21:58
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 48996 steps/s (collection: 1.874s, learning 0.132s)
             Mean action noise std: 2.08
          Mean value_function loss: 54.8430
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 46.6680
                       Mean reward: 664.20
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.1086
    Episode_Reward/rotating_object: 137.0307
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.01s
                      Time elapsed: 00:22:00
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 49948 steps/s (collection: 1.839s, learning 0.129s)
             Mean action noise std: 2.08
          Mean value_function loss: 50.7809
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.6997
                       Mean reward: 726.36
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.1359
    Episode_Reward/rotating_object: 142.3891
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.97s
                      Time elapsed: 00:22:02
                               ETA: 00:30:53

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 50486 steps/s (collection: 1.814s, learning 0.133s)
             Mean action noise std: 2.09
          Mean value_function loss: 56.8535
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 46.7242
                       Mean reward: 714.53
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 1.1353
    Episode_Reward/rotating_object: 141.4866
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.95s
                      Time elapsed: 00:22:04
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 49698 steps/s (collection: 1.842s, learning 0.136s)
             Mean action noise std: 2.09
          Mean value_function loss: 55.3885
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.7360
                       Mean reward: 699.48
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.1090
    Episode_Reward/rotating_object: 137.6309
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.98s
                      Time elapsed: 00:22:06
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 49580 steps/s (collection: 1.856s, learning 0.127s)
             Mean action noise std: 2.09
          Mean value_function loss: 50.8548
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 46.7564
                       Mean reward: 730.56
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 1.1402
    Episode_Reward/rotating_object: 143.5807
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.98s
                      Time elapsed: 00:22:08
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 50613 steps/s (collection: 1.839s, learning 0.104s)
             Mean action noise std: 2.09
          Mean value_function loss: 50.8709
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.7714
                       Mean reward: 701.36
               Mean episode length: 244.85
    Episode_Reward/reaching_object: 1.1295
    Episode_Reward/rotating_object: 141.3632
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.94s
                      Time elapsed: 00:22:10
                               ETA: 00:30:44

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 49457 steps/s (collection: 1.862s, learning 0.126s)
             Mean action noise std: 2.09
          Mean value_function loss: 57.6906
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.7833
                       Mean reward: 667.88
               Mean episode length: 232.71
    Episode_Reward/reaching_object: 1.1095
    Episode_Reward/rotating_object: 136.0764
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.99s
                      Time elapsed: 00:22:12
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 50151 steps/s (collection: 1.826s, learning 0.135s)
             Mean action noise std: 2.09
          Mean value_function loss: 48.0183
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.7956
                       Mean reward: 701.29
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.1285
    Episode_Reward/rotating_object: 139.9615
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.96s
                      Time elapsed: 00:22:14
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 50174 steps/s (collection: 1.826s, learning 0.133s)
             Mean action noise std: 2.10
          Mean value_function loss: 50.9866
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.8087
                       Mean reward: 714.65
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 1.1210
    Episode_Reward/rotating_object: 139.2410
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.96s
                      Time elapsed: 00:22:16
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 50274 steps/s (collection: 1.830s, learning 0.125s)
             Mean action noise std: 2.10
          Mean value_function loss: 51.9027
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.8159
                       Mean reward: 698.71
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 1.1071
    Episode_Reward/rotating_object: 137.5616
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.96s
                      Time elapsed: 00:22:18
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 50902 steps/s (collection: 1.812s, learning 0.120s)
             Mean action noise std: 2.10
          Mean value_function loss: 53.4599
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 46.8281
                       Mean reward: 722.48
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 1.1226
    Episode_Reward/rotating_object: 142.1811
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.93s
                      Time elapsed: 00:22:20
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 51434 steps/s (collection: 1.790s, learning 0.121s)
             Mean action noise std: 2.10
          Mean value_function loss: 50.3398
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.8455
                       Mean reward: 709.52
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.1175
    Episode_Reward/rotating_object: 140.3448
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.91s
                      Time elapsed: 00:22:22
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 50979 steps/s (collection: 1.809s, learning 0.120s)
             Mean action noise std: 2.10
          Mean value_function loss: 51.7084
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.8610
                       Mean reward: 711.25
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 1.1213
    Episode_Reward/rotating_object: 138.7475
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.93s
                      Time elapsed: 00:22:24
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 50226 steps/s (collection: 1.831s, learning 0.126s)
             Mean action noise std: 2.10
          Mean value_function loss: 48.8859
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 46.8737
                       Mean reward: 723.81
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 1.1300
    Episode_Reward/rotating_object: 141.9955
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.96s
                      Time elapsed: 00:22:25
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 51867 steps/s (collection: 1.795s, learning 0.100s)
             Mean action noise std: 2.11
          Mean value_function loss: 45.1519
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 46.8958
                       Mean reward: 726.21
               Mean episode length: 246.56
    Episode_Reward/reaching_object: 1.1192
    Episode_Reward/rotating_object: 140.4992
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.90s
                      Time elapsed: 00:22:27
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 50984 steps/s (collection: 1.800s, learning 0.128s)
             Mean action noise std: 2.11
          Mean value_function loss: 42.1095
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 46.9220
                       Mean reward: 691.87
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 1.1200
    Episode_Reward/rotating_object: 142.3079
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.93s
                      Time elapsed: 00:22:29
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 49975 steps/s (collection: 1.835s, learning 0.132s)
             Mean action noise std: 2.11
          Mean value_function loss: 44.8885
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.9411
                       Mean reward: 722.14
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 1.1130
    Episode_Reward/rotating_object: 139.8166
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.97s
                      Time elapsed: 00:22:31
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 49462 steps/s (collection: 1.867s, learning 0.120s)
             Mean action noise std: 2.11
          Mean value_function loss: 50.1097
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 46.9575
                       Mean reward: 712.10
               Mean episode length: 246.87
    Episode_Reward/reaching_object: 1.1337
    Episode_Reward/rotating_object: 141.5872
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.99s
                      Time elapsed: 00:22:33
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 49326 steps/s (collection: 1.868s, learning 0.125s)
             Mean action noise std: 2.12
          Mean value_function loss: 44.9932
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.9804
                       Mean reward: 705.87
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 1.1193
    Episode_Reward/rotating_object: 141.2932
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.99s
                      Time elapsed: 00:22:35
                               ETA: 00:30:14

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 50109 steps/s (collection: 1.838s, learning 0.124s)
             Mean action noise std: 2.12
          Mean value_function loss: 52.3589
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.0028
                       Mean reward: 712.18
               Mean episode length: 242.30
    Episode_Reward/reaching_object: 1.1392
    Episode_Reward/rotating_object: 141.6364
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.96s
                      Time elapsed: 00:22:37
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 47666 steps/s (collection: 1.932s, learning 0.131s)
             Mean action noise std: 2.12
          Mean value_function loss: 48.1198
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 47.0194
                       Mean reward: 687.52
               Mean episode length: 242.44
    Episode_Reward/reaching_object: 1.1080
    Episode_Reward/rotating_object: 139.1071
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.06s
                      Time elapsed: 00:22:39
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 50275 steps/s (collection: 1.828s, learning 0.127s)
             Mean action noise std: 2.12
          Mean value_function loss: 45.5866
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.0230
                       Mean reward: 719.87
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.1392
    Episode_Reward/rotating_object: 141.9315
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.96s
                      Time elapsed: 00:22:41
                               ETA: 00:30:07

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 50470 steps/s (collection: 1.821s, learning 0.127s)
             Mean action noise std: 2.12
          Mean value_function loss: 44.9637
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.0269
                       Mean reward: 717.82
               Mean episode length: 244.67
    Episode_Reward/reaching_object: 1.1297
    Episode_Reward/rotating_object: 141.0512
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 1.95s
                      Time elapsed: 00:22:43
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 50752 steps/s (collection: 1.814s, learning 0.123s)
             Mean action noise std: 2.13
          Mean value_function loss: 45.9827
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.0493
                       Mean reward: 690.28
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.1056
    Episode_Reward/rotating_object: 139.8456
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.94s
                      Time elapsed: 00:22:45
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 51334 steps/s (collection: 1.791s, learning 0.124s)
             Mean action noise std: 2.13
          Mean value_function loss: 47.9349
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.0786
                       Mean reward: 680.01
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 140.1668
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.91s
                      Time elapsed: 00:22:47
                               ETA: 00:30:00

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 50235 steps/s (collection: 1.826s, learning 0.131s)
             Mean action noise std: 2.13
          Mean value_function loss: 34.7705
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.0986
                       Mean reward: 735.96
               Mean episode length: 247.35
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 143.5923
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.96s
                      Time elapsed: 00:22:49
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 51544 steps/s (collection: 1.807s, learning 0.101s)
             Mean action noise std: 2.13
          Mean value_function loss: 50.1646
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.1139
                       Mean reward: 707.17
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.1420
    Episode_Reward/rotating_object: 145.4033
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.91s
                      Time elapsed: 00:22:51
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 50833 steps/s (collection: 1.816s, learning 0.117s)
             Mean action noise std: 2.14
          Mean value_function loss: 42.2439
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.1351
                       Mean reward: 704.27
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 1.1259
    Episode_Reward/rotating_object: 141.8800
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 1.93s
                      Time elapsed: 00:22:53
                               ETA: 00:29:53

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 49727 steps/s (collection: 1.842s, learning 0.135s)
             Mean action noise std: 2.14
          Mean value_function loss: 44.4474
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 47.1501
                       Mean reward: 716.57
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 1.1361
    Episode_Reward/rotating_object: 144.2909
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 1.98s
                      Time elapsed: 00:22:55
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 50254 steps/s (collection: 1.831s, learning 0.125s)
             Mean action noise std: 2.14
          Mean value_function loss: 53.5857
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.1633
                       Mean reward: 704.18
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 1.1399
    Episode_Reward/rotating_object: 141.5537
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.96s
                      Time elapsed: 00:22:57
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 50439 steps/s (collection: 1.822s, learning 0.127s)
             Mean action noise std: 2.14
          Mean value_function loss: 53.1948
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.1788
                       Mean reward: 731.55
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.1301
    Episode_Reward/rotating_object: 144.2421
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.95s
                      Time elapsed: 00:22:59
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 49970 steps/s (collection: 1.841s, learning 0.126s)
             Mean action noise std: 2.14
          Mean value_function loss: 49.6519
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 47.1904
                       Mean reward: 729.47
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 1.1510
    Episode_Reward/rotating_object: 144.9721
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.97s
                      Time elapsed: 00:23:01
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 50131 steps/s (collection: 1.846s, learning 0.115s)
             Mean action noise std: 2.14
          Mean value_function loss: 46.8073
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 47.2011
                       Mean reward: 724.82
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 144.9521
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.96s
                      Time elapsed: 00:23:03
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 50387 steps/s (collection: 1.826s, learning 0.125s)
             Mean action noise std: 2.15
          Mean value_function loss: 41.5655
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 47.2275
                       Mean reward: 704.42
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 1.1425
    Episode_Reward/rotating_object: 140.9065
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.95s
                      Time elapsed: 00:23:05
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 50462 steps/s (collection: 1.834s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 51.3562
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 47.2475
                       Mean reward: 726.16
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 1.1345
    Episode_Reward/rotating_object: 143.7527
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.95s
                      Time elapsed: 00:23:07
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 49843 steps/s (collection: 1.861s, learning 0.111s)
             Mean action noise std: 2.15
          Mean value_function loss: 39.0914
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.2586
                       Mean reward: 742.10
               Mean episode length: 246.83
    Episode_Reward/reaching_object: 1.1343
    Episode_Reward/rotating_object: 144.3816
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.97s
                      Time elapsed: 00:23:09
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 51795 steps/s (collection: 1.794s, learning 0.104s)
             Mean action noise std: 2.15
          Mean value_function loss: 35.9147
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.2799
                       Mean reward: 733.03
               Mean episode length: 247.56
    Episode_Reward/reaching_object: 1.1387
    Episode_Reward/rotating_object: 143.3997
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.90s
                      Time elapsed: 00:23:10
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 51440 steps/s (collection: 1.791s, learning 0.121s)
             Mean action noise std: 2.15
          Mean value_function loss: 45.2464
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.2995
                       Mean reward: 755.74
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 1.1444
    Episode_Reward/rotating_object: 144.5562
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.91s
                      Time elapsed: 00:23:12
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 49722 steps/s (collection: 1.843s, learning 0.134s)
             Mean action noise std: 2.16
          Mean value_function loss: 39.5569
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.3145
                       Mean reward: 738.37
               Mean episode length: 246.64
    Episode_Reward/reaching_object: 1.1418
    Episode_Reward/rotating_object: 143.6883
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.98s
                      Time elapsed: 00:23:14
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 50873 steps/s (collection: 1.804s, learning 0.129s)
             Mean action noise std: 2.16
          Mean value_function loss: 43.3635
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 47.3380
                       Mean reward: 715.24
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.1367
    Episode_Reward/rotating_object: 144.7648
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.93s
                      Time elapsed: 00:23:16
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 50337 steps/s (collection: 1.818s, learning 0.135s)
             Mean action noise std: 2.17
          Mean value_function loss: 51.0724
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.3717
                       Mean reward: 690.37
               Mean episode length: 236.60
    Episode_Reward/reaching_object: 1.1204
    Episode_Reward/rotating_object: 140.7686
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.95s
                      Time elapsed: 00:23:18
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 51474 steps/s (collection: 1.787s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 47.7083
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.4047
                       Mean reward: 750.25
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 1.1297
    Episode_Reward/rotating_object: 143.2120
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.91s
                      Time elapsed: 00:23:20
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 51406 steps/s (collection: 1.788s, learning 0.124s)
             Mean action noise std: 2.17
          Mean value_function loss: 47.4479
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 47.4186
                       Mean reward: 703.30
               Mean episode length: 238.36
    Episode_Reward/reaching_object: 1.1268
    Episode_Reward/rotating_object: 143.0293
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.91s
                      Time elapsed: 00:23:22
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 29207 steps/s (collection: 3.249s, learning 0.117s)
             Mean action noise std: 2.17
          Mean value_function loss: 40.8482
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.4320
                       Mean reward: 724.65
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 1.1231
    Episode_Reward/rotating_object: 142.9588
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.37s
                      Time elapsed: 00:23:25
                               ETA: 00:29:17

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 15343 steps/s (collection: 6.273s, learning 0.134s)
             Mean action noise std: 2.17
          Mean value_function loss: 45.1543
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.4457
                       Mean reward: 714.97
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 145.3441
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.41s
                      Time elapsed: 00:23:32
                               ETA: 00:29:21

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 15122 steps/s (collection: 6.371s, learning 0.130s)
             Mean action noise std: 2.17
          Mean value_function loss: 36.4254
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.4613
                       Mean reward: 705.38
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 1.1202
    Episode_Reward/rotating_object: 143.4523
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.50s
                      Time elapsed: 00:23:38
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14904 steps/s (collection: 6.463s, learning 0.133s)
             Mean action noise std: 2.18
          Mean value_function loss: 37.9130
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.4737
                       Mean reward: 741.99
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 1.1246
    Episode_Reward/rotating_object: 143.0645
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.60s
                      Time elapsed: 00:23:45
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14680 steps/s (collection: 6.557s, learning 0.140s)
             Mean action noise std: 2.18
          Mean value_function loss: 41.9622
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.4888
                       Mean reward: 756.66
               Mean episode length: 249.89
    Episode_Reward/reaching_object: 1.1244
    Episode_Reward/rotating_object: 144.2584
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.70s
                      Time elapsed: 00:23:52
                               ETA: 00:29:31

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 15738 steps/s (collection: 6.126s, learning 0.120s)
             Mean action noise std: 2.18
          Mean value_function loss: 41.8061
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.5061
                       Mean reward: 708.39
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.1132
    Episode_Reward/rotating_object: 143.8982
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.25s
                      Time elapsed: 00:23:58
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 15264 steps/s (collection: 6.296s, learning 0.145s)
             Mean action noise std: 2.18
          Mean value_function loss: 44.6023
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.5225
                       Mean reward: 736.54
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 1.1244
    Episode_Reward/rotating_object: 145.9473
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.44s
                      Time elapsed: 00:24:04
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 14908 steps/s (collection: 6.465s, learning 0.129s)
             Mean action noise std: 2.18
          Mean value_function loss: 47.9670
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.5362
                       Mean reward: 718.56
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 1.1144
    Episode_Reward/rotating_object: 141.2343
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.59s
                      Time elapsed: 00:24:11
                               ETA: 00:29:40

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 15228 steps/s (collection: 6.323s, learning 0.133s)
             Mean action noise std: 2.19
          Mean value_function loss: 46.8517
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.5576
                       Mean reward: 723.05
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.1123
    Episode_Reward/rotating_object: 142.0122
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.46s
                      Time elapsed: 00:24:17
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 25591 steps/s (collection: 3.734s, learning 0.107s)
             Mean action noise std: 2.19
          Mean value_function loss: 42.5294
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.5702
                       Mean reward: 734.85
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 1.1403
    Episode_Reward/rotating_object: 145.1884
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 3.84s
                      Time elapsed: 00:24:21
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 52817 steps/s (collection: 1.747s, learning 0.115s)
             Mean action noise std: 2.19
          Mean value_function loss: 45.7627
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.5797
                       Mean reward: 728.68
               Mean episode length: 242.45
    Episode_Reward/reaching_object: 1.1404
    Episode_Reward/rotating_object: 145.5702
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.86s
                      Time elapsed: 00:24:23
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 54446 steps/s (collection: 1.704s, learning 0.102s)
             Mean action noise std: 2.19
          Mean value_function loss: 46.6295
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.5930
                       Mean reward: 697.23
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.1251
    Episode_Reward/rotating_object: 143.4604
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.81s
                      Time elapsed: 00:24:25
                               ETA: 00:29:38

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 54157 steps/s (collection: 1.698s, learning 0.117s)
             Mean action noise std: 2.19
          Mean value_function loss: 49.4898
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 47.6082
                       Mean reward: 725.60
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 1.1253
    Episode_Reward/rotating_object: 143.4092
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.82s
                      Time elapsed: 00:24:27
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 54841 steps/s (collection: 1.684s, learning 0.109s)
             Mean action noise std: 2.20
          Mean value_function loss: 42.8657
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 47.6264
                       Mean reward: 732.83
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 1.1174
    Episode_Reward/rotating_object: 144.1599
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0147
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.79s
                      Time elapsed: 00:24:28
                               ETA: 00:29:33

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 53367 steps/s (collection: 1.734s, learning 0.108s)
             Mean action noise std: 2.20
          Mean value_function loss: 48.2864
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.6376
                       Mean reward: 734.29
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.1228
    Episode_Reward/rotating_object: 143.6985
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.84s
                      Time elapsed: 00:24:30
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 53482 steps/s (collection: 1.727s, learning 0.112s)
             Mean action noise std: 2.20
          Mean value_function loss: 53.3222
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.6527
                       Mean reward: 718.14
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 1.1274
    Episode_Reward/rotating_object: 144.0719
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.84s
                      Time elapsed: 00:24:32
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 52130 steps/s (collection: 1.778s, learning 0.108s)
             Mean action noise std: 2.20
          Mean value_function loss: 46.7914
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.6695
                       Mean reward: 742.55
               Mean episode length: 247.39
    Episode_Reward/reaching_object: 1.1403
    Episode_Reward/rotating_object: 145.4402
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0151
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.89s
                      Time elapsed: 00:24:34
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 53558 steps/s (collection: 1.720s, learning 0.116s)
             Mean action noise std: 2.21
          Mean value_function loss: 48.0293
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.6884
                       Mean reward: 713.68
               Mean episode length: 238.38
    Episode_Reward/reaching_object: 1.1241
    Episode_Reward/rotating_object: 142.9992
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.84s
                      Time elapsed: 00:24:36
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 53640 steps/s (collection: 1.715s, learning 0.118s)
             Mean action noise std: 2.21
          Mean value_function loss: 50.3259
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.7155
                       Mean reward: 717.40
               Mean episode length: 240.61
    Episode_Reward/reaching_object: 1.1241
    Episode_Reward/rotating_object: 143.6273
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.83s
                      Time elapsed: 00:24:38
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 52952 steps/s (collection: 1.732s, learning 0.125s)
             Mean action noise std: 2.21
          Mean value_function loss: 50.5283
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 47.7410
                       Mean reward: 726.63
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 1.1276
    Episode_Reward/rotating_object: 143.9825
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.86s
                      Time elapsed: 00:24:40
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 52969 steps/s (collection: 1.739s, learning 0.117s)
             Mean action noise std: 2.21
          Mean value_function loss: 46.2901
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.7640
                       Mean reward: 718.06
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.1267
    Episode_Reward/rotating_object: 143.5608
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.86s
                      Time elapsed: 00:24:41
                               ETA: 00:29:15

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 53801 steps/s (collection: 1.734s, learning 0.094s)
             Mean action noise std: 2.22
          Mean value_function loss: 42.4699
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.7912
                       Mean reward: 754.41
               Mean episode length: 248.32
    Episode_Reward/reaching_object: 1.1398
    Episode_Reward/rotating_object: 145.2064
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.83s
                      Time elapsed: 00:24:43
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 53313 steps/s (collection: 1.733s, learning 0.111s)
             Mean action noise std: 2.22
          Mean value_function loss: 45.1278
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.8121
                       Mean reward: 705.63
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.1294
    Episode_Reward/rotating_object: 143.9167
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.84s
                      Time elapsed: 00:24:45
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 54149 steps/s (collection: 1.698s, learning 0.118s)
             Mean action noise std: 2.22
          Mean value_function loss: 45.7049
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.8323
                       Mean reward: 704.24
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.1261
    Episode_Reward/rotating_object: 141.0264
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.82s
                      Time elapsed: 00:24:47
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 53223 steps/s (collection: 1.731s, learning 0.116s)
             Mean action noise std: 2.22
          Mean value_function loss: 36.1778
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.8519
                       Mean reward: 747.14
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 1.1500
    Episode_Reward/rotating_object: 143.9919
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.85s
                      Time elapsed: 00:24:49
                               ETA: 00:29:05

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 53476 steps/s (collection: 1.723s, learning 0.115s)
             Mean action noise std: 2.23
          Mean value_function loss: 49.8840
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 47.8710
                       Mean reward: 717.68
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.1173
    Episode_Reward/rotating_object: 141.1208
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.84s
                      Time elapsed: 00:24:51
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 54575 steps/s (collection: 1.697s, learning 0.105s)
             Mean action noise std: 2.23
          Mean value_function loss: 53.0319
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 47.8978
                       Mean reward: 706.45
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.1275
    Episode_Reward/rotating_object: 144.1590
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.80s
                      Time elapsed: 00:24:52
                               ETA: 00:29:00

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 53071 steps/s (collection: 1.741s, learning 0.111s)
             Mean action noise std: 2.23
          Mean value_function loss: 47.7678
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 47.9150
                       Mean reward: 724.90
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.1310
    Episode_Reward/rotating_object: 144.9480
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.85s
                      Time elapsed: 00:24:54
                               ETA: 00:28:58

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 52206 steps/s (collection: 1.770s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 46.8490
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 47.9414
                       Mean reward: 750.60
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 1.1334
    Episode_Reward/rotating_object: 142.9062
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.88s
                      Time elapsed: 00:24:56
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 52550 steps/s (collection: 1.757s, learning 0.114s)
             Mean action noise std: 2.24
          Mean value_function loss: 50.6259
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 47.9652
                       Mean reward: 730.83
               Mean episode length: 240.36
    Episode_Reward/reaching_object: 1.1275
    Episode_Reward/rotating_object: 144.5694
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.87s
                      Time elapsed: 00:24:58
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 54571 steps/s (collection: 1.704s, learning 0.097s)
             Mean action noise std: 2.24
          Mean value_function loss: 43.6410
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.9896
                       Mean reward: 723.19
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 1.1358
    Episode_Reward/rotating_object: 145.0915
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.80s
                      Time elapsed: 00:25:00
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 53166 steps/s (collection: 1.741s, learning 0.108s)
             Mean action noise std: 2.24
          Mean value_function loss: 41.2689
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.0177
                       Mean reward: 728.97
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 1.1371
    Episode_Reward/rotating_object: 145.2096
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.85s
                      Time elapsed: 00:25:02
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 53011 steps/s (collection: 1.742s, learning 0.113s)
             Mean action noise std: 2.25
          Mean value_function loss: 38.1206
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 48.0385
                       Mean reward: 724.66
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 1.1377
    Episode_Reward/rotating_object: 146.0178
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.85s
                      Time elapsed: 00:25:03
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 52906 steps/s (collection: 1.747s, learning 0.111s)
             Mean action noise std: 2.25
          Mean value_function loss: 48.4553
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 48.0493
                       Mean reward: 701.18
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.1148
    Episode_Reward/rotating_object: 140.4741
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.86s
                      Time elapsed: 00:25:05
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 52778 steps/s (collection: 1.748s, learning 0.114s)
             Mean action noise std: 2.25
          Mean value_function loss: 38.3121
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 48.0578
                       Mean reward: 728.15
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.1446
    Episode_Reward/rotating_object: 146.6690
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.86s
                      Time elapsed: 00:25:07
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 52591 steps/s (collection: 1.752s, learning 0.118s)
             Mean action noise std: 2.25
          Mean value_function loss: 38.0862
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.0645
                       Mean reward: 766.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1615
    Episode_Reward/rotating_object: 148.8142
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.87s
                      Time elapsed: 00:25:09
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 54004 steps/s (collection: 1.722s, learning 0.098s)
             Mean action noise std: 2.25
          Mean value_function loss: 46.1368
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.0706
                       Mean reward: 709.10
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.1427
    Episode_Reward/rotating_object: 142.8537
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.82s
                      Time elapsed: 00:25:11
                               ETA: 00:28:35

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 53822 steps/s (collection: 1.703s, learning 0.123s)
             Mean action noise std: 2.25
          Mean value_function loss: 38.5882
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 48.0934
                       Mean reward: 754.52
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 1.1480
    Episode_Reward/rotating_object: 146.5574
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.83s
                      Time elapsed: 00:25:13
                               ETA: 00:28:33

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 53775 steps/s (collection: 1.713s, learning 0.115s)
             Mean action noise std: 2.25
          Mean value_function loss: 40.3569
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 48.1045
                       Mean reward: 760.23
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 1.1550
    Episode_Reward/rotating_object: 146.4399
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.83s
                      Time elapsed: 00:25:15
                               ETA: 00:28:30

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 53541 steps/s (collection: 1.728s, learning 0.108s)
             Mean action noise std: 2.25
          Mean value_function loss: 38.5745
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.1087
                       Mean reward: 741.24
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.1546
    Episode_Reward/rotating_object: 147.2531
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.84s
                      Time elapsed: 00:25:16
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 54060 steps/s (collection: 1.710s, learning 0.108s)
             Mean action noise std: 2.26
          Mean value_function loss: 37.8584
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.1177
                       Mean reward: 757.23
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 1.1334
    Episode_Reward/rotating_object: 145.3646
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.82s
                      Time elapsed: 00:25:18
                               ETA: 00:28:25

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 52353 steps/s (collection: 1.772s, learning 0.106s)
             Mean action noise std: 2.26
          Mean value_function loss: 38.9344
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.1372
                       Mean reward: 745.84
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.1477
    Episode_Reward/rotating_object: 149.0920
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.88s
                      Time elapsed: 00:25:20
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 54023 steps/s (collection: 1.702s, learning 0.118s)
             Mean action noise std: 2.26
          Mean value_function loss: 36.3156
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.1618
                       Mean reward: 732.75
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.1412
    Episode_Reward/rotating_object: 147.8933
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.82s
                      Time elapsed: 00:25:22
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 53407 steps/s (collection: 1.728s, learning 0.113s)
             Mean action noise std: 2.26
          Mean value_function loss: 41.4019
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.1796
                       Mean reward: 695.50
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.1213
    Episode_Reward/rotating_object: 142.7606
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.84s
                      Time elapsed: 00:25:24
                               ETA: 00:28:18

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 53388 steps/s (collection: 1.727s, learning 0.114s)
             Mean action noise std: 2.26
          Mean value_function loss: 31.5816
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.1936
                       Mean reward: 742.05
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.1348
    Episode_Reward/rotating_object: 148.4964
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.84s
                      Time elapsed: 00:25:26
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 52983 steps/s (collection: 1.748s, learning 0.108s)
             Mean action noise std: 2.27
          Mean value_function loss: 33.4367
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.2100
                       Mean reward: 752.24
               Mean episode length: 248.68
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 150.5855
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.86s
                      Time elapsed: 00:25:27
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 54233 steps/s (collection: 1.714s, learning 0.099s)
             Mean action noise std: 2.27
          Mean value_function loss: 39.3098
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.2346
                       Mean reward: 734.50
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.1307
    Episode_Reward/rotating_object: 147.0834
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.81s
                      Time elapsed: 00:25:29
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 52226 steps/s (collection: 1.757s, learning 0.125s)
             Mean action noise std: 2.27
          Mean value_function loss: 30.5090
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.2565
                       Mean reward: 767.38
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 1.1480
    Episode_Reward/rotating_object: 151.4495
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.88s
                      Time elapsed: 00:25:31
                               ETA: 00:28:08

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 52856 steps/s (collection: 1.742s, learning 0.118s)
             Mean action noise std: 2.28
          Mean value_function loss: 39.8084
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 48.2774
                       Mean reward: 744.07
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.1306
    Episode_Reward/rotating_object: 145.8785
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.86s
                      Time elapsed: 00:25:33
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 52467 steps/s (collection: 1.762s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 42.8231
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.2901
                       Mean reward: 739.58
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 1.1253
    Episode_Reward/rotating_object: 144.6577
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.87s
                      Time elapsed: 00:25:35
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 53271 steps/s (collection: 1.734s, learning 0.112s)
             Mean action noise std: 2.28
          Mean value_function loss: 47.0256
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.3076
                       Mean reward: 734.12
               Mean episode length: 245.07
    Episode_Reward/reaching_object: 1.1367
    Episode_Reward/rotating_object: 148.8467
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.85s
                      Time elapsed: 00:25:37
                               ETA: 00:28:00

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 53724 steps/s (collection: 1.724s, learning 0.105s)
             Mean action noise std: 2.28
          Mean value_function loss: 31.2899
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.3387
                       Mean reward: 752.84
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.1496
    Episode_Reward/rotating_object: 148.6694
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.83s
                      Time elapsed: 00:25:39
                               ETA: 00:27:58

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 53428 steps/s (collection: 1.731s, learning 0.109s)
             Mean action noise std: 2.29
          Mean value_function loss: 34.9794
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 48.3488
                       Mean reward: 751.52
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 147.8316
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.84s
                      Time elapsed: 00:25:40
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 53534 steps/s (collection: 1.721s, learning 0.116s)
             Mean action noise std: 2.29
          Mean value_function loss: 38.0268
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.3672
                       Mean reward: 751.48
               Mean episode length: 249.86
    Episode_Reward/reaching_object: 1.1419
    Episode_Reward/rotating_object: 146.0269
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.84s
                      Time elapsed: 00:25:42
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 52940 steps/s (collection: 1.738s, learning 0.119s)
             Mean action noise std: 2.29
          Mean value_function loss: 45.6702
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.3863
                       Mean reward: 726.86
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.1337
    Episode_Reward/rotating_object: 145.2958
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.86s
                      Time elapsed: 00:25:44
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 53096 steps/s (collection: 1.731s, learning 0.121s)
             Mean action noise std: 2.29
          Mean value_function loss: 37.5699
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.4045
                       Mean reward: 734.33
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 1.1461
    Episode_Reward/rotating_object: 146.8833
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.85s
                      Time elapsed: 00:25:46
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 53691 steps/s (collection: 1.723s, learning 0.108s)
             Mean action noise std: 2.30
          Mean value_function loss: 43.9557
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.4314
                       Mean reward: 719.31
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.1426
    Episode_Reward/rotating_object: 146.7579
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.83s
                      Time elapsed: 00:25:48
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 53783 steps/s (collection: 1.718s, learning 0.110s)
             Mean action noise std: 2.30
          Mean value_function loss: 36.7266
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 48.4626
                       Mean reward: 726.20
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.1439
    Episode_Reward/rotating_object: 146.4281
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.83s
                      Time elapsed: 00:25:50
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 53155 steps/s (collection: 1.736s, learning 0.114s)
             Mean action noise std: 2.30
          Mean value_function loss: 31.5848
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.4801
                       Mean reward: 763.64
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 1.1469
    Episode_Reward/rotating_object: 148.0928
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.85s
                      Time elapsed: 00:25:51
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 52719 steps/s (collection: 1.761s, learning 0.104s)
             Mean action noise std: 2.30
          Mean value_function loss: 38.6284
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 48.4886
                       Mean reward: 767.18
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 1.1611
    Episode_Reward/rotating_object: 150.2594
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.86s
                      Time elapsed: 00:25:53
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 52148 steps/s (collection: 1.787s, learning 0.098s)
             Mean action noise std: 2.30
          Mean value_function loss: 48.3125
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 48.5016
                       Mean reward: 750.80
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 1.1378
    Episode_Reward/rotating_object: 147.0231
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.89s
                      Time elapsed: 00:25:55
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 53394 steps/s (collection: 1.745s, learning 0.097s)
             Mean action noise std: 2.31
          Mean value_function loss: 45.5749
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.5350
                       Mean reward: 741.19
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 1.1412
    Episode_Reward/rotating_object: 146.9987
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.84s
                      Time elapsed: 00:25:57
                               ETA: 00:27:33

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 52733 steps/s (collection: 1.760s, learning 0.104s)
             Mean action noise std: 2.31
          Mean value_function loss: 39.9034
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.5749
                       Mean reward: 788.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 150.2440
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.86s
                      Time elapsed: 00:25:59
                               ETA: 00:27:31

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 53758 steps/s (collection: 1.726s, learning 0.103s)
             Mean action noise std: 2.31
          Mean value_function loss: 46.1947
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.5964
                       Mean reward: 775.34
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 1.1540
    Episode_Reward/rotating_object: 148.2983
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.83s
                      Time elapsed: 00:26:01
                               ETA: 00:27:28

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 53318 steps/s (collection: 1.745s, learning 0.099s)
             Mean action noise std: 2.32
          Mean value_function loss: 41.5669
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 48.6200
                       Mean reward: 732.70
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 1.1557
    Episode_Reward/rotating_object: 145.6547
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.84s
                      Time elapsed: 00:26:03
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 52629 steps/s (collection: 1.768s, learning 0.100s)
             Mean action noise std: 2.32
          Mean value_function loss: 41.8106
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 48.6370
                       Mean reward: 758.55
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 147.8610
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.87s
                      Time elapsed: 00:26:04
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 52199 steps/s (collection: 1.787s, learning 0.096s)
             Mean action noise std: 2.32
          Mean value_function loss: 37.5154
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.6611
                       Mean reward: 730.09
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 146.5030
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.88s
                      Time elapsed: 00:26:06
                               ETA: 00:27:21

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 51893 steps/s (collection: 1.789s, learning 0.106s)
             Mean action noise std: 2.33
          Mean value_function loss: 34.7428
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.6832
                       Mean reward: 756.34
               Mean episode length: 243.33
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 148.6717
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.89s
                      Time elapsed: 00:26:08
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 53576 steps/s (collection: 1.746s, learning 0.089s)
             Mean action noise std: 2.33
          Mean value_function loss: 30.0144
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 48.7129
                       Mean reward: 755.31
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 151.5527
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.83s
                      Time elapsed: 00:26:10
                               ETA: 00:27:16

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 53314 steps/s (collection: 1.740s, learning 0.104s)
             Mean action noise std: 2.33
          Mean value_function loss: 45.5037
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 48.7258
                       Mean reward: 708.17
               Mean episode length: 235.75
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 146.1789
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.84s
                      Time elapsed: 00:26:12
                               ETA: 00:27:14

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 53273 steps/s (collection: 1.751s, learning 0.094s)
             Mean action noise std: 2.33
          Mean value_function loss: 39.0232
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 48.7462
                       Mean reward: 765.36
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 1.1569
    Episode_Reward/rotating_object: 150.0546
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0152
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.85s
                      Time elapsed: 00:26:14
                               ETA: 00:27:11

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 53202 steps/s (collection: 1.754s, learning 0.094s)
             Mean action noise std: 2.34
          Mean value_function loss: 40.4225
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 48.7753
                       Mean reward: 775.19
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 1.1502
    Episode_Reward/rotating_object: 148.7085
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0148
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.85s
                      Time elapsed: 00:26:16
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 53497 steps/s (collection: 1.739s, learning 0.099s)
             Mean action noise std: 2.34
          Mean value_function loss: 38.3625
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.7959
                       Mean reward: 752.50
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 1.1378
    Episode_Reward/rotating_object: 144.4253
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.84s
                      Time elapsed: 00:26:17
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 52618 steps/s (collection: 1.749s, learning 0.119s)
             Mean action noise std: 2.34
          Mean value_function loss: 49.8936
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 48.8157
                       Mean reward: 767.45
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 1.1516
    Episode_Reward/rotating_object: 148.8703
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.87s
                      Time elapsed: 00:26:19
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 53370 steps/s (collection: 1.731s, learning 0.111s)
             Mean action noise std: 2.34
          Mean value_function loss: 42.6463
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.8252
                       Mean reward: 741.64
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 1.1309
    Episode_Reward/rotating_object: 145.5488
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.84s
                      Time elapsed: 00:26:21
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 52542 steps/s (collection: 1.759s, learning 0.112s)
             Mean action noise std: 2.34
          Mean value_function loss: 38.6504
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 48.8474
                       Mean reward: 740.98
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 148.5324
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.87s
                      Time elapsed: 00:26:23
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 53221 steps/s (collection: 1.742s, learning 0.106s)
             Mean action noise std: 2.35
          Mean value_function loss: 35.8684
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 48.8825
                       Mean reward: 754.36
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 1.1395
    Episode_Reward/rotating_object: 145.7395
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.85s
                      Time elapsed: 00:26:25
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 53473 steps/s (collection: 1.725s, learning 0.113s)
             Mean action noise std: 2.35
          Mean value_function loss: 46.6967
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 48.9084
                       Mean reward: 736.98
               Mean episode length: 242.11
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 149.1759
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.84s
                      Time elapsed: 00:26:27
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 52700 steps/s (collection: 1.754s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 44.6850
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 48.9303
                       Mean reward: 752.86
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 149.7121
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.87s
                      Time elapsed: 00:26:29
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 53258 steps/s (collection: 1.740s, learning 0.106s)
             Mean action noise std: 2.36
          Mean value_function loss: 41.2888
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 48.9498
                       Mean reward: 735.14
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 149.1811
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0154
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.85s
                      Time elapsed: 00:26:30
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 52423 steps/s (collection: 1.758s, learning 0.117s)
             Mean action noise std: 2.36
          Mean value_function loss: 40.9279
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 48.9617
                       Mean reward: 701.54
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 146.2369
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.88s
                      Time elapsed: 00:26:32
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 51643 steps/s (collection: 1.794s, learning 0.109s)
             Mean action noise std: 2.36
          Mean value_function loss: 41.5967
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 48.9694
                       Mean reward: 750.88
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.1559
    Episode_Reward/rotating_object: 147.9207
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.90s
                      Time elapsed: 00:26:34
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 53319 steps/s (collection: 1.739s, learning 0.105s)
             Mean action noise std: 2.36
          Mean value_function loss: 41.6966
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 48.9853
                       Mean reward: 757.34
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 1.1595
    Episode_Reward/rotating_object: 150.1575
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.84s
                      Time elapsed: 00:26:36
                               ETA: 00:26:42

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 53907 steps/s (collection: 1.713s, learning 0.111s)
             Mean action noise std: 2.36
          Mean value_function loss: 39.4633
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.0072
                       Mean reward: 756.60
               Mean episode length: 243.56
    Episode_Reward/reaching_object: 1.1623
    Episode_Reward/rotating_object: 148.9353
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.82s
                      Time elapsed: 00:26:38
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 52094 steps/s (collection: 1.775s, learning 0.112s)
             Mean action noise std: 2.36
          Mean value_function loss: 31.6415
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.0247
                       Mean reward: 752.54
               Mean episode length: 245.07
    Episode_Reward/reaching_object: 1.1613
    Episode_Reward/rotating_object: 150.2678
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.89s
                      Time elapsed: 00:26:40
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 51226 steps/s (collection: 1.814s, learning 0.105s)
             Mean action noise std: 2.37
          Mean value_function loss: 39.3581
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 49.0368
                       Mean reward: 746.26
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.1370
    Episode_Reward/rotating_object: 145.4547
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.92s
                      Time elapsed: 00:26:42
                               ETA: 00:26:35

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 52563 steps/s (collection: 1.759s, learning 0.112s)
             Mean action noise std: 2.37
          Mean value_function loss: 33.0868
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 49.0499
                       Mean reward: 741.62
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.1702
    Episode_Reward/rotating_object: 149.3072
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.87s
                      Time elapsed: 00:26:43
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 52671 steps/s (collection: 1.758s, learning 0.109s)
             Mean action noise std: 2.37
          Mean value_function loss: 33.9929
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.0643
                       Mean reward: 772.83
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.1430
    Episode_Reward/rotating_object: 148.6789
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.87s
                      Time elapsed: 00:26:45
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 53291 steps/s (collection: 1.739s, learning 0.105s)
             Mean action noise std: 2.37
          Mean value_function loss: 32.5361
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.0812
                       Mean reward: 773.96
               Mean episode length: 248.59
    Episode_Reward/reaching_object: 1.1537
    Episode_Reward/rotating_object: 149.8203
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.84s
                      Time elapsed: 00:26:47
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 53226 steps/s (collection: 1.737s, learning 0.110s)
             Mean action noise std: 2.37
          Mean value_function loss: 38.0342
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.0971
                       Mean reward: 710.80
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.1561
    Episode_Reward/rotating_object: 149.3260
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.85s
                      Time elapsed: 00:26:49
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 53265 steps/s (collection: 1.736s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 36.3824
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.1103
                       Mean reward: 776.82
               Mean episode length: 247.19
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 150.9609
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.85s
                      Time elapsed: 00:26:51
                               ETA: 00:26:23

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 53518 steps/s (collection: 1.730s, learning 0.107s)
             Mean action noise std: 2.38
          Mean value_function loss: 37.9194
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.1285
                       Mean reward: 749.70
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.1638
    Episode_Reward/rotating_object: 151.3193
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.84s
                      Time elapsed: 00:26:53
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 52337 steps/s (collection: 1.769s, learning 0.110s)
             Mean action noise std: 2.38
          Mean value_function loss: 42.3384
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.1501
                       Mean reward: 754.16
               Mean episode length: 242.24
    Episode_Reward/reaching_object: 1.1602
    Episode_Reward/rotating_object: 150.6337
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.88s
                      Time elapsed: 00:26:55
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 53436 steps/s (collection: 1.748s, learning 0.092s)
             Mean action noise std: 2.39
          Mean value_function loss: 39.2459
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.1834
                       Mean reward: 729.98
               Mean episode length: 234.91
    Episode_Reward/reaching_object: 1.1336
    Episode_Reward/rotating_object: 148.1583
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.84s
                      Time elapsed: 00:26:56
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 53737 steps/s (collection: 1.727s, learning 0.102s)
             Mean action noise std: 2.39
          Mean value_function loss: 39.7732
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.2116
                       Mean reward: 738.71
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 1.1299
    Episode_Reward/rotating_object: 145.9774
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.83s
                      Time elapsed: 00:26:58
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 53877 steps/s (collection: 1.712s, learning 0.113s)
             Mean action noise std: 2.39
          Mean value_function loss: 37.0776
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.2383
                       Mean reward: 752.89
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 1.1515
    Episode_Reward/rotating_object: 149.3444
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.82s
                      Time elapsed: 00:27:00
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 53190 steps/s (collection: 1.739s, learning 0.110s)
             Mean action noise std: 2.39
          Mean value_function loss: 40.6378
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 49.2614
                       Mean reward: 713.88
               Mean episode length: 234.34
    Episode_Reward/reaching_object: 1.1368
    Episode_Reward/rotating_object: 147.9158
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.85s
                      Time elapsed: 00:27:02
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 53293 steps/s (collection: 1.741s, learning 0.103s)
             Mean action noise std: 2.39
          Mean value_function loss: 38.5292
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.2746
                       Mean reward: 734.55
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.1644
    Episode_Reward/rotating_object: 151.1158
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.84s
                      Time elapsed: 00:27:04
                               ETA: 00:26:06

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 53667 steps/s (collection: 1.743s, learning 0.089s)
             Mean action noise std: 2.40
          Mean value_function loss: 38.7726
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 49.2890
                       Mean reward: 720.27
               Mean episode length: 233.77
    Episode_Reward/reaching_object: 1.1395
    Episode_Reward/rotating_object: 148.1496
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.83s
                      Time elapsed: 00:27:06
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 52759 steps/s (collection: 1.747s, learning 0.116s)
             Mean action noise std: 2.40
          Mean value_function loss: 40.0769
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.3127
                       Mean reward: 734.25
               Mean episode length: 236.69
    Episode_Reward/reaching_object: 1.1464
    Episode_Reward/rotating_object: 147.8321
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.86s
                      Time elapsed: 00:27:07
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 52568 steps/s (collection: 1.754s, learning 0.116s)
             Mean action noise std: 2.40
          Mean value_function loss: 29.5062
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 49.3329
                       Mean reward: 788.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1671
    Episode_Reward/rotating_object: 151.7039
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.87s
                      Time elapsed: 00:27:09
                               ETA: 00:25:59

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 52546 steps/s (collection: 1.751s, learning 0.120s)
             Mean action noise std: 2.41
          Mean value_function loss: 43.9601
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.3517
                       Mean reward: 759.80
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.1642
    Episode_Reward/rotating_object: 151.0507
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.87s
                      Time elapsed: 00:27:11
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 53347 steps/s (collection: 1.737s, learning 0.106s)
             Mean action noise std: 2.41
          Mean value_function loss: 41.9817
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 49.3797
                       Mean reward: 750.36
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.1631
    Episode_Reward/rotating_object: 149.0094
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.84s
                      Time elapsed: 00:27:13
                               ETA: 00:25:54

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 53333 steps/s (collection: 1.735s, learning 0.109s)
             Mean action noise std: 2.41
          Mean value_function loss: 40.2324
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 49.3964
                       Mean reward: 780.41
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 149.6999
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.84s
                      Time elapsed: 00:27:15
                               ETA: 00:25:52

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 51655 steps/s (collection: 1.782s, learning 0.121s)
             Mean action noise std: 2.41
          Mean value_function loss: 37.0632
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.4069
                       Mean reward: 744.12
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.1714
    Episode_Reward/rotating_object: 149.3337
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.90s
                      Time elapsed: 00:27:17
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 52955 steps/s (collection: 1.747s, learning 0.109s)
             Mean action noise std: 2.41
          Mean value_function loss: 39.5959
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 49.4219
                       Mean reward: 728.43
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.1770
    Episode_Reward/rotating_object: 151.1410
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.86s
                      Time elapsed: 00:27:19
                               ETA: 00:25:47

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 52863 steps/s (collection: 1.752s, learning 0.107s)
             Mean action noise std: 2.42
          Mean value_function loss: 39.2745
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.4401
                       Mean reward: 738.12
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 1.1701
    Episode_Reward/rotating_object: 148.3386
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.86s
                      Time elapsed: 00:27:21
                               ETA: 00:25:45

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 52347 steps/s (collection: 1.757s, learning 0.121s)
             Mean action noise std: 2.42
          Mean value_function loss: 35.6205
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.4528
                       Mean reward: 780.34
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 151.1800
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.88s
                      Time elapsed: 00:27:22
                               ETA: 00:25:43

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 52899 steps/s (collection: 1.744s, learning 0.115s)
             Mean action noise std: 2.42
          Mean value_function loss: 29.9722
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.4676
                       Mean reward: 763.57
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.1734
    Episode_Reward/rotating_object: 150.7784
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.86s
                      Time elapsed: 00:27:24
                               ETA: 00:25:40

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 52682 steps/s (collection: 1.771s, learning 0.095s)
             Mean action noise std: 2.42
          Mean value_function loss: 36.8644
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.4926
                       Mean reward: 791.63
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.1860
    Episode_Reward/rotating_object: 151.3892
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.87s
                      Time elapsed: 00:27:26
                               ETA: 00:25:38

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 51769 steps/s (collection: 1.783s, learning 0.116s)
             Mean action noise std: 2.43
          Mean value_function loss: 39.3551
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.5166
                       Mean reward: 743.07
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.1761
    Episode_Reward/rotating_object: 151.0959
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.90s
                      Time elapsed: 00:27:28
                               ETA: 00:25:36

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 51905 steps/s (collection: 1.787s, learning 0.106s)
             Mean action noise std: 2.43
          Mean value_function loss: 44.4949
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 49.5326
                       Mean reward: 746.92
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.1765
    Episode_Reward/rotating_object: 150.8374
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.89s
                      Time elapsed: 00:27:30
                               ETA: 00:25:33

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 52477 steps/s (collection: 1.761s, learning 0.113s)
             Mean action noise std: 2.43
          Mean value_function loss: 44.1923
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 49.5483
                       Mean reward: 756.52
               Mean episode length: 238.55
    Episode_Reward/reaching_object: 1.1586
    Episode_Reward/rotating_object: 149.2827
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.87s
                      Time elapsed: 00:27:32
                               ETA: 00:25:31

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 47197 steps/s (collection: 1.963s, learning 0.120s)
             Mean action noise std: 2.43
          Mean value_function loss: 36.8891
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.5623
                       Mean reward: 765.56
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 1.1731
    Episode_Reward/rotating_object: 151.6637
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.08s
                      Time elapsed: 00:27:34
                               ETA: 00:25:29

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 46640 steps/s (collection: 1.992s, learning 0.116s)
             Mean action noise std: 2.44
          Mean value_function loss: 33.8846
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.5825
                       Mean reward: 749.22
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 1.1650
    Episode_Reward/rotating_object: 150.0712
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.11s
                      Time elapsed: 00:27:36
                               ETA: 00:25:27

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 48128 steps/s (collection: 1.920s, learning 0.122s)
             Mean action noise std: 2.44
          Mean value_function loss: 28.5707
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.6004
                       Mean reward: 763.61
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 1.1677
    Episode_Reward/rotating_object: 150.7383
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.04s
                      Time elapsed: 00:27:38
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 46500 steps/s (collection: 1.984s, learning 0.130s)
             Mean action noise std: 2.44
          Mean value_function loss: 33.1194
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 49.6183
                       Mean reward: 761.53
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 152.4886
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.11s
                      Time elapsed: 00:27:40
                               ETA: 00:25:22

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 48446 steps/s (collection: 1.939s, learning 0.090s)
             Mean action noise std: 2.44
          Mean value_function loss: 30.4678
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.6295
                       Mean reward: 777.21
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 152.4389
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.03s
                      Time elapsed: 00:27:42
                               ETA: 00:25:20

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 43069 steps/s (collection: 2.063s, learning 0.219s)
             Mean action noise std: 2.44
          Mean value_function loss: 40.7421
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.6415
                       Mean reward: 773.36
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 1.1709
    Episode_Reward/rotating_object: 151.4329
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.28s
                      Time elapsed: 00:27:44
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 44382 steps/s (collection: 2.022s, learning 0.192s)
             Mean action noise std: 2.45
          Mean value_function loss: 44.1818
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 49.6623
                       Mean reward: 782.34
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 152.9059
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.21s
                      Time elapsed: 00:27:47
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 42387 steps/s (collection: 2.221s, learning 0.099s)
             Mean action noise std: 2.45
          Mean value_function loss: 39.8829
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.6860
                       Mean reward: 776.84
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.1673
    Episode_Reward/rotating_object: 151.4110
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.32s
                      Time elapsed: 00:27:49
                               ETA: 00:25:14

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 45880 steps/s (collection: 2.034s, learning 0.109s)
             Mean action noise std: 2.45
          Mean value_function loss: 46.7508
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.7018
                       Mean reward: 695.35
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.1630
    Episode_Reward/rotating_object: 147.3391
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.14s
                      Time elapsed: 00:27:51
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 46928 steps/s (collection: 1.913s, learning 0.182s)
             Mean action noise std: 2.45
          Mean value_function loss: 44.7657
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.7264
                       Mean reward: 770.35
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 152.3858
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.09s
                      Time elapsed: 00:27:53
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 44615 steps/s (collection: 2.084s, learning 0.120s)
             Mean action noise std: 2.46
          Mean value_function loss: 40.0068
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.7437
                       Mean reward: 768.61
               Mean episode length: 240.47
    Episode_Reward/reaching_object: 1.1829
    Episode_Reward/rotating_object: 150.3131
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.20s
                      Time elapsed: 00:27:55
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 47670 steps/s (collection: 1.921s, learning 0.142s)
             Mean action noise std: 2.46
          Mean value_function loss: 48.4842
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.7607
                       Mean reward: 745.22
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.1737
    Episode_Reward/rotating_object: 149.5115
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.06s
                      Time elapsed: 00:27:58
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 48548 steps/s (collection: 1.906s, learning 0.119s)
             Mean action noise std: 2.46
          Mean value_function loss: 43.8896
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.7806
                       Mean reward: 760.65
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 1.1853
    Episode_Reward/rotating_object: 149.9694
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.02s
                      Time elapsed: 00:28:00
                               ETA: 00:25:03

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 51674 steps/s (collection: 1.782s, learning 0.120s)
             Mean action noise std: 2.46
          Mean value_function loss: 40.8405
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.7946
                       Mean reward: 746.83
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 1.1794
    Episode_Reward/rotating_object: 150.5138
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.90s
                      Time elapsed: 00:28:01
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 52253 steps/s (collection: 1.761s, learning 0.120s)
             Mean action noise std: 2.47
          Mean value_function loss: 40.1994
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 49.8060
                       Mean reward: 770.56
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.1605
    Episode_Reward/rotating_object: 147.8500
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.88s
                      Time elapsed: 00:28:03
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 52203 steps/s (collection: 1.770s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 48.6799
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.8255
                       Mean reward: 767.18
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 1.1621
    Episode_Reward/rotating_object: 146.7464
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.88s
                      Time elapsed: 00:28:05
                               ETA: 00:24:56

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 52481 steps/s (collection: 1.760s, learning 0.114s)
             Mean action noise std: 2.47
          Mean value_function loss: 38.7643
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 49.8501
                       Mean reward: 768.75
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 1.1920
    Episode_Reward/rotating_object: 153.9094
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.87s
                      Time elapsed: 00:28:07
                               ETA: 00:24:54

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 52844 steps/s (collection: 1.747s, learning 0.114s)
             Mean action noise std: 2.47
          Mean value_function loss: 47.2411
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.8732
                       Mean reward: 738.29
               Mean episode length: 234.77
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 151.4107
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.86s
                      Time elapsed: 00:28:09
                               ETA: 00:24:52

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 51708 steps/s (collection: 1.792s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 37.9315
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 49.8987
                       Mean reward: 765.20
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 149.8057
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.90s
                      Time elapsed: 00:28:11
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 50954 steps/s (collection: 1.813s, learning 0.116s)
             Mean action noise std: 2.48
          Mean value_function loss: 36.8956
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 49.9176
                       Mean reward: 765.19
               Mean episode length: 242.17
    Episode_Reward/reaching_object: 1.1906
    Episode_Reward/rotating_object: 151.0315
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.93s
                      Time elapsed: 00:28:13
                               ETA: 00:24:47

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 52409 steps/s (collection: 1.745s, learning 0.131s)
             Mean action noise std: 2.48
          Mean value_function loss: 36.2513
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.9275
                       Mean reward: 754.63
               Mean episode length: 240.83
    Episode_Reward/reaching_object: 1.1892
    Episode_Reward/rotating_object: 150.3880
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.88s
                      Time elapsed: 00:28:15
                               ETA: 00:24:45

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 52732 steps/s (collection: 1.753s, learning 0.112s)
             Mean action noise std: 2.48
          Mean value_function loss: 45.5294
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 49.9429
                       Mean reward: 755.89
               Mean episode length: 239.33
    Episode_Reward/reaching_object: 1.1837
    Episode_Reward/rotating_object: 151.1854
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0160
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.86s
                      Time elapsed: 00:28:17
                               ETA: 00:24:43

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 51711 steps/s (collection: 1.792s, learning 0.109s)
             Mean action noise std: 2.49
          Mean value_function loss: 44.3367
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 49.9663
                       Mean reward: 768.87
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.1942
    Episode_Reward/rotating_object: 149.9235
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.90s
                      Time elapsed: 00:28:18
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 52004 steps/s (collection: 1.772s, learning 0.119s)
             Mean action noise std: 2.49
          Mean value_function loss: 38.8667
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.9911
                       Mean reward: 759.29
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.1879
    Episode_Reward/rotating_object: 152.6534
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.89s
                      Time elapsed: 00:28:20
                               ETA: 00:24:38

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 52335 steps/s (collection: 1.768s, learning 0.110s)
             Mean action noise std: 2.49
          Mean value_function loss: 41.4972
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.0135
                       Mean reward: 777.57
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.1920
    Episode_Reward/rotating_object: 152.2370
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.88s
                      Time elapsed: 00:28:22
                               ETA: 00:24:36

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 51757 steps/s (collection: 1.782s, learning 0.118s)
             Mean action noise std: 2.50
          Mean value_function loss: 34.1190
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.0351
                       Mean reward: 752.20
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.1715
    Episode_Reward/rotating_object: 148.9597
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.90s
                      Time elapsed: 00:28:24
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 52169 steps/s (collection: 1.776s, learning 0.109s)
             Mean action noise std: 2.50
          Mean value_function loss: 40.3151
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.0533
                       Mean reward: 740.59
               Mean episode length: 238.47
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 152.1145
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.88s
                      Time elapsed: 00:28:26
                               ETA: 00:24:31

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 51889 steps/s (collection: 1.778s, learning 0.116s)
             Mean action noise std: 2.50
          Mean value_function loss: 35.1678
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 50.0657
                       Mean reward: 788.50
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 1.1898
    Episode_Reward/rotating_object: 150.9573
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.89s
                      Time elapsed: 00:28:28
                               ETA: 00:24:29

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 50849 steps/s (collection: 1.816s, learning 0.118s)
             Mean action noise std: 2.50
          Mean value_function loss: 34.2248
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.0788
                       Mean reward: 791.39
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 152.1109
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.93s
                      Time elapsed: 00:28:30
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 51120 steps/s (collection: 1.812s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 38.7495
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 50.0907
                       Mean reward: 787.54
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 1.1974
    Episode_Reward/rotating_object: 153.6395
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.92s
                      Time elapsed: 00:28:32
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 51396 steps/s (collection: 1.799s, learning 0.114s)
             Mean action noise std: 2.50
          Mean value_function loss: 44.0329
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.0961
                       Mean reward: 758.12
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.1771
    Episode_Reward/rotating_object: 149.2119
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.91s
                      Time elapsed: 00:28:34
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 52312 steps/s (collection: 1.772s, learning 0.108s)
             Mean action noise std: 2.51
          Mean value_function loss: 39.4717
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.1149
                       Mean reward: 765.85
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.1851
    Episode_Reward/rotating_object: 153.0474
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.88s
                      Time elapsed: 00:28:35
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 51848 steps/s (collection: 1.786s, learning 0.110s)
             Mean action noise std: 2.51
          Mean value_function loss: 46.7525
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.1287
                       Mean reward: 732.46
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.1681
    Episode_Reward/rotating_object: 151.7809
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.90s
                      Time elapsed: 00:28:37
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 50916 steps/s (collection: 1.816s, learning 0.115s)
             Mean action noise std: 2.51
          Mean value_function loss: 44.4607
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 50.1462
                       Mean reward: 702.46
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 148.0230
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.93s
                      Time elapsed: 00:28:39
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 52205 steps/s (collection: 1.772s, learning 0.111s)
             Mean action noise std: 2.51
          Mean value_function loss: 50.7259
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.1701
                       Mean reward: 749.69
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 1.1496
    Episode_Reward/rotating_object: 148.4225
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.88s
                      Time elapsed: 00:28:41
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 52986 steps/s (collection: 1.749s, learning 0.106s)
             Mean action noise std: 2.52
          Mean value_function loss: 32.0110
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.1952
                       Mean reward: 767.17
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 153.1497
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.86s
                      Time elapsed: 00:28:43
                               ETA: 00:24:10

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 51621 steps/s (collection: 1.797s, learning 0.107s)
             Mean action noise std: 2.52
          Mean value_function loss: 37.2025
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.2121
                       Mean reward: 782.98
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 1.1873
    Episode_Reward/rotating_object: 152.7608
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.90s
                      Time elapsed: 00:28:45
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 52309 steps/s (collection: 1.756s, learning 0.124s)
             Mean action noise std: 2.52
          Mean value_function loss: 40.2598
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.2319
                       Mean reward: 753.38
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.1830
    Episode_Reward/rotating_object: 151.1690
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.88s
                      Time elapsed: 00:28:47
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 52844 steps/s (collection: 1.739s, learning 0.122s)
             Mean action noise std: 2.52
          Mean value_function loss: 43.3987
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 50.2547
                       Mean reward: 755.03
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.1751
    Episode_Reward/rotating_object: 152.6310
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.86s
                      Time elapsed: 00:28:49
                               ETA: 00:24:03

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 52192 steps/s (collection: 1.764s, learning 0.120s)
             Mean action noise std: 2.53
          Mean value_function loss: 43.7265
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.2896
                       Mean reward: 751.64
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.1874
    Episode_Reward/rotating_object: 152.8672
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.88s
                      Time elapsed: 00:28:51
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 50816 steps/s (collection: 1.810s, learning 0.124s)
             Mean action noise std: 2.53
          Mean value_function loss: 40.1412
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 50.3136
                       Mean reward: 767.93
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.1901
    Episode_Reward/rotating_object: 152.7784
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.93s
                      Time elapsed: 00:28:53
                               ETA: 00:23:59

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 51130 steps/s (collection: 1.808s, learning 0.115s)
             Mean action noise std: 2.53
          Mean value_function loss: 42.6769
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.3236
                       Mean reward: 786.17
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.1810
    Episode_Reward/rotating_object: 151.3692
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.92s
                      Time elapsed: 00:28:54
                               ETA: 00:23:56

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 51692 steps/s (collection: 1.791s, learning 0.111s)
             Mean action noise std: 2.53
          Mean value_function loss: 43.0968
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.3382
                       Mean reward: 747.32
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 1.1719
    Episode_Reward/rotating_object: 151.7777
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.90s
                      Time elapsed: 00:28:56
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 50008 steps/s (collection: 1.869s, learning 0.097s)
             Mean action noise std: 2.54
          Mean value_function loss: 42.7308
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.3681
                       Mean reward: 795.62
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 1.1717
    Episode_Reward/rotating_object: 152.3207
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.97s
                      Time elapsed: 00:28:58
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 50324 steps/s (collection: 1.829s, learning 0.124s)
             Mean action noise std: 2.54
          Mean value_function loss: 38.5642
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.3863
                       Mean reward: 775.63
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 1.1766
    Episode_Reward/rotating_object: 151.9735
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.95s
                      Time elapsed: 00:29:00
                               ETA: 00:23:50

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 50037 steps/s (collection: 1.846s, learning 0.119s)
             Mean action noise std: 2.54
          Mean value_function loss: 33.1993
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.4062
                       Mean reward: 789.88
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.1805
    Episode_Reward/rotating_object: 153.9289
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.96s
                      Time elapsed: 00:29:02
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 50952 steps/s (collection: 1.816s, learning 0.113s)
             Mean action noise std: 2.54
          Mean value_function loss: 32.5333
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.4237
                       Mean reward: 783.65
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 1.1809
    Episode_Reward/rotating_object: 153.3407
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.93s
                      Time elapsed: 00:29:04
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 53587 steps/s (collection: 1.722s, learning 0.113s)
             Mean action noise std: 2.55
          Mean value_function loss: 30.2650
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.4326
                       Mean reward: 794.21
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 1.1905
    Episode_Reward/rotating_object: 154.6095
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.83s
                      Time elapsed: 00:29:06
                               ETA: 00:23:43

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 51620 steps/s (collection: 1.786s, learning 0.118s)
             Mean action noise std: 2.55
          Mean value_function loss: 34.0866
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.4424
                       Mean reward: 780.72
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 1.1824
    Episode_Reward/rotating_object: 151.2207
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.90s
                      Time elapsed: 00:29:08
                               ETA: 00:23:41

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 52225 steps/s (collection: 1.764s, learning 0.119s)
             Mean action noise std: 2.55
          Mean value_function loss: 28.2606
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.4570
                       Mean reward: 781.05
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 1.1768
    Episode_Reward/rotating_object: 152.6699
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.88s
                      Time elapsed: 00:29:10
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 53643 steps/s (collection: 1.734s, learning 0.099s)
             Mean action noise std: 2.55
          Mean value_function loss: 34.7908
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 50.4725
                       Mean reward: 758.69
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 1.1785
    Episode_Reward/rotating_object: 151.8127
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.83s
                      Time elapsed: 00:29:12
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 52527 steps/s (collection: 1.761s, learning 0.110s)
             Mean action noise std: 2.56
          Mean value_function loss: 30.6763
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 50.4890
                       Mean reward: 784.28
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 1.1828
    Episode_Reward/rotating_object: 153.9164
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0162
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.87s
                      Time elapsed: 00:29:13
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 51754 steps/s (collection: 1.782s, learning 0.118s)
             Mean action noise std: 2.56
          Mean value_function loss: 35.3415
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 50.5027
                       Mean reward: 778.15
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 1.1741
    Episode_Reward/rotating_object: 153.3929
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.90s
                      Time elapsed: 00:29:15
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 53082 steps/s (collection: 1.735s, learning 0.117s)
             Mean action noise std: 2.56
          Mean value_function loss: 29.0732
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.5214
                       Mean reward: 764.35
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 153.1509
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.85s
                      Time elapsed: 00:29:17
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 49601 steps/s (collection: 1.870s, learning 0.112s)
             Mean action noise std: 2.56
          Mean value_function loss: 45.3409
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.5501
                       Mean reward: 727.20
               Mean episode length: 234.37
    Episode_Reward/reaching_object: 1.1552
    Episode_Reward/rotating_object: 149.4289
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.98s
                      Time elapsed: 00:29:19
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 52523 steps/s (collection: 1.757s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 30.3925
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.5796
                       Mean reward: 748.98
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 1.1527
    Episode_Reward/rotating_object: 151.9341
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.87s
                      Time elapsed: 00:29:21
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 52833 steps/s (collection: 1.743s, learning 0.118s)
             Mean action noise std: 2.57
          Mean value_function loss: 27.7789
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.5920
                       Mean reward: 794.78
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 1.1735
    Episode_Reward/rotating_object: 155.8956
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.86s
                      Time elapsed: 00:29:23
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 52577 steps/s (collection: 1.753s, learning 0.117s)
             Mean action noise std: 2.57
          Mean value_function loss: 39.7583
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.6107
                       Mean reward: 768.50
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.1654
    Episode_Reward/rotating_object: 153.8187
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.87s
                      Time elapsed: 00:29:25
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 52733 steps/s (collection: 1.748s, learning 0.116s)
             Mean action noise std: 2.58
          Mean value_function loss: 37.4976
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 50.6402
                       Mean reward: 769.02
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.1707
    Episode_Reward/rotating_object: 153.3025
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.86s
                      Time elapsed: 00:29:27
                               ETA: 00:23:18

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 52080 steps/s (collection: 1.773s, learning 0.114s)
             Mean action noise std: 2.58
          Mean value_function loss: 32.5169
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.6568
                       Mean reward: 758.48
               Mean episode length: 245.99
    Episode_Reward/reaching_object: 1.1694
    Episode_Reward/rotating_object: 153.7293
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.89s
                      Time elapsed: 00:29:29
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 52714 steps/s (collection: 1.753s, learning 0.112s)
             Mean action noise std: 2.58
          Mean value_function loss: 29.9561
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.6750
                       Mean reward: 774.50
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 1.1807
    Episode_Reward/rotating_object: 156.6738
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.86s
                      Time elapsed: 00:29:30
                               ETA: 00:23:13

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 53049 steps/s (collection: 1.753s, learning 0.101s)
             Mean action noise std: 2.58
          Mean value_function loss: 30.1087
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.6845
                       Mean reward: 777.68
               Mean episode length: 247.32
    Episode_Reward/reaching_object: 1.1817
    Episode_Reward/rotating_object: 155.8090
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.85s
                      Time elapsed: 00:29:32
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 53395 steps/s (collection: 1.745s, learning 0.096s)
             Mean action noise std: 2.58
          Mean value_function loss: 32.5457
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 50.6966
                       Mean reward: 778.14
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.1639
    Episode_Reward/rotating_object: 153.4526
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.84s
                      Time elapsed: 00:29:34
                               ETA: 00:23:08

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 52874 steps/s (collection: 1.743s, learning 0.116s)
             Mean action noise std: 2.59
          Mean value_function loss: 44.1334
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 50.7288
                       Mean reward: 768.22
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 1.1442
    Episode_Reward/rotating_object: 150.7646
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.86s
                      Time elapsed: 00:29:36
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 53089 steps/s (collection: 1.738s, learning 0.114s)
             Mean action noise std: 2.59
          Mean value_function loss: 32.3093
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.7618
                       Mean reward: 775.22
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.1702
    Episode_Reward/rotating_object: 154.7744
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.85s
                      Time elapsed: 00:29:38
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 53414 steps/s (collection: 1.728s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 36.9133
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.7963
                       Mean reward: 788.39
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 1.1685
    Episode_Reward/rotating_object: 154.9519
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.84s
                      Time elapsed: 00:29:40
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 52533 steps/s (collection: 1.758s, learning 0.113s)
             Mean action noise std: 2.60
          Mean value_function loss: 36.0413
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 50.8040
                       Mean reward: 795.36
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.1631
    Episode_Reward/rotating_object: 154.3982
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.87s
                      Time elapsed: 00:29:42
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 53299 steps/s (collection: 1.736s, learning 0.109s)
             Mean action noise std: 2.60
          Mean value_function loss: 31.1928
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.8100
                       Mean reward: 787.26
               Mean episode length: 246.75
    Episode_Reward/reaching_object: 1.1498
    Episode_Reward/rotating_object: 153.0535
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.84s
                      Time elapsed: 00:29:43
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 53353 steps/s (collection: 1.732s, learning 0.110s)
             Mean action noise std: 2.60
          Mean value_function loss: 33.5562
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.8177
                       Mean reward: 801.80
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 1.1444
    Episode_Reward/rotating_object: 152.4180
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.84s
                      Time elapsed: 00:29:45
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 53151 steps/s (collection: 1.754s, learning 0.095s)
             Mean action noise std: 2.60
          Mean value_function loss: 36.9432
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.8324
                       Mean reward: 772.24
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 154.0745
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.85s
                      Time elapsed: 00:29:47
                               ETA: 00:22:52

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 52366 steps/s (collection: 1.753s, learning 0.125s)
             Mean action noise std: 2.61
          Mean value_function loss: 30.9066
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.8646
                       Mean reward: 782.61
               Mean episode length: 246.63
    Episode_Reward/reaching_object: 1.1675
    Episode_Reward/rotating_object: 155.5566
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.88s
                      Time elapsed: 00:29:49
                               ETA: 00:22:50

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 48198 steps/s (collection: 1.900s, learning 0.140s)
             Mean action noise std: 2.61
          Mean value_function loss: 39.4976
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.8933
                       Mean reward: 766.96
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.1452
    Episode_Reward/rotating_object: 153.5414
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.04s
                      Time elapsed: 00:29:51
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 49165 steps/s (collection: 1.878s, learning 0.121s)
             Mean action noise std: 2.61
          Mean value_function loss: 36.1719
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 50.9146
                       Mean reward: 768.51
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.1394
    Episode_Reward/rotating_object: 153.8144
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.00s
                      Time elapsed: 00:29:53
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 43477 steps/s (collection: 1.933s, learning 0.328s)
             Mean action noise std: 2.62
          Mean value_function loss: 33.2821
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.9399
                       Mean reward: 766.54
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.1435
    Episode_Reward/rotating_object: 152.7702
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.26s
                      Time elapsed: 00:29:55
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 41806 steps/s (collection: 2.198s, learning 0.154s)
             Mean action noise std: 2.62
          Mean value_function loss: 38.9878
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.9567
                       Mean reward: 755.77
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 1.1490
    Episode_Reward/rotating_object: 154.3791
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.35s
                      Time elapsed: 00:29:58
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 42579 steps/s (collection: 2.175s, learning 0.134s)
             Mean action noise std: 2.62
          Mean value_function loss: 32.8671
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 50.9705
                       Mean reward: 782.44
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.1516
    Episode_Reward/rotating_object: 153.9927
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.31s
                      Time elapsed: 00:30:00
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 47800 steps/s (collection: 1.892s, learning 0.164s)
             Mean action noise std: 2.62
          Mean value_function loss: 32.7064
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 50.9828
                       Mean reward: 776.85
               Mean episode length: 244.01
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 154.2746
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.06s
                      Time elapsed: 00:30:02
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 46393 steps/s (collection: 1.987s, learning 0.132s)
             Mean action noise std: 2.62
          Mean value_function loss: 35.6472
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.0006
                       Mean reward: 754.03
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.1533
    Episode_Reward/rotating_object: 153.4936
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.12s
                      Time elapsed: 00:30:04
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 49713 steps/s (collection: 1.866s, learning 0.112s)
             Mean action noise std: 2.63
          Mean value_function loss: 40.7599
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.0215
                       Mean reward: 776.07
               Mean episode length: 244.59
    Episode_Reward/reaching_object: 1.1538
    Episode_Reward/rotating_object: 152.7572
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.98s
                      Time elapsed: 00:30:06
                               ETA: 00:22:33

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 43633 steps/s (collection: 2.150s, learning 0.103s)
             Mean action noise std: 2.63
          Mean value_function loss: 36.4397
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.0434
                       Mean reward: 767.63
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 1.1340
    Episode_Reward/rotating_object: 150.8739
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.25s
                      Time elapsed: 00:30:08
                               ETA: 00:22:31

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 49394 steps/s (collection: 1.867s, learning 0.123s)
             Mean action noise std: 2.63
          Mean value_function loss: 31.2212
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.0720
                       Mean reward: 768.75
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 153.9308
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.99s
                      Time elapsed: 00:30:10
                               ETA: 00:22:29

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 40480 steps/s (collection: 2.249s, learning 0.179s)
             Mean action noise std: 2.64
          Mean value_function loss: 28.1157
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.0906
                       Mean reward: 771.61
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 156.3716
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.43s
                      Time elapsed: 00:30:13
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 48237 steps/s (collection: 1.927s, learning 0.111s)
             Mean action noise std: 2.64
          Mean value_function loss: 30.7424
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 51.1028
                       Mean reward: 805.13
               Mean episode length: 247.01
    Episode_Reward/reaching_object: 1.1708
    Episode_Reward/rotating_object: 157.0214
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.04s
                      Time elapsed: 00:30:15
                               ETA: 00:22:25

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 48787 steps/s (collection: 1.896s, learning 0.119s)
             Mean action noise std: 2.64
          Mean value_function loss: 35.4272
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 51.1190
                       Mean reward: 792.93
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 1.1586
    Episode_Reward/rotating_object: 154.8253
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.01s
                      Time elapsed: 00:30:17
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 51214 steps/s (collection: 1.805s, learning 0.115s)
             Mean action noise std: 2.64
          Mean value_function loss: 36.0232
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.1429
                       Mean reward: 804.92
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 1.1644
    Episode_Reward/rotating_object: 155.7411
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.92s
                      Time elapsed: 00:30:19
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 51263 steps/s (collection: 1.805s, learning 0.113s)
             Mean action noise std: 2.65
          Mean value_function loss: 28.5217
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.1636
                       Mean reward: 786.60
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 1.1582
    Episode_Reward/rotating_object: 155.2980
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.92s
                      Time elapsed: 00:30:21
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 50415 steps/s (collection: 1.831s, learning 0.119s)
             Mean action noise std: 2.65
          Mean value_function loss: 39.4811
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.1789
                       Mean reward: 794.82
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 1.1493
    Episode_Reward/rotating_object: 152.2831
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.95s
                      Time elapsed: 00:30:23
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 50689 steps/s (collection: 1.819s, learning 0.121s)
             Mean action noise std: 2.65
          Mean value_function loss: 31.5972
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.2017
                       Mean reward: 787.93
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.1616
    Episode_Reward/rotating_object: 156.4656
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.94s
                      Time elapsed: 00:30:25
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 52121 steps/s (collection: 1.772s, learning 0.114s)
             Mean action noise std: 2.65
          Mean value_function loss: 31.0090
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.2221
                       Mean reward: 756.73
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.1390
    Episode_Reward/rotating_object: 152.0517
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.89s
                      Time elapsed: 00:30:26
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 52226 steps/s (collection: 1.760s, learning 0.122s)
             Mean action noise std: 2.66
          Mean value_function loss: 31.1771
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.2392
                       Mean reward: 778.58
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 1.1634
    Episode_Reward/rotating_object: 155.8158
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.88s
                      Time elapsed: 00:30:28
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 52994 steps/s (collection: 1.738s, learning 0.117s)
             Mean action noise std: 2.66
          Mean value_function loss: 34.1964
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.2581
                       Mean reward: 810.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1652
    Episode_Reward/rotating_object: 156.2282
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.85s
                      Time elapsed: 00:30:30
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 53632 steps/s (collection: 1.718s, learning 0.115s)
             Mean action noise std: 2.66
          Mean value_function loss: 31.2410
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 51.2711
                       Mean reward: 804.63
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 1.1505
    Episode_Reward/rotating_object: 154.9059
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.83s
                      Time elapsed: 00:30:32
                               ETA: 00:22:05

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 53230 steps/s (collection: 1.734s, learning 0.113s)
             Mean action noise std: 2.66
          Mean value_function loss: 37.9342
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.2772
                       Mean reward: 748.56
               Mean episode length: 238.62
    Episode_Reward/reaching_object: 1.1441
    Episode_Reward/rotating_object: 154.0478
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.85s
                      Time elapsed: 00:30:34
                               ETA: 00:22:03

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 53665 steps/s (collection: 1.740s, learning 0.092s)
             Mean action noise std: 2.67
          Mean value_function loss: 31.6956
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.2897
                       Mean reward: 810.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1689
    Episode_Reward/rotating_object: 157.5290
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.83s
                      Time elapsed: 00:30:36
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 53098 steps/s (collection: 1.725s, learning 0.126s)
             Mean action noise std: 2.67
          Mean value_function loss: 39.5203
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 51.3054
                       Mean reward: 790.99
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.1532
    Episode_Reward/rotating_object: 156.5734
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.85s
                      Time elapsed: 00:30:38
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 52969 steps/s (collection: 1.767s, learning 0.089s)
             Mean action noise std: 2.67
          Mean value_function loss: 38.3588
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 51.3170
                       Mean reward: 774.56
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 1.1482
    Episode_Reward/rotating_object: 154.8854
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.86s
                      Time elapsed: 00:30:39
                               ETA: 00:21:56

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 52592 steps/s (collection: 1.753s, learning 0.116s)
             Mean action noise std: 2.67
          Mean value_function loss: 42.5904
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.3384
                       Mean reward: 761.94
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 1.1436
    Episode_Reward/rotating_object: 153.5404
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.87s
                      Time elapsed: 00:30:41
                               ETA: 00:21:54

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 51819 steps/s (collection: 1.773s, learning 0.124s)
             Mean action noise std: 2.67
          Mean value_function loss: 41.4830
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.3549
                       Mean reward: 766.42
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.1349
    Episode_Reward/rotating_object: 152.1570
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.90s
                      Time elapsed: 00:30:43
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 54346 steps/s (collection: 1.717s, learning 0.092s)
             Mean action noise std: 2.68
          Mean value_function loss: 35.0505
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.3731
                       Mean reward: 799.73
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.1529
    Episode_Reward/rotating_object: 155.2202
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.81s
                      Time elapsed: 00:30:45
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 53497 steps/s (collection: 1.737s, learning 0.101s)
             Mean action noise std: 2.68
          Mean value_function loss: 29.1946
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.3941
                       Mean reward: 775.76
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 156.2762
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.84s
                      Time elapsed: 00:30:47
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 52554 steps/s (collection: 1.754s, learning 0.117s)
             Mean action noise std: 2.68
          Mean value_function loss: 43.8258
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.4068
                       Mean reward: 772.51
               Mean episode length: 240.57
    Episode_Reward/reaching_object: 1.1521
    Episode_Reward/rotating_object: 155.2413
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.87s
                      Time elapsed: 00:30:49
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 52002 steps/s (collection: 1.771s, learning 0.119s)
             Mean action noise std: 2.68
          Mean value_function loss: 39.7997
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.4193
                       Mean reward: 775.82
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 1.1405
    Episode_Reward/rotating_object: 155.6693
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.89s
                      Time elapsed: 00:30:51
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 51863 steps/s (collection: 1.772s, learning 0.123s)
             Mean action noise std: 2.69
          Mean value_function loss: 37.9405
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.4375
                       Mean reward: 788.43
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.1273
    Episode_Reward/rotating_object: 153.3875
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.90s
                      Time elapsed: 00:30:52
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 51402 steps/s (collection: 1.790s, learning 0.122s)
             Mean action noise std: 2.69
          Mean value_function loss: 52.6893
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.4584
                       Mean reward: 782.88
               Mean episode length: 242.50
    Episode_Reward/reaching_object: 1.1313
    Episode_Reward/rotating_object: 153.7013
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.91s
                      Time elapsed: 00:30:54
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 51711 steps/s (collection: 1.777s, learning 0.124s)
             Mean action noise std: 2.69
          Mean value_function loss: 33.1797
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.4887
                       Mean reward: 769.98
               Mean episode length: 243.01
    Episode_Reward/reaching_object: 1.1534
    Episode_Reward/rotating_object: 154.3139
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.90s
                      Time elapsed: 00:30:56
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 51969 steps/s (collection: 1.771s, learning 0.120s)
             Mean action noise std: 2.70
          Mean value_function loss: 35.4749
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.5099
                       Mean reward: 764.19
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.1424
    Episode_Reward/rotating_object: 153.2879
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.89s
                      Time elapsed: 00:30:58
                               ETA: 00:21:33

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 52155 steps/s (collection: 1.757s, learning 0.128s)
             Mean action noise std: 2.70
          Mean value_function loss: 30.5064
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.5411
                       Mean reward: 767.10
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.1507
    Episode_Reward/rotating_object: 154.7672
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.88s
                      Time elapsed: 00:31:00
                               ETA: 00:21:31

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 51931 steps/s (collection: 1.780s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 39.1902
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 51.5580
                       Mean reward: 755.34
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.1487
    Episode_Reward/rotating_object: 153.7793
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.89s
                      Time elapsed: 00:31:02
                               ETA: 00:21:29

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 51666 steps/s (collection: 1.782s, learning 0.121s)
             Mean action noise std: 2.71
          Mean value_function loss: 43.0166
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 51.5856
                       Mean reward: 789.03
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.1401
    Episode_Reward/rotating_object: 153.5871
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.90s
                      Time elapsed: 00:31:04
                               ETA: 00:21:26

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 52616 steps/s (collection: 1.756s, learning 0.113s)
             Mean action noise std: 2.71
          Mean value_function loss: 38.7434
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.6150
                       Mean reward: 773.44
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 1.1524
    Episode_Reward/rotating_object: 154.8130
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.87s
                      Time elapsed: 00:31:06
                               ETA: 00:21:24

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 52240 steps/s (collection: 1.758s, learning 0.124s)
             Mean action noise std: 2.71
          Mean value_function loss: 28.7219
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.6311
                       Mean reward: 791.83
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 1.1444
    Episode_Reward/rotating_object: 154.6110
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.88s
                      Time elapsed: 00:31:08
                               ETA: 00:21:22

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 53324 steps/s (collection: 1.745s, learning 0.098s)
             Mean action noise std: 2.71
          Mean value_function loss: 40.1262
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 51.6457
                       Mean reward: 766.09
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 1.1245
    Episode_Reward/rotating_object: 152.0489
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.84s
                      Time elapsed: 00:31:09
                               ETA: 00:21:20

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 52522 steps/s (collection: 1.749s, learning 0.123s)
             Mean action noise std: 2.71
          Mean value_function loss: 33.8896
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.6572
                       Mean reward: 739.64
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 1.1254
    Episode_Reward/rotating_object: 149.8083
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.87s
                      Time elapsed: 00:31:11
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 50588 steps/s (collection: 1.808s, learning 0.135s)
             Mean action noise std: 2.72
          Mean value_function loss: 36.2362
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.6708
                       Mean reward: 782.68
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 155.6236
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.94s
                      Time elapsed: 00:31:13
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 47528 steps/s (collection: 1.926s, learning 0.143s)
             Mean action noise std: 2.72
          Mean value_function loss: 31.9865
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 51.6908
                       Mean reward: 774.35
               Mean episode length: 244.08
    Episode_Reward/reaching_object: 1.1473
    Episode_Reward/rotating_object: 155.7681
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.07s
                      Time elapsed: 00:31:15
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 48110 steps/s (collection: 1.907s, learning 0.136s)
             Mean action noise std: 2.72
          Mean value_function loss: 29.3180
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.7152
                       Mean reward: 809.63
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 1.1659
    Episode_Reward/rotating_object: 158.6236
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.04s
                      Time elapsed: 00:31:17
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 42549 steps/s (collection: 2.130s, learning 0.180s)
             Mean action noise std: 2.73
          Mean value_function loss: 35.8920
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.7380
                       Mean reward: 761.55
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.1369
    Episode_Reward/rotating_object: 153.8100
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.31s
                      Time elapsed: 00:31:20
                               ETA: 00:21:09

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 40745 steps/s (collection: 2.296s, learning 0.117s)
             Mean action noise std: 2.73
          Mean value_function loss: 31.2700
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.7646
                       Mean reward: 756.43
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.1588
    Episode_Reward/rotating_object: 156.6270
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.41s
                      Time elapsed: 00:31:22
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 46796 steps/s (collection: 1.977s, learning 0.124s)
             Mean action noise std: 2.73
          Mean value_function loss: 30.5215
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.7754
                       Mean reward: 787.05
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 1.1516
    Episode_Reward/rotating_object: 156.2491
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.10s
                      Time elapsed: 00:31:24
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 42324 steps/s (collection: 2.101s, learning 0.222s)
             Mean action noise std: 2.73
          Mean value_function loss: 28.0472
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.7831
                       Mean reward: 796.28
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 1.1456
    Episode_Reward/rotating_object: 155.2112
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.32s
                      Time elapsed: 00:31:26
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 43085 steps/s (collection: 2.114s, learning 0.167s)
             Mean action noise std: 2.73
          Mean value_function loss: 36.1973
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.7972
                       Mean reward: 775.70
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.1482
    Episode_Reward/rotating_object: 155.8757
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.28s
                      Time elapsed: 00:31:29
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 47516 steps/s (collection: 1.915s, learning 0.154s)
             Mean action noise std: 2.74
          Mean value_function loss: 36.9698
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.8174
                       Mean reward: 783.81
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.1517
    Episode_Reward/rotating_object: 155.7101
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.07s
                      Time elapsed: 00:31:31
                               ETA: 00:20:59

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 47166 steps/s (collection: 1.979s, learning 0.105s)
             Mean action noise std: 2.74
          Mean value_function loss: 36.5796
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.8266
                       Mean reward: 790.04
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 1.1381
    Episode_Reward/rotating_object: 153.1418
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.08s
                      Time elapsed: 00:31:33
                               ETA: 00:20:57

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 45382 steps/s (collection: 2.051s, learning 0.116s)
             Mean action noise std: 2.74
          Mean value_function loss: 31.6432
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.8367
                       Mean reward: 775.18
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 1.1564
    Episode_Reward/rotating_object: 154.0533
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.17s
                      Time elapsed: 00:31:35
                               ETA: 00:20:55

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 45947 steps/s (collection: 1.936s, learning 0.203s)
             Mean action noise std: 2.74
          Mean value_function loss: 34.3354
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 51.8455
                       Mean reward: 773.44
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.1632
    Episode_Reward/rotating_object: 156.9336
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.14s
                      Time elapsed: 00:31:37
                               ETA: 00:20:53

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 50266 steps/s (collection: 1.844s, learning 0.112s)
             Mean action noise std: 2.74
          Mean value_function loss: 43.5685
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.8529
                       Mean reward: 745.05
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.1417
    Episode_Reward/rotating_object: 151.9509
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.96s
                      Time elapsed: 00:31:39
                               ETA: 00:20:51

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 50621 steps/s (collection: 1.836s, learning 0.106s)
             Mean action noise std: 2.75
          Mean value_function loss: 39.8187
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.8682
                       Mean reward: 784.86
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 1.1541
    Episode_Reward/rotating_object: 154.9196
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.94s
                      Time elapsed: 00:31:41
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 47652 steps/s (collection: 1.866s, learning 0.197s)
             Mean action noise std: 2.75
          Mean value_function loss: 33.3914
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.8826
                       Mean reward: 793.65
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.1640
    Episode_Reward/rotating_object: 155.8860
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.06s
                      Time elapsed: 00:31:43
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 50480 steps/s (collection: 1.845s, learning 0.103s)
             Mean action noise std: 2.75
          Mean value_function loss: 31.5627
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.8976
                       Mean reward: 774.15
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.1417
    Episode_Reward/rotating_object: 152.2876
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.95s
                      Time elapsed: 00:31:45
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 41365 steps/s (collection: 2.136s, learning 0.241s)
             Mean action noise std: 2.75
          Mean value_function loss: 33.3895
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.9180
                       Mean reward: 785.44
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 157.8941
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.38s
                      Time elapsed: 00:31:48
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 39197 steps/s (collection: 2.397s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 29.0070
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 51.9342
                       Mean reward: 787.92
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 156.0254
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.51s
                      Time elapsed: 00:31:50
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 40876 steps/s (collection: 2.189s, learning 0.216s)
             Mean action noise std: 2.76
          Mean value_function loss: 39.7810
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.9551
                       Mean reward: 757.12
               Mean episode length: 235.88
    Episode_Reward/reaching_object: 1.1364
    Episode_Reward/rotating_object: 151.6722
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.40s
                      Time elapsed: 00:31:52
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 39514 steps/s (collection: 2.383s, learning 0.105s)
             Mean action noise std: 2.76
          Mean value_function loss: 30.5716
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.9786
                       Mean reward: 798.40
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 1.1759
    Episode_Reward/rotating_object: 158.9588
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.49s
                      Time elapsed: 00:31:55
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 38609 steps/s (collection: 2.264s, learning 0.282s)
             Mean action noise std: 2.77
          Mean value_function loss: 39.0455
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.9929
                       Mean reward: 793.05
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 1.1576
    Episode_Reward/rotating_object: 155.1304
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.55s
                      Time elapsed: 00:31:57
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 41878 steps/s (collection: 2.239s, learning 0.109s)
             Mean action noise std: 2.77
          Mean value_function loss: 43.7691
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.0111
                       Mean reward: 789.31
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 1.1548
    Episode_Reward/rotating_object: 154.5115
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.35s
                      Time elapsed: 00:32:00
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 41967 steps/s (collection: 2.222s, learning 0.121s)
             Mean action noise std: 2.77
          Mean value_function loss: 37.3883
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 52.0309
                       Mean reward: 755.13
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.1584
    Episode_Reward/rotating_object: 153.7485
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.34s
                      Time elapsed: 00:32:02
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 39918 steps/s (collection: 2.290s, learning 0.172s)
             Mean action noise std: 2.77
          Mean value_function loss: 33.3722
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.0406
                       Mean reward: 772.72
               Mean episode length: 239.77
    Episode_Reward/reaching_object: 1.1685
    Episode_Reward/rotating_object: 154.7570
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.46s
                      Time elapsed: 00:32:05
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 41178 steps/s (collection: 2.225s, learning 0.163s)
             Mean action noise std: 2.77
          Mean value_function loss: 35.6507
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.0524
                       Mean reward: 809.78
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 1.1711
    Episode_Reward/rotating_object: 157.0867
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.39s
                      Time elapsed: 00:32:07
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 46433 steps/s (collection: 1.985s, learning 0.132s)
             Mean action noise std: 2.78
          Mean value_function loss: 37.4955
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.0685
                       Mean reward: 781.09
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.1494
    Episode_Reward/rotating_object: 154.5092
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.12s
                      Time elapsed: 00:32:09
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 43693 steps/s (collection: 2.068s, learning 0.182s)
             Mean action noise std: 2.78
          Mean value_function loss: 39.3153
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.0857
                       Mean reward: 780.73
               Mean episode length: 241.09
    Episode_Reward/reaching_object: 1.1490
    Episode_Reward/rotating_object: 152.4587
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.25s
                      Time elapsed: 00:32:11
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 43979 steps/s (collection: 2.078s, learning 0.158s)
             Mean action noise std: 2.78
          Mean value_function loss: 24.2253
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.1010
                       Mean reward: 793.64
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 1.1518
    Episode_Reward/rotating_object: 153.7604
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.24s
                      Time elapsed: 00:32:14
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 41212 steps/s (collection: 2.214s, learning 0.172s)
             Mean action noise std: 2.78
          Mean value_function loss: 26.2840
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.1164
                       Mean reward: 792.00
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.1642
    Episode_Reward/rotating_object: 156.1069
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.39s
                      Time elapsed: 00:32:16
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 41150 steps/s (collection: 2.198s, learning 0.191s)
             Mean action noise std: 2.79
          Mean value_function loss: 30.8343
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 52.1253
                       Mean reward: 787.98
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.1523
    Episode_Reward/rotating_object: 155.7677
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.39s
                      Time elapsed: 00:32:18
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 41689 steps/s (collection: 2.243s, learning 0.115s)
             Mean action noise std: 2.79
          Mean value_function loss: 27.9756
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.1451
                       Mean reward: 798.96
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 1.1667
    Episode_Reward/rotating_object: 157.1440
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.36s
                      Time elapsed: 00:32:21
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 44169 steps/s (collection: 2.119s, learning 0.107s)
             Mean action noise std: 2.79
          Mean value_function loss: 37.8197
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.1637
                       Mean reward: 778.86
               Mean episode length: 239.78
    Episode_Reward/reaching_object: 1.1441
    Episode_Reward/rotating_object: 155.3183
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.23s
                      Time elapsed: 00:32:23
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 44394 steps/s (collection: 2.106s, learning 0.109s)
             Mean action noise std: 2.79
          Mean value_function loss: 30.0149
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 52.1739
                       Mean reward: 793.01
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.1643
    Episode_Reward/rotating_object: 157.2486
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.21s
                      Time elapsed: 00:32:25
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 44399 steps/s (collection: 2.036s, learning 0.178s)
             Mean action noise std: 2.79
          Mean value_function loss: 32.1050
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.1872
                       Mean reward: 801.37
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 1.1853
    Episode_Reward/rotating_object: 160.3901
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.21s
                      Time elapsed: 00:32:27
                               ETA: 00:20:09

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 46919 steps/s (collection: 1.962s, learning 0.134s)
             Mean action noise std: 2.80
          Mean value_function loss: 26.1730
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.1997
                       Mean reward: 801.56
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 1.1871
    Episode_Reward/rotating_object: 158.9327
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.10s
                      Time elapsed: 00:32:29
                               ETA: 00:20:07

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 47699 steps/s (collection: 1.933s, learning 0.128s)
             Mean action noise std: 2.80
          Mean value_function loss: 31.7098
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 52.2063
                       Mean reward: 785.62
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 157.1064
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.06s
                      Time elapsed: 00:32:32
                               ETA: 00:20:05

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 48061 steps/s (collection: 1.892s, learning 0.153s)
             Mean action noise std: 2.80
          Mean value_function loss: 29.6493
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.2142
                       Mean reward: 784.08
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 1.1645
    Episode_Reward/rotating_object: 156.1348
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.05s
                      Time elapsed: 00:32:34
                               ETA: 00:20:03

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 45036 steps/s (collection: 2.017s, learning 0.166s)
             Mean action noise std: 2.80
          Mean value_function loss: 32.0960
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 52.2277
                       Mean reward: 778.57
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 1.1660
    Episode_Reward/rotating_object: 155.5975
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.18s
                      Time elapsed: 00:32:36
                               ETA: 00:20:01

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 49095 steps/s (collection: 1.901s, learning 0.102s)
             Mean action noise std: 2.80
          Mean value_function loss: 25.7643
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 52.2497
                       Mean reward: 798.05
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 160.4691
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.00s
                      Time elapsed: 00:32:38
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 50069 steps/s (collection: 1.868s, learning 0.096s)
             Mean action noise std: 2.81
          Mean value_function loss: 30.9011
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.2660
                       Mean reward: 812.87
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 158.4507
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.96s
                      Time elapsed: 00:32:40
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 49391 steps/s (collection: 1.881s, learning 0.110s)
             Mean action noise std: 2.81
          Mean value_function loss: 23.1914
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.2806
                       Mean reward: 802.58
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 1.1966
    Episode_Reward/rotating_object: 159.4963
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.99s
                      Time elapsed: 00:32:42
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 49737 steps/s (collection: 1.874s, learning 0.102s)
             Mean action noise std: 2.81
          Mean value_function loss: 27.1365
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.2846
                       Mean reward: 799.37
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 157.1934
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.98s
                      Time elapsed: 00:32:44
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 47726 steps/s (collection: 1.878s, learning 0.182s)
             Mean action noise std: 2.81
          Mean value_function loss: 33.2268
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.2861
                       Mean reward: 785.17
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 157.6756
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.06s
                      Time elapsed: 00:32:46
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 48770 steps/s (collection: 1.917s, learning 0.099s)
             Mean action noise std: 2.81
          Mean value_function loss: 34.4488
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.2918
                       Mean reward: 792.44
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 156.8427
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.02s
                      Time elapsed: 00:32:48
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 48629 steps/s (collection: 1.889s, learning 0.132s)
             Mean action noise std: 2.81
          Mean value_function loss: 26.5168
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.3037
                       Mean reward: 803.05
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 159.8691
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.02s
                      Time elapsed: 00:32:50
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 50168 steps/s (collection: 1.860s, learning 0.099s)
             Mean action noise std: 2.81
          Mean value_function loss: 33.8923
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.3121
                       Mean reward: 780.05
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.1975
    Episode_Reward/rotating_object: 158.7746
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.96s
                      Time elapsed: 00:32:52
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 46610 steps/s (collection: 1.985s, learning 0.124s)
             Mean action noise std: 2.82
          Mean value_function loss: 30.2557
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.3253
                       Mean reward: 785.34
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 156.4911
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.11s
                      Time elapsed: 00:32:54
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 49670 steps/s (collection: 1.854s, learning 0.126s)
             Mean action noise std: 2.82
          Mean value_function loss: 35.4664
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.3459
                       Mean reward: 795.18
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 1.1972
    Episode_Reward/rotating_object: 157.9635
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.98s
                      Time elapsed: 00:32:56
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 48966 steps/s (collection: 1.884s, learning 0.124s)
             Mean action noise std: 2.82
          Mean value_function loss: 33.1851
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.3618
                       Mean reward: 777.92
               Mean episode length: 238.24
    Episode_Reward/reaching_object: 1.1830
    Episode_Reward/rotating_object: 157.6681
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.01s
                      Time elapsed: 00:32:58
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 48292 steps/s (collection: 1.919s, learning 0.117s)
             Mean action noise std: 2.82
          Mean value_function loss: 35.0128
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.3786
                       Mean reward: 797.99
               Mean episode length: 244.16
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 156.5246
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.04s
                      Time elapsed: 00:33:00
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 49556 steps/s (collection: 1.882s, learning 0.102s)
             Mean action noise std: 2.83
          Mean value_function loss: 35.8044
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.3956
                       Mean reward: 773.01
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.1719
    Episode_Reward/rotating_object: 155.9652
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.98s
                      Time elapsed: 00:33:02
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 50644 steps/s (collection: 1.837s, learning 0.104s)
             Mean action noise std: 2.83
          Mean value_function loss: 30.0121
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.4095
                       Mean reward: 775.39
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.1836
    Episode_Reward/rotating_object: 155.4991
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.94s
                      Time elapsed: 00:33:04
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 51031 steps/s (collection: 1.806s, learning 0.121s)
             Mean action noise std: 2.83
          Mean value_function loss: 29.2736
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 52.4229
                       Mean reward: 775.75
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 158.7809
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.93s
                      Time elapsed: 00:33:06
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 49415 steps/s (collection: 1.865s, learning 0.125s)
             Mean action noise std: 2.83
          Mean value_function loss: 35.4912
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.4290
                       Mean reward: 807.45
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.2013
    Episode_Reward/rotating_object: 159.3682
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.99s
                      Time elapsed: 00:33:08
                               ETA: 00:19:26

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 48409 steps/s (collection: 1.849s, learning 0.182s)
             Mean action noise std: 2.83
          Mean value_function loss: 32.5487
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.4390
                       Mean reward: 783.81
               Mean episode length: 241.95
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 158.9534
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.03s
                      Time elapsed: 00:33:10
                               ETA: 00:19:24

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 50084 steps/s (collection: 1.837s, learning 0.126s)
             Mean action noise std: 2.83
          Mean value_function loss: 23.9254
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.4499
                       Mean reward: 790.91
               Mean episode length: 241.89
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 157.4346
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.96s
                      Time elapsed: 00:33:12
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 50698 steps/s (collection: 1.845s, learning 0.094s)
             Mean action noise std: 2.84
          Mean value_function loss: 26.5857
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.4652
                       Mean reward: 787.81
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 1.1955
    Episode_Reward/rotating_object: 159.4046
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.94s
                      Time elapsed: 00:33:14
                               ETA: 00:19:19

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 48699 steps/s (collection: 1.916s, learning 0.103s)
             Mean action noise std: 2.84
          Mean value_function loss: 25.3294
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.4800
                       Mean reward: 821.93
               Mean episode length: 248.66
    Episode_Reward/reaching_object: 1.1790
    Episode_Reward/rotating_object: 159.5322
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.02s
                      Time elapsed: 00:33:16
                               ETA: 00:19:17

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 48283 steps/s (collection: 1.932s, learning 0.104s)
             Mean action noise std: 2.84
          Mean value_function loss: 29.6633
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.4960
                       Mean reward: 814.06
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 159.0934
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.04s
                      Time elapsed: 00:33:18
                               ETA: 00:19:15

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 49051 steps/s (collection: 1.910s, learning 0.094s)
             Mean action noise std: 2.84
          Mean value_function loss: 27.7797
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.5047
                       Mean reward: 807.48
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.1936
    Episode_Reward/rotating_object: 159.2719
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.00s
                      Time elapsed: 00:33:20
                               ETA: 00:19:13

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 49463 steps/s (collection: 1.888s, learning 0.100s)
             Mean action noise std: 2.84
          Mean value_function loss: 32.6346
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 52.5117
                       Mean reward: 785.65
               Mean episode length: 240.04
    Episode_Reward/reaching_object: 1.1811
    Episode_Reward/rotating_object: 157.3708
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.99s
                      Time elapsed: 00:33:22
                               ETA: 00:19:11

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 47067 steps/s (collection: 1.983s, learning 0.106s)
             Mean action noise std: 2.85
          Mean value_function loss: 33.5981
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 52.5207
                       Mean reward: 808.59
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 159.9440
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.09s
                      Time elapsed: 00:33:24
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 46447 steps/s (collection: 2.012s, learning 0.105s)
             Mean action noise std: 2.85
          Mean value_function loss: 25.7766
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.5394
                       Mean reward: 788.24
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 159.5771
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.12s
                      Time elapsed: 00:33:26
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 49794 steps/s (collection: 1.873s, learning 0.102s)
             Mean action noise std: 2.85
          Mean value_function loss: 25.8424
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.5581
                       Mean reward: 803.44
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.2028
    Episode_Reward/rotating_object: 159.5159
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.97s
                      Time elapsed: 00:33:28
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 49515 steps/s (collection: 1.880s, learning 0.105s)
             Mean action noise std: 2.85
          Mean value_function loss: 28.1967
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.5704
                       Mean reward: 795.34
               Mean episode length: 242.87
    Episode_Reward/reaching_object: 1.1876
    Episode_Reward/rotating_object: 157.7520
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.99s
                      Time elapsed: 00:33:30
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 48268 steps/s (collection: 1.888s, learning 0.149s)
             Mean action noise std: 2.85
          Mean value_function loss: 25.3887
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.5784
                       Mean reward: 804.76
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 1.2014
    Episode_Reward/rotating_object: 160.8822
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.04s
                      Time elapsed: 00:33:32
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 48190 steps/s (collection: 1.939s, learning 0.101s)
             Mean action noise std: 2.86
          Mean value_function loss: 34.8255
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.5899
                       Mean reward: 803.59
               Mean episode length: 246.28
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 159.2919
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.04s
                      Time elapsed: 00:33:34
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 49833 steps/s (collection: 1.849s, learning 0.124s)
             Mean action noise std: 2.86
          Mean value_function loss: 31.8501
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 52.6001
                       Mean reward: 828.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2107
    Episode_Reward/rotating_object: 161.8820
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.97s
                      Time elapsed: 00:33:36
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 50997 steps/s (collection: 1.814s, learning 0.114s)
             Mean action noise std: 2.86
          Mean value_function loss: 26.0370
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.6092
                       Mean reward: 809.13
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 159.9115
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.93s
                      Time elapsed: 00:33:38
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 44581 steps/s (collection: 2.014s, learning 0.191s)
             Mean action noise std: 2.86
          Mean value_function loss: 30.3418
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.6253
                       Mean reward: 806.83
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 1.2066
    Episode_Reward/rotating_object: 161.2464
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.21s
                      Time elapsed: 00:33:40
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 47306 steps/s (collection: 1.973s, learning 0.105s)
             Mean action noise std: 2.86
          Mean value_function loss: 33.1251
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.6413
                       Mean reward: 772.91
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.1872
    Episode_Reward/rotating_object: 157.7445
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.08s
                      Time elapsed: 00:33:42
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 47387 steps/s (collection: 1.926s, learning 0.149s)
             Mean action noise std: 2.87
          Mean value_function loss: 29.1913
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 52.6526
                       Mean reward: 796.63
               Mean episode length: 247.18
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 157.4421
        Episode_Reward/action_rate: -0.0461
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.07s
                      Time elapsed: 00:33:44
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 47468 steps/s (collection: 1.973s, learning 0.098s)
             Mean action noise std: 2.87
          Mean value_function loss: 28.4575
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.6607
                       Mean reward: 811.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 159.5177
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.07s
                      Time elapsed: 00:33:46
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 47947 steps/s (collection: 1.915s, learning 0.135s)
             Mean action noise std: 2.87
          Mean value_function loss: 23.0115
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.6739
                       Mean reward: 813.17
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 161.6469
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.05s
                      Time elapsed: 00:33:48
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 47210 steps/s (collection: 1.962s, learning 0.120s)
             Mean action noise std: 2.87
          Mean value_function loss: 27.2506
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 52.6835
                       Mean reward: 812.67
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.1944
    Episode_Reward/rotating_object: 160.8037
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.08s
                      Time elapsed: 00:33:50
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 47682 steps/s (collection: 1.921s, learning 0.141s)
             Mean action noise std: 2.87
          Mean value_function loss: 25.8196
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.6912
                       Mean reward: 799.06
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 159.4339
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.06s
                      Time elapsed: 00:33:52
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 47191 steps/s (collection: 1.971s, learning 0.113s)
             Mean action noise std: 2.88
          Mean value_function loss: 26.1449
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.7055
                       Mean reward: 780.34
               Mean episode length: 244.82
    Episode_Reward/reaching_object: 1.1939
    Episode_Reward/rotating_object: 160.1162
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.08s
                      Time elapsed: 00:33:55
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 50301 steps/s (collection: 1.830s, learning 0.125s)
             Mean action noise std: 2.88
          Mean value_function loss: 30.3806
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.7243
                       Mean reward: 791.02
               Mean episode length: 244.53
    Episode_Reward/reaching_object: 1.1695
    Episode_Reward/rotating_object: 156.5953
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.95s
                      Time elapsed: 00:33:57
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 48841 steps/s (collection: 1.893s, learning 0.120s)
             Mean action noise std: 2.88
          Mean value_function loss: 26.7813
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.7395
                       Mean reward: 778.16
               Mean episode length: 242.74
    Episode_Reward/reaching_object: 1.1552
    Episode_Reward/rotating_object: 152.9311
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.01s
                      Time elapsed: 00:33:59
                               ETA: 00:18:32

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 50534 steps/s (collection: 1.851s, learning 0.095s)
             Mean action noise std: 2.88
          Mean value_function loss: 27.4785
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.7545
                       Mean reward: 809.04
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 1.1868
    Episode_Reward/rotating_object: 159.1360
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.95s
                      Time elapsed: 00:34:00
                               ETA: 00:18:30

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 49402 steps/s (collection: 1.892s, learning 0.098s)
             Mean action noise std: 2.88
          Mean value_function loss: 30.3681
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.7703
                       Mean reward: 793.22
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 1.1843
    Episode_Reward/rotating_object: 158.3094
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.99s
                      Time elapsed: 00:34:02
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 50415 steps/s (collection: 1.850s, learning 0.100s)
             Mean action noise std: 2.89
          Mean value_function loss: 30.1346
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.7867
                       Mean reward: 772.25
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.1782
    Episode_Reward/rotating_object: 156.9580
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.95s
                      Time elapsed: 00:34:04
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 48606 steps/s (collection: 1.910s, learning 0.113s)
             Mean action noise std: 2.89
          Mean value_function loss: 24.2090
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.8022
                       Mean reward: 795.34
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.1923
    Episode_Reward/rotating_object: 159.6187
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.02s
                      Time elapsed: 00:34:06
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 49027 steps/s (collection: 1.881s, learning 0.124s)
             Mean action noise std: 2.89
          Mean value_function loss: 31.8340
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.8204
                       Mean reward: 778.52
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 1.1887
    Episode_Reward/rotating_object: 158.9474
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.01s
                      Time elapsed: 00:34:08
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 48613 steps/s (collection: 1.901s, learning 0.121s)
             Mean action noise std: 2.90
          Mean value_function loss: 25.0433
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.8383
                       Mean reward: 815.03
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 1.1971
    Episode_Reward/rotating_object: 159.4634
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.02s
                      Time elapsed: 00:34:10
                               ETA: 00:18:20

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 50448 steps/s (collection: 1.843s, learning 0.106s)
             Mean action noise std: 2.90
          Mean value_function loss: 28.3285
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.8483
                       Mean reward: 809.00
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 159.3638
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.95s
                      Time elapsed: 00:34:12
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 48915 steps/s (collection: 1.892s, learning 0.118s)
             Mean action noise std: 2.90
          Mean value_function loss: 28.4855
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.8554
                       Mean reward: 828.67
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2091
    Episode_Reward/rotating_object: 161.0614
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.01s
                      Time elapsed: 00:34:14
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 49326 steps/s (collection: 1.892s, learning 0.101s)
             Mean action noise std: 2.90
          Mean value_function loss: 20.5060
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 52.8648
                       Mean reward: 807.75
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 1.1933
    Episode_Reward/rotating_object: 157.4243
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.99s
                      Time elapsed: 00:34:16
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 50599 steps/s (collection: 1.827s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 23.4184
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.8696
                       Mean reward: 815.88
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.2058
    Episode_Reward/rotating_object: 161.1315
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 1.94s
                      Time elapsed: 00:34:18
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 46777 steps/s (collection: 1.948s, learning 0.153s)
             Mean action noise std: 2.90
          Mean value_function loss: 25.2542
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.8803
                       Mean reward: 792.78
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 159.6570
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.10s
                      Time elapsed: 00:34:20
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 48201 steps/s (collection: 1.937s, learning 0.103s)
             Mean action noise std: 2.90
          Mean value_function loss: 21.6041
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 52.8929
                       Mean reward: 828.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2167
    Episode_Reward/rotating_object: 162.3773
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.04s
                      Time elapsed: 00:34:23
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 49164 steps/s (collection: 1.892s, learning 0.107s)
             Mean action noise std: 2.91
          Mean value_function loss: 19.3505
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.9002
                       Mean reward: 791.85
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 158.9355
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.00s
                      Time elapsed: 00:34:24
                               ETA: 00:18:04

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 49793 steps/s (collection: 1.874s, learning 0.101s)
             Mean action noise std: 2.91
          Mean value_function loss: 27.2344
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.9070
                       Mean reward: 816.25
               Mean episode length: 249.20
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 160.5026
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.97s
                      Time elapsed: 00:34:26
                               ETA: 00:18:02

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 49940 steps/s (collection: 1.850s, learning 0.119s)
             Mean action noise std: 2.91
          Mean value_function loss: 30.5386
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.9177
                       Mean reward: 795.63
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 159.3275
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.97s
                      Time elapsed: 00:34:28
                               ETA: 00:18:00

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 48484 steps/s (collection: 1.910s, learning 0.117s)
             Mean action noise std: 2.91
          Mean value_function loss: 31.3542
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.9276
                       Mean reward: 787.98
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.1901
    Episode_Reward/rotating_object: 158.0786
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.03s
                      Time elapsed: 00:34:30
                               ETA: 00:17:58

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 49672 steps/s (collection: 1.884s, learning 0.095s)
             Mean action noise std: 2.91
          Mean value_function loss: 34.9367
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.9344
                       Mean reward: 798.68
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 159.1459
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.98s
                      Time elapsed: 00:34:32
                               ETA: 00:17:56

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 50896 steps/s (collection: 1.823s, learning 0.109s)
             Mean action noise std: 2.92
          Mean value_function loss: 28.1265
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 52.9481
                       Mean reward: 809.90
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 1.2099
    Episode_Reward/rotating_object: 160.1017
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.93s
                      Time elapsed: 00:34:34
                               ETA: 00:17:54

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 46932 steps/s (collection: 1.996s, learning 0.099s)
             Mean action noise std: 2.92
          Mean value_function loss: 31.5680
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.9638
                       Mean reward: 809.95
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 159.5511
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.09s
                      Time elapsed: 00:34:36
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 48760 steps/s (collection: 1.884s, learning 0.133s)
             Mean action noise std: 2.92
          Mean value_function loss: 29.6551
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.9820
                       Mean reward: 816.46
               Mean episode length: 246.28
    Episode_Reward/reaching_object: 1.2122
    Episode_Reward/rotating_object: 160.4753
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.02s
                      Time elapsed: 00:34:38
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 51303 steps/s (collection: 1.819s, learning 0.098s)
             Mean action noise std: 2.92
          Mean value_function loss: 30.3442
               Mean surrogate loss: 0.0129
                 Mean entropy loss: 52.9907
                       Mean reward: 827.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 160.0151
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.92s
                      Time elapsed: 00:34:40
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 48476 steps/s (collection: 1.906s, learning 0.122s)
             Mean action noise std: 2.92
          Mean value_function loss: 26.4730
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.9923
                       Mean reward: 814.35
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 161.4455
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.03s
                      Time elapsed: 00:34:42
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 45986 steps/s (collection: 2.025s, learning 0.113s)
             Mean action noise std: 2.92
          Mean value_function loss: 31.2502
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.9956
                       Mean reward: 823.70
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 161.5533
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.14s
                      Time elapsed: 00:34:45
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 43868 steps/s (collection: 2.003s, learning 0.238s)
             Mean action noise std: 2.92
          Mean value_function loss: 31.6899
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0052
                       Mean reward: 789.21
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.1910
    Episode_Reward/rotating_object: 157.1121
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.24s
                      Time elapsed: 00:34:47
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 44660 steps/s (collection: 2.009s, learning 0.193s)
             Mean action noise std: 2.93
          Mean value_function loss: 28.0563
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.0229
                       Mean reward: 823.28
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 1.2098
    Episode_Reward/rotating_object: 160.7829
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.20s
                      Time elapsed: 00:34:49
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 44813 steps/s (collection: 2.075s, learning 0.119s)
             Mean action noise std: 2.93
          Mean value_function loss: 38.5157
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 53.0410
                       Mean reward: 797.41
               Mean episode length: 242.99
    Episode_Reward/reaching_object: 1.1904
    Episode_Reward/rotating_object: 157.9387
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.19s
                      Time elapsed: 00:34:51
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 46587 steps/s (collection: 1.998s, learning 0.113s)
             Mean action noise std: 2.93
          Mean value_function loss: 27.3348
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.0549
                       Mean reward: 794.69
               Mean episode length: 246.81
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 159.5348
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.11s
                      Time elapsed: 00:34:53
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 43279 steps/s (collection: 2.146s, learning 0.126s)
             Mean action noise std: 2.93
          Mean value_function loss: 30.0517
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.0624
                       Mean reward: 782.91
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 158.2153
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.27s
                      Time elapsed: 00:34:56
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 49113 steps/s (collection: 1.908s, learning 0.094s)
             Mean action noise std: 2.93
          Mean value_function loss: 27.5116
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.0755
                       Mean reward: 792.82
               Mean episode length: 240.76
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 160.1572
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.00s
                      Time elapsed: 00:34:58
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14491 steps/s (collection: 6.662s, learning 0.121s)
             Mean action noise std: 2.94
          Mean value_function loss: 34.1615
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.1027
                       Mean reward: 806.88
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.1971
    Episode_Reward/rotating_object: 158.0556
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.78s
                      Time elapsed: 00:35:04
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 13618 steps/s (collection: 7.054s, learning 0.165s)
             Mean action noise std: 2.94
          Mean value_function loss: 37.1333
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 53.1278
                       Mean reward: 822.72
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.1876
    Episode_Reward/rotating_object: 157.0759
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 7.22s
                      Time elapsed: 00:35:12
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14462 steps/s (collection: 6.643s, learning 0.155s)
             Mean action noise std: 2.94
          Mean value_function loss: 27.2366
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 53.1345
                       Mean reward: 810.54
               Mean episode length: 246.57
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 157.3786
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.80s
                      Time elapsed: 00:35:18
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 13699 steps/s (collection: 6.913s, learning 0.263s)
             Mean action noise std: 2.94
          Mean value_function loss: 24.8606
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 53.1425
                       Mean reward: 779.43
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 158.9955
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 7.18s
                      Time elapsed: 00:35:26
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 12909 steps/s (collection: 7.396s, learning 0.219s)
             Mean action noise std: 2.95
          Mean value_function loss: 32.2996
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.1557
                       Mean reward: 803.68
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 159.8795
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 7.62s
                      Time elapsed: 00:35:33
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 13840 steps/s (collection: 6.927s, learning 0.176s)
             Mean action noise std: 2.95
          Mean value_function loss: 26.8596
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 53.1697
                       Mean reward: 793.81
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.1951
    Episode_Reward/rotating_object: 156.9425
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 7.10s
                      Time elapsed: 00:35:40
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 13848 steps/s (collection: 6.953s, learning 0.145s)
             Mean action noise std: 2.95
          Mean value_function loss: 23.6583
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.1759
                       Mean reward: 812.39
               Mean episode length: 246.12
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 160.2963
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 7.10s
                      Time elapsed: 00:35:47
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 14692 steps/s (collection: 6.563s, learning 0.127s)
             Mean action noise std: 2.95
          Mean value_function loss: 25.6221
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.1881
                       Mean reward: 819.08
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 159.6634
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.69s
                      Time elapsed: 00:35:54
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 16779 steps/s (collection: 5.713s, learning 0.146s)
             Mean action noise std: 2.96
          Mean value_function loss: 28.5117
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 53.2041
                       Mean reward: 833.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2197
    Episode_Reward/rotating_object: 160.4378
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.86s
                      Time elapsed: 00:36:00
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 51630 steps/s (collection: 1.781s, learning 0.123s)
             Mean action noise std: 2.96
          Mean value_function loss: 35.9304
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 53.2160
                       Mean reward: 810.23
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.2232
    Episode_Reward/rotating_object: 160.7903
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.90s
                      Time elapsed: 00:36:02
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 51550 steps/s (collection: 1.793s, learning 0.114s)
             Mean action noise std: 2.96
          Mean value_function loss: 30.7148
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.2282
                       Mean reward: 814.32
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 158.8085
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.91s
                      Time elapsed: 00:36:04
                               ETA: 00:17:28

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 47204 steps/s (collection: 1.909s, learning 0.174s)
             Mean action noise std: 2.96
          Mean value_function loss: 29.2770
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.2375
                       Mean reward: 796.73
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.2197
    Episode_Reward/rotating_object: 158.4789
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.08s
                      Time elapsed: 00:36:06
                               ETA: 00:17:26

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 50817 steps/s (collection: 1.823s, learning 0.111s)
             Mean action noise std: 2.96
          Mean value_function loss: 33.1927
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.2432
                       Mean reward: 817.48
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 1.2421
    Episode_Reward/rotating_object: 161.9647
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.93s
                      Time elapsed: 00:36:08
                               ETA: 00:17:24

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 50094 steps/s (collection: 1.854s, learning 0.108s)
             Mean action noise std: 2.96
          Mean value_function loss: 29.3756
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 53.2535
                       Mean reward: 803.78
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 158.1284
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.96s
                      Time elapsed: 00:36:10
                               ETA: 00:17:22

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 52419 steps/s (collection: 1.779s, learning 0.096s)
             Mean action noise std: 2.97
          Mean value_function loss: 21.4615
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.2613
                       Mean reward: 833.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2294
    Episode_Reward/rotating_object: 161.8514
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.88s
                      Time elapsed: 00:36:12
                               ETA: 00:17:20

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 49663 steps/s (collection: 1.883s, learning 0.097s)
             Mean action noise std: 2.97
          Mean value_function loss: 42.6813
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.2801
                       Mean reward: 788.71
               Mean episode length: 240.23
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 158.5533
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.98s
                      Time elapsed: 00:36:14
                               ETA: 00:17:17

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 43780 steps/s (collection: 2.072s, learning 0.173s)
             Mean action noise std: 2.97
          Mean value_function loss: 27.6652
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.3007
                       Mean reward: 795.16
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.1943
    Episode_Reward/rotating_object: 158.1733
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.25s
                      Time elapsed: 00:36:16
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 49419 steps/s (collection: 1.884s, learning 0.106s)
             Mean action noise std: 2.97
          Mean value_function loss: 22.9392
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 53.3073
                       Mean reward: 792.88
               Mean episode length: 241.48
    Episode_Reward/reaching_object: 1.2096
    Episode_Reward/rotating_object: 160.0134
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.99s
                      Time elapsed: 00:36:18
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 50784 steps/s (collection: 1.832s, learning 0.104s)
             Mean action noise std: 2.97
          Mean value_function loss: 29.8321
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.3144
                       Mean reward: 808.51
               Mean episode length: 246.29
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 159.9780
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.94s
                      Time elapsed: 00:36:20
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 53184 steps/s (collection: 1.738s, learning 0.110s)
             Mean action noise std: 2.98
          Mean value_function loss: 28.0936
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.3278
                       Mean reward: 790.93
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 1.2082
    Episode_Reward/rotating_object: 159.4157
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.85s
                      Time elapsed: 00:36:22
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 41505 steps/s (collection: 2.199s, learning 0.170s)
             Mean action noise std: 2.98
          Mean value_function loss: 36.4389
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.3470
                       Mean reward: 786.14
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 1.1836
    Episode_Reward/rotating_object: 156.7216
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.37s
                      Time elapsed: 00:36:24
                               ETA: 00:17:06

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 46345 steps/s (collection: 2.008s, learning 0.114s)
             Mean action noise std: 2.98
          Mean value_function loss: 31.6542
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 53.3710
                       Mean reward: 808.58
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 159.2425
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.12s
                      Time elapsed: 00:36:26
                               ETA: 00:17:04

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 49859 steps/s (collection: 1.861s, learning 0.111s)
             Mean action noise std: 2.98
          Mean value_function loss: 40.2612
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.3888
                       Mean reward: 802.60
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.1804
    Episode_Reward/rotating_object: 156.9277
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.97s
                      Time elapsed: 00:36:28
                               ETA: 00:17:02

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 49151 steps/s (collection: 1.896s, learning 0.104s)
             Mean action noise std: 2.99
          Mean value_function loss: 28.2722
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 53.4052
                       Mean reward: 772.74
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.1940
    Episode_Reward/rotating_object: 157.7151
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.00s
                      Time elapsed: 00:36:30
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 42321 steps/s (collection: 2.103s, learning 0.220s)
             Mean action noise std: 2.99
          Mean value_function loss: 28.0519
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.4146
                       Mean reward: 816.77
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 162.0896
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.32s
                      Time elapsed: 00:36:32
                               ETA: 00:16:58

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 50891 steps/s (collection: 1.780s, learning 0.152s)
             Mean action noise std: 2.99
          Mean value_function loss: 30.2271
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.4330
                       Mean reward: 786.46
               Mean episode length: 240.91
    Episode_Reward/reaching_object: 1.2028
    Episode_Reward/rotating_object: 160.1635
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.93s
                      Time elapsed: 00:36:34
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 49130 steps/s (collection: 1.839s, learning 0.162s)
             Mean action noise std: 3.00
          Mean value_function loss: 35.5869
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.4555
                       Mean reward: 798.54
               Mean episode length: 242.67
    Episode_Reward/reaching_object: 1.2040
    Episode_Reward/rotating_object: 159.9927
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.00s
                      Time elapsed: 00:36:36
                               ETA: 00:16:53

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 49108 steps/s (collection: 1.890s, learning 0.112s)
             Mean action noise std: 3.00
          Mean value_function loss: 36.2687
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 53.4698
                       Mean reward: 805.54
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 160.3105
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.00s
                      Time elapsed: 00:36:38
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 51076 steps/s (collection: 1.823s, learning 0.102s)
             Mean action noise std: 3.00
          Mean value_function loss: 29.5673
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 53.4759
                       Mean reward: 790.12
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.1760
    Episode_Reward/rotating_object: 156.2283
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.92s
                      Time elapsed: 00:36:40
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 49369 steps/s (collection: 1.882s, learning 0.110s)
             Mean action noise std: 3.00
          Mean value_function loss: 36.6568
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.4853
                       Mean reward: 807.96
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 160.2948
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.99s
                      Time elapsed: 00:36:42
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 52324 steps/s (collection: 1.781s, learning 0.098s)
             Mean action noise std: 3.00
          Mean value_function loss: 29.7444
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 53.5097
                       Mean reward: 793.55
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 158.2857
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.88s
                      Time elapsed: 00:36:44
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 46227 steps/s (collection: 2.019s, learning 0.107s)
             Mean action noise std: 3.01
          Mean value_function loss: 38.4505
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.5416
                       Mean reward: 802.77
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.1782
    Episode_Reward/rotating_object: 157.3422
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.13s
                      Time elapsed: 00:36:46
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 47291 steps/s (collection: 1.931s, learning 0.148s)
             Mean action noise std: 3.01
          Mean value_function loss: 33.0340
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 53.5701
                       Mean reward: 825.94
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.1989
    Episode_Reward/rotating_object: 160.1849
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.08s
                      Time elapsed: 00:36:48
                               ETA: 00:16:40

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 48781 steps/s (collection: 1.875s, learning 0.140s)
             Mean action noise std: 3.01
          Mean value_function loss: 34.4794
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.5858
                       Mean reward: 828.91
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 1.1902
    Episode_Reward/rotating_object: 158.8069
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.02s
                      Time elapsed: 00:36:50
                               ETA: 00:16:38

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 44354 steps/s (collection: 1.870s, learning 0.347s)
             Mean action noise std: 3.02
          Mean value_function loss: 31.3661
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.5972
                       Mean reward: 792.59
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.1993
    Episode_Reward/rotating_object: 159.3465
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.22s
                      Time elapsed: 00:36:53
                               ETA: 00:16:36

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 41439 steps/s (collection: 2.189s, learning 0.184s)
             Mean action noise std: 3.02
          Mean value_function loss: 37.3952
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.6039
                       Mean reward: 791.00
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.1828
    Episode_Reward/rotating_object: 157.3931
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.37s
                      Time elapsed: 00:36:55
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 39818 steps/s (collection: 2.199s, learning 0.270s)
             Mean action noise std: 3.02
          Mean value_function loss: 28.4608
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.6193
                       Mean reward: 816.73
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 1.1897
    Episode_Reward/rotating_object: 158.6389
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.47s
                      Time elapsed: 00:36:57
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 46155 steps/s (collection: 1.959s, learning 0.171s)
             Mean action noise std: 3.02
          Mean value_function loss: 28.3320
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 53.6377
                       Mean reward: 807.90
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.1861
    Episode_Reward/rotating_object: 157.8984
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.13s
                      Time elapsed: 00:37:00
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 39830 steps/s (collection: 2.281s, learning 0.187s)
             Mean action noise std: 3.03
          Mean value_function loss: 29.6514
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 53.6556
                       Mean reward: 786.94
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.1924
    Episode_Reward/rotating_object: 158.3829
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.47s
                      Time elapsed: 00:37:02
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 39914 steps/s (collection: 2.289s, learning 0.174s)
             Mean action noise std: 3.03
          Mean value_function loss: 37.2169
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.6752
                       Mean reward: 817.02
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 158.9725
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.46s
                      Time elapsed: 00:37:04
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 46241 steps/s (collection: 1.989s, learning 0.137s)
             Mean action noise std: 3.03
          Mean value_function loss: 34.4048
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 53.6889
                       Mean reward: 781.35
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 157.8429
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.13s
                      Time elapsed: 00:37:07
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 42511 steps/s (collection: 2.154s, learning 0.159s)
             Mean action noise std: 3.03
          Mean value_function loss: 27.2854
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.6972
                       Mean reward: 815.34
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.1850
    Episode_Reward/rotating_object: 158.4366
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.31s
                      Time elapsed: 00:37:09
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 39663 steps/s (collection: 2.293s, learning 0.185s)
             Mean action noise std: 3.03
          Mean value_function loss: 30.1285
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 53.7178
                       Mean reward: 824.48
               Mean episode length: 248.52
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 159.0368
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.48s
                      Time elapsed: 00:37:11
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 41037 steps/s (collection: 2.204s, learning 0.191s)
             Mean action noise std: 3.04
          Mean value_function loss: 24.8706
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.7381
                       Mean reward: 818.84
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 159.9466
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.40s
                      Time elapsed: 00:37:14
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 38568 steps/s (collection: 2.268s, learning 0.281s)
             Mean action noise std: 3.04
          Mean value_function loss: 19.2874
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 53.7546
                       Mean reward: 792.44
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 162.0382
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.55s
                      Time elapsed: 00:37:16
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 25537 steps/s (collection: 3.660s, learning 0.190s)
             Mean action noise std: 3.04
          Mean value_function loss: 32.3658
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 53.7653
                       Mean reward: 817.69
               Mean episode length: 247.20
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 159.2274
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 3.85s
                      Time elapsed: 00:37:20
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 31976 steps/s (collection: 2.867s, learning 0.207s)
             Mean action noise std: 3.04
          Mean value_function loss: 25.5564
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 53.7900
                       Mean reward: 790.01
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 159.0304
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 3.07s
                      Time elapsed: 00:37:23
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 40085 steps/s (collection: 2.148s, learning 0.304s)
             Mean action noise std: 3.04
          Mean value_function loss: 23.1673
               Mean surrogate loss: 0.0028
                 Mean entropy loss: 53.8068
                       Mean reward: 792.92
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 1.2155
    Episode_Reward/rotating_object: 161.7900
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.45s
                      Time elapsed: 00:37:26
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 42100 steps/s (collection: 2.237s, learning 0.098s)
             Mean action noise std: 3.05
          Mean value_function loss: 32.6159
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.8127
                       Mean reward: 788.86
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.1928
    Episode_Reward/rotating_object: 158.7608
        Episode_Reward/action_rate: -0.0514
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.33s
                      Time elapsed: 00:37:28
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 46400 steps/s (collection: 2.021s, learning 0.098s)
             Mean action noise std: 3.05
          Mean value_function loss: 38.3189
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.8290
                       Mean reward: 777.72
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.1927
    Episode_Reward/rotating_object: 157.8250
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.12s
                      Time elapsed: 00:37:30
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 43516 steps/s (collection: 2.054s, learning 0.205s)
             Mean action noise std: 3.05
          Mean value_function loss: 30.7901
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.8415
                       Mean reward: 817.84
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 161.6534
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 19.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.26s
                      Time elapsed: 00:37:32
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 38772 steps/s (collection: 2.384s, learning 0.152s)
             Mean action noise std: 3.05
          Mean value_function loss: 38.9902
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 53.8541
                       Mean reward: 807.88
               Mean episode length: 247.13
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 158.8594
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.54s
                      Time elapsed: 00:37:35
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 41432 steps/s (collection: 2.168s, learning 0.205s)
             Mean action noise std: 3.06
          Mean value_function loss: 26.6361
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 53.8661
                       Mean reward: 812.84
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 159.5854
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.37s
                      Time elapsed: 00:37:37
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 44667 steps/s (collection: 1.979s, learning 0.222s)
             Mean action noise std: 3.06
          Mean value_function loss: 22.3709
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.8810
                       Mean reward: 814.83
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 159.8318
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.20s
                      Time elapsed: 00:37:40
                               ETA: 00:15:58

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 45570 steps/s (collection: 2.051s, learning 0.106s)
             Mean action noise std: 3.06
          Mean value_function loss: 24.1076
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 53.8932
                       Mean reward: 815.15
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 160.0335
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.16s
                      Time elapsed: 00:37:42
                               ETA: 00:15:56

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 47998 steps/s (collection: 1.941s, learning 0.107s)
             Mean action noise std: 3.06
          Mean value_function loss: 31.6491
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.9006
                       Mean reward: 800.48
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 158.5777
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.05s
                      Time elapsed: 00:37:44
                               ETA: 00:15:54

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 46492 steps/s (collection: 2.009s, learning 0.106s)
             Mean action noise std: 3.06
          Mean value_function loss: 28.1055
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.9143
                       Mean reward: 813.44
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 160.3930
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.11s
                      Time elapsed: 00:37:46
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 46161 steps/s (collection: 1.943s, learning 0.187s)
             Mean action noise std: 3.07
          Mean value_function loss: 24.3219
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 53.9338
                       Mean reward: 804.73
               Mean episode length: 243.94
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 161.0018
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.13s
                      Time elapsed: 00:37:48
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 48051 steps/s (collection: 1.948s, learning 0.098s)
             Mean action noise std: 3.07
          Mean value_function loss: 37.3773
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.9492
                       Mean reward: 804.86
               Mean episode length: 240.92
    Episode_Reward/reaching_object: 1.1943
    Episode_Reward/rotating_object: 159.5372
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0163
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.05s
                      Time elapsed: 00:37:50
                               ETA: 00:15:47

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 46596 steps/s (collection: 1.946s, learning 0.164s)
             Mean action noise std: 3.07
          Mean value_function loss: 25.4819
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.9634
                       Mean reward: 825.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2132
    Episode_Reward/rotating_object: 161.8986
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.11s
                      Time elapsed: 00:37:52
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 46670 steps/s (collection: 1.938s, learning 0.168s)
             Mean action noise std: 3.08
          Mean value_function loss: 34.8634
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.9844
                       Mean reward: 803.76
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 1.1866
    Episode_Reward/rotating_object: 158.4556
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.11s
                      Time elapsed: 00:37:54
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 44813 steps/s (collection: 1.995s, learning 0.199s)
             Mean action noise std: 3.08
          Mean value_function loss: 36.7453
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.0059
                       Mean reward: 794.75
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 157.2305
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.19s
                      Time elapsed: 00:37:56
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 50508 steps/s (collection: 1.840s, learning 0.107s)
             Mean action noise std: 3.08
          Mean value_function loss: 29.7272
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 54.0233
                       Mean reward: 791.67
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.1824
    Episode_Reward/rotating_object: 157.9068
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.95s
                      Time elapsed: 00:37:58
                               ETA: 00:15:38

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 49982 steps/s (collection: 1.870s, learning 0.097s)
             Mean action noise std: 3.09
          Mean value_function loss: 19.1726
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 54.0471
                       Mean reward: 805.04
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 160.8721
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.97s
                      Time elapsed: 00:38:00
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 48393 steps/s (collection: 1.907s, learning 0.124s)
             Mean action noise std: 3.09
          Mean value_function loss: 23.2461
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 54.0612
                       Mean reward: 796.78
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 1.2096
    Episode_Reward/rotating_object: 161.1687
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.03s
                      Time elapsed: 00:38:02
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 50781 steps/s (collection: 1.785s, learning 0.151s)
             Mean action noise std: 3.09
          Mean value_function loss: 29.4418
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.0739
                       Mean reward: 790.36
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.1867
    Episode_Reward/rotating_object: 157.1736
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.94s
                      Time elapsed: 00:38:04
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 48787 steps/s (collection: 1.903s, learning 0.112s)
             Mean action noise std: 3.09
          Mean value_function loss: 24.6401
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 54.0957
                       Mean reward: 781.93
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 160.3699
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.01s
                      Time elapsed: 00:38:06
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 49760 steps/s (collection: 1.883s, learning 0.093s)
             Mean action noise std: 3.09
          Mean value_function loss: 24.3367
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 54.1104
                       Mean reward: 815.18
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 1.2281
    Episode_Reward/rotating_object: 162.9290
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.98s
                      Time elapsed: 00:38:08
                               ETA: 00:15:27

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 49034 steps/s (collection: 1.914s, learning 0.091s)
             Mean action noise std: 3.10
          Mean value_function loss: 33.8717
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.1210
                       Mean reward: 802.00
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 160.5618
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.00s
                      Time elapsed: 00:38:10
                               ETA: 00:15:25

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 46642 steps/s (collection: 1.985s, learning 0.123s)
             Mean action noise std: 3.10
          Mean value_function loss: 35.3500
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 54.1478
                       Mean reward: 831.69
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 1.1997
    Episode_Reward/rotating_object: 159.2155
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.11s
                      Time elapsed: 00:38:12
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 49997 steps/s (collection: 1.849s, learning 0.117s)
             Mean action noise std: 3.10
          Mean value_function loss: 41.5840
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 54.1692
                       Mean reward: 804.05
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 1.1992
    Episode_Reward/rotating_object: 157.9487
        Episode_Reward/action_rate: -0.0534
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.97s
                      Time elapsed: 00:38:14
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 44766 steps/s (collection: 2.006s, learning 0.190s)
             Mean action noise std: 3.10
          Mean value_function loss: 35.4163
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.1732
                       Mean reward: 805.84
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 159.8906
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 18.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.20s
                      Time elapsed: 00:38:17
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 44732 steps/s (collection: 2.071s, learning 0.127s)
             Mean action noise std: 3.11
          Mean value_function loss: 30.0581
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.1880
                       Mean reward: 811.90
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.2068
    Episode_Reward/rotating_object: 161.0325
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.20s
                      Time elapsed: 00:38:19
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 48468 steps/s (collection: 1.931s, learning 0.097s)
             Mean action noise std: 3.11
          Mean value_function loss: 23.6712
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.2003
                       Mean reward: 823.56
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 160.6549
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.03s
                      Time elapsed: 00:38:21
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 49519 steps/s (collection: 1.887s, learning 0.099s)
             Mean action noise std: 3.11
          Mean value_function loss: 21.5938
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 54.2168
                       Mean reward: 827.98
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 160.3746
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.99s
                      Time elapsed: 00:38:23
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 45115 steps/s (collection: 2.029s, learning 0.150s)
             Mean action noise std: 3.11
          Mean value_function loss: 26.4002
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 54.2290
                       Mean reward: 800.27
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.2264
    Episode_Reward/rotating_object: 162.8674
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.18s
                      Time elapsed: 00:38:25
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 46729 steps/s (collection: 1.945s, learning 0.159s)
             Mean action noise std: 3.11
          Mean value_function loss: 26.0369
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.2354
                       Mean reward: 809.97
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.2073
    Episode_Reward/rotating_object: 161.6849
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.10s
                      Time elapsed: 00:38:27
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 48985 steps/s (collection: 1.911s, learning 0.096s)
             Mean action noise std: 3.12
          Mean value_function loss: 29.4064
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.2497
                       Mean reward: 801.30
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 159.4697
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.01s
                      Time elapsed: 00:38:29
                               ETA: 00:15:06

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 50315 steps/s (collection: 1.835s, learning 0.119s)
             Mean action noise std: 3.12
          Mean value_function loss: 21.0897
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 54.2644
                       Mean reward: 815.36
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.2192
    Episode_Reward/rotating_object: 161.2452
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.95s
                      Time elapsed: 00:38:31
                               ETA: 00:15:04

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 50542 steps/s (collection: 1.811s, learning 0.134s)
             Mean action noise std: 3.12
          Mean value_function loss: 31.4381
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.2836
                       Mean reward: 810.46
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 162.0386
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.94s
                      Time elapsed: 00:38:33
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 49800 steps/s (collection: 1.871s, learning 0.103s)
             Mean action noise std: 3.12
          Mean value_function loss: 28.4729
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.3066
                       Mean reward: 785.39
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 158.8278
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.97s
                      Time elapsed: 00:38:35
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 47093 steps/s (collection: 1.982s, learning 0.105s)
             Mean action noise std: 3.13
          Mean value_function loss: 23.0872
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 54.3242
                       Mean reward: 795.92
               Mean episode length: 240.95
    Episode_Reward/reaching_object: 1.2130
    Episode_Reward/rotating_object: 161.7633
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.09s
                      Time elapsed: 00:38:37
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 46413 steps/s (collection: 1.922s, learning 0.196s)
             Mean action noise std: 3.13
          Mean value_function loss: 26.6193
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 54.3356
                       Mean reward: 804.54
               Mean episode length: 241.77
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 159.2670
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.12s
                      Time elapsed: 00:38:39
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 38313 steps/s (collection: 2.385s, learning 0.181s)
             Mean action noise std: 3.13
          Mean value_function loss: 35.1134
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.3516
                       Mean reward: 826.82
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.1878
    Episode_Reward/rotating_object: 157.2390
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.57s
                      Time elapsed: 00:38:42
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 48410 steps/s (collection: 1.888s, learning 0.143s)
             Mean action noise std: 3.13
          Mean value_function loss: 31.3599
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.3719
                       Mean reward: 804.42
               Mean episode length: 241.02
    Episode_Reward/reaching_object: 1.2091
    Episode_Reward/rotating_object: 160.2486
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0166
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.03s
                      Time elapsed: 00:38:44
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 45920 steps/s (collection: 2.030s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 31.5974
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 54.3880
                       Mean reward: 825.42
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.1992
    Episode_Reward/rotating_object: 159.3198
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.14s
                      Time elapsed: 00:38:46
                               ETA: 00:14:48

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 45278 steps/s (collection: 2.075s, learning 0.096s)
             Mean action noise std: 3.14
          Mean value_function loss: 23.0356
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.4034
                       Mean reward: 828.07
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 1.1995
    Episode_Reward/rotating_object: 159.5597
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.17s
                      Time elapsed: 00:38:48
                               ETA: 00:14:46

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 46390 steps/s (collection: 1.969s, learning 0.150s)
             Mean action noise std: 3.14
          Mean value_function loss: 19.5256
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 54.4138
                       Mean reward: 825.80
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 163.3070
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.12s
                      Time elapsed: 00:38:50
                               ETA: 00:14:44

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 45578 steps/s (collection: 2.055s, learning 0.102s)
             Mean action noise std: 3.14
          Mean value_function loss: 28.5432
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 54.4151
                       Mean reward: 800.52
               Mean episode length: 242.03
    Episode_Reward/reaching_object: 1.2141
    Episode_Reward/rotating_object: 162.5529
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.16s
                      Time elapsed: 00:38:52
                               ETA: 00:14:42

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 46803 steps/s (collection: 1.978s, learning 0.122s)
             Mean action noise std: 3.14
          Mean value_function loss: 26.8806
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 54.4246
                       Mean reward: 802.37
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 159.6237
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.10s
                      Time elapsed: 00:38:54
                               ETA: 00:14:40

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 43928 steps/s (collection: 2.079s, learning 0.159s)
             Mean action noise std: 3.15
          Mean value_function loss: 42.1244
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.4402
                       Mean reward: 789.70
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2081
    Episode_Reward/rotating_object: 160.5981
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.24s
                      Time elapsed: 00:38:57
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 48136 steps/s (collection: 1.904s, learning 0.138s)
             Mean action noise std: 3.15
          Mean value_function loss: 26.3284
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 54.4561
                       Mean reward: 795.90
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.2057
    Episode_Reward/rotating_object: 158.8385
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.04s
                      Time elapsed: 00:38:59
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 51560 steps/s (collection: 1.808s, learning 0.099s)
             Mean action noise std: 3.15
          Mean value_function loss: 31.3997
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.4746
                       Mean reward: 802.56
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 1.2097
    Episode_Reward/rotating_object: 161.2885
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 18.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.91s
                      Time elapsed: 00:39:01
                               ETA: 00:14:33

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 52710 steps/s (collection: 1.765s, learning 0.100s)
             Mean action noise std: 3.15
          Mean value_function loss: 25.5697
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 54.4964
                       Mean reward: 817.19
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.1998
    Episode_Reward/rotating_object: 159.3978
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.86s
                      Time elapsed: 00:39:02
                               ETA: 00:14:31

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 51697 steps/s (collection: 1.780s, learning 0.122s)
             Mean action noise std: 3.16
          Mean value_function loss: 25.5317
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 54.5167
                       Mean reward: 821.00
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.2152
    Episode_Reward/rotating_object: 164.2726
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.90s
                      Time elapsed: 00:39:04
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 51757 steps/s (collection: 1.804s, learning 0.095s)
             Mean action noise std: 3.16
          Mean value_function loss: 31.5408
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.5424
                       Mean reward: 818.82
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.2068
    Episode_Reward/rotating_object: 161.3680
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.90s
                      Time elapsed: 00:39:06
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 48513 steps/s (collection: 1.909s, learning 0.118s)
             Mean action noise std: 3.16
          Mean value_function loss: 38.2102
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 54.5607
                       Mean reward: 788.14
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.1920
    Episode_Reward/rotating_object: 158.7793
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.03s
                      Time elapsed: 00:39:08
                               ETA: 00:14:25

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 44697 steps/s (collection: 2.027s, learning 0.173s)
             Mean action noise std: 3.17
          Mean value_function loss: 32.0519
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 54.5799
                       Mean reward: 808.42
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 1.1822
    Episode_Reward/rotating_object: 158.5978
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.20s
                      Time elapsed: 00:39:10
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 46986 steps/s (collection: 1.938s, learning 0.154s)
             Mean action noise std: 3.17
          Mean value_function loss: 24.8161
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 54.6005
                       Mean reward: 803.98
               Mean episode length: 242.30
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 159.3035
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.09s
                      Time elapsed: 00:39:13
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 45771 steps/s (collection: 1.966s, learning 0.182s)
             Mean action noise std: 3.17
          Mean value_function loss: 22.2184
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 54.6082
                       Mean reward: 810.38
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 161.5510
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.15s
                      Time elapsed: 00:39:15
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 45456 steps/s (collection: 1.950s, learning 0.212s)
             Mean action noise std: 3.17
          Mean value_function loss: 19.1563
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.6164
                       Mean reward: 831.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2164
    Episode_Reward/rotating_object: 164.3064
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.16s
                      Time elapsed: 00:39:17
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 42953 steps/s (collection: 2.185s, learning 0.104s)
             Mean action noise std: 3.17
          Mean value_function loss: 18.1133
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.6292
                       Mean reward: 811.41
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 161.5134
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.29s
                      Time elapsed: 00:39:19
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 44766 steps/s (collection: 2.099s, learning 0.097s)
             Mean action noise std: 3.18
          Mean value_function loss: 24.1905
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.6431
                       Mean reward: 833.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2012
    Episode_Reward/rotating_object: 162.8427
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.20s
                      Time elapsed: 00:39:21
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 47057 steps/s (collection: 1.989s, learning 0.100s)
             Mean action noise std: 3.18
          Mean value_function loss: 27.4555
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 54.6625
                       Mean reward: 805.21
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.1898
    Episode_Reward/rotating_object: 159.8354
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.09s
                      Time elapsed: 00:39:23
                               ETA: 00:14:10

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 44839 steps/s (collection: 2.041s, learning 0.152s)
             Mean action noise std: 3.18
          Mean value_function loss: 29.2552
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.6776
                       Mean reward: 813.91
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 1.1952
    Episode_Reward/rotating_object: 160.9173
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.19s
                      Time elapsed: 00:39:26
                               ETA: 00:14:07

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 39235 steps/s (collection: 2.350s, learning 0.155s)
             Mean action noise std: 3.18
          Mean value_function loss: 26.9589
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 54.6920
                       Mean reward: 783.55
               Mean episode length: 236.89
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 158.6189
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.51s
                      Time elapsed: 00:39:28
                               ETA: 00:14:05

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 44444 steps/s (collection: 2.070s, learning 0.142s)
             Mean action noise std: 3.19
          Mean value_function loss: 28.9502
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 54.7100
                       Mean reward: 813.18
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 161.5143
        Episode_Reward/action_rate: -0.0571
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.21s
                      Time elapsed: 00:39:30
                               ETA: 00:14:03

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 43025 steps/s (collection: 2.142s, learning 0.143s)
             Mean action noise std: 3.19
          Mean value_function loss: 29.7524
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.7244
                       Mean reward: 826.23
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 163.5936
        Episode_Reward/action_rate: -0.0576
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.28s
                      Time elapsed: 00:39:33
                               ETA: 00:14:01

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 44470 steps/s (collection: 2.029s, learning 0.182s)
             Mean action noise std: 3.19
          Mean value_function loss: 19.4478
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 54.7398
                       Mean reward: 816.09
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.1916
    Episode_Reward/rotating_object: 160.0469
        Episode_Reward/action_rate: -0.0568
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.21s
                      Time elapsed: 00:39:35
                               ETA: 00:13:59

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 46696 steps/s (collection: 1.963s, learning 0.142s)
             Mean action noise std: 3.19
          Mean value_function loss: 19.8284
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 54.7509
                       Mean reward: 791.86
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 162.6015
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.11s
                      Time elapsed: 00:39:37
                               ETA: 00:13:57

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 47020 steps/s (collection: 1.898s, learning 0.193s)
             Mean action noise std: 3.19
          Mean value_function loss: 23.9133
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.7534
                       Mean reward: 825.64
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.1959
    Episode_Reward/rotating_object: 162.4000
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.09s
                      Time elapsed: 00:39:39
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 49419 steps/s (collection: 1.899s, learning 0.091s)
             Mean action noise std: 3.20
          Mean value_function loss: 23.6873
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.7605
                       Mean reward: 825.61
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 161.8583
        Episode_Reward/action_rate: -0.0577
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.99s
                      Time elapsed: 00:39:41
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 51005 steps/s (collection: 1.794s, learning 0.133s)
             Mean action noise std: 3.20
          Mean value_function loss: 29.1942
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 54.7741
                       Mean reward: 822.97
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 1.1772
    Episode_Reward/rotating_object: 159.7576
        Episode_Reward/action_rate: -0.0569
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.93s
                      Time elapsed: 00:39:43
                               ETA: 00:13:50

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 47482 steps/s (collection: 1.963s, learning 0.107s)
             Mean action noise std: 3.20
          Mean value_function loss: 29.6284
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.7878
                       Mean reward: 804.77
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.2010
    Episode_Reward/rotating_object: 161.8829
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.07s
                      Time elapsed: 00:39:45
                               ETA: 00:13:48

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 52032 steps/s (collection: 1.779s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 32.3629
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.8056
                       Mean reward: 784.04
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.1866
    Episode_Reward/rotating_object: 157.9404
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.89s
                      Time elapsed: 00:39:47
                               ETA: 00:13:46

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 49030 steps/s (collection: 1.852s, learning 0.153s)
             Mean action noise std: 3.21
          Mean value_function loss: 27.8700
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.8190
                       Mean reward: 817.54
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 161.5291
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.00s
                      Time elapsed: 00:39:49
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 45979 steps/s (collection: 2.013s, learning 0.125s)
             Mean action noise std: 3.21
          Mean value_function loss: 23.5308
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.8270
                       Mean reward: 821.79
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 1.2083
    Episode_Reward/rotating_object: 160.5291
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.14s
                      Time elapsed: 00:39:51
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 47143 steps/s (collection: 1.974s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 26.1863
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 54.8438
                       Mean reward: 801.55
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 159.5936
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.09s
                      Time elapsed: 00:39:53
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 50994 steps/s (collection: 1.833s, learning 0.095s)
             Mean action noise std: 3.21
          Mean value_function loss: 29.6521
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.8619
                       Mean reward: 822.97
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 161.2272
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.93s
                      Time elapsed: 00:39:55
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 47665 steps/s (collection: 1.896s, learning 0.167s)
             Mean action noise std: 3.22
          Mean value_function loss: 22.2239
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 54.8815
                       Mean reward: 835.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 163.3638
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.06s
                      Time elapsed: 00:39:57
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 50556 steps/s (collection: 1.808s, learning 0.136s)
             Mean action noise std: 3.22
          Mean value_function loss: 25.4057
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 54.9003
                       Mean reward: 814.82
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 163.0721
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.94s
                      Time elapsed: 00:39:59
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 49977 steps/s (collection: 1.825s, learning 0.142s)
             Mean action noise std: 3.22
          Mean value_function loss: 30.6923
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.9174
                       Mean reward: 812.68
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 162.2390
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.97s
                      Time elapsed: 00:40:01
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 50207 steps/s (collection: 1.824s, learning 0.133s)
             Mean action noise std: 3.22
          Mean value_function loss: 22.7170
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.9303
                       Mean reward: 814.43
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.1964
    Episode_Reward/rotating_object: 159.3659
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.96s
                      Time elapsed: 00:40:03
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 49109 steps/s (collection: 1.824s, learning 0.178s)
             Mean action noise std: 3.23
          Mean value_function loss: 25.6785
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.9451
                       Mean reward: 817.44
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 162.6206
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.00s
                      Time elapsed: 00:40:05
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 46142 steps/s (collection: 1.879s, learning 0.251s)
             Mean action noise std: 3.23
          Mean value_function loss: 23.0168
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.9567
                       Mean reward: 831.31
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 163.5282
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.13s
                      Time elapsed: 00:40:07
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 48028 steps/s (collection: 1.937s, learning 0.109s)
             Mean action noise std: 3.23
          Mean value_function loss: 21.9523
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 54.9646
                       Mean reward: 813.89
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 162.0150
        Episode_Reward/action_rate: -0.0586
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.05s
                      Time elapsed: 00:40:09
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 49113 steps/s (collection: 1.905s, learning 0.097s)
             Mean action noise std: 3.23
          Mean value_function loss: 22.5440
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.9698
                       Mean reward: 831.86
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.2138
    Episode_Reward/rotating_object: 161.5063
        Episode_Reward/action_rate: -0.0590
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.00s
                      Time elapsed: 00:40:11
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 48329 steps/s (collection: 1.936s, learning 0.098s)
             Mean action noise std: 3.23
          Mean value_function loss: 29.8962
               Mean surrogate loss: 0.0036
                 Mean entropy loss: 54.9773
                       Mean reward: 817.05
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.2079
    Episode_Reward/rotating_object: 161.3951
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.03s
                      Time elapsed: 00:40:13
                               ETA: 00:13:18

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 48780 steps/s (collection: 1.887s, learning 0.128s)
             Mean action noise std: 3.23
          Mean value_function loss: 22.1697
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 54.9806
                       Mean reward: 840.66
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2238
    Episode_Reward/rotating_object: 163.3030
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.02s
                      Time elapsed: 00:40:15
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 47850 steps/s (collection: 1.935s, learning 0.120s)
             Mean action noise std: 3.23
          Mean value_function loss: 25.0159
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.9898
                       Mean reward: 807.48
               Mean episode length: 244.66
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 158.2041
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.05s
                      Time elapsed: 00:40:17
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 44324 steps/s (collection: 2.022s, learning 0.196s)
             Mean action noise std: 3.24
          Mean value_function loss: 24.5575
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 55.0047
                       Mean reward: 833.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 160.2932
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.22s
                      Time elapsed: 00:40:20
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 45986 steps/s (collection: 1.980s, learning 0.158s)
             Mean action noise std: 3.24
          Mean value_function loss: 29.4495
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 55.0240
                       Mean reward: 813.70
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 1.2068
    Episode_Reward/rotating_object: 160.5672
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.14s
                      Time elapsed: 00:40:22
                               ETA: 00:13:09

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 46996 steps/s (collection: 1.942s, learning 0.150s)
             Mean action noise std: 3.24
          Mean value_function loss: 25.8538
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.0417
                       Mean reward: 797.96
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 162.2235
        Episode_Reward/action_rate: -0.0593
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.09s
                      Time elapsed: 00:40:24
                               ETA: 00:13:07

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 49142 steps/s (collection: 1.878s, learning 0.123s)
             Mean action noise std: 3.24
          Mean value_function loss: 35.2755
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.0579
                       Mean reward: 808.27
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 1.1968
    Episode_Reward/rotating_object: 159.8147
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.00s
                      Time elapsed: 00:40:26
                               ETA: 00:13:05

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 50817 steps/s (collection: 1.825s, learning 0.110s)
             Mean action noise std: 3.25
          Mean value_function loss: 31.6593
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 55.0703
                       Mean reward: 769.92
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 160.0645
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.93s
                      Time elapsed: 00:40:28
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 50871 steps/s (collection: 1.827s, learning 0.105s)
             Mean action noise std: 3.25
          Mean value_function loss: 25.5094
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.0816
                       Mean reward: 841.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 161.6239
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.93s
                      Time elapsed: 00:40:30
                               ETA: 00:13:00

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 48903 steps/s (collection: 1.891s, learning 0.120s)
             Mean action noise std: 3.25
          Mean value_function loss: 22.7618
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 55.0942
                       Mean reward: 805.24
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 162.2392
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.01s
                      Time elapsed: 00:40:32
                               ETA: 00:12:58

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 50899 steps/s (collection: 1.782s, learning 0.150s)
             Mean action noise std: 3.25
          Mean value_function loss: 23.7067
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.1064
                       Mean reward: 826.49
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 1.2357
    Episode_Reward/rotating_object: 164.3192
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.93s
                      Time elapsed: 00:40:34
                               ETA: 00:12:56

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 51958 steps/s (collection: 1.786s, learning 0.106s)
             Mean action noise std: 3.25
          Mean value_function loss: 28.5541
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 55.1133
                       Mean reward: 816.41
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 1.2176
    Episode_Reward/rotating_object: 160.8810
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.89s
                      Time elapsed: 00:40:35
                               ETA: 00:12:54

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 51435 steps/s (collection: 1.809s, learning 0.102s)
             Mean action noise std: 3.25
          Mean value_function loss: 22.6885
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 55.1193
                       Mean reward: 800.06
               Mean episode length: 242.99
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 161.8424
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.91s
                      Time elapsed: 00:40:37
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 47545 steps/s (collection: 1.898s, learning 0.170s)
             Mean action noise std: 3.26
          Mean value_function loss: 25.2352
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 55.1262
                       Mean reward: 800.22
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.2056
    Episode_Reward/rotating_object: 159.3421
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.07s
                      Time elapsed: 00:40:39
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 50940 steps/s (collection: 1.826s, learning 0.104s)
             Mean action noise std: 3.26
          Mean value_function loss: 23.2971
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 55.1342
                       Mean reward: 818.85
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 163.1389
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.93s
                      Time elapsed: 00:40:41
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 51891 steps/s (collection: 1.794s, learning 0.101s)
             Mean action noise std: 3.26
          Mean value_function loss: 26.7589
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 55.1387
                       Mean reward: 816.03
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 159.1171
        Episode_Reward/action_rate: -0.0592
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.89s
                      Time elapsed: 00:40:43
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 51742 steps/s (collection: 1.808s, learning 0.092s)
             Mean action noise std: 3.26
          Mean value_function loss: 26.0766
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 55.1408
                       Mean reward: 820.89
               Mean episode length: 246.62
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 160.5069
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.90s
                      Time elapsed: 00:40:45
                               ETA: 00:12:43

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 46706 steps/s (collection: 1.942s, learning 0.163s)
             Mean action noise std: 3.26
          Mean value_function loss: 32.5163
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.1458
                       Mean reward: 814.18
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 161.2043
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.10s
                      Time elapsed: 00:40:47
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 49515 steps/s (collection: 1.818s, learning 0.167s)
             Mean action noise std: 3.26
          Mean value_function loss: 22.5646
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.1504
                       Mean reward: 827.00
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 162.7500
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.99s
                      Time elapsed: 00:40:49
                               ETA: 00:12:38

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 48323 steps/s (collection: 1.870s, learning 0.165s)
             Mean action noise std: 3.26
          Mean value_function loss: 15.7370
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.1560
                       Mean reward: 830.12
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 1.2289
    Episode_Reward/rotating_object: 163.3750
        Episode_Reward/action_rate: -0.0603
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.03s
                      Time elapsed: 00:40:51
                               ETA: 00:12:36

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 49192 steps/s (collection: 1.844s, learning 0.155s)
             Mean action noise std: 3.27
          Mean value_function loss: 31.1468
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 55.1652
                       Mean reward: 791.14
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 1.2177
    Episode_Reward/rotating_object: 161.3716
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.00s
                      Time elapsed: 00:40:53
                               ETA: 00:12:34

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 48183 steps/s (collection: 1.923s, learning 0.118s)
             Mean action noise std: 3.27
          Mean value_function loss: 21.7101
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 55.1790
                       Mean reward: 800.96
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 160.6710
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.04s
                      Time elapsed: 00:40:55
                               ETA: 00:12:32

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 49751 steps/s (collection: 1.841s, learning 0.135s)
             Mean action noise std: 3.27
          Mean value_function loss: 15.0265
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 55.1916
                       Mean reward: 840.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2367
    Episode_Reward/rotating_object: 163.3015
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.98s
                      Time elapsed: 00:40:57
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 46500 steps/s (collection: 1.987s, learning 0.127s)
             Mean action noise std: 3.27
          Mean value_function loss: 28.8386
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.1991
                       Mean reward: 819.18
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.2343
    Episode_Reward/rotating_object: 162.8375
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.11s
                      Time elapsed: 00:40:59
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 47210 steps/s (collection: 1.951s, learning 0.131s)
             Mean action noise std: 3.27
          Mean value_function loss: 38.6274
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 55.2066
                       Mean reward: 809.74
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.2144
    Episode_Reward/rotating_object: 160.5011
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.08s
                      Time elapsed: 00:41:02
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 48226 steps/s (collection: 1.915s, learning 0.124s)
             Mean action noise std: 3.27
          Mean value_function loss: 23.8555
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.2153
                       Mean reward: 810.68
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 1.2237
    Episode_Reward/rotating_object: 161.3200
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.04s
                      Time elapsed: 00:41:04
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 46832 steps/s (collection: 1.863s, learning 0.236s)
             Mean action noise std: 3.28
          Mean value_function loss: 21.5896
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.2300
                       Mean reward: 815.21
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 162.3979
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.10s
                      Time elapsed: 00:41:06
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 40008 steps/s (collection: 2.210s, learning 0.247s)
             Mean action noise std: 3.28
          Mean value_function loss: 17.6965
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.2384
                       Mean reward: 818.93
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 161.6074
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.46s
                      Time elapsed: 00:41:08
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 42770 steps/s (collection: 2.167s, learning 0.131s)
             Mean action noise std: 3.28
          Mean value_function loss: 34.8126
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.2487
                       Mean reward: 799.23
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 162.6018
        Episode_Reward/action_rate: -0.0606
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.30s
                      Time elapsed: 00:41:10
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 44244 steps/s (collection: 2.083s, learning 0.139s)
             Mean action noise std: 3.28
          Mean value_function loss: 25.4001
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 55.2591
                       Mean reward: 818.14
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 160.6427
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.22s
                      Time elapsed: 00:41:13
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 39816 steps/s (collection: 2.230s, learning 0.239s)
             Mean action noise std: 3.28
          Mean value_function loss: 21.8761
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 55.2694
                       Mean reward: 829.79
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 1.2374
    Episode_Reward/rotating_object: 163.6318
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.47s
                      Time elapsed: 00:41:15
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 45074 steps/s (collection: 1.974s, learning 0.207s)
             Mean action noise std: 3.29
          Mean value_function loss: 23.2478
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 55.2799
                       Mean reward: 814.27
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 161.2068
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.18s
                      Time elapsed: 00:41:17
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 50928 steps/s (collection: 1.798s, learning 0.132s)
             Mean action noise std: 3.29
          Mean value_function loss: 30.5190
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.2919
                       Mean reward: 798.00
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.2145
    Episode_Reward/rotating_object: 159.8379
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.93s
                      Time elapsed: 00:41:19
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 50670 steps/s (collection: 1.838s, learning 0.102s)
             Mean action noise std: 3.29
          Mean value_function loss: 23.5136
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.3069
                       Mean reward: 798.38
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.2020
    Episode_Reward/rotating_object: 159.9173
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.94s
                      Time elapsed: 00:41:21
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 48963 steps/s (collection: 1.846s, learning 0.162s)
             Mean action noise std: 3.29
          Mean value_function loss: 21.9263
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.3170
                       Mean reward: 818.12
               Mean episode length: 246.28
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 159.1259
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.01s
                      Time elapsed: 00:41:23
                               ETA: 00:12:04

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 42006 steps/s (collection: 2.152s, learning 0.188s)
             Mean action noise std: 3.29
          Mean value_function loss: 29.5472
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.3261
                       Mean reward: 820.08
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.1981
    Episode_Reward/rotating_object: 159.7647
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.34s
                      Time elapsed: 00:41:25
                               ETA: 00:12:02

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 40943 steps/s (collection: 2.230s, learning 0.171s)
             Mean action noise std: 3.30
          Mean value_function loss: 22.3334
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 55.3375
                       Mean reward: 813.91
               Mean episode length: 243.19
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 163.6803
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.40s
                      Time elapsed: 00:41:28
                               ETA: 00:12:00

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 43351 steps/s (collection: 2.084s, learning 0.184s)
             Mean action noise std: 3.30
          Mean value_function loss: 23.1244
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 55.3437
                       Mean reward: 824.65
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 1.2133
    Episode_Reward/rotating_object: 161.3251
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.27s
                      Time elapsed: 00:41:30
                               ETA: 00:11:58

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 38144 steps/s (collection: 2.428s, learning 0.149s)
             Mean action noise std: 3.30
          Mean value_function loss: 28.3590
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 55.3526
                       Mean reward: 798.09
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 161.9072
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.58s
                      Time elapsed: 00:41:33
                               ETA: 00:11:56

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 43130 steps/s (collection: 2.079s, learning 0.201s)
             Mean action noise std: 3.30
          Mean value_function loss: 19.1039
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 55.3665
                       Mean reward: 822.05
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 163.9468
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.28s
                      Time elapsed: 00:41:35
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 46020 steps/s (collection: 1.925s, learning 0.211s)
             Mean action noise std: 3.30
          Mean value_function loss: 26.6861
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.3797
                       Mean reward: 832.66
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 163.8139
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.14s
                      Time elapsed: 00:41:37
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 46002 steps/s (collection: 1.909s, learning 0.228s)
             Mean action noise std: 3.31
          Mean value_function loss: 23.3852
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 55.3880
                       Mean reward: 812.56
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 162.4923
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.14s
                      Time elapsed: 00:41:39
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 43652 steps/s (collection: 2.108s, learning 0.144s)
             Mean action noise std: 3.31
          Mean value_function loss: 22.8335
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 55.3944
                       Mean reward: 814.01
               Mean episode length: 244.02
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 159.5052
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.25s
                      Time elapsed: 00:41:42
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 43759 steps/s (collection: 2.092s, learning 0.155s)
             Mean action noise std: 3.31
          Mean value_function loss: 34.2779
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.4091
                       Mean reward: 810.49
               Mean episode length: 241.18
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 162.0213
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.25s
                      Time elapsed: 00:41:44
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 41862 steps/s (collection: 2.121s, learning 0.228s)
             Mean action noise std: 3.31
          Mean value_function loss: 27.8445
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 55.4260
                       Mean reward: 798.46
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 161.5144
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.35s
                      Time elapsed: 00:41:46
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 43170 steps/s (collection: 2.149s, learning 0.129s)
             Mean action noise std: 3.31
          Mean value_function loss: 23.1520
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.4337
                       Mean reward: 824.07
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 162.0574
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.28s
                      Time elapsed: 00:41:48
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 46505 steps/s (collection: 1.977s, learning 0.137s)
             Mean action noise std: 3.31
          Mean value_function loss: 35.1844
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.4460
                       Mean reward: 793.79
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.2072
    Episode_Reward/rotating_object: 159.2598
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.11s
                      Time elapsed: 00:41:51
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 46964 steps/s (collection: 1.979s, learning 0.114s)
             Mean action noise std: 3.32
          Mean value_function loss: 27.8733
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 55.4580
                       Mean reward: 834.61
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2331
    Episode_Reward/rotating_object: 163.4709
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.09s
                      Time elapsed: 00:41:53
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 46092 steps/s (collection: 2.034s, learning 0.099s)
             Mean action noise std: 3.32
          Mean value_function loss: 21.8315
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.4663
                       Mean reward: 826.41
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 1.2352
    Episode_Reward/rotating_object: 161.8644
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.13s
                      Time elapsed: 00:41:55
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 44628 steps/s (collection: 2.070s, learning 0.133s)
             Mean action noise std: 3.32
          Mean value_function loss: 28.9041
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 55.4815
                       Mean reward: 815.24
               Mean episode length: 243.22
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 162.5730
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.20s
                      Time elapsed: 00:41:57
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 50005 steps/s (collection: 1.851s, learning 0.115s)
             Mean action noise std: 3.32
          Mean value_function loss: 27.2249
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 55.4969
                       Mean reward: 791.75
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 156.8893
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.97s
                      Time elapsed: 00:41:59
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 42956 steps/s (collection: 1.964s, learning 0.325s)
             Mean action noise std: 3.33
          Mean value_function loss: 19.5038
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 55.5129
                       Mean reward: 829.82
               Mean episode length: 246.96
    Episode_Reward/reaching_object: 1.2387
    Episode_Reward/rotating_object: 163.6248
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.29s
                      Time elapsed: 00:42:01
                               ETA: 00:11:28

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 41504 steps/s (collection: 2.265s, learning 0.104s)
             Mean action noise std: 3.33
          Mean value_function loss: 31.9539
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 55.5310
                       Mean reward: 797.55
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.2222
    Episode_Reward/rotating_object: 160.1661
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.37s
                      Time elapsed: 00:42:04
                               ETA: 00:11:26

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 48191 steps/s (collection: 1.883s, learning 0.157s)
             Mean action noise std: 3.33
          Mean value_function loss: 35.2644
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.5458
                       Mean reward: 802.55
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 159.8318
        Episode_Reward/action_rate: -0.0617
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.04s
                      Time elapsed: 00:42:06
                               ETA: 00:11:24

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 52459 steps/s (collection: 1.778s, learning 0.096s)
             Mean action noise std: 3.33
          Mean value_function loss: 25.2418
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.5574
                       Mean reward: 802.78
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 160.4258
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.87s
                      Time elapsed: 00:42:07
                               ETA: 00:11:22

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 46991 steps/s (collection: 1.946s, learning 0.146s)
             Mean action noise std: 3.33
          Mean value_function loss: 24.5166
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 55.5694
                       Mean reward: 828.76
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 163.1061
        Episode_Reward/action_rate: -0.0631
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.09s
                      Time elapsed: 00:42:10
                               ETA: 00:11:20

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 47524 steps/s (collection: 1.953s, learning 0.115s)
             Mean action noise std: 3.33
          Mean value_function loss: 21.7063
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 55.5775
                       Mean reward: 830.16
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 161.8338
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.07s
                      Time elapsed: 00:42:12
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 49455 steps/s (collection: 1.896s, learning 0.092s)
             Mean action noise std: 3.34
          Mean value_function loss: 29.0153
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 55.5863
                       Mean reward: 790.90
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 1.2439
    Episode_Reward/rotating_object: 162.1596
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.99s
                      Time elapsed: 00:42:14
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 33621 steps/s (collection: 2.543s, learning 0.381s)
             Mean action noise std: 3.34
          Mean value_function loss: 28.1858
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 55.6046
                       Mean reward: 843.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2384
    Episode_Reward/rotating_object: 162.1051
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.92s
                      Time elapsed: 00:42:17
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 47575 steps/s (collection: 1.974s, learning 0.093s)
             Mean action noise std: 3.34
          Mean value_function loss: 27.0787
               Mean surrogate loss: 0.0049
                 Mean entropy loss: 55.6194
                       Mean reward: 805.54
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 1.2415
    Episode_Reward/rotating_object: 162.2630
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.07s
                      Time elapsed: 00:42:19
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 38632 steps/s (collection: 2.084s, learning 0.460s)
             Mean action noise std: 3.34
          Mean value_function loss: 29.4468
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 55.6207
                       Mean reward: 793.36
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 159.6899
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.54s
                      Time elapsed: 00:42:21
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 37241 steps/s (collection: 2.505s, learning 0.135s)
             Mean action noise std: 3.34
          Mean value_function loss: 20.3315
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.6274
                       Mean reward: 816.25
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 1.2486
    Episode_Reward/rotating_object: 164.4019
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.64s
                      Time elapsed: 00:42:24
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 43748 steps/s (collection: 2.114s, learning 0.133s)
             Mean action noise std: 3.35
          Mean value_function loss: 31.0387
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 55.6486
                       Mean reward: 815.10
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.2446
    Episode_Reward/rotating_object: 162.2123
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.25s
                      Time elapsed: 00:42:26
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 40357 steps/s (collection: 2.239s, learning 0.197s)
             Mean action noise std: 3.35
          Mean value_function loss: 28.1561
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 55.6755
                       Mean reward: 820.65
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.2429
    Episode_Reward/rotating_object: 162.7359
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.44s
                      Time elapsed: 00:42:28
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 40771 steps/s (collection: 2.239s, learning 0.172s)
             Mean action noise std: 3.35
          Mean value_function loss: 27.1850
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 55.6896
                       Mean reward: 808.60
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 157.5177
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.41s
                      Time elapsed: 00:42:31
                               ETA: 00:11:01

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 43338 steps/s (collection: 2.115s, learning 0.153s)
             Mean action noise std: 3.36
          Mean value_function loss: 25.9581
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.7026
                       Mean reward: 815.11
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 1.2429
    Episode_Reward/rotating_object: 161.6797
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.27s
                      Time elapsed: 00:42:33
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 37417 steps/s (collection: 2.344s, learning 0.284s)
             Mean action noise std: 3.36
          Mean value_function loss: 20.8446
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.7220
                       Mean reward: 813.55
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 161.6524
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.63s
                      Time elapsed: 00:42:36
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 37082 steps/s (collection: 2.367s, learning 0.284s)
             Mean action noise std: 3.36
          Mean value_function loss: 24.8621
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 55.7390
                       Mean reward: 802.50
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.2352
    Episode_Reward/rotating_object: 162.7582
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.65s
                      Time elapsed: 00:42:38
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 38387 steps/s (collection: 2.385s, learning 0.176s)
             Mean action noise std: 3.36
          Mean value_function loss: 29.5378
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.7531
                       Mean reward: 816.48
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 162.1720
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.56s
                      Time elapsed: 00:42:41
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 40695 steps/s (collection: 2.190s, learning 0.226s)
             Mean action noise std: 3.37
          Mean value_function loss: 37.4970
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.7677
                       Mean reward: 809.75
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 1.2367
    Episode_Reward/rotating_object: 161.4624
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.42s
                      Time elapsed: 00:42:43
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 38131 steps/s (collection: 2.435s, learning 0.143s)
             Mean action noise std: 3.37
          Mean value_function loss: 27.3941
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 55.7822
                       Mean reward: 821.05
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.2281
    Episode_Reward/rotating_object: 160.3672
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.58s
                      Time elapsed: 00:42:46
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 39989 steps/s (collection: 2.244s, learning 0.215s)
             Mean action noise std: 3.37
          Mean value_function loss: 27.0175
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 55.7898
                       Mean reward: 812.30
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 160.5448
        Episode_Reward/action_rate: -0.0635
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.46s
                      Time elapsed: 00:42:48
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 44903 steps/s (collection: 2.008s, learning 0.182s)
             Mean action noise std: 3.37
          Mean value_function loss: 29.2396
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 55.7994
                       Mean reward: 823.32
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.2543
    Episode_Reward/rotating_object: 164.1286
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.19s
                      Time elapsed: 00:42:51
                               ETA: 00:10:44

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 47814 steps/s (collection: 1.956s, learning 0.100s)
             Mean action noise std: 3.37
          Mean value_function loss: 28.7850
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 55.8149
                       Mean reward: 796.87
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 159.9816
        Episode_Reward/action_rate: -0.0636
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.06s
                      Time elapsed: 00:42:53
                               ETA: 00:10:42

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 48589 steps/s (collection: 1.918s, learning 0.106s)
             Mean action noise std: 3.37
          Mean value_function loss: 28.9482
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.8215
                       Mean reward: 827.52
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.2315
    Episode_Reward/rotating_object: 159.7493
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.02s
                      Time elapsed: 00:42:55
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 49330 steps/s (collection: 1.841s, learning 0.152s)
             Mean action noise std: 3.38
          Mean value_function loss: 25.7414
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 55.8266
                       Mean reward: 800.07
               Mean episode length: 238.99
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 162.1448
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.99s
                      Time elapsed: 00:42:57
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 45000 steps/s (collection: 2.020s, learning 0.165s)
             Mean action noise std: 3.38
          Mean value_function loss: 34.8191
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 55.8360
                       Mean reward: 813.56
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 161.8419
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.18s
                      Time elapsed: 00:42:59
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 40412 steps/s (collection: 2.235s, learning 0.197s)
             Mean action noise std: 3.38
          Mean value_function loss: 28.5214
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 55.8564
                       Mean reward: 801.20
               Mean episode length: 239.12
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 162.1404
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.43s
                      Time elapsed: 00:43:01
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 43033 steps/s (collection: 2.109s, learning 0.176s)
             Mean action noise std: 3.38
          Mean value_function loss: 26.6148
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 55.8693
                       Mean reward: 827.84
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 1.2425
    Episode_Reward/rotating_object: 159.8212
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.28s
                      Time elapsed: 00:43:04
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 43564 steps/s (collection: 2.067s, learning 0.189s)
             Mean action noise std: 3.39
          Mean value_function loss: 30.7354
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 55.8842
                       Mean reward: 836.34
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 1.2424
    Episode_Reward/rotating_object: 161.9239
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.26s
                      Time elapsed: 00:43:06
                               ETA: 00:10:29

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 44549 steps/s (collection: 2.071s, learning 0.136s)
             Mean action noise std: 3.39
          Mean value_function loss: 30.3884
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 55.9029
                       Mean reward: 814.29
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 1.2395
    Episode_Reward/rotating_object: 161.4477
        Episode_Reward/action_rate: -0.0639
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.21s
                      Time elapsed: 00:43:08
                               ETA: 00:10:27

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 43060 steps/s (collection: 2.041s, learning 0.242s)
             Mean action noise std: 3.39
          Mean value_function loss: 25.0683
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 55.9167
                       Mean reward: 825.68
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 1.2545
    Episode_Reward/rotating_object: 163.6931
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.28s
                      Time elapsed: 00:43:10
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 42405 steps/s (collection: 2.063s, learning 0.256s)
             Mean action noise std: 3.39
          Mean value_function loss: 17.9723
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 55.9226
                       Mean reward: 830.06
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 160.2444
        Episode_Reward/action_rate: -0.0640
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.32s
                      Time elapsed: 00:43:13
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 44147 steps/s (collection: 2.096s, learning 0.131s)
             Mean action noise std: 3.39
          Mean value_function loss: 23.1044
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.9275
                       Mean reward: 822.15
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 162.7405
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.23s
                      Time elapsed: 00:43:15
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 45339 steps/s (collection: 1.944s, learning 0.224s)
             Mean action noise std: 3.39
          Mean value_function loss: 22.5770
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 55.9336
                       Mean reward: 796.16
               Mean episode length: 241.20
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 161.6029
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.17s
                      Time elapsed: 00:43:17
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 49072 steps/s (collection: 1.901s, learning 0.103s)
             Mean action noise std: 3.40
          Mean value_function loss: 25.1229
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.9417
                       Mean reward: 827.08
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 1.2455
    Episode_Reward/rotating_object: 162.0262
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.00s
                      Time elapsed: 00:43:19
                               ETA: 00:10:17

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 43959 steps/s (collection: 2.123s, learning 0.113s)
             Mean action noise std: 3.40
          Mean value_function loss: 21.6437
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 55.9485
                       Mean reward: 819.02
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 161.1386
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.24s
                      Time elapsed: 00:43:21
                               ETA: 00:10:15

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 42549 steps/s (collection: 2.212s, learning 0.099s)
             Mean action noise std: 3.40
          Mean value_function loss: 28.7447
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.9541
                       Mean reward: 826.05
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 162.6390
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.31s
                      Time elapsed: 00:43:24
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 41131 steps/s (collection: 2.215s, learning 0.175s)
             Mean action noise std: 3.40
          Mean value_function loss: 31.4714
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.9707
                       Mean reward: 805.53
               Mean episode length: 239.38
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 161.9969
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.39s
                      Time elapsed: 00:43:26
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 40783 steps/s (collection: 2.179s, learning 0.232s)
             Mean action noise std: 3.40
          Mean value_function loss: 32.3966
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 55.9885
                       Mean reward: 817.48
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 1.2331
    Episode_Reward/rotating_object: 161.8498
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.41s
                      Time elapsed: 00:43:28
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 39212 steps/s (collection: 2.288s, learning 0.219s)
             Mean action noise std: 3.41
          Mean value_function loss: 26.7648
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 56.0037
                       Mean reward: 828.93
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 164.5995
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.51s
                      Time elapsed: 00:43:31
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 41831 steps/s (collection: 2.106s, learning 0.244s)
             Mean action noise std: 3.41
          Mean value_function loss: 23.2477
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 56.0146
                       Mean reward: 795.72
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 160.5715
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.35s
                      Time elapsed: 00:43:33
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 41417 steps/s (collection: 2.239s, learning 0.135s)
             Mean action noise std: 3.41
          Mean value_function loss: 29.9483
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 56.0196
                       Mean reward: 815.70
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.2193
    Episode_Reward/rotating_object: 159.4774
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.37s
                      Time elapsed: 00:43:36
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 43975 steps/s (collection: 2.012s, learning 0.224s)
             Mean action noise std: 3.41
          Mean value_function loss: 22.3933
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.0228
                       Mean reward: 810.73
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 162.6023
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.24s
                      Time elapsed: 00:43:38
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 38484 steps/s (collection: 2.346s, learning 0.209s)
             Mean action noise std: 3.41
          Mean value_function loss: 30.6455
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 56.0266
                       Mean reward: 800.79
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 1.2448
    Episode_Reward/rotating_object: 161.6129
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.55s
                      Time elapsed: 00:43:40
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 39260 steps/s (collection: 2.336s, learning 0.168s)
             Mean action noise std: 3.41
          Mean value_function loss: 17.9530
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.0314
                       Mean reward: 839.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2538
    Episode_Reward/rotating_object: 164.7169
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.50s
                      Time elapsed: 00:43:43
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 40939 steps/s (collection: 2.246s, learning 0.155s)
             Mean action noise std: 3.41
          Mean value_function loss: 31.0618
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.0408
                       Mean reward: 835.63
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 159.7944
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.40s
                      Time elapsed: 00:43:45
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 42430 steps/s (collection: 2.188s, learning 0.129s)
             Mean action noise std: 3.42
          Mean value_function loss: 16.7967
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 56.0570
                       Mean reward: 830.70
               Mean episode length: 247.14
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 163.3760
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.32s
                      Time elapsed: 00:43:48
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 39920 steps/s (collection: 2.265s, learning 0.197s)
             Mean action noise std: 3.42
          Mean value_function loss: 19.1470
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 56.0700
                       Mean reward: 795.57
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 161.7449
        Episode_Reward/action_rate: -0.0660
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.46s
                      Time elapsed: 00:43:50
                               ETA: 00:09:50

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 38274 steps/s (collection: 2.383s, learning 0.185s)
             Mean action noise std: 3.42
          Mean value_function loss: 19.5425
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 56.0754
                       Mean reward: 840.24
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 1.2425
    Episode_Reward/rotating_object: 164.6317
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.57s
                      Time elapsed: 00:43:53
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 37556 steps/s (collection: 2.371s, learning 0.246s)
             Mean action noise std: 3.42
          Mean value_function loss: 24.5470
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.0864
                       Mean reward: 821.36
               Mean episode length: 244.48
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 164.3540
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.62s
                      Time elapsed: 00:43:55
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 42863 steps/s (collection: 2.103s, learning 0.191s)
             Mean action noise std: 3.42
          Mean value_function loss: 21.9490
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 56.0977
                       Mean reward: 845.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 163.3361
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.29s
                      Time elapsed: 00:43:58
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 38871 steps/s (collection: 2.231s, learning 0.298s)
             Mean action noise std: 3.42
          Mean value_function loss: 24.6544
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.1071
                       Mean reward: 815.19
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 160.9677
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.53s
                      Time elapsed: 00:44:00
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 37200 steps/s (collection: 2.453s, learning 0.190s)
             Mean action noise std: 3.43
          Mean value_function loss: 28.0220
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.1169
                       Mean reward: 808.99
               Mean episode length: 241.51
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 162.5024
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.64s
                      Time elapsed: 00:44:03
                               ETA: 00:09:39

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 39949 steps/s (collection: 2.215s, learning 0.246s)
             Mean action noise std: 3.43
          Mean value_function loss: 33.7640
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.1300
                       Mean reward: 783.69
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.2299
    Episode_Reward/rotating_object: 159.9572
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.46s
                      Time elapsed: 00:44:05
                               ETA: 00:09:37

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 39728 steps/s (collection: 2.306s, learning 0.168s)
             Mean action noise std: 3.43
          Mean value_function loss: 31.6315
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.1469
                       Mean reward: 804.76
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 159.8007
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.47s
                      Time elapsed: 00:44:08
                               ETA: 00:09:35

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 41466 steps/s (collection: 2.187s, learning 0.184s)
             Mean action noise std: 3.43
          Mean value_function loss: 24.4888
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 56.1644
                       Mean reward: 823.07
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 164.2157
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.37s
                      Time elapsed: 00:44:10
                               ETA: 00:09:33

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 38857 steps/s (collection: 2.266s, learning 0.264s)
             Mean action noise std: 3.43
          Mean value_function loss: 22.6882
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 56.1705
                       Mean reward: 806.31
               Mean episode length: 242.52
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 160.3126
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.53s
                      Time elapsed: 00:44:13
                               ETA: 00:09:31

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 39010 steps/s (collection: 2.332s, learning 0.188s)
             Mean action noise std: 3.43
          Mean value_function loss: 27.5084
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 56.1774
                       Mean reward: 811.53
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 159.9735
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.52s
                      Time elapsed: 00:44:15
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 39746 steps/s (collection: 2.203s, learning 0.270s)
             Mean action noise std: 3.44
          Mean value_function loss: 19.0302
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.1824
                       Mean reward: 823.71
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 164.6160
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.47s
                      Time elapsed: 00:44:18
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 42707 steps/s (collection: 2.078s, learning 0.224s)
             Mean action noise std: 3.44
          Mean value_function loss: 30.8974
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 56.1926
                       Mean reward: 814.83
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 1.2392
    Episode_Reward/rotating_object: 162.8275
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.30s
                      Time elapsed: 00:44:20
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 44082 steps/s (collection: 2.112s, learning 0.118s)
             Mean action noise std: 3.44
          Mean value_function loss: 28.5022
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 56.2073
                       Mean reward: 804.94
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.2312
    Episode_Reward/rotating_object: 161.5525
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.23s
                      Time elapsed: 00:44:22
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 41753 steps/s (collection: 2.109s, learning 0.245s)
             Mean action noise std: 3.44
          Mean value_function loss: 20.9294
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 56.2134
                       Mean reward: 817.10
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 1.2451
    Episode_Reward/rotating_object: 164.4731
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.35s
                      Time elapsed: 00:44:25
                               ETA: 00:09:20

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 42183 steps/s (collection: 2.181s, learning 0.149s)
             Mean action noise std: 3.44
          Mean value_function loss: 30.8380
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 56.2181
                       Mean reward: 812.04
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 157.9129
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.33s
                      Time elapsed: 00:44:27
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 45810 steps/s (collection: 1.962s, learning 0.184s)
             Mean action noise std: 3.44
          Mean value_function loss: 29.3503
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 56.2217
                       Mean reward: 803.89
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 160.2600
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.15s
                      Time elapsed: 00:44:29
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 41002 steps/s (collection: 2.211s, learning 0.186s)
             Mean action noise std: 3.44
          Mean value_function loss: 20.7479
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 56.2237
                       Mean reward: 804.70
               Mean episode length: 239.07
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 162.7929
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.40s
                      Time elapsed: 00:44:31
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 37506 steps/s (collection: 2.376s, learning 0.245s)
             Mean action noise std: 3.44
          Mean value_function loss: 18.5708
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 56.2267
                       Mean reward: 843.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2595
    Episode_Reward/rotating_object: 166.0705
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.62s
                      Time elapsed: 00:44:34
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 33124 steps/s (collection: 2.755s, learning 0.212s)
             Mean action noise std: 3.45
          Mean value_function loss: 21.2041
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 56.2351
                       Mean reward: 836.01
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 162.1478
        Episode_Reward/action_rate: -0.0666
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.97s
                      Time elapsed: 00:44:37
                               ETA: 00:09:10

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 32710 steps/s (collection: 2.796s, learning 0.210s)
             Mean action noise std: 3.45
          Mean value_function loss: 21.8447
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.2523
                       Mean reward: 842.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 161.6068
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 3.01s
                      Time elapsed: 00:44:40
                               ETA: 00:09:08

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 38617 steps/s (collection: 2.387s, learning 0.159s)
             Mean action noise std: 3.45
          Mean value_function loss: 21.0297
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.2633
                       Mean reward: 816.15
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 1.2534
    Episode_Reward/rotating_object: 164.4791
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.55s
                      Time elapsed: 00:44:43
                               ETA: 00:09:06

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 44116 steps/s (collection: 2.131s, learning 0.098s)
             Mean action noise std: 3.45
          Mean value_function loss: 27.2795
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.2743
                       Mean reward: 773.59
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.2330
    Episode_Reward/rotating_object: 160.8627
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.23s
                      Time elapsed: 00:44:45
                               ETA: 00:09:04

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 47365 steps/s (collection: 1.971s, learning 0.104s)
             Mean action noise std: 3.45
          Mean value_function loss: 27.8557
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.2848
                       Mean reward: 813.68
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 164.7660
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.08s
                      Time elapsed: 00:44:47
                               ETA: 00:09:02

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 45816 steps/s (collection: 1.971s, learning 0.175s)
             Mean action noise std: 3.45
          Mean value_function loss: 25.5021
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.2945
                       Mean reward: 802.40
               Mean episode length: 242.19
    Episode_Reward/reaching_object: 1.2355
    Episode_Reward/rotating_object: 160.1150
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.15s
                      Time elapsed: 00:44:49
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 34411 steps/s (collection: 2.555s, learning 0.302s)
             Mean action noise std: 3.46
          Mean value_function loss: 24.7669
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.3060
                       Mean reward: 807.28
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.2517
    Episode_Reward/rotating_object: 162.7750
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.86s
                      Time elapsed: 00:44:52
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 37863 steps/s (collection: 2.410s, learning 0.186s)
             Mean action noise std: 3.46
          Mean value_function loss: 27.5298
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.3203
                       Mean reward: 826.66
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 1.2223
    Episode_Reward/rotating_object: 161.0457
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.60s
                      Time elapsed: 00:44:54
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 35478 steps/s (collection: 2.537s, learning 0.234s)
             Mean action noise std: 3.46
          Mean value_function loss: 22.7818
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.3339
                       Mean reward: 820.74
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 161.2133
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.77s
                      Time elapsed: 00:44:57
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 38107 steps/s (collection: 2.290s, learning 0.290s)
             Mean action noise std: 3.46
          Mean value_function loss: 37.9914
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 56.3451
                       Mean reward: 803.53
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 162.3886
        Episode_Reward/action_rate: -0.0668
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.58s
                      Time elapsed: 00:45:00
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 36952 steps/s (collection: 2.441s, learning 0.220s)
             Mean action noise std: 3.46
          Mean value_function loss: 21.1315
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 56.3486
                       Mean reward: 816.20
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.2551
    Episode_Reward/rotating_object: 164.1573
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.66s
                      Time elapsed: 00:45:02
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 42608 steps/s (collection: 2.092s, learning 0.215s)
             Mean action noise std: 3.46
          Mean value_function loss: 24.6201
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.3510
                       Mean reward: 796.89
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2343
    Episode_Reward/rotating_object: 162.6211
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.31s
                      Time elapsed: 00:45:05
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 44729 steps/s (collection: 2.061s, learning 0.137s)
             Mean action noise std: 3.47
          Mean value_function loss: 30.1901
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 56.3554
                       Mean reward: 820.08
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 161.9556
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.20s
                      Time elapsed: 00:45:07
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 38786 steps/s (collection: 2.320s, learning 0.215s)
             Mean action noise std: 3.47
          Mean value_function loss: 32.7909
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.3630
                       Mean reward: 820.43
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 1.2357
    Episode_Reward/rotating_object: 162.8275
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.53s
                      Time elapsed: 00:45:09
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 37250 steps/s (collection: 2.442s, learning 0.197s)
             Mean action noise std: 3.47
          Mean value_function loss: 27.1603
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.3811
                       Mean reward: 817.45
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 163.6252
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.64s
                      Time elapsed: 00:45:12
                               ETA: 00:08:41

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 39463 steps/s (collection: 2.322s, learning 0.169s)
             Mean action noise std: 3.47
          Mean value_function loss: 25.2908
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 56.3984
                       Mean reward: 835.13
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.2230
    Episode_Reward/rotating_object: 164.3750
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.49s
                      Time elapsed: 00:45:15
                               ETA: 00:08:39

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 43835 steps/s (collection: 2.012s, learning 0.231s)
             Mean action noise std: 3.47
          Mean value_function loss: 26.3371
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 56.4073
                       Mean reward: 823.20
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 162.6932
        Episode_Reward/action_rate: -0.0677
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.24s
                      Time elapsed: 00:45:17
                               ETA: 00:08:37

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 43795 steps/s (collection: 2.085s, learning 0.160s)
             Mean action noise std: 3.48
          Mean value_function loss: 23.5930
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 56.4180
                       Mean reward: 834.50
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 1.2117
    Episode_Reward/rotating_object: 164.5283
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.24s
                      Time elapsed: 00:45:19
                               ETA: 00:08:35

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 39263 steps/s (collection: 2.287s, learning 0.217s)
             Mean action noise std: 3.48
          Mean value_function loss: 29.1714
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 56.4313
                       Mean reward: 804.41
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 162.2212
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.50s
                      Time elapsed: 00:45:22
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 40027 steps/s (collection: 2.329s, learning 0.127s)
             Mean action noise std: 3.48
          Mean value_function loss: 29.2208
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.4437
                       Mean reward: 822.56
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 162.1858
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.46s
                      Time elapsed: 00:45:24
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 43376 steps/s (collection: 2.135s, learning 0.132s)
             Mean action noise std: 3.48
          Mean value_function loss: 26.4809
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 56.4574
                       Mean reward: 810.78
               Mean episode length: 243.65
    Episode_Reward/reaching_object: 1.1750
    Episode_Reward/rotating_object: 159.2681
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.27s
                      Time elapsed: 00:45:26
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 45247 steps/s (collection: 1.992s, learning 0.181s)
             Mean action noise std: 3.48
          Mean value_function loss: 32.3773
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 56.4674
                       Mean reward: 799.50
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 1.1829
    Episode_Reward/rotating_object: 161.0401
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.17s
                      Time elapsed: 00:45:28
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 45689 steps/s (collection: 1.951s, learning 0.201s)
             Mean action noise std: 3.48
          Mean value_function loss: 21.3874
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 56.4773
                       Mean reward: 828.82
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 1.2068
    Episode_Reward/rotating_object: 162.5091
        Episode_Reward/action_rate: -0.0683
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.15s
                      Time elapsed: 00:45:31
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 44877 steps/s (collection: 2.020s, learning 0.171s)
             Mean action noise std: 3.49
          Mean value_function loss: 20.5446
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 56.4843
                       Mean reward: 796.62
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 162.0423
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.19s
                      Time elapsed: 00:45:33
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 45540 steps/s (collection: 2.014s, learning 0.145s)
             Mean action noise std: 3.49
          Mean value_function loss: 26.7816
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.4957
                       Mean reward: 825.53
               Mean episode length: 246.63
    Episode_Reward/reaching_object: 1.2103
    Episode_Reward/rotating_object: 163.5570
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.16s
                      Time elapsed: 00:45:35
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 45262 steps/s (collection: 2.065s, learning 0.107s)
             Mean action noise std: 3.49
          Mean value_function loss: 22.8132
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.5153
                       Mean reward: 798.12
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 1.2022
    Episode_Reward/rotating_object: 162.3145
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.17s
                      Time elapsed: 00:45:37
                               ETA: 00:08:17

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 49375 steps/s (collection: 1.858s, learning 0.133s)
             Mean action noise std: 3.49
          Mean value_function loss: 25.5368
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 56.5354
                       Mean reward: 808.43
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.2012
    Episode_Reward/rotating_object: 161.0601
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.99s
                      Time elapsed: 00:45:39
                               ETA: 00:08:15

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 50047 steps/s (collection: 1.861s, learning 0.103s)
             Mean action noise std: 3.50
          Mean value_function loss: 21.4311
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.5467
                       Mean reward: 819.22
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 163.8275
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 1.96s
                      Time elapsed: 00:45:41
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 49837 steps/s (collection: 1.866s, learning 0.107s)
             Mean action noise std: 3.50
          Mean value_function loss: 24.3590
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.5542
                       Mean reward: 817.29
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 162.3682
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 1.97s
                      Time elapsed: 00:45:43
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 49495 steps/s (collection: 1.873s, learning 0.114s)
             Mean action noise std: 3.50
          Mean value_function loss: 23.2072
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 56.5636
                       Mean reward: 813.56
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 1.2165
    Episode_Reward/rotating_object: 162.7115
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 1.99s
                      Time elapsed: 00:45:45
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 51920 steps/s (collection: 1.794s, learning 0.100s)
             Mean action noise std: 3.50
          Mean value_function loss: 20.5237
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 56.5785
                       Mean reward: 813.10
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 162.4212
        Episode_Reward/action_rate: -0.0685
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.89s
                      Time elapsed: 00:45:47
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 49911 steps/s (collection: 1.785s, learning 0.185s)
             Mean action noise std: 3.50
          Mean value_function loss: 19.9646
               Mean surrogate loss: 0.0061
                 Mean entropy loss: 56.5902
                       Mean reward: 827.78
               Mean episode length: 248.44
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 164.3976
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.97s
                      Time elapsed: 00:45:49
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 49651 steps/s (collection: 1.857s, learning 0.123s)
             Mean action noise std: 3.50
          Mean value_function loss: 18.9392
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.5931
                       Mean reward: 809.04
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.2342
    Episode_Reward/rotating_object: 162.6015
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 1.98s
                      Time elapsed: 00:45:51
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 50868 steps/s (collection: 1.803s, learning 0.130s)
             Mean action noise std: 3.51
          Mean value_function loss: 21.5448
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 56.6049
                       Mean reward: 827.53
               Mean episode length: 248.48
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 164.9577
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 1.93s
                      Time elapsed: 00:45:53
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 52863 steps/s (collection: 1.765s, learning 0.095s)
             Mean action noise std: 3.51
          Mean value_function loss: 24.3784
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 56.6220
                       Mean reward: 811.88
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.2229
    Episode_Reward/rotating_object: 162.8788
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 1.86s
                      Time elapsed: 00:45:55
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 49284 steps/s (collection: 1.868s, learning 0.127s)
             Mean action noise std: 3.51
          Mean value_function loss: 31.8185
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 56.6372
                       Mean reward: 822.69
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.2173
    Episode_Reward/rotating_object: 162.2450
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 1.99s
                      Time elapsed: 00:45:57
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 51116 steps/s (collection: 1.790s, learning 0.134s)
             Mean action noise std: 3.51
          Mean value_function loss: 28.6679
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 56.6430
                       Mean reward: 830.25
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 1.2204
    Episode_Reward/rotating_object: 161.6585
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 1.92s
                      Time elapsed: 00:45:59
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 49942 steps/s (collection: 1.818s, learning 0.150s)
             Mean action noise std: 3.51
          Mean value_function loss: 27.0769
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 56.6563
                       Mean reward: 816.96
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 162.6551
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 1.97s
                      Time elapsed: 00:46:01
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 52071 steps/s (collection: 1.783s, learning 0.105s)
             Mean action noise std: 3.52
          Mean value_function loss: 26.2997
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.6765
                       Mean reward: 819.31
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.2194
    Episode_Reward/rotating_object: 162.3707
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 1.89s
                      Time elapsed: 00:46:02
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 48424 steps/s (collection: 1.912s, learning 0.118s)
             Mean action noise std: 3.52
          Mean value_function loss: 24.7278
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.6996
                       Mean reward: 834.00
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 165.3974
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.03s
                      Time elapsed: 00:46:05
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 48921 steps/s (collection: 1.916s, learning 0.093s)
             Mean action noise std: 3.52
          Mean value_function loss: 29.3842
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 56.7148
                       Mean reward: 826.83
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 162.3927
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.01s
                      Time elapsed: 00:46:07
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 50932 steps/s (collection: 1.810s, learning 0.120s)
             Mean action noise std: 3.53
          Mean value_function loss: 27.4961
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 56.7242
                       Mean reward: 820.13
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 1.2170
    Episode_Reward/rotating_object: 162.2824
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 1.93s
                      Time elapsed: 00:46:08
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 48171 steps/s (collection: 1.944s, learning 0.097s)
             Mean action noise std: 3.53
          Mean value_function loss: 30.0622
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 56.7302
                       Mean reward: 796.35
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.2106
    Episode_Reward/rotating_object: 161.1214
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.04s
                      Time elapsed: 00:46:10
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 51008 steps/s (collection: 1.820s, learning 0.107s)
             Mean action noise std: 3.53
          Mean value_function loss: 30.0000
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 56.7386
                       Mean reward: 830.09
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 163.8709
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 1.93s
                      Time elapsed: 00:46:12
                               ETA: 00:07:38

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 52332 steps/s (collection: 1.766s, learning 0.113s)
             Mean action noise std: 3.53
          Mean value_function loss: 16.9754
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 56.7524
                       Mean reward: 824.31
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 1.2171
    Episode_Reward/rotating_object: 163.3138
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 1.88s
                      Time elapsed: 00:46:14
                               ETA: 00:07:36

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 53454 steps/s (collection: 1.732s, learning 0.107s)
             Mean action noise std: 3.53
          Mean value_function loss: 23.3858
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.7654
                       Mean reward: 828.20
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 164.1865
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.84s
                      Time elapsed: 00:46:16
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 53531 steps/s (collection: 1.706s, learning 0.131s)
             Mean action noise std: 3.54
          Mean value_function loss: 28.0826
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 56.7888
                       Mean reward: 818.19
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 162.8581
        Episode_Reward/action_rate: -0.0701
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 1.84s
                      Time elapsed: 00:46:18
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 52115 steps/s (collection: 1.754s, learning 0.133s)
             Mean action noise std: 3.54
          Mean value_function loss: 16.7824
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 56.8074
                       Mean reward: 814.05
               Mean episode length: 243.78
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 161.7152
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 1.89s
                      Time elapsed: 00:46:20
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 50706 steps/s (collection: 1.774s, learning 0.165s)
             Mean action noise std: 3.54
          Mean value_function loss: 30.0184
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 56.8202
                       Mean reward: 835.08
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 161.8688
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 1.94s
                      Time elapsed: 00:46:22
                               ETA: 00:07:27

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 50507 steps/s (collection: 1.778s, learning 0.169s)
             Mean action noise std: 3.54
          Mean value_function loss: 20.8458
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 56.8348
                       Mean reward: 826.30
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 162.6540
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.95s
                      Time elapsed: 00:46:24
                               ETA: 00:07:25

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 47781 steps/s (collection: 1.903s, learning 0.154s)
             Mean action noise std: 3.55
          Mean value_function loss: 32.1245
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 56.8488
                       Mean reward: 810.64
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.2029
    Episode_Reward/rotating_object: 160.7985
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.06s
                      Time elapsed: 00:46:26
                               ETA: 00:07:23

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 48278 steps/s (collection: 1.900s, learning 0.136s)
             Mean action noise std: 3.55
          Mean value_function loss: 23.5488
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 56.8609
                       Mean reward: 835.62
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 163.4932
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.04s
                      Time elapsed: 00:46:28
                               ETA: 00:07:21

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 48371 steps/s (collection: 1.914s, learning 0.118s)
             Mean action noise std: 3.55
          Mean value_function loss: 31.4328
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.8744
                       Mean reward: 776.85
               Mean episode length: 235.00
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 159.7410
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.03s
                      Time elapsed: 00:46:30
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 52451 steps/s (collection: 1.712s, learning 0.163s)
             Mean action noise std: 3.55
          Mean value_function loss: 25.9587
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 56.8899
                       Mean reward: 818.30
               Mean episode length: 245.38
    Episode_Reward/reaching_object: 1.2251
    Episode_Reward/rotating_object: 163.7363
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.87s
                      Time elapsed: 00:46:32
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 47203 steps/s (collection: 1.940s, learning 0.142s)
             Mean action noise std: 3.56
          Mean value_function loss: 21.6069
               Mean surrogate loss: 0.0073
                 Mean entropy loss: 56.9096
                       Mean reward: 835.44
               Mean episode length: 248.74
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 164.6564
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.08s
                      Time elapsed: 00:46:34
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 53094 steps/s (collection: 1.725s, learning 0.126s)
             Mean action noise std: 3.56
          Mean value_function loss: 20.4358
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 56.9153
                       Mean reward: 828.30
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 164.2463
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.85s
                      Time elapsed: 00:46:36
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 53034 steps/s (collection: 1.757s, learning 0.097s)
             Mean action noise std: 3.56
          Mean value_function loss: 30.8827
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 56.9178
                       Mean reward: 777.98
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 1.1797
    Episode_Reward/rotating_object: 159.2032
        Episode_Reward/action_rate: -0.0695
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 1.85s
                      Time elapsed: 00:46:38
                               ETA: 00:07:10

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 48758 steps/s (collection: 1.911s, learning 0.106s)
             Mean action noise std: 3.56
          Mean value_function loss: 30.7282
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.9260
                       Mean reward: 814.54
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 1.2004
    Episode_Reward/rotating_object: 162.9798
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.02s
                      Time elapsed: 00:46:40
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 49535 steps/s (collection: 1.879s, learning 0.106s)
             Mean action noise std: 3.56
          Mean value_function loss: 30.6439
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 56.9407
                       Mean reward: 807.35
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.1908
    Episode_Reward/rotating_object: 160.7645
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.98s
                      Time elapsed: 00:46:42
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 51461 steps/s (collection: 1.799s, learning 0.112s)
             Mean action noise std: 3.57
          Mean value_function loss: 27.5972
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 56.9650
                       Mean reward: 799.34
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.1979
    Episode_Reward/rotating_object: 162.7895
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 1.91s
                      Time elapsed: 00:46:43
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 51545 steps/s (collection: 1.811s, learning 0.096s)
             Mean action noise std: 3.57
          Mean value_function loss: 27.0725
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 56.9906
                       Mean reward: 817.25
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 160.8024
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 1.91s
                      Time elapsed: 00:46:45
                               ETA: 00:07:01

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 47408 steps/s (collection: 1.979s, learning 0.095s)
             Mean action noise std: 3.57
          Mean value_function loss: 21.0371
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.0043
                       Mean reward: 803.55
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 162.2898
        Episode_Reward/action_rate: -0.0709
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.07s
                      Time elapsed: 00:46:47
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 46136 steps/s (collection: 2.035s, learning 0.096s)
             Mean action noise std: 3.58
          Mean value_function loss: 23.1592
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.0158
                       Mean reward: 819.35
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 163.0993
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.13s
                      Time elapsed: 00:46:50
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 49221 steps/s (collection: 1.898s, learning 0.100s)
             Mean action noise std: 3.58
          Mean value_function loss: 25.5372
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 57.0295
                       Mean reward: 782.40
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 162.7257
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.00s
                      Time elapsed: 00:46:52
                               ETA: 00:06:54

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 50010 steps/s (collection: 1.876s, learning 0.090s)
             Mean action noise std: 3.58
          Mean value_function loss: 18.6174
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.0408
                       Mean reward: 829.29
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.2007
    Episode_Reward/rotating_object: 161.4616
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.97s
                      Time elapsed: 00:46:54
                               ETA: 00:06:52

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 52313 steps/s (collection: 1.787s, learning 0.092s)
             Mean action noise std: 3.58
          Mean value_function loss: 18.9299
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 57.0539
                       Mean reward: 818.30
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.2204
    Episode_Reward/rotating_object: 163.7019
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 1.88s
                      Time elapsed: 00:46:55
                               ETA: 00:06:50

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 51857 steps/s (collection: 1.797s, learning 0.099s)
             Mean action noise std: 3.58
          Mean value_function loss: 26.6497
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.0624
                       Mean reward: 826.46
               Mean episode length: 246.47
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 160.6561
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.90s
                      Time elapsed: 00:46:57
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 48976 steps/s (collection: 1.911s, learning 0.096s)
             Mean action noise std: 3.58
          Mean value_function loss: 23.9001
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 57.0772
                       Mean reward: 844.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2195
    Episode_Reward/rotating_object: 162.6940
        Episode_Reward/action_rate: -0.0715
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.01s
                      Time elapsed: 00:46:59
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 51736 steps/s (collection: 1.778s, learning 0.123s)
             Mean action noise std: 3.59
          Mean value_function loss: 30.5135
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.0955
                       Mean reward: 821.11
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.1987
    Episode_Reward/rotating_object: 160.1216
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 1.90s
                      Time elapsed: 00:47:01
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 50892 steps/s (collection: 1.795s, learning 0.137s)
             Mean action noise std: 3.59
          Mean value_function loss: 34.0755
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.1145
                       Mean reward: 788.27
               Mean episode length: 239.09
    Episode_Reward/reaching_object: 1.2056
    Episode_Reward/rotating_object: 161.2450
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.93s
                      Time elapsed: 00:47:03
                               ETA: 00:06:41

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 52201 steps/s (collection: 1.788s, learning 0.095s)
             Mean action noise std: 3.59
          Mean value_function loss: 29.3403
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.1358
                       Mean reward: 806.54
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 160.5397
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.88s
                      Time elapsed: 00:47:05
                               ETA: 00:06:39

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 52220 steps/s (collection: 1.772s, learning 0.110s)
             Mean action noise std: 3.60
          Mean value_function loss: 31.7182
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 57.1517
                       Mean reward: 819.61
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 1.2190
    Episode_Reward/rotating_object: 163.2553
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 1.88s
                      Time elapsed: 00:47:07
                               ETA: 00:06:37

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 52534 steps/s (collection: 1.776s, learning 0.096s)
             Mean action noise std: 3.60
          Mean value_function loss: 23.3922
               Mean surrogate loss: 0.0064
                 Mean entropy loss: 57.1596
                       Mean reward: 826.97
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 1.2129
    Episode_Reward/rotating_object: 160.9791
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 1.87s
                      Time elapsed: 00:47:09
                               ETA: 00:06:35

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 54237 steps/s (collection: 1.711s, learning 0.102s)
             Mean action noise std: 3.60
          Mean value_function loss: 33.1638
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 57.1624
                       Mean reward: 794.42
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 159.6784
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.81s
                      Time elapsed: 00:47:11
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 52694 steps/s (collection: 1.751s, learning 0.115s)
             Mean action noise std: 3.60
          Mean value_function loss: 23.5251
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 57.1681
                       Mean reward: 799.72
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 161.9521
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.87s
                      Time elapsed: 00:47:12
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 47886 steps/s (collection: 1.920s, learning 0.133s)
             Mean action noise std: 3.60
          Mean value_function loss: 25.1094
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 57.1796
                       Mean reward: 812.21
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 1.2126
    Episode_Reward/rotating_object: 162.6224
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.05s
                      Time elapsed: 00:47:15
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 53437 steps/s (collection: 1.711s, learning 0.129s)
             Mean action noise std: 3.60
          Mean value_function loss: 23.7666
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.1905
                       Mean reward: 827.77
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 163.6902
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 1.84s
                      Time elapsed: 00:47:16
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 51513 steps/s (collection: 1.808s, learning 0.100s)
             Mean action noise std: 3.61
          Mean value_function loss: 34.0391
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.2026
                       Mean reward: 824.07
               Mean episode length: 244.05
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 162.2169
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.91s
                      Time elapsed: 00:47:18
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 48831 steps/s (collection: 1.922s, learning 0.091s)
             Mean action noise std: 3.61
          Mean value_function loss: 21.6291
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.2216
                       Mean reward: 832.08
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 163.8637
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.01s
                      Time elapsed: 00:47:20
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 46372 steps/s (collection: 1.947s, learning 0.173s)
             Mean action noise std: 3.61
          Mean value_function loss: 28.9683
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 57.2362
                       Mean reward: 816.89
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 162.3099
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.12s
                      Time elapsed: 00:47:22
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 46302 steps/s (collection: 1.964s, learning 0.159s)
             Mean action noise std: 3.61
          Mean value_function loss: 24.7853
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 57.2457
                       Mean reward: 830.36
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 161.2277
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.12s
                      Time elapsed: 00:47:25
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 43607 steps/s (collection: 2.144s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 23.4875
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 57.2590
                       Mean reward: 833.54
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 1.2424
    Episode_Reward/rotating_object: 165.2085
        Episode_Reward/action_rate: -0.0735
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.25s
                      Time elapsed: 00:47:27
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 53525 steps/s (collection: 1.748s, learning 0.089s)
             Mean action noise std: 3.62
          Mean value_function loss: 28.2864
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.2657
                       Mean reward: 829.53
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 1.2102
    Episode_Reward/rotating_object: 159.9961
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.84s
                      Time elapsed: 00:47:29
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 54183 steps/s (collection: 1.705s, learning 0.109s)
             Mean action noise std: 3.62
          Mean value_function loss: 27.7070
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 57.2750
                       Mean reward: 818.73
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 1.2181
    Episode_Reward/rotating_object: 162.1597
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.81s
                      Time elapsed: 00:47:30
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 48252 steps/s (collection: 1.934s, learning 0.104s)
             Mean action noise std: 3.62
          Mean value_function loss: 20.7455
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.2893
                       Mean reward: 818.61
               Mean episode length: 245.89
    Episode_Reward/reaching_object: 1.2341
    Episode_Reward/rotating_object: 162.6651
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.04s
                      Time elapsed: 00:47:32
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 50490 steps/s (collection: 1.817s, learning 0.130s)
             Mean action noise std: 3.62
          Mean value_function loss: 31.3112
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.3058
                       Mean reward: 815.33
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 161.8127
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.95s
                      Time elapsed: 00:47:34
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 49560 steps/s (collection: 1.868s, learning 0.116s)
             Mean action noise std: 3.63
          Mean value_function loss: 28.9913
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.3283
                       Mean reward: 813.28
               Mean episode length: 241.76
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 160.7648
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.98s
                      Time elapsed: 00:47:36
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 48710 steps/s (collection: 1.895s, learning 0.123s)
             Mean action noise std: 3.63
          Mean value_function loss: 40.6687
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.3547
                       Mean reward: 811.10
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 160.0226
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.02s
                      Time elapsed: 00:47:38
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 47415 steps/s (collection: 1.982s, learning 0.092s)
             Mean action noise std: 3.63
          Mean value_function loss: 30.2019
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 57.3752
                       Mean reward: 805.66
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.2090
    Episode_Reward/rotating_object: 159.7769
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.07s
                      Time elapsed: 00:47:40
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 18177 steps/s (collection: 5.288s, learning 0.120s)
             Mean action noise std: 3.64
          Mean value_function loss: 37.0043
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.3850
                       Mean reward: 759.33
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.2019
    Episode_Reward/rotating_object: 157.7931
        Episode_Reward/action_rate: -0.0722
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.41s
                      Time elapsed: 00:47:46
                               ETA: 00:05:58

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14253 steps/s (collection: 6.746s, learning 0.151s)
             Mean action noise std: 3.64
          Mean value_function loss: 25.7456
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.4042
                       Mean reward: 819.61
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 160.7321
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.90s
                      Time elapsed: 00:47:53
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 14447 steps/s (collection: 6.674s, learning 0.131s)
             Mean action noise std: 3.64
          Mean value_function loss: 26.5107
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 57.4190
                       Mean reward: 813.12
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 163.4999
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.80s
                      Time elapsed: 00:48:00
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14880 steps/s (collection: 6.462s, learning 0.145s)
             Mean action noise std: 3.64
          Mean value_function loss: 33.6852
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.4307
                       Mean reward: 816.77
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 1.2252
    Episode_Reward/rotating_object: 161.2276
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.61s
                      Time elapsed: 00:48:06
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 14358 steps/s (collection: 6.702s, learning 0.145s)
             Mean action noise std: 3.65
          Mean value_function loss: 18.5598
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.4430
                       Mean reward: 818.59
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 162.0729
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.85s
                      Time elapsed: 00:48:13
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 14391 steps/s (collection: 6.717s, learning 0.114s)
             Mean action noise std: 3.65
          Mean value_function loss: 36.8736
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.4630
                       Mean reward: 818.66
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 1.2215
    Episode_Reward/rotating_object: 161.3388
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.83s
                      Time elapsed: 00:48:20
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14011 steps/s (collection: 6.860s, learning 0.155s)
             Mean action noise std: 3.65
          Mean value_function loss: 28.9488
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 57.4881
                       Mean reward: 777.92
               Mean episode length: 234.93
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 161.2979
        Episode_Reward/action_rate: -0.0737
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 7.02s
                      Time elapsed: 00:48:27
                               ETA: 00:05:49

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 13962 steps/s (collection: 6.890s, learning 0.150s)
             Mean action noise std: 3.66
          Mean value_function loss: 26.3129
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.5134
                       Mean reward: 835.38
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 1.2198
    Episode_Reward/rotating_object: 161.5499
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 7.04s
                      Time elapsed: 00:48:34
                               ETA: 00:05:47

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 11991 steps/s (collection: 8.079s, learning 0.119s)
             Mean action noise std: 3.66
          Mean value_function loss: 31.1066
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 57.5270
                       Mean reward: 805.08
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 160.6564
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 8.20s
                      Time elapsed: 00:48:42
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 51987 steps/s (collection: 1.782s, learning 0.109s)
             Mean action noise std: 3.66
          Mean value_function loss: 32.9550
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 57.5315
                       Mean reward: 798.07
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 161.2898
        Episode_Reward/action_rate: -0.0747
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 1.89s
                      Time elapsed: 00:48:44
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 52388 steps/s (collection: 1.768s, learning 0.109s)
             Mean action noise std: 3.66
          Mean value_function loss: 20.2517
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.5415
                       Mean reward: 818.31
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 164.5037
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.88s
                      Time elapsed: 00:48:46
                               ETA: 00:05:41

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 51995 steps/s (collection: 1.775s, learning 0.116s)
             Mean action noise std: 3.66
          Mean value_function loss: 25.4667
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 57.5566
                       Mean reward: 809.63
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 1.2141
    Episode_Reward/rotating_object: 161.4820
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.89s
                      Time elapsed: 00:48:48
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 42597 steps/s (collection: 2.079s, learning 0.229s)
             Mean action noise std: 3.67
          Mean value_function loss: 26.0716
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.5714
                       Mean reward: 825.73
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 163.5539
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.31s
                      Time elapsed: 00:48:50
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 48245 steps/s (collection: 1.937s, learning 0.101s)
             Mean action noise std: 3.67
          Mean value_function loss: 34.9495
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.5854
                       Mean reward: 807.42
               Mean episode length: 239.05
    Episode_Reward/reaching_object: 1.1863
    Episode_Reward/rotating_object: 159.2088
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.04s
                      Time elapsed: 00:48:52
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 51833 steps/s (collection: 1.792s, learning 0.105s)
             Mean action noise std: 3.67
          Mean value_function loss: 23.9320
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 57.6100
                       Mean reward: 818.98
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 1.2102
    Episode_Reward/rotating_object: 161.4361
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.90s
                      Time elapsed: 00:48:54
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 54258 steps/s (collection: 1.704s, learning 0.108s)
             Mean action noise std: 3.67
          Mean value_function loss: 23.0829
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 57.6159
                       Mean reward: 808.44
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.2210
    Episode_Reward/rotating_object: 162.7529
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.81s
                      Time elapsed: 00:48:56
                               ETA: 00:05:30

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 54498 steps/s (collection: 1.712s, learning 0.092s)
             Mean action noise std: 3.68
          Mean value_function loss: 29.2650
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.6222
                       Mean reward: 791.83
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 160.2135
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.80s
                      Time elapsed: 00:48:58
                               ETA: 00:05:28

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 50113 steps/s (collection: 1.833s, learning 0.129s)
             Mean action noise std: 3.68
          Mean value_function loss: 35.6199
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.6354
                       Mean reward: 833.69
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2026
    Episode_Reward/rotating_object: 159.3122
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0183
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.96s
                      Time elapsed: 00:49:00
                               ETA: 00:05:26

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 45558 steps/s (collection: 1.973s, learning 0.184s)
             Mean action noise std: 3.68
          Mean value_function loss: 32.5030
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.6497
                       Mean reward: 821.07
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 1.2069
    Episode_Reward/rotating_object: 161.4630
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.16s
                      Time elapsed: 00:49:02
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 44621 steps/s (collection: 1.970s, learning 0.233s)
             Mean action noise std: 3.68
          Mean value_function loss: 21.9035
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 57.6651
                       Mean reward: 841.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 162.3500
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.20s
                      Time elapsed: 00:49:04
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 43227 steps/s (collection: 2.081s, learning 0.193s)
             Mean action noise std: 3.69
          Mean value_function loss: 34.6374
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 57.6772
                       Mean reward: 786.65
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 161.1597
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.27s
                      Time elapsed: 00:49:06
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 45889 steps/s (collection: 1.977s, learning 0.165s)
             Mean action noise std: 3.69
          Mean value_function loss: 23.3012
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 57.6914
                       Mean reward: 824.78
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 163.0864
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.14s
                      Time elapsed: 00:49:08
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 43159 steps/s (collection: 2.042s, learning 0.236s)
             Mean action noise std: 3.69
          Mean value_function loss: 32.8306
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 57.6999
                       Mean reward: 785.67
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 159.6352
        Episode_Reward/action_rate: -0.0748
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.28s
                      Time elapsed: 00:49:11
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 44399 steps/s (collection: 2.075s, learning 0.139s)
             Mean action noise std: 3.69
          Mean value_function loss: 30.4379
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 57.7085
                       Mean reward: 797.71
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 161.3999
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.21s
                      Time elapsed: 00:49:13
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 49885 steps/s (collection: 1.860s, learning 0.110s)
             Mean action noise std: 3.69
          Mean value_function loss: 32.6876
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.7263
                       Mean reward: 831.38
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 161.2348
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.97s
                      Time elapsed: 00:49:15
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 42667 steps/s (collection: 2.125s, learning 0.179s)
             Mean action noise std: 3.70
          Mean value_function loss: 23.9275
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.7473
                       Mean reward: 843.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 164.1508
        Episode_Reward/action_rate: -0.0766
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.30s
                      Time elapsed: 00:49:17
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 48386 steps/s (collection: 1.878s, learning 0.154s)
             Mean action noise std: 3.70
          Mean value_function loss: 27.9861
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.7658
                       Mean reward: 820.75
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 1.2271
    Episode_Reward/rotating_object: 162.6641
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.03s
                      Time elapsed: 00:49:19
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 49588 steps/s (collection: 1.862s, learning 0.121s)
             Mean action noise std: 3.70
          Mean value_function loss: 28.0771
               Mean surrogate loss: 0.0030
                 Mean entropy loss: 57.7801
                       Mean reward: 820.43
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.2256
    Episode_Reward/rotating_object: 162.2142
        Episode_Reward/action_rate: -0.0764
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.98s
                      Time elapsed: 00:49:21
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 49970 steps/s (collection: 1.862s, learning 0.105s)
             Mean action noise std: 3.70
          Mean value_function loss: 31.0729
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 57.7852
                       Mean reward: 813.35
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 160.4081
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.97s
                      Time elapsed: 00:49:23
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 47857 steps/s (collection: 1.869s, learning 0.185s)
             Mean action noise std: 3.70
          Mean value_function loss: 29.6541
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 57.7902
                       Mean reward: 809.94
               Mean episode length: 242.77
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 160.1062
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.05s
                      Time elapsed: 00:49:25
                               ETA: 00:05:00

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 43828 steps/s (collection: 2.071s, learning 0.172s)
             Mean action noise std: 3.71
          Mean value_function loss: 29.7524
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 57.7953
                       Mean reward: 818.13
               Mean episode length: 243.19
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 163.6302
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.24s
                      Time elapsed: 00:49:27
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 43458 steps/s (collection: 2.070s, learning 0.192s)
             Mean action noise std: 3.71
          Mean value_function loss: 25.3902
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.8010
                       Mean reward: 823.86
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 1.2281
    Episode_Reward/rotating_object: 161.9540
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.26s
                      Time elapsed: 00:49:30
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 43640 steps/s (collection: 2.078s, learning 0.174s)
             Mean action noise std: 3.71
          Mean value_function loss: 20.2914
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 57.8137
                       Mean reward: 802.74
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 1.2486
    Episode_Reward/rotating_object: 162.9159
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.25s
                      Time elapsed: 00:49:32
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 47043 steps/s (collection: 1.927s, learning 0.163s)
             Mean action noise std: 3.71
          Mean value_function loss: 21.9378
               Mean surrogate loss: 0.0135
                 Mean entropy loss: 57.8241
                       Mean reward: 814.95
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 163.3708
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.09s
                      Time elapsed: 00:49:34
                               ETA: 00:04:51

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 48635 steps/s (collection: 1.887s, learning 0.134s)
             Mean action noise std: 3.71
          Mean value_function loss: 29.5579
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 57.8264
                       Mean reward: 801.92
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.2476
    Episode_Reward/rotating_object: 162.2916
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.02s
                      Time elapsed: 00:49:36
                               ETA: 00:04:49

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 45481 steps/s (collection: 1.964s, learning 0.198s)
             Mean action noise std: 3.71
          Mean value_function loss: 20.6977
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 57.8334
                       Mean reward: 823.52
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 1.2324
    Episode_Reward/rotating_object: 161.5020
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.16s
                      Time elapsed: 00:49:38
                               ETA: 00:04:47

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 44998 steps/s (collection: 1.970s, learning 0.215s)
             Mean action noise std: 3.71
          Mean value_function loss: 23.1209
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.8449
                       Mean reward: 813.37
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 1.2356
    Episode_Reward/rotating_object: 162.0189
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.18s
                      Time elapsed: 00:49:40
                               ETA: 00:04:45

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 48165 steps/s (collection: 1.897s, learning 0.144s)
             Mean action noise std: 3.72
          Mean value_function loss: 19.9450
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 57.8525
                       Mean reward: 828.48
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.2344
    Episode_Reward/rotating_object: 163.3262
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.04s
                      Time elapsed: 00:49:42
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 45312 steps/s (collection: 1.995s, learning 0.175s)
             Mean action noise std: 3.72
          Mean value_function loss: 17.3419
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 57.8647
                       Mean reward: 834.36
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2372
    Episode_Reward/rotating_object: 164.2128
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.17s
                      Time elapsed: 00:49:45
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 47942 steps/s (collection: 1.878s, learning 0.173s)
             Mean action noise std: 3.72
          Mean value_function loss: 25.6574
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 57.8777
                       Mean reward: 828.20
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 163.8503
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.05s
                      Time elapsed: 00:49:47
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 44845 steps/s (collection: 2.084s, learning 0.108s)
             Mean action noise std: 3.72
          Mean value_function loss: 24.7004
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 57.8908
                       Mean reward: 822.41
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 163.0810
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.19s
                      Time elapsed: 00:49:49
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 44599 steps/s (collection: 2.016s, learning 0.189s)
             Mean action noise std: 3.73
          Mean value_function loss: 31.5035
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 57.9102
                       Mean reward: 825.97
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 163.6737
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.20s
                      Time elapsed: 00:49:51
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 46661 steps/s (collection: 1.999s, learning 0.108s)
             Mean action noise std: 3.73
          Mean value_function loss: 32.2797
               Mean surrogate loss: 0.0096
                 Mean entropy loss: 57.9291
                       Mean reward: 824.49
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 1.2139
    Episode_Reward/rotating_object: 160.4359
        Episode_Reward/action_rate: -0.0774
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.11s
                      Time elapsed: 00:49:53
                               ETA: 00:04:31

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 46436 steps/s (collection: 2.015s, learning 0.102s)
             Mean action noise std: 3.73
          Mean value_function loss: 22.2750
               Mean surrogate loss: 0.0654
                 Mean entropy loss: 57.9368
                       Mean reward: 817.42
               Mean episode length: 243.10
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 162.9204
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.12s
                      Time elapsed: 00:49:55
                               ETA: 00:04:29

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 39682 steps/s (collection: 2.153s, learning 0.325s)
             Mean action noise std: 3.73
          Mean value_function loss: 26.8247
               Mean surrogate loss: 0.0043
                 Mean entropy loss: 57.9377
                       Mean reward: 838.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2340
    Episode_Reward/rotating_object: 163.6191
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.48s
                      Time elapsed: 00:49:58
                               ETA: 00:04:27

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 41653 steps/s (collection: 2.244s, learning 0.116s)
             Mean action noise std: 3.73
          Mean value_function loss: 21.5174
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 57.9382
                       Mean reward: 808.12
               Mean episode length: 242.33
    Episode_Reward/reaching_object: 1.2150
    Episode_Reward/rotating_object: 163.0243
        Episode_Reward/action_rate: -0.0778
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.36s
                      Time elapsed: 00:50:00
                               ETA: 00:04:25

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 49679 steps/s (collection: 1.850s, learning 0.129s)
             Mean action noise std: 3.73
          Mean value_function loss: 21.5973
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 57.9384
                       Mean reward: 817.36
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 1.2017
    Episode_Reward/rotating_object: 163.4873
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.98s
                      Time elapsed: 00:50:02
                               ETA: 00:04:23

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 47314 steps/s (collection: 1.890s, learning 0.188s)
             Mean action noise std: 3.73
          Mean value_function loss: 23.2933
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 57.9423
                       Mean reward: 814.62
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 1.1900
    Episode_Reward/rotating_object: 163.2273
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.08s
                      Time elapsed: 00:50:04
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 46183 steps/s (collection: 2.024s, learning 0.105s)
             Mean action noise std: 3.73
          Mean value_function loss: 19.6398
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 57.9492
                       Mean reward: 824.23
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 1.1936
    Episode_Reward/rotating_object: 164.9077
        Episode_Reward/action_rate: -0.0788
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.13s
                      Time elapsed: 00:50:06
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 47004 steps/s (collection: 1.924s, learning 0.168s)
             Mean action noise std: 3.74
          Mean value_function loss: 23.6739
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.9631
                       Mean reward: 805.27
               Mean episode length: 243.77
    Episode_Reward/reaching_object: 1.1687
    Episode_Reward/rotating_object: 161.6536
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.09s
                      Time elapsed: 00:50:08
                               ETA: 00:04:16

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 46174 steps/s (collection: 2.006s, learning 0.123s)
             Mean action noise std: 3.74
          Mean value_function loss: 33.4428
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 57.9767
                       Mean reward: 815.80
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.1544
    Episode_Reward/rotating_object: 159.8811
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0185
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.13s
                      Time elapsed: 00:50:11
                               ETA: 00:04:14

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 47510 steps/s (collection: 1.869s, learning 0.200s)
             Mean action noise std: 3.74
          Mean value_function loss: 18.4334
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 57.9869
                       Mean reward: 823.54
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.1795
    Episode_Reward/rotating_object: 164.4136
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.07s
                      Time elapsed: 00:50:13
                               ETA: 00:04:12

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 44326 steps/s (collection: 2.004s, learning 0.214s)
             Mean action noise std: 3.74
          Mean value_function loss: 27.5903
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.0003
                       Mean reward: 809.13
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 1.1854
    Episode_Reward/rotating_object: 161.6663
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.22s
                      Time elapsed: 00:50:15
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 48253 steps/s (collection: 1.834s, learning 0.203s)
             Mean action noise std: 3.74
          Mean value_function loss: 18.1633
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.0181
                       Mean reward: 822.80
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.1866
    Episode_Reward/rotating_object: 160.4779
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0187
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.04s
                      Time elapsed: 00:50:17
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 44679 steps/s (collection: 2.020s, learning 0.180s)
             Mean action noise std: 3.75
          Mean value_function loss: 22.6035
               Mean surrogate loss: 0.0064
                 Mean entropy loss: 58.0343
                       Mean reward: 812.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 162.1310
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.20s
                      Time elapsed: 00:50:19
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 41802 steps/s (collection: 2.109s, learning 0.243s)
             Mean action noise std: 3.75
          Mean value_function loss: 20.9238
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 58.0357
                       Mean reward: 823.88
               Mean episode length: 249.18
    Episode_Reward/reaching_object: 1.2096
    Episode_Reward/rotating_object: 162.5816
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.35s
                      Time elapsed: 00:50:21
                               ETA: 00:04:03

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 42414 steps/s (collection: 2.075s, learning 0.243s)
             Mean action noise std: 3.75
          Mean value_function loss: 31.5867
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 58.0367
                       Mean reward: 802.86
               Mean episode length: 243.55
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 159.1826
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.32s
                      Time elapsed: 00:50:24
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 46099 steps/s (collection: 1.881s, learning 0.252s)
             Mean action noise std: 3.75
          Mean value_function loss: 26.0414
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 58.0436
                       Mean reward: 793.33
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.1808
    Episode_Reward/rotating_object: 160.8855
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.13s
                      Time elapsed: 00:50:26
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 45827 steps/s (collection: 1.974s, learning 0.171s)
             Mean action noise std: 3.75
          Mean value_function loss: 26.1298
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.0527
                       Mean reward: 814.28
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.1970
    Episode_Reward/rotating_object: 162.1729
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.15s
                      Time elapsed: 00:50:28
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 43042 steps/s (collection: 2.135s, learning 0.148s)
             Mean action noise std: 3.75
          Mean value_function loss: 18.7341
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.0606
                       Mean reward: 833.71
               Mean episode length: 248.50
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 161.1033
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.28s
                      Time elapsed: 00:50:30
                               ETA: 00:03:54

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 46986 steps/s (collection: 1.898s, learning 0.195s)
             Mean action noise std: 3.75
          Mean value_function loss: 34.4513
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 58.0677
                       Mean reward: 823.41
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 1.1908
    Episode_Reward/rotating_object: 162.1257
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.09s
                      Time elapsed: 00:50:32
                               ETA: 00:03:52

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 45726 steps/s (collection: 1.975s, learning 0.175s)
             Mean action noise std: 3.76
          Mean value_function loss: 24.1047
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.0791
                       Mean reward: 828.82
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.1780
    Episode_Reward/rotating_object: 159.5545
        Episode_Reward/action_rate: -0.0779
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.15s
                      Time elapsed: 00:50:35
                               ETA: 00:03:50

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 44302 steps/s (collection: 2.053s, learning 0.166s)
             Mean action noise std: 3.76
          Mean value_function loss: 26.3646
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.0920
                       Mean reward: 836.12
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 1.2095
    Episode_Reward/rotating_object: 162.7367
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.22s
                      Time elapsed: 00:50:37
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 44279 steps/s (collection: 1.989s, learning 0.231s)
             Mean action noise std: 3.76
          Mean value_function loss: 21.1344
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 58.1050
                       Mean reward: 825.75
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 1.2095
    Episode_Reward/rotating_object: 163.3000
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.22s
                      Time elapsed: 00:50:39
                               ETA: 00:03:46

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 40939 steps/s (collection: 2.236s, learning 0.166s)
             Mean action noise std: 3.76
          Mean value_function loss: 25.0181
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.1139
                       Mean reward: 837.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 162.6556
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.40s
                      Time elapsed: 00:50:41
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 39597 steps/s (collection: 2.258s, learning 0.224s)
             Mean action noise std: 3.77
          Mean value_function loss: 21.5064
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 58.1290
                       Mean reward: 801.63
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.2087
    Episode_Reward/rotating_object: 162.6604
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.48s
                      Time elapsed: 00:50:44
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 38599 steps/s (collection: 2.398s, learning 0.148s)
             Mean action noise std: 3.77
          Mean value_function loss: 22.7595
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.1438
                       Mean reward: 835.66
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 1.1918
    Episode_Reward/rotating_object: 160.6483
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.55s
                      Time elapsed: 00:50:46
                               ETA: 00:03:39

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 44479 steps/s (collection: 2.037s, learning 0.173s)
             Mean action noise std: 3.77
          Mean value_function loss: 22.9360
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 58.1580
                       Mean reward: 796.09
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.2039
    Episode_Reward/rotating_object: 163.0435
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.21s
                      Time elapsed: 00:50:49
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 42086 steps/s (collection: 2.169s, learning 0.167s)
             Mean action noise std: 3.77
          Mean value_function loss: 20.2633
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 58.1673
                       Mean reward: 825.64
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 1.1931
    Episode_Reward/rotating_object: 161.2968
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.34s
                      Time elapsed: 00:50:51
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 44938 steps/s (collection: 1.995s, learning 0.193s)
             Mean action noise std: 3.78
          Mean value_function loss: 30.5255
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 58.1799
                       Mean reward: 816.69
               Mean episode length: 243.36
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 161.8245
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.19s
                      Time elapsed: 00:50:53
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 44676 steps/s (collection: 2.039s, learning 0.161s)
             Mean action noise std: 3.78
          Mean value_function loss: 27.1207
               Mean surrogate loss: 0.0029
                 Mean entropy loss: 58.1923
                       Mean reward: 814.15
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.1986
    Episode_Reward/rotating_object: 162.1223
        Episode_Reward/action_rate: -0.0794
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.20s
                      Time elapsed: 00:50:55
                               ETA: 00:03:31

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 44044 steps/s (collection: 2.063s, learning 0.169s)
             Mean action noise std: 3.78
          Mean value_function loss: 29.5391
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 58.1975
                       Mean reward: 814.44
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 163.3983
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.23s
                      Time elapsed: 00:50:58
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 44235 steps/s (collection: 2.059s, learning 0.164s)
             Mean action noise std: 3.78
          Mean value_function loss: 23.1555
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 58.2117
                       Mean reward: 808.08
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 1.2137
    Episode_Reward/rotating_object: 163.1250
        Episode_Reward/action_rate: -0.0805
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.22s
                      Time elapsed: 00:51:00
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 47744 steps/s (collection: 1.910s, learning 0.149s)
             Mean action noise std: 3.78
          Mean value_function loss: 25.4139
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.2305
                       Mean reward: 833.04
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 1.2079
    Episode_Reward/rotating_object: 161.6871
        Episode_Reward/action_rate: -0.0796
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.06s
                      Time elapsed: 00:51:02
                               ETA: 00:03:24

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 45492 steps/s (collection: 1.930s, learning 0.230s)
             Mean action noise std: 3.79
          Mean value_function loss: 23.3225
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 58.2534
                       Mean reward: 825.14
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.2274
    Episode_Reward/rotating_object: 165.0609
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.16s
                      Time elapsed: 00:51:04
                               ETA: 00:03:22

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 45439 steps/s (collection: 2.046s, learning 0.117s)
             Mean action noise std: 3.79
          Mean value_function loss: 27.3552
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 58.2629
                       Mean reward: 796.86
               Mean episode length: 241.35
    Episode_Reward/reaching_object: 1.2071
    Episode_Reward/rotating_object: 162.0029
        Episode_Reward/action_rate: -0.0797
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.16s
                      Time elapsed: 00:51:06
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 50018 steps/s (collection: 1.864s, learning 0.102s)
             Mean action noise std: 3.79
          Mean value_function loss: 31.7690
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.2769
                       Mean reward: 836.76
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 1.1937
    Episode_Reward/rotating_object: 160.7223
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.97s
                      Time elapsed: 00:51:08
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 52294 steps/s (collection: 1.727s, learning 0.153s)
             Mean action noise std: 3.79
          Mean value_function loss: 39.5737
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.2867
                       Mean reward: 800.77
               Mean episode length: 239.40
    Episode_Reward/reaching_object: 1.1938
    Episode_Reward/rotating_object: 159.2991
        Episode_Reward/action_rate: -0.0792
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.88s
                      Time elapsed: 00:51:10
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 49801 steps/s (collection: 1.842s, learning 0.132s)
             Mean action noise std: 3.79
          Mean value_function loss: 28.3010
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 58.2960
                       Mean reward: 803.65
               Mean episode length: 239.69
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 161.6583
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.97s
                      Time elapsed: 00:51:12
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 48045 steps/s (collection: 1.923s, learning 0.123s)
             Mean action noise std: 3.80
          Mean value_function loss: 27.5100
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 58.3049
                       Mean reward: 795.62
               Mean episode length: 237.62
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 162.1617
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.05s
                      Time elapsed: 00:51:14
                               ETA: 00:03:11

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 51978 steps/s (collection: 1.713s, learning 0.178s)
             Mean action noise std: 3.80
          Mean value_function loss: 28.8599
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.3206
                       Mean reward: 826.28
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 161.2431
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.89s
                      Time elapsed: 00:51:16
                               ETA: 00:03:09

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 49502 steps/s (collection: 1.813s, learning 0.173s)
             Mean action noise std: 3.80
          Mean value_function loss: 33.5240
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.3343
                       Mean reward: 820.03
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.1937
    Episode_Reward/rotating_object: 160.6095
        Episode_Reward/action_rate: -0.0798
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.99s
                      Time elapsed: 00:51:18
                               ETA: 00:03:07

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 52314 steps/s (collection: 1.744s, learning 0.135s)
             Mean action noise std: 3.80
          Mean value_function loss: 36.9123
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 58.3439
                       Mean reward: 790.99
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 161.8651
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.88s
                      Time elapsed: 00:51:20
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 48274 steps/s (collection: 1.861s, learning 0.176s)
             Mean action noise std: 3.80
          Mean value_function loss: 27.9777
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 58.3501
                       Mean reward: 824.36
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 161.0744
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.04s
                      Time elapsed: 00:51:22
                               ETA: 00:03:02

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 47482 steps/s (collection: 1.918s, learning 0.152s)
             Mean action noise std: 3.81
          Mean value_function loss: 39.3135
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.3671
                       Mean reward: 826.11
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 1.1965
    Episode_Reward/rotating_object: 160.7994
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.07s
                      Time elapsed: 00:51:24
                               ETA: 00:03:00

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 47723 steps/s (collection: 1.899s, learning 0.161s)
             Mean action noise std: 3.81
          Mean value_function loss: 30.8460
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.3848
                       Mean reward: 818.00
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 1.2017
    Episode_Reward/rotating_object: 159.8063
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.06s
                      Time elapsed: 00:51:26
                               ETA: 00:02:58

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 49963 steps/s (collection: 1.858s, learning 0.110s)
             Mean action noise std: 3.81
          Mean value_function loss: 26.3158
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 58.4027
                       Mean reward: 814.66
               Mean episode length: 244.66
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 164.9570
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.97s
                      Time elapsed: 00:51:28
                               ETA: 00:02:56

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 52101 steps/s (collection: 1.780s, learning 0.107s)
             Mean action noise std: 3.82
          Mean value_function loss: 37.2059
               Mean surrogate loss: 0.0169
                 Mean entropy loss: 58.4180
                       Mean reward: 818.00
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.2000
    Episode_Reward/rotating_object: 160.3208
        Episode_Reward/action_rate: -0.0803
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.89s
                      Time elapsed: 00:51:30
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 52771 steps/s (collection: 1.755s, learning 0.108s)
             Mean action noise std: 3.82
          Mean value_function loss: 36.5569
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.4221
                       Mean reward: 813.31
               Mean episode length: 244.37
    Episode_Reward/reaching_object: 1.2049
    Episode_Reward/rotating_object: 159.9195
        Episode_Reward/action_rate: -0.0809
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.86s
                      Time elapsed: 00:51:32
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 49374 steps/s (collection: 1.888s, learning 0.103s)
             Mean action noise std: 3.82
          Mean value_function loss: 41.2406
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.4295
                       Mean reward: 783.13
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 156.3525
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.99s
                      Time elapsed: 00:51:34
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 51300 steps/s (collection: 1.816s, learning 0.101s)
             Mean action noise std: 3.82
          Mean value_function loss: 43.4188
               Mean surrogate loss: 0.0085
                 Mean entropy loss: 58.4435
                       Mean reward: 816.86
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.1898
    Episode_Reward/rotating_object: 160.1750
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.92s
                      Time elapsed: 00:51:36
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 50151 steps/s (collection: 1.864s, learning 0.097s)
             Mean action noise std: 3.82
          Mean value_function loss: 37.4152
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 58.4468
                       Mean reward: 776.05
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.1616
    Episode_Reward/rotating_object: 154.8087
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.96s
                      Time elapsed: 00:51:38
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 47451 steps/s (collection: 1.967s, learning 0.105s)
             Mean action noise std: 3.82
          Mean value_function loss: 37.2741
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 58.4544
                       Mean reward: 828.26
               Mean episode length: 247.03
    Episode_Reward/reaching_object: 1.2006
    Episode_Reward/rotating_object: 161.0654
        Episode_Reward/action_rate: -0.0808
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.07s
                      Time elapsed: 00:51:40
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 48194 steps/s (collection: 1.870s, learning 0.170s)
             Mean action noise std: 3.82
          Mean value_function loss: 37.5863
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 58.4644
                       Mean reward: 809.74
               Mean episode length: 241.00
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 156.4952
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.04s
                      Time elapsed: 00:51:42
                               ETA: 00:02:40

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 45779 steps/s (collection: 1.989s, learning 0.159s)
             Mean action noise std: 3.82
          Mean value_function loss: 33.4604
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 58.4679
                       Mean reward: 824.44
               Mean episode length: 248.29
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 162.0318
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.15s
                      Time elapsed: 00:51:44
                               ETA: 00:02:38

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 48325 steps/s (collection: 1.832s, learning 0.203s)
             Mean action noise std: 3.83
          Mean value_function loss: 36.1902
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.4765
                       Mean reward: 825.84
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 1.2052
    Episode_Reward/rotating_object: 159.7712
        Episode_Reward/action_rate: -0.0815
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.03s
                      Time elapsed: 00:51:46
                               ETA: 00:02:36

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 44562 steps/s (collection: 2.050s, learning 0.156s)
             Mean action noise std: 3.83
          Mean value_function loss: 27.1829
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 58.4898
                       Mean reward: 813.54
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 161.8251
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0202
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.21s
                      Time elapsed: 00:51:48
                               ETA: 00:02:34

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 48726 steps/s (collection: 1.900s, learning 0.118s)
             Mean action noise std: 3.83
          Mean value_function loss: 24.6428
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.4993
                       Mean reward: 805.19
               Mean episode length: 244.10
    Episode_Reward/reaching_object: 1.2206
    Episode_Reward/rotating_object: 162.4950
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.02s
                      Time elapsed: 00:51:50
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 50315 steps/s (collection: 1.849s, learning 0.105s)
             Mean action noise std: 3.83
          Mean value_function loss: 32.4257
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.5079
                       Mean reward: 811.73
               Mean episode length: 244.30
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 160.2930
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.95s
                      Time elapsed: 00:51:52
                               ETA: 00:02:29

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 48014 steps/s (collection: 1.911s, learning 0.137s)
             Mean action noise std: 3.83
          Mean value_function loss: 25.4253
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 58.5171
                       Mean reward: 806.55
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 1.2136
    Episode_Reward/rotating_object: 162.1397
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.05s
                      Time elapsed: 00:51:54
                               ETA: 00:02:27

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 48894 steps/s (collection: 1.850s, learning 0.161s)
             Mean action noise std: 3.84
          Mean value_function loss: 28.0725
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.5287
                       Mean reward: 812.27
               Mean episode length: 242.02
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 160.4940
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.01s
                      Time elapsed: 00:51:56
                               ETA: 00:02:25

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 49883 steps/s (collection: 1.819s, learning 0.152s)
             Mean action noise std: 3.84
          Mean value_function loss: 23.0570
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 58.5420
                       Mean reward: 819.69
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 1.2226
    Episode_Reward/rotating_object: 162.4916
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.97s
                      Time elapsed: 00:51:58
                               ETA: 00:02:23

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 48908 steps/s (collection: 1.820s, learning 0.190s)
             Mean action noise std: 3.84
          Mean value_function loss: 32.2184
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 58.5476
                       Mean reward: 798.98
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 159.9012
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.01s
                      Time elapsed: 00:52:00
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 50330 steps/s (collection: 1.774s, learning 0.179s)
             Mean action noise std: 3.84
          Mean value_function loss: 22.0715
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.5555
                       Mean reward: 824.13
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 1.2284
    Episode_Reward/rotating_object: 162.9869
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.95s
                      Time elapsed: 00:52:02
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 45053 steps/s (collection: 2.002s, learning 0.180s)
             Mean action noise std: 3.84
          Mean value_function loss: 37.2394
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.5635
                       Mean reward: 801.37
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.1873
    Episode_Reward/rotating_object: 158.4648
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.18s
                      Time elapsed: 00:52:04
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 44120 steps/s (collection: 2.092s, learning 0.136s)
             Mean action noise std: 3.85
          Mean value_function loss: 30.8195
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.5737
                       Mean reward: 774.10
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.2053
    Episode_Reward/rotating_object: 160.9433
        Episode_Reward/action_rate: -0.0820
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.23s
                      Time elapsed: 00:52:06
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 44126 steps/s (collection: 2.102s, learning 0.126s)
             Mean action noise std: 3.85
          Mean value_function loss: 24.9584
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.5818
                       Mean reward: 807.55
               Mean episode length: 241.32
    Episode_Reward/reaching_object: 1.2233
    Episode_Reward/rotating_object: 162.2157
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.23s
                      Time elapsed: 00:52:09
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 47681 steps/s (collection: 1.929s, learning 0.132s)
             Mean action noise std: 3.85
          Mean value_function loss: 27.0745
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.5924
                       Mean reward: 789.48
               Mean episode length: 238.65
    Episode_Reward/reaching_object: 1.2148
    Episode_Reward/rotating_object: 161.8884
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.06s
                      Time elapsed: 00:52:11
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 43836 steps/s (collection: 2.019s, learning 0.223s)
             Mean action noise std: 3.85
          Mean value_function loss: 19.5597
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 58.6016
                       Mean reward: 824.40
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.2320
    Episode_Reward/rotating_object: 162.7001
        Episode_Reward/action_rate: -0.0833
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.24s
                      Time elapsed: 00:52:13
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 41852 steps/s (collection: 2.167s, learning 0.182s)
             Mean action noise std: 3.85
          Mean value_function loss: 25.6617
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.6059
                       Mean reward: 826.66
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2382
    Episode_Reward/rotating_object: 163.0031
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.35s
                      Time elapsed: 00:52:15
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 43465 steps/s (collection: 2.089s, learning 0.173s)
             Mean action noise std: 3.86
          Mean value_function loss: 31.4704
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.6199
                       Mean reward: 809.88
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 160.9300
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.26s
                      Time elapsed: 00:52:18
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 43716 steps/s (collection: 2.125s, learning 0.124s)
             Mean action noise std: 3.86
          Mean value_function loss: 31.2920
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 58.6358
                       Mean reward: 820.84
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 1.2178
    Episode_Reward/rotating_object: 160.4161
        Episode_Reward/action_rate: -0.0824
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.25s
                      Time elapsed: 00:52:20
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 40241 steps/s (collection: 2.148s, learning 0.295s)
             Mean action noise std: 3.86
          Mean value_function loss: 27.4858
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 58.6422
                       Mean reward: 801.27
               Mean episode length: 239.04
    Episode_Reward/reaching_object: 1.2128
    Episode_Reward/rotating_object: 159.5105
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.44s
                      Time elapsed: 00:52:22
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 44741 steps/s (collection: 1.962s, learning 0.236s)
             Mean action noise std: 3.86
          Mean value_function loss: 26.4134
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.6472
                       Mean reward: 823.04
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 164.0627
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.20s
                      Time elapsed: 00:52:24
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 45005 steps/s (collection: 2.080s, learning 0.104s)
             Mean action noise std: 3.86
          Mean value_function loss: 33.4965
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 58.6568
                       Mean reward: 791.73
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 1.2213
    Episode_Reward/rotating_object: 160.8967
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.18s
                      Time elapsed: 00:52:27
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 49862 steps/s (collection: 1.860s, learning 0.112s)
             Mean action noise std: 3.86
          Mean value_function loss: 28.7567
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.6651
                       Mean reward: 798.47
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 161.1257
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.97s
                      Time elapsed: 00:52:29
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 41608 steps/s (collection: 2.161s, learning 0.202s)
             Mean action noise std: 3.87
          Mean value_function loss: 29.7350
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.6731
                       Mean reward: 827.32
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 162.4079
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.36s
                      Time elapsed: 00:52:31
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 45562 steps/s (collection: 1.988s, learning 0.169s)
             Mean action noise std: 3.87
          Mean value_function loss: 29.0350
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 58.6922
                       Mean reward: 810.48
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 161.2364
        Episode_Reward/action_rate: -0.0826
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.16s
                      Time elapsed: 00:52:33
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 44853 steps/s (collection: 2.017s, learning 0.174s)
             Mean action noise std: 3.87
          Mean value_function loss: 31.0493
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 58.7147
                       Mean reward: 843.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 162.1527
        Episode_Reward/action_rate: -0.0832
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.19s
                      Time elapsed: 00:52:35
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 48298 steps/s (collection: 1.882s, learning 0.154s)
             Mean action noise std: 3.88
          Mean value_function loss: 22.3735
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 58.7253
                       Mean reward: 809.00
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 162.0357
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.04s
                      Time elapsed: 00:52:37
                               ETA: 00:01:44

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 46897 steps/s (collection: 1.981s, learning 0.115s)
             Mean action noise std: 3.88
          Mean value_function loss: 25.6920
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 58.7350
                       Mean reward: 797.94
               Mean episode length: 239.14
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 161.4613
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.10s
                      Time elapsed: 00:52:39
                               ETA: 00:01:42

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 52204 steps/s (collection: 1.784s, learning 0.099s)
             Mean action noise std: 3.88
          Mean value_function loss: 28.3497
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 58.7444
                       Mean reward: 828.95
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 1.2079
    Episode_Reward/rotating_object: 162.1198
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.88s
                      Time elapsed: 00:52:41
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 51044 steps/s (collection: 1.808s, learning 0.118s)
             Mean action noise std: 3.88
          Mean value_function loss: 39.2100
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 58.7536
                       Mean reward: 779.23
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.2012
    Episode_Reward/rotating_object: 159.1876
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.93s
                      Time elapsed: 00:52:43
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 50568 steps/s (collection: 1.803s, learning 0.141s)
             Mean action noise std: 3.88
          Mean value_function loss: 24.6229
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 58.7671
                       Mean reward: 834.74
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 162.1960
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.94s
                      Time elapsed: 00:52:45
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 49101 steps/s (collection: 1.848s, learning 0.154s)
             Mean action noise std: 3.89
          Mean value_function loss: 33.2964
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 58.7782
                       Mean reward: 802.95
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 160.7713
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.00s
                      Time elapsed: 00:52:47
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 48335 steps/s (collection: 1.929s, learning 0.105s)
             Mean action noise std: 3.89
          Mean value_function loss: 27.4311
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 58.7856
                       Mean reward: 807.67
               Mean episode length: 241.85
    Episode_Reward/reaching_object: 1.2256
    Episode_Reward/rotating_object: 161.7028
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.03s
                      Time elapsed: 00:52:49
                               ETA: 00:01:31

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 52467 steps/s (collection: 1.780s, learning 0.094s)
             Mean action noise std: 3.89
          Mean value_function loss: 21.8586
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.7975
                       Mean reward: 844.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 163.8171
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.87s
                      Time elapsed: 00:52:51
                               ETA: 00:01:29

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 51043 steps/s (collection: 1.799s, learning 0.127s)
             Mean action noise std: 3.89
          Mean value_function loss: 22.5738
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.8139
                       Mean reward: 808.85
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 1.2251
    Episode_Reward/rotating_object: 161.1552
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.93s
                      Time elapsed: 00:52:53
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 49494 steps/s (collection: 1.827s, learning 0.159s)
             Mean action noise std: 3.90
          Mean value_function loss: 33.0735
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 58.8225
                       Mean reward: 805.89
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.2269
    Episode_Reward/rotating_object: 161.3284
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.99s
                      Time elapsed: 00:52:55
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 52597 steps/s (collection: 1.746s, learning 0.123s)
             Mean action noise std: 3.90
          Mean value_function loss: 20.9690
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 58.8347
                       Mean reward: 797.44
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 161.6740
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.87s
                      Time elapsed: 00:52:57
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 52434 steps/s (collection: 1.775s, learning 0.100s)
             Mean action noise std: 3.90
          Mean value_function loss: 30.6615
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 58.8388
                       Mean reward: 808.36
               Mean episode length: 241.53
    Episode_Reward/reaching_object: 1.2297
    Episode_Reward/rotating_object: 161.4214
        Episode_Reward/action_rate: -0.0836
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.87s
                      Time elapsed: 00:52:59
                               ETA: 00:01:20

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 52565 steps/s (collection: 1.759s, learning 0.111s)
             Mean action noise std: 3.90
          Mean value_function loss: 25.0180
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 58.8449
                       Mean reward: 827.46
               Mean episode length: 246.62
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 161.0779
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.87s
                      Time elapsed: 00:53:01
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 49807 steps/s (collection: 1.820s, learning 0.154s)
             Mean action noise std: 3.90
          Mean value_function loss: 29.2120
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.8530
                       Mean reward: 818.99
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.2313
    Episode_Reward/rotating_object: 161.8769
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.97s
                      Time elapsed: 00:53:03
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 45919 steps/s (collection: 1.970s, learning 0.171s)
             Mean action noise std: 3.90
          Mean value_function loss: 28.8800
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 58.8648
                       Mean reward: 810.53
               Mean episode length: 242.57
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 160.7629
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.14s
                      Time elapsed: 00:53:05
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 46009 steps/s (collection: 1.964s, learning 0.172s)
             Mean action noise std: 3.91
          Mean value_function loss: 22.1836
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 58.8735
                       Mean reward: 827.88
               Mean episode length: 246.18
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 165.8142
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.14s
                      Time elapsed: 00:53:07
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 44841 steps/s (collection: 2.001s, learning 0.192s)
             Mean action noise std: 3.91
          Mean value_function loss: 28.8673
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 58.8795
                       Mean reward: 813.06
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 1.2362
    Episode_Reward/rotating_object: 161.3588
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.19s
                      Time elapsed: 00:53:09
                               ETA: 00:01:09

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 47606 steps/s (collection: 1.906s, learning 0.159s)
             Mean action noise std: 3.91
          Mean value_function loss: 20.3954
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 58.8880
                       Mean reward: 809.33
               Mean episode length: 242.60
    Episode_Reward/reaching_object: 1.2593
    Episode_Reward/rotating_object: 164.2079
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.06s
                      Time elapsed: 00:53:11
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 43796 steps/s (collection: 2.140s, learning 0.105s)
             Mean action noise std: 3.91
          Mean value_function loss: 36.2683
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 58.9003
                       Mean reward: 789.10
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 161.7911
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.24s
                      Time elapsed: 00:53:13
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 48216 steps/s (collection: 1.938s, learning 0.101s)
             Mean action noise std: 3.91
          Mean value_function loss: 28.7558
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 58.9171
                       Mean reward: 806.82
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 1.2331
    Episode_Reward/rotating_object: 158.8702
        Episode_Reward/action_rate: -0.0837
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.04s
                      Time elapsed: 00:53:15
                               ETA: 00:01:02

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 45286 steps/s (collection: 2.068s, learning 0.102s)
             Mean action noise std: 3.92
          Mean value_function loss: 23.2656
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.9266
                       Mean reward: 800.16
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 1.2621
    Episode_Reward/rotating_object: 162.1883
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.17s
                      Time elapsed: 00:53:18
                               ETA: 00:01:00

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 47857 steps/s (collection: 1.931s, learning 0.123s)
             Mean action noise std: 3.92
          Mean value_function loss: 28.2320
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 58.9353
                       Mean reward: 811.05
               Mean episode length: 241.99
    Episode_Reward/reaching_object: 1.2454
    Episode_Reward/rotating_object: 159.7160
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.05s
                      Time elapsed: 00:53:20
                               ETA: 00:00:58

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 50552 steps/s (collection: 1.833s, learning 0.112s)
             Mean action noise std: 3.92
          Mean value_function loss: 22.7648
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 58.9408
                       Mean reward: 821.18
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 1.2701
    Episode_Reward/rotating_object: 163.6237
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.94s
                      Time elapsed: 00:53:22
                               ETA: 00:00:56

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 48335 steps/s (collection: 1.902s, learning 0.132s)
             Mean action noise std: 3.92
          Mean value_function loss: 23.3547
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 58.9447
                       Mean reward: 817.91
               Mean episode length: 246.32
    Episode_Reward/reaching_object: 1.2494
    Episode_Reward/rotating_object: 160.3730
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.03s
                      Time elapsed: 00:53:24
                               ETA: 00:00:54

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 49364 steps/s (collection: 1.828s, learning 0.163s)
             Mean action noise std: 3.92
          Mean value_function loss: 25.4402
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 58.9544
                       Mean reward: 839.40
               Mean episode length: 248.48
    Episode_Reward/reaching_object: 1.2595
    Episode_Reward/rotating_object: 163.9794
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 19.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.99s
                      Time elapsed: 00:53:26
                               ETA: 00:00:52

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 50142 steps/s (collection: 1.856s, learning 0.104s)
             Mean action noise std: 3.93
          Mean value_function loss: 36.8143
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 58.9741
                       Mean reward: 797.47
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 159.4623
        Episode_Reward/action_rate: -0.0840
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.96s
                      Time elapsed: 00:53:28
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 51675 steps/s (collection: 1.793s, learning 0.109s)
             Mean action noise std: 3.93
          Mean value_function loss: 31.4542
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 58.9897
                       Mean reward: 830.51
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 163.4783
        Episode_Reward/action_rate: -0.0857
          Episode_Reward/joint_vel: -0.0197
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.90s
                      Time elapsed: 00:53:29
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 52001 steps/s (collection: 1.755s, learning 0.135s)
             Mean action noise std: 3.93
          Mean value_function loss: 39.6404
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 58.9982
                       Mean reward: 789.21
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 156.8425
        Episode_Reward/action_rate: -0.0830
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.89s
                      Time elapsed: 00:53:31
                               ETA: 00:00:45

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 51790 steps/s (collection: 1.778s, learning 0.120s)
             Mean action noise std: 3.93
          Mean value_function loss: 29.3229
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.0096
                       Mean reward: 814.77
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.2320
    Episode_Reward/rotating_object: 161.4181
        Episode_Reward/action_rate: -0.0846
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.90s
                      Time elapsed: 00:53:33
                               ETA: 00:00:43

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 50526 steps/s (collection: 1.822s, learning 0.124s)
             Mean action noise std: 3.93
          Mean value_function loss: 30.9010
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 59.0241
                       Mean reward: 824.98
               Mean episode length: 244.00
    Episode_Reward/reaching_object: 1.2446
    Episode_Reward/rotating_object: 163.8137
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.95s
                      Time elapsed: 00:53:35
                               ETA: 00:00:41

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 51725 steps/s (collection: 1.799s, learning 0.102s)
             Mean action noise std: 3.94
          Mean value_function loss: 25.0961
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.0374
                       Mean reward: 796.27
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 160.9733
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.90s
                      Time elapsed: 00:53:37
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 48552 steps/s (collection: 1.799s, learning 0.226s)
             Mean action noise std: 3.94
          Mean value_function loss: 34.7672
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 59.0495
                       Mean reward: 813.39
               Mean episode length: 244.91
    Episode_Reward/reaching_object: 1.2334
    Episode_Reward/rotating_object: 160.1784
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.02s
                      Time elapsed: 00:53:39
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 42597 steps/s (collection: 2.149s, learning 0.159s)
             Mean action noise std: 3.94
          Mean value_function loss: 23.5960
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.0603
                       Mean reward: 797.20
               Mean episode length: 238.04
    Episode_Reward/reaching_object: 1.2566
    Episode_Reward/rotating_object: 164.6068
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.31s
                      Time elapsed: 00:53:41
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 45203 steps/s (collection: 1.979s, learning 0.196s)
             Mean action noise std: 3.94
          Mean value_function loss: 21.1446
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 59.0681
                       Mean reward: 822.05
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 162.5317
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.17s
                      Time elapsed: 00:53:44
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 48954 steps/s (collection: 1.910s, learning 0.098s)
             Mean action noise std: 3.94
          Mean value_function loss: 25.9671
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 59.0721
                       Mean reward: 812.13
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 1.2392
    Episode_Reward/rotating_object: 162.3470
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.01s
                      Time elapsed: 00:53:46
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 44673 steps/s (collection: 2.045s, learning 0.155s)
             Mean action noise std: 3.94
          Mean value_function loss: 28.0955
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.0772
                       Mean reward: 817.65
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.2568
    Episode_Reward/rotating_object: 164.1889
        Episode_Reward/action_rate: -0.0866
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.20s
                      Time elapsed: 00:53:48
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 44788 steps/s (collection: 2.035s, learning 0.160s)
             Mean action noise std: 3.95
          Mean value_function loss: 27.4569
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.0875
                       Mean reward: 817.32
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 1.2437
    Episode_Reward/rotating_object: 162.9697
        Episode_Reward/action_rate: -0.0863
          Episode_Reward/joint_vel: -0.0205
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.19s
                      Time elapsed: 00:53:50
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 43602 steps/s (collection: 2.047s, learning 0.208s)
             Mean action noise std: 3.95
          Mean value_function loss: 22.6131
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 59.1000
                       Mean reward: 826.36
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 1.2329
    Episode_Reward/rotating_object: 161.0006
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.25s
                      Time elapsed: 00:53:52
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 43391 steps/s (collection: 2.072s, learning 0.194s)
             Mean action noise std: 3.95
          Mean value_function loss: 32.8310
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 59.1076
                       Mean reward: 812.68
               Mean episode length: 241.81
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 161.4034
        Episode_Reward/action_rate: -0.0856
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.27s
                      Time elapsed: 00:53:55
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 43443 steps/s (collection: 2.142s, learning 0.121s)
             Mean action noise std: 3.95
          Mean value_function loss: 25.3380
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 59.1136
                       Mean reward: 829.09
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 161.6782
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.26s
                      Time elapsed: 00:53:57
                               ETA: 00:00:19

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 44938 steps/s (collection: 1.976s, learning 0.211s)
             Mean action noise std: 3.95
          Mean value_function loss: 20.9582
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 59.1191
                       Mean reward: 837.13
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 1.2582
    Episode_Reward/rotating_object: 164.2077
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.19s
                      Time elapsed: 00:53:59
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 43959 steps/s (collection: 2.082s, learning 0.155s)
             Mean action noise std: 3.96
          Mean value_function loss: 24.8132
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 59.1241
                       Mean reward: 818.68
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 162.1477
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0198
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.24s
                      Time elapsed: 00:54:01
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 50408 steps/s (collection: 1.806s, learning 0.144s)
             Mean action noise std: 3.96
          Mean value_function loss: 21.2176
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 59.1305
                       Mean reward: 835.55
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 1.2511
    Episode_Reward/rotating_object: 163.1953
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.95s
                      Time elapsed: 00:54:03
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 48016 steps/s (collection: 1.880s, learning 0.168s)
             Mean action noise std: 3.96
          Mean value_function loss: 18.6561
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 59.1370
                       Mean reward: 845.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2638
    Episode_Reward/rotating_object: 165.3051
        Episode_Reward/action_rate: -0.0875
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.05s
                      Time elapsed: 00:54:05
                               ETA: 00:00:10

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 48779 steps/s (collection: 1.842s, learning 0.174s)
             Mean action noise std: 3.96
          Mean value_function loss: 16.1561
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 59.1424
                       Mean reward: 828.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 1.2586
    Episode_Reward/rotating_object: 162.6490
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.02s
                      Time elapsed: 00:54:07
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 49584 steps/s (collection: 1.807s, learning 0.175s)
             Mean action noise std: 3.96
          Mean value_function loss: 18.8607
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 59.1475
                       Mean reward: 815.00
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 1.2601
    Episode_Reward/rotating_object: 164.4008
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.98s
                      Time elapsed: 00:54:09
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 50097 steps/s (collection: 1.814s, learning 0.148s)
             Mean action noise std: 3.97
          Mean value_function loss: 28.4886
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.1545
                       Mean reward: 810.12
               Mean episode length: 241.39
    Episode_Reward/reaching_object: 1.2435
    Episode_Reward/rotating_object: 162.3755
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.96s
                      Time elapsed: 00:54:11
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 44133 steps/s (collection: 2.045s, learning 0.182s)
             Mean action noise std: 3.97
          Mean value_function loss: 40.0904
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 59.1658
                       Mean reward: 801.41
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 160.4180
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.23s
                      Time elapsed: 00:54:13
                               ETA: 00:00:02

