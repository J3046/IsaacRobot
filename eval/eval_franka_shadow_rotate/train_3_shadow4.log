################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 22681 steps/s (collection: 4.213s, learning 0.121s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0048
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 36.9275
                       Mean reward: 0.00
               Mean episode length: 21.31
    Episode_Reward/reaching_object: 0.0009
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 4.33s
                      Time elapsed: 00:00:04
                               ETA: 01:48:21

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 52508 steps/s (collection: 1.760s, learning 0.112s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 37.0545
                       Mean reward: 0.00
               Mean episode length: 45.35
    Episode_Reward/reaching_object: 0.0028
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0008
          Episode_Reward/joint_vel: -0.0011
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 1.87s
                      Time elapsed: 00:00:06
                               ETA: 01:17:31

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 52275 steps/s (collection: 1.767s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.1482
                       Mean reward: 0.01
               Mean episode length: 69.71
    Episode_Reward/reaching_object: 0.0050
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0013
          Episode_Reward/joint_vel: -0.0018
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 1.88s
                      Time elapsed: 00:00:08
                               ETA: 01:07:17

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 51655 steps/s (collection: 1.789s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.1905
                       Mean reward: 0.02
               Mean episode length: 93.33
    Episode_Reward/reaching_object: 0.0076
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0018
          Episode_Reward/joint_vel: -0.0025
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 1.90s
                      Time elapsed: 00:00:09
                               ETA: 01:02:18

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 52528 steps/s (collection: 1.758s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.2335
                       Mean reward: 0.03
               Mean episode length: 117.98
    Episode_Reward/reaching_object: 0.0111
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0033
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 1.87s
                      Time elapsed: 00:00:11
                               ETA: 00:59:08

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 53309 steps/s (collection: 1.730s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 37.2699
                       Mean reward: 0.04
               Mean episode length: 141.18
    Episode_Reward/reaching_object: 0.0142
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0028
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 1.84s
                      Time elapsed: 00:00:13
                               ETA: 00:56:54

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 50885 steps/s (collection: 1.801s, learning 0.131s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 37.2928
                       Mean reward: 0.07
               Mean episode length: 165.30
    Episode_Reward/reaching_object: 0.0195
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 1.93s
                      Time elapsed: 00:00:15
                               ETA: 00:55:37

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 50141 steps/s (collection: 1.849s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 37.3390
                       Mean reward: 0.10
               Mean episode length: 189.28
    Episode_Reward/reaching_object: 0.0252
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 1.96s
                      Time elapsed: 00:00:17
                               ETA: 00:54:44

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 52722 steps/s (collection: 1.753s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 37.3709
                       Mean reward: 0.13
               Mean episode length: 213.34
    Episode_Reward/reaching_object: 0.0333
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0044
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 1.86s
                      Time elapsed: 00:00:19
                               ETA: 00:53:46

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 53722 steps/s (collection: 1.719s, learning 0.111s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.4187
                       Mean reward: 0.19
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 0.0474
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.83s
                      Time elapsed: 00:00:21
                               ETA: 00:52:54

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 53798 steps/s (collection: 1.716s, learning 0.112s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 37.4376
                       Mean reward: 0.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0601
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.83s
                      Time elapsed: 00:00:23
                               ETA: 00:52:11

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 53750 steps/s (collection: 1.718s, learning 0.111s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 37.4692
                       Mean reward: 0.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0719
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.83s
                      Time elapsed: 00:00:24
                               ETA: 00:51:35

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 52438 steps/s (collection: 1.760s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0012
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 37.5379
                       Mean reward: 0.36
               Mean episode length: 249.85
    Episode_Reward/reaching_object: 0.0842
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.87s
                      Time elapsed: 00:00:26
                               ETA: 00:51:10

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 51982 steps/s (collection: 1.780s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0018
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 37.5771
                       Mean reward: 0.49
               Mean episode length: 249.37
    Episode_Reward/reaching_object: 0.1133
    Episode_Reward/rotating_object: 0.0013
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.89s
                      Time elapsed: 00:00:28
                               ETA: 00:50:49

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 49582 steps/s (collection: 1.871s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0030
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 37.6259
                       Mean reward: 0.62
               Mean episode length: 249.24
    Episode_Reward/reaching_object: 0.1324
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.98s
                      Time elapsed: 00:00:30
                               ETA: 00:50:41

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 49847 steps/s (collection: 1.861s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0045
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.6869
                       Mean reward: 0.82
               Mean episode length: 247.48
    Episode_Reward/reaching_object: 0.1717
    Episode_Reward/rotating_object: 0.0005
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.97s
                      Time elapsed: 00:00:32
                               ETA: 00:50:32

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 47910 steps/s (collection: 1.940s, learning 0.112s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0075
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 37.7560
                       Mean reward: 0.96
               Mean episode length: 244.85
    Episode_Reward/reaching_object: 0.2179
    Episode_Reward/rotating_object: 0.0012
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 2.05s
                      Time elapsed: 00:00:34
                               ETA: 00:50:30

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 47793 steps/s (collection: 1.944s, learning 0.113s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0130
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 37.8087
                       Mean reward: 1.25
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.2332
    Episode_Reward/rotating_object: 0.0032
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.1250
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 2.06s
                      Time elapsed: 00:00:36
                               ETA: 00:50:30

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 46533 steps/s (collection: 1.996s, learning 0.116s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0071
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 37.8766
                       Mean reward: 1.43
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.2704
    Episode_Reward/rotating_object: 0.0028
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 9.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.6667
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 2.11s
                      Time elapsed: 00:00:38
                               ETA: 00:50:33

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 47102 steps/s (collection: 1.973s, learning 0.114s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0103
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 37.9929
                       Mean reward: 1.58
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 0.2984
    Episode_Reward/rotating_object: 0.0043
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 8.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.6667
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 2.09s
                      Time elapsed: 00:00:40
                               ETA: 00:50:34

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 45666 steps/s (collection: 2.042s, learning 0.111s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0070
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 38.0636
                       Mean reward: 1.74
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 0.3189
    Episode_Reward/rotating_object: 0.0077
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 5.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.2917
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 2.15s
                      Time elapsed: 00:00:43
                               ETA: 00:50:39

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 46296 steps/s (collection: 2.010s, learning 0.114s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0082
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 38.1053
                       Mean reward: 1.96
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 0.3551
    Episode_Reward/rotating_object: 0.0169
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 6.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.3750
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 2.12s
                      Time elapsed: 00:00:45
                               ETA: 00:50:42

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 46311 steps/s (collection: 2.010s, learning 0.112s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0110
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 38.2302
                       Mean reward: 1.89
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 0.3703
    Episode_Reward/rotating_object: 0.0202
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 4.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 12.3333
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 2.12s
                      Time elapsed: 00:00:47
                               ETA: 00:50:44

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 44949 steps/s (collection: 2.073s, learning 0.114s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0107
               Mean surrogate loss: -0.0107
                 Mean entropy loss: 38.3079
                       Mean reward: 2.28
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 0.4132
    Episode_Reward/rotating_object: 0.0244
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 4.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.1667
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 2.19s
                      Time elapsed: 00:00:49
                               ETA: 00:50:50

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 45678 steps/s (collection: 2.041s, learning 0.111s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0167
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 38.3893
                       Mean reward: 2.22
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 0.4342
    Episode_Reward/rotating_object: 0.0242
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 5.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 2.15s
                      Time elapsed: 00:00:51
                               ETA: 00:50:53

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 44569 steps/s (collection: 2.094s, learning 0.111s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0322
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 38.4937
                       Mean reward: 2.61
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 0.4801
    Episode_Reward/rotating_object: 0.0371
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 6.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 2.21s
                      Time elapsed: 00:00:53
                               ETA: 00:50:58

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 45032 steps/s (collection: 2.071s, learning 0.112s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0397
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 38.5909
                       Mean reward: 2.88
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 0.5211
    Episode_Reward/rotating_object: 0.0837
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 7.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.8750
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 2.18s
                      Time elapsed: 00:00:56
                               ETA: 00:51:02

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 44405 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0256
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 38.7419
                       Mean reward: 3.10
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 0.5712
    Episode_Reward/rotating_object: 0.0857
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 10.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.8333
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 2.21s
                      Time elapsed: 00:00:58
                               ETA: 00:51:07

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 43866 steps/s (collection: 2.126s, learning 0.115s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0678
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 38.8196
                       Mean reward: 3.46
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 0.6084
    Episode_Reward/rotating_object: 0.0935
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 2.24s
                      Time elapsed: 00:01:00
                               ETA: 00:51:13

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 44034 steps/s (collection: 2.118s, learning 0.115s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.2609
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.9173
                       Mean reward: 3.60
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 0.6119
    Episode_Reward/rotating_object: 0.1018
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.23s
                      Time elapsed: 00:01:02
                               ETA: 00:51:18

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 43394 steps/s (collection: 2.154s, learning 0.112s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3409
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 38.9749
                       Mean reward: 4.94
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 0.6716
    Episode_Reward/rotating_object: 0.1452
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 2.27s
                      Time elapsed: 00:01:05
                               ETA: 00:51:24

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 43821 steps/s (collection: 2.129s, learning 0.114s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3141
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 39.1243
                       Mean reward: 5.15
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 0.7053
    Episode_Reward/rotating_object: 0.2409
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.24s
                      Time elapsed: 00:01:07
                               ETA: 00:51:29

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 43306 steps/s (collection: 2.159s, learning 0.111s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5511
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 39.2434
                       Mean reward: 5.06
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 0.7615
    Episode_Reward/rotating_object: 0.2224
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 11.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 2.27s
                      Time elapsed: 00:01:09
                               ETA: 00:51:34

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 43296 steps/s (collection: 2.158s, learning 0.113s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.8621
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.4361
                       Mean reward: 7.09
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 0.8219
    Episode_Reward/rotating_object: 0.4300
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 2.27s
                      Time elapsed: 00:01:11
                               ETA: 00:51:39

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 42647 steps/s (collection: 2.185s, learning 0.120s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.9322
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.6156
                       Mean reward: 8.86
               Mean episode length: 233.41
    Episode_Reward/reaching_object: 0.8738
    Episode_Reward/rotating_object: 0.6214
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 2.31s
                      Time elapsed: 00:01:14
                               ETA: 00:51:45

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 42583 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.8189
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.7693
                       Mean reward: 5.66
               Mean episode length: 235.18
    Episode_Reward/reaching_object: 0.8629
    Episode_Reward/rotating_object: 0.3765
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 2.31s
                      Time elapsed: 00:01:16
                               ETA: 00:51:51

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 43710 steps/s (collection: 2.138s, learning 0.111s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.8719
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 39.8997
                       Mean reward: 8.56
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 0.9765
    Episode_Reward/rotating_object: 0.8204
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.25s
                      Time elapsed: 00:01:18
                               ETA: 00:51:54

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 43890 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.9617
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 40.0087
                       Mean reward: 8.09
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 0.9580
    Episode_Reward/rotating_object: 0.5626
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.24s
                      Time elapsed: 00:01:20
                               ETA: 00:51:56

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 43682 steps/s (collection: 2.138s, learning 0.112s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.4282
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 40.1188
                       Mean reward: 8.54
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 1.0265
    Episode_Reward/rotating_object: 0.7549
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 2.25s
                      Time elapsed: 00:01:23
                               ETA: 00:51:58

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 43605 steps/s (collection: 2.135s, learning 0.120s)
             Mean action noise std: 1.14
          Mean value_function loss: 1.3608
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 40.2454
                       Mean reward: 9.23
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 1.0297
    Episode_Reward/rotating_object: 0.6521
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0119
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.25s
                      Time elapsed: 00:01:25
                               ETA: 00:52:00

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 39686 steps/s (collection: 2.350s, learning 0.127s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.7059
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.3965
                       Mean reward: 10.12
               Mean episode length: 247.36
    Episode_Reward/reaching_object: 1.0441
    Episode_Reward/rotating_object: 0.9451
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0121
      Episode_Termination/time_out: 18.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.48s
                      Time elapsed: 00:01:27
                               ETA: 00:52:10

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 38409 steps/s (collection: 2.430s, learning 0.129s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.3532
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.4361
                       Mean reward: 9.43
               Mean episode length: 245.08
    Episode_Reward/reaching_object: 1.0542
    Episode_Reward/rotating_object: 1.0606
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 2.56s
                      Time elapsed: 00:01:30
                               ETA: 00:52:23

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 40883 steps/s (collection: 2.278s, learning 0.126s)
             Mean action noise std: 1.15
          Mean value_function loss: 1.9487
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.5287
                       Mean reward: 13.53
               Mean episode length: 246.94
    Episode_Reward/reaching_object: 1.0531
    Episode_Reward/rotating_object: 1.2559
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.40s
                      Time elapsed: 00:01:32
                               ETA: 00:52:29

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 39582 steps/s (collection: 2.356s, learning 0.127s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.6314
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.6507
                       Mean reward: 11.06
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 1.0270
    Episode_Reward/rotating_object: 1.3119
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.48s
                      Time elapsed: 00:01:35
                               ETA: 00:52:38

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 40241 steps/s (collection: 2.317s, learning 0.126s)
             Mean action noise std: 1.16
          Mean value_function loss: 1.4257
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.7623
                       Mean reward: 16.58
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 1.0475
    Episode_Reward/rotating_object: 1.4075
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.44s
                      Time elapsed: 00:01:37
                               ETA: 00:52:44

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 43111 steps/s (collection: 2.169s, learning 0.111s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.7427
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.8476
                       Mean reward: 12.27
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 1.0045
    Episode_Reward/rotating_object: 1.3860
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0123
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.28s
                      Time elapsed: 00:01:40
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 43021 steps/s (collection: 2.172s, learning 0.113s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.3685
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 40.8873
                       Mean reward: 8.63
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 1.0344
    Episode_Reward/rotating_object: 1.0365
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.28s
                      Time elapsed: 00:01:42
                               ETA: 00:52:47

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 43509 steps/s (collection: 2.144s, learning 0.116s)
             Mean action noise std: 1.17
          Mean value_function loss: 2.8290
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.9596
                       Mean reward: 8.48
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.0192
    Episode_Reward/rotating_object: 1.2707
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.26s
                      Time elapsed: 00:01:44
                               ETA: 00:52:47

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 43279 steps/s (collection: 2.160s, learning 0.111s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.8362
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.0887
                       Mean reward: 16.89
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.0214
    Episode_Reward/rotating_object: 1.4613
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0127
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.27s
                      Time elapsed: 00:01:46
                               ETA: 00:52:48

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 43228 steps/s (collection: 2.161s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 2.3944
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.2169
                       Mean reward: 15.15
               Mean episode length: 247.11
    Episode_Reward/reaching_object: 0.9929
    Episode_Reward/rotating_object: 1.7241
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.27s
                      Time elapsed: 00:01:49
                               ETA: 00:52:48

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 43366 steps/s (collection: 2.153s, learning 0.114s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.3124
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 41.3080
                       Mean reward: 17.52
               Mean episode length: 249.67
    Episode_Reward/reaching_object: 1.0190
    Episode_Reward/rotating_object: 1.6636
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.27s
                      Time elapsed: 00:01:51
                               ETA: 00:52:48

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 43468 steps/s (collection: 2.148s, learning 0.113s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.0533
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 41.3338
                       Mean reward: 13.46
               Mean episode length: 247.45
    Episode_Reward/reaching_object: 1.0593
    Episode_Reward/rotating_object: 1.6575
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0132
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.26s
                      Time elapsed: 00:01:53
                               ETA: 00:52:48

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 43152 steps/s (collection: 2.164s, learning 0.114s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.0852
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.3935
                       Mean reward: 9.25
               Mean episode length: 248.73
    Episode_Reward/reaching_object: 1.0272
    Episode_Reward/rotating_object: 1.1120
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.28s
                      Time elapsed: 00:01:55
                               ETA: 00:52:48

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 44087 steps/s (collection: 2.119s, learning 0.111s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.1569
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.4690
                       Mean reward: 16.34
               Mean episode length: 249.08
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 2.0115
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0134
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.23s
                      Time elapsed: 00:01:58
                               ETA: 00:52:47

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 44038 steps/s (collection: 2.121s, learning 0.111s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.6193
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.5860
                       Mean reward: 11.91
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 1.0277
    Episode_Reward/rotating_object: 1.4727
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0136
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.23s
                      Time elapsed: 00:02:00
                               ETA: 00:52:46

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 44290 steps/s (collection: 2.109s, learning 0.111s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.7030
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.6484
                       Mean reward: 8.99
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.0359
    Episode_Reward/rotating_object: 1.5065
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.22s
                      Time elapsed: 00:02:02
                               ETA: 00:52:45

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 44183 steps/s (collection: 2.114s, learning 0.111s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.1635
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.7527
                       Mean reward: 11.41
               Mean episode length: 246.53
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 1.3743
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0137
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.22s
                      Time elapsed: 00:02:04
                               ETA: 00:52:44

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 44295 steps/s (collection: 2.104s, learning 0.115s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.2203
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.8842
                       Mean reward: 14.13
               Mean episode length: 249.13
    Episode_Reward/reaching_object: 1.0548
    Episode_Reward/rotating_object: 2.0781
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0138
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.22s
                      Time elapsed: 00:02:07
                               ETA: 00:52:42

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 43714 steps/s (collection: 2.138s, learning 0.111s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.3803
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.9661
                       Mean reward: 16.52
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 1.0262
    Episode_Reward/rotating_object: 1.6977
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0140
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.25s
                      Time elapsed: 00:02:09
                               ETA: 00:52:41

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 43360 steps/s (collection: 2.156s, learning 0.111s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.7323
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.0509
                       Mean reward: 14.26
               Mean episode length: 247.61
    Episode_Reward/reaching_object: 1.0391
    Episode_Reward/rotating_object: 2.2209
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0143
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.27s
                      Time elapsed: 00:02:11
                               ETA: 00:52:41

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 43468 steps/s (collection: 2.148s, learning 0.113s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.5682
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.1503
                       Mean reward: 17.75
               Mean episode length: 246.41
    Episode_Reward/reaching_object: 1.0234
    Episode_Reward/rotating_object: 1.5459
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0145
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.26s
                      Time elapsed: 00:02:13
                               ETA: 00:52:40

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 43388 steps/s (collection: 2.150s, learning 0.115s)
             Mean action noise std: 1.23
          Mean value_function loss: 4.0108
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.2411
                       Mean reward: 15.72
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 1.7429
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0146
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.27s
                      Time elapsed: 00:02:16
                               ETA: 00:52:40

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 43574 steps/s (collection: 2.145s, learning 0.111s)
             Mean action noise std: 1.23
          Mean value_function loss: 3.4114
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.2994
                       Mean reward: 16.31
               Mean episode length: 245.29
    Episode_Reward/reaching_object: 1.0544
    Episode_Reward/rotating_object: 2.1489
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0149
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.26s
                      Time elapsed: 00:02:18
                               ETA: 00:52:39

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 43659 steps/s (collection: 2.141s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 3.2482
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 42.3937
                       Mean reward: 17.16
               Mean episode length: 246.80
    Episode_Reward/reaching_object: 1.0244
    Episode_Reward/rotating_object: 2.1922
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.25s
                      Time elapsed: 00:02:20
                               ETA: 00:52:38

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 43599 steps/s (collection: 2.142s, learning 0.113s)
             Mean action noise std: 1.24
          Mean value_function loss: 3.6134
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.4496
                       Mean reward: 22.31
               Mean episode length: 243.59
    Episode_Reward/reaching_object: 1.0432
    Episode_Reward/rotating_object: 2.6140
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.25s
                      Time elapsed: 00:02:22
                               ETA: 00:52:37

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 44094 steps/s (collection: 2.115s, learning 0.114s)
             Mean action noise std: 1.24
          Mean value_function loss: 3.5149
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 42.5067
                       Mean reward: 23.28
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.0487
    Episode_Reward/rotating_object: 3.2264
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.23s
                      Time elapsed: 00:02:25
                               ETA: 00:52:35

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 43362 steps/s (collection: 2.154s, learning 0.113s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.0542
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6008
                       Mean reward: 24.91
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 1.0310
    Episode_Reward/rotating_object: 2.9051
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.27s
                      Time elapsed: 00:02:27
                               ETA: 00:52:35

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 44154 steps/s (collection: 2.111s, learning 0.115s)
             Mean action noise std: 1.25
          Mean value_function loss: 4.3273
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 42.7030
                       Mean reward: 22.23
               Mean episode length: 248.44
    Episode_Reward/reaching_object: 0.9991
    Episode_Reward/rotating_object: 2.4194
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.23s
                      Time elapsed: 00:02:29
                               ETA: 00:52:33

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 44609 steps/s (collection: 2.093s, learning 0.111s)
             Mean action noise std: 1.26
          Mean value_function loss: 5.1846
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.7924
                       Mean reward: 17.89
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 1.0048
    Episode_Reward/rotating_object: 2.7034
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0156
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.20s
                      Time elapsed: 00:02:31
                               ETA: 00:52:31

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 44149 steps/s (collection: 2.111s, learning 0.115s)
             Mean action noise std: 1.26
          Mean value_function loss: 5.2677
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.8943
                       Mean reward: 29.24
               Mean episode length: 248.60
    Episode_Reward/reaching_object: 1.0377
    Episode_Reward/rotating_object: 3.2305
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.23s
                      Time elapsed: 00:02:34
                               ETA: 00:52:29

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 44411 steps/s (collection: 2.100s, learning 0.113s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.8528
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.9622
                       Mean reward: 20.81
               Mean episode length: 248.53
    Episode_Reward/reaching_object: 1.0215
    Episode_Reward/rotating_object: 3.0047
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0155
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.21s
                      Time elapsed: 00:02:36
                               ETA: 00:52:27

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 42905 steps/s (collection: 2.173s, learning 0.118s)
             Mean action noise std: 1.27
          Mean value_function loss: 6.0803
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.0250
                       Mean reward: 18.56
               Mean episode length: 247.23
    Episode_Reward/reaching_object: 0.9998
    Episode_Reward/rotating_object: 3.1103
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.29s
                      Time elapsed: 00:02:38
                               ETA: 00:52:27

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 43834 steps/s (collection: 2.131s, learning 0.111s)
             Mean action noise std: 1.27
          Mean value_function loss: 5.9302
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.1087
                       Mean reward: 26.48
               Mean episode length: 247.58
    Episode_Reward/reaching_object: 1.0372
    Episode_Reward/rotating_object: 4.1839
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0158
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.24s
                      Time elapsed: 00:02:40
                               ETA: 00:52:25

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 44191 steps/s (collection: 2.113s, learning 0.112s)
             Mean action noise std: 1.28
          Mean value_function loss: 5.9375
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 43.1760
                       Mean reward: 25.62
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 1.0125
    Episode_Reward/rotating_object: 4.2042
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.22s
                      Time elapsed: 00:02:43
                               ETA: 00:52:24

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 43434 steps/s (collection: 2.152s, learning 0.112s)
             Mean action noise std: 1.28
          Mean value_function loss: 6.8877
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 43.2658
                       Mean reward: 21.40
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 0.9978
    Episode_Reward/rotating_object: 3.8221
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0159
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.26s
                      Time elapsed: 00:02:45
                               ETA: 00:52:23

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 44650 steps/s (collection: 2.090s, learning 0.112s)
             Mean action noise std: 1.28
          Mean value_function loss: 8.1819
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.3413
                       Mean reward: 20.04
               Mean episode length: 246.90
    Episode_Reward/reaching_object: 0.9983
    Episode_Reward/rotating_object: 3.7177
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0161
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.20s
                      Time elapsed: 00:02:47
                               ETA: 00:52:20

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 44473 steps/s (collection: 2.099s, learning 0.111s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.4876
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.3952
                       Mean reward: 26.44
               Mean episode length: 244.81
    Episode_Reward/reaching_object: 1.0241
    Episode_Reward/rotating_object: 4.1342
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.21s
                      Time elapsed: 00:02:49
                               ETA: 00:52:18

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 44344 steps/s (collection: 2.105s, learning 0.112s)
             Mean action noise std: 1.29
          Mean value_function loss: 7.4007
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 43.4595
                       Mean reward: 30.51
               Mean episode length: 246.37
    Episode_Reward/reaching_object: 1.0535
    Episode_Reward/rotating_object: 5.7943
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.22s
                      Time elapsed: 00:02:51
                               ETA: 00:52:16

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 44451 steps/s (collection: 2.100s, learning 0.111s)
             Mean action noise std: 1.29
          Mean value_function loss: 8.3379
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 43.5147
                       Mean reward: 25.62
               Mean episode length: 246.95
    Episode_Reward/reaching_object: 1.0291
    Episode_Reward/rotating_object: 3.7552
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.21s
                      Time elapsed: 00:02:54
                               ETA: 00:52:14

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 44284 steps/s (collection: 2.104s, learning 0.116s)
             Mean action noise std: 1.29
          Mean value_function loss: 9.7957
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.5601
                       Mean reward: 25.33
               Mean episode length: 247.55
    Episode_Reward/reaching_object: 1.0218
    Episode_Reward/rotating_object: 3.1587
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.22s
                      Time elapsed: 00:02:56
                               ETA: 00:52:12

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 45027 steps/s (collection: 2.072s, learning 0.112s)
             Mean action noise std: 1.30
          Mean value_function loss: 10.0949
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 43.6003
                       Mean reward: 22.75
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 1.0428
    Episode_Reward/rotating_object: 4.2210
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.18s
                      Time elapsed: 00:02:58
                               ETA: 00:52:10

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 44007 steps/s (collection: 2.120s, learning 0.113s)
             Mean action noise std: 1.30
          Mean value_function loss: 9.7749
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 43.6788
                       Mean reward: 28.61
               Mean episode length: 246.86
    Episode_Reward/reaching_object: 1.0326
    Episode_Reward/rotating_object: 4.4662
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0169
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.23s
                      Time elapsed: 00:03:00
                               ETA: 00:52:08

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 43929 steps/s (collection: 2.123s, learning 0.115s)
             Mean action noise std: 1.31
          Mean value_function loss: 11.1436
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 43.7784
                       Mean reward: 31.23
               Mean episode length: 246.43
    Episode_Reward/reaching_object: 1.0273
    Episode_Reward/rotating_object: 4.5040
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.24s
                      Time elapsed: 00:03:03
                               ETA: 00:52:06

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 44147 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 11.2041
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 43.8449
                       Mean reward: 27.76
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.9817
    Episode_Reward/rotating_object: 4.7995
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.23s
                      Time elapsed: 00:03:05
                               ETA: 00:52:05

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 43522 steps/s (collection: 2.147s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.1856
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 43.8927
                       Mean reward: 33.92
               Mean episode length: 246.22
    Episode_Reward/reaching_object: 1.0115
    Episode_Reward/rotating_object: 5.8923
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0172
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.26s
                      Time elapsed: 00:03:07
                               ETA: 00:52:03

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 44370 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.0929
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.9423
                       Mean reward: 30.01
               Mean episode length: 243.66
    Episode_Reward/reaching_object: 1.0158
    Episode_Reward/rotating_object: 4.5873
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0171
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.22s
                      Time elapsed: 00:03:09
                               ETA: 00:52:01

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 43190 steps/s (collection: 2.161s, learning 0.115s)
             Mean action noise std: 1.31
          Mean value_function loss: 10.3367
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.9589
                       Mean reward: 31.87
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 1.0314
    Episode_Reward/rotating_object: 4.5764
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.28s
                      Time elapsed: 00:03:12
                               ETA: 00:52:00

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 43591 steps/s (collection: 2.144s, learning 0.111s)
             Mean action noise std: 1.32
          Mean value_function loss: 10.5961
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.9923
                       Mean reward: 43.23
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 1.0147
    Episode_Reward/rotating_object: 5.3721
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.26s
                      Time elapsed: 00:03:14
                               ETA: 00:51:59

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 44254 steps/s (collection: 2.109s, learning 0.112s)
             Mean action noise std: 1.32
          Mean value_function loss: 12.2341
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 44.0338
                       Mean reward: 35.93
               Mean episode length: 244.26
    Episode_Reward/reaching_object: 1.0340
    Episode_Reward/rotating_object: 4.8598
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.22s
                      Time elapsed: 00:03:16
                               ETA: 00:51:57

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 43659 steps/s (collection: 2.138s, learning 0.114s)
             Mean action noise std: 1.32
          Mean value_function loss: 12.8493
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.0922
                       Mean reward: 34.21
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 1.0227
    Episode_Reward/rotating_object: 5.2857
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0173
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.25s
                      Time elapsed: 00:03:18
                               ETA: 00:51:55

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 43828 steps/s (collection: 2.127s, learning 0.116s)
             Mean action noise std: 1.32
          Mean value_function loss: 13.3976
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.1377
                       Mean reward: 28.56
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 1.0054
    Episode_Reward/rotating_object: 4.5133
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.24s
                      Time elapsed: 00:03:20
                               ETA: 00:51:53

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 43813 steps/s (collection: 2.133s, learning 0.111s)
             Mean action noise std: 1.33
          Mean value_function loss: 12.7512
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 44.1784
                       Mean reward: 27.85
               Mean episode length: 246.07
    Episode_Reward/reaching_object: 1.0084
    Episode_Reward/rotating_object: 5.4498
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0175
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.24s
                      Time elapsed: 00:03:23
                               ETA: 00:51:52

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 43914 steps/s (collection: 2.127s, learning 0.112s)
             Mean action noise std: 1.33
          Mean value_function loss: 17.2777
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.2349
                       Mean reward: 34.84
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.0092
    Episode_Reward/rotating_object: 5.2299
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0176
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.24s
                      Time elapsed: 00:03:25
                               ETA: 00:51:50

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 44285 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 1.33
          Mean value_function loss: 16.9459
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.2985
                       Mean reward: 35.21
               Mean episode length: 246.96
    Episode_Reward/reaching_object: 1.0247
    Episode_Reward/rotating_object: 5.2843
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.22s
                      Time elapsed: 00:03:27
                               ETA: 00:51:48

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 43298 steps/s (collection: 2.156s, learning 0.114s)
             Mean action noise std: 1.34
          Mean value_function loss: 15.4033
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 44.3626
                       Mean reward: 36.79
               Mean episode length: 241.92
    Episode_Reward/reaching_object: 1.0087
    Episode_Reward/rotating_object: 6.2466
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.27s
                      Time elapsed: 00:03:29
                               ETA: 00:51:47

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 44012 steps/s (collection: 2.122s, learning 0.112s)
             Mean action noise std: 1.34
          Mean value_function loss: 16.1367
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.4156
                       Mean reward: 31.00
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 0.9796
    Episode_Reward/rotating_object: 5.4751
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0177
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.23s
                      Time elapsed: 00:03:32
                               ETA: 00:51:45

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 43769 steps/s (collection: 2.134s, learning 0.112s)
             Mean action noise std: 1.34
          Mean value_function loss: 16.3139
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 44.4677
                       Mean reward: 41.75
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.9876
    Episode_Reward/rotating_object: 6.9003
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.25s
                      Time elapsed: 00:03:34
                               ETA: 00:51:43

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 44310 steps/s (collection: 2.107s, learning 0.112s)
             Mean action noise std: 1.34
          Mean value_function loss: 15.9468
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.5210
                       Mean reward: 36.33
               Mean episode length: 242.34
    Episode_Reward/reaching_object: 0.9773
    Episode_Reward/rotating_object: 5.9788
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.22s
                      Time elapsed: 00:03:36
                               ETA: 00:51:41

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 44561 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 1.35
          Mean value_function loss: 15.9613
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.5692
                       Mean reward: 33.19
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 1.0019
    Episode_Reward/rotating_object: 5.3558
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0181
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.21s
                      Time elapsed: 00:03:38
                               ETA: 00:51:39

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 43866 steps/s (collection: 2.130s, learning 0.111s)
             Mean action noise std: 1.35
          Mean value_function loss: 17.2649
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.6155
                       Mean reward: 40.18
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 0.9857
    Episode_Reward/rotating_object: 6.7608
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.24s
                      Time elapsed: 00:03:41
                               ETA: 00:51:37

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 44787 steps/s (collection: 2.083s, learning 0.111s)
             Mean action noise std: 1.35
          Mean value_function loss: 20.4107
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 44.6536
                       Mean reward: 35.78
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 1.0249
    Episode_Reward/rotating_object: 6.6705
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.19s
                      Time elapsed: 00:03:43
                               ETA: 00:51:35

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 43472 steps/s (collection: 2.148s, learning 0.114s)
             Mean action noise std: 1.35
          Mean value_function loss: 18.2702
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 44.6870
                       Mean reward: 37.59
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 0.9984
    Episode_Reward/rotating_object: 5.9954
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0188
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.26s
                      Time elapsed: 00:03:45
                               ETA: 00:51:33

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 44513 steps/s (collection: 2.089s, learning 0.119s)
             Mean action noise std: 1.35
          Mean value_function loss: 19.0302
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 44.7283
                       Mean reward: 43.89
               Mean episode length: 245.65
    Episode_Reward/reaching_object: 0.9904
    Episode_Reward/rotating_object: 6.9815
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0190
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.21s
                      Time elapsed: 00:03:47
                               ETA: 00:51:31

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 44671 steps/s (collection: 2.087s, learning 0.114s)
             Mean action noise std: 1.36
          Mean value_function loss: 15.9020
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 44.7666
                       Mean reward: 39.21
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 6.6551
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.20s
                      Time elapsed: 00:03:49
                               ETA: 00:51:28

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 44058 steps/s (collection: 2.120s, learning 0.112s)
             Mean action noise std: 1.36
          Mean value_function loss: 15.9703
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 44.8083
                       Mean reward: 38.73
               Mean episode length: 246.92
    Episode_Reward/reaching_object: 1.0255
    Episode_Reward/rotating_object: 7.3181
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0191
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.23s
                      Time elapsed: 00:03:52
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 41387 steps/s (collection: 2.247s, learning 0.128s)
             Mean action noise std: 1.36
          Mean value_function loss: 17.7459
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.8514
                       Mean reward: 51.67
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 1.0151
    Episode_Reward/rotating_object: 7.8743
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.38s
                      Time elapsed: 00:03:54
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 41145 steps/s (collection: 2.260s, learning 0.129s)
             Mean action noise std: 1.36
          Mean value_function loss: 16.0528
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.8832
                       Mean reward: 30.89
               Mean episode length: 242.93
    Episode_Reward/reaching_object: 0.9830
    Episode_Reward/rotating_object: 7.0803
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.39s
                      Time elapsed: 00:03:56
                               ETA: 00:51:27

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 40919 steps/s (collection: 2.276s, learning 0.127s)
             Mean action noise std: 1.36
          Mean value_function loss: 15.4329
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.9181
                       Mean reward: 29.31
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.9675
    Episode_Reward/rotating_object: 7.4316
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.40s
                      Time elapsed: 00:03:59
                               ETA: 00:51:27

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 41517 steps/s (collection: 2.238s, learning 0.129s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.2304
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 44.9447
                       Mean reward: 52.36
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 0.9701
    Episode_Reward/rotating_object: 6.7262
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.37s
                      Time elapsed: 00:04:01
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 41099 steps/s (collection: 2.262s, learning 0.130s)
             Mean action noise std: 1.37
          Mean value_function loss: 18.2900
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 44.9739
                       Mean reward: 53.08
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 0.9517
    Episode_Reward/rotating_object: 7.3581
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.39s
                      Time elapsed: 00:04:04
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 41602 steps/s (collection: 2.242s, learning 0.121s)
             Mean action noise std: 1.37
          Mean value_function loss: 21.7258
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 45.0098
                       Mean reward: 41.89
               Mean episode length: 244.74
    Episode_Reward/reaching_object: 0.9137
    Episode_Reward/rotating_object: 7.2548
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.36s
                      Time elapsed: 00:04:06
                               ETA: 00:51:26

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 44970 steps/s (collection: 2.071s, learning 0.115s)
             Mean action noise std: 1.37
          Mean value_function loss: 17.6533
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.0545
                       Mean reward: 48.38
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.9664
    Episode_Reward/rotating_object: 9.7935
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.19s
                      Time elapsed: 00:04:08
                               ETA: 00:51:23

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 44403 steps/s (collection: 2.103s, learning 0.111s)
             Mean action noise std: 1.37
          Mean value_function loss: 18.0121
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.1000
                       Mean reward: 38.28
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 0.9424
    Episode_Reward/rotating_object: 8.9937
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0200
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.21s
                      Time elapsed: 00:04:10
                               ETA: 00:51:21

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 44707 steps/s (collection: 2.087s, learning 0.112s)
             Mean action noise std: 1.38
          Mean value_function loss: 19.4475
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.1512
                       Mean reward: 56.51
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 0.9527
    Episode_Reward/rotating_object: 8.9979
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.20s
                      Time elapsed: 00:04:13
                               ETA: 00:51:19

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 44379 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 17.2270
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.2110
                       Mean reward: 48.74
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 0.9290
    Episode_Reward/rotating_object: 8.2877
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.22s
                      Time elapsed: 00:04:15
                               ETA: 00:51:16

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 44093 steps/s (collection: 2.115s, learning 0.115s)
             Mean action noise std: 1.38
          Mean value_function loss: 16.3602
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.2550
                       Mean reward: 48.59
               Mean episode length: 242.73
    Episode_Reward/reaching_object: 0.8946
    Episode_Reward/rotating_object: 7.4864
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.23s
                      Time elapsed: 00:04:17
                               ETA: 00:51:14

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 44635 steps/s (collection: 2.091s, learning 0.111s)
             Mean action noise std: 1.38
          Mean value_function loss: 17.4926
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.2838
                       Mean reward: 47.20
               Mean episode length: 243.02
    Episode_Reward/reaching_object: 0.9174
    Episode_Reward/rotating_object: 9.4903
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.20s
                      Time elapsed: 00:04:19
                               ETA: 00:51:12

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 44393 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.39
          Mean value_function loss: 17.1382
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 45.3290
                       Mean reward: 52.59
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.9270
    Episode_Reward/rotating_object: 9.7841
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.21s
                      Time elapsed: 00:04:21
                               ETA: 00:51:09

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 46112 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 1.39
          Mean value_function loss: 19.7781
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.3970
                       Mean reward: 45.45
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.8938
    Episode_Reward/rotating_object: 8.5995
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.13s
                      Time elapsed: 00:04:24
                               ETA: 00:51:06

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 45401 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 1.39
          Mean value_function loss: 18.8365
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 45.4546
                       Mean reward: 46.13
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 0.9110
    Episode_Reward/rotating_object: 9.2124
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.17s
                      Time elapsed: 00:04:26
                               ETA: 00:51:03

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 45753 steps/s (collection: 2.037s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 19.5737
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.4969
                       Mean reward: 62.61
               Mean episode length: 242.92
    Episode_Reward/reaching_object: 0.9041
    Episode_Reward/rotating_object: 8.9230
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.15s
                      Time elapsed: 00:04:28
                               ETA: 00:51:00

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 45361 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 1.40
          Mean value_function loss: 19.3340
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.5391
                       Mean reward: 57.60
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 0.8797
    Episode_Reward/rotating_object: 9.0759
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.17s
                      Time elapsed: 00:04:30
                               ETA: 00:50:58

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 45316 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 1.40
          Mean value_function loss: 18.1672
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 45.5766
                       Mean reward: 41.64
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 0.8957
    Episode_Reward/rotating_object: 9.8338
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.17s
                      Time elapsed: 00:04:32
                               ETA: 00:50:55

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 45986 steps/s (collection: 2.027s, learning 0.111s)
             Mean action noise std: 1.40
          Mean value_function loss: 18.1618
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 45.6264
                       Mean reward: 47.81
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.8931
    Episode_Reward/rotating_object: 8.8671
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.14s
                      Time elapsed: 00:04:34
                               ETA: 00:50:52

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 45223 steps/s (collection: 2.063s, learning 0.110s)
             Mean action noise std: 1.41
          Mean value_function loss: 19.4794
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 45.6905
                       Mean reward: 58.23
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.9241
    Episode_Reward/rotating_object: 10.1050
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0214
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.17s
                      Time elapsed: 00:04:37
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 45526 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 1.41
          Mean value_function loss: 20.9640
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 45.7433
                       Mean reward: 33.17
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 0.8795
    Episode_Reward/rotating_object: 8.2644
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0218
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.16s
                      Time elapsed: 00:04:39
                               ETA: 00:50:46

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 44623 steps/s (collection: 2.092s, learning 0.111s)
             Mean action noise std: 1.41
          Mean value_function loss: 18.5183
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.7941
                       Mean reward: 47.35
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.9031
    Episode_Reward/rotating_object: 9.1930
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.20s
                      Time elapsed: 00:04:41
                               ETA: 00:50:44

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 44185 steps/s (collection: 2.113s, learning 0.112s)
             Mean action noise std: 1.42
          Mean value_function loss: 20.9395
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 45.8457
                       Mean reward: 44.60
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.8719
    Episode_Reward/rotating_object: 7.9734
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.22s
                      Time elapsed: 00:04:43
                               ETA: 00:50:42

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 44936 steps/s (collection: 2.074s, learning 0.114s)
             Mean action noise std: 1.42
          Mean value_function loss: 23.2321
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 45.9060
                       Mean reward: 60.99
               Mean episode length: 242.25
    Episode_Reward/reaching_object: 0.9166
    Episode_Reward/rotating_object: 10.4562
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0219
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.19s
                      Time elapsed: 00:04:45
                               ETA: 00:50:39

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 43538 steps/s (collection: 2.144s, learning 0.114s)
             Mean action noise std: 1.42
          Mean value_function loss: 26.8442
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 45.9567
                       Mean reward: 61.36
               Mean episode length: 239.98
    Episode_Reward/reaching_object: 0.9042
    Episode_Reward/rotating_object: 10.0984
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.26s
                      Time elapsed: 00:04:48
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 44894 steps/s (collection: 2.078s, learning 0.112s)
             Mean action noise std: 1.42
          Mean value_function loss: 31.3225
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 45.9958
                       Mean reward: 38.05
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.8784
    Episode_Reward/rotating_object: 7.4318
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0217
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.19s
                      Time elapsed: 00:04:50
                               ETA: 00:50:35

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 44091 steps/s (collection: 2.114s, learning 0.115s)
             Mean action noise std: 1.43
          Mean value_function loss: 28.9991
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.0389
                       Mean reward: 60.12
               Mean episode length: 241.68
    Episode_Reward/reaching_object: 0.9247
    Episode_Reward/rotating_object: 9.6004
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0215
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.23s
                      Time elapsed: 00:04:52
                               ETA: 00:50:33

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 44462 steps/s (collection: 2.098s, learning 0.113s)
             Mean action noise std: 1.43
          Mean value_function loss: 26.4891
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 46.0959
                       Mean reward: 53.67
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 0.9215
    Episode_Reward/rotating_object: 8.2586
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.21s
                      Time elapsed: 00:04:54
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 42255 steps/s (collection: 2.212s, learning 0.114s)
             Mean action noise std: 1.43
          Mean value_function loss: 23.5910
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 46.1326
                       Mean reward: 59.17
               Mean episode length: 243.98
    Episode_Reward/reaching_object: 0.9340
    Episode_Reward/rotating_object: 9.6610
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.33s
                      Time elapsed: 00:04:57
                               ETA: 00:50:30

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 41090 steps/s (collection: 2.278s, learning 0.114s)
             Mean action noise std: 1.43
          Mean value_function loss: 26.6355
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 46.1635
                       Mean reward: 56.40
               Mean episode length: 241.65
    Episode_Reward/reaching_object: 0.9185
    Episode_Reward/rotating_object: 9.7257
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.39s
                      Time elapsed: 00:04:59
                               ETA: 00:50:29

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 42263 steps/s (collection: 2.212s, learning 0.114s)
             Mean action noise std: 1.43
          Mean value_function loss: 24.7249
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 46.2030
                       Mean reward: 42.18
               Mean episode length: 243.75
    Episode_Reward/reaching_object: 0.9224
    Episode_Reward/rotating_object: 8.4483
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.33s
                      Time elapsed: 00:05:01
                               ETA: 00:50:28

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 44450 steps/s (collection: 2.097s, learning 0.115s)
             Mean action noise std: 1.44
          Mean value_function loss: 25.5480
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.2531
                       Mean reward: 50.03
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.9275
    Episode_Reward/rotating_object: 9.3110
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.21s
                      Time elapsed: 00:05:03
                               ETA: 00:50:26

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 44024 steps/s (collection: 2.120s, learning 0.113s)
             Mean action noise std: 1.44
          Mean value_function loss: 25.5081
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 46.2998
                       Mean reward: 58.69
               Mean episode length: 240.82
    Episode_Reward/reaching_object: 0.9332
    Episode_Reward/rotating_object: 11.1097
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.23s
                      Time elapsed: 00:05:06
                               ETA: 00:50:24

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 44717 steps/s (collection: 2.087s, learning 0.111s)
             Mean action noise std: 1.44
          Mean value_function loss: 24.8591
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 46.3420
                       Mean reward: 52.87
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.8896
    Episode_Reward/rotating_object: 8.8063
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.20s
                      Time elapsed: 00:05:08
                               ETA: 00:50:21

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 44036 steps/s (collection: 2.121s, learning 0.112s)
             Mean action noise std: 1.44
          Mean value_function loss: 26.1665
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.3838
                       Mean reward: 46.25
               Mean episode length: 240.61
    Episode_Reward/reaching_object: 0.8910
    Episode_Reward/rotating_object: 8.5063
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.23s
                      Time elapsed: 00:05:10
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 45640 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 1.45
          Mean value_function loss: 28.7239
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 46.4226
                       Mean reward: 76.26
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 0.9291
    Episode_Reward/rotating_object: 10.3592
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.15s
                      Time elapsed: 00:05:12
                               ETA: 00:50:16

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 45106 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 1.45
          Mean value_function loss: 25.2479
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 46.4729
                       Mean reward: 62.03
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.9263
    Episode_Reward/rotating_object: 10.8713
        Episode_Reward/action_rate: -0.0118
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.18s
                      Time elapsed: 00:05:14
                               ETA: 00:50:14

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 45278 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 25.8316
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.5492
                       Mean reward: 57.60
               Mean episode length: 244.55
    Episode_Reward/reaching_object: 0.9293
    Episode_Reward/rotating_object: 10.5323
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.17s
                      Time elapsed: 00:05:17
                               ETA: 00:50:11

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 45435 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 28.9921
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 46.6217
                       Mean reward: 58.79
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 0.9160
    Episode_Reward/rotating_object: 10.0106
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.16s
                      Time elapsed: 00:05:19
                               ETA: 00:50:08

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 45080 steps/s (collection: 2.070s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 27.4158
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 46.6613
                       Mean reward: 55.57
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 0.9341
    Episode_Reward/rotating_object: 9.6883
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.18s
                      Time elapsed: 00:05:21
                               ETA: 00:50:06

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 45724 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 25.8240
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 46.6973
                       Mean reward: 70.76
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 12.3285
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.15s
                      Time elapsed: 00:05:23
                               ETA: 00:50:03

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 44451 steps/s (collection: 2.098s, learning 0.113s)
             Mean action noise std: 1.46
          Mean value_function loss: 24.7433
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 46.7305
                       Mean reward: 39.42
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 0.9206
    Episode_Reward/rotating_object: 10.7940
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.21s
                      Time elapsed: 00:05:25
                               ETA: 00:50:01

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 43710 steps/s (collection: 2.138s, learning 0.111s)
             Mean action noise std: 1.47
          Mean value_function loss: 34.3129
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 46.7761
                       Mean reward: 56.21
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 0.8986
    Episode_Reward/rotating_object: 10.1797
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.25s
                      Time elapsed: 00:05:28
                               ETA: 00:49:59

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 43815 steps/s (collection: 2.126s, learning 0.117s)
             Mean action noise std: 1.47
          Mean value_function loss: 30.1367
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 46.8219
                       Mean reward: 48.42
               Mean episode length: 236.35
    Episode_Reward/reaching_object: 0.9038
    Episode_Reward/rotating_object: 9.9319
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.24s
                      Time elapsed: 00:05:30
                               ETA: 00:49:57

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 43079 steps/s (collection: 2.168s, learning 0.113s)
             Mean action noise std: 1.47
          Mean value_function loss: 31.2870
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 46.8552
                       Mean reward: 87.13
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 0.8994
    Episode_Reward/rotating_object: 11.4173
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.28s
                      Time elapsed: 00:05:32
                               ETA: 00:49:55

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 44476 steps/s (collection: 2.096s, learning 0.114s)
             Mean action noise std: 1.47
          Mean value_function loss: 30.7995
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 46.8784
                       Mean reward: 45.73
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 0.9029
    Episode_Reward/rotating_object: 10.8400
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.21s
                      Time elapsed: 00:05:34
                               ETA: 00:49:53

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 42919 steps/s (collection: 2.178s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 36.0248
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 46.9299
                       Mean reward: 69.24
               Mean episode length: 237.37
    Episode_Reward/reaching_object: 0.8768
    Episode_Reward/rotating_object: 10.5026
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.29s
                      Time elapsed: 00:05:37
                               ETA: 00:49:51

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 43746 steps/s (collection: 2.128s, learning 0.119s)
             Mean action noise std: 1.48
          Mean value_function loss: 32.1705
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 46.9756
                       Mean reward: 68.69
               Mean episode length: 238.06
    Episode_Reward/reaching_object: 0.9099
    Episode_Reward/rotating_object: 13.6143
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.25s
                      Time elapsed: 00:05:39
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 44141 steps/s (collection: 2.115s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 34.1521
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.0123
                       Mean reward: 46.16
               Mean episode length: 237.25
    Episode_Reward/reaching_object: 0.8927
    Episode_Reward/rotating_object: 10.5459
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.23s
                      Time elapsed: 00:05:41
                               ETA: 00:49:47

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 43807 steps/s (collection: 2.132s, learning 0.112s)
             Mean action noise std: 1.48
          Mean value_function loss: 36.1162
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.0447
                       Mean reward: 63.89
               Mean episode length: 229.59
    Episode_Reward/reaching_object: 0.8976
    Episode_Reward/rotating_object: 10.4240
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.24s
                      Time elapsed: 00:05:43
                               ETA: 00:49:45

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 44518 steps/s (collection: 2.097s, learning 0.111s)
             Mean action noise std: 1.48
          Mean value_function loss: 39.5255
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 47.0740
                       Mean reward: 75.88
               Mean episode length: 232.73
    Episode_Reward/reaching_object: 0.8734
    Episode_Reward/rotating_object: 11.8912
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.21s
                      Time elapsed: 00:05:46
                               ETA: 00:49:43

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 43692 steps/s (collection: 2.135s, learning 0.115s)
             Mean action noise std: 1.49
          Mean value_function loss: 37.2303
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 47.1062
                       Mean reward: 63.02
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 0.9215
    Episode_Reward/rotating_object: 11.6925
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.25s
                      Time elapsed: 00:05:48
                               ETA: 00:49:41

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 43532 steps/s (collection: 2.142s, learning 0.116s)
             Mean action noise std: 1.49
          Mean value_function loss: 41.5749
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 47.1408
                       Mean reward: 54.09
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 0.9168
    Episode_Reward/rotating_object: 11.9760
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.26s
                      Time elapsed: 00:05:50
                               ETA: 00:49:39

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 43810 steps/s (collection: 2.131s, learning 0.113s)
             Mean action noise std: 1.49
          Mean value_function loss: 41.3113
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.1685
                       Mean reward: 39.84
               Mean episode length: 227.29
    Episode_Reward/reaching_object: 0.8961
    Episode_Reward/rotating_object: 11.8721
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.24s
                      Time elapsed: 00:05:52
                               ETA: 00:49:37

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 42821 steps/s (collection: 2.185s, learning 0.111s)
             Mean action noise std: 1.49
          Mean value_function loss: 36.2143
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 47.1979
                       Mean reward: 75.35
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 0.9248
    Episode_Reward/rotating_object: 14.4909
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.30s
                      Time elapsed: 00:05:55
                               ETA: 00:49:35

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 44106 steps/s (collection: 2.116s, learning 0.113s)
             Mean action noise std: 1.49
          Mean value_function loss: 40.0746
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.2338
                       Mean reward: 55.76
               Mean episode length: 225.91
    Episode_Reward/reaching_object: 0.9379
    Episode_Reward/rotating_object: 14.6422
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.23s
                      Time elapsed: 00:05:57
                               ETA: 00:49:33

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 43714 steps/s (collection: 2.138s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 39.1286
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 47.2685
                       Mean reward: 70.94
               Mean episode length: 232.50
    Episode_Reward/reaching_object: 0.8873
    Episode_Reward/rotating_object: 13.4846
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.25s
                      Time elapsed: 00:05:59
                               ETA: 00:49:31

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 43850 steps/s (collection: 2.124s, learning 0.117s)
             Mean action noise std: 1.50
          Mean value_function loss: 42.6613
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.2948
                       Mean reward: 49.97
               Mean episode length: 228.72
    Episode_Reward/reaching_object: 0.8872
    Episode_Reward/rotating_object: 12.8399
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.24s
                      Time elapsed: 00:06:01
                               ETA: 00:49:29

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 44550 steps/s (collection: 2.096s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 37.2094
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 47.3303
                       Mean reward: 54.82
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 0.8858
    Episode_Reward/rotating_object: 12.1317
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.21s
                      Time elapsed: 00:06:03
                               ETA: 00:49:27

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 43651 steps/s (collection: 2.141s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 41.9323
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 47.3661
                       Mean reward: 62.97
               Mean episode length: 229.09
    Episode_Reward/reaching_object: 0.8748
    Episode_Reward/rotating_object: 13.2877
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.25s
                      Time elapsed: 00:06:06
                               ETA: 00:49:25

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 44775 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 1.50
          Mean value_function loss: 45.7494
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.3863
                       Mean reward: 72.02
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 0.9066
    Episode_Reward/rotating_object: 14.3221
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.20s
                      Time elapsed: 00:06:08
                               ETA: 00:49:23

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 44116 steps/s (collection: 2.118s, learning 0.111s)
             Mean action noise std: 1.51
          Mean value_function loss: 40.3482
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.4239
                       Mean reward: 64.51
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 0.8675
    Episode_Reward/rotating_object: 12.3841
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.23s
                      Time elapsed: 00:06:10
                               ETA: 00:49:20

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 44233 steps/s (collection: 2.112s, learning 0.111s)
             Mean action noise std: 1.51
          Mean value_function loss: 44.9580
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 47.4759
                       Mean reward: 70.42
               Mean episode length: 228.52
    Episode_Reward/reaching_object: 0.8870
    Episode_Reward/rotating_object: 13.4770
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.22s
                      Time elapsed: 00:06:12
                               ETA: 00:49:18

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 43519 steps/s (collection: 2.130s, learning 0.129s)
             Mean action noise std: 1.51
          Mean value_function loss: 42.6360
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 47.5075
                       Mean reward: 70.76
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 0.8675
    Episode_Reward/rotating_object: 11.5032
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.26s
                      Time elapsed: 00:06:15
                               ETA: 00:49:16

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 42851 steps/s (collection: 2.180s, learning 0.114s)
             Mean action noise std: 1.51
          Mean value_function loss: 42.0677
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.5300
                       Mean reward: 48.71
               Mean episode length: 231.81
    Episode_Reward/reaching_object: 0.8831
    Episode_Reward/rotating_object: 12.1946
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.29s
                      Time elapsed: 00:06:17
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 43465 steps/s (collection: 2.142s, learning 0.119s)
             Mean action noise std: 1.51
          Mean value_function loss: 44.4453
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.5683
                       Mean reward: 68.44
               Mean episode length: 236.85
    Episode_Reward/reaching_object: 0.9098
    Episode_Reward/rotating_object: 13.6066
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.26s
                      Time elapsed: 00:06:19
                               ETA: 00:49:13

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 42842 steps/s (collection: 2.183s, learning 0.111s)
             Mean action noise std: 1.52
          Mean value_function loss: 43.8862
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 47.6171
                       Mean reward: 89.25
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 0.9143
    Episode_Reward/rotating_object: 14.7904
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.29s
                      Time elapsed: 00:06:22
                               ETA: 00:49:11

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 42825 steps/s (collection: 2.181s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 42.2929
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 47.6657
                       Mean reward: 85.67
               Mean episode length: 234.86
    Episode_Reward/reaching_object: 0.9058
    Episode_Reward/rotating_object: 14.8459
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.30s
                      Time elapsed: 00:06:24
                               ETA: 00:49:09

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 43525 steps/s (collection: 2.144s, learning 0.115s)
             Mean action noise std: 1.52
          Mean value_function loss: 45.2518
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 47.7145
                       Mean reward: 72.88
               Mean episode length: 230.77
    Episode_Reward/reaching_object: 0.8760
    Episode_Reward/rotating_object: 12.5099
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.26s
                      Time elapsed: 00:06:26
                               ETA: 00:49:08

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 42777 steps/s (collection: 2.184s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 46.1807
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 47.7526
                       Mean reward: 69.00
               Mean episode length: 235.03
    Episode_Reward/reaching_object: 0.8995
    Episode_Reward/rotating_object: 13.3555
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.30s
                      Time elapsed: 00:06:28
                               ETA: 00:49:06

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 42765 steps/s (collection: 2.185s, learning 0.114s)
             Mean action noise std: 1.52
          Mean value_function loss: 47.2220
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 47.7730
                       Mean reward: 76.98
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 0.9022
    Episode_Reward/rotating_object: 16.3472
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.30s
                      Time elapsed: 00:06:31
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 42355 steps/s (collection: 2.203s, learning 0.118s)
             Mean action noise std: 1.53
          Mean value_function loss: 43.9494
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.8049
                       Mean reward: 57.58
               Mean episode length: 230.03
    Episode_Reward/reaching_object: 0.8867
    Episode_Reward/rotating_object: 13.3797
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.32s
                      Time elapsed: 00:06:33
                               ETA: 00:49:03

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 41641 steps/s (collection: 2.241s, learning 0.119s)
             Mean action noise std: 1.53
          Mean value_function loss: 46.6480
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.8409
                       Mean reward: 63.90
               Mean episode length: 229.55
    Episode_Reward/reaching_object: 0.8826
    Episode_Reward/rotating_object: 14.3935
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.36s
                      Time elapsed: 00:06:35
                               ETA: 00:49:02

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 43595 steps/s (collection: 2.143s, learning 0.112s)
             Mean action noise std: 1.53
          Mean value_function loss: 50.8117
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 47.8718
                       Mean reward: 75.82
               Mean episode length: 235.23
    Episode_Reward/reaching_object: 0.8881
    Episode_Reward/rotating_object: 14.6787
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.25s
                      Time elapsed: 00:06:38
                               ETA: 00:49:00

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 42909 steps/s (collection: 2.180s, learning 0.111s)
             Mean action noise std: 1.53
          Mean value_function loss: 44.0875
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 47.9064
                       Mean reward: 84.76
               Mean episode length: 232.94
    Episode_Reward/reaching_object: 0.9039
    Episode_Reward/rotating_object: 15.4656
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.29s
                      Time elapsed: 00:06:40
                               ETA: 00:48:58

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 43493 steps/s (collection: 2.147s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 44.9967
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.9412
                       Mean reward: 89.21
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 0.9120
    Episode_Reward/rotating_object: 16.0972
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.26s
                      Time elapsed: 00:06:42
                               ETA: 00:48:56

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 43413 steps/s (collection: 2.152s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 45.1523
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 47.9820
                       Mean reward: 82.07
               Mean episode length: 231.33
    Episode_Reward/reaching_object: 0.8757
    Episode_Reward/rotating_object: 14.6558
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.26s
                      Time elapsed: 00:06:44
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 42895 steps/s (collection: 2.178s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 54.2040
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.0182
                       Mean reward: 74.27
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 0.9041
    Episode_Reward/rotating_object: 15.0105
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.29s
                      Time elapsed: 00:06:47
                               ETA: 00:48:52

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 44240 steps/s (collection: 2.111s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 53.6839
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 48.0418
                       Mean reward: 76.26
               Mean episode length: 231.73
    Episode_Reward/reaching_object: 0.8585
    Episode_Reward/rotating_object: 13.6221
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.22s
                      Time elapsed: 00:06:49
                               ETA: 00:48:50

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 43528 steps/s (collection: 2.147s, learning 0.112s)
             Mean action noise std: 1.54
          Mean value_function loss: 49.2627
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.0630
                       Mean reward: 86.84
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 0.9056
    Episode_Reward/rotating_object: 15.5829
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.26s
                      Time elapsed: 00:06:51
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 43868 steps/s (collection: 2.130s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 54.0229
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 48.1018
                       Mean reward: 100.00
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 0.9226
    Episode_Reward/rotating_object: 16.7468
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.24s
                      Time elapsed: 00:06:53
                               ETA: 00:48:46

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 43911 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 1.55
          Mean value_function loss: 53.4313
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 48.1420
                       Mean reward: 96.74
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 0.9446
    Episode_Reward/rotating_object: 16.8238
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.24s
                      Time elapsed: 00:06:56
                               ETA: 00:48:44

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 43374 steps/s (collection: 2.156s, learning 0.111s)
             Mean action noise std: 1.55
          Mean value_function loss: 49.9741
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 48.1734
                       Mean reward: 79.31
               Mean episode length: 229.70
    Episode_Reward/reaching_object: 0.9310
    Episode_Reward/rotating_object: 15.7265
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.27s
                      Time elapsed: 00:06:58
                               ETA: 00:48:42

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 44007 steps/s (collection: 2.122s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 50.6322
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 48.2006
                       Mean reward: 79.17
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 0.9218
    Episode_Reward/rotating_object: 17.0473
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.23s
                      Time elapsed: 00:07:00
                               ETA: 00:48:40

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 43506 steps/s (collection: 2.142s, learning 0.117s)
             Mean action noise std: 1.55
          Mean value_function loss: 52.0517
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 48.2367
                       Mean reward: 79.00
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 0.9122
    Episode_Reward/rotating_object: 16.1784
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.26s
                      Time elapsed: 00:07:02
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 42734 steps/s (collection: 2.189s, learning 0.111s)
             Mean action noise std: 1.56
          Mean value_function loss: 50.7795
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 48.2717
                       Mean reward: 74.51
               Mean episode length: 227.55
    Episode_Reward/reaching_object: 0.8970
    Episode_Reward/rotating_object: 15.6800
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.30s
                      Time elapsed: 00:07:05
                               ETA: 00:48:36

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 42911 steps/s (collection: 2.177s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 46.1809
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 48.3011
                       Mean reward: 102.73
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 0.8957
    Episode_Reward/rotating_object: 16.2875
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 11.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.29s
                      Time elapsed: 00:07:07
                               ETA: 00:48:34

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 41908 steps/s (collection: 2.233s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 52.3779
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.3169
                       Mean reward: 78.13
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 0.8876
    Episode_Reward/rotating_object: 15.6320
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.35s
                      Time elapsed: 00:07:09
                               ETA: 00:48:33

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 43001 steps/s (collection: 2.174s, learning 0.112s)
             Mean action noise std: 1.56
          Mean value_function loss: 53.9513
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 48.3456
                       Mean reward: 109.51
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 0.9306
    Episode_Reward/rotating_object: 18.7229
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.29s
                      Time elapsed: 00:07:12
                               ETA: 00:48:31

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 42746 steps/s (collection: 2.187s, learning 0.113s)
             Mean action noise std: 1.56
          Mean value_function loss: 60.3643
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.3893
                       Mean reward: 79.05
               Mean episode length: 221.30
    Episode_Reward/reaching_object: 0.9309
    Episode_Reward/rotating_object: 16.9510
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.30s
                      Time elapsed: 00:07:14
                               ETA: 00:48:29

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 42578 steps/s (collection: 2.195s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 50.6901
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 48.4159
                       Mean reward: 88.92
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 0.9207
    Episode_Reward/rotating_object: 16.7805
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.31s
                      Time elapsed: 00:07:16
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 43055 steps/s (collection: 2.168s, learning 0.115s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.6704
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 48.4380
                       Mean reward: 106.39
               Mean episode length: 227.04
    Episode_Reward/reaching_object: 0.8994
    Episode_Reward/rotating_object: 18.1515
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.4583
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.28s
                      Time elapsed: 00:07:19
                               ETA: 00:48:26

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 42076 steps/s (collection: 2.223s, learning 0.114s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.5311
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 48.4671
                       Mean reward: 77.58
               Mean episode length: 222.76
    Episode_Reward/reaching_object: 0.9418
    Episode_Reward/rotating_object: 18.3903
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.34s
                      Time elapsed: 00:07:21
                               ETA: 00:48:24

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 42728 steps/s (collection: 2.188s, learning 0.113s)
             Mean action noise std: 1.57
          Mean value_function loss: 59.8445
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 48.4982
                       Mean reward: 79.53
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 0.9271
    Episode_Reward/rotating_object: 17.9405
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.30s
                      Time elapsed: 00:07:23
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 42734 steps/s (collection: 2.188s, learning 0.112s)
             Mean action noise std: 1.57
          Mean value_function loss: 55.9768
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 48.5270
                       Mean reward: 103.02
               Mean episode length: 223.77
    Episode_Reward/reaching_object: 0.9102
    Episode_Reward/rotating_object: 19.5681
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.30s
                      Time elapsed: 00:07:25
                               ETA: 00:48:21

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 42016 steps/s (collection: 2.226s, learning 0.114s)
             Mean action noise std: 1.57
          Mean value_function loss: 56.3317
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 48.5702
                       Mean reward: 82.64
               Mean episode length: 219.85
    Episode_Reward/reaching_object: 0.8975
    Episode_Reward/rotating_object: 18.9108
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.34s
                      Time elapsed: 00:07:28
                               ETA: 00:48:19

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 42867 steps/s (collection: 2.179s, learning 0.114s)
             Mean action noise std: 1.58
          Mean value_function loss: 52.6052
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 48.6054
                       Mean reward: 80.15
               Mean episode length: 217.76
    Episode_Reward/reaching_object: 0.8970
    Episode_Reward/rotating_object: 18.7552
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.29s
                      Time elapsed: 00:07:30
                               ETA: 00:48:17

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 42712 steps/s (collection: 2.189s, learning 0.113s)
             Mean action noise std: 1.58
          Mean value_function loss: 55.0045
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 48.6310
                       Mean reward: 93.44
               Mean episode length: 223.35
    Episode_Reward/reaching_object: 0.9120
    Episode_Reward/rotating_object: 19.1285
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.30s
                      Time elapsed: 00:07:32
                               ETA: 00:48:15

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 42553 steps/s (collection: 2.198s, learning 0.112s)
             Mean action noise std: 1.58
          Mean value_function loss: 53.7400
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 48.6410
                       Mean reward: 138.45
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 0.8876
    Episode_Reward/rotating_object: 19.7298
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.31s
                      Time elapsed: 00:07:35
                               ETA: 00:48:14

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 43868 steps/s (collection: 2.129s, learning 0.112s)
             Mean action noise std: 1.58
          Mean value_function loss: 48.2441
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 48.6657
                       Mean reward: 108.97
               Mean episode length: 223.97
    Episode_Reward/reaching_object: 0.8645
    Episode_Reward/rotating_object: 17.8952
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.24s
                      Time elapsed: 00:07:37
                               ETA: 00:48:12

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 42627 steps/s (collection: 2.195s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 53.6765
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 48.7119
                       Mean reward: 86.09
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 0.8798
    Episode_Reward/rotating_object: 19.2884
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.31s
                      Time elapsed: 00:07:39
                               ETA: 00:48:10

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 43492 steps/s (collection: 2.149s, learning 0.111s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.4739
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 48.7424
                       Mean reward: 87.91
               Mean episode length: 219.68
    Episode_Reward/reaching_object: 0.8735
    Episode_Reward/rotating_object: 16.9066
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.26s
                      Time elapsed: 00:07:42
                               ETA: 00:48:08

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 43434 steps/s (collection: 2.152s, learning 0.111s)
             Mean action noise std: 1.59
          Mean value_function loss: 64.1304
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 48.7779
                       Mean reward: 96.23
               Mean episode length: 228.08
    Episode_Reward/reaching_object: 0.8708
    Episode_Reward/rotating_object: 18.4541
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.26s
                      Time elapsed: 00:07:44
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 43319 steps/s (collection: 2.158s, learning 0.111s)
             Mean action noise std: 1.59
          Mean value_function loss: 64.9319
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.8069
                       Mean reward: 82.71
               Mean episode length: 226.38
    Episode_Reward/reaching_object: 0.8739
    Episode_Reward/rotating_object: 17.9551
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.27s
                      Time elapsed: 00:07:46
                               ETA: 00:48:04

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 42558 steps/s (collection: 2.186s, learning 0.124s)
             Mean action noise std: 1.59
          Mean value_function loss: 64.5583
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 48.8343
                       Mean reward: 87.65
               Mean episode length: 216.01
    Episode_Reward/reaching_object: 0.8859
    Episode_Reward/rotating_object: 18.9981
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.31s
                      Time elapsed: 00:07:48
                               ETA: 00:48:02

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 41373 steps/s (collection: 2.251s, learning 0.125s)
             Mean action noise std: 1.59
          Mean value_function loss: 70.0072
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 48.8602
                       Mean reward: 101.09
               Mean episode length: 220.56
    Episode_Reward/reaching_object: 0.8972
    Episode_Reward/rotating_object: 19.2151
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.38s
                      Time elapsed: 00:07:51
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 40693 steps/s (collection: 2.292s, learning 0.124s)
             Mean action noise std: 1.59
          Mean value_function loss: 72.1300
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 48.8867
                       Mean reward: 105.73
               Mean episode length: 218.20
    Episode_Reward/reaching_object: 0.9076
    Episode_Reward/rotating_object: 19.3557
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0285
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.42s
                      Time elapsed: 00:07:53
                               ETA: 00:47:59

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 42091 steps/s (collection: 2.219s, learning 0.116s)
             Mean action noise std: 1.59
          Mean value_function loss: 80.7482
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 48.9174
                       Mean reward: 128.08
               Mean episode length: 223.17
    Episode_Reward/reaching_object: 0.9239
    Episode_Reward/rotating_object: 21.0811
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.34s
                      Time elapsed: 00:07:55
                               ETA: 00:47:58

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 42029 steps/s (collection: 2.220s, learning 0.119s)
             Mean action noise std: 1.60
          Mean value_function loss: 71.9761
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 48.9399
                       Mean reward: 133.25
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 0.9461
    Episode_Reward/rotating_object: 24.0934
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 11.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.34s
                      Time elapsed: 00:07:58
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 41755 steps/s (collection: 2.243s, learning 0.112s)
             Mean action noise std: 1.60
          Mean value_function loss: 75.2587
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 48.9719
                       Mean reward: 108.55
               Mean episode length: 222.87
    Episode_Reward/reaching_object: 0.9360
    Episode_Reward/rotating_object: 20.2218
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.35s
                      Time elapsed: 00:08:00
                               ETA: 00:47:55

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 42473 steps/s (collection: 2.201s, learning 0.114s)
             Mean action noise std: 1.60
          Mean value_function loss: 74.7401
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 49.0046
                       Mean reward: 99.33
               Mean episode length: 216.28
    Episode_Reward/reaching_object: 0.9344
    Episode_Reward/rotating_object: 20.5383
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 11.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.31s
                      Time elapsed: 00:08:02
                               ETA: 00:47:53

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 42674 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 1.60
          Mean value_function loss: 75.4031
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.0433
                       Mean reward: 112.23
               Mean episode length: 218.40
    Episode_Reward/reaching_object: 0.9087
    Episode_Reward/rotating_object: 19.6932
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.30s
                      Time elapsed: 00:08:05
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 42718 steps/s (collection: 2.186s, learning 0.115s)
             Mean action noise std: 1.60
          Mean value_function loss: 71.4841
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.0636
                       Mean reward: 108.73
               Mean episode length: 221.92
    Episode_Reward/reaching_object: 0.9290
    Episode_Reward/rotating_object: 22.9266
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.30s
                      Time elapsed: 00:08:07
                               ETA: 00:47:49

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 42515 steps/s (collection: 2.201s, learning 0.111s)
             Mean action noise std: 1.61
          Mean value_function loss: 77.9891
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 49.0862
                       Mean reward: 130.81
               Mean episode length: 219.48
    Episode_Reward/reaching_object: 0.9188
    Episode_Reward/rotating_object: 22.3936
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.31s
                      Time elapsed: 00:08:09
                               ETA: 00:47:47

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 42015 steps/s (collection: 2.212s, learning 0.128s)
             Mean action noise std: 1.61
          Mean value_function loss: 72.1135
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.1117
                       Mean reward: 133.73
               Mean episode length: 227.47
    Episode_Reward/reaching_object: 0.9080
    Episode_Reward/rotating_object: 22.6073
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 10.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.34s
                      Time elapsed: 00:08:12
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 41906 steps/s (collection: 2.232s, learning 0.113s)
             Mean action noise std: 1.61
          Mean value_function loss: 73.8104
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 49.1387
                       Mean reward: 126.97
               Mean episode length: 217.03
    Episode_Reward/reaching_object: 0.9028
    Episode_Reward/rotating_object: 22.2104
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.35s
                      Time elapsed: 00:08:14
                               ETA: 00:47:44

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 42696 steps/s (collection: 2.191s, learning 0.111s)
             Mean action noise std: 1.61
          Mean value_function loss: 68.8043
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 49.1667
                       Mean reward: 144.20
               Mean episode length: 220.84
    Episode_Reward/reaching_object: 0.9233
    Episode_Reward/rotating_object: 24.2504
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.30s
                      Time elapsed: 00:08:16
                               ETA: 00:47:42

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 42355 steps/s (collection: 2.209s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 79.2088
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 49.1921
                       Mean reward: 78.28
               Mean episode length: 210.18
    Episode_Reward/reaching_object: 0.9230
    Episode_Reward/rotating_object: 21.8957
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.32s
                      Time elapsed: 00:08:19
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 42486 steps/s (collection: 2.201s, learning 0.113s)
             Mean action noise std: 1.62
          Mean value_function loss: 79.6318
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 49.2292
                       Mean reward: 96.70
               Mean episode length: 215.24
    Episode_Reward/reaching_object: 0.8874
    Episode_Reward/rotating_object: 20.6003
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 10.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.31s
                      Time elapsed: 00:08:21
                               ETA: 00:47:39

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 42048 steps/s (collection: 2.225s, learning 0.113s)
             Mean action noise std: 1.62
          Mean value_function loss: 74.9851
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 49.2705
                       Mean reward: 125.68
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 0.9000
    Episode_Reward/rotating_object: 22.7316
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 11.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.4167
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.34s
                      Time elapsed: 00:08:23
                               ETA: 00:47:37

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 42949 steps/s (collection: 2.178s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 82.4815
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 49.3015
                       Mean reward: 138.06
               Mean episode length: 217.55
    Episode_Reward/reaching_object: 0.9407
    Episode_Reward/rotating_object: 25.4090
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.29s
                      Time elapsed: 00:08:26
                               ETA: 00:47:35

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 42985 steps/s (collection: 2.175s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 87.8960
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 49.3284
                       Mean reward: 157.93
               Mean episode length: 216.42
    Episode_Reward/reaching_object: 0.9367
    Episode_Reward/rotating_object: 26.3363
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 10.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.29s
                      Time elapsed: 00:08:28
                               ETA: 00:47:33

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 43102 steps/s (collection: 2.170s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 82.2622
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 49.3491
                       Mean reward: 121.86
               Mean episode length: 216.30
    Episode_Reward/reaching_object: 0.9096
    Episode_Reward/rotating_object: 22.5660
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 11.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.28s
                      Time elapsed: 00:08:30
                               ETA: 00:47:31

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 43287 steps/s (collection: 2.160s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 82.9686
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 49.3623
                       Mean reward: 116.71
               Mean episode length: 214.04
    Episode_Reward/reaching_object: 0.9227
    Episode_Reward/rotating_object: 24.0524
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.27s
                      Time elapsed: 00:08:33
                               ETA: 00:47:29

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 43033 steps/s (collection: 2.174s, learning 0.111s)
             Mean action noise std: 1.62
          Mean value_function loss: 78.9986
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 49.3793
                       Mean reward: 140.98
               Mean episode length: 222.89
    Episode_Reward/reaching_object: 0.9366
    Episode_Reward/rotating_object: 24.7244
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 11.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 7.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.28s
                      Time elapsed: 00:08:35
                               ETA: 00:47:27

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 43239 steps/s (collection: 2.163s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 79.2842
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 49.3936
                       Mean reward: 142.37
               Mean episode length: 220.31
    Episode_Reward/reaching_object: 0.9568
    Episode_Reward/rotating_object: 25.1868
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.0417
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.27s
                      Time elapsed: 00:08:37
                               ETA: 00:47:25

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 42541 steps/s (collection: 2.199s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 79.3471
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 49.4055
                       Mean reward: 97.47
               Mean episode length: 214.26
    Episode_Reward/reaching_object: 0.9262
    Episode_Reward/rotating_object: 24.4882
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.5000
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.31s
                      Time elapsed: 00:08:39
                               ETA: 00:47:23

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 42312 steps/s (collection: 2.212s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 80.5027
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.4242
                       Mean reward: 124.20
               Mean episode length: 213.71
    Episode_Reward/reaching_object: 0.9384
    Episode_Reward/rotating_object: 25.6233
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.32s
                      Time elapsed: 00:08:42
                               ETA: 00:47:21

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 42110 steps/s (collection: 2.223s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 86.8178
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.4507
                       Mean reward: 128.90
               Mean episode length: 215.49
    Episode_Reward/reaching_object: 0.9546
    Episode_Reward/rotating_object: 26.8793
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.33s
                      Time elapsed: 00:08:44
                               ETA: 00:47:20

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 42035 steps/s (collection: 2.227s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 85.9244
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.4838
                       Mean reward: 125.52
               Mean episode length: 214.27
    Episode_Reward/reaching_object: 0.9665
    Episode_Reward/rotating_object: 29.6665
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.34s
                      Time elapsed: 00:08:46
                               ETA: 00:47:18

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 42276 steps/s (collection: 2.214s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 91.0128
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.5150
                       Mean reward: 179.59
               Mean episode length: 224.02
    Episode_Reward/reaching_object: 0.9725
    Episode_Reward/rotating_object: 30.9395
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.33s
                      Time elapsed: 00:08:49
                               ETA: 00:47:16

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 42216 steps/s (collection: 2.216s, learning 0.113s)
             Mean action noise std: 1.63
          Mean value_function loss: 88.1400
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 49.5368
                       Mean reward: 119.92
               Mean episode length: 216.90
    Episode_Reward/reaching_object: 0.9368
    Episode_Reward/rotating_object: 25.9211
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 11.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.33s
                      Time elapsed: 00:08:51
                               ETA: 00:47:14

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 41890 steps/s (collection: 2.235s, learning 0.112s)
             Mean action noise std: 1.64
          Mean value_function loss: 83.6255
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 49.5538
                       Mean reward: 136.37
               Mean episode length: 217.37
    Episode_Reward/reaching_object: 0.9168
    Episode_Reward/rotating_object: 26.6576
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 11.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.35s
                      Time elapsed: 00:08:53
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 42332 steps/s (collection: 2.208s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 90.7042
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 49.5738
                       Mean reward: 166.92
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 0.9698
    Episode_Reward/rotating_object: 31.4191
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.32s
                      Time elapsed: 00:08:56
                               ETA: 00:47:11

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 41962 steps/s (collection: 2.229s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 86.3667
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 49.5954
                       Mean reward: 134.29
               Mean episode length: 222.17
    Episode_Reward/reaching_object: 0.9765
    Episode_Reward/rotating_object: 30.3063
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.34s
                      Time elapsed: 00:08:58
                               ETA: 00:47:09

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 41042 steps/s (collection: 2.281s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 87.2722
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 49.6100
                       Mean reward: 140.48
               Mean episode length: 209.59
    Episode_Reward/reaching_object: 0.9172
    Episode_Reward/rotating_object: 28.5610
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 7.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.40s
                      Time elapsed: 00:09:00
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 38925 steps/s (collection: 2.412s, learning 0.113s)
             Mean action noise std: 1.64
          Mean value_function loss: 86.4374
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 49.6241
                       Mean reward: 160.91
               Mean episode length: 217.12
    Episode_Reward/reaching_object: 0.9182
    Episode_Reward/rotating_object: 28.5525
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 6.5417
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.53s
                      Time elapsed: 00:09:03
                               ETA: 00:47:07

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 41557 steps/s (collection: 2.250s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 83.8810
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 49.6401
                       Mean reward: 182.01
               Mean episode length: 221.54
    Episode_Reward/reaching_object: 0.9671
    Episode_Reward/rotating_object: 31.2506
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 11.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.37s
                      Time elapsed: 00:09:05
                               ETA: 00:47:05

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 41689 steps/s (collection: 2.247s, learning 0.111s)
             Mean action noise std: 1.64
          Mean value_function loss: 76.5719
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 49.6627
                       Mean reward: 128.01
               Mean episode length: 218.18
    Episode_Reward/reaching_object: 0.9294
    Episode_Reward/rotating_object: 30.4017
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.36s
                      Time elapsed: 00:09:08
                               ETA: 00:47:04

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 42274 steps/s (collection: 2.214s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 72.6257
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 49.6890
                       Mean reward: 163.23
               Mean episode length: 214.96
    Episode_Reward/reaching_object: 0.9495
    Episode_Reward/rotating_object: 32.5371
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 11.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.33s
                      Time elapsed: 00:09:10
                               ETA: 00:47:02

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 42195 steps/s (collection: 2.219s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 80.0370
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 49.7096
                       Mean reward: 136.47
               Mean episode length: 197.65
    Episode_Reward/reaching_object: 0.9168
    Episode_Reward/rotating_object: 31.9184
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 11.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.33s
                      Time elapsed: 00:09:12
                               ETA: 00:47:00

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 43281 steps/s (collection: 2.160s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 76.0539
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 49.7245
                       Mean reward: 177.70
               Mean episode length: 217.65
    Episode_Reward/reaching_object: 0.9362
    Episode_Reward/rotating_object: 31.6017
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 12.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.27s
                      Time elapsed: 00:09:15
                               ETA: 00:46:58

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 42965 steps/s (collection: 2.178s, learning 0.110s)
             Mean action noise std: 1.65
          Mean value_function loss: 77.5101
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 49.7378
                       Mean reward: 154.52
               Mean episode length: 217.45
    Episode_Reward/reaching_object: 0.9604
    Episode_Reward/rotating_object: 32.4561
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.29s
                      Time elapsed: 00:09:17
                               ETA: 00:46:56

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 43114 steps/s (collection: 2.170s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 82.7834
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 49.7500
                       Mean reward: 174.01
               Mean episode length: 220.19
    Episode_Reward/reaching_object: 0.9451
    Episode_Reward/rotating_object: 32.2419
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.28s
                      Time elapsed: 00:09:19
                               ETA: 00:46:54

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 43245 steps/s (collection: 2.163s, learning 0.110s)
             Mean action noise std: 1.65
          Mean value_function loss: 86.4696
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 49.7636
                       Mean reward: 166.95
               Mean episode length: 217.81
    Episode_Reward/reaching_object: 0.9273
    Episode_Reward/rotating_object: 32.3180
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.27s
                      Time elapsed: 00:09:21
                               ETA: 00:46:51

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 42698 steps/s (collection: 2.192s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 81.5852
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 49.7720
                       Mean reward: 192.17
               Mean episode length: 214.07
    Episode_Reward/reaching_object: 0.9435
    Episode_Reward/rotating_object: 35.0389
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.30s
                      Time elapsed: 00:09:24
                               ETA: 00:46:50

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 42729 steps/s (collection: 2.190s, learning 0.111s)
             Mean action noise std: 1.65
          Mean value_function loss: 88.8382
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 49.7891
                       Mean reward: 137.33
               Mean episode length: 207.16
    Episode_Reward/reaching_object: 0.9152
    Episode_Reward/rotating_object: 30.5859
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.30s
                      Time elapsed: 00:09:26
                               ETA: 00:46:48

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 42259 steps/s (collection: 2.212s, learning 0.114s)
             Mean action noise std: 1.65
          Mean value_function loss: 86.5379
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 49.8051
                       Mean reward: 182.20
               Mean episode length: 210.15
    Episode_Reward/reaching_object: 0.9267
    Episode_Reward/rotating_object: 34.6923
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.33s
                      Time elapsed: 00:09:28
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 39824 steps/s (collection: 2.354s, learning 0.114s)
             Mean action noise std: 1.66
          Mean value_function loss: 87.7507
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 49.8315
                       Mean reward: 156.99
               Mean episode length: 202.77
    Episode_Reward/reaching_object: 0.9100
    Episode_Reward/rotating_object: 31.8311
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.47s
                      Time elapsed: 00:09:31
                               ETA: 00:46:44

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 40291 steps/s (collection: 2.327s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 92.3621
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 49.8648
                       Mean reward: 188.71
               Mean episode length: 211.50
    Episode_Reward/reaching_object: 0.9705
    Episode_Reward/rotating_object: 39.0527
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.44s
                      Time elapsed: 00:09:33
                               ETA: 00:46:43

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 42000 steps/s (collection: 2.226s, learning 0.114s)
             Mean action noise std: 1.66
          Mean value_function loss: 92.3185
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 49.8942
                       Mean reward: 166.46
               Mean episode length: 211.37
    Episode_Reward/reaching_object: 0.9206
    Episode_Reward/rotating_object: 36.9829
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 11.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.34s
                      Time elapsed: 00:09:36
                               ETA: 00:46:41

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 41852 steps/s (collection: 2.235s, learning 0.114s)
             Mean action noise std: 1.66
          Mean value_function loss: 91.7073
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 49.9107
                       Mean reward: 206.07
               Mean episode length: 213.05
    Episode_Reward/reaching_object: 0.9711
    Episode_Reward/rotating_object: 38.7156
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.35s
                      Time elapsed: 00:09:38
                               ETA: 00:46:40

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 42228 steps/s (collection: 2.215s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 91.5345
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 49.9224
                       Mean reward: 149.23
               Mean episode length: 206.89
    Episode_Reward/reaching_object: 0.9425
    Episode_Reward/rotating_object: 34.1503
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 11.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.33s
                      Time elapsed: 00:09:40
                               ETA: 00:46:38

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 41778 steps/s (collection: 2.240s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 100.1487
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 49.9438
                       Mean reward: 167.54
               Mean episode length: 207.99
    Episode_Reward/reaching_object: 0.9206
    Episode_Reward/rotating_object: 33.7005
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.35s
                      Time elapsed: 00:09:43
                               ETA: 00:46:36

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 41722 steps/s (collection: 2.243s, learning 0.113s)
             Mean action noise std: 1.66
          Mean value_function loss: 105.8437
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 49.9654
                       Mean reward: 192.42
               Mean episode length: 201.04
    Episode_Reward/reaching_object: 0.9431
    Episode_Reward/rotating_object: 37.9202
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 12.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.36s
                      Time elapsed: 00:09:45
                               ETA: 00:46:34

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 41694 steps/s (collection: 2.243s, learning 0.114s)
             Mean action noise std: 1.67
          Mean value_function loss: 108.6234
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 49.9939
                       Mean reward: 221.78
               Mean episode length: 203.62
    Episode_Reward/reaching_object: 0.9809
    Episode_Reward/rotating_object: 40.5194
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.2917
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.36s
                      Time elapsed: 00:09:47
                               ETA: 00:46:32

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 42119 steps/s (collection: 2.220s, learning 0.114s)
             Mean action noise std: 1.67
          Mean value_function loss: 96.0026
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.0080
                       Mean reward: 210.10
               Mean episode length: 218.41
    Episode_Reward/reaching_object: 0.9949
    Episode_Reward/rotating_object: 42.1116
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.8333
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.33s
                      Time elapsed: 00:09:50
                               ETA: 00:46:31

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 41887 steps/s (collection: 2.234s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 88.8883
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.0296
                       Mean reward: 232.90
               Mean episode length: 212.08
    Episode_Reward/reaching_object: 1.0100
    Episode_Reward/rotating_object: 43.3909
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.35s
                      Time elapsed: 00:09:52
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 41472 steps/s (collection: 2.257s, learning 0.114s)
             Mean action noise std: 1.67
          Mean value_function loss: 94.2446
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.0460
                       Mean reward: 233.52
               Mean episode length: 216.96
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 43.0748
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.7500
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.37s
                      Time elapsed: 00:09:54
                               ETA: 00:46:27

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 42071 steps/s (collection: 2.224s, learning 0.113s)
             Mean action noise std: 1.67
          Mean value_function loss: 98.6895
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.0618
                       Mean reward: 221.45
               Mean episode length: 211.60
    Episode_Reward/reaching_object: 0.9955
    Episode_Reward/rotating_object: 42.7562
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.34s
                      Time elapsed: 00:09:57
                               ETA: 00:46:25

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 41845 steps/s (collection: 2.238s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 105.3218
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 50.0781
                       Mean reward: 219.35
               Mean episode length: 217.25
    Episode_Reward/reaching_object: 0.9947
    Episode_Reward/rotating_object: 44.1256
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 12.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.35s
                      Time elapsed: 00:09:59
                               ETA: 00:46:23

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 41760 steps/s (collection: 2.239s, learning 0.115s)
             Mean action noise std: 1.67
          Mean value_function loss: 101.3661
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 50.0824
                       Mean reward: 255.69
               Mean episode length: 215.71
    Episode_Reward/reaching_object: 1.0206
    Episode_Reward/rotating_object: 46.8785
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.35s
                      Time elapsed: 00:10:01
                               ETA: 00:46:22

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 41760 steps/s (collection: 2.221s, learning 0.133s)
             Mean action noise std: 1.67
          Mean value_function loss: 102.5629
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 50.0868
                       Mean reward: 213.18
               Mean episode length: 208.62
    Episode_Reward/reaching_object: 1.0076
    Episode_Reward/rotating_object: 42.9155
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.35s
                      Time elapsed: 00:10:04
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 42473 steps/s (collection: 2.203s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 105.5859
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.0909
                       Mean reward: 239.32
               Mean episode length: 222.54
    Episode_Reward/reaching_object: 1.0096
    Episode_Reward/rotating_object: 45.5605
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.31s
                      Time elapsed: 00:10:06
                               ETA: 00:46:18

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 42422 steps/s (collection: 2.205s, learning 0.112s)
             Mean action noise std: 1.67
          Mean value_function loss: 102.4948
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.0987
                       Mean reward: 282.07
               Mean episode length: 221.71
    Episode_Reward/reaching_object: 1.0378
    Episode_Reward/rotating_object: 47.7040
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.32s
                      Time elapsed: 00:10:08
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 42375 steps/s (collection: 2.209s, learning 0.111s)
             Mean action noise std: 1.67
          Mean value_function loss: 107.4562
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 50.1166
                       Mean reward: 242.78
               Mean episode length: 210.01
    Episode_Reward/reaching_object: 1.0382
    Episode_Reward/rotating_object: 46.2996
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.32s
                      Time elapsed: 00:10:11
                               ETA: 00:46:14

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 42363 steps/s (collection: 2.209s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 109.8234
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 50.1347
                       Mean reward: 207.34
               Mean episode length: 207.75
    Episode_Reward/reaching_object: 1.0514
    Episode_Reward/rotating_object: 48.6813
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.32s
                      Time elapsed: 00:10:13
                               ETA: 00:46:12

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 42308 steps/s (collection: 2.212s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 106.3985
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 50.1547
                       Mean reward: 243.08
               Mean episode length: 206.24
    Episode_Reward/reaching_object: 1.0078
    Episode_Reward/rotating_object: 46.9757
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.3750
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.32s
                      Time elapsed: 00:10:15
                               ETA: 00:46:10

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 42066 steps/s (collection: 2.225s, learning 0.112s)
             Mean action noise std: 1.68
          Mean value_function loss: 105.2924
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 50.1683
                       Mean reward: 279.29
               Mean episode length: 215.31
    Episode_Reward/reaching_object: 1.0264
    Episode_Reward/rotating_object: 48.8859
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.34s
                      Time elapsed: 00:10:18
                               ETA: 00:46:08

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 41468 steps/s (collection: 2.260s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 110.4461
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 50.1750
                       Mean reward: 281.36
               Mean episode length: 215.15
    Episode_Reward/reaching_object: 1.0142
    Episode_Reward/rotating_object: 47.9907
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 7.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.37s
                      Time elapsed: 00:10:20
                               ETA: 00:46:06

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 41678 steps/s (collection: 2.245s, learning 0.114s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.5037
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.1842
                       Mean reward: 260.12
               Mean episode length: 207.52
    Episode_Reward/reaching_object: 1.0201
    Episode_Reward/rotating_object: 47.4074
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.36s
                      Time elapsed: 00:10:22
                               ETA: 00:46:05

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 41642 steps/s (collection: 2.246s, learning 0.114s)
             Mean action noise std: 1.68
          Mean value_function loss: 104.1139
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 50.1965
                       Mean reward: 206.41
               Mean episode length: 190.28
    Episode_Reward/reaching_object: 0.9482
    Episode_Reward/rotating_object: 43.4299
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 7.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.36s
                      Time elapsed: 00:10:25
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 41571 steps/s (collection: 2.251s, learning 0.114s)
             Mean action noise std: 1.68
          Mean value_function loss: 105.9335
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 50.2071
                       Mean reward: 234.40
               Mean episode length: 206.70
    Episode_Reward/reaching_object: 1.0018
    Episode_Reward/rotating_object: 46.2088
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 11.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.36s
                      Time elapsed: 00:10:27
                               ETA: 00:46:01

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 41397 steps/s (collection: 2.251s, learning 0.123s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.7021
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.2141
                       Mean reward: 222.82
               Mean episode length: 207.71
    Episode_Reward/reaching_object: 0.9999
    Episode_Reward/rotating_object: 46.6905
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 6.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.37s
                      Time elapsed: 00:10:30
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 40014 steps/s (collection: 2.345s, learning 0.111s)
             Mean action noise std: 1.68
          Mean value_function loss: 101.1946
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 50.2214
                       Mean reward: 243.77
               Mean episode length: 202.49
    Episode_Reward/reaching_object: 1.0289
    Episode_Reward/rotating_object: 50.9310
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.46s
                      Time elapsed: 00:10:32
                               ETA: 00:45:58

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 37823 steps/s (collection: 2.483s, learning 0.116s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.1597
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 50.2261
                       Mean reward: 215.70
               Mean episode length: 196.70
    Episode_Reward/reaching_object: 0.9955
    Episode_Reward/rotating_object: 48.8742
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.60s
                      Time elapsed: 00:10:35
                               ETA: 00:45:57

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 39873 steps/s (collection: 2.351s, learning 0.115s)
             Mean action noise std: 1.68
          Mean value_function loss: 99.2966
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 50.2371
                       Mean reward: 259.25
               Mean episode length: 212.19
    Episode_Reward/reaching_object: 1.0281
    Episode_Reward/rotating_object: 52.9233
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.47s
                      Time elapsed: 00:10:37
                               ETA: 00:45:56

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 41534 steps/s (collection: 2.253s, learning 0.114s)
             Mean action noise std: 1.68
          Mean value_function loss: 95.7143
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 50.2425
                       Mean reward: 256.45
               Mean episode length: 210.68
    Episode_Reward/reaching_object: 1.0566
    Episode_Reward/rotating_object: 55.9019
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.37s
                      Time elapsed: 00:10:39
                               ETA: 00:45:54

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 41830 steps/s (collection: 2.229s, learning 0.121s)
             Mean action noise std: 1.68
          Mean value_function loss: 94.9979
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 50.2516
                       Mean reward: 227.95
               Mean episode length: 195.94
    Episode_Reward/reaching_object: 1.0405
    Episode_Reward/rotating_object: 53.9533
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.35s
                      Time elapsed: 00:10:42
                               ETA: 00:45:52

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 41952 steps/s (collection: 2.232s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 95.8570
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.2705
                       Mean reward: 265.37
               Mean episode length: 215.94
    Episode_Reward/reaching_object: 1.0281
    Episode_Reward/rotating_object: 52.9948
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.34s
                      Time elapsed: 00:10:44
                               ETA: 00:45:50

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 41974 steps/s (collection: 2.229s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 99.4011
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 50.2893
                       Mean reward: 261.47
               Mean episode length: 208.27
    Episode_Reward/reaching_object: 1.0405
    Episode_Reward/rotating_object: 53.9541
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.34s
                      Time elapsed: 00:10:46
                               ETA: 00:45:48

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 41164 steps/s (collection: 2.276s, learning 0.112s)
             Mean action noise std: 1.69
          Mean value_function loss: 102.5668
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 50.3043
                       Mean reward: 249.75
               Mean episode length: 200.77
    Episode_Reward/reaching_object: 1.0209
    Episode_Reward/rotating_object: 53.8058
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.39s
                      Time elapsed: 00:10:49
                               ETA: 00:45:46

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 42305 steps/s (collection: 2.204s, learning 0.120s)
             Mean action noise std: 1.69
          Mean value_function loss: 107.7854
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.3125
                       Mean reward: 269.32
               Mean episode length: 206.22
    Episode_Reward/reaching_object: 1.0085
    Episode_Reward/rotating_object: 52.6812
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.32s
                      Time elapsed: 00:10:51
                               ETA: 00:45:44

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 42577 steps/s (collection: 2.198s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 110.2109
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 50.3208
                       Mean reward: 273.69
               Mean episode length: 214.12
    Episode_Reward/reaching_object: 1.0571
    Episode_Reward/rotating_object: 54.9203
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.31s
                      Time elapsed: 00:10:54
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 42211 steps/s (collection: 2.207s, learning 0.122s)
             Mean action noise std: 1.69
          Mean value_function loss: 113.8945
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.3291
                       Mean reward: 240.94
               Mean episode length: 196.28
    Episode_Reward/reaching_object: 1.0541
    Episode_Reward/rotating_object: 55.1870
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.33s
                      Time elapsed: 00:10:56
                               ETA: 00:45:40

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 42422 steps/s (collection: 2.206s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 104.4926
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 50.3368
                       Mean reward: 297.75
               Mean episode length: 213.11
    Episode_Reward/reaching_object: 1.0533
    Episode_Reward/rotating_object: 55.9599
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.32s
                      Time elapsed: 00:10:58
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 41698 steps/s (collection: 2.247s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 102.8745
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.3453
                       Mean reward: 292.60
               Mean episode length: 215.13
    Episode_Reward/reaching_object: 1.0661
    Episode_Reward/rotating_object: 57.7962
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.36s
                      Time elapsed: 00:11:01
                               ETA: 00:45:36

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 41170 steps/s (collection: 2.277s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 107.1619
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 50.3590
                       Mean reward: 289.15
               Mean episode length: 214.45
    Episode_Reward/reaching_object: 1.0336
    Episode_Reward/rotating_object: 53.3689
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.39s
                      Time elapsed: 00:11:03
                               ETA: 00:45:35

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 42106 steps/s (collection: 2.217s, learning 0.117s)
             Mean action noise std: 1.69
          Mean value_function loss: 97.2989
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 50.3681
                       Mean reward: 265.69
               Mean episode length: 207.90
    Episode_Reward/reaching_object: 1.0709
    Episode_Reward/rotating_object: 58.2222
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.33s
                      Time elapsed: 00:11:05
                               ETA: 00:45:33

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 41947 steps/s (collection: 2.230s, learning 0.114s)
             Mean action noise std: 1.69
          Mean value_function loss: 91.2035
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 50.3773
                       Mean reward: 274.37
               Mean episode length: 212.13
    Episode_Reward/reaching_object: 1.0648
    Episode_Reward/rotating_object: 57.3004
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.34s
                      Time elapsed: 00:11:08
                               ETA: 00:45:31

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 42147 steps/s (collection: 2.221s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 90.5841
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 50.3849
                       Mean reward: 268.67
               Mean episode length: 214.70
    Episode_Reward/reaching_object: 1.0976
    Episode_Reward/rotating_object: 60.8417
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.33s
                      Time elapsed: 00:11:10
                               ETA: 00:45:29

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 42030 steps/s (collection: 2.228s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 95.6154
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 50.3932
                       Mean reward: 284.71
               Mean episode length: 210.83
    Episode_Reward/reaching_object: 1.0634
    Episode_Reward/rotating_object: 57.3900
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.34s
                      Time elapsed: 00:11:12
                               ETA: 00:45:27

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 41772 steps/s (collection: 2.238s, learning 0.115s)
             Mean action noise std: 1.69
          Mean value_function loss: 101.7003
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 50.4024
                       Mean reward: 336.17
               Mean episode length: 215.55
    Episode_Reward/reaching_object: 1.0874
    Episode_Reward/rotating_object: 60.6099
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.35s
                      Time elapsed: 00:11:15
                               ETA: 00:45:25

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 42199 steps/s (collection: 2.219s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 99.2405
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 50.4192
                       Mean reward: 329.20
               Mean episode length: 215.65
    Episode_Reward/reaching_object: 1.1152
    Episode_Reward/rotating_object: 63.9838
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.33s
                      Time elapsed: 00:11:17
                               ETA: 00:45:23

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 42178 steps/s (collection: 2.220s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 113.6576
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 50.4352
                       Mean reward: 319.18
               Mean episode length: 219.65
    Episode_Reward/reaching_object: 1.0956
    Episode_Reward/rotating_object: 59.8624
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.33s
                      Time elapsed: 00:11:19
                               ETA: 00:45:21

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 42175 steps/s (collection: 2.215s, learning 0.116s)
             Mean action noise std: 1.70
          Mean value_function loss: 100.5488
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 50.4468
                       Mean reward: 348.14
               Mean episode length: 225.25
    Episode_Reward/reaching_object: 1.1015
    Episode_Reward/rotating_object: 65.0531
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.33s
                      Time elapsed: 00:11:22
                               ETA: 00:45:19

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 41748 steps/s (collection: 2.243s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 99.9912
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 50.4594
                       Mean reward: 313.51
               Mean episode length: 218.38
    Episode_Reward/reaching_object: 1.1108
    Episode_Reward/rotating_object: 62.5715
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.35s
                      Time elapsed: 00:11:24
                               ETA: 00:45:17

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 42187 steps/s (collection: 2.216s, learning 0.114s)
             Mean action noise std: 1.70
          Mean value_function loss: 100.5980
               Mean surrogate loss: 0.0034
                 Mean entropy loss: 50.4760
                       Mean reward: 313.58
               Mean episode length: 219.59
    Episode_Reward/reaching_object: 1.0864
    Episode_Reward/rotating_object: 60.9361
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.33s
                      Time elapsed: 00:11:26
                               ETA: 00:45:15

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 42449 steps/s (collection: 2.202s, learning 0.113s)
             Mean action noise std: 1.70
          Mean value_function loss: 119.0032
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 50.4831
                       Mean reward: 314.48
               Mean episode length: 210.02
    Episode_Reward/reaching_object: 1.1080
    Episode_Reward/rotating_object: 63.6661
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.32s
                      Time elapsed: 00:11:29
                               ETA: 00:45:13

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 41785 steps/s (collection: 2.241s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 104.1140
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 50.4886
                       Mean reward: 354.11
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 1.1238
    Episode_Reward/rotating_object: 66.5107
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.35s
                      Time elapsed: 00:11:31
                               ETA: 00:45:11

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 41951 steps/s (collection: 2.231s, learning 0.112s)
             Mean action noise std: 1.70
          Mean value_function loss: 95.4577
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 50.4973
                       Mean reward: 310.79
               Mean episode length: 216.37
    Episode_Reward/reaching_object: 1.1211
    Episode_Reward/rotating_object: 64.6279
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.34s
                      Time elapsed: 00:11:33
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 42005 steps/s (collection: 2.228s, learning 0.113s)
             Mean action noise std: 1.70
          Mean value_function loss: 102.3893
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.5116
                       Mean reward: 354.32
               Mean episode length: 220.48
    Episode_Reward/reaching_object: 1.1178
    Episode_Reward/rotating_object: 67.2311
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.34s
                      Time elapsed: 00:11:36
                               ETA: 00:45:07

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 42481 steps/s (collection: 2.203s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 111.9120
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 50.5237
                       Mean reward: 357.08
               Mean episode length: 224.05
    Episode_Reward/reaching_object: 1.1299
    Episode_Reward/rotating_object: 67.1289
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.31s
                      Time elapsed: 00:11:38
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 43069 steps/s (collection: 2.171s, learning 0.111s)
             Mean action noise std: 1.70
          Mean value_function loss: 103.2334
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.5340
                       Mean reward: 332.94
               Mean episode length: 213.14
    Episode_Reward/reaching_object: 1.1272
    Episode_Reward/rotating_object: 65.1391
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.28s
                      Time elapsed: 00:11:40
                               ETA: 00:45:03

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 42746 steps/s (collection: 2.188s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 103.6625
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 50.5493
                       Mean reward: 344.76
               Mean episode length: 216.09
    Episode_Reward/reaching_object: 1.1267
    Episode_Reward/rotating_object: 68.5431
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.30s
                      Time elapsed: 00:11:43
                               ETA: 00:45:01

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 43170 steps/s (collection: 2.166s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 106.2652
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 50.5617
                       Mean reward: 352.86
               Mean episode length: 213.85
    Episode_Reward/reaching_object: 1.1237
    Episode_Reward/rotating_object: 70.1434
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.28s
                      Time elapsed: 00:11:45
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 43352 steps/s (collection: 2.156s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 97.6535
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 50.5732
                       Mean reward: 380.50
               Mean episode length: 226.44
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 71.9464
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.27s
                      Time elapsed: 00:11:47
                               ETA: 00:44:56

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 42963 steps/s (collection: 2.177s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 90.0262
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 50.5858
                       Mean reward: 358.31
               Mean episode length: 218.81
    Episode_Reward/reaching_object: 1.1061
    Episode_Reward/rotating_object: 69.3351
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.29s
                      Time elapsed: 00:11:49
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 42699 steps/s (collection: 2.191s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 96.2676
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 50.5953
                       Mean reward: 347.68
               Mean episode length: 218.41
    Episode_Reward/reaching_object: 1.1433
    Episode_Reward/rotating_object: 74.8036
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.30s
                      Time elapsed: 00:11:52
                               ETA: 00:44:52

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 42058 steps/s (collection: 2.221s, learning 0.116s)
             Mean action noise std: 1.71
          Mean value_function loss: 93.5950
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.6008
                       Mean reward: 338.05
               Mean episode length: 217.33
    Episode_Reward/reaching_object: 1.0827
    Episode_Reward/rotating_object: 65.3863
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.34s
                      Time elapsed: 00:11:54
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 42048 steps/s (collection: 2.210s, learning 0.128s)
             Mean action noise std: 1.71
          Mean value_function loss: 102.2740
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 50.6080
                       Mean reward: 412.18
               Mean episode length: 223.20
    Episode_Reward/reaching_object: 1.1273
    Episode_Reward/rotating_object: 70.6597
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.34s
                      Time elapsed: 00:11:56
                               ETA: 00:44:48

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 41790 steps/s (collection: 2.224s, learning 0.128s)
             Mean action noise std: 1.71
          Mean value_function loss: 105.4407
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.6177
                       Mean reward: 380.98
               Mean episode length: 220.23
    Episode_Reward/reaching_object: 1.1524
    Episode_Reward/rotating_object: 73.5327
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.35s
                      Time elapsed: 00:11:59
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 41979 steps/s (collection: 2.230s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 109.0464
               Mean surrogate loss: 0.0041
                 Mean entropy loss: 50.6272
                       Mean reward: 357.15
               Mean episode length: 220.90
    Episode_Reward/reaching_object: 1.1567
    Episode_Reward/rotating_object: 73.5953
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.34s
                      Time elapsed: 00:12:01
                               ETA: 00:44:44

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 42758 steps/s (collection: 2.186s, learning 0.113s)
             Mean action noise std: 1.71
          Mean value_function loss: 115.3171
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 50.6296
                       Mean reward: 408.39
               Mean episode length: 224.17
    Episode_Reward/reaching_object: 1.1430
    Episode_Reward/rotating_object: 74.8183
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.30s
                      Time elapsed: 00:12:03
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 42317 steps/s (collection: 2.212s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 107.0144
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 50.6318
                       Mean reward: 333.22
               Mean episode length: 209.89
    Episode_Reward/reaching_object: 1.1686
    Episode_Reward/rotating_object: 74.4409
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.32s
                      Time elapsed: 00:12:06
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 42467 steps/s (collection: 2.204s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 94.9121
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.6350
                       Mean reward: 338.02
               Mean episode length: 217.85
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 71.7827
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.31s
                      Time elapsed: 00:12:08
                               ETA: 00:44:37

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 42354 steps/s (collection: 2.210s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 103.4792
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 50.6427
                       Mean reward: 367.76
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 1.1679
    Episode_Reward/rotating_object: 73.9826
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.32s
                      Time elapsed: 00:12:10
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 42347 steps/s (collection: 2.211s, learning 0.111s)
             Mean action noise std: 1.71
          Mean value_function loss: 96.9423
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 50.6574
                       Mean reward: 375.36
               Mean episode length: 220.81
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 76.1947
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.32s
                      Time elapsed: 00:12:13
                               ETA: 00:44:33

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 42460 steps/s (collection: 2.201s, learning 0.114s)
             Mean action noise std: 1.71
          Mean value_function loss: 102.7765
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 50.6735
                       Mean reward: 365.43
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.1549
    Episode_Reward/rotating_object: 72.8856
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.32s
                      Time elapsed: 00:12:15
                               ETA: 00:44:31

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 41964 steps/s (collection: 2.227s, learning 0.115s)
             Mean action noise std: 1.72
          Mean value_function loss: 104.6909
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 50.6904
                       Mean reward: 382.85
               Mean episode length: 225.50
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 77.1635
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.34s
                      Time elapsed: 00:12:17
                               ETA: 00:44:29

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 42167 steps/s (collection: 2.220s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 107.1497
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 50.6991
                       Mean reward: 397.56
               Mean episode length: 221.57
    Episode_Reward/reaching_object: 1.1814
    Episode_Reward/rotating_object: 81.6428
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.33s
                      Time elapsed: 00:12:20
                               ETA: 00:44:27

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 42358 steps/s (collection: 2.207s, learning 0.114s)
             Mean action noise std: 1.72
          Mean value_function loss: 106.2492
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 50.7133
                       Mean reward: 426.75
               Mean episode length: 223.26
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 80.8782
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.32s
                      Time elapsed: 00:12:22
                               ETA: 00:44:25

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 41967 steps/s (collection: 2.212s, learning 0.131s)
             Mean action noise std: 1.72
          Mean value_function loss: 111.8195
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 50.7226
                       Mean reward: 393.68
               Mean episode length: 223.24
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 80.5238
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.34s
                      Time elapsed: 00:12:24
                               ETA: 00:44:23

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 42600 steps/s (collection: 2.197s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 105.0049
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 50.7316
                       Mean reward: 407.99
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.2020
    Episode_Reward/rotating_object: 80.5267
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.31s
                      Time elapsed: 00:12:27
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 43647 steps/s (collection: 2.141s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 98.0583
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.7404
                       Mean reward: 410.48
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 81.6370
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.25s
                      Time elapsed: 00:12:29
                               ETA: 00:44:18

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 43307 steps/s (collection: 2.158s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 97.9657
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 50.7458
                       Mean reward: 398.79
               Mean episode length: 232.03
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 79.2035
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.27s
                      Time elapsed: 00:12:31
                               ETA: 00:44:16

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 43054 steps/s (collection: 2.173s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 114.4257
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.7519
                       Mean reward: 415.75
               Mean episode length: 217.15
    Episode_Reward/reaching_object: 1.1642
    Episode_Reward/rotating_object: 80.8341
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.28s
                      Time elapsed: 00:12:33
                               ETA: 00:44:14

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 43499 steps/s (collection: 2.149s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 101.2396
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 50.7637
                       Mean reward: 451.17
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.1854
    Episode_Reward/rotating_object: 82.2681
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.26s
                      Time elapsed: 00:12:36
                               ETA: 00:44:12

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 43221 steps/s (collection: 2.163s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 113.4875
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 50.7736
                       Mean reward: 411.83
               Mean episode length: 218.09
    Episode_Reward/reaching_object: 1.1762
    Episode_Reward/rotating_object: 80.5533
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 2.27s
                      Time elapsed: 00:12:38
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 42612 steps/s (collection: 2.195s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 123.9155
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 50.7845
                       Mean reward: 413.82
               Mean episode length: 219.80
    Episode_Reward/reaching_object: 1.1776
    Episode_Reward/rotating_object: 78.8833
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 2.31s
                      Time elapsed: 00:12:40
                               ETA: 00:44:07

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 42342 steps/s (collection: 2.210s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 113.8162
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 50.7990
                       Mean reward: 388.12
               Mean episode length: 218.96
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 81.7161
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 2.32s
                      Time elapsed: 00:12:43
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 42577 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 1.72
          Mean value_function loss: 109.1512
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 50.8070
                       Mean reward: 401.85
               Mean episode length: 230.35
    Episode_Reward/reaching_object: 1.1566
    Episode_Reward/rotating_object: 74.3683
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 2.31s
                      Time elapsed: 00:12:45
                               ETA: 00:44:03

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 42294 steps/s (collection: 2.211s, learning 0.113s)
             Mean action noise std: 1.72
          Mean value_function loss: 108.9117
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 50.8180
                       Mean reward: 434.49
               Mean episode length: 228.85
    Episode_Reward/reaching_object: 1.1849
    Episode_Reward/rotating_object: 79.8849
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 2.32s
                      Time elapsed: 00:12:47
                               ETA: 00:44:01

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 41587 steps/s (collection: 2.242s, learning 0.122s)
             Mean action noise std: 1.73
          Mean value_function loss: 107.7218
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 50.8260
                       Mean reward: 405.05
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.2024
    Episode_Reward/rotating_object: 81.5226
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 2.36s
                      Time elapsed: 00:12:50
                               ETA: 00:43:59

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 42087 steps/s (collection: 2.219s, learning 0.117s)
             Mean action noise std: 1.73
          Mean value_function loss: 105.7126
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 50.8349
                       Mean reward: 372.78
               Mean episode length: 212.62
    Episode_Reward/reaching_object: 1.1666
    Episode_Reward/rotating_object: 76.1313
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 2.34s
                      Time elapsed: 00:12:52
                               ETA: 00:43:57

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 41669 steps/s (collection: 2.246s, learning 0.113s)
             Mean action noise std: 1.73
          Mean value_function loss: 118.3619
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 50.8439
                       Mean reward: 387.88
               Mean episode length: 217.77
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 79.2269
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 2.36s
                      Time elapsed: 00:12:54
                               ETA: 00:43:55

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 42306 steps/s (collection: 2.201s, learning 0.122s)
             Mean action noise std: 1.73
          Mean value_function loss: 107.4305
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 50.8555
                       Mean reward: 426.10
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.1857
    Episode_Reward/rotating_object: 80.2002
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 2.32s
                      Time elapsed: 00:12:57
                               ETA: 00:43:53

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 42201 steps/s (collection: 2.215s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 108.6490
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 50.8699
                       Mean reward: 392.78
               Mean episode length: 224.31
    Episode_Reward/reaching_object: 1.2033
    Episode_Reward/rotating_object: 81.0265
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.33s
                      Time elapsed: 00:12:59
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 42337 steps/s (collection: 2.210s, learning 0.112s)
             Mean action noise std: 1.73
          Mean value_function loss: 99.8217
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 50.8812
                       Mean reward: 409.01
               Mean episode length: 221.99
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 80.0706
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.32s
                      Time elapsed: 00:13:01
                               ETA: 00:43:49

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 42016 steps/s (collection: 2.224s, learning 0.116s)
             Mean action noise std: 1.73
          Mean value_function loss: 85.8042
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 50.8964
                       Mean reward: 326.77
               Mean episode length: 199.44
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 79.8354
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.34s
                      Time elapsed: 00:13:04
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 42410 steps/s (collection: 2.207s, learning 0.111s)
             Mean action noise std: 1.73
          Mean value_function loss: 88.3282
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.9112
                       Mean reward: 414.32
               Mean episode length: 224.96
    Episode_Reward/reaching_object: 1.1823
    Episode_Reward/rotating_object: 81.2956
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.32s
                      Time elapsed: 00:13:06
                               ETA: 00:43:45

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 41963 steps/s (collection: 2.228s, learning 0.114s)
             Mean action noise std: 1.73
          Mean value_function loss: 95.8361
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 50.9270
                       Mean reward: 432.08
               Mean episode length: 235.53
    Episode_Reward/reaching_object: 1.2001
    Episode_Reward/rotating_object: 86.6281
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.34s
                      Time elapsed: 00:13:08
                               ETA: 00:43:42

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 41941 steps/s (collection: 2.231s, learning 0.113s)
             Mean action noise std: 1.73
          Mean value_function loss: 86.8976
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 50.9418
                       Mean reward: 387.38
               Mean episode length: 217.37
    Episode_Reward/reaching_object: 1.1948
    Episode_Reward/rotating_object: 82.4729
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.34s
                      Time elapsed: 00:13:11
                               ETA: 00:43:40

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 42854 steps/s (collection: 2.182s, learning 0.112s)
             Mean action noise std: 1.73
          Mean value_function loss: 91.5883
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 50.9544
                       Mean reward: 425.87
               Mean episode length: 219.90
    Episode_Reward/reaching_object: 1.1740
    Episode_Reward/rotating_object: 85.9565
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.29s
                      Time elapsed: 00:13:13
                               ETA: 00:43:38

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 42891 steps/s (collection: 2.181s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 93.1324
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 50.9611
                       Mean reward: 434.45
               Mean episode length: 219.43
    Episode_Reward/reaching_object: 1.1803
    Episode_Reward/rotating_object: 86.7164
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.29s
                      Time elapsed: 00:13:15
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 43404 steps/s (collection: 2.149s, learning 0.116s)
             Mean action noise std: 1.74
          Mean value_function loss: 99.8048
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 50.9706
                       Mean reward: 445.11
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 1.2042
    Episode_Reward/rotating_object: 86.0927
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.26s
                      Time elapsed: 00:13:17
                               ETA: 00:43:34

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 43611 steps/s (collection: 2.139s, learning 0.115s)
             Mean action noise std: 1.74
          Mean value_function loss: 100.8017
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 50.9825
                       Mean reward: 415.11
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 1.1591
    Episode_Reward/rotating_object: 80.6953
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.25s
                      Time elapsed: 00:13:20
                               ETA: 00:43:31

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 43656 steps/s (collection: 2.141s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 101.4062
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 50.9932
                       Mean reward: 427.58
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 1.1696
    Episode_Reward/rotating_object: 82.4608
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.25s
                      Time elapsed: 00:13:22
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 43839 steps/s (collection: 2.131s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 102.0956
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.0019
                       Mean reward: 410.01
               Mean episode length: 216.89
    Episode_Reward/reaching_object: 1.1976
    Episode_Reward/rotating_object: 83.9121
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.24s
                      Time elapsed: 00:13:24
                               ETA: 00:43:27

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 43475 steps/s (collection: 2.150s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 100.8725
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 51.0126
                       Mean reward: 379.45
               Mean episode length: 213.59
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 81.7927
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.26s
                      Time elapsed: 00:13:26
                               ETA: 00:43:24

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 43702 steps/s (collection: 2.139s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 100.8606
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 51.0197
                       Mean reward: 449.45
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.2002
    Episode_Reward/rotating_object: 84.6588
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.25s
                      Time elapsed: 00:13:29
                               ETA: 00:43:22

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 43076 steps/s (collection: 2.170s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 109.0331
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.0303
                       Mean reward: 460.25
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.2163
    Episode_Reward/rotating_object: 85.6882
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.28s
                      Time elapsed: 00:13:31
                               ETA: 00:43:20

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 42899 steps/s (collection: 2.176s, learning 0.116s)
             Mean action noise std: 1.74
          Mean value_function loss: 106.5613
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 51.0368
                       Mean reward: 422.25
               Mean episode length: 218.47
    Episode_Reward/reaching_object: 1.2362
    Episode_Reward/rotating_object: 89.0810
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.29s
                      Time elapsed: 00:13:33
                               ETA: 00:43:18

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 42272 steps/s (collection: 2.212s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 98.3144
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.0414
                       Mean reward: 460.54
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 88.5748
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.33s
                      Time elapsed: 00:13:36
                               ETA: 00:43:15

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 42602 steps/s (collection: 2.194s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 105.0030
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 51.0497
                       Mean reward: 471.53
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.2601
    Episode_Reward/rotating_object: 88.6350
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.31s
                      Time elapsed: 00:13:38
                               ETA: 00:43:13

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 42792 steps/s (collection: 2.186s, learning 0.111s)
             Mean action noise std: 1.74
          Mean value_function loss: 116.8237
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.0579
                       Mean reward: 452.16
               Mean episode length: 225.34
    Episode_Reward/reaching_object: 1.1966
    Episode_Reward/rotating_object: 88.2915
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.30s
                      Time elapsed: 00:13:40
                               ETA: 00:43:11

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 42288 steps/s (collection: 2.213s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 99.7921
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 51.0715
                       Mean reward: 442.53
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 1.2357
    Episode_Reward/rotating_object: 90.6184
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.32s
                      Time elapsed: 00:13:42
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 42855 steps/s (collection: 2.181s, learning 0.113s)
             Mean action noise std: 1.74
          Mean value_function loss: 102.5592
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 51.0866
                       Mean reward: 483.71
               Mean episode length: 234.43
    Episode_Reward/reaching_object: 1.2552
    Episode_Reward/rotating_object: 93.3924
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.29s
                      Time elapsed: 00:13:45
                               ETA: 00:43:07

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 42835 steps/s (collection: 2.184s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 100.3786
               Mean surrogate loss: 0.0009
                 Mean entropy loss: 51.0963
                       Mean reward: 474.24
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.2257
    Episode_Reward/rotating_object: 90.9627
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.29s
                      Time elapsed: 00:13:47
                               ETA: 00:43:05

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 42690 steps/s (collection: 2.189s, learning 0.114s)
             Mean action noise std: 1.75
          Mean value_function loss: 100.6083
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.1020
                       Mean reward: 439.10
               Mean episode length: 223.37
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 90.5208
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.30s
                      Time elapsed: 00:13:49
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 42809 steps/s (collection: 2.182s, learning 0.114s)
             Mean action noise std: 1.75
          Mean value_function loss: 93.1580
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.1083
                       Mean reward: 429.26
               Mean episode length: 226.93
    Episode_Reward/reaching_object: 1.2044
    Episode_Reward/rotating_object: 88.6193
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.30s
                      Time elapsed: 00:13:52
                               ETA: 00:43:00

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 42817 steps/s (collection: 2.184s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 99.4287
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 51.1142
                       Mean reward: 509.53
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.2246
    Episode_Reward/rotating_object: 92.6386
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.30s
                      Time elapsed: 00:13:54
                               ETA: 00:42:58

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 43221 steps/s (collection: 2.164s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.8048
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 51.1253
                       Mean reward: 442.08
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.1924
    Episode_Reward/rotating_object: 87.6150
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.27s
                      Time elapsed: 00:13:56
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 43150 steps/s (collection: 2.167s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.2302
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 51.1388
                       Mean reward: 458.25
               Mean episode length: 230.13
    Episode_Reward/reaching_object: 1.1890
    Episode_Reward/rotating_object: 90.1536
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.28s
                      Time elapsed: 00:13:59
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 43006 steps/s (collection: 2.174s, learning 0.112s)
             Mean action noise std: 1.75
          Mean value_function loss: 101.1317
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 51.1465
                       Mean reward: 499.06
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.1955
    Episode_Reward/rotating_object: 92.5695
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.29s
                      Time elapsed: 00:14:01
                               ETA: 00:42:51

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 42793 steps/s (collection: 2.183s, learning 0.114s)
             Mean action noise std: 1.75
          Mean value_function loss: 100.0458
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 51.1485
                       Mean reward: 470.06
               Mean episode length: 226.57
    Episode_Reward/reaching_object: 1.2043
    Episode_Reward/rotating_object: 89.9492
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.30s
                      Time elapsed: 00:14:03
                               ETA: 00:42:49

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 43975 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 102.6327
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 51.1543
                       Mean reward: 495.37
               Mean episode length: 224.14
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 93.2709
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.24s
                      Time elapsed: 00:14:05
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 44041 steps/s (collection: 2.122s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 107.1311
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.1642
                       Mean reward: 445.07
               Mean episode length: 220.44
    Episode_Reward/reaching_object: 1.1637
    Episode_Reward/rotating_object: 86.2057
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.23s
                      Time elapsed: 00:14:08
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 43975 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 120.7074
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 51.1796
                       Mean reward: 475.25
               Mean episode length: 225.67
    Episode_Reward/reaching_object: 1.1847
    Episode_Reward/rotating_object: 87.3964
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.24s
                      Time elapsed: 00:14:10
                               ETA: 00:42:42

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 43985 steps/s (collection: 2.124s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 120.1466
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.1860
                       Mean reward: 491.56
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 1.2012
    Episode_Reward/rotating_object: 94.8362
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.23s
                      Time elapsed: 00:14:12
                               ETA: 00:42:39

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 44308 steps/s (collection: 2.108s, learning 0.111s)
             Mean action noise std: 1.75
          Mean value_function loss: 105.6636
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 51.1926
                       Mean reward: 452.17
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 1.1903
    Episode_Reward/rotating_object: 91.6093
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.22s
                      Time elapsed: 00:14:14
                               ETA: 00:42:37

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 43694 steps/s (collection: 2.139s, learning 0.110s)
             Mean action noise std: 1.75
          Mean value_function loss: 110.0625
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 51.2015
                       Mean reward: 457.71
               Mean episode length: 219.94
    Episode_Reward/reaching_object: 1.2289
    Episode_Reward/rotating_object: 94.6624
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.25s
                      Time elapsed: 00:14:17
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 43602 steps/s (collection: 2.141s, learning 0.113s)
             Mean action noise std: 1.75
          Mean value_function loss: 115.6557
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.2128
                       Mean reward: 468.80
               Mean episode length: 223.72
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 93.9474
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.25s
                      Time elapsed: 00:14:19
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 43240 steps/s (collection: 2.162s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 100.6626
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 51.2215
                       Mean reward: 481.22
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 93.0989
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.27s
                      Time elapsed: 00:14:21
                               ETA: 00:42:30

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 43003 steps/s (collection: 2.171s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 96.7960
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.2299
                       Mean reward: 507.89
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.2348
    Episode_Reward/rotating_object: 93.8470
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.29s
                      Time elapsed: 00:14:23
                               ETA: 00:42:28

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 43158 steps/s (collection: 2.165s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 112.2178
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 51.2460
                       Mean reward: 474.40
               Mean episode length: 224.66
    Episode_Reward/reaching_object: 1.2415
    Episode_Reward/rotating_object: 92.8975
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.28s
                      Time elapsed: 00:14:26
                               ETA: 00:42:26

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 43329 steps/s (collection: 2.155s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 104.5373
               Mean surrogate loss: 0.0056
                 Mean entropy loss: 51.2541
                       Mean reward: 466.97
               Mean episode length: 215.90
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 96.5716
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.27s
                      Time elapsed: 00:14:28
                               ETA: 00:42:23

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 43239 steps/s (collection: 2.158s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 123.6530
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 51.2555
                       Mean reward: 516.72
               Mean episode length: 230.79
    Episode_Reward/reaching_object: 1.2294
    Episode_Reward/rotating_object: 97.3992
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.27s
                      Time elapsed: 00:14:30
                               ETA: 00:42:21

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 43163 steps/s (collection: 2.163s, learning 0.115s)
             Mean action noise std: 1.76
          Mean value_function loss: 137.1530
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.2597
                       Mean reward: 500.45
               Mean episode length: 232.92
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 92.4938
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.28s
                      Time elapsed: 00:14:32
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 42616 steps/s (collection: 2.192s, learning 0.114s)
             Mean action noise std: 1.76
          Mean value_function loss: 155.0801
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 51.2679
                       Mean reward: 461.65
               Mean episode length: 223.80
    Episode_Reward/reaching_object: 1.2067
    Episode_Reward/rotating_object: 91.6201
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.31s
                      Time elapsed: 00:14:35
                               ETA: 00:42:17

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 42751 steps/s (collection: 2.186s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 162.5787
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 51.2788
                       Mean reward: 472.48
               Mean episode length: 221.12
    Episode_Reward/reaching_object: 1.1887
    Episode_Reward/rotating_object: 90.3808
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.30s
                      Time elapsed: 00:14:37
                               ETA: 00:42:14

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 42797 steps/s (collection: 2.186s, learning 0.111s)
             Mean action noise std: 1.76
          Mean value_function loss: 138.3760
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 51.2883
                       Mean reward: 463.92
               Mean episode length: 224.48
    Episode_Reward/reaching_object: 1.2230
    Episode_Reward/rotating_object: 91.4266
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.30s
                      Time elapsed: 00:14:39
                               ETA: 00:42:12

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 42281 steps/s (collection: 2.212s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 138.5835
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 51.3013
                       Mean reward: 474.15
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 1.2037
    Episode_Reward/rotating_object: 91.8453
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.32s
                      Time elapsed: 00:14:42
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 40456 steps/s (collection: 2.316s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 127.0516
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 51.3111
                       Mean reward: 457.03
               Mean episode length: 220.74
    Episode_Reward/reaching_object: 1.2452
    Episode_Reward/rotating_object: 96.8393
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.43s
                      Time elapsed: 00:14:44
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 40890 steps/s (collection: 2.288s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 135.0506
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.3222
                       Mean reward: 464.88
               Mean episode length: 220.21
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 93.3563
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.40s
                      Time elapsed: 00:14:46
                               ETA: 00:42:06

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 42533 steps/s (collection: 2.198s, learning 0.113s)
             Mean action noise std: 1.76
          Mean value_function loss: 106.5684
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.3370
                       Mean reward: 469.98
               Mean episode length: 219.99
    Episode_Reward/reaching_object: 1.2206
    Episode_Reward/rotating_object: 91.5450
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.31s
                      Time elapsed: 00:14:49
                               ETA: 00:42:04

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 43122 steps/s (collection: 2.167s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 112.8861
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 51.3510
                       Mean reward: 480.30
               Mean episode length: 220.43
    Episode_Reward/reaching_object: 1.2108
    Episode_Reward/rotating_object: 93.2850
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.28s
                      Time elapsed: 00:14:51
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 43066 steps/s (collection: 2.170s, learning 0.113s)
             Mean action noise std: 1.77
          Mean value_function loss: 106.3712
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 51.3613
                       Mean reward: 515.34
               Mean episode length: 230.99
    Episode_Reward/reaching_object: 1.2678
    Episode_Reward/rotating_object: 97.2391
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.28s
                      Time elapsed: 00:14:53
                               ETA: 00:42:00

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 43937 steps/s (collection: 2.126s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 113.8371
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.3756
                       Mean reward: 493.74
               Mean episode length: 229.43
    Episode_Reward/reaching_object: 1.2464
    Episode_Reward/rotating_object: 96.3328
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.24s
                      Time elapsed: 00:14:56
                               ETA: 00:41:57

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 43913 steps/s (collection: 2.128s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 96.5838
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 51.3941
                       Mean reward: 531.07
               Mean episode length: 234.00
    Episode_Reward/reaching_object: 1.2763
    Episode_Reward/rotating_object: 101.4450
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.24s
                      Time elapsed: 00:14:58
                               ETA: 00:41:55

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 43757 steps/s (collection: 2.136s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 92.7931
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.4075
                       Mean reward: 490.21
               Mean episode length: 225.88
    Episode_Reward/reaching_object: 1.2697
    Episode_Reward/rotating_object: 100.7721
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.25s
                      Time elapsed: 00:15:00
                               ETA: 00:41:53

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 43918 steps/s (collection: 2.127s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 85.0708
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 51.4240
                       Mean reward: 496.24
               Mean episode length: 228.64
    Episode_Reward/reaching_object: 1.2591
    Episode_Reward/rotating_object: 98.4990
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.24s
                      Time elapsed: 00:15:02
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 44120 steps/s (collection: 2.117s, learning 0.111s)
             Mean action noise std: 1.77
          Mean value_function loss: 79.9511
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 51.4401
                       Mean reward: 514.21
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.2644
    Episode_Reward/rotating_object: 100.7881
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.23s
                      Time elapsed: 00:15:05
                               ETA: 00:41:48

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 44171 steps/s (collection: 2.111s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 78.7493
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 51.4504
                       Mean reward: 572.41
               Mean episode length: 239.97
    Episode_Reward/reaching_object: 1.2819
    Episode_Reward/rotating_object: 103.8335
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.23s
                      Time elapsed: 00:15:07
                               ETA: 00:41:45

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 42108 steps/s (collection: 2.208s, learning 0.127s)
             Mean action noise std: 1.77
          Mean value_function loss: 85.3427
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 51.4548
                       Mean reward: 516.66
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.2291
    Episode_Reward/rotating_object: 99.7119
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.33s
                      Time elapsed: 00:15:09
                               ETA: 00:41:43

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 41790 steps/s (collection: 2.241s, learning 0.112s)
             Mean action noise std: 1.77
          Mean value_function loss: 92.6573
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 51.4629
                       Mean reward: 534.27
               Mean episode length: 230.32
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 100.2090
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.35s
                      Time elapsed: 00:15:11
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 43474 steps/s (collection: 2.148s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 89.6199
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 51.4798
                       Mean reward: 491.27
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 98.7033
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.26s
                      Time elapsed: 00:15:14
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 42962 steps/s (collection: 2.174s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 93.8749
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 51.4940
                       Mean reward: 486.92
               Mean episode length: 226.13
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 96.1642
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.29s
                      Time elapsed: 00:15:16
                               ETA: 00:41:37

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 42882 steps/s (collection: 2.179s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 85.2351
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 51.5003
                       Mean reward: 489.83
               Mean episode length: 227.89
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 101.4830
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.29s
                      Time elapsed: 00:15:18
                               ETA: 00:41:34

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 42919 steps/s (collection: 2.176s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 90.0367
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.5092
                       Mean reward: 498.67
               Mean episode length: 223.44
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 100.5536
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.29s
                      Time elapsed: 00:15:21
                               ETA: 00:41:32

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 42317 steps/s (collection: 2.211s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 102.2814
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 51.5181
                       Mean reward: 507.58
               Mean episode length: 228.13
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 99.8371
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.32s
                      Time elapsed: 00:15:23
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 43120 steps/s (collection: 2.162s, learning 0.117s)
             Mean action noise std: 1.78
          Mean value_function loss: 100.3641
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 51.5294
                       Mean reward: 512.29
               Mean episode length: 231.03
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 101.7857
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.28s
                      Time elapsed: 00:15:25
                               ETA: 00:41:28

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 43300 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 105.5879
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 51.5386
                       Mean reward: 508.35
               Mean episode length: 231.59
    Episode_Reward/reaching_object: 1.2264
    Episode_Reward/rotating_object: 99.7954
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.27s
                      Time elapsed: 00:15:27
                               ETA: 00:41:25

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 42740 steps/s (collection: 2.186s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 97.2775
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.5463
                       Mean reward: 524.38
               Mean episode length: 233.22
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 99.8693
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.30s
                      Time elapsed: 00:15:30
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 42464 steps/s (collection: 2.202s, learning 0.113s)
             Mean action noise std: 1.78
          Mean value_function loss: 85.0840
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 51.5561
                       Mean reward: 513.36
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.2657
    Episode_Reward/rotating_object: 103.2130
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.31s
                      Time elapsed: 00:15:32
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 42505 steps/s (collection: 2.197s, learning 0.116s)
             Mean action noise std: 1.78
          Mean value_function loss: 93.2911
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.5707
                       Mean reward: 489.74
               Mean episode length: 222.40
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 100.6650
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.31s
                      Time elapsed: 00:15:34
                               ETA: 00:41:19

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 42976 steps/s (collection: 2.173s, learning 0.114s)
             Mean action noise std: 1.78
          Mean value_function loss: 93.2173
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 51.5859
                       Mean reward: 535.49
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 101.7393
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.29s
                      Time elapsed: 00:15:37
                               ETA: 00:41:17

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 42298 steps/s (collection: 2.212s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 94.1343
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 51.5967
                       Mean reward: 565.09
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 1.2665
    Episode_Reward/rotating_object: 107.0252
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.32s
                      Time elapsed: 00:15:39
                               ETA: 00:41:15

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 43575 steps/s (collection: 2.145s, learning 0.111s)
             Mean action noise std: 1.78
          Mean value_function loss: 91.7871
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 51.6143
                       Mean reward: 553.01
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.2757
    Episode_Reward/rotating_object: 107.1929
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.26s
                      Time elapsed: 00:15:41
                               ETA: 00:41:12

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 44236 steps/s (collection: 2.112s, learning 0.110s)
             Mean action noise std: 1.79
          Mean value_function loss: 95.3511
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.6268
                       Mean reward: 485.93
               Mean episode length: 225.45
    Episode_Reward/reaching_object: 1.2505
    Episode_Reward/rotating_object: 100.3993
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.22s
                      Time elapsed: 00:15:43
                               ETA: 00:41:10

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 44336 steps/s (collection: 2.106s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 88.5950
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 51.6361
                       Mean reward: 516.58
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.2710
    Episode_Reward/rotating_object: 104.5007
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.22s
                      Time elapsed: 00:15:46
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 44041 steps/s (collection: 2.121s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 93.9377
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 51.6414
                       Mean reward: 537.29
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.2776
    Episode_Reward/rotating_object: 107.1083
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.23s
                      Time elapsed: 00:15:48
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 44068 steps/s (collection: 2.119s, learning 0.112s)
             Mean action noise std: 1.79
          Mean value_function loss: 88.4317
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.6489
                       Mean reward: 518.66
               Mean episode length: 230.90
    Episode_Reward/reaching_object: 1.2661
    Episode_Reward/rotating_object: 103.2862
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.23s
                      Time elapsed: 00:15:50
                               ETA: 00:41:03

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 44008 steps/s (collection: 2.122s, learning 0.112s)
             Mean action noise std: 1.79
          Mean value_function loss: 86.7177
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 51.6616
                       Mean reward: 581.85
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.2516
    Episode_Reward/rotating_object: 107.7429
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.23s
                      Time elapsed: 00:15:52
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 44035 steps/s (collection: 2.121s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 85.2376
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.6720
                       Mean reward: 536.63
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.2613
    Episode_Reward/rotating_object: 105.8172
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.23s
                      Time elapsed: 00:15:55
                               ETA: 00:40:58

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 43462 steps/s (collection: 2.150s, learning 0.112s)
             Mean action noise std: 1.79
          Mean value_function loss: 114.4224
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.6860
                       Mean reward: 492.03
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.2575
    Episode_Reward/rotating_object: 106.7321
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.26s
                      Time elapsed: 00:15:57
                               ETA: 00:40:56

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 42902 steps/s (collection: 2.175s, learning 0.117s)
             Mean action noise std: 1.79
          Mean value_function loss: 103.2180
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 51.6975
                       Mean reward: 471.26
               Mean episode length: 212.18
    Episode_Reward/reaching_object: 1.2208
    Episode_Reward/rotating_object: 102.5639
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.29s
                      Time elapsed: 00:15:59
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 42757 steps/s (collection: 2.186s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 92.3663
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.7062
                       Mean reward: 529.08
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.2436
    Episode_Reward/rotating_object: 106.8729
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.30s
                      Time elapsed: 00:16:01
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 43099 steps/s (collection: 2.167s, learning 0.114s)
             Mean action noise std: 1.79
          Mean value_function loss: 89.6341
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 51.7243
                       Mean reward: 537.90
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.2682
    Episode_Reward/rotating_object: 106.3936
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.28s
                      Time elapsed: 00:16:04
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 43341 steps/s (collection: 2.155s, learning 0.113s)
             Mean action noise std: 1.79
          Mean value_function loss: 90.5476
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 51.7443
                       Mean reward: 542.42
               Mean episode length: 229.74
    Episode_Reward/reaching_object: 1.2282
    Episode_Reward/rotating_object: 103.7147
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.27s
                      Time elapsed: 00:16:06
                               ETA: 00:40:47

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 43061 steps/s (collection: 2.168s, learning 0.115s)
             Mean action noise std: 1.80
          Mean value_function loss: 95.0204
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 51.7571
                       Mean reward: 523.09
               Mean episode length: 222.36
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 105.3282
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.28s
                      Time elapsed: 00:16:08
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 43201 steps/s (collection: 2.162s, learning 0.113s)
             Mean action noise std: 1.80
          Mean value_function loss: 99.3502
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.7706
                       Mean reward: 564.48
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.2560
    Episode_Reward/rotating_object: 109.5141
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.28s
                      Time elapsed: 00:16:11
                               ETA: 00:40:42

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 42814 steps/s (collection: 2.182s, learning 0.114s)
             Mean action noise std: 1.80
          Mean value_function loss: 84.4788
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.7849
                       Mean reward: 554.62
               Mean episode length: 226.86
    Episode_Reward/reaching_object: 1.2573
    Episode_Reward/rotating_object: 109.2661
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.30s
                      Time elapsed: 00:16:13
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 43426 steps/s (collection: 2.148s, learning 0.115s)
             Mean action noise std: 1.80
          Mean value_function loss: 91.2200
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.8012
                       Mean reward: 535.91
               Mean episode length: 228.62
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 105.7146
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.26s
                      Time elapsed: 00:16:15
                               ETA: 00:40:38

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 43190 steps/s (collection: 2.161s, learning 0.115s)
             Mean action noise std: 1.80
          Mean value_function loss: 86.1043
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 51.8175
                       Mean reward: 560.33
               Mean episode length: 239.19
    Episode_Reward/reaching_object: 1.2513
    Episode_Reward/rotating_object: 105.9811
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.28s
                      Time elapsed: 00:16:17
                               ETA: 00:40:35

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 43280 steps/s (collection: 2.156s, learning 0.115s)
             Mean action noise std: 1.80
          Mean value_function loss: 87.1672
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 51.8341
                       Mean reward: 512.30
               Mean episode length: 220.59
    Episode_Reward/reaching_object: 1.1996
    Episode_Reward/rotating_object: 100.4252
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.27s
                      Time elapsed: 00:16:20
                               ETA: 00:40:33

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 42970 steps/s (collection: 2.176s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 102.2906
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.8475
                       Mean reward: 522.97
               Mean episode length: 215.47
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 106.4314
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.29s
                      Time elapsed: 00:16:22
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 43367 steps/s (collection: 2.151s, learning 0.116s)
             Mean action noise std: 1.80
          Mean value_function loss: 93.5904
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 51.8659
                       Mean reward: 559.73
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 1.2501
    Episode_Reward/rotating_object: 107.0790
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.27s
                      Time elapsed: 00:16:24
                               ETA: 00:40:28

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 43356 steps/s (collection: 2.153s, learning 0.114s)
             Mean action noise std: 1.81
          Mean value_function loss: 92.4656
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 51.8820
                       Mean reward: 556.01
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 110.3824
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.27s
                      Time elapsed: 00:16:27
                               ETA: 00:40:26

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 43112 steps/s (collection: 2.168s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 87.8532
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 51.8966
                       Mean reward: 550.85
               Mean episode length: 225.62
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 112.0940
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.28s
                      Time elapsed: 00:16:29
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 44073 steps/s (collection: 2.119s, learning 0.111s)
             Mean action noise std: 1.81
          Mean value_function loss: 96.1130
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 51.9153
                       Mean reward: 551.41
               Mean episode length: 237.53
    Episode_Reward/reaching_object: 1.2850
    Episode_Reward/rotating_object: 111.5497
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.23s
                      Time elapsed: 00:16:31
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 44165 steps/s (collection: 2.113s, learning 0.113s)
             Mean action noise std: 1.81
          Mean value_function loss: 93.8907
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 51.9274
                       Mean reward: 508.82
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 103.1790
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.23s
                      Time elapsed: 00:16:33
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 44334 steps/s (collection: 2.104s, learning 0.113s)
             Mean action noise std: 1.81
          Mean value_function loss: 86.2861
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.9394
                       Mean reward: 530.77
               Mean episode length: 222.93
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 104.4289
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.22s
                      Time elapsed: 00:16:35
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 44289 steps/s (collection: 2.105s, learning 0.114s)
             Mean action noise std: 1.81
          Mean value_function loss: 82.9824
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 51.9571
                       Mean reward: 547.63
               Mean episode length: 237.57
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 106.0037
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.22s
                      Time elapsed: 00:16:38
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 44461 steps/s (collection: 2.100s, learning 0.111s)
             Mean action noise std: 1.81
          Mean value_function loss: 77.8793
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 51.9676
                       Mean reward: 573.44
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.2238
    Episode_Reward/rotating_object: 106.4932
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.21s
                      Time elapsed: 00:16:40
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 44555 steps/s (collection: 2.095s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 82.9380
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 51.9737
                       Mean reward: 535.27
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.2453
    Episode_Reward/rotating_object: 105.8469
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.21s
                      Time elapsed: 00:16:42
                               ETA: 00:40:09

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 43942 steps/s (collection: 2.125s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 93.1131
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 51.9804
                       Mean reward: 548.80
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 103.9428
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.24s
                      Time elapsed: 00:16:44
                               ETA: 00:40:07

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 43229 steps/s (collection: 2.161s, learning 0.113s)
             Mean action noise std: 1.81
          Mean value_function loss: 102.7961
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 51.9938
                       Mean reward: 504.50
               Mean episode length: 218.92
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 106.6879
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.27s
                      Time elapsed: 00:16:47
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 43721 steps/s (collection: 2.134s, learning 0.115s)
             Mean action noise std: 1.82
          Mean value_function loss: 92.7572
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 52.0115
                       Mean reward: 550.22
               Mean episode length: 227.84
    Episode_Reward/reaching_object: 1.2029
    Episode_Reward/rotating_object: 104.5604
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.25s
                      Time elapsed: 00:16:49
                               ETA: 00:40:02

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 43839 steps/s (collection: 2.129s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 88.6987
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 52.0264
                       Mean reward: 572.57
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 1.2476
    Episode_Reward/rotating_object: 109.9951
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0238
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.24s
                      Time elapsed: 00:16:51
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 42157 steps/s (collection: 2.202s, learning 0.130s)
             Mean action noise std: 1.82
          Mean value_function loss: 96.9757
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.0323
                       Mean reward: 513.73
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 106.1101
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.33s
                      Time elapsed: 00:16:53
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 43573 steps/s (collection: 2.144s, learning 0.112s)
             Mean action noise std: 1.82
          Mean value_function loss: 87.6563
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.0465
                       Mean reward: 574.23
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.2534
    Episode_Reward/rotating_object: 110.3588
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.26s
                      Time elapsed: 00:16:56
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 43377 steps/s (collection: 2.155s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 92.6692
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.0698
                       Mean reward: 548.36
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.2709
    Episode_Reward/rotating_object: 108.6539
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.27s
                      Time elapsed: 00:16:58
                               ETA: 00:39:53

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 43840 steps/s (collection: 2.129s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 108.6356
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.0908
                       Mean reward: 481.72
               Mean episode length: 215.08
    Episode_Reward/reaching_object: 1.2075
    Episode_Reward/rotating_object: 105.8175
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.24s
                      Time elapsed: 00:17:00
                               ETA: 00:39:51

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 43915 steps/s (collection: 2.126s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 96.6784
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.1102
                       Mean reward: 560.70
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 107.2165
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.24s
                      Time elapsed: 00:17:02
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 44040 steps/s (collection: 2.118s, learning 0.114s)
             Mean action noise std: 1.82
          Mean value_function loss: 78.3723
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.1217
                       Mean reward: 540.13
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.2519
    Episode_Reward/rotating_object: 111.1755
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.23s
                      Time elapsed: 00:17:05
                               ETA: 00:39:46

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 44258 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 1.82
          Mean value_function loss: 80.3565
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.1348
                       Mean reward: 547.21
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.2711
    Episode_Reward/rotating_object: 112.3656
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.22s
                      Time elapsed: 00:17:07
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 43812 steps/s (collection: 2.129s, learning 0.115s)
             Mean action noise std: 1.83
          Mean value_function loss: 91.2014
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.1504
                       Mean reward: 579.95
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 1.2564
    Episode_Reward/rotating_object: 111.9753
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.24s
                      Time elapsed: 00:17:09
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 43856 steps/s (collection: 2.128s, learning 0.113s)
             Mean action noise std: 1.83
          Mean value_function loss: 91.1070
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.1650
                       Mean reward: 550.16
               Mean episode length: 222.81
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 109.3083
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.24s
                      Time elapsed: 00:17:11
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 43049 steps/s (collection: 2.171s, learning 0.112s)
             Mean action noise std: 1.83
          Mean value_function loss: 85.6492
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.1787
                       Mean reward: 571.72
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.2374
    Episode_Reward/rotating_object: 110.0790
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.28s
                      Time elapsed: 00:17:14
                               ETA: 00:39:37

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 42920 steps/s (collection: 2.175s, learning 0.116s)
             Mean action noise std: 1.83
          Mean value_function loss: 100.6212
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 52.1889
                       Mean reward: 601.16
               Mean episode length: 239.32
    Episode_Reward/reaching_object: 1.2446
    Episode_Reward/rotating_object: 109.1305
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.29s
                      Time elapsed: 00:17:16
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 43350 steps/s (collection: 2.156s, learning 0.112s)
             Mean action noise std: 1.83
          Mean value_function loss: 90.3008
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.2085
                       Mean reward: 550.92
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.2654
    Episode_Reward/rotating_object: 114.7067
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.27s
                      Time elapsed: 00:17:18
                               ETA: 00:39:32

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 44636 steps/s (collection: 2.091s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 91.0817
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.2268
                       Mean reward: 540.19
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 111.2575
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.20s
                      Time elapsed: 00:17:20
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 45018 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 85.1903
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.2429
                       Mean reward: 551.12
               Mean episode length: 229.30
    Episode_Reward/reaching_object: 1.2464
    Episode_Reward/rotating_object: 108.5498
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.18s
                      Time elapsed: 00:17:23
                               ETA: 00:39:28

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 45065 steps/s (collection: 2.070s, learning 0.111s)
             Mean action noise std: 1.83
          Mean value_function loss: 92.6179
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.2609
                       Mean reward: 574.37
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 1.2690
    Episode_Reward/rotating_object: 114.5086
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.18s
                      Time elapsed: 00:17:25
                               ETA: 00:39:25

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 44934 steps/s (collection: 2.077s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 84.9321
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.2825
                       Mean reward: 557.31
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.2567
    Episode_Reward/rotating_object: 111.4936
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.19s
                      Time elapsed: 00:17:27
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 44916 steps/s (collection: 2.078s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 76.7836
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 52.2929
                       Mean reward: 539.56
               Mean episode length: 227.98
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 109.8621
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.19s
                      Time elapsed: 00:17:29
                               ETA: 00:39:20

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 44409 steps/s (collection: 2.102s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 85.3751
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 52.3041
                       Mean reward: 574.53
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.2702
    Episode_Reward/rotating_object: 111.3378
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.21s
                      Time elapsed: 00:17:31
                               ETA: 00:39:18

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 43688 steps/s (collection: 2.139s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 83.8348
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.3234
                       Mean reward: 547.08
               Mean episode length: 221.09
    Episode_Reward/reaching_object: 1.2326
    Episode_Reward/rotating_object: 109.4426
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.25s
                      Time elapsed: 00:17:34
                               ETA: 00:39:15

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 40325 steps/s (collection: 2.323s, learning 0.115s)
             Mean action noise std: 1.84
          Mean value_function loss: 86.2253
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 52.3414
                       Mean reward: 560.08
               Mean episode length: 236.91
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 111.6317
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.44s
                      Time elapsed: 00:17:36
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 40632 steps/s (collection: 2.305s, learning 0.114s)
             Mean action noise std: 1.84
          Mean value_function loss: 88.1853
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.3500
                       Mean reward: 556.80
               Mean episode length: 233.13
    Episode_Reward/reaching_object: 1.2524
    Episode_Reward/rotating_object: 112.6591
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.42s
                      Time elapsed: 00:17:38
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 41845 steps/s (collection: 2.236s, learning 0.113s)
             Mean action noise std: 1.84
          Mean value_function loss: 93.9352
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 52.3661
                       Mean reward: 568.14
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 108.8420
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.35s
                      Time elapsed: 00:17:41
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 43399 steps/s (collection: 2.154s, learning 0.111s)
             Mean action noise std: 1.84
          Mean value_function loss: 94.0747
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.3813
                       Mean reward: 563.54
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.2406
    Episode_Reward/rotating_object: 111.5274
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.27s
                      Time elapsed: 00:17:43
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 42036 steps/s (collection: 2.224s, learning 0.115s)
             Mean action noise std: 1.84
          Mean value_function loss: 105.6020
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 52.3926
                       Mean reward: 566.84
               Mean episode length: 225.36
    Episode_Reward/reaching_object: 1.2407
    Episode_Reward/rotating_object: 111.9880
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.34s
                      Time elapsed: 00:17:45
                               ETA: 00:39:05

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 41442 steps/s (collection: 2.258s, learning 0.114s)
             Mean action noise std: 1.84
          Mean value_function loss: 82.5000
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.3976
                       Mean reward: 553.45
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.2255
    Episode_Reward/rotating_object: 109.7631
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.37s
                      Time elapsed: 00:17:48
                               ETA: 00:39:03

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 43554 steps/s (collection: 2.131s, learning 0.126s)
             Mean action noise std: 1.85
          Mean value_function loss: 86.8035
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 52.4035
                       Mean reward: 541.38
               Mean episode length: 221.77
    Episode_Reward/reaching_object: 1.2496
    Episode_Reward/rotating_object: 112.9096
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.26s
                      Time elapsed: 00:17:50
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 43617 steps/s (collection: 2.110s, learning 0.144s)
             Mean action noise std: 1.85
          Mean value_function loss: 95.0610
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 52.4147
                       Mean reward: 563.13
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 111.4807
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.25s
                      Time elapsed: 00:17:52
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 43831 steps/s (collection: 2.106s, learning 0.137s)
             Mean action noise std: 1.85
          Mean value_function loss: 85.1159
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 52.4304
                       Mean reward: 628.91
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.2681
    Episode_Reward/rotating_object: 117.4673
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.24s
                      Time elapsed: 00:17:55
                               ETA: 00:38:56

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 43471 steps/s (collection: 2.101s, learning 0.161s)
             Mean action noise std: 1.85
          Mean value_function loss: 77.0906
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.4444
                       Mean reward: 589.99
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.2770
    Episode_Reward/rotating_object: 117.3754
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.26s
                      Time elapsed: 00:17:57
                               ETA: 00:38:54

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 43737 steps/s (collection: 2.110s, learning 0.138s)
             Mean action noise std: 1.85
          Mean value_function loss: 85.7540
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 52.4544
                       Mean reward: 582.59
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 113.8100
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.25s
                      Time elapsed: 00:17:59
                               ETA: 00:38:51

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 44241 steps/s (collection: 2.110s, learning 0.112s)
             Mean action noise std: 1.85
          Mean value_function loss: 95.3913
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 52.4661
                       Mean reward: 623.18
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 115.1711
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.22s
                      Time elapsed: 00:18:01
                               ETA: 00:38:49

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 42892 steps/s (collection: 2.179s, learning 0.113s)
             Mean action noise std: 1.85
          Mean value_function loss: 84.0026
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.4826
                       Mean reward: 617.64
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.2766
    Episode_Reward/rotating_object: 118.1479
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.29s
                      Time elapsed: 00:18:04
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 44316 steps/s (collection: 2.108s, learning 0.111s)
             Mean action noise std: 1.85
          Mean value_function loss: 101.5300
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.4996
                       Mean reward: 594.74
               Mean episode length: 230.53
    Episode_Reward/reaching_object: 1.2236
    Episode_Reward/rotating_object: 112.5885
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.22s
                      Time elapsed: 00:18:06
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 44972 steps/s (collection: 2.075s, learning 0.111s)
             Mean action noise std: 1.85
          Mean value_function loss: 90.4804
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.5141
                       Mean reward: 584.42
               Mean episode length: 223.13
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 114.9288
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.19s
                      Time elapsed: 00:18:08
                               ETA: 00:38:42

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 44758 steps/s (collection: 2.086s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 90.9328
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 52.5210
                       Mean reward: 564.67
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.2629
    Episode_Reward/rotating_object: 115.3582
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.20s
                      Time elapsed: 00:18:10
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 44408 steps/s (collection: 2.103s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 84.9224
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.5345
                       Mean reward: 525.63
               Mean episode length: 221.28
    Episode_Reward/reaching_object: 1.2536
    Episode_Reward/rotating_object: 113.9991
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.21s
                      Time elapsed: 00:18:12
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 45043 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 1.86
          Mean value_function loss: 93.7007
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 52.5436
                       Mean reward: 562.89
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.2287
    Episode_Reward/rotating_object: 113.4199
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.18s
                      Time elapsed: 00:18:15
                               ETA: 00:38:35

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 45422 steps/s (collection: 2.054s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 85.5895
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.5469
                       Mean reward: 574.99
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 1.2448
    Episode_Reward/rotating_object: 116.3017
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.16s
                      Time elapsed: 00:18:17
                               ETA: 00:38:32

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 45059 steps/s (collection: 2.071s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 80.9375
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.5556
                       Mean reward: 595.54
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.2615
    Episode_Reward/rotating_object: 117.3401
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.18s
                      Time elapsed: 00:18:19
                               ETA: 00:38:30

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 44878 steps/s (collection: 2.080s, learning 0.110s)
             Mean action noise std: 1.86
          Mean value_function loss: 78.0862
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 52.5757
                       Mean reward: 602.80
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.2441
    Episode_Reward/rotating_object: 117.5286
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.19s
                      Time elapsed: 00:18:21
                               ETA: 00:38:27

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 44882 steps/s (collection: 2.078s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 76.2613
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 52.5849
                       Mean reward: 613.04
               Mean episode length: 229.57
    Episode_Reward/reaching_object: 1.2789
    Episode_Reward/rotating_object: 121.9516
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.19s
                      Time elapsed: 00:18:23
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 44279 steps/s (collection: 2.107s, learning 0.113s)
             Mean action noise std: 1.86
          Mean value_function loss: 88.4746
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.5955
                       Mean reward: 557.72
               Mean episode length: 223.78
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 117.2239
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.22s
                      Time elapsed: 00:18:26
                               ETA: 00:38:22

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 44519 steps/s (collection: 2.096s, learning 0.112s)
             Mean action noise std: 1.86
          Mean value_function loss: 77.3798
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 52.6171
                       Mean reward: 622.27
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 118.2689
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.21s
                      Time elapsed: 00:18:28
                               ETA: 00:38:20

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 44371 steps/s (collection: 2.101s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 101.1750
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.6438
                       Mean reward: 504.72
               Mean episode length: 210.66
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 111.8742
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.22s
                      Time elapsed: 00:18:30
                               ETA: 00:38:18

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 43541 steps/s (collection: 2.145s, learning 0.113s)
             Mean action noise std: 1.87
          Mean value_function loss: 86.7669
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.6628
                       Mean reward: 609.93
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 118.3224
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.26s
                      Time elapsed: 00:18:32
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 43679 steps/s (collection: 2.137s, learning 0.114s)
             Mean action noise std: 1.87
          Mean value_function loss: 90.2837
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 52.6723
                       Mean reward: 599.56
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 1.2197
    Episode_Reward/rotating_object: 116.0517
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0220
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.25s
                      Time elapsed: 00:18:34
                               ETA: 00:38:13

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 44124 steps/s (collection: 2.116s, learning 0.112s)
             Mean action noise std: 1.87
          Mean value_function loss: 88.7576
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.6925
                       Mean reward: 628.92
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.2461
    Episode_Reward/rotating_object: 117.8691
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.23s
                      Time elapsed: 00:18:37
                               ETA: 00:38:11

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 44546 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 1.87
          Mean value_function loss: 85.0054
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.7165
                       Mean reward: 605.59
               Mean episode length: 231.96
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 121.2113
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.21s
                      Time elapsed: 00:18:39
                               ETA: 00:38:08

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 44105 steps/s (collection: 2.107s, learning 0.122s)
             Mean action noise std: 1.87
          Mean value_function loss: 93.8036
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 52.7326
                       Mean reward: 609.46
               Mean episode length: 228.99
    Episode_Reward/reaching_object: 1.2575
    Episode_Reward/rotating_object: 119.2454
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.23s
                      Time elapsed: 00:18:41
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 44190 steps/s (collection: 2.098s, learning 0.126s)
             Mean action noise std: 1.87
          Mean value_function loss: 114.0788
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.7501
                       Mean reward: 619.95
               Mean episode length: 233.73
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 115.7430
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.22s
                      Time elapsed: 00:18:43
                               ETA: 00:38:04

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 43554 steps/s (collection: 2.121s, learning 0.136s)
             Mean action noise std: 1.87
          Mean value_function loss: 93.9691
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 52.7602
                       Mean reward: 578.89
               Mean episode length: 226.14
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 118.5220
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.26s
                      Time elapsed: 00:18:46
                               ETA: 00:38:01

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 44307 steps/s (collection: 2.104s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 91.2261
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 52.7781
                       Mean reward: 570.17
               Mean episode length: 219.24
    Episode_Reward/reaching_object: 1.2496
    Episode_Reward/rotating_object: 117.8914
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0221
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.22s
                      Time elapsed: 00:18:48
                               ETA: 00:37:59

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 44384 steps/s (collection: 2.101s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 96.5021
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 52.7972
                       Mean reward: 653.56
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.2610
    Episode_Reward/rotating_object: 121.8527
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.21s
                      Time elapsed: 00:18:50
                               ETA: 00:37:56

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 43486 steps/s (collection: 2.147s, learning 0.114s)
             Mean action noise std: 1.88
          Mean value_function loss: 89.6669
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.8143
                       Mean reward: 614.16
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.2502
    Episode_Reward/rotating_object: 118.7395
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0223
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.26s
                      Time elapsed: 00:18:52
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 44176 steps/s (collection: 2.110s, learning 0.115s)
             Mean action noise std: 1.88
          Mean value_function loss: 95.6961
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 52.8368
                       Mean reward: 616.62
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 118.3869
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.23s
                      Time elapsed: 00:18:55
                               ETA: 00:37:52

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 44866 steps/s (collection: 2.080s, learning 0.111s)
             Mean action noise std: 1.88
          Mean value_function loss: 86.1922
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 52.8632
                       Mean reward: 586.99
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.2527
    Episode_Reward/rotating_object: 118.7171
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.19s
                      Time elapsed: 00:18:57
                               ETA: 00:37:49

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 44832 steps/s (collection: 2.082s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 95.7887
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.8927
                       Mean reward: 612.75
               Mean episode length: 234.60
    Episode_Reward/reaching_object: 1.2738
    Episode_Reward/rotating_object: 122.2627
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.19s
                      Time elapsed: 00:18:59
                               ETA: 00:37:47

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 44847 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 84.4006
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 52.9125
                       Mean reward: 621.41
               Mean episode length: 227.99
    Episode_Reward/reaching_object: 1.2835
    Episode_Reward/rotating_object: 121.8873
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.19s
                      Time elapsed: 00:19:01
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 45081 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 84.8452
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 52.9296
                       Mean reward: 598.38
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 1.2545
    Episode_Reward/rotating_object: 116.9559
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.18s
                      Time elapsed: 00:19:03
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 44809 steps/s (collection: 2.083s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 87.7120
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 52.9580
                       Mean reward: 630.32
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.2713
    Episode_Reward/rotating_object: 118.9381
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0231
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.19s
                      Time elapsed: 00:19:05
                               ETA: 00:37:40

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 45006 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 1.89
          Mean value_function loss: 89.3796
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.9835
                       Mean reward: 601.37
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 1.2605
    Episode_Reward/rotating_object: 119.5140
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.18s
                      Time elapsed: 00:19:08
                               ETA: 00:37:37

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 45184 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 80.5070
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 52.9964
                       Mean reward: 615.02
               Mean episode length: 229.04
    Episode_Reward/reaching_object: 1.2700
    Episode_Reward/rotating_object: 120.4611
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.18s
                      Time elapsed: 00:19:10
                               ETA: 00:37:35

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 43792 steps/s (collection: 2.131s, learning 0.113s)
             Mean action noise std: 1.89
          Mean value_function loss: 84.0643
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.0069
                       Mean reward: 626.62
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 1.2857
    Episode_Reward/rotating_object: 123.0878
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.24s
                      Time elapsed: 00:19:12
                               ETA: 00:37:33

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 44386 steps/s (collection: 2.101s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 94.4430
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 53.0232
                       Mean reward: 647.24
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 1.2634
    Episode_Reward/rotating_object: 122.5768
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.21s
                      Time elapsed: 00:19:14
                               ETA: 00:37:30

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 43861 steps/s (collection: 2.127s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 84.0568
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.0414
                       Mean reward: 554.33
               Mean episode length: 222.59
    Episode_Reward/reaching_object: 1.2450
    Episode_Reward/rotating_object: 116.8651
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0226
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.24s
                      Time elapsed: 00:19:17
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 44193 steps/s (collection: 2.111s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 91.8476
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 53.0659
                       Mean reward: 617.55
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 1.2544
    Episode_Reward/rotating_object: 121.6001
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0227
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.22s
                      Time elapsed: 00:19:19
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 44180 steps/s (collection: 2.112s, learning 0.113s)
             Mean action noise std: 1.90
          Mean value_function loss: 87.1481
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 53.0917
                       Mean reward: 596.38
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 1.2623
    Episode_Reward/rotating_object: 119.3833
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.23s
                      Time elapsed: 00:19:21
                               ETA: 00:37:23

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 44227 steps/s (collection: 2.108s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 89.1772
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.1137
                       Mean reward: 603.16
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.2428
    Episode_Reward/rotating_object: 119.2804
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.22s
                      Time elapsed: 00:19:23
                               ETA: 00:37:21

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 44456 steps/s (collection: 2.101s, learning 0.111s)
             Mean action noise std: 1.90
          Mean value_function loss: 71.9352
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.1341
                       Mean reward: 622.78
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.2747
    Episode_Reward/rotating_object: 122.4778
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.21s
                      Time elapsed: 00:19:25
                               ETA: 00:37:18

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 43494 steps/s (collection: 2.142s, learning 0.118s)
             Mean action noise std: 1.91
          Mean value_function loss: 76.8848
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.1659
                       Mean reward: 604.58
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.2839
    Episode_Reward/rotating_object: 122.3850
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.26s
                      Time elapsed: 00:19:28
                               ETA: 00:37:16

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 44748 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 70.7941
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.1934
                       Mean reward: 569.81
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 1.2835
    Episode_Reward/rotating_object: 125.4072
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.20s
                      Time elapsed: 00:19:30
                               ETA: 00:37:14

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 44530 steps/s (collection: 2.095s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 74.3089
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 53.2176
                       Mean reward: 670.65
               Mean episode length: 242.58
    Episode_Reward/reaching_object: 1.2767
    Episode_Reward/rotating_object: 125.7958
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.21s
                      Time elapsed: 00:19:32
                               ETA: 00:37:11

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 44672 steps/s (collection: 2.087s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 81.6082
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 53.2274
                       Mean reward: 600.80
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.2592
    Episode_Reward/rotating_object: 119.7670
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0233
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.20s
                      Time elapsed: 00:19:34
                               ETA: 00:37:09

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 44617 steps/s (collection: 2.089s, learning 0.114s)
             Mean action noise std: 1.91
          Mean value_function loss: 76.0790
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 53.2395
                       Mean reward: 624.90
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.2912
    Episode_Reward/rotating_object: 125.2468
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.20s
                      Time elapsed: 00:19:37
                               ETA: 00:37:07

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 41285 steps/s (collection: 2.266s, learning 0.115s)
             Mean action noise std: 1.91
          Mean value_function loss: 71.2704
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.2605
                       Mean reward: 622.36
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 1.2613
    Episode_Reward/rotating_object: 122.4299
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.38s
                      Time elapsed: 00:19:39
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 44768 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 77.9879
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.2945
                       Mean reward: 571.95
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.2741
    Episode_Reward/rotating_object: 122.4108
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.20s
                      Time elapsed: 00:19:41
                               ETA: 00:37:02

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 45017 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 76.5574
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.3291
                       Mean reward: 623.91
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.2708
    Episode_Reward/rotating_object: 126.2047
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.18s
                      Time elapsed: 00:19:43
                               ETA: 00:37:00

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 45537 steps/s (collection: 2.047s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 68.9386
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 53.3587
                       Mean reward: 645.28
               Mean episode length: 239.79
    Episode_Reward/reaching_object: 1.2839
    Episode_Reward/rotating_object: 126.8512
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0241
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.16s
                      Time elapsed: 00:19:45
                               ETA: 00:36:57

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 45240 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 1.92
          Mean value_function loss: 75.9919
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.3735
                       Mean reward: 676.88
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.2780
    Episode_Reward/rotating_object: 126.9455
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.17s
                      Time elapsed: 00:19:48
                               ETA: 00:36:55

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 43604 steps/s (collection: 2.144s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 66.9404
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.4020
                       Mean reward: 640.55
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.2761
    Episode_Reward/rotating_object: 125.8648
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.25s
                      Time elapsed: 00:19:50
                               ETA: 00:36:52

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 42888 steps/s (collection: 2.182s, learning 0.110s)
             Mean action noise std: 1.93
          Mean value_function loss: 77.0053
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.4378
                       Mean reward: 637.85
               Mean episode length: 230.24
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 124.7181
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.29s
                      Time elapsed: 00:19:52
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 44569 steps/s (collection: 2.094s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 69.5129
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.4683
                       Mean reward: 636.27
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.2724
    Episode_Reward/rotating_object: 125.2903
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.21s
                      Time elapsed: 00:19:54
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 45276 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 1.93
          Mean value_function loss: 70.5595
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.5041
                       Mean reward: 639.66
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 1.2754
    Episode_Reward/rotating_object: 123.9796
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.17s
                      Time elapsed: 00:19:57
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 44487 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 1.94
          Mean value_function loss: 85.2288
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 53.5315
                       Mean reward: 608.07
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 1.2507
    Episode_Reward/rotating_object: 122.6233
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0234
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.21s
                      Time elapsed: 00:19:59
                               ETA: 00:36:43

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 44651 steps/s (collection: 2.089s, learning 0.112s)
             Mean action noise std: 1.94
          Mean value_function loss: 70.7541
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 53.5554
                       Mean reward: 606.08
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.2465
    Episode_Reward/rotating_object: 122.5563
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.20s
                      Time elapsed: 00:20:01
                               ETA: 00:36:41

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 44058 steps/s (collection: 2.119s, learning 0.112s)
             Mean action noise std: 1.94
          Mean value_function loss: 73.8573
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.5782
                       Mean reward: 643.22
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.2684
    Episode_Reward/rotating_object: 125.2542
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.23s
                      Time elapsed: 00:20:03
                               ETA: 00:36:38

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 43895 steps/s (collection: 2.125s, learning 0.114s)
             Mean action noise std: 1.94
          Mean value_function loss: 85.1974
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 53.6056
                       Mean reward: 631.37
               Mean episode length: 231.36
    Episode_Reward/reaching_object: 1.2726
    Episode_Reward/rotating_object: 127.7917
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.24s
                      Time elapsed: 00:20:05
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 43884 steps/s (collection: 2.125s, learning 0.115s)
             Mean action noise std: 1.94
          Mean value_function loss: 80.4039
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.6348
                       Mean reward: 562.15
               Mean episode length: 219.79
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 122.3650
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0235
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.24s
                      Time elapsed: 00:20:08
                               ETA: 00:36:34

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 44578 steps/s (collection: 2.092s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 70.6012
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.6616
                       Mean reward: 624.02
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.2577
    Episode_Reward/rotating_object: 122.9373
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.21s
                      Time elapsed: 00:20:10
                               ETA: 00:36:31

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 43946 steps/s (collection: 2.124s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 72.6917
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 53.6846
                       Mean reward: 675.17
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.2714
    Episode_Reward/rotating_object: 126.2033
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.24s
                      Time elapsed: 00:20:12
                               ETA: 00:36:29

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 44421 steps/s (collection: 2.102s, learning 0.111s)
             Mean action noise std: 1.95
          Mean value_function loss: 86.0735
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.7105
                       Mean reward: 592.95
               Mean episode length: 229.48
    Episode_Reward/reaching_object: 1.2539
    Episode_Reward/rotating_object: 122.2704
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0230
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.21s
                      Time elapsed: 00:20:14
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 43733 steps/s (collection: 2.126s, learning 0.122s)
             Mean action noise std: 1.95
          Mean value_function loss: 80.9393
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.7354
                       Mean reward: 615.19
               Mean episode length: 229.25
    Episode_Reward/reaching_object: 1.2558
    Episode_Reward/rotating_object: 123.7869
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.25s
                      Time elapsed: 00:20:17
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 44178 steps/s (collection: 2.112s, learning 0.114s)
             Mean action noise std: 1.95
          Mean value_function loss: 81.1471
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 53.7584
                       Mean reward: 621.13
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.2668
    Episode_Reward/rotating_object: 125.5318
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0237
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.23s
                      Time elapsed: 00:20:19
                               ETA: 00:36:22

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 44060 steps/s (collection: 2.104s, learning 0.127s)
             Mean action noise std: 1.95
          Mean value_function loss: 68.7312
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.7692
                       Mean reward: 672.07
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.2865
    Episode_Reward/rotating_object: 129.2440
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.23s
                      Time elapsed: 00:20:21
                               ETA: 00:36:20

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 44223 steps/s (collection: 2.110s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 66.2220
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.7821
                       Mean reward: 637.15
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 1.2850
    Episode_Reward/rotating_object: 128.2328
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.22s
                      Time elapsed: 00:20:23
                               ETA: 00:36:17

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 44121 steps/s (collection: 2.114s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 76.6444
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 53.7962
                       Mean reward: 635.21
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.2792
    Episode_Reward/rotating_object: 126.6973
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.23s
                      Time elapsed: 00:20:25
                               ETA: 00:36:15

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 44124 steps/s (collection: 2.112s, learning 0.115s)
             Mean action noise std: 1.96
          Mean value_function loss: 70.7298
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.8273
                       Mean reward: 657.97
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 1.2863
    Episode_Reward/rotating_object: 128.3384
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.23s
                      Time elapsed: 00:20:28
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 44578 steps/s (collection: 2.091s, learning 0.114s)
             Mean action noise std: 1.96
          Mean value_function loss: 75.4004
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 53.8611
                       Mean reward: 670.00
               Mean episode length: 239.56
    Episode_Reward/reaching_object: 1.2671
    Episode_Reward/rotating_object: 126.0998
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.21s
                      Time elapsed: 00:20:30
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 44848 steps/s (collection: 2.081s, learning 0.111s)
             Mean action noise std: 1.96
          Mean value_function loss: 75.7601
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.8875
                       Mean reward: 630.20
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.2784
    Episode_Reward/rotating_object: 128.1248
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.19s
                      Time elapsed: 00:20:32
                               ETA: 00:36:08

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 45215 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 78.2123
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 53.9151
                       Mean reward: 670.81
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.2892
    Episode_Reward/rotating_object: 130.4606
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.17s
                      Time elapsed: 00:20:34
                               ETA: 00:36:05

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 45484 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 70.6360
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 53.9458
                       Mean reward: 655.97
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 1.2714
    Episode_Reward/rotating_object: 130.7099
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.16s
                      Time elapsed: 00:20:36
                               ETA: 00:36:03

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 45596 steps/s (collection: 2.045s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 73.4034
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 53.9798
                       Mean reward: 652.04
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.2978
    Episode_Reward/rotating_object: 129.8487
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.16s
                      Time elapsed: 00:20:39
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 45489 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 1.97
          Mean value_function loss: 77.5453
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 54.0098
                       Mean reward: 620.82
               Mean episode length: 228.59
    Episode_Reward/reaching_object: 1.2588
    Episode_Reward/rotating_object: 125.0133
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.16s
                      Time elapsed: 00:20:41
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 45725 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 78.4718
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.0365
                       Mean reward: 620.01
               Mean episode length: 226.64
    Episode_Reward/reaching_object: 1.2656
    Episode_Reward/rotating_object: 126.6266
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.15s
                      Time elapsed: 00:20:43
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 45308 steps/s (collection: 2.059s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 86.2855
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 54.0684
                       Mean reward: 632.70
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.2516
    Episode_Reward/rotating_object: 128.4123
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0243
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.17s
                      Time elapsed: 00:20:45
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 44701 steps/s (collection: 2.087s, learning 0.112s)
             Mean action noise std: 1.98
          Mean value_function loss: 71.8742
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.0944
                       Mean reward: 590.19
               Mean episode length: 219.15
    Episode_Reward/reaching_object: 1.2440
    Episode_Reward/rotating_object: 128.0894
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.20s
                      Time elapsed: 00:20:47
                               ETA: 00:35:51

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 43386 steps/s (collection: 2.154s, learning 0.111s)
             Mean action noise std: 1.98
          Mean value_function loss: 74.9052
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 54.1245
                       Mean reward: 680.33
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 1.2566
    Episode_Reward/rotating_object: 128.3907
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.27s
                      Time elapsed: 00:20:50
                               ETA: 00:35:49

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 44418 steps/s (collection: 2.099s, learning 0.114s)
             Mean action noise std: 1.99
          Mean value_function loss: 78.4672
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.1551
                       Mean reward: 596.07
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 1.2566
    Episode_Reward/rotating_object: 127.9093
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.21s
                      Time elapsed: 00:20:52
                               ETA: 00:35:46

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 42522 steps/s (collection: 2.201s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 75.7910
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.1854
                       Mean reward: 642.34
               Mean episode length: 238.84
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 124.2457
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.31s
                      Time elapsed: 00:20:54
                               ETA: 00:35:44

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 42585 steps/s (collection: 2.197s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 81.0330
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.2152
                       Mean reward: 618.25
               Mean episode length: 229.36
    Episode_Reward/reaching_object: 1.2124
    Episode_Reward/rotating_object: 122.1165
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.31s
                      Time elapsed: 00:20:56
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 44373 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 1.99
          Mean value_function loss: 68.4600
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.2470
                       Mean reward: 598.34
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.2484
    Episode_Reward/rotating_object: 126.4273
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.22s
                      Time elapsed: 00:20:59
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 43896 steps/s (collection: 2.123s, learning 0.117s)
             Mean action noise std: 2.00
          Mean value_function loss: 68.5362
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.2788
                       Mean reward: 691.73
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.2807
    Episode_Reward/rotating_object: 133.8822
        Episode_Reward/action_rate: -0.0248
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.24s
                      Time elapsed: 00:21:01
                               ETA: 00:35:37

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 42591 steps/s (collection: 2.194s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 71.3357
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.3170
                       Mean reward: 635.76
               Mean episode length: 236.63
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 124.7313
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.31s
                      Time elapsed: 00:21:03
                               ETA: 00:35:35

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 44038 steps/s (collection: 2.118s, learning 0.114s)
             Mean action noise std: 2.00
          Mean value_function loss: 76.8802
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.3487
                       Mean reward: 627.84
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.2579
    Episode_Reward/rotating_object: 127.9714
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.23s
                      Time elapsed: 00:21:05
                               ETA: 00:35:33

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 43741 steps/s (collection: 2.137s, learning 0.111s)
             Mean action noise std: 2.00
          Mean value_function loss: 81.7087
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.3903
                       Mean reward: 652.59
               Mean episode length: 234.35
    Episode_Reward/reaching_object: 1.2388
    Episode_Reward/rotating_object: 127.1157
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.25s
                      Time elapsed: 00:21:08
                               ETA: 00:35:30

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 44671 steps/s (collection: 2.089s, learning 0.111s)
             Mean action noise std: 2.01
          Mean value_function loss: 78.9026
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.4280
                       Mean reward: 596.65
               Mean episode length: 221.84
    Episode_Reward/reaching_object: 1.2078
    Episode_Reward/rotating_object: 123.9109
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0246
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.20s
                      Time elapsed: 00:21:10
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 44220 steps/s (collection: 2.099s, learning 0.124s)
             Mean action noise std: 2.01
          Mean value_function loss: 78.8760
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 54.4555
                       Mean reward: 608.68
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 1.2462
    Episode_Reward/rotating_object: 126.0196
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.22s
                      Time elapsed: 00:21:12
                               ETA: 00:35:26

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 44523 steps/s (collection: 2.095s, learning 0.113s)
             Mean action noise std: 2.01
          Mean value_function loss: 86.6527
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 54.4796
                       Mean reward: 678.11
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 1.2126
    Episode_Reward/rotating_object: 125.3971
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0244
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.21s
                      Time elapsed: 00:21:14
                               ETA: 00:35:23

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 43695 steps/s (collection: 2.134s, learning 0.116s)
             Mean action noise std: 2.01
          Mean value_function loss: 66.9299
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 54.5066
                       Mean reward: 654.29
               Mean episode length: 231.44
    Episode_Reward/reaching_object: 1.1858
    Episode_Reward/rotating_object: 118.8851
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.25s
                      Time elapsed: 00:21:16
                               ETA: 00:35:21

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 44255 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 87.5782
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 54.5333
                       Mean reward: 693.75
               Mean episode length: 243.43
    Episode_Reward/reaching_object: 1.2557
    Episode_Reward/rotating_object: 131.3643
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.22s
                      Time elapsed: 00:21:19
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 44746 steps/s (collection: 2.083s, learning 0.114s)
             Mean action noise std: 2.02
          Mean value_function loss: 83.4705
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.5574
                       Mean reward: 664.27
               Mean episode length: 242.04
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 127.0918
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.20s
                      Time elapsed: 00:21:21
                               ETA: 00:35:16

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 45067 steps/s (collection: 2.069s, learning 0.112s)
             Mean action noise std: 2.02
          Mean value_function loss: 67.6975
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 54.5909
                       Mean reward: 621.09
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 1.2444
    Episode_Reward/rotating_object: 127.9350
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.18s
                      Time elapsed: 00:21:23
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 44984 steps/s (collection: 2.072s, learning 0.113s)
             Mean action noise std: 2.02
          Mean value_function loss: 79.0506
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.6189
                       Mean reward: 614.82
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 1.2266
    Episode_Reward/rotating_object: 121.9768
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.19s
                      Time elapsed: 00:21:25
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 44711 steps/s (collection: 2.087s, learning 0.111s)
             Mean action noise std: 2.03
          Mean value_function loss: 78.0789
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.6451
                       Mean reward: 623.16
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 1.2372
    Episode_Reward/rotating_object: 127.4859
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.20s
                      Time elapsed: 00:21:27
                               ETA: 00:35:09

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 45204 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 2.03
          Mean value_function loss: 68.2223
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.6800
                       Mean reward: 674.81
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.2596
    Episode_Reward/rotating_object: 132.1544
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.17s
                      Time elapsed: 00:21:30
                               ETA: 00:35:07

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 45022 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 2.03
          Mean value_function loss: 68.1264
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.7069
                       Mean reward: 637.77
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.2518
    Episode_Reward/rotating_object: 128.4430
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.18s
                      Time elapsed: 00:21:32
                               ETA: 00:35:04

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 45523 steps/s (collection: 2.044s, learning 0.115s)
             Mean action noise std: 2.03
          Mean value_function loss: 70.1163
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 54.7412
                       Mean reward: 688.63
               Mean episode length: 238.49
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 132.8159
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.16s
                      Time elapsed: 00:21:34
                               ETA: 00:35:02

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 44486 steps/s (collection: 2.086s, learning 0.123s)
             Mean action noise std: 2.04
          Mean value_function loss: 66.7919
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 54.7792
                       Mean reward: 663.64
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 126.9706
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.21s
                      Time elapsed: 00:21:36
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 44406 steps/s (collection: 2.095s, learning 0.119s)
             Mean action noise std: 2.04
          Mean value_function loss: 62.6389
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 54.8099
                       Mean reward: 670.36
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 1.2483
    Episode_Reward/rotating_object: 130.2232
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.21s
                      Time elapsed: 00:21:38
                               ETA: 00:34:57

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 43057 steps/s (collection: 2.172s, learning 0.111s)
             Mean action noise std: 2.04
          Mean value_function loss: 70.1446
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 54.8453
                       Mean reward: 636.29
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 128.7124
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0252
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.28s
                      Time elapsed: 00:21:41
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 43833 steps/s (collection: 2.125s, learning 0.118s)
             Mean action noise std: 2.04
          Mean value_function loss: 81.2728
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 54.8774
                       Mean reward: 684.78
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 129.9723
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.24s
                      Time elapsed: 00:21:43
                               ETA: 00:34:53

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 44128 steps/s (collection: 2.114s, learning 0.114s)
             Mean action noise std: 2.05
          Mean value_function loss: 81.5456
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 54.9065
                       Mean reward: 648.13
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 129.1399
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.23s
                      Time elapsed: 00:21:45
                               ETA: 00:34:50

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 43754 steps/s (collection: 2.132s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 83.1144
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.9457
                       Mean reward: 650.83
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 1.2367
    Episode_Reward/rotating_object: 128.9419
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.25s
                      Time elapsed: 00:21:47
                               ETA: 00:34:48

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 44472 steps/s (collection: 2.097s, learning 0.113s)
             Mean action noise std: 2.05
          Mean value_function loss: 72.2963
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 54.9789
                       Mean reward: 626.87
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 1.2100
    Episode_Reward/rotating_object: 124.9441
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0249
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.21s
                      Time elapsed: 00:21:50
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 44443 steps/s (collection: 2.097s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 64.1753
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.9980
                       Mean reward: 646.33
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 128.1870
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.21s
                      Time elapsed: 00:21:52
                               ETA: 00:34:43

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 44490 steps/s (collection: 2.096s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 69.7877
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.0211
                       Mean reward: 675.64
               Mean episode length: 239.93
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 128.8002
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.21s
                      Time elapsed: 00:21:54
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 44494 steps/s (collection: 2.095s, learning 0.114s)
             Mean action noise std: 2.06
          Mean value_function loss: 72.1286
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.0482
                       Mean reward: 607.44
               Mean episode length: 223.92
    Episode_Reward/reaching_object: 1.2037
    Episode_Reward/rotating_object: 124.0060
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.21s
                      Time elapsed: 00:21:56
                               ETA: 00:34:39

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 44533 steps/s (collection: 2.096s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 74.5775
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.0725
                       Mean reward: 641.96
               Mean episode length: 228.71
    Episode_Reward/reaching_object: 1.2370
    Episode_Reward/rotating_object: 131.0326
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.21s
                      Time elapsed: 00:21:58
                               ETA: 00:34:36

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 44359 steps/s (collection: 2.105s, learning 0.111s)
             Mean action noise std: 2.06
          Mean value_function loss: 80.7678
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.1054
                       Mean reward: 649.39
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 130.5795
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.22s
                      Time elapsed: 00:22:01
                               ETA: 00:34:34

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 43793 steps/s (collection: 2.130s, learning 0.115s)
             Mean action noise std: 2.07
          Mean value_function loss: 70.4780
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 55.1488
                       Mean reward: 638.47
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 128.1335
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.24s
                      Time elapsed: 00:22:03
                               ETA: 00:34:32

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 42987 steps/s (collection: 2.171s, learning 0.116s)
             Mean action noise std: 2.07
          Mean value_function loss: 72.5113
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 55.1741
                       Mean reward: 661.91
               Mean episode length: 241.50
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 128.2580
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.29s
                      Time elapsed: 00:22:05
                               ETA: 00:34:29

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 43974 steps/s (collection: 2.117s, learning 0.118s)
             Mean action noise std: 2.07
          Mean value_function loss: 90.3567
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2043
                       Mean reward: 652.37
               Mean episode length: 231.15
    Episode_Reward/reaching_object: 1.2186
    Episode_Reward/rotating_object: 127.7063
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.24s
                      Time elapsed: 00:22:07
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 44318 steps/s (collection: 2.106s, learning 0.112s)
             Mean action noise std: 2.07
          Mean value_function loss: 77.1098
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 55.2247
                       Mean reward: 646.20
               Mean episode length: 236.78
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 131.3054
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.22s
                      Time elapsed: 00:22:10
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 45044 steps/s (collection: 2.071s, learning 0.112s)
             Mean action noise std: 2.07
          Mean value_function loss: 78.9269
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.2359
                       Mean reward: 686.52
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 1.2212
    Episode_Reward/rotating_object: 126.1295
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0251
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.18s
                      Time elapsed: 00:22:12
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 45119 steps/s (collection: 2.064s, learning 0.115s)
             Mean action noise std: 2.08
          Mean value_function loss: 84.2723
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.2622
                       Mean reward: 646.99
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 127.3133
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.18s
                      Time elapsed: 00:22:14
                               ETA: 00:34:20

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 44651 steps/s (collection: 2.075s, learning 0.127s)
             Mean action noise std: 2.08
          Mean value_function loss: 88.3247
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.2847
                       Mean reward: 647.27
               Mean episode length: 225.20
    Episode_Reward/reaching_object: 1.2227
    Episode_Reward/rotating_object: 127.5721
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.20s
                      Time elapsed: 00:22:16
                               ETA: 00:34:18

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 45015 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 70.7428
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.3136
                       Mean reward: 644.43
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 128.2720
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.18s
                      Time elapsed: 00:22:18
                               ETA: 00:34:15

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 45358 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 75.4375
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.3464
                       Mean reward: 638.89
               Mean episode length: 233.04
    Episode_Reward/reaching_object: 1.2286
    Episode_Reward/rotating_object: 126.0945
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.17s
                      Time elapsed: 00:22:21
                               ETA: 00:34:13

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 44930 steps/s (collection: 2.077s, learning 0.111s)
             Mean action noise std: 2.09
          Mean value_function loss: 75.8192
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.3817
                       Mean reward: 680.73
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 130.1957
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.19s
                      Time elapsed: 00:22:23
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 44475 steps/s (collection: 2.097s, learning 0.113s)
             Mean action noise std: 2.09
          Mean value_function loss: 77.9787
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 55.4062
                       Mean reward: 659.37
               Mean episode length: 231.65
    Episode_Reward/reaching_object: 1.2290
    Episode_Reward/rotating_object: 129.5493
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.21s
                      Time elapsed: 00:22:25
                               ETA: 00:34:08

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 43864 steps/s (collection: 2.119s, learning 0.122s)
             Mean action noise std: 2.09
          Mean value_function loss: 75.2709
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.4265
                       Mean reward: 648.86
               Mean episode length: 239.15
    Episode_Reward/reaching_object: 1.2607
    Episode_Reward/rotating_object: 134.4733
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.24s
                      Time elapsed: 00:22:27
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 44235 steps/s (collection: 2.107s, learning 0.116s)
             Mean action noise std: 2.09
          Mean value_function loss: 81.1093
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.4603
                       Mean reward: 640.05
               Mean episode length: 230.82
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 128.6758
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.22s
                      Time elapsed: 00:22:29
                               ETA: 00:34:04

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 43956 steps/s (collection: 2.123s, learning 0.114s)
             Mean action noise std: 2.10
          Mean value_function loss: 90.3151
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.4955
                       Mean reward: 600.80
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 125.1887
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.24s
                      Time elapsed: 00:22:32
                               ETA: 00:34:01

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 43024 steps/s (collection: 2.172s, learning 0.113s)
             Mean action noise std: 2.10
          Mean value_function loss: 81.3176
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 55.5307
                       Mean reward: 652.50
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 129.1548
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.28s
                      Time elapsed: 00:22:34
                               ETA: 00:33:59

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 43968 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 2.10
          Mean value_function loss: 86.9902
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.5637
                       Mean reward: 651.33
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 128.3785
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.24s
                      Time elapsed: 00:22:36
                               ETA: 00:33:57

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 43828 steps/s (collection: 2.129s, learning 0.114s)
             Mean action noise std: 2.11
          Mean value_function loss: 72.5012
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 55.5987
                       Mean reward: 653.42
               Mean episode length: 233.01
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 128.9268
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.24s
                      Time elapsed: 00:22:38
                               ETA: 00:33:54

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 43974 steps/s (collection: 2.124s, learning 0.111s)
             Mean action noise std: 2.11
          Mean value_function loss: 75.6441
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.6324
                       Mean reward: 683.58
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 1.2554
    Episode_Reward/rotating_object: 130.3820
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.24s
                      Time elapsed: 00:22:41
                               ETA: 00:33:52

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 44438 steps/s (collection: 2.099s, learning 0.113s)
             Mean action noise std: 2.11
          Mean value_function loss: 65.7077
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.6669
                       Mean reward: 650.27
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.2580
    Episode_Reward/rotating_object: 129.2164
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.21s
                      Time elapsed: 00:22:43
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 44238 steps/s (collection: 2.109s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 81.1879
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.6956
                       Mean reward: 681.15
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 1.2700
    Episode_Reward/rotating_object: 132.7368
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.22s
                      Time elapsed: 00:22:45
                               ETA: 00:33:48

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 44289 steps/s (collection: 2.104s, learning 0.116s)
             Mean action noise std: 2.12
          Mean value_function loss: 81.5245
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 55.7176
                       Mean reward: 630.65
               Mean episode length: 230.23
    Episode_Reward/reaching_object: 1.2519
    Episode_Reward/rotating_object: 130.6647
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.22s
                      Time elapsed: 00:22:47
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 43640 steps/s (collection: 2.139s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 64.0914
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 55.7412
                       Mean reward: 681.41
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.2599
    Episode_Reward/rotating_object: 132.0828
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.25s
                      Time elapsed: 00:22:50
                               ETA: 00:33:43

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 43780 steps/s (collection: 2.132s, learning 0.114s)
             Mean action noise std: 2.12
          Mean value_function loss: 85.7230
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.7612
                       Mean reward: 604.31
               Mean episode length: 224.89
    Episode_Reward/reaching_object: 1.2190
    Episode_Reward/rotating_object: 123.0991
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.25s
                      Time elapsed: 00:22:52
                               ETA: 00:33:41

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 43826 steps/s (collection: 2.132s, learning 0.111s)
             Mean action noise std: 2.12
          Mean value_function loss: 86.6074
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 55.7881
                       Mean reward: 657.20
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 130.5325
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.24s
                      Time elapsed: 00:22:54
                               ETA: 00:33:38

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 43585 steps/s (collection: 2.130s, learning 0.126s)
             Mean action noise std: 2.13
          Mean value_function loss: 76.7606
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.8216
                       Mean reward: 633.70
               Mean episode length: 229.65
    Episode_Reward/reaching_object: 1.2445
    Episode_Reward/rotating_object: 129.8739
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.26s
                      Time elapsed: 00:22:56
                               ETA: 00:33:36

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 45214 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 2.13
          Mean value_function loss: 80.9535
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 55.8449
                       Mean reward: 679.70
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 1.2765
    Episode_Reward/rotating_object: 136.5416
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.17s
                      Time elapsed: 00:22:58
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 45188 steps/s (collection: 2.065s, learning 0.111s)
             Mean action noise std: 2.13
          Mean value_function loss: 66.0311
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 55.8553
                       Mean reward: 673.30
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 1.2815
    Episode_Reward/rotating_object: 132.7698
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.18s
                      Time elapsed: 00:23:01
                               ETA: 00:33:31

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 45406 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 2.13
          Mean value_function loss: 62.5040
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.8821
                       Mean reward: 641.15
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.2761
    Episode_Reward/rotating_object: 132.8579
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.16s
                      Time elapsed: 00:23:03
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 45171 steps/s (collection: 2.065s, learning 0.111s)
             Mean action noise std: 2.13
          Mean value_function loss: 95.1878
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 55.9105
                       Mean reward: 632.76
               Mean episode length: 226.05
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 130.6585
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.18s
                      Time elapsed: 00:23:05
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 45581 steps/s (collection: 2.045s, learning 0.112s)
             Mean action noise std: 2.14
          Mean value_function loss: 70.2628
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 55.9407
                       Mean reward: 656.08
               Mean episode length: 238.26
    Episode_Reward/reaching_object: 1.2655
    Episode_Reward/rotating_object: 129.0319
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.16s
                      Time elapsed: 00:23:07
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 45094 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 80.1809
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 55.9704
                       Mean reward: 659.56
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.2786
    Episode_Reward/rotating_object: 134.0872
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.18s
                      Time elapsed: 00:23:09
                               ETA: 00:33:22

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 44352 steps/s (collection: 2.105s, learning 0.111s)
             Mean action noise std: 2.14
          Mean value_function loss: 71.7825
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 56.0089
                       Mean reward: 625.33
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.2436
    Episode_Reward/rotating_object: 127.9833
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.22s
                      Time elapsed: 00:23:12
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 44102 steps/s (collection: 2.114s, learning 0.115s)
             Mean action noise std: 2.15
          Mean value_function loss: 63.7362
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.0441
                       Mean reward: 627.62
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.2651
    Episode_Reward/rotating_object: 130.3758
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.23s
                      Time elapsed: 00:23:14
                               ETA: 00:33:17

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 44094 steps/s (collection: 2.115s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 78.5415
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 56.0720
                       Mean reward: 689.84
               Mean episode length: 235.21
    Episode_Reward/reaching_object: 1.2672
    Episode_Reward/rotating_object: 133.7724
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.23s
                      Time elapsed: 00:23:16
                               ETA: 00:33:15

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 44283 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 74.1612
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 56.1033
                       Mean reward: 686.88
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.2470
    Episode_Reward/rotating_object: 127.6649
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0250
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.22s
                      Time elapsed: 00:23:18
                               ETA: 00:33:13

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 43840 steps/s (collection: 2.116s, learning 0.127s)
             Mean action noise std: 2.15
          Mean value_function loss: 68.2891
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.1323
                       Mean reward: 635.42
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 1.2488
    Episode_Reward/rotating_object: 129.7066
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.24s
                      Time elapsed: 00:23:20
                               ETA: 00:33:10

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 43996 steps/s (collection: 2.108s, learning 0.126s)
             Mean action noise std: 2.16
          Mean value_function loss: 71.6284
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.1673
                       Mean reward: 675.53
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.2782
    Episode_Reward/rotating_object: 136.9633
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.23s
                      Time elapsed: 00:23:23
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 44006 steps/s (collection: 2.117s, learning 0.117s)
             Mean action noise std: 2.16
          Mean value_function loss: 77.1545
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.2142
                       Mean reward: 662.44
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.2412
    Episode_Reward/rotating_object: 127.2001
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.23s
                      Time elapsed: 00:23:25
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 44047 steps/s (collection: 2.120s, learning 0.111s)
             Mean action noise std: 2.16
          Mean value_function loss: 70.3586
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.2391
                       Mean reward: 649.11
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.2731
    Episode_Reward/rotating_object: 132.9921
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.23s
                      Time elapsed: 00:23:27
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 44523 steps/s (collection: 2.094s, learning 0.114s)
             Mean action noise std: 2.17
          Mean value_function loss: 74.3928
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.2643
                       Mean reward: 631.73
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 126.7527
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.21s
                      Time elapsed: 00:23:29
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 44117 steps/s (collection: 2.117s, learning 0.111s)
             Mean action noise std: 2.17
          Mean value_function loss: 71.4411
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 56.2908
                       Mean reward: 651.93
               Mean episode length: 233.37
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 131.7442
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.23s
                      Time elapsed: 00:23:32
                               ETA: 00:32:59

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 44446 steps/s (collection: 2.099s, learning 0.112s)
             Mean action noise std: 2.17
          Mean value_function loss: 74.6978
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.3191
                       Mean reward: 688.21
               Mean episode length: 239.57
    Episode_Reward/reaching_object: 1.2636
    Episode_Reward/rotating_object: 134.7953
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.21s
                      Time elapsed: 00:23:34
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 44200 steps/s (collection: 2.109s, learning 0.115s)
             Mean action noise std: 2.17
          Mean value_function loss: 81.1807
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 56.3385
                       Mean reward: 647.81
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 1.2214
    Episode_Reward/rotating_object: 129.7924
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.22s
                      Time elapsed: 00:23:36
                               ETA: 00:32:54

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 42713 steps/s (collection: 2.190s, learning 0.111s)
             Mean action noise std: 2.18
          Mean value_function loss: 75.3679
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 56.3741
                       Mean reward: 619.56
               Mean episode length: 233.27
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 130.9144
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.30s
                      Time elapsed: 00:23:38
                               ETA: 00:32:52

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 42466 steps/s (collection: 2.201s, learning 0.114s)
             Mean action noise std: 2.18
          Mean value_function loss: 75.8160
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.4207
                       Mean reward: 681.53
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.2439
    Episode_Reward/rotating_object: 131.2657
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.31s
                      Time elapsed: 00:23:41
                               ETA: 00:32:50

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 43919 steps/s (collection: 2.124s, learning 0.114s)
             Mean action noise std: 2.18
          Mean value_function loss: 89.8805
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.4664
                       Mean reward: 585.68
               Mean episode length: 224.90
    Episode_Reward/reaching_object: 1.2110
    Episode_Reward/rotating_object: 122.5498
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.24s
                      Time elapsed: 00:23:43
                               ETA: 00:32:47

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 44316 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 2.19
          Mean value_function loss: 80.2258
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 56.5053
                       Mean reward: 662.98
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.2348
    Episode_Reward/rotating_object: 131.4662
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.22s
                      Time elapsed: 00:23:45
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 44483 steps/s (collection: 2.099s, learning 0.111s)
             Mean action noise std: 2.19
          Mean value_function loss: 87.7987
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 56.5304
                       Mean reward: 653.27
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.2298
    Episode_Reward/rotating_object: 128.6630
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.21s
                      Time elapsed: 00:23:47
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 45701 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 2.19
          Mean value_function loss: 80.8400
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.5653
                       Mean reward: 653.44
               Mean episode length: 230.55
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 126.6943
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0255
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.15s
                      Time elapsed: 00:23:49
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 45719 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 76.6595
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.5991
                       Mean reward: 679.69
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 1.2158
    Episode_Reward/rotating_object: 129.1389
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.15s
                      Time elapsed: 00:23:52
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 43046 steps/s (collection: 2.173s, learning 0.110s)
             Mean action noise std: 2.20
          Mean value_function loss: 64.8036
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 56.6306
                       Mean reward: 650.96
               Mean episode length: 232.63
    Episode_Reward/reaching_object: 1.2502
    Episode_Reward/rotating_object: 131.9565
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.28s
                      Time elapsed: 00:23:54
                               ETA: 00:32:36

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 42266 steps/s (collection: 2.215s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 79.8220
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 56.6543
                       Mean reward: 677.59
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 130.7236
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.33s
                      Time elapsed: 00:23:56
                               ETA: 00:32:34

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 42381 steps/s (collection: 2.208s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 79.0132
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 56.6828
                       Mean reward: 693.83
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 132.3336
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.32s
                      Time elapsed: 00:23:59
                               ETA: 00:32:31

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 43399 steps/s (collection: 2.153s, learning 0.112s)
             Mean action noise std: 2.21
          Mean value_function loss: 85.8257
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 56.7247
                       Mean reward: 674.18
               Mean episode length: 233.97
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 132.5116
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.27s
                      Time elapsed: 00:24:01
                               ETA: 00:32:29

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 44795 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 2.21
          Mean value_function loss: 69.3413
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.7714
                       Mean reward: 649.46
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 129.1867
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.19s
                      Time elapsed: 00:24:03
                               ETA: 00:32:27

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 43510 steps/s (collection: 2.146s, learning 0.113s)
             Mean action noise std: 2.21
          Mean value_function loss: 72.2350
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 56.8039
                       Mean reward: 649.77
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 134.6660
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.26s
                      Time elapsed: 00:24:05
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 41399 steps/s (collection: 2.239s, learning 0.135s)
             Mean action noise std: 2.22
          Mean value_function loss: 81.2584
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 56.8295
                       Mean reward: 693.77
               Mean episode length: 237.30
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 130.0574
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.37s
                      Time elapsed: 00:24:08
                               ETA: 00:32:22

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 43776 steps/s (collection: 2.132s, learning 0.113s)
             Mean action noise std: 2.22
          Mean value_function loss: 77.1253
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 56.8645
                       Mean reward: 646.53
               Mean episode length: 237.71
    Episode_Reward/reaching_object: 1.2360
    Episode_Reward/rotating_object: 130.3822
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.25s
                      Time elapsed: 00:24:10
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 44271 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 2.22
          Mean value_function loss: 73.2385
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 56.9146
                       Mean reward: 656.37
               Mean episode length: 230.73
    Episode_Reward/reaching_object: 1.2516
    Episode_Reward/rotating_object: 135.4597
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.22s
                      Time elapsed: 00:24:12
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 43826 steps/s (collection: 2.132s, learning 0.111s)
             Mean action noise std: 2.23
          Mean value_function loss: 85.7648
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.9509
                       Mean reward: 656.19
               Mean episode length: 227.64
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 132.6825
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.24s
                      Time elapsed: 00:24:14
                               ETA: 00:32:16

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 44360 steps/s (collection: 2.103s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 75.8396
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 56.9767
                       Mean reward: 625.94
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 128.4521
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.22s
                      Time elapsed: 00:24:17
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 44293 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 2.23
          Mean value_function loss: 77.6023
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.0022
                       Mean reward: 638.86
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 129.6728
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.22s
                      Time elapsed: 00:24:19
                               ETA: 00:32:11

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 42198 steps/s (collection: 2.201s, learning 0.128s)
             Mean action noise std: 2.24
          Mean value_function loss: 78.1085
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.0349
                       Mean reward: 616.45
               Mean episode length: 236.43
    Episode_Reward/reaching_object: 1.2284
    Episode_Reward/rotating_object: 126.7284
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0257
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.33s
                      Time elapsed: 00:24:21
                               ETA: 00:32:09

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 44881 steps/s (collection: 2.079s, learning 0.111s)
             Mean action noise std: 2.24
          Mean value_function loss: 77.3256
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 57.0722
                       Mean reward: 690.90
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 1.2535
    Episode_Reward/rotating_object: 132.8375
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.19s
                      Time elapsed: 00:24:23
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 44285 steps/s (collection: 2.107s, learning 0.113s)
             Mean action noise std: 2.24
          Mean value_function loss: 76.8344
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.1005
                       Mean reward: 677.08
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 1.2446
    Episode_Reward/rotating_object: 133.2185
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.22s
                      Time elapsed: 00:24:26
                               ETA: 00:32:04

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 44328 steps/s (collection: 2.104s, learning 0.114s)
             Mean action noise std: 2.25
          Mean value_function loss: 69.2639
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 57.1423
                       Mean reward: 683.37
               Mean episode length: 238.64
    Episode_Reward/reaching_object: 1.2671
    Episode_Reward/rotating_object: 133.5604
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.22s
                      Time elapsed: 00:24:28
                               ETA: 00:32:02

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 43449 steps/s (collection: 2.151s, learning 0.112s)
             Mean action noise std: 2.25
          Mean value_function loss: 89.9569
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 57.1929
                       Mean reward: 651.50
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 1.2474
    Episode_Reward/rotating_object: 129.2837
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.26s
                      Time elapsed: 00:24:30
                               ETA: 00:32:00

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 43937 steps/s (collection: 2.124s, learning 0.113s)
             Mean action noise std: 2.25
          Mean value_function loss: 81.9775
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 57.2458
                       Mean reward: 675.43
               Mean episode length: 234.23
    Episode_Reward/reaching_object: 1.2306
    Episode_Reward/rotating_object: 130.4706
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.24s
                      Time elapsed: 00:24:32
                               ETA: 00:31:57

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 42951 steps/s (collection: 2.176s, learning 0.112s)
             Mean action noise std: 2.26
          Mean value_function loss: 88.4672
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 57.2768
                       Mean reward: 657.37
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 132.0595
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.29s
                      Time elapsed: 00:24:35
                               ETA: 00:31:55

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 45343 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 2.26
          Mean value_function loss: 80.0066
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.3042
                       Mean reward: 646.58
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.2148
    Episode_Reward/rotating_object: 126.7918
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.17s
                      Time elapsed: 00:24:37
                               ETA: 00:31:53

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 45408 steps/s (collection: 2.051s, learning 0.114s)
             Mean action noise std: 2.26
          Mean value_function loss: 93.8459
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 57.3450
                       Mean reward: 628.21
               Mean episode length: 221.26
    Episode_Reward/reaching_object: 1.2085
    Episode_Reward/rotating_object: 128.9203
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.16s
                      Time elapsed: 00:24:39
                               ETA: 00:31:50

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 45334 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 2.27
          Mean value_function loss: 90.2997
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 57.3804
                       Mean reward: 674.96
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.2398
    Episode_Reward/rotating_object: 128.9449
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.17s
                      Time elapsed: 00:24:41
                               ETA: 00:31:48

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 45323 steps/s (collection: 2.047s, learning 0.122s)
             Mean action noise std: 2.27
          Mean value_function loss: 86.3694
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.4296
                       Mean reward: 655.87
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.2244
    Episode_Reward/rotating_object: 128.1179
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0262
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.17s
                      Time elapsed: 00:24:43
                               ETA: 00:31:46

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 45347 steps/s (collection: 2.056s, learning 0.112s)
             Mean action noise std: 2.28
          Mean value_function loss: 71.9712
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.4812
                       Mean reward: 690.85
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.2430
    Episode_Reward/rotating_object: 132.9498
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.17s
                      Time elapsed: 00:24:45
                               ETA: 00:31:43

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 45687 steps/s (collection: 2.041s, learning 0.111s)
             Mean action noise std: 2.28
          Mean value_function loss: 83.0183
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.5237
                       Mean reward: 677.12
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 1.2502
    Episode_Reward/rotating_object: 132.9763
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.15s
                      Time elapsed: 00:24:48
                               ETA: 00:31:41

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 44066 steps/s (collection: 2.118s, learning 0.113s)
             Mean action noise std: 2.28
          Mean value_function loss: 72.5180
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 57.5651
                       Mean reward: 678.53
               Mean episode length: 237.24
    Episode_Reward/reaching_object: 1.2456
    Episode_Reward/rotating_object: 129.3972
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.23s
                      Time elapsed: 00:24:50
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 44453 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 2.29
          Mean value_function loss: 91.5653
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.6036
                       Mean reward: 684.36
               Mean episode length: 237.67
    Episode_Reward/reaching_object: 1.2546
    Episode_Reward/rotating_object: 131.7919
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.21s
                      Time elapsed: 00:24:52
                               ETA: 00:31:36

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 44775 steps/s (collection: 2.085s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 85.7062
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.6425
                       Mean reward: 644.21
               Mean episode length: 227.14
    Episode_Reward/reaching_object: 1.2063
    Episode_Reward/rotating_object: 126.1877
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.20s
                      Time elapsed: 00:24:54
                               ETA: 00:31:34

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 44531 steps/s (collection: 2.097s, learning 0.111s)
             Mean action noise std: 2.29
          Mean value_function loss: 89.5939
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.6662
                       Mean reward: 606.85
               Mean episode length: 223.43
    Episode_Reward/reaching_object: 1.2140
    Episode_Reward/rotating_object: 128.0486
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.21s
                      Time elapsed: 00:24:56
                               ETA: 00:31:31

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 44401 steps/s (collection: 2.100s, learning 0.114s)
             Mean action noise std: 2.29
          Mean value_function loss: 80.6583
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 57.6872
                       Mean reward: 665.55
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 133.9633
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.21s
                      Time elapsed: 00:24:59
                               ETA: 00:31:29

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 41644 steps/s (collection: 2.247s, learning 0.114s)
             Mean action noise std: 2.30
          Mean value_function loss: 86.0719
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.7113
                       Mean reward: 647.85
               Mean episode length: 224.59
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 127.7627
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.36s
                      Time elapsed: 00:25:01
                               ETA: 00:31:27

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 44386 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 2.30
          Mean value_function loss: 81.3574
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 57.7422
                       Mean reward: 632.92
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 1.2644
    Episode_Reward/rotating_object: 134.3003
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.21s
                      Time elapsed: 00:25:03
                               ETA: 00:31:25

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 43965 steps/s (collection: 2.123s, learning 0.113s)
             Mean action noise std: 2.30
          Mean value_function loss: 76.0373
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 57.7722
                       Mean reward: 693.49
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 125.2595
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0268
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 2.24s
                      Time elapsed: 00:25:05
                               ETA: 00:31:22

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 43188 steps/s (collection: 2.162s, learning 0.114s)
             Mean action noise std: 2.31
          Mean value_function loss: 75.6692
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 57.8030
                       Mean reward: 657.99
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.2502
    Episode_Reward/rotating_object: 132.3931
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 2.28s
                      Time elapsed: 00:25:08
                               ETA: 00:31:20

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 43927 steps/s (collection: 2.124s, learning 0.114s)
             Mean action noise std: 2.31
          Mean value_function loss: 89.2574
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 57.8411
                       Mean reward: 690.92
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.2591
    Episode_Reward/rotating_object: 133.1544
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 2.24s
                      Time elapsed: 00:25:10
                               ETA: 00:31:18

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 43349 steps/s (collection: 2.155s, learning 0.113s)
             Mean action noise std: 2.31
          Mean value_function loss: 90.0722
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 57.8756
                       Mean reward: 689.77
               Mean episode length: 237.42
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 130.7884
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 2.27s
                      Time elapsed: 00:25:12
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 43306 steps/s (collection: 2.157s, learning 0.113s)
             Mean action noise std: 2.32
          Mean value_function loss: 79.9764
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 57.9131
                       Mean reward: 682.10
               Mean episode length: 237.72
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 129.9946
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 2.27s
                      Time elapsed: 00:25:14
                               ETA: 00:31:13

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 44088 steps/s (collection: 2.119s, learning 0.111s)
             Mean action noise std: 2.32
          Mean value_function loss: 85.3889
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 57.9579
                       Mean reward: 673.04
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 132.1404
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 2.23s
                      Time elapsed: 00:25:17
                               ETA: 00:31:11

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 43978 steps/s (collection: 2.124s, learning 0.111s)
             Mean action noise std: 2.32
          Mean value_function loss: 81.4258
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 57.9867
                       Mean reward: 669.55
               Mean episode length: 232.25
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 137.1405
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 2.24s
                      Time elapsed: 00:25:19
                               ETA: 00:31:09

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 43983 steps/s (collection: 2.114s, learning 0.121s)
             Mean action noise std: 2.33
          Mean value_function loss: 100.8074
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.0185
                       Mean reward: 649.15
               Mean episode length: 227.01
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 124.7441
        Episode_Reward/action_rate: -0.0314
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 2.24s
                      Time elapsed: 00:25:21
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 44789 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 2.33
          Mean value_function loss: 82.1684
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.0527
                       Mean reward: 671.32
               Mean episode length: 232.04
    Episode_Reward/reaching_object: 1.2360
    Episode_Reward/rotating_object: 129.8504
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 2.19s
                      Time elapsed: 00:25:23
                               ETA: 00:31:04

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 45271 steps/s (collection: 2.061s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 78.1917
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.0893
                       Mean reward: 666.63
               Mean episode length: 231.09
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 127.8496
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 2.17s
                      Time elapsed: 00:25:26
                               ETA: 00:31:02

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 44446 steps/s (collection: 2.101s, learning 0.110s)
             Mean action noise std: 2.33
          Mean value_function loss: 78.4259
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.1148
                       Mean reward: 648.27
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.2268
    Episode_Reward/rotating_object: 127.8356
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.21s
                      Time elapsed: 00:25:28
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 45176 steps/s (collection: 2.066s, learning 0.110s)
             Mean action noise std: 2.34
          Mean value_function loss: 71.7351
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.1406
                       Mean reward: 702.62
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.2662
    Episode_Reward/rotating_object: 135.9422
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.18s
                      Time elapsed: 00:25:30
                               ETA: 00:30:57

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 45361 steps/s (collection: 2.057s, learning 0.110s)
             Mean action noise std: 2.34
          Mean value_function loss: 80.3771
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 58.1719
                       Mean reward: 629.39
               Mean episode length: 228.73
    Episode_Reward/reaching_object: 1.2423
    Episode_Reward/rotating_object: 128.1269
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0272
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.17s
                      Time elapsed: 00:25:32
                               ETA: 00:30:55

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 45272 steps/s (collection: 2.059s, learning 0.112s)
             Mean action noise std: 2.34
          Mean value_function loss: 80.2168
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.2091
                       Mean reward: 684.19
               Mean episode length: 238.27
    Episode_Reward/reaching_object: 1.2550
    Episode_Reward/rotating_object: 131.3071
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.17s
                      Time elapsed: 00:25:34
                               ETA: 00:30:52

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 45089 steps/s (collection: 2.067s, learning 0.113s)
             Mean action noise std: 2.35
          Mean value_function loss: 97.9266
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.2480
                       Mean reward: 634.39
               Mean episode length: 221.61
    Episode_Reward/reaching_object: 1.2156
    Episode_Reward/rotating_object: 127.0423
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0261
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.18s
                      Time elapsed: 00:25:36
                               ETA: 00:30:50

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 44015 steps/s (collection: 2.119s, learning 0.114s)
             Mean action noise std: 2.35
          Mean value_function loss: 93.8117
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 58.2829
                       Mean reward: 674.37
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.2338
    Episode_Reward/rotating_object: 129.7729
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.23s
                      Time elapsed: 00:25:39
                               ETA: 00:30:48

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 44507 steps/s (collection: 2.098s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 80.4450
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.3178
                       Mean reward: 655.19
               Mean episode length: 241.06
    Episode_Reward/reaching_object: 1.2612
    Episode_Reward/rotating_object: 130.3874
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.21s
                      Time elapsed: 00:25:41
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 43638 steps/s (collection: 2.127s, learning 0.126s)
             Mean action noise std: 2.36
          Mean value_function loss: 83.7341
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.3460
                       Mean reward: 636.30
               Mean episode length: 224.37
    Episode_Reward/reaching_object: 1.2046
    Episode_Reward/rotating_object: 126.1593
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.25s
                      Time elapsed: 00:25:43
                               ETA: 00:30:43

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 44666 steps/s (collection: 2.085s, learning 0.116s)
             Mean action noise std: 2.36
          Mean value_function loss: 90.9858
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.3741
                       Mean reward: 675.46
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 1.1980
    Episode_Reward/rotating_object: 125.3399
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.20s
                      Time elapsed: 00:25:45
                               ETA: 00:30:41

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 43812 steps/s (collection: 2.133s, learning 0.111s)
             Mean action noise std: 2.36
          Mean value_function loss: 82.8609
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 58.4041
                       Mean reward: 674.07
               Mean episode length: 231.12
    Episode_Reward/reaching_object: 1.2577
    Episode_Reward/rotating_object: 134.2091
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.24s
                      Time elapsed: 00:25:48
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 44107 steps/s (collection: 2.116s, learning 0.113s)
             Mean action noise std: 2.37
          Mean value_function loss: 75.9152
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.4393
                       Mean reward: 661.96
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.2397
    Episode_Reward/rotating_object: 129.9951
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0266
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.23s
                      Time elapsed: 00:25:50
                               ETA: 00:30:36

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 44322 steps/s (collection: 2.107s, learning 0.111s)
             Mean action noise std: 2.37
          Mean value_function loss: 74.6838
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 58.4749
                       Mean reward: 685.07
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.2636
    Episode_Reward/rotating_object: 132.3095
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.22s
                      Time elapsed: 00:25:52
                               ETA: 00:30:34

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 43752 steps/s (collection: 2.134s, learning 0.113s)
             Mean action noise std: 2.37
          Mean value_function loss: 77.8270
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 58.5090
                       Mean reward: 666.69
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 1.2476
    Episode_Reward/rotating_object: 131.9038
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.25s
                      Time elapsed: 00:25:54
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 44515 steps/s (collection: 2.098s, learning 0.111s)
             Mean action noise std: 2.38
          Mean value_function loss: 77.0722
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 58.5487
                       Mean reward: 685.29
               Mean episode length: 240.29
    Episode_Reward/reaching_object: 1.2822
    Episode_Reward/rotating_object: 134.3893
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.21s
                      Time elapsed: 00:25:56
                               ETA: 00:30:29

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 44404 steps/s (collection: 2.100s, learning 0.114s)
             Mean action noise std: 2.38
          Mean value_function loss: 81.2280
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 58.5877
                       Mean reward: 683.08
               Mean episode length: 234.95
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 128.7435
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.21s
                      Time elapsed: 00:25:59
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 43992 steps/s (collection: 2.121s, learning 0.113s)
             Mean action noise std: 2.38
          Mean value_function loss: 87.8617
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 58.6067
                       Mean reward: 616.61
               Mean episode length: 216.67
    Episode_Reward/reaching_object: 1.2237
    Episode_Reward/rotating_object: 127.0064
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.23s
                      Time elapsed: 00:26:01
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 44624 steps/s (collection: 2.089s, learning 0.114s)
             Mean action noise std: 2.38
          Mean value_function loss: 79.7482
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 58.6271
                       Mean reward: 690.72
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.2594
    Episode_Reward/rotating_object: 131.4920
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.20s
                      Time elapsed: 00:26:03
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 44014 steps/s (collection: 2.120s, learning 0.114s)
             Mean action noise std: 2.39
          Mean value_function loss: 84.2388
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.6632
                       Mean reward: 689.44
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.2694
    Episode_Reward/rotating_object: 135.9250
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0271
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.23s
                      Time elapsed: 00:26:05
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 44716 steps/s (collection: 2.087s, learning 0.112s)
             Mean action noise std: 2.39
          Mean value_function loss: 91.1036
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.7007
                       Mean reward: 643.23
               Mean episode length: 232.27
    Episode_Reward/reaching_object: 1.2608
    Episode_Reward/rotating_object: 131.5302
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.20s
                      Time elapsed: 00:26:08
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 44159 steps/s (collection: 2.115s, learning 0.111s)
             Mean action noise std: 2.39
          Mean value_function loss: 72.0468
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 58.7295
                       Mean reward: 674.44
               Mean episode length: 235.69
    Episode_Reward/reaching_object: 1.2788
    Episode_Reward/rotating_object: 135.9017
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.23s
                      Time elapsed: 00:26:10
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 45067 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 2.40
          Mean value_function loss: 84.6243
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.7528
                       Mean reward: 658.99
               Mean episode length: 230.27
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 130.2620
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.18s
                      Time elapsed: 00:26:12
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 44807 steps/s (collection: 2.082s, learning 0.112s)
             Mean action noise std: 2.40
          Mean value_function loss: 77.6900
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 58.7889
                       Mean reward: 629.30
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 131.3307
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.19s
                      Time elapsed: 00:26:14
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 44793 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 2.40
          Mean value_function loss: 83.6804
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 58.8248
                       Mean reward: 639.11
               Mean episode length: 227.41
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 129.3257
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.19s
                      Time elapsed: 00:26:16
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 45393 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 2.41
          Mean value_function loss: 87.6131
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.8645
                       Mean reward: 673.53
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 1.2666
    Episode_Reward/rotating_object: 130.2372
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.17s
                      Time elapsed: 00:26:19
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 45623 steps/s (collection: 2.044s, learning 0.110s)
             Mean action noise std: 2.41
          Mean value_function loss: 85.9402
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 58.9022
                       Mean reward: 677.11
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.2471
    Episode_Reward/rotating_object: 128.9880
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.15s
                      Time elapsed: 00:26:21
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 45497 steps/s (collection: 2.050s, learning 0.111s)
             Mean action noise std: 2.42
          Mean value_function loss: 83.0010
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 58.9456
                       Mean reward: 655.64
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.2522
    Episode_Reward/rotating_object: 132.1057
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.16s
                      Time elapsed: 00:26:23
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 45222 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 2.42
          Mean value_function loss: 74.0959
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 58.9814
                       Mean reward: 651.48
               Mean episode length: 234.83
    Episode_Reward/reaching_object: 1.2676
    Episode_Reward/rotating_object: 135.0813
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.17s
                      Time elapsed: 00:26:25
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 44806 steps/s (collection: 2.081s, learning 0.113s)
             Mean action noise std: 2.42
          Mean value_function loss: 83.1308
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.0096
                       Mean reward: 624.68
               Mean episode length: 232.40
    Episode_Reward/reaching_object: 1.2609
    Episode_Reward/rotating_object: 132.2081
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.19s
                      Time elapsed: 00:26:27
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 42387 steps/s (collection: 2.206s, learning 0.113s)
             Mean action noise std: 2.42
          Mean value_function loss: 75.9768
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 59.0377
                       Mean reward: 670.87
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.2664
    Episode_Reward/rotating_object: 133.4807
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.32s
                      Time elapsed: 00:26:30
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 43983 steps/s (collection: 2.119s, learning 0.116s)
             Mean action noise std: 2.43
          Mean value_function loss: 78.3773
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 59.0665
                       Mean reward: 648.24
               Mean episode length: 224.42
    Episode_Reward/reaching_object: 1.2406
    Episode_Reward/rotating_object: 132.8278
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.24s
                      Time elapsed: 00:26:32
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 44080 steps/s (collection: 2.115s, learning 0.115s)
             Mean action noise std: 2.43
          Mean value_function loss: 72.2099
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 59.0881
                       Mean reward: 664.57
               Mean episode length: 230.07
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 134.6083
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.23s
                      Time elapsed: 00:26:34
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 44271 steps/s (collection: 2.108s, learning 0.113s)
             Mean action noise std: 2.43
          Mean value_function loss: 59.3020
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 59.1182
                       Mean reward: 653.19
               Mean episode length: 229.11
    Episode_Reward/reaching_object: 1.2666
    Episode_Reward/rotating_object: 133.1842
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.22s
                      Time elapsed: 00:26:36
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 44529 steps/s (collection: 2.096s, learning 0.112s)
             Mean action noise std: 2.43
          Mean value_function loss: 72.9126
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.1454
                       Mean reward: 700.70
               Mean episode length: 235.19
    Episode_Reward/reaching_object: 1.2920
    Episode_Reward/rotating_object: 136.5158
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.21s
                      Time elapsed: 00:26:38
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 44271 steps/s (collection: 2.106s, learning 0.114s)
             Mean action noise std: 2.44
          Mean value_function loss: 83.2509
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 59.1775
                       Mean reward: 654.43
               Mean episode length: 228.28
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 128.1328
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.22s
                      Time elapsed: 00:26:41
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 44280 steps/s (collection: 2.092s, learning 0.128s)
             Mean action noise std: 2.44
          Mean value_function loss: 69.6859
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.2247
                       Mean reward: 691.34
               Mean episode length: 235.50
    Episode_Reward/reaching_object: 1.2615
    Episode_Reward/rotating_object: 134.0672
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.22s
                      Time elapsed: 00:26:43
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 44241 steps/s (collection: 2.108s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 76.0094
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.2743
                       Mean reward: 673.65
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.2658
    Episode_Reward/rotating_object: 135.9815
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.22s
                      Time elapsed: 00:26:45
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 43708 steps/s (collection: 2.135s, learning 0.114s)
             Mean action noise std: 2.45
          Mean value_function loss: 92.7807
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 59.3189
                       Mean reward: 668.45
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 129.3831
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.25s
                      Time elapsed: 00:26:47
                               ETA: 00:29:36

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 44492 steps/s (collection: 2.099s, learning 0.111s)
             Mean action noise std: 2.45
          Mean value_function loss: 85.3370
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.3499
                       Mean reward: 691.81
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.2425
    Episode_Reward/rotating_object: 131.8477
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.21s
                      Time elapsed: 00:26:50
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 43623 steps/s (collection: 2.137s, learning 0.116s)
             Mean action noise std: 2.46
          Mean value_function loss: 85.3783
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 59.3736
                       Mean reward: 642.76
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.2580
    Episode_Reward/rotating_object: 134.3519
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.25s
                      Time elapsed: 00:26:52
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 44418 steps/s (collection: 2.088s, learning 0.125s)
             Mean action noise std: 2.46
          Mean value_function loss: 87.0574
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 59.4081
                       Mean reward: 630.38
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.2416
    Episode_Reward/rotating_object: 132.7684
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0270
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.21s
                      Time elapsed: 00:26:54
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 44616 steps/s (collection: 2.088s, learning 0.116s)
             Mean action noise std: 2.46
          Mean value_function loss: 75.9115
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 59.4428
                       Mean reward: 651.39
               Mean episode length: 233.00
    Episode_Reward/reaching_object: 1.2673
    Episode_Reward/rotating_object: 132.7978
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.20s
                      Time elapsed: 00:26:56
                               ETA: 00:29:27

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 45099 steps/s (collection: 2.066s, learning 0.113s)
             Mean action noise std: 2.47
          Mean value_function loss: 77.4454
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.4747
                       Mean reward: 671.10
               Mean episode length: 237.83
    Episode_Reward/reaching_object: 1.2442
    Episode_Reward/rotating_object: 132.0516
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.18s
                      Time elapsed: 00:26:58
                               ETA: 00:29:25

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 45086 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 2.47
          Mean value_function loss: 70.3623
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 59.4943
                       Mean reward: 653.24
               Mean episode length: 231.34
    Episode_Reward/reaching_object: 1.2305
    Episode_Reward/rotating_object: 131.0677
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.18s
                      Time elapsed: 00:27:01
                               ETA: 00:29:23

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 45499 steps/s (collection: 2.049s, learning 0.112s)
             Mean action noise std: 2.47
          Mean value_function loss: 81.9230
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 59.5161
                       Mean reward: 649.69
               Mean episode length: 227.94
    Episode_Reward/reaching_object: 1.2506
    Episode_Reward/rotating_object: 133.7829
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.16s
                      Time elapsed: 00:27:03
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 45740 steps/s (collection: 2.039s, learning 0.110s)
             Mean action noise std: 2.48
          Mean value_function loss: 76.3232
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 59.5520
                       Mean reward: 701.11
               Mean episode length: 240.08
    Episode_Reward/reaching_object: 1.2616
    Episode_Reward/rotating_object: 132.9277
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.15s
                      Time elapsed: 00:27:05
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 45396 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 2.48
          Mean value_function loss: 80.1447
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.5881
                       Mean reward: 700.40
               Mean episode length: 239.55
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 131.5291
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.17s
                      Time elapsed: 00:27:07
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 45548 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 2.48
          Mean value_function loss: 69.2325
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 59.6206
                       Mean reward: 667.60
               Mean episode length: 238.72
    Episode_Reward/reaching_object: 1.2597
    Episode_Reward/rotating_object: 133.8997
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.16s
                      Time elapsed: 00:27:09
                               ETA: 00:29:13

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 45511 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 2.48
          Mean value_function loss: 92.4359
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 59.6436
                       Mean reward: 657.08
               Mean episode length: 228.53
    Episode_Reward/reaching_object: 1.2610
    Episode_Reward/rotating_object: 135.8511
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.16s
                      Time elapsed: 00:27:11
                               ETA: 00:29:11

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 45504 steps/s (collection: 2.045s, learning 0.115s)
             Mean action noise std: 2.49
          Mean value_function loss: 78.6071
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.6715
                       Mean reward: 690.39
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.2653
    Episode_Reward/rotating_object: 134.6860
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.16s
                      Time elapsed: 00:27:14
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 44829 steps/s (collection: 2.080s, learning 0.113s)
             Mean action noise std: 2.49
          Mean value_function loss: 76.0822
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.7001
                       Mean reward: 720.97
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 1.2657
    Episode_Reward/rotating_object: 136.1587
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.19s
                      Time elapsed: 00:27:16
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 44250 steps/s (collection: 2.104s, learning 0.118s)
             Mean action noise std: 2.49
          Mean value_function loss: 78.4430
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 59.7232
                       Mean reward: 679.95
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2688
    Episode_Reward/rotating_object: 134.8445
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.22s
                      Time elapsed: 00:27:18
                               ETA: 00:29:04

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 44944 steps/s (collection: 2.076s, learning 0.111s)
             Mean action noise std: 2.50
          Mean value_function loss: 70.9786
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.7531
                       Mean reward: 686.62
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 133.1400
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.19s
                      Time elapsed: 00:27:20
                               ETA: 00:29:02

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 44816 steps/s (collection: 2.080s, learning 0.114s)
             Mean action noise std: 2.50
          Mean value_function loss: 75.9815
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 59.7805
                       Mean reward: 677.16
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.2542
    Episode_Reward/rotating_object: 133.6608
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.19s
                      Time elapsed: 00:27:22
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 44451 steps/s (collection: 2.096s, learning 0.116s)
             Mean action noise std: 2.50
          Mean value_function loss: 73.8978
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 59.8117
                       Mean reward: 666.25
               Mean episode length: 234.74
    Episode_Reward/reaching_object: 1.2675
    Episode_Reward/rotating_object: 133.3311
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.21s
                      Time elapsed: 00:27:25
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 44795 steps/s (collection: 2.081s, learning 0.113s)
             Mean action noise std: 2.51
          Mean value_function loss: 64.2184
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 59.8508
                       Mean reward: 684.59
               Mean episode length: 237.61
    Episode_Reward/reaching_object: 1.2759
    Episode_Reward/rotating_object: 136.8925
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.19s
                      Time elapsed: 00:27:27
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 45038 steps/s (collection: 2.070s, learning 0.112s)
             Mean action noise std: 2.51
          Mean value_function loss: 69.3704
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 59.8886
                       Mean reward: 655.83
               Mean episode length: 225.96
    Episode_Reward/reaching_object: 1.2621
    Episode_Reward/rotating_object: 135.2868
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.18s
                      Time elapsed: 00:27:29
                               ETA: 00:28:52

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 45416 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 2.51
          Mean value_function loss: 75.9197
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 59.9248
                       Mean reward: 713.90
               Mean episode length: 243.05
    Episode_Reward/reaching_object: 1.2737
    Episode_Reward/rotating_object: 137.2814
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.16s
                      Time elapsed: 00:27:31
                               ETA: 00:28:50

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 45077 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 2.52
          Mean value_function loss: 82.7501
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 59.9535
                       Mean reward: 661.29
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.2725
    Episode_Reward/rotating_object: 136.0073
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.18s
                      Time elapsed: 00:27:33
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 44790 steps/s (collection: 2.080s, learning 0.115s)
             Mean action noise std: 2.52
          Mean value_function loss: 73.4143
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 59.9847
                       Mean reward: 626.86
               Mean episode length: 225.51
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 132.1226
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0274
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.19s
                      Time elapsed: 00:27:35
                               ETA: 00:28:45

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 43863 steps/s (collection: 2.125s, learning 0.116s)
             Mean action noise std: 2.52
          Mean value_function loss: 70.7114
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 60.0122
                       Mean reward: 694.47
               Mean episode length: 236.26
    Episode_Reward/reaching_object: 1.2540
    Episode_Reward/rotating_object: 136.8673
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.24s
                      Time elapsed: 00:27:38
                               ETA: 00:28:43

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 43867 steps/s (collection: 2.127s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 85.4460
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 60.0533
                       Mean reward: 671.97
               Mean episode length: 227.10
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 136.7873
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0280
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.24s
                      Time elapsed: 00:27:40
                               ETA: 00:28:41

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 45081 steps/s (collection: 2.066s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 80.6490
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 60.0901
                       Mean reward: 693.87
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.2492
    Episode_Reward/rotating_object: 136.0748
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0281
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.18s
                      Time elapsed: 00:27:42
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 44665 steps/s (collection: 2.075s, learning 0.126s)
             Mean action noise std: 2.53
          Mean value_function loss: 75.2536
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.1184
                       Mean reward: 735.10
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 1.2548
    Episode_Reward/rotating_object: 135.0164
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.20s
                      Time elapsed: 00:27:44
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 44818 steps/s (collection: 2.079s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 69.2088
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 60.1406
                       Mean reward: 753.90
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 1.2614
    Episode_Reward/rotating_object: 138.5598
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.19s
                      Time elapsed: 00:27:46
                               ETA: 00:28:34

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 45385 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 2.54
          Mean value_function loss: 73.0235
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.1675
                       Mean reward: 699.81
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 134.3708
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0276
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.17s
                      Time elapsed: 00:27:49
                               ETA: 00:28:31

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 45404 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 2.54
          Mean value_function loss: 72.4353
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.2057
                       Mean reward: 669.69
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 1.2625
    Episode_Reward/rotating_object: 134.9194
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0286
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.17s
                      Time elapsed: 00:27:51
                               ETA: 00:28:29

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 45885 steps/s (collection: 2.031s, learning 0.111s)
             Mean action noise std: 2.54
          Mean value_function loss: 75.8444
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.2309
                       Mean reward: 643.34
               Mean episode length: 231.63
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 134.5429
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.14s
                      Time elapsed: 00:27:53
                               ETA: 00:28:27

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 45842 steps/s (collection: 2.034s, learning 0.111s)
             Mean action noise std: 2.55
          Mean value_function loss: 86.3069
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.2560
                       Mean reward: 691.22
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.2354
    Episode_Reward/rotating_object: 132.9312
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0275
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.14s
                      Time elapsed: 00:27:55
                               ETA: 00:28:24

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 46071 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 2.55
          Mean value_function loss: 73.1328
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.2989
                       Mean reward: 686.12
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.2447
    Episode_Reward/rotating_object: 133.8737
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.13s
                      Time elapsed: 00:27:57
                               ETA: 00:28:22

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 45881 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 2.55
          Mean value_function loss: 88.9138
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 60.3353
                       Mean reward: 673.88
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 1.2525
    Episode_Reward/rotating_object: 134.5847
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0282
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.14s
                      Time elapsed: 00:27:59
                               ETA: 00:28:20

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 45244 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 2.56
          Mean value_function loss: 72.2528
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.3627
                       Mean reward: 693.59
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.2623
    Episode_Reward/rotating_object: 135.0112
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.17s
                      Time elapsed: 00:28:02
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 45206 steps/s (collection: 2.061s, learning 0.114s)
             Mean action noise std: 2.56
          Mean value_function loss: 83.4030
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 60.3962
                       Mean reward: 652.31
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.2579
    Episode_Reward/rotating_object: 133.4091
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.17s
                      Time elapsed: 00:28:04
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 44837 steps/s (collection: 2.079s, learning 0.113s)
             Mean action noise std: 2.56
          Mean value_function loss: 81.6120
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.4184
                       Mean reward: 677.09
               Mean episode length: 230.02
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 135.5422
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.19s
                      Time elapsed: 00:28:06
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 45418 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 2.57
          Mean value_function loss: 83.8161
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.4404
                       Mean reward: 709.77
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 1.2343
    Episode_Reward/rotating_object: 133.1858
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.16s
                      Time elapsed: 00:28:08
                               ETA: 00:28:10

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 44898 steps/s (collection: 2.078s, learning 0.112s)
             Mean action noise std: 2.57
          Mean value_function loss: 84.0929
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 60.4682
                       Mean reward: 640.94
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.2509
    Episode_Reward/rotating_object: 131.9933
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.19s
                      Time elapsed: 00:28:10
                               ETA: 00:28:08

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 43093 steps/s (collection: 2.167s, learning 0.114s)
             Mean action noise std: 2.57
          Mean value_function loss: 73.7520
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 60.5008
                       Mean reward: 639.29
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 1.2466
    Episode_Reward/rotating_object: 132.4016
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.28s
                      Time elapsed: 00:28:13
                               ETA: 00:28:06

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 42061 steps/s (collection: 2.226s, learning 0.111s)
             Mean action noise std: 2.58
          Mean value_function loss: 63.5563
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.5391
                       Mean reward: 706.10
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 134.6044
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.34s
                      Time elapsed: 00:28:15
                               ETA: 00:28:04

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 42192 steps/s (collection: 2.216s, learning 0.114s)
             Mean action noise std: 2.58
          Mean value_function loss: 68.4854
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 60.5654
                       Mean reward: 726.78
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 1.2870
    Episode_Reward/rotating_object: 137.7963
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0289
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.33s
                      Time elapsed: 00:28:17
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 41684 steps/s (collection: 2.247s, learning 0.112s)
             Mean action noise std: 2.58
          Mean value_function loss: 79.8111
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 60.5903
                       Mean reward: 633.43
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.2489
    Episode_Reward/rotating_object: 130.1974
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.36s
                      Time elapsed: 00:28:20
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 42174 steps/s (collection: 2.219s, learning 0.112s)
             Mean action noise std: 2.59
          Mean value_function loss: 78.5593
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 60.6158
                       Mean reward: 644.86
               Mean episode length: 229.91
    Episode_Reward/reaching_object: 1.2604
    Episode_Reward/rotating_object: 132.5838
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.33s
                      Time elapsed: 00:28:22
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 44049 steps/s (collection: 2.116s, learning 0.116s)
             Mean action noise std: 2.59
          Mean value_function loss: 83.8619
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 60.6416
                       Mean reward: 638.70
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.2582
    Episode_Reward/rotating_object: 129.6206
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0293
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.23s
                      Time elapsed: 00:28:24
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 44381 steps/s (collection: 2.099s, learning 0.116s)
             Mean action noise std: 2.59
          Mean value_function loss: 83.4940
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 60.6738
                       Mean reward: 628.83
               Mean episode length: 227.21
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 133.1124
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0295
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.21s
                      Time elapsed: 00:28:26
                               ETA: 00:27:53

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 44829 steps/s (collection: 2.081s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 71.5263
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 60.7132
                       Mean reward: 681.35
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.2651
    Episode_Reward/rotating_object: 134.1644
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0292
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.19s
                      Time elapsed: 00:28:29
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 44989 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 2.60
          Mean value_function loss: 76.6239
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 60.7595
                       Mean reward: 651.90
               Mean episode length: 231.54
    Episode_Reward/reaching_object: 1.2576
    Episode_Reward/rotating_object: 134.3646
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0290
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.19s
                      Time elapsed: 00:28:31
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 42289 steps/s (collection: 2.214s, learning 0.111s)
             Mean action noise std: 2.60
          Mean value_function loss: 81.2558
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 60.7938
                       Mean reward: 671.12
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.2809
    Episode_Reward/rotating_object: 136.0729
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0298
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.32s
                      Time elapsed: 00:28:33
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 44761 steps/s (collection: 2.082s, learning 0.114s)
             Mean action noise std: 2.61
          Mean value_function loss: 77.9212
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.8186
                       Mean reward: 659.77
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 135.2989
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.20s
                      Time elapsed: 00:28:35
                               ETA: 00:27:43

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 45112 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 66.4177
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.8469
                       Mean reward: 676.54
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.2690
    Episode_Reward/rotating_object: 139.0267
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0288
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.18s
                      Time elapsed: 00:28:37
                               ETA: 00:27:41

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 45446 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 2.61
          Mean value_function loss: 78.4961
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 60.8706
                       Mean reward: 665.72
               Mean episode length: 234.18
    Episode_Reward/reaching_object: 1.2490
    Episode_Reward/rotating_object: 132.2283
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.16s
                      Time elapsed: 00:28:40
                               ETA: 00:27:39

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 45982 steps/s (collection: 2.025s, learning 0.113s)
             Mean action noise std: 2.62
          Mean value_function loss: 76.5291
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.9030
                       Mean reward: 659.34
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.2576
    Episode_Reward/rotating_object: 133.3810
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.14s
                      Time elapsed: 00:28:42
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 45593 steps/s (collection: 2.037s, learning 0.119s)
             Mean action noise std: 2.62
          Mean value_function loss: 76.2961
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 60.9340
                       Mean reward: 649.38
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 1.2694
    Episode_Reward/rotating_object: 134.6236
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.16s
                      Time elapsed: 00:28:44
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 45906 steps/s (collection: 2.029s, learning 0.113s)
             Mean action noise std: 2.62
          Mean value_function loss: 80.6414
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 60.9646
                       Mean reward: 679.51
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.2612
    Episode_Reward/rotating_object: 135.6086
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.14s
                      Time elapsed: 00:28:46
                               ETA: 00:27:32

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 45896 steps/s (collection: 2.030s, learning 0.112s)
             Mean action noise std: 2.62
          Mean value_function loss: 81.2851
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 60.9932
                       Mean reward: 690.96
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2375
    Episode_Reward/rotating_object: 131.3596
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0291
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.14s
                      Time elapsed: 00:28:48
                               ETA: 00:27:29

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 45636 steps/s (collection: 2.039s, learning 0.115s)
             Mean action noise std: 2.63
          Mean value_function loss: 73.0723
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.0264
                       Mean reward: 710.48
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 133.8420
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0296
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.15s
                      Time elapsed: 00:28:50
                               ETA: 00:27:27

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 45452 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 2.63
          Mean value_function loss: 71.7785
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.0470
                       Mean reward: 661.18
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.2604
    Episode_Reward/rotating_object: 133.1682
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.16s
                      Time elapsed: 00:28:52
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 45184 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 2.63
          Mean value_function loss: 68.6881
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.0647
                       Mean reward: 705.74
               Mean episode length: 235.82
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 135.3651
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.18s
                      Time elapsed: 00:28:55
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 44198 steps/s (collection: 2.108s, learning 0.116s)
             Mean action noise std: 2.64
          Mean value_function loss: 75.5491
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 61.0903
                       Mean reward: 663.48
               Mean episode length: 233.54
    Episode_Reward/reaching_object: 1.2651
    Episode_Reward/rotating_object: 139.8679
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.22s
                      Time elapsed: 00:28:57
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 45070 steps/s (collection: 2.067s, learning 0.114s)
             Mean action noise std: 2.64
          Mean value_function loss: 73.9888
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.1221
                       Mean reward: 704.37
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 1.2558
    Episode_Reward/rotating_object: 137.1309
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.18s
                      Time elapsed: 00:28:59
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 43911 steps/s (collection: 2.124s, learning 0.115s)
             Mean action noise std: 2.64
          Mean value_function loss: 78.3324
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 61.1636
                       Mean reward: 675.89
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.2621
    Episode_Reward/rotating_object: 133.2992
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.24s
                      Time elapsed: 00:29:01
                               ETA: 00:27:16

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 45452 steps/s (collection: 2.049s, learning 0.114s)
             Mean action noise std: 2.65
          Mean value_function loss: 83.0790
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.2010
                       Mean reward: 685.98
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.2598
    Episode_Reward/rotating_object: 136.6549
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0300
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.16s
                      Time elapsed: 00:29:03
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 44805 steps/s (collection: 2.083s, learning 0.111s)
             Mean action noise std: 2.65
          Mean value_function loss: 64.6391
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.2258
                       Mean reward: 685.56
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 135.0560
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.19s
                      Time elapsed: 00:29:06
                               ETA: 00:27:11

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 44978 steps/s (collection: 2.071s, learning 0.115s)
             Mean action noise std: 2.65
          Mean value_function loss: 76.8697
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.2509
                       Mean reward: 700.65
               Mean episode length: 240.66
    Episode_Reward/reaching_object: 1.2832
    Episode_Reward/rotating_object: 139.7857
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.19s
                      Time elapsed: 00:29:08
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 44786 steps/s (collection: 2.080s, learning 0.115s)
             Mean action noise std: 2.65
          Mean value_function loss: 75.2213
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.2777
                       Mean reward: 673.53
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.2728
    Episode_Reward/rotating_object: 136.0431
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.19s
                      Time elapsed: 00:29:10
                               ETA: 00:27:06

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 45375 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 2.66
          Mean value_function loss: 77.3815
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 61.2960
                       Mean reward: 691.33
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.2509
    Episode_Reward/rotating_object: 135.5873
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.17s
                      Time elapsed: 00:29:12
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 44587 steps/s (collection: 2.080s, learning 0.125s)
             Mean action noise std: 2.66
          Mean value_function loss: 71.2633
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.3134
                       Mean reward: 659.93
               Mean episode length: 223.81
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 132.0928
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.20s
                      Time elapsed: 00:29:14
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 41644 steps/s (collection: 2.231s, learning 0.129s)
             Mean action noise std: 2.66
          Mean value_function loss: 79.9475
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.3336
                       Mean reward: 611.18
               Mean episode length: 224.22
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 133.7380
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.36s
                      Time elapsed: 00:29:17
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 41428 steps/s (collection: 2.233s, learning 0.140s)
             Mean action noise std: 2.67
          Mean value_function loss: 71.9672
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 61.3714
                       Mean reward: 744.54
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 1.2534
    Episode_Reward/rotating_object: 134.8433
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0309
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.37s
                      Time elapsed: 00:29:19
                               ETA: 00:26:57

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 41950 steps/s (collection: 2.218s, learning 0.126s)
             Mean action noise std: 2.67
          Mean value_function loss: 94.3852
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 61.4038
                       Mean reward: 640.62
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.2331
    Episode_Reward/rotating_object: 130.0322
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.34s
                      Time elapsed: 00:29:21
                               ETA: 00:26:55

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 43999 steps/s (collection: 2.119s, learning 0.115s)
             Mean action noise std: 2.67
          Mean value_function loss: 82.5028
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 61.4264
                       Mean reward: 663.59
               Mean episode length: 233.53
    Episode_Reward/reaching_object: 1.2712
    Episode_Reward/rotating_object: 137.6512
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.23s
                      Time elapsed: 00:29:24
                               ETA: 00:26:53

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 45098 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 2.67
          Mean value_function loss: 81.7545
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.4478
                       Mean reward: 654.19
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 132.7434
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.18s
                      Time elapsed: 00:29:26
                               ETA: 00:26:51

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 45830 steps/s (collection: 2.033s, learning 0.112s)
             Mean action noise std: 2.68
          Mean value_function loss: 69.6501
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.4675
                       Mean reward: 668.60
               Mean episode length: 236.73
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 134.0038
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.14s
                      Time elapsed: 00:29:28
                               ETA: 00:26:48

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 45961 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 2.68
          Mean value_function loss: 75.3535
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.4926
                       Mean reward: 721.78
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 1.2676
    Episode_Reward/rotating_object: 136.8832
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.14s
                      Time elapsed: 00:29:30
                               ETA: 00:26:46

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 46298 steps/s (collection: 2.012s, learning 0.112s)
             Mean action noise std: 2.68
          Mean value_function loss: 84.6878
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 61.5321
                       Mean reward: 673.92
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 1.2330
    Episode_Reward/rotating_object: 132.4778
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0307
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.12s
                      Time elapsed: 00:29:32
                               ETA: 00:26:44

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 46097 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 2.69
          Mean value_function loss: 67.6396
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 61.5735
                       Mean reward: 696.86
               Mean episode length: 242.22
    Episode_Reward/reaching_object: 1.2743
    Episode_Reward/rotating_object: 136.2184
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.13s
                      Time elapsed: 00:29:34
                               ETA: 00:26:41

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 46088 steps/s (collection: 2.021s, learning 0.112s)
             Mean action noise std: 2.69
          Mean value_function loss: 75.6298
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.6061
                       Mean reward: 697.95
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.2499
    Episode_Reward/rotating_object: 135.1295
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.13s
                      Time elapsed: 00:29:37
                               ETA: 00:26:39

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 45718 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 2.69
          Mean value_function loss: 72.9585
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 61.6278
                       Mean reward: 665.93
               Mean episode length: 239.87
    Episode_Reward/reaching_object: 1.2680
    Episode_Reward/rotating_object: 134.3832
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.15s
                      Time elapsed: 00:29:39
                               ETA: 00:26:37

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 45057 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 76.2587
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 61.6580
                       Mean reward: 718.64
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.2736
    Episode_Reward/rotating_object: 139.7686
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.18s
                      Time elapsed: 00:29:41
                               ETA: 00:26:34

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 45136 steps/s (collection: 2.067s, learning 0.111s)
             Mean action noise std: 2.70
          Mean value_function loss: 79.0628
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 61.6849
                       Mean reward: 680.92
               Mean episode length: 233.45
    Episode_Reward/reaching_object: 1.2464
    Episode_Reward/rotating_object: 131.3556
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.18s
                      Time elapsed: 00:29:43
                               ETA: 00:26:32

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 41048 steps/s (collection: 2.262s, learning 0.132s)
             Mean action noise std: 2.70
          Mean value_function loss: 82.3942
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 61.7155
                       Mean reward: 683.82
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.2491
    Episode_Reward/rotating_object: 134.5986
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.39s
                      Time elapsed: 00:29:45
                               ETA: 00:26:30

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 44083 steps/s (collection: 2.098s, learning 0.132s)
             Mean action noise std: 2.71
          Mean value_function loss: 81.1932
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 61.7453
                       Mean reward: 681.93
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 133.4357
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.23s
                      Time elapsed: 00:29:48
                               ETA: 00:26:28

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 44801 steps/s (collection: 2.077s, learning 0.117s)
             Mean action noise std: 2.71
          Mean value_function loss: 78.1270
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 61.7752
                       Mean reward: 678.38
               Mean episode length: 237.39
    Episode_Reward/reaching_object: 1.2710
    Episode_Reward/rotating_object: 136.3243
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.19s
                      Time elapsed: 00:29:50
                               ETA: 00:26:25

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 45428 steps/s (collection: 2.050s, learning 0.114s)
             Mean action noise std: 2.71
          Mean value_function loss: 82.8917
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 61.8026
                       Mean reward: 696.96
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.2524
    Episode_Reward/rotating_object: 135.4134
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.16s
                      Time elapsed: 00:29:52
                               ETA: 00:26:23

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 45067 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 2.71
          Mean value_function loss: 87.9640
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 61.8208
                       Mean reward: 683.20
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.2503
    Episode_Reward/rotating_object: 134.9996
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.18s
                      Time elapsed: 00:29:54
                               ETA: 00:26:21

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 45186 steps/s (collection: 2.060s, learning 0.115s)
             Mean action noise std: 2.72
          Mean value_function loss: 79.6882
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 61.8424
                       Mean reward: 670.88
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.2594
    Episode_Reward/rotating_object: 134.4027
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.18s
                      Time elapsed: 00:29:56
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 44478 steps/s (collection: 2.096s, learning 0.114s)
             Mean action noise std: 2.72
          Mean value_function loss: 84.9112
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 61.8755
                       Mean reward: 702.50
               Mean episode length: 240.96
    Episode_Reward/reaching_object: 1.2454
    Episode_Reward/rotating_object: 135.0447
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.21s
                      Time elapsed: 00:29:59
                               ETA: 00:26:16

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 45261 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 2.72
          Mean value_function loss: 86.0257
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 61.9050
                       Mean reward: 638.50
               Mean episode length: 222.94
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 131.1875
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.17s
                      Time elapsed: 00:30:01
                               ETA: 00:26:14

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 43248 steps/s (collection: 2.162s, learning 0.111s)
             Mean action noise std: 2.72
          Mean value_function loss: 82.0974
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 61.9294
                       Mean reward: 726.48
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.2540
    Episode_Reward/rotating_object: 139.2146
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.27s
                      Time elapsed: 00:30:03
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 44770 steps/s (collection: 2.083s, learning 0.113s)
             Mean action noise std: 2.73
          Mean value_function loss: 88.5684
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 61.9497
                       Mean reward: 694.71
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.2726
    Episode_Reward/rotating_object: 138.9432
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.20s
                      Time elapsed: 00:30:05
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 45287 steps/s (collection: 2.056s, learning 0.115s)
             Mean action noise std: 2.73
          Mean value_function loss: 82.7831
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.9714
                       Mean reward: 680.48
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 131.8253
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.17s
                      Time elapsed: 00:30:07
                               ETA: 00:26:07

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 44915 steps/s (collection: 2.075s, learning 0.114s)
             Mean action noise std: 2.73
          Mean value_function loss: 69.6001
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 61.9935
                       Mean reward: 668.88
               Mean episode length: 234.71
    Episode_Reward/reaching_object: 1.2797
    Episode_Reward/rotating_object: 139.8463
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.19s
                      Time elapsed: 00:30:10
                               ETA: 00:26:05

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 44872 steps/s (collection: 2.080s, learning 0.111s)
             Mean action noise std: 2.74
          Mean value_function loss: 77.2540
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.0213
                       Mean reward: 722.18
               Mean episode length: 241.36
    Episode_Reward/reaching_object: 1.2602
    Episode_Reward/rotating_object: 137.2853
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.19s
                      Time elapsed: 00:30:12
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 45383 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 2.74
          Mean value_function loss: 75.1019
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.0560
                       Mean reward: 678.81
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.2527
    Episode_Reward/rotating_object: 135.3979
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.17s
                      Time elapsed: 00:30:14
                               ETA: 00:26:00

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 46204 steps/s (collection: 2.008s, learning 0.120s)
             Mean action noise std: 2.74
          Mean value_function loss: 71.0591
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 62.0912
                       Mean reward: 684.15
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.2618
    Episode_Reward/rotating_object: 135.2265
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.13s
                      Time elapsed: 00:30:16
                               ETA: 00:25:58

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 45014 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 2.75
          Mean value_function loss: 64.8950
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.1304
                       Mean reward: 689.78
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 1.2784
    Episode_Reward/rotating_object: 137.9138
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.18s
                      Time elapsed: 00:30:18
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 44496 steps/s (collection: 2.099s, learning 0.111s)
             Mean action noise std: 2.75
          Mean value_function loss: 67.1570
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.1721
                       Mean reward: 682.48
               Mean episode length: 238.03
    Episode_Reward/reaching_object: 1.2715
    Episode_Reward/rotating_object: 135.3799
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.21s
                      Time elapsed: 00:30:21
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 45619 steps/s (collection: 2.042s, learning 0.112s)
             Mean action noise std: 2.76
          Mean value_function loss: 63.0591
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.2079
                       Mean reward: 717.06
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 1.2763
    Episode_Reward/rotating_object: 141.1590
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.15s
                      Time elapsed: 00:30:23
                               ETA: 00:25:51

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 46432 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 80.6197
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 62.2481
                       Mean reward: 668.42
               Mean episode length: 232.14
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 132.7172
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.12s
                      Time elapsed: 00:30:25
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 46241 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 2.76
          Mean value_function loss: 71.2211
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.2753
                       Mean reward: 675.53
               Mean episode length: 231.69
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 135.4847
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.13s
                      Time elapsed: 00:30:27
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 44772 steps/s (collection: 2.083s, learning 0.113s)
             Mean action noise std: 2.77
          Mean value_function loss: 87.6259
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.2948
                       Mean reward: 685.68
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.2263
    Episode_Reward/rotating_object: 134.5897
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.20s
                      Time elapsed: 00:30:29
                               ETA: 00:25:44

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 45049 steps/s (collection: 2.070s, learning 0.112s)
             Mean action noise std: 2.77
          Mean value_function loss: 81.8382
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 62.3232
                       Mean reward: 657.85
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.2367
    Episode_Reward/rotating_object: 132.7327
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.18s
                      Time elapsed: 00:30:31
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 45264 steps/s (collection: 2.058s, learning 0.113s)
             Mean action noise std: 2.77
          Mean value_function loss: 85.7086
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 62.3512
                       Mean reward: 685.17
               Mean episode length: 229.28
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 134.8907
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.17s
                      Time elapsed: 00:30:33
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 45110 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 2.78
          Mean value_function loss: 71.1470
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 62.3803
                       Mean reward: 733.10
               Mean episode length: 242.35
    Episode_Reward/reaching_object: 1.2714
    Episode_Reward/rotating_object: 141.5533
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.18s
                      Time elapsed: 00:30:36
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 45145 steps/s (collection: 2.065s, learning 0.113s)
             Mean action noise std: 2.78
          Mean value_function loss: 85.4000
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.4115
                       Mean reward: 655.33
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 1.2377
    Episode_Reward/rotating_object: 134.1454
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.18s
                      Time elapsed: 00:30:38
                               ETA: 00:25:34

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 44238 steps/s (collection: 2.110s, learning 0.113s)
             Mean action noise std: 2.78
          Mean value_function loss: 72.6385
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.4382
                       Mean reward: 680.32
               Mean episode length: 236.33
    Episode_Reward/reaching_object: 1.2619
    Episode_Reward/rotating_object: 136.6943
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.22s
                      Time elapsed: 00:30:40
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 44919 steps/s (collection: 2.076s, learning 0.113s)
             Mean action noise std: 2.79
          Mean value_function loss: 70.1459
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.4650
                       Mean reward: 648.71
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.2456
    Episode_Reward/rotating_object: 134.8174
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.19s
                      Time elapsed: 00:30:42
                               ETA: 00:25:30

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 45319 steps/s (collection: 2.058s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 71.2252
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 62.4919
                       Mean reward: 674.36
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.2648
    Episode_Reward/rotating_object: 136.6592
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.17s
                      Time elapsed: 00:30:44
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 45223 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 2.79
          Mean value_function loss: 80.7194
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 62.5196
                       Mean reward: 744.35
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 1.2963
    Episode_Reward/rotating_object: 141.8361
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.17s
                      Time elapsed: 00:30:47
                               ETA: 00:25:25

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 45046 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 2.80
          Mean value_function loss: 79.1475
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 62.5480
                       Mean reward: 674.38
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.2438
    Episode_Reward/rotating_object: 135.0602
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.18s
                      Time elapsed: 00:30:49
                               ETA: 00:25:23

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 42860 steps/s (collection: 2.179s, learning 0.114s)
             Mean action noise std: 2.80
          Mean value_function loss: 87.6263
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.5806
                       Mean reward: 707.71
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 1.2503
    Episode_Reward/rotating_object: 135.2550
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.29s
                      Time elapsed: 00:30:51
                               ETA: 00:25:21

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 44977 steps/s (collection: 2.071s, learning 0.115s)
             Mean action noise std: 2.80
          Mean value_function loss: 79.0443
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 62.6173
                       Mean reward: 707.52
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 1.2369
    Episode_Reward/rotating_object: 134.8916
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.19s
                      Time elapsed: 00:30:53
                               ETA: 00:25:18

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 44798 steps/s (collection: 2.081s, learning 0.113s)
             Mean action noise std: 2.81
          Mean value_function loss: 80.1456
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 62.6501
                       Mean reward: 699.63
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.2576
    Episode_Reward/rotating_object: 134.2153
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.19s
                      Time elapsed: 00:30:55
                               ETA: 00:25:16

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 44921 steps/s (collection: 2.075s, learning 0.114s)
             Mean action noise std: 2.81
          Mean value_function loss: 85.6325
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 62.6764
                       Mean reward: 696.85
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.2824
    Episode_Reward/rotating_object: 140.1338
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.19s
                      Time elapsed: 00:30:58
                               ETA: 00:25:14

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 44729 steps/s (collection: 2.083s, learning 0.115s)
             Mean action noise std: 2.81
          Mean value_function loss: 85.5815
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 62.6908
                       Mean reward: 704.49
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.2643
    Episode_Reward/rotating_object: 136.0114
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.20s
                      Time elapsed: 00:31:00
                               ETA: 00:25:12

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 45291 steps/s (collection: 2.059s, learning 0.111s)
             Mean action noise std: 2.81
          Mean value_function loss: 79.6353
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.7013
                       Mean reward: 712.92
               Mean episode length: 237.27
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 136.7636
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.17s
                      Time elapsed: 00:31:02
                               ETA: 00:25:09

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 45850 steps/s (collection: 2.032s, learning 0.112s)
             Mean action noise std: 2.82
          Mean value_function loss: 66.2204
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 62.7203
                       Mean reward: 722.82
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.2631
    Episode_Reward/rotating_object: 136.5217
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.14s
                      Time elapsed: 00:31:04
                               ETA: 00:25:07

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 45776 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 85.2512
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.7482
                       Mean reward: 693.02
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2408
    Episode_Reward/rotating_object: 127.8925
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.15s
                      Time elapsed: 00:31:06
                               ETA: 00:25:05

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 45915 steps/s (collection: 2.030s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 68.4795
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 62.7747
                       Mean reward: 686.55
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 1.2690
    Episode_Reward/rotating_object: 137.2653
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.14s
                      Time elapsed: 00:31:08
                               ETA: 00:25:02

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 45816 steps/s (collection: 2.035s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 74.1481
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 62.7884
                       Mean reward: 649.02
               Mean episode length: 227.40
    Episode_Reward/reaching_object: 1.2597
    Episode_Reward/rotating_object: 135.1903
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.15s
                      Time elapsed: 00:31:11
                               ETA: 00:25:00

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 45340 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 85.9910
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 62.7982
                       Mean reward: 715.50
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 1.2678
    Episode_Reward/rotating_object: 135.6333
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.17s
                      Time elapsed: 00:31:13
                               ETA: 00:24:58

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 45296 steps/s (collection: 2.059s, learning 0.111s)
             Mean action noise std: 2.83
          Mean value_function loss: 99.0015
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 62.8109
                       Mean reward: 684.98
               Mean episode length: 232.02
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 132.2559
        Episode_Reward/action_rate: -0.0467
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.17s
                      Time elapsed: 00:31:15
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 45238 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 2.83
          Mean value_function loss: 69.6644
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 62.8384
                       Mean reward: 676.58
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 1.2660
    Episode_Reward/rotating_object: 133.6221
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.17s
                      Time elapsed: 00:31:17
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 44443 steps/s (collection: 2.098s, learning 0.114s)
             Mean action noise std: 2.83
          Mean value_function loss: 92.0739
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 62.8629
                       Mean reward: 672.63
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2451
    Episode_Reward/rotating_object: 133.9039
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.21s
                      Time elapsed: 00:31:19
                               ETA: 00:24:51

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 43988 steps/s (collection: 2.118s, learning 0.116s)
             Mean action noise std: 2.84
          Mean value_function loss: 81.1663
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 62.8839
                       Mean reward: 701.60
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.2736
    Episode_Reward/rotating_object: 137.6592
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.23s
                      Time elapsed: 00:31:22
                               ETA: 00:24:49

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 42010 steps/s (collection: 2.228s, learning 0.111s)
             Mean action noise std: 2.84
          Mean value_function loss: 79.4269
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 62.9184
                       Mean reward: 698.67
               Mean episode length: 234.17
    Episode_Reward/reaching_object: 1.2496
    Episode_Reward/rotating_object: 136.0174
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.34s
                      Time elapsed: 00:31:24
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 43983 steps/s (collection: 2.116s, learning 0.119s)
             Mean action noise std: 2.84
          Mean value_function loss: 77.7905
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 62.9492
                       Mean reward: 696.08
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.2636
    Episode_Reward/rotating_object: 137.1781
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.24s
                      Time elapsed: 00:31:26
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 44605 steps/s (collection: 2.089s, learning 0.115s)
             Mean action noise std: 2.85
          Mean value_function loss: 74.9504
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 62.9750
                       Mean reward: 734.74
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.2695
    Episode_Reward/rotating_object: 139.8449
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.20s
                      Time elapsed: 00:31:28
                               ETA: 00:24:42

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 45090 steps/s (collection: 2.068s, learning 0.112s)
             Mean action noise std: 2.85
          Mean value_function loss: 77.6832
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 62.9995
                       Mean reward: 652.21
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.2447
    Episode_Reward/rotating_object: 130.1487
        Episode_Reward/action_rate: -0.0477
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.18s
                      Time elapsed: 00:31:30
                               ETA: 00:24:40

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 45154 steps/s (collection: 2.063s, learning 0.114s)
             Mean action noise std: 2.85
          Mean value_function loss: 71.3073
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 63.0447
                       Mean reward: 727.03
               Mean episode length: 242.47
    Episode_Reward/reaching_object: 1.2766
    Episode_Reward/rotating_object: 137.6778
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.18s
                      Time elapsed: 00:31:33
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 44753 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 2.86
          Mean value_function loss: 78.5121
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 63.0760
                       Mean reward: 690.57
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.2708
    Episode_Reward/rotating_object: 137.3537
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.20s
                      Time elapsed: 00:31:35
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 44829 steps/s (collection: 2.069s, learning 0.124s)
             Mean action noise std: 2.86
          Mean value_function loss: 78.6190
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.1011
                       Mean reward: 682.74
               Mean episode length: 233.06
    Episode_Reward/reaching_object: 1.2446
    Episode_Reward/rotating_object: 135.2426
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.19s
                      Time elapsed: 00:31:37
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 44709 steps/s (collection: 2.085s, learning 0.114s)
             Mean action noise std: 2.86
          Mean value_function loss: 81.5315
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.1281
                       Mean reward: 714.81
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 1.2633
    Episode_Reward/rotating_object: 135.6823
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.20s
                      Time elapsed: 00:31:39
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 44669 steps/s (collection: 2.089s, learning 0.111s)
             Mean action noise std: 2.87
          Mean value_function loss: 76.4502
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.1542
                       Mean reward: 674.77
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.2676
    Episode_Reward/rotating_object: 137.3757
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.20s
                      Time elapsed: 00:31:41
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 44712 steps/s (collection: 2.087s, learning 0.112s)
             Mean action noise std: 2.87
          Mean value_function loss: 93.0746
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.1819
                       Mean reward: 640.47
               Mean episode length: 225.97
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 135.6536
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.20s
                      Time elapsed: 00:31:44
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 43522 steps/s (collection: 2.145s, learning 0.113s)
             Mean action noise std: 2.87
          Mean value_function loss: 77.7263
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.2151
                       Mean reward: 682.39
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 134.9896
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.26s
                      Time elapsed: 00:31:46
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 43993 steps/s (collection: 2.120s, learning 0.114s)
             Mean action noise std: 2.88
          Mean value_function loss: 85.5260
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.2427
                       Mean reward: 669.68
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.2458
    Episode_Reward/rotating_object: 134.0286
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.23s
                      Time elapsed: 00:31:48
                               ETA: 00:24:21

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 43659 steps/s (collection: 2.137s, learning 0.115s)
             Mean action noise std: 2.88
          Mean value_function loss: 80.3501
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.2704
                       Mean reward: 678.65
               Mean episode length: 231.35
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 137.0495
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.25s
                      Time elapsed: 00:31:50
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 45039 steps/s (collection: 2.071s, learning 0.111s)
             Mean action noise std: 2.88
          Mean value_function loss: 82.7084
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.2964
                       Mean reward: 634.44
               Mean episode length: 226.43
    Episode_Reward/reaching_object: 1.2574
    Episode_Reward/rotating_object: 136.9635
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.18s
                      Time elapsed: 00:31:53
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 45164 steps/s (collection: 2.065s, learning 0.112s)
             Mean action noise std: 2.89
          Mean value_function loss: 88.9677
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 63.3167
                       Mean reward: 678.81
               Mean episode length: 231.13
    Episode_Reward/reaching_object: 1.2261
    Episode_Reward/rotating_object: 130.3716
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.18s
                      Time elapsed: 00:31:55
                               ETA: 00:24:14

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 45520 steps/s (collection: 2.048s, learning 0.111s)
             Mean action noise std: 2.89
          Mean value_function loss: 69.6802
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 63.3333
                       Mean reward: 735.69
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.2904
    Episode_Reward/rotating_object: 142.4076
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.16s
                      Time elapsed: 00:31:57
                               ETA: 00:24:12

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 45640 steps/s (collection: 2.042s, learning 0.112s)
             Mean action noise std: 2.89
          Mean value_function loss: 92.3264
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.3562
                       Mean reward: 672.61
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.2253
    Episode_Reward/rotating_object: 130.6435
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.15s
                      Time elapsed: 00:31:59
                               ETA: 00:24:10

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 45615 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 2.89
          Mean value_function loss: 73.8597
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.3808
                       Mean reward: 709.68
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 1.2681
    Episode_Reward/rotating_object: 136.8117
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.16s
                      Time elapsed: 00:32:01
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 45338 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 2.90
          Mean value_function loss: 79.3999
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 63.4003
                       Mean reward: 718.63
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.2751
    Episode_Reward/rotating_object: 139.5240
        Episode_Reward/action_rate: -0.0505
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.17s
                      Time elapsed: 00:32:03
                               ETA: 00:24:05

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 45268 steps/s (collection: 2.057s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 96.5925
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 63.4216
                       Mean reward: 655.22
               Mean episode length: 220.98
    Episode_Reward/reaching_object: 1.2290
    Episode_Reward/rotating_object: 134.3587
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.17s
                      Time elapsed: 00:32:06
                               ETA: 00:24:03

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 43027 steps/s (collection: 2.173s, learning 0.112s)
             Mean action noise std: 2.90
          Mean value_function loss: 98.3489
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 63.4409
                       Mean reward: 668.63
               Mean episode length: 223.80
    Episode_Reward/reaching_object: 1.2151
    Episode_Reward/rotating_object: 130.8040
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.28s
                      Time elapsed: 00:32:08
                               ETA: 00:24:01

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 44708 steps/s (collection: 2.084s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 85.3714
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 63.4563
                       Mean reward: 696.76
               Mean episode length: 235.40
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 135.7513
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.20s
                      Time elapsed: 00:32:10
                               ETA: 00:23:58

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 44638 steps/s (collection: 2.084s, learning 0.118s)
             Mean action noise std: 2.90
          Mean value_function loss: 78.7536
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 63.4707
                       Mean reward: 627.56
               Mean episode length: 215.06
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 133.0255
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.20s
                      Time elapsed: 00:32:12
                               ETA: 00:23:56

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 44761 steps/s (collection: 2.080s, learning 0.116s)
             Mean action noise std: 2.91
          Mean value_function loss: 92.8304
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.4968
                       Mean reward: 666.79
               Mean episode length: 229.03
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 134.0080
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.20s
                      Time elapsed: 00:32:14
                               ETA: 00:23:54

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 44803 steps/s (collection: 2.080s, learning 0.114s)
             Mean action noise std: 2.91
          Mean value_function loss: 80.2647
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 63.5299
                       Mean reward: 675.49
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.2470
    Episode_Reward/rotating_object: 135.2631
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.19s
                      Time elapsed: 00:32:17
                               ETA: 00:23:52

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 44737 steps/s (collection: 2.084s, learning 0.113s)
             Mean action noise std: 2.91
          Mean value_function loss: 73.2786
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 63.5517
                       Mean reward: 629.92
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 1.2098
    Episode_Reward/rotating_object: 131.1796
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.20s
                      Time elapsed: 00:32:19
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 45070 steps/s (collection: 2.070s, learning 0.111s)
             Mean action noise std: 2.92
          Mean value_function loss: 74.6533
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.5734
                       Mean reward: 685.67
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.2589
    Episode_Reward/rotating_object: 136.3422
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.18s
                      Time elapsed: 00:32:21
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 44913 steps/s (collection: 2.073s, learning 0.116s)
             Mean action noise std: 2.92
          Mean value_function loss: 83.3867
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 63.6004
                       Mean reward: 696.60
               Mean episode length: 237.23
    Episode_Reward/reaching_object: 1.2551
    Episode_Reward/rotating_object: 137.2900
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.19s
                      Time elapsed: 00:32:23
                               ETA: 00:23:45

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 43602 steps/s (collection: 2.140s, learning 0.114s)
             Mean action noise std: 2.92
          Mean value_function loss: 83.6262
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 63.6279
                       Mean reward: 690.47
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 131.2383
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.25s
                      Time elapsed: 00:32:25
                               ETA: 00:23:42

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 41100 steps/s (collection: 2.280s, learning 0.111s)
             Mean action noise std: 2.93
          Mean value_function loss: 85.2170
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.6512
                       Mean reward: 659.82
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.2526
    Episode_Reward/rotating_object: 136.3532
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.39s
                      Time elapsed: 00:32:28
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 44053 steps/s (collection: 2.104s, learning 0.128s)
             Mean action noise std: 2.93
          Mean value_function loss: 85.9069
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.6748
                       Mean reward: 695.79
               Mean episode length: 236.64
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 131.8950
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.23s
                      Time elapsed: 00:32:30
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 44761 steps/s (collection: 2.081s, learning 0.115s)
             Mean action noise std: 2.93
          Mean value_function loss: 73.7358
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 63.7054
                       Mean reward: 709.97
               Mean episode length: 233.15
    Episode_Reward/reaching_object: 1.2564
    Episode_Reward/rotating_object: 138.2583
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.20s
                      Time elapsed: 00:32:32
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 44201 steps/s (collection: 2.113s, learning 0.111s)
             Mean action noise std: 2.93
          Mean value_function loss: 87.6604
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.7284
                       Mean reward: 666.40
               Mean episode length: 229.64
    Episode_Reward/reaching_object: 1.2623
    Episode_Reward/rotating_object: 135.1150
        Episode_Reward/action_rate: -0.0515
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.22s
                      Time elapsed: 00:32:35
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 44612 steps/s (collection: 2.077s, learning 0.126s)
             Mean action noise std: 2.94
          Mean value_function loss: 77.5782
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.7459
                       Mean reward: 749.21
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 1.2907
    Episode_Reward/rotating_object: 141.5849
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.20s
                      Time elapsed: 00:32:37
                               ETA: 00:23:31

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 44211 steps/s (collection: 2.113s, learning 0.111s)
             Mean action noise std: 2.94
          Mean value_function loss: 95.5569
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.7650
                       Mean reward: 710.45
               Mean episode length: 232.48
    Episode_Reward/reaching_object: 1.2224
    Episode_Reward/rotating_object: 131.9673
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.22s
                      Time elapsed: 00:32:39
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 45406 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 2.94
          Mean value_function loss: 92.9690
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 63.7864
                       Mean reward: 663.71
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 132.3693
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.16s
                      Time elapsed: 00:32:41
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 45578 steps/s (collection: 2.046s, learning 0.111s)
             Mean action noise std: 2.95
          Mean value_function loss: 94.9480
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.8129
                       Mean reward: 661.38
               Mean episode length: 224.65
    Episode_Reward/reaching_object: 1.2481
    Episode_Reward/rotating_object: 134.4900
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.16s
                      Time elapsed: 00:32:43
                               ETA: 00:23:24

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 46121 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 2.95
          Mean value_function loss: 91.3084
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 63.8395
                       Mean reward: 701.16
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.2311
    Episode_Reward/rotating_object: 133.4020
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.13s
                      Time elapsed: 00:32:45
                               ETA: 00:23:22

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 45596 steps/s (collection: 2.045s, learning 0.111s)
             Mean action noise std: 2.95
          Mean value_function loss: 92.9260
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 63.8645
                       Mean reward: 711.21
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.2508
    Episode_Reward/rotating_object: 134.0501
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.16s
                      Time elapsed: 00:32:48
                               ETA: 00:23:20

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 45271 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 2.96
          Mean value_function loss: 78.1095
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 63.9016
                       Mean reward: 716.75
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 134.8255
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.17s
                      Time elapsed: 00:32:50
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 45766 steps/s (collection: 2.037s, learning 0.111s)
             Mean action noise std: 2.96
          Mean value_function loss: 78.9090
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.9304
                       Mean reward: 724.60
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.2604
    Episode_Reward/rotating_object: 137.8741
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.15s
                      Time elapsed: 00:32:52
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 45017 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 2.96
          Mean value_function loss: 87.4851
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 63.9507
                       Mean reward: 716.82
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 134.3697
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.18s
                      Time elapsed: 00:32:54
                               ETA: 00:23:13

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 45048 steps/s (collection: 2.067s, learning 0.115s)
             Mean action noise std: 2.96
          Mean value_function loss: 92.0819
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 63.9632
                       Mean reward: 723.53
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 1.2674
    Episode_Reward/rotating_object: 135.8437
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.18s
                      Time elapsed: 00:32:56
                               ETA: 00:23:11

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 44568 steps/s (collection: 2.095s, learning 0.111s)
             Mean action noise std: 2.97
          Mean value_function loss: 84.4334
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 63.9886
                       Mean reward: 712.55
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.2705
    Episode_Reward/rotating_object: 139.0298
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.21s
                      Time elapsed: 00:32:58
                               ETA: 00:23:08

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 44113 steps/s (collection: 2.116s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 90.6775
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 64.0186
                       Mean reward: 653.97
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.2462
    Episode_Reward/rotating_object: 132.7556
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.23s
                      Time elapsed: 00:33:01
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 43624 steps/s (collection: 2.140s, learning 0.114s)
             Mean action noise std: 2.97
          Mean value_function loss: 74.7754
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.0317
                       Mean reward: 658.35
               Mean episode length: 228.06
    Episode_Reward/reaching_object: 1.2246
    Episode_Reward/rotating_object: 132.2512
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.25s
                      Time elapsed: 00:33:03
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 44922 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 73.4022
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.0506
                       Mean reward: 656.56
               Mean episode length: 230.81
    Episode_Reward/reaching_object: 1.2655
    Episode_Reward/rotating_object: 137.6938
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.19s
                      Time elapsed: 00:33:05
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 45000 steps/s (collection: 2.069s, learning 0.115s)
             Mean action noise std: 2.98
          Mean value_function loss: 70.1877
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 64.0730
                       Mean reward: 693.57
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.2755
    Episode_Reward/rotating_object: 137.5014
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.18s
                      Time elapsed: 00:33:07
                               ETA: 00:22:59

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 45199 steps/s (collection: 2.059s, learning 0.116s)
             Mean action noise std: 2.98
          Mean value_function loss: 82.4603
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.0959
                       Mean reward: 663.02
               Mean episode length: 229.35
    Episode_Reward/reaching_object: 1.2697
    Episode_Reward/rotating_object: 136.7714
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.17s
                      Time elapsed: 00:33:09
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 44756 steps/s (collection: 2.084s, learning 0.112s)
             Mean action noise std: 2.98
          Mean value_function loss: 89.3098
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.1202
                       Mean reward: 697.57
               Mean episode length: 236.70
    Episode_Reward/reaching_object: 1.2586
    Episode_Reward/rotating_object: 135.3611
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.20s
                      Time elapsed: 00:33:12
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 43623 steps/s (collection: 2.142s, learning 0.111s)
             Mean action noise std: 2.98
          Mean value_function loss: 81.3783
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 64.1453
                       Mean reward: 676.93
               Mean episode length: 229.37
    Episode_Reward/reaching_object: 1.2557
    Episode_Reward/rotating_object: 136.6753
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.25s
                      Time elapsed: 00:33:14
                               ETA: 00:22:52

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 44159 steps/s (collection: 2.113s, learning 0.113s)
             Mean action noise std: 2.99
          Mean value_function loss: 106.1615
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.1679
                       Mean reward: 636.46
               Mean episode length: 219.83
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 132.5618
        Episode_Reward/action_rate: -0.0520
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.23s
                      Time elapsed: 00:33:16
                               ETA: 00:22:50

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 44306 steps/s (collection: 2.105s, learning 0.114s)
             Mean action noise std: 2.99
          Mean value_function loss: 90.4604
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.1961
                       Mean reward: 687.03
               Mean episode length: 230.87
    Episode_Reward/reaching_object: 1.2436
    Episode_Reward/rotating_object: 133.8819
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.22s
                      Time elapsed: 00:33:18
                               ETA: 00:22:48

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 43242 steps/s (collection: 2.162s, learning 0.111s)
             Mean action noise std: 2.99
          Mean value_function loss: 83.3247
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 64.2286
                       Mean reward: 663.80
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 130.9987
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.27s
                      Time elapsed: 00:33:21
                               ETA: 00:22:46

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 44687 steps/s (collection: 2.088s, learning 0.112s)
             Mean action noise std: 3.00
          Mean value_function loss: 76.8892
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 64.2534
                       Mean reward: 724.12
               Mean episode length: 239.37
    Episode_Reward/reaching_object: 1.2707
    Episode_Reward/rotating_object: 139.1112
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.20s
                      Time elapsed: 00:33:23
                               ETA: 00:22:43

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 44829 steps/s (collection: 2.079s, learning 0.114s)
             Mean action noise std: 3.00
          Mean value_function loss: 91.8556
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.2887
                       Mean reward: 710.40
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.2531
    Episode_Reward/rotating_object: 138.4801
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.19s
                      Time elapsed: 00:33:25
                               ETA: 00:22:41

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 45398 steps/s (collection: 2.052s, learning 0.114s)
             Mean action noise std: 3.01
          Mean value_function loss: 82.7415
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 64.3137
                       Mean reward: 666.89
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 136.5833
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.17s
                      Time elapsed: 00:33:27
                               ETA: 00:22:39

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 46167 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.01
          Mean value_function loss: 73.6175
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 64.3336
                       Mean reward: 694.35
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 1.2474
    Episode_Reward/rotating_object: 135.5493
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.13s
                      Time elapsed: 00:33:29
                               ETA: 00:22:37

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 46067 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.9553
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.3568
                       Mean reward: 663.32
               Mean episode length: 227.15
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 134.0880
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.13s
                      Time elapsed: 00:33:31
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 45746 steps/s (collection: 2.036s, learning 0.113s)
             Mean action noise std: 3.01
          Mean value_function loss: 79.2755
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 64.3796
                       Mean reward: 691.55
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.2633
    Episode_Reward/rotating_object: 137.5202
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.15s
                      Time elapsed: 00:33:34
                               ETA: 00:22:32

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 46603 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 3.02
          Mean value_function loss: 84.5268
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 64.4068
                       Mean reward: 652.48
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.2602
    Episode_Reward/rotating_object: 138.1504
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.11s
                      Time elapsed: 00:33:36
                               ETA: 00:22:30

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 45724 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 3.02
          Mean value_function loss: 72.1763
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.4321
                       Mean reward: 701.96
               Mean episode length: 238.58
    Episode_Reward/reaching_object: 1.2742
    Episode_Reward/rotating_object: 137.7567
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.15s
                      Time elapsed: 00:33:38
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 45958 steps/s (collection: 2.026s, learning 0.113s)
             Mean action noise std: 3.02
          Mean value_function loss: 86.6292
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.4652
                       Mean reward: 670.99
               Mean episode length: 229.27
    Episode_Reward/reaching_object: 1.2479
    Episode_Reward/rotating_object: 134.8894
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.14s
                      Time elapsed: 00:33:40
                               ETA: 00:22:25

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 45648 steps/s (collection: 2.040s, learning 0.114s)
             Mean action noise std: 3.03
          Mean value_function loss: 84.3742
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.4967
                       Mean reward: 635.61
               Mean episode length: 223.87
    Episode_Reward/reaching_object: 1.2448
    Episode_Reward/rotating_object: 136.0008
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.15s
                      Time elapsed: 00:33:42
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 44686 steps/s (collection: 2.071s, learning 0.128s)
             Mean action noise std: 3.03
          Mean value_function loss: 83.0725
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 64.5220
                       Mean reward: 735.04
               Mean episode length: 242.06
    Episode_Reward/reaching_object: 1.2530
    Episode_Reward/rotating_object: 140.4809
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.20s
                      Time elapsed: 00:33:44
                               ETA: 00:22:20

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 45710 steps/s (collection: 2.037s, learning 0.114s)
             Mean action noise std: 3.03
          Mean value_function loss: 68.1198
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 64.5416
                       Mean reward: 711.49
               Mean episode length: 238.78
    Episode_Reward/reaching_object: 1.2750
    Episode_Reward/rotating_object: 140.1677
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.15s
                      Time elapsed: 00:33:47
                               ETA: 00:22:18

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 45017 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 3.04
          Mean value_function loss: 77.6654
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.5744
                       Mean reward: 698.00
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 1.2661
    Episode_Reward/rotating_object: 137.3876
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.18s
                      Time elapsed: 00:33:49
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 44652 steps/s (collection: 2.088s, learning 0.113s)
             Mean action noise std: 3.04
          Mean value_function loss: 86.1502
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 64.6077
                       Mean reward: 701.83
               Mean episode length: 236.93
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 135.0386
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.20s
                      Time elapsed: 00:33:51
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 45332 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 3.04
          Mean value_function loss: 80.5745
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 64.6302
                       Mean reward: 686.20
               Mean episode length: 233.05
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 133.7823
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.17s
                      Time elapsed: 00:33:53
                               ETA: 00:22:11

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 45419 steps/s (collection: 2.051s, learning 0.114s)
             Mean action noise std: 3.05
          Mean value_function loss: 80.1237
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 64.6510
                       Mean reward: 677.97
               Mean episode length: 240.79
    Episode_Reward/reaching_object: 1.2674
    Episode_Reward/rotating_object: 134.1436
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.16s
                      Time elapsed: 00:33:55
                               ETA: 00:22:09

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 45133 steps/s (collection: 2.065s, learning 0.113s)
             Mean action noise std: 3.05
          Mean value_function loss: 82.1039
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 64.6805
                       Mean reward: 702.74
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 1.2798
    Episode_Reward/rotating_object: 138.6202
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.18s
                      Time elapsed: 00:33:57
                               ETA: 00:22:07

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 45187 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 3.05
          Mean value_function loss: 77.7585
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 64.7003
                       Mean reward: 681.48
               Mean episode length: 235.12
    Episode_Reward/reaching_object: 1.2660
    Episode_Reward/rotating_object: 135.6462
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.18s
                      Time elapsed: 00:34:00
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 44265 steps/s (collection: 2.109s, learning 0.112s)
             Mean action noise std: 3.06
          Mean value_function loss: 92.7438
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 64.7274
                       Mean reward: 672.41
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 128.8312
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.22s
                      Time elapsed: 00:34:02
                               ETA: 00:22:02

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 44888 steps/s (collection: 2.079s, learning 0.111s)
             Mean action noise std: 3.06
          Mean value_function loss: 87.2601
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 64.7535
                       Mean reward: 667.52
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 1.2624
    Episode_Reward/rotating_object: 134.6207
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.19s
                      Time elapsed: 00:34:04
                               ETA: 00:22:00

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 45273 steps/s (collection: 2.061s, learning 0.111s)
             Mean action noise std: 3.06
          Mean value_function loss: 73.9231
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 64.7772
                       Mean reward: 713.77
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.2830
    Episode_Reward/rotating_object: 139.3240
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.17s
                      Time elapsed: 00:34:06
                               ETA: 00:21:58

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 45698 steps/s (collection: 2.041s, learning 0.111s)
             Mean action noise std: 3.06
          Mean value_function loss: 76.0237
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 64.7963
                       Mean reward: 702.55
               Mean episode length: 241.52
    Episode_Reward/reaching_object: 1.2918
    Episode_Reward/rotating_object: 138.8156
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.15s
                      Time elapsed: 00:34:08
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 44336 steps/s (collection: 2.092s, learning 0.125s)
             Mean action noise std: 3.07
          Mean value_function loss: 76.1409
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 64.8126
                       Mean reward: 628.97
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.2675
    Episode_Reward/rotating_object: 136.1173
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.22s
                      Time elapsed: 00:34:11
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 44586 steps/s (collection: 2.091s, learning 0.114s)
             Mean action noise std: 3.07
          Mean value_function loss: 72.9314
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 64.8396
                       Mean reward: 677.87
               Mean episode length: 240.45
    Episode_Reward/reaching_object: 1.2664
    Episode_Reward/rotating_object: 134.9035
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.20s
                      Time elapsed: 00:34:13
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 45397 steps/s (collection: 2.052s, learning 0.114s)
             Mean action noise std: 3.07
          Mean value_function loss: 92.7480
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 64.8807
                       Mean reward: 710.33
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.2851
    Episode_Reward/rotating_object: 137.5584
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.17s
                      Time elapsed: 00:34:15
                               ETA: 00:21:48

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 45948 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 96.7823
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 64.9095
                       Mean reward: 659.34
               Mean episode length: 236.06
    Episode_Reward/reaching_object: 1.2522
    Episode_Reward/rotating_object: 132.1198
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.14s
                      Time elapsed: 00:34:17
                               ETA: 00:21:46

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 46013 steps/s (collection: 2.026s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 85.4623
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 64.9276
                       Mean reward: 694.87
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.2723
    Episode_Reward/rotating_object: 136.4022
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.14s
                      Time elapsed: 00:34:19
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 46417 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 3.08
          Mean value_function loss: 86.9707
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 64.9568
                       Mean reward: 674.02
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.2703
    Episode_Reward/rotating_object: 134.1108
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.12s
                      Time elapsed: 00:34:21
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 46058 steps/s (collection: 2.024s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 80.0696
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 64.9852
                       Mean reward: 679.62
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.2765
    Episode_Reward/rotating_object: 136.1702
        Episode_Reward/action_rate: -0.0564
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.13s
                      Time elapsed: 00:34:23
                               ETA: 00:21:39

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 46048 steps/s (collection: 2.024s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 101.5211
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.0058
                       Mean reward: 647.03
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 135.2053
        Episode_Reward/action_rate: -0.0556
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.13s
                      Time elapsed: 00:34:26
                               ETA: 00:21:37

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 46088 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 3.09
          Mean value_function loss: 104.5988
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 65.0232
                       Mean reward: 668.10
               Mean episode length: 227.92
    Episode_Reward/reaching_object: 1.2502
    Episode_Reward/rotating_object: 132.2331
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.13s
                      Time elapsed: 00:34:28
                               ETA: 00:21:35

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 46152 steps/s (collection: 2.020s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 95.0204
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.0375
                       Mean reward: 625.81
               Mean episode length: 221.07
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 133.0186
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.13s
                      Time elapsed: 00:34:30
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 45586 steps/s (collection: 2.046s, learning 0.110s)
             Mean action noise std: 3.10
          Mean value_function loss: 88.9521
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 65.0649
                       Mean reward: 623.52
               Mean episode length: 221.73
    Episode_Reward/reaching_object: 1.2413
    Episode_Reward/rotating_object: 133.2856
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.16s
                      Time elapsed: 00:34:32
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 43686 steps/s (collection: 2.139s, learning 0.111s)
             Mean action noise std: 3.10
          Mean value_function loss: 80.5457
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.0988
                       Mean reward: 671.81
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 129.0686
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.25s
                      Time elapsed: 00:34:34
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 45459 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 3.10
          Mean value_function loss: 73.1121
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 65.1216
                       Mean reward: 672.64
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.2588
    Episode_Reward/rotating_object: 135.8824
        Episode_Reward/action_rate: -0.0566
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.16s
                      Time elapsed: 00:34:36
                               ETA: 00:21:26

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 44618 steps/s (collection: 2.091s, learning 0.113s)
             Mean action noise std: 3.11
          Mean value_function loss: 82.7405
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.1420
                       Mean reward: 712.92
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.2784
    Episode_Reward/rotating_object: 136.6883
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.20s
                      Time elapsed: 00:34:39
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 44490 steps/s (collection: 2.094s, learning 0.115s)
             Mean action noise std: 3.11
          Mean value_function loss: 97.4907
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 65.1572
                       Mean reward: 648.00
               Mean episode length: 229.41
    Episode_Reward/reaching_object: 1.2626
    Episode_Reward/rotating_object: 132.5287
        Episode_Reward/action_rate: -0.0574
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.21s
                      Time elapsed: 00:34:41
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 43358 steps/s (collection: 2.153s, learning 0.114s)
             Mean action noise std: 3.11
          Mean value_function loss: 76.5534
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.1752
                       Mean reward: 732.26
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 1.2960
    Episode_Reward/rotating_object: 141.9995
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.27s
                      Time elapsed: 00:34:43
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 43922 steps/s (collection: 2.127s, learning 0.111s)
             Mean action noise std: 3.11
          Mean value_function loss: 77.9861
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.2008
                       Mean reward: 654.59
               Mean episode length: 226.11
    Episode_Reward/reaching_object: 1.2480
    Episode_Reward/rotating_object: 132.4451
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.24s
                      Time elapsed: 00:34:45
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 44608 steps/s (collection: 2.090s, learning 0.114s)
             Mean action noise std: 3.12
          Mean value_function loss: 78.1699
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.2290
                       Mean reward: 670.03
               Mean episode length: 229.88
    Episode_Reward/reaching_object: 1.2751
    Episode_Reward/rotating_object: 138.0228
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.20s
                      Time elapsed: 00:34:48
                               ETA: 00:21:14

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 44817 steps/s (collection: 2.080s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 88.8100
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.2465
                       Mean reward: 633.00
               Mean episode length: 233.48
    Episode_Reward/reaching_object: 1.2429
    Episode_Reward/rotating_object: 132.3446
        Episode_Reward/action_rate: -0.0565
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.19s
                      Time elapsed: 00:34:50
                               ETA: 00:21:12

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 44020 steps/s (collection: 2.120s, learning 0.113s)
             Mean action noise std: 3.12
          Mean value_function loss: 77.3007
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.2605
                       Mean reward: 679.68
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 1.2659
    Episode_Reward/rotating_object: 136.8394
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.23s
                      Time elapsed: 00:34:52
                               ETA: 00:21:10

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 44497 steps/s (collection: 2.098s, learning 0.111s)
             Mean action noise std: 3.13
          Mean value_function loss: 81.1664
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.2881
                       Mean reward: 624.33
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.2516
    Episode_Reward/rotating_object: 133.5789
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.21s
                      Time elapsed: 00:34:54
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 44672 steps/s (collection: 2.088s, learning 0.113s)
             Mean action noise std: 3.13
          Mean value_function loss: 85.1827
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.3146
                       Mean reward: 654.35
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 133.5414
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.20s
                      Time elapsed: 00:34:56
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 44370 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 3.13
          Mean value_function loss: 83.3020
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 65.3336
                       Mean reward: 672.80
               Mean episode length: 231.83
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 135.4821
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.22s
                      Time elapsed: 00:34:59
                               ETA: 00:21:03

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 45229 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 3.13
          Mean value_function loss: 86.1863
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.3467
                       Mean reward: 681.86
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.2645
    Episode_Reward/rotating_object: 136.9794
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.17s
                      Time elapsed: 00:35:01
                               ETA: 00:21:01

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 45156 steps/s (collection: 2.066s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 98.8824
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.3726
                       Mean reward: 692.22
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 1.2655
    Episode_Reward/rotating_object: 137.4033
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.18s
                      Time elapsed: 00:35:03
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 45869 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 77.5135
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.4017
                       Mean reward: 720.86
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 1.2612
    Episode_Reward/rotating_object: 137.6306
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.14s
                      Time elapsed: 00:35:05
                               ETA: 00:20:56

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 45949 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 71.9183
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.4157
                       Mean reward: 696.73
               Mean episode length: 234.08
    Episode_Reward/reaching_object: 1.2699
    Episode_Reward/rotating_object: 138.2094
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.14s
                      Time elapsed: 00:35:07
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 45752 steps/s (collection: 2.038s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 75.5024
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 65.4288
                       Mean reward: 716.99
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 1.2716
    Episode_Reward/rotating_object: 134.7954
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.15s
                      Time elapsed: 00:35:09
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 45997 steps/s (collection: 2.024s, learning 0.113s)
             Mean action noise std: 3.14
          Mean value_function loss: 88.7522
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.4449
                       Mean reward: 737.44
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.2659
    Episode_Reward/rotating_object: 137.1436
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.14s
                      Time elapsed: 00:35:11
                               ETA: 00:20:49

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 45889 steps/s (collection: 2.031s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 102.0016
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 65.4617
                       Mean reward: 692.09
               Mean episode length: 232.24
    Episode_Reward/reaching_object: 1.2430
    Episode_Reward/rotating_object: 134.5004
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.14s
                      Time elapsed: 00:35:14
                               ETA: 00:20:47

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 45775 steps/s (collection: 2.037s, learning 0.111s)
             Mean action noise std: 3.15
          Mean value_function loss: 86.3198
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 65.4840
                       Mean reward: 712.93
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.2448
    Episode_Reward/rotating_object: 133.5620
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.15s
                      Time elapsed: 00:35:16
                               ETA: 00:20:45

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 45454 steps/s (collection: 2.051s, learning 0.112s)
             Mean action noise std: 3.15
          Mean value_function loss: 78.8061
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 65.5125
                       Mean reward: 696.74
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.2646
    Episode_Reward/rotating_object: 133.0101
        Episode_Reward/action_rate: -0.0588
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.16s
                      Time elapsed: 00:35:18
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 43988 steps/s (collection: 2.120s, learning 0.114s)
             Mean action noise std: 3.16
          Mean value_function loss: 89.2064
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.5409
                       Mean reward: 689.05
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.2684
    Episode_Reward/rotating_object: 139.2645
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.23s
                      Time elapsed: 00:35:20
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 44417 steps/s (collection: 2.098s, learning 0.115s)
             Mean action noise std: 3.16
          Mean value_function loss: 82.9217
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.5698
                       Mean reward: 705.02
               Mean episode length: 232.91
    Episode_Reward/reaching_object: 1.2522
    Episode_Reward/rotating_object: 134.1337
        Episode_Reward/action_rate: -0.0585
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.21s
                      Time elapsed: 00:35:22
                               ETA: 00:20:38

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 44847 steps/s (collection: 2.077s, learning 0.115s)
             Mean action noise std: 3.16
          Mean value_function loss: 91.2784
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 65.5938
                       Mean reward: 671.14
               Mean episode length: 232.10
    Episode_Reward/reaching_object: 1.2637
    Episode_Reward/rotating_object: 136.5277
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.19s
                      Time elapsed: 00:35:25
                               ETA: 00:20:36

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 44823 steps/s (collection: 2.079s, learning 0.114s)
             Mean action noise std: 3.17
          Mean value_function loss: 99.3423
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 65.6160
                       Mean reward: 735.09
               Mean episode length: 238.02
    Episode_Reward/reaching_object: 1.2686
    Episode_Reward/rotating_object: 139.9826
        Episode_Reward/action_rate: -0.0595
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.19s
                      Time elapsed: 00:35:27
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 43277 steps/s (collection: 2.157s, learning 0.114s)
             Mean action noise std: 3.17
          Mean value_function loss: 92.6719
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 65.6317
                       Mean reward: 690.69
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 133.1712
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.27s
                      Time elapsed: 00:35:29
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 43454 steps/s (collection: 2.151s, learning 0.111s)
             Mean action noise std: 3.17
          Mean value_function loss: 78.4056
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 65.6448
                       Mean reward: 683.27
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.2704
    Episode_Reward/rotating_object: 136.9413
        Episode_Reward/action_rate: -0.0596
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.26s
                      Time elapsed: 00:35:31
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 44135 steps/s (collection: 2.114s, learning 0.113s)
             Mean action noise std: 3.17
          Mean value_function loss: 85.7067
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 65.6653
                       Mean reward: 700.97
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.2642
    Episode_Reward/rotating_object: 134.7905
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.23s
                      Time elapsed: 00:35:34
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 44063 steps/s (collection: 2.106s, learning 0.125s)
             Mean action noise std: 3.17
          Mean value_function loss: 89.9234
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 65.6903
                       Mean reward: 658.24
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 131.5433
        Episode_Reward/action_rate: -0.0598
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.23s
                      Time elapsed: 00:35:36
                               ETA: 00:20:24

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 44675 steps/s (collection: 2.082s, learning 0.118s)
             Mean action noise std: 3.18
          Mean value_function loss: 69.5662
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 65.7035
                       Mean reward: 724.92
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 1.2647
    Episode_Reward/rotating_object: 139.2036
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.20s
                      Time elapsed: 00:35:38
                               ETA: 00:20:22

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 44988 steps/s (collection: 2.070s, learning 0.115s)
             Mean action noise std: 3.18
          Mean value_function loss: 74.4942
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 65.7209
                       Mean reward: 706.76
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.2913
    Episode_Reward/rotating_object: 141.1243
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.19s
                      Time elapsed: 00:35:40
                               ETA: 00:20:20

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 45409 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 3.18
          Mean value_function loss: 76.7901
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 65.7457
                       Mean reward: 704.43
               Mean episode length: 234.56
    Episode_Reward/reaching_object: 1.2677
    Episode_Reward/rotating_object: 134.4323
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.16s
                      Time elapsed: 00:35:42
                               ETA: 00:20:18

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 45137 steps/s (collection: 2.065s, learning 0.113s)
             Mean action noise std: 3.19
          Mean value_function loss: 85.7976
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.7654
                       Mean reward: 710.62
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 1.2574
    Episode_Reward/rotating_object: 137.7683
        Episode_Reward/action_rate: -0.0602
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.18s
                      Time elapsed: 00:35:44
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 45242 steps/s (collection: 2.058s, learning 0.115s)
             Mean action noise std: 3.19
          Mean value_function loss: 80.5412
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.7922
                       Mean reward: 698.31
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 135.8723
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.17s
                      Time elapsed: 00:35:47
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 44802 steps/s (collection: 2.081s, learning 0.113s)
             Mean action noise std: 3.19
          Mean value_function loss: 79.4576
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 65.8152
                       Mean reward: 667.83
               Mean episode length: 226.85
    Episode_Reward/reaching_object: 1.2552
    Episode_Reward/rotating_object: 139.1167
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.19s
                      Time elapsed: 00:35:49
                               ETA: 00:20:11

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 45304 steps/s (collection: 2.057s, learning 0.113s)
             Mean action noise std: 3.19
          Mean value_function loss: 95.7138
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.8345
                       Mean reward: 729.08
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 135.9480
        Episode_Reward/action_rate: -0.0599
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.17s
                      Time elapsed: 00:35:51
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 45260 steps/s (collection: 2.061s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 79.8297
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 65.8531
                       Mean reward: 686.51
               Mean episode length: 242.54
    Episode_Reward/reaching_object: 1.2724
    Episode_Reward/rotating_object: 138.0381
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.17s
                      Time elapsed: 00:35:53
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 46105 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 91.7649
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 65.8704
                       Mean reward: 717.69
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.2458
    Episode_Reward/rotating_object: 138.1189
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.13s
                      Time elapsed: 00:35:55
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 45704 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 87.0107
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.8910
                       Mean reward: 688.74
               Mean episode length: 233.38
    Episode_Reward/reaching_object: 1.2427
    Episode_Reward/rotating_object: 134.5112
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.15s
                      Time elapsed: 00:35:57
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 46014 steps/s (collection: 2.025s, learning 0.111s)
             Mean action noise std: 3.21
          Mean value_function loss: 88.7310
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 65.9178
                       Mean reward: 682.86
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 1.2431
    Episode_Reward/rotating_object: 134.8868
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.14s
                      Time elapsed: 00:36:00
                               ETA: 00:19:59

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 46179 steps/s (collection: 2.017s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 82.5369
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 65.9415
                       Mean reward: 711.93
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.2701
    Episode_Reward/rotating_object: 141.3912
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.13s
                      Time elapsed: 00:36:02
                               ETA: 00:19:57

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 45570 steps/s (collection: 2.045s, learning 0.112s)
             Mean action noise std: 3.21
          Mean value_function loss: 86.5121
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 65.9653
                       Mean reward: 697.83
               Mean episode length: 236.37
    Episode_Reward/reaching_object: 1.2283
    Episode_Reward/rotating_object: 133.1630
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.16s
                      Time elapsed: 00:36:04
                               ETA: 00:19:55

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 45670 steps/s (collection: 2.041s, learning 0.111s)
             Mean action noise std: 3.21
          Mean value_function loss: 83.4394
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 65.9894
                       Mean reward: 654.96
               Mean episode length: 233.07
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 133.6620
        Episode_Reward/action_rate: -0.0612
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.15s
                      Time elapsed: 00:36:06
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 44325 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 3.22
          Mean value_function loss: 84.2865
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.0052
                       Mean reward: 672.14
               Mean episode length: 230.20
    Episode_Reward/reaching_object: 1.2493
    Episode_Reward/rotating_object: 137.0296
        Episode_Reward/action_rate: -0.0614
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.22s
                      Time elapsed: 00:36:08
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 45484 steps/s (collection: 2.047s, learning 0.115s)
             Mean action noise std: 3.22
          Mean value_function loss: 81.7736
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 66.0207
                       Mean reward: 660.12
               Mean episode length: 231.77
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 133.1568
        Episode_Reward/action_rate: -0.0609
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.16s
                      Time elapsed: 00:36:10
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 44921 steps/s (collection: 2.073s, learning 0.115s)
             Mean action noise std: 3.22
          Mean value_function loss: 72.6489
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 66.0364
                       Mean reward: 656.53
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 1.2441
    Episode_Reward/rotating_object: 131.8752
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.19s
                      Time elapsed: 00:36:13
                               ETA: 00:19:46

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 44304 steps/s (collection: 2.105s, learning 0.114s)
             Mean action noise std: 3.22
          Mean value_function loss: 91.5747
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 66.0478
                       Mean reward: 680.75
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.2533
    Episode_Reward/rotating_object: 137.4905
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.22s
                      Time elapsed: 00:36:15
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 44011 steps/s (collection: 2.121s, learning 0.113s)
             Mean action noise std: 3.23
          Mean value_function loss: 73.7872
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.0621
                       Mean reward: 674.09
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.2768
    Episode_Reward/rotating_object: 139.6661
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.23s
                      Time elapsed: 00:36:17
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 44347 steps/s (collection: 2.103s, learning 0.114s)
             Mean action noise std: 3.23
          Mean value_function loss: 76.6297
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.0832
                       Mean reward: 648.97
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.2681
    Episode_Reward/rotating_object: 137.6875
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.22s
                      Time elapsed: 00:36:19
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 45042 steps/s (collection: 2.071s, learning 0.112s)
             Mean action noise std: 3.23
          Mean value_function loss: 82.1084
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 66.1028
                       Mean reward: 637.18
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.2400
    Episode_Reward/rotating_object: 134.5585
        Episode_Reward/action_rate: -0.0613
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.18s
                      Time elapsed: 00:36:21
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 45078 steps/s (collection: 2.067s, learning 0.114s)
             Mean action noise std: 3.23
          Mean value_function loss: 82.5404
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 66.1239
                       Mean reward: 675.46
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 135.5118
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.18s
                      Time elapsed: 00:36:24
                               ETA: 00:19:34

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 45184 steps/s (collection: 2.062s, learning 0.114s)
             Mean action noise std: 3.23
          Mean value_function loss: 93.0486
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 66.1383
                       Mean reward: 686.66
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.2304
    Episode_Reward/rotating_object: 133.3000
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.18s
                      Time elapsed: 00:36:26
                               ETA: 00:19:32

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 45142 steps/s (collection: 2.064s, learning 0.114s)
             Mean action noise std: 3.24
          Mean value_function loss: 70.4315
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.1551
                       Mean reward: 673.41
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.2486
    Episode_Reward/rotating_object: 138.2563
        Episode_Reward/action_rate: -0.0625
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.18s
                      Time elapsed: 00:36:28
                               ETA: 00:19:30

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 45123 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 3.24
          Mean value_function loss: 70.5636
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.1734
                       Mean reward: 719.16
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 1.2615
    Episode_Reward/rotating_object: 140.8037
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.18s
                      Time elapsed: 00:36:30
                               ETA: 00:19:28

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 45075 steps/s (collection: 2.070s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 66.3552
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.1913
                       Mean reward: 678.79
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 140.2896
        Episode_Reward/action_rate: -0.0628
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.18s
                      Time elapsed: 00:36:32
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 45271 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 3.24
          Mean value_function loss: 80.1741
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.2108
                       Mean reward: 721.76
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.2537
    Episode_Reward/rotating_object: 140.0296
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.17s
                      Time elapsed: 00:36:35
                               ETA: 00:19:23

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 45215 steps/s (collection: 2.062s, learning 0.112s)
             Mean action noise std: 3.25
          Mean value_function loss: 81.0109
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 66.2271
                       Mean reward: 682.40
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 133.6675
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.17s
                      Time elapsed: 00:36:37
                               ETA: 00:19:21

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 44711 steps/s (collection: 2.086s, learning 0.113s)
             Mean action noise std: 3.25
          Mean value_function loss: 84.8258
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.2443
                       Mean reward: 686.39
               Mean episode length: 234.52
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 140.2359
        Episode_Reward/action_rate: -0.0633
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.20s
                      Time elapsed: 00:36:39
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 45150 steps/s (collection: 2.066s, learning 0.111s)
             Mean action noise std: 3.25
          Mean value_function loss: 72.0789
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.2706
                       Mean reward: 696.44
               Mean episode length: 239.11
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 140.2178
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.18s
                      Time elapsed: 00:36:41
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 45804 steps/s (collection: 2.035s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 67.2997
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 66.2961
                       Mean reward: 722.74
               Mean episode length: 235.01
    Episode_Reward/reaching_object: 1.2412
    Episode_Reward/rotating_object: 138.7463
        Episode_Reward/action_rate: -0.0629
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.15s
                      Time elapsed: 00:36:43
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 46568 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 67.5447
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.3206
                       Mean reward: 693.85
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.2458
    Episode_Reward/rotating_object: 137.1415
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.11s
                      Time elapsed: 00:36:45
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 46245 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 3.26
          Mean value_function loss: 78.4196
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.3497
                       Mean reward: 729.96
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.2257
    Episode_Reward/rotating_object: 137.4080
        Episode_Reward/action_rate: -0.0623
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.13s
                      Time elapsed: 00:36:47
                               ETA: 00:19:09

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 46446 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 80.3156
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 66.3784
                       Mean reward: 715.78
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 135.9062
        Episode_Reward/action_rate: -0.0622
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.12s
                      Time elapsed: 00:36:50
                               ETA: 00:19:07

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 46268 steps/s (collection: 2.011s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 89.6080
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 66.3977
                       Mean reward: 711.25
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.2217
    Episode_Reward/rotating_object: 135.1468
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.12s
                      Time elapsed: 00:36:52
                               ETA: 00:19:05

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 45919 steps/s (collection: 2.030s, learning 0.111s)
             Mean action noise std: 3.27
          Mean value_function loss: 80.7880
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.4164
                       Mean reward: 683.03
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.2381
    Episode_Reward/rotating_object: 137.2945
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.14s
                      Time elapsed: 00:36:54
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 46108 steps/s (collection: 2.018s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 88.6946
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 66.4392
                       Mean reward: 700.35
               Mean episode length: 235.13
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 134.8223
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.13s
                      Time elapsed: 00:36:56
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 45172 steps/s (collection: 2.061s, learning 0.115s)
             Mean action noise std: 3.28
          Mean value_function loss: 77.3793
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.4641
                       Mean reward: 669.95
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 1.2277
    Episode_Reward/rotating_object: 134.8934
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.18s
                      Time elapsed: 00:36:58
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 45016 steps/s (collection: 2.070s, learning 0.114s)
             Mean action noise std: 3.28
          Mean value_function loss: 83.5001
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.4947
                       Mean reward: 710.45
               Mean episode length: 232.87
    Episode_Reward/reaching_object: 1.2475
    Episode_Reward/rotating_object: 142.2353
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.18s
                      Time elapsed: 00:37:00
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 45342 steps/s (collection: 2.054s, learning 0.114s)
             Mean action noise std: 3.28
          Mean value_function loss: 85.2673
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.5228
                       Mean reward: 716.98
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 139.4623
        Episode_Reward/action_rate: -0.0645
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.17s
                      Time elapsed: 00:37:03
                               ETA: 00:18:53

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 45162 steps/s (collection: 2.063s, learning 0.114s)
             Mean action noise std: 3.29
          Mean value_function loss: 94.2472
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 66.5418
                       Mean reward: 700.63
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.2202
    Episode_Reward/rotating_object: 136.8499
        Episode_Reward/action_rate: -0.0630
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.18s
                      Time elapsed: 00:37:05
                               ETA: 00:18:51

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 44398 steps/s (collection: 2.101s, learning 0.113s)
             Mean action noise std: 3.29
          Mean value_function loss: 96.3319
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 66.5585
                       Mean reward: 676.76
               Mean episode length: 227.61
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 137.6412
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.21s
                      Time elapsed: 00:37:07
                               ETA: 00:18:49

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 44217 steps/s (collection: 2.112s, learning 0.111s)
             Mean action noise std: 3.29
          Mean value_function loss: 83.9008
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.5892
                       Mean reward: 683.92
               Mean episode length: 235.70
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 135.4382
        Episode_Reward/action_rate: -0.0641
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.22s
                      Time elapsed: 00:37:09
                               ETA: 00:18:47

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 45431 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 3.30
          Mean value_function loss: 70.7170
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.6211
                       Mean reward: 729.64
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.2415
    Episode_Reward/rotating_object: 135.9430
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.16s
                      Time elapsed: 00:37:11
                               ETA: 00:18:44

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 45411 steps/s (collection: 2.053s, learning 0.112s)
             Mean action noise std: 3.30
          Mean value_function loss: 70.6691
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.6403
                       Mean reward: 716.57
               Mean episode length: 239.02
    Episode_Reward/reaching_object: 1.2526
    Episode_Reward/rotating_object: 140.8740
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.16s
                      Time elapsed: 00:37:13
                               ETA: 00:18:42

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 45319 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 3.30
          Mean value_function loss: 90.1693
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.6535
                       Mean reward: 684.77
               Mean episode length: 229.84
    Episode_Reward/reaching_object: 1.2171
    Episode_Reward/rotating_object: 137.7266
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.17s
                      Time elapsed: 00:37:16
                               ETA: 00:18:40

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 45412 steps/s (collection: 2.052s, learning 0.112s)
             Mean action noise std: 3.30
          Mean value_function loss: 83.0493
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 66.6699
                       Mean reward: 692.12
               Mean episode length: 231.56
    Episode_Reward/reaching_object: 1.2183
    Episode_Reward/rotating_object: 134.0627
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 2.16s
                      Time elapsed: 00:37:18
                               ETA: 00:18:38

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 45025 steps/s (collection: 2.073s, learning 0.111s)
             Mean action noise std: 3.31
          Mean value_function loss: 76.7654
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 66.6938
                       Mean reward: 676.42
               Mean episode length: 237.34
    Episode_Reward/reaching_object: 1.2359
    Episode_Reward/rotating_object: 137.0529
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 2.18s
                      Time elapsed: 00:37:20
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 45008 steps/s (collection: 2.069s, learning 0.115s)
             Mean action noise std: 3.31
          Mean value_function loss: 79.5820
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 66.7169
                       Mean reward: 689.08
               Mean episode length: 228.97
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 136.2706
        Episode_Reward/action_rate: -0.0646
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 2.18s
                      Time elapsed: 00:37:22
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 45369 steps/s (collection: 2.052s, learning 0.115s)
             Mean action noise std: 3.31
          Mean value_function loss: 84.5282
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 66.7442
                       Mean reward: 657.83
               Mean episode length: 234.57
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 137.8631
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 2.17s
                      Time elapsed: 00:37:24
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 44970 steps/s (collection: 2.070s, learning 0.116s)
             Mean action noise std: 3.32
          Mean value_function loss: 93.7519
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.7685
                       Mean reward: 624.32
               Mean episode length: 233.20
    Episode_Reward/reaching_object: 1.2340
    Episode_Reward/rotating_object: 134.6058
        Episode_Reward/action_rate: -0.0652
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 2.19s
                      Time elapsed: 00:37:27
                               ETA: 00:18:28

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 44905 steps/s (collection: 2.074s, learning 0.115s)
             Mean action noise std: 3.32
          Mean value_function loss: 82.0750
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 66.7931
                       Mean reward: 706.64
               Mean episode length: 237.41
    Episode_Reward/reaching_object: 1.2405
    Episode_Reward/rotating_object: 136.4557
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 2.19s
                      Time elapsed: 00:37:29
                               ETA: 00:18:26

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 45911 steps/s (collection: 2.031s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 87.4584
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.8094
                       Mean reward: 676.32
               Mean episode length: 231.29
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 135.4468
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 2.14s
                      Time elapsed: 00:37:31
                               ETA: 00:18:24

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 46310 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 3.32
          Mean value_function loss: 69.3847
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.8257
                       Mean reward: 720.24
               Mean episode length: 237.81
    Episode_Reward/reaching_object: 1.2495
    Episode_Reward/rotating_object: 141.4172
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 2.12s
                      Time elapsed: 00:37:33
                               ETA: 00:18:22

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 46151 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 3.33
          Mean value_function loss: 86.3362
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.8418
                       Mean reward: 688.35
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 131.1749
        Episode_Reward/action_rate: -0.0644
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 2.13s
                      Time elapsed: 00:37:35
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 46269 steps/s (collection: 2.014s, learning 0.111s)
             Mean action noise std: 3.33
          Mean value_function loss: 79.8671
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.8606
                       Mean reward: 675.11
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 1.2176
    Episode_Reward/rotating_object: 134.0641
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 2.12s
                      Time elapsed: 00:37:37
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 45876 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 3.33
          Mean value_function loss: 73.0473
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 66.8882
                       Mean reward: 757.93
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 1.2627
    Episode_Reward/rotating_object: 142.1654
        Episode_Reward/action_rate: -0.0669
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.14s
                      Time elapsed: 00:37:39
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 46181 steps/s (collection: 2.017s, learning 0.112s)
             Mean action noise std: 3.34
          Mean value_function loss: 77.7425
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.9207
                       Mean reward: 688.25
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 140.0380
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.13s
                      Time elapsed: 00:37:41
                               ETA: 00:18:12

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 46157 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 3.34
          Mean value_function loss: 88.5963
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 66.9388
                       Mean reward: 717.21
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.2618
    Episode_Reward/rotating_object: 140.9561
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.13s
                      Time elapsed: 00:37:44
                               ETA: 00:18:10

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 45567 steps/s (collection: 2.044s, learning 0.113s)
             Mean action noise std: 3.34
          Mean value_function loss: 79.0894
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 66.9557
                       Mean reward: 674.80
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 132.5207
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 2.16s
                      Time elapsed: 00:37:46
                               ETA: 00:18:08

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 44985 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 3.34
          Mean value_function loss: 84.3644
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 66.9707
                       Mean reward: 694.43
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 1.2695
    Episode_Reward/rotating_object: 141.6168
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.19s
                      Time elapsed: 00:37:48
                               ETA: 00:18:06

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 44830 steps/s (collection: 2.077s, learning 0.116s)
             Mean action noise std: 3.35
          Mean value_function loss: 80.2086
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.9951
                       Mean reward: 674.10
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 1.2172
    Episode_Reward/rotating_object: 132.0794
        Episode_Reward/action_rate: -0.0653
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.19s
                      Time elapsed: 00:37:50
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 44187 steps/s (collection: 2.100s, learning 0.125s)
             Mean action noise std: 3.35
          Mean value_function loss: 71.2223
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.0246
                       Mean reward: 676.00
               Mean episode length: 229.26
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 135.5923
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.22s
                      Time elapsed: 00:37:52
                               ETA: 00:18:01

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 42662 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 3.35
          Mean value_function loss: 65.8916
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.0447
                       Mean reward: 695.95
               Mean episode length: 236.82
    Episode_Reward/reaching_object: 1.2547
    Episode_Reward/rotating_object: 140.1533
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.30s
                      Time elapsed: 00:37:55
                               ETA: 00:17:59

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 42750 steps/s (collection: 2.185s, learning 0.115s)
             Mean action noise std: 3.36
          Mean value_function loss: 76.6648
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 67.0675
                       Mean reward: 669.72
               Mean episode length: 232.65
    Episode_Reward/reaching_object: 1.2394
    Episode_Reward/rotating_object: 134.8416
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.30s
                      Time elapsed: 00:37:57
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 44469 steps/s (collection: 2.084s, learning 0.126s)
             Mean action noise std: 3.36
          Mean value_function loss: 79.6625
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.0963
                       Mean reward: 686.93
               Mean episode length: 231.02
    Episode_Reward/reaching_object: 1.2383
    Episode_Reward/rotating_object: 139.0143
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.21s
                      Time elapsed: 00:37:59
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 43853 steps/s (collection: 2.101s, learning 0.140s)
             Mean action noise std: 3.36
          Mean value_function loss: 84.2880
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.1162
                       Mean reward: 687.77
               Mean episode length: 232.12
    Episode_Reward/reaching_object: 1.2038
    Episode_Reward/rotating_object: 133.1272
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 2.24s
                      Time elapsed: 00:38:01
                               ETA: 00:17:52

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 45502 steps/s (collection: 2.046s, learning 0.114s)
             Mean action noise std: 3.36
          Mean value_function loss: 85.8958
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 67.1397
                       Mean reward: 670.33
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.2027
    Episode_Reward/rotating_object: 131.0298
        Episode_Reward/action_rate: -0.0655
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 2.16s
                      Time elapsed: 00:38:04
                               ETA: 00:17:50

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 45370 steps/s (collection: 2.040s, learning 0.127s)
             Mean action noise std: 3.37
          Mean value_function loss: 76.0399
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 67.1594
                       Mean reward: 703.84
               Mean episode length: 237.19
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 138.1993
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 2.17s
                      Time elapsed: 00:38:06
                               ETA: 00:17:48

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 45497 steps/s (collection: 2.047s, learning 0.113s)
             Mean action noise std: 3.37
          Mean value_function loss: 72.1792
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 67.1768
                       Mean reward: 695.40
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.2181
    Episode_Reward/rotating_object: 134.8968
        Episode_Reward/action_rate: -0.0665
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.16s
                      Time elapsed: 00:38:08
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 45513 steps/s (collection: 2.046s, learning 0.114s)
             Mean action noise std: 3.37
          Mean value_function loss: 85.3475
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.1977
                       Mean reward: 716.68
               Mean episode length: 238.89
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 138.6509
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 2.16s
                      Time elapsed: 00:38:10
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 45039 steps/s (collection: 2.068s, learning 0.114s)
             Mean action noise std: 3.37
          Mean value_function loss: 59.3127
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 67.2155
                       Mean reward: 698.35
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 1.2767
    Episode_Reward/rotating_object: 142.2411
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 2.18s
                      Time elapsed: 00:38:12
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 43797 steps/s (collection: 2.134s, learning 0.111s)
             Mean action noise std: 3.38
          Mean value_function loss: 80.9427
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.2341
                       Mean reward: 702.91
               Mean episode length: 233.02
    Episode_Reward/reaching_object: 1.2469
    Episode_Reward/rotating_object: 139.0496
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.24s
                      Time elapsed: 00:38:15
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 45181 steps/s (collection: 2.058s, learning 0.118s)
             Mean action noise std: 3.38
          Mean value_function loss: 71.6758
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 67.2580
                       Mean reward: 655.75
               Mean episode length: 228.88
    Episode_Reward/reaching_object: 1.2489
    Episode_Reward/rotating_object: 137.0828
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.18s
                      Time elapsed: 00:38:17
                               ETA: 00:17:36

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 45952 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 3.38
          Mean value_function loss: 79.6831
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.2812
                       Mean reward: 737.73
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 141.2970
        Episode_Reward/action_rate: -0.0680
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.14s
                      Time elapsed: 00:38:19
                               ETA: 00:17:34

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 46129 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 68.3562
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 67.3022
                       Mean reward: 733.68
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 1.2595
    Episode_Reward/rotating_object: 141.3192
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.13s
                      Time elapsed: 00:38:21
                               ETA: 00:17:32

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 46097 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 3.39
          Mean value_function loss: 79.8359
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.3199
                       Mean reward: 695.24
               Mean episode length: 237.56
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 133.8531
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.13s
                      Time elapsed: 00:38:23
                               ETA: 00:17:30

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 46025 steps/s (collection: 2.026s, learning 0.110s)
             Mean action noise std: 3.39
          Mean value_function loss: 81.3317
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.3442
                       Mean reward: 730.18
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2682
    Episode_Reward/rotating_object: 141.2396
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.14s
                      Time elapsed: 00:38:25
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 45834 steps/s (collection: 2.034s, learning 0.110s)
             Mean action noise std: 3.40
          Mean value_function loss: 83.1440
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.3685
                       Mean reward: 664.76
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 1.2498
    Episode_Reward/rotating_object: 137.1345
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.14s
                      Time elapsed: 00:38:27
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 45702 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 3.40
          Mean value_function loss: 87.7008
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 67.3886
                       Mean reward: 700.58
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 138.5739
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 2.15s
                      Time elapsed: 00:38:30
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 45019 steps/s (collection: 2.070s, learning 0.114s)
             Mean action noise std: 3.40
          Mean value_function loss: 75.0787
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 67.4030
                       Mean reward: 696.38
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.2315
    Episode_Reward/rotating_object: 136.9493
        Episode_Reward/action_rate: -0.0679
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.18s
                      Time elapsed: 00:38:32
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 43192 steps/s (collection: 2.162s, learning 0.114s)
             Mean action noise std: 3.40
          Mean value_function loss: 86.8712
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.4136
                       Mean reward: 662.42
               Mean episode length: 233.78
    Episode_Reward/reaching_object: 1.2613
    Episode_Reward/rotating_object: 137.8886
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.28s
                      Time elapsed: 00:38:34
                               ETA: 00:17:18

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 45466 steps/s (collection: 2.048s, learning 0.114s)
             Mean action noise std: 3.41
          Mean value_function loss: 87.4240
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.4432
                       Mean reward: 711.26
               Mean episode length: 235.29
    Episode_Reward/reaching_object: 1.2581
    Episode_Reward/rotating_object: 139.8013
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.16s
                      Time elapsed: 00:38:36
                               ETA: 00:17:16

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 44904 steps/s (collection: 2.076s, learning 0.113s)
             Mean action noise std: 3.41
          Mean value_function loss: 75.4761
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.4650
                       Mean reward: 711.97
               Mean episode length: 237.38
    Episode_Reward/reaching_object: 1.2512
    Episode_Reward/rotating_object: 140.2478
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.19s
                      Time elapsed: 00:38:38
                               ETA: 00:17:14

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 45650 steps/s (collection: 2.040s, learning 0.114s)
             Mean action noise std: 3.41
          Mean value_function loss: 83.8313
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 67.4837
                       Mean reward: 667.24
               Mean episode length: 227.51
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 134.8098
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.15s
                      Time elapsed: 00:38:40
                               ETA: 00:17:12

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 44621 steps/s (collection: 2.088s, learning 0.116s)
             Mean action noise std: 3.42
          Mean value_function loss: 79.9908
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.5031
                       Mean reward: 666.97
               Mean episode length: 228.35
    Episode_Reward/reaching_object: 1.2380
    Episode_Reward/rotating_object: 136.5995
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 2.20s
                      Time elapsed: 00:38:43
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 45298 steps/s (collection: 2.056s, learning 0.114s)
             Mean action noise std: 3.42
          Mean value_function loss: 75.8504
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.5143
                       Mean reward: 681.47
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.2296
    Episode_Reward/rotating_object: 134.2273
        Episode_Reward/action_rate: -0.0687
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.17s
                      Time elapsed: 00:38:45
                               ETA: 00:17:07

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 44757 steps/s (collection: 2.082s, learning 0.114s)
             Mean action noise std: 3.42
          Mean value_function loss: 84.1494
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.5270
                       Mean reward: 712.51
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 140.1213
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.20s
                      Time elapsed: 00:38:47
                               ETA: 00:17:05

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 45183 steps/s (collection: 2.061s, learning 0.114s)
             Mean action noise std: 3.42
          Mean value_function loss: 76.2756
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 67.5504
                       Mean reward: 689.44
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 136.4225
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 2.18s
                      Time elapsed: 00:38:49
                               ETA: 00:17:03

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 45375 steps/s (collection: 2.053s, learning 0.113s)
             Mean action noise std: 3.43
          Mean value_function loss: 87.5256
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.5754
                       Mean reward: 722.90
               Mean episode length: 235.63
    Episode_Reward/reaching_object: 1.2483
    Episode_Reward/rotating_object: 140.2990
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.17s
                      Time elapsed: 00:38:51
                               ETA: 00:17:00

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 45088 steps/s (collection: 2.065s, learning 0.115s)
             Mean action noise std: 3.43
          Mean value_function loss: 81.4781
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.5898
                       Mean reward: 699.89
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.2418
    Episode_Reward/rotating_object: 135.0241
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 2.18s
                      Time elapsed: 00:38:54
                               ETA: 00:16:58

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 45329 steps/s (collection: 2.050s, learning 0.118s)
             Mean action noise std: 3.43
          Mean value_function loss: 94.5325
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.6021
                       Mean reward: 720.70
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 136.5343
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.17s
                      Time elapsed: 00:38:56
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 44258 steps/s (collection: 2.108s, learning 0.113s)
             Mean action noise std: 3.43
          Mean value_function loss: 80.4019
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.6162
                       Mean reward: 692.77
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 138.9421
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.22s
                      Time elapsed: 00:38:58
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 45113 steps/s (collection: 2.065s, learning 0.114s)
             Mean action noise std: 3.43
          Mean value_function loss: 90.4728
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.6330
                       Mean reward: 728.68
               Mean episode length: 245.09
    Episode_Reward/reaching_object: 1.2517
    Episode_Reward/rotating_object: 139.0626
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 2.18s
                      Time elapsed: 00:39:00
                               ETA: 00:16:51

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 44894 steps/s (collection: 2.077s, learning 0.112s)
             Mean action noise std: 3.44
          Mean value_function loss: 89.8776
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.6496
                       Mean reward: 691.89
               Mean episode length: 237.44
    Episode_Reward/reaching_object: 1.2567
    Episode_Reward/rotating_object: 140.0378
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 2.19s
                      Time elapsed: 00:39:02
                               ETA: 00:16:49

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 45090 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 3.44
          Mean value_function loss: 83.4477
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 67.6605
                       Mean reward: 665.71
               Mean episode length: 230.37
    Episode_Reward/reaching_object: 1.2451
    Episode_Reward/rotating_object: 135.7994
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 2.18s
                      Time elapsed: 00:39:05
                               ETA: 00:16:47

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 44228 steps/s (collection: 2.112s, learning 0.110s)
             Mean action noise std: 3.44
          Mean value_function loss: 67.5846
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 67.6707
                       Mean reward: 706.51
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 1.2565
    Episode_Reward/rotating_object: 140.2305
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 2.22s
                      Time elapsed: 00:39:07
                               ETA: 00:16:45

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 45568 steps/s (collection: 2.047s, learning 0.111s)
             Mean action noise std: 3.44
          Mean value_function loss: 94.8794
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 67.6836
                       Mean reward: 622.41
               Mean episode length: 218.02
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 132.9096
        Episode_Reward/action_rate: -0.0690
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.16s
                      Time elapsed: 00:39:09
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 46197 steps/s (collection: 2.017s, learning 0.111s)
             Mean action noise std: 3.44
          Mean value_function loss: 78.7538
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.7025
                       Mean reward: 644.73
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 138.3427
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 2.13s
                      Time elapsed: 00:39:11
                               ETA: 00:16:40

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 45396 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 3.45
          Mean value_function loss: 88.4994
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.7210
                       Mean reward: 678.25
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 1.2272
    Episode_Reward/rotating_object: 135.2451
        Episode_Reward/action_rate: -0.0696
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.17s
                      Time elapsed: 00:39:13
                               ETA: 00:16:38

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 45605 steps/s (collection: 2.045s, learning 0.111s)
             Mean action noise std: 3.45
          Mean value_function loss: 85.9377
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 67.7360
                       Mean reward: 681.05
               Mean episode length: 228.42
    Episode_Reward/reaching_object: 1.2486
    Episode_Reward/rotating_object: 138.9503
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 2.16s
                      Time elapsed: 00:39:15
                               ETA: 00:16:35

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 46091 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 3.45
          Mean value_function loss: 78.5594
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 67.7600
                       Mean reward: 656.43
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.2605
    Episode_Reward/rotating_object: 139.5970
        Episode_Reward/action_rate: -0.0714
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.13s
                      Time elapsed: 00:39:17
                               ETA: 00:16:33

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 46056 steps/s (collection: 2.024s, learning 0.111s)
             Mean action noise std: 3.46
          Mean value_function loss: 81.2997
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.7842
                       Mean reward: 641.12
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 1.2449
    Episode_Reward/rotating_object: 135.1243
        Episode_Reward/action_rate: -0.0711
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.13s
                      Time elapsed: 00:39:20
                               ETA: 00:16:31

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 44722 steps/s (collection: 2.070s, learning 0.128s)
             Mean action noise std: 3.46
          Mean value_function loss: 80.4210
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.8007
                       Mean reward: 689.95
               Mean episode length: 239.85
    Episode_Reward/reaching_object: 1.2553
    Episode_Reward/rotating_object: 139.9830
        Episode_Reward/action_rate: -0.0717
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.20s
                      Time elapsed: 00:39:22
                               ETA: 00:16:29

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 45072 steps/s (collection: 2.070s, learning 0.111s)
             Mean action noise std: 3.46
          Mean value_function loss: 66.4533
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 67.8214
                       Mean reward: 686.19
               Mean episode length: 231.55
    Episode_Reward/reaching_object: 1.2392
    Episode_Reward/rotating_object: 136.1731
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.18s
                      Time elapsed: 00:39:24
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 44085 steps/s (collection: 2.119s, learning 0.110s)
             Mean action noise std: 3.46
          Mean value_function loss: 77.8911
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 67.8480
                       Mean reward: 732.42
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 1.2470
    Episode_Reward/rotating_object: 139.5695
        Episode_Reward/action_rate: -0.0713
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.23s
                      Time elapsed: 00:39:26
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 42327 steps/s (collection: 2.210s, learning 0.112s)
             Mean action noise std: 3.47
          Mean value_function loss: 68.3341
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.8643
                       Mean reward: 700.00
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.2121
    Episode_Reward/rotating_object: 132.5656
        Episode_Reward/action_rate: -0.0699
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.32s
                      Time elapsed: 00:39:29
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 44790 steps/s (collection: 2.084s, learning 0.111s)
             Mean action noise std: 3.47
          Mean value_function loss: 52.4731
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.8785
                       Mean reward: 707.82
               Mean episode length: 238.83
    Episode_Reward/reaching_object: 1.2666
    Episode_Reward/rotating_object: 141.4294
        Episode_Reward/action_rate: -0.0731
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 2.19s
                      Time elapsed: 00:39:31
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 45010 steps/s (collection: 2.072s, learning 0.112s)
             Mean action noise std: 3.47
          Mean value_function loss: 76.2770
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.8950
                       Mean reward: 725.57
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.2487
    Episode_Reward/rotating_object: 140.8017
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 2.18s
                      Time elapsed: 00:39:33
                               ETA: 00:16:17

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 45322 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 3.47
          Mean value_function loss: 80.2031
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 67.9142
                       Mean reward: 674.12
               Mean episode length: 236.61
    Episode_Reward/reaching_object: 1.2643
    Episode_Reward/rotating_object: 141.7720
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.17s
                      Time elapsed: 00:39:35
                               ETA: 00:16:15

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 44200 steps/s (collection: 2.111s, learning 0.113s)
             Mean action noise std: 3.48
          Mean value_function loss: 78.6920
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 67.9289
                       Mean reward: 742.80
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.2539
    Episode_Reward/rotating_object: 141.2604
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.22s
                      Time elapsed: 00:39:37
                               ETA: 00:16:13

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 45289 steps/s (collection: 2.060s, learning 0.111s)
             Mean action noise std: 3.48
          Mean value_function loss: 66.0924
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 67.9402
                       Mean reward: 692.71
               Mean episode length: 242.84
    Episode_Reward/reaching_object: 1.2549
    Episode_Reward/rotating_object: 137.0481
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.17s
                      Time elapsed: 00:39:39
                               ETA: 00:16:11

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 44718 steps/s (collection: 2.070s, learning 0.129s)
             Mean action noise std: 3.48
          Mean value_function loss: 81.4229
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 67.9530
                       Mean reward: 700.74
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.2433
    Episode_Reward/rotating_object: 141.7563
        Episode_Reward/action_rate: -0.0729
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.20s
                      Time elapsed: 00:39:42
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 45224 steps/s (collection: 2.063s, learning 0.111s)
             Mean action noise std: 3.48
          Mean value_function loss: 87.9550
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 67.9687
                       Mean reward: 750.42
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 141.6078
        Episode_Reward/action_rate: -0.0721
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.17s
                      Time elapsed: 00:39:44
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 44992 steps/s (collection: 2.073s, learning 0.112s)
             Mean action noise std: 3.48
          Mean value_function loss: 81.6840
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 67.9870
                       Mean reward: 715.57
               Mean episode length: 235.04
    Episode_Reward/reaching_object: 1.2246
    Episode_Reward/rotating_object: 135.7079
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.18s
                      Time elapsed: 00:39:46
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 45558 steps/s (collection: 2.047s, learning 0.111s)
             Mean action noise std: 3.49
          Mean value_function loss: 84.1819
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 68.0001
                       Mean reward: 726.45
               Mean episode length: 234.67
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 140.7241
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.16s
                      Time elapsed: 00:39:48
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 45434 steps/s (collection: 2.053s, learning 0.111s)
             Mean action noise std: 3.49
          Mean value_function loss: 82.9581
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.0194
                       Mean reward: 663.19
               Mean episode length: 220.23
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 136.4001
        Episode_Reward/action_rate: -0.0698
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.16s
                      Time elapsed: 00:39:50
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 44678 steps/s (collection: 2.089s, learning 0.111s)
             Mean action noise std: 3.49
          Mean value_function loss: 71.0457
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.0351
                       Mean reward: 716.17
               Mean episode length: 238.29
    Episode_Reward/reaching_object: 1.2616
    Episode_Reward/rotating_object: 146.0005
        Episode_Reward/action_rate: -0.0736
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.20s
                      Time elapsed: 00:39:53
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 45201 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 3.49
          Mean value_function loss: 69.1241
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.0568
                       Mean reward: 722.49
               Mean episode length: 239.54
    Episode_Reward/reaching_object: 1.2415
    Episode_Reward/rotating_object: 137.8187
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 2.17s
                      Time elapsed: 00:39:55
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 46180 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.50
          Mean value_function loss: 70.3951
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 68.0769
                       Mean reward: 740.08
               Mean episode length: 243.26
    Episode_Reward/reaching_object: 1.2514
    Episode_Reward/rotating_object: 141.4041
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.13s
                      Time elapsed: 00:39:57
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 46217 steps/s (collection: 2.017s, learning 0.110s)
             Mean action noise std: 3.50
          Mean value_function loss: 58.4976
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 68.0973
                       Mean reward: 736.52
               Mean episode length: 239.59
    Episode_Reward/reaching_object: 1.2632
    Episode_Reward/rotating_object: 141.7723
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.13s
                      Time elapsed: 00:39:59
                               ETA: 00:15:50

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 45553 steps/s (collection: 2.041s, learning 0.117s)
             Mean action noise std: 3.50
          Mean value_function loss: 78.1613
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.1120
                       Mean reward: 668.81
               Mean episode length: 231.93
    Episode_Reward/reaching_object: 1.2499
    Episode_Reward/rotating_object: 138.7989
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.16s
                      Time elapsed: 00:40:01
                               ETA: 00:15:48

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 46294 steps/s (collection: 2.013s, learning 0.111s)
             Mean action noise std: 3.50
          Mean value_function loss: 81.0324
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.1262
                       Mean reward: 697.46
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 137.8271
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.12s
                      Time elapsed: 00:40:03
                               ETA: 00:15:46

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 46036 steps/s (collection: 2.025s, learning 0.111s)
             Mean action noise std: 3.51
          Mean value_function loss: 80.1022
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.1419
                       Mean reward: 721.16
               Mean episode length: 235.83
    Episode_Reward/reaching_object: 1.2567
    Episode_Reward/rotating_object: 142.9718
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.14s
                      Time elapsed: 00:40:05
                               ETA: 00:15:44

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 45371 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 3.51
          Mean value_function loss: 80.7094
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.1612
                       Mean reward: 717.23
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.2562
    Episode_Reward/rotating_object: 143.0473
        Episode_Reward/action_rate: -0.0745
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.17s
                      Time elapsed: 00:40:08
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 45876 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 3.51
          Mean value_function loss: 70.1154
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 68.1795
                       Mean reward: 683.11
               Mean episode length: 233.49
    Episode_Reward/reaching_object: 1.2235
    Episode_Reward/rotating_object: 135.8685
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.14s
                      Time elapsed: 00:40:10
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 44882 steps/s (collection: 2.075s, learning 0.116s)
             Mean action noise std: 3.51
          Mean value_function loss: 83.3174
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.1947
                       Mean reward: 718.18
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 139.1576
        Episode_Reward/action_rate: -0.0730
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.19s
                      Time elapsed: 00:40:12
                               ETA: 00:15:37

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 44222 steps/s (collection: 2.092s, learning 0.131s)
             Mean action noise std: 3.51
          Mean value_function loss: 80.9907
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 68.2082
                       Mean reward: 765.47
               Mean episode length: 241.94
    Episode_Reward/reaching_object: 1.2332
    Episode_Reward/rotating_object: 140.7715
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.22s
                      Time elapsed: 00:40:14
                               ETA: 00:15:35

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 44083 steps/s (collection: 2.116s, learning 0.114s)
             Mean action noise std: 3.52
          Mean value_function loss: 70.8078
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 68.2217
                       Mean reward: 711.78
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 140.0038
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.23s
                      Time elapsed: 00:40:16
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 42181 steps/s (collection: 2.218s, learning 0.112s)
             Mean action noise std: 3.52
          Mean value_function loss: 72.2194
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.2475
                       Mean reward: 733.72
               Mean episode length: 240.21
    Episode_Reward/reaching_object: 1.2557
    Episode_Reward/rotating_object: 144.8809
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.33s
                      Time elapsed: 00:40:19
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 44707 steps/s (collection: 2.083s, learning 0.115s)
             Mean action noise std: 3.52
          Mean value_function loss: 85.6673
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 68.2643
                       Mean reward: 680.41
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 1.2178
    Episode_Reward/rotating_object: 138.2652
        Episode_Reward/action_rate: -0.0733
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.20s
                      Time elapsed: 00:40:21
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 45000 steps/s (collection: 2.072s, learning 0.112s)
             Mean action noise std: 3.52
          Mean value_function loss: 83.0554
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.2818
                       Mean reward: 723.58
               Mean episode length: 237.73
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 135.4131
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.18s
                      Time elapsed: 00:40:23
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 45582 steps/s (collection: 2.044s, learning 0.113s)
             Mean action noise std: 3.53
          Mean value_function loss: 83.6205
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.2937
                       Mean reward: 716.39
               Mean episode length: 239.92
    Episode_Reward/reaching_object: 1.2475
    Episode_Reward/rotating_object: 141.6675
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 2.16s
                      Time elapsed: 00:40:25
                               ETA: 00:15:23

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 43123 steps/s (collection: 2.154s, learning 0.126s)
             Mean action noise std: 3.53
          Mean value_function loss: 75.3553
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 68.3095
                       Mean reward: 656.98
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.2234
    Episode_Reward/rotating_object: 137.2636
        Episode_Reward/action_rate: -0.0740
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.28s
                      Time elapsed: 00:40:28
                               ETA: 00:15:21

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 44237 steps/s (collection: 2.111s, learning 0.111s)
             Mean action noise std: 3.53
          Mean value_function loss: 85.4128
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.3273
                       Mean reward: 719.15
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.2177
    Episode_Reward/rotating_object: 136.7641
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.22s
                      Time elapsed: 00:40:30
                               ETA: 00:15:19

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 45026 steps/s (collection: 2.072s, learning 0.111s)
             Mean action noise std: 3.53
          Mean value_function loss: 77.5681
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 68.3389
                       Mean reward: 715.02
               Mean episode length: 245.02
    Episode_Reward/reaching_object: 1.2488
    Episode_Reward/rotating_object: 141.5033
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.18s
                      Time elapsed: 00:40:32
                               ETA: 00:15:17

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 44969 steps/s (collection: 2.074s, learning 0.112s)
             Mean action noise std: 3.54
          Mean value_function loss: 60.3098
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 68.3519
                       Mean reward: 694.31
               Mean episode length: 235.77
    Episode_Reward/reaching_object: 1.2507
    Episode_Reward/rotating_object: 142.2175
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.19s
                      Time elapsed: 00:40:34
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 45353 steps/s (collection: 2.054s, learning 0.114s)
             Mean action noise std: 3.54
          Mean value_function loss: 98.5059
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.3756
                       Mean reward: 709.73
               Mean episode length: 236.01
    Episode_Reward/reaching_object: 1.1864
    Episode_Reward/rotating_object: 134.4964
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.17s
                      Time elapsed: 00:40:36
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 44952 steps/s (collection: 2.075s, learning 0.111s)
             Mean action noise std: 3.54
          Mean value_function loss: 73.2157
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 68.3987
                       Mean reward: 681.39
               Mean episode length: 236.57
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 138.2627
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 2.19s
                      Time elapsed: 00:40:38
                               ETA: 00:15:10

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 44716 steps/s (collection: 2.086s, learning 0.112s)
             Mean action noise std: 3.54
          Mean value_function loss: 75.7783
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.4157
                       Mean reward: 718.38
               Mean episode length: 235.76
    Episode_Reward/reaching_object: 1.2292
    Episode_Reward/rotating_object: 140.5528
        Episode_Reward/action_rate: -0.0744
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.20s
                      Time elapsed: 00:40:41
                               ETA: 00:15:08

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 45384 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 3.55
          Mean value_function loss: 55.4948
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.4342
                       Mean reward: 726.87
               Mean episode length: 240.93
    Episode_Reward/reaching_object: 1.2606
    Episode_Reward/rotating_object: 143.6829
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.17s
                      Time elapsed: 00:40:43
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 46469 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 3.55
          Mean value_function loss: 76.3057
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.4512
                       Mean reward: 746.54
               Mean episode length: 248.39
    Episode_Reward/reaching_object: 1.2577
    Episode_Reward/rotating_object: 140.8773
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.12s
                      Time elapsed: 00:40:45
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 46180 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.55
          Mean value_function loss: 88.8498
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 68.4698
                       Mean reward: 681.87
               Mean episode length: 236.83
    Episode_Reward/reaching_object: 1.2348
    Episode_Reward/rotating_object: 138.9232
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.13s
                      Time elapsed: 00:40:47
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 46245 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 3.56
          Mean value_function loss: 73.6073
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.4882
                       Mean reward: 663.69
               Mean episode length: 220.93
    Episode_Reward/reaching_object: 1.2151
    Episode_Reward/rotating_object: 137.7393
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.13s
                      Time elapsed: 00:40:49
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 46243 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 3.56
          Mean value_function loss: 77.3904
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.5100
                       Mean reward: 664.42
               Mean episode length: 227.93
    Episode_Reward/reaching_object: 1.2293
    Episode_Reward/rotating_object: 138.9826
        Episode_Reward/action_rate: -0.0751
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.13s
                      Time elapsed: 00:40:51
                               ETA: 00:14:56

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 46544 steps/s (collection: 2.001s, learning 0.111s)
             Mean action noise std: 3.56
          Mean value_function loss: 60.9089
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 68.5305
                       Mean reward: 713.58
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 142.0699
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.11s
                      Time elapsed: 00:40:53
                               ETA: 00:14:54

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 46466 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 3.56
          Mean value_function loss: 72.6401
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.5468
                       Mean reward: 737.47
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.2412
    Episode_Reward/rotating_object: 137.4609
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.12s
                      Time elapsed: 00:40:56
                               ETA: 00:14:52

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 46157 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.57
          Mean value_function loss: 72.6543
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.5734
                       Mean reward: 733.68
               Mean episode length: 235.98
    Episode_Reward/reaching_object: 1.2539
    Episode_Reward/rotating_object: 144.3564
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.13s
                      Time elapsed: 00:40:58
                               ETA: 00:14:50

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 44199 steps/s (collection: 2.110s, learning 0.114s)
             Mean action noise std: 3.57
          Mean value_function loss: 89.8456
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.5984
                       Mean reward: 718.07
               Mean episode length: 230.96
    Episode_Reward/reaching_object: 1.2296
    Episode_Reward/rotating_object: 142.7465
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.22s
                      Time elapsed: 00:41:00
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 44189 steps/s (collection: 2.103s, learning 0.121s)
             Mean action noise std: 3.57
          Mean value_function loss: 68.8832
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.6205
                       Mean reward: 703.33
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 1.2386
    Episode_Reward/rotating_object: 142.9574
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.22s
                      Time elapsed: 00:41:02
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 44316 steps/s (collection: 2.105s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 77.5185
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 68.6435
                       Mean reward: 726.93
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.2207
    Episode_Reward/rotating_object: 141.3725
        Episode_Reward/action_rate: -0.0753
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.22s
                      Time elapsed: 00:41:04
                               ETA: 00:14:43

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 44148 steps/s (collection: 2.112s, learning 0.114s)
             Mean action noise std: 3.58
          Mean value_function loss: 73.8833
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 68.6665
                       Mean reward: 713.08
               Mean episode length: 230.58
    Episode_Reward/reaching_object: 1.2375
    Episode_Reward/rotating_object: 144.1435
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.23s
                      Time elapsed: 00:41:07
                               ETA: 00:14:41

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 44229 steps/s (collection: 2.109s, learning 0.113s)
             Mean action noise std: 3.58
          Mean value_function loss: 70.4427
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 68.6862
                       Mean reward: 729.69
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.2557
    Episode_Reward/rotating_object: 146.9721
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.22s
                      Time elapsed: 00:41:09
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 45253 steps/s (collection: 2.061s, learning 0.111s)
             Mean action noise std: 3.58
          Mean value_function loss: 68.6668
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.7061
                       Mean reward: 730.01
               Mean episode length: 236.14
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 144.8454
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.17s
                      Time elapsed: 00:41:11
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 45555 steps/s (collection: 2.047s, learning 0.111s)
             Mean action noise std: 3.59
          Mean value_function loss: 82.4852
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 68.7172
                       Mean reward: 715.16
               Mean episode length: 236.50
    Episode_Reward/reaching_object: 1.2285
    Episode_Reward/rotating_object: 139.7423
        Episode_Reward/action_rate: -0.0771
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.16s
                      Time elapsed: 00:41:13
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 44972 steps/s (collection: 2.070s, learning 0.116s)
             Mean action noise std: 3.59
          Mean value_function loss: 78.0064
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.7256
                       Mean reward: 698.86
               Mean episode length: 235.78
    Episode_Reward/reaching_object: 1.2411
    Episode_Reward/rotating_object: 143.0449
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.19s
                      Time elapsed: 00:41:15
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 45596 steps/s (collection: 2.041s, learning 0.115s)
             Mean action noise std: 3.59
          Mean value_function loss: 71.5156
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 68.7370
                       Mean reward: 642.31
               Mean episode length: 229.44
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 133.5394
        Episode_Reward/action_rate: -0.0760
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.16s
                      Time elapsed: 00:41:17
                               ETA: 00:14:29

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 45109 steps/s (collection: 2.067s, learning 0.112s)
             Mean action noise std: 3.59
          Mean value_function loss: 60.0218
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.7519
                       Mean reward: 714.96
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.2526
    Episode_Reward/rotating_object: 143.8453
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.18s
                      Time elapsed: 00:41:20
                               ETA: 00:14:27

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 44937 steps/s (collection: 2.070s, learning 0.117s)
             Mean action noise std: 3.59
          Mean value_function loss: 78.3384
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 68.7667
                       Mean reward: 691.86
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 141.6467
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.19s
                      Time elapsed: 00:41:22
                               ETA: 00:14:25

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 44601 steps/s (collection: 2.087s, learning 0.117s)
             Mean action noise std: 3.60
          Mean value_function loss: 75.8648
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.7856
                       Mean reward: 733.45
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 1.2440
    Episode_Reward/rotating_object: 141.9242
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.20s
                      Time elapsed: 00:41:24
                               ETA: 00:14:23

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 45162 steps/s (collection: 2.064s, learning 0.113s)
             Mean action noise std: 3.60
          Mean value_function loss: 81.6706
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.8022
                       Mean reward: 698.40
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.2371
    Episode_Reward/rotating_object: 142.1028
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.18s
                      Time elapsed: 00:41:26
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 45218 steps/s (collection: 2.059s, learning 0.115s)
             Mean action noise std: 3.60
          Mean value_function loss: 71.8200
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 68.8272
                       Mean reward: 698.30
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.2621
    Episode_Reward/rotating_object: 145.1200
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.17s
                      Time elapsed: 00:41:28
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 45104 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 75.8832
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.8485
                       Mean reward: 729.10
               Mean episode length: 237.88
    Episode_Reward/reaching_object: 1.2511
    Episode_Reward/rotating_object: 144.8299
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.18s
                      Time elapsed: 00:41:31
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 45820 steps/s (collection: 2.035s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 74.4238
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 68.8701
                       Mean reward: 670.41
               Mean episode length: 223.09
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 140.1555
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.15s
                      Time elapsed: 00:41:33
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 46418 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 70.5541
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.8911
                       Mean reward: 699.02
               Mean episode length: 231.07
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 139.2312
        Episode_Reward/action_rate: -0.0785
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.12s
                      Time elapsed: 00:41:35
                               ETA: 00:14:11

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 46318 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 3.61
          Mean value_function loss: 66.6763
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.9091
                       Mean reward: 738.46
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 1.2515
    Episode_Reward/rotating_object: 143.4103
        Episode_Reward/action_rate: -0.0795
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 2.12s
                      Time elapsed: 00:41:37
                               ETA: 00:14:09

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 46054 steps/s (collection: 2.024s, learning 0.111s)
             Mean action noise std: 3.62
          Mean value_function loss: 81.2347
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 68.9278
                       Mean reward: 708.63
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 142.6927
        Episode_Reward/action_rate: -0.0786
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 2.13s
                      Time elapsed: 00:41:39
                               ETA: 00:14:07

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 46163 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 3.62
          Mean value_function loss: 64.0729
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 68.9421
                       Mean reward: 730.95
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 141.6439
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 2.13s
                      Time elapsed: 00:41:41
                               ETA: 00:14:05

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 46123 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 3.62
          Mean value_function loss: 71.4729
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 68.9524
                       Mean reward: 732.04
               Mean episode length: 245.03
    Episode_Reward/reaching_object: 1.2373
    Episode_Reward/rotating_object: 142.9908
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.13s
                      Time elapsed: 00:41:43
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 46158 steps/s (collection: 2.018s, learning 0.112s)
             Mean action noise std: 3.62
          Mean value_function loss: 73.0477
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 68.9701
                       Mean reward: 697.91
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.2447
    Episode_Reward/rotating_object: 141.7106
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.13s
                      Time elapsed: 00:41:45
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 45652 steps/s (collection: 2.042s, learning 0.111s)
             Mean action noise std: 3.63
          Mean value_function loss: 64.8490
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 68.9881
                       Mean reward: 696.42
               Mean episode length: 234.45
    Episode_Reward/reaching_object: 1.2503
    Episode_Reward/rotating_object: 142.4922
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.15s
                      Time elapsed: 00:41:48
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 45562 steps/s (collection: 2.044s, learning 0.114s)
             Mean action noise std: 3.63
          Mean value_function loss: 70.6709
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.0046
                       Mean reward: 719.38
               Mean episode length: 233.93
    Episode_Reward/reaching_object: 1.2251
    Episode_Reward/rotating_object: 139.9017
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.16s
                      Time elapsed: 00:41:50
                               ETA: 00:13:56

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 45241 steps/s (collection: 2.060s, learning 0.113s)
             Mean action noise std: 3.63
          Mean value_function loss: 90.7918
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.0188
                       Mean reward: 687.93
               Mean episode length: 228.48
    Episode_Reward/reaching_object: 1.2280
    Episode_Reward/rotating_object: 140.9085
        Episode_Reward/action_rate: -0.0791
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.17s
                      Time elapsed: 00:41:52
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 44384 steps/s (collection: 2.082s, learning 0.133s)
             Mean action noise std: 3.63
          Mean value_function loss: 80.2873
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.0300
                       Mean reward: 693.41
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 141.4968
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.21s
                      Time elapsed: 00:41:54
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 45323 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 3.63
          Mean value_function loss: 71.1383
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 69.0392
                       Mean reward: 751.93
               Mean episode length: 242.26
    Episode_Reward/reaching_object: 1.2499
    Episode_Reward/rotating_object: 145.1496
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.17s
                      Time elapsed: 00:41:56
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 45439 steps/s (collection: 2.051s, learning 0.113s)
             Mean action noise std: 3.64
          Mean value_function loss: 64.2609
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.0526
                       Mean reward: 691.60
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2402
    Episode_Reward/rotating_object: 142.2097
        Episode_Reward/action_rate: -0.0806
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.16s
                      Time elapsed: 00:41:59
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 45025 steps/s (collection: 2.068s, learning 0.115s)
             Mean action noise std: 3.64
          Mean value_function loss: 66.3527
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.0723
                       Mean reward: 735.75
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.2576
    Episode_Reward/rotating_object: 148.1146
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.18s
                      Time elapsed: 00:42:01
                               ETA: 00:13:44

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 45401 steps/s (collection: 2.050s, learning 0.116s)
             Mean action noise std: 3.64
          Mean value_function loss: 76.8665
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 69.0954
                       Mean reward: 742.04
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.2293
    Episode_Reward/rotating_object: 143.8651
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.17s
                      Time elapsed: 00:42:03
                               ETA: 00:13:42

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 45371 steps/s (collection: 2.053s, learning 0.114s)
             Mean action noise std: 3.65
          Mean value_function loss: 63.4082
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 69.1174
                       Mean reward: 735.79
               Mean episode length: 244.94
    Episode_Reward/reaching_object: 1.2590
    Episode_Reward/rotating_object: 142.2109
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.17s
                      Time elapsed: 00:42:05
                               ETA: 00:13:40

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 45003 steps/s (collection: 2.059s, learning 0.125s)
             Mean action noise std: 3.65
          Mean value_function loss: 60.9501
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.1381
                       Mean reward: 701.30
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 139.6371
        Episode_Reward/action_rate: -0.0813
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.18s
                      Time elapsed: 00:42:07
                               ETA: 00:13:38

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 44415 steps/s (collection: 2.085s, learning 0.128s)
             Mean action noise std: 3.65
          Mean value_function loss: 80.1385
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 69.1537
                       Mean reward: 706.72
               Mean episode length: 231.91
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 144.1064
        Episode_Reward/action_rate: -0.0807
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.21s
                      Time elapsed: 00:42:09
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 43780 steps/s (collection: 2.125s, learning 0.120s)
             Mean action noise std: 3.65
          Mean value_function loss: 61.6807
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 69.1727
                       Mean reward: 738.88
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.2301
    Episode_Reward/rotating_object: 141.3608
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.25s
                      Time elapsed: 00:42:12
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 45549 steps/s (collection: 2.046s, learning 0.112s)
             Mean action noise std: 3.66
          Mean value_function loss: 71.5318
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.1990
                       Mean reward: 720.37
               Mean episode length: 239.76
    Episode_Reward/reaching_object: 1.2513
    Episode_Reward/rotating_object: 142.9768
        Episode_Reward/action_rate: -0.0810
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 2.16s
                      Time elapsed: 00:42:14
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 44821 steps/s (collection: 2.079s, learning 0.114s)
             Mean action noise std: 3.66
          Mean value_function loss: 71.4347
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 69.2197
                       Mean reward: 721.40
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.2509
    Episode_Reward/rotating_object: 142.2434
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.19s
                      Time elapsed: 00:42:16
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 44870 steps/s (collection: 2.080s, learning 0.111s)
             Mean action noise std: 3.66
          Mean value_function loss: 71.9228
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.2368
                       Mean reward: 745.19
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.2647
    Episode_Reward/rotating_object: 146.0710
        Episode_Reward/action_rate: -0.0821
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.19s
                      Time elapsed: 00:42:18
                               ETA: 00:13:26

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 45704 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 3.67
          Mean value_function loss: 59.7745
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 69.2595
                       Mean reward: 724.41
               Mean episode length: 237.65
    Episode_Reward/reaching_object: 1.2621
    Episode_Reward/rotating_object: 144.8038
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.15s
                      Time elapsed: 00:42:20
                               ETA: 00:13:24

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 46394 steps/s (collection: 2.008s, learning 0.111s)
             Mean action noise std: 3.67
          Mean value_function loss: 66.7411
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 69.2741
                       Mean reward: 757.62
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 1.2551
    Episode_Reward/rotating_object: 144.5269
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.12s
                      Time elapsed: 00:42:22
                               ETA: 00:13:22

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 46191 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 3.67
          Mean value_function loss: 58.3818
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.2921
                       Mean reward: 682.92
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 1.2678
    Episode_Reward/rotating_object: 144.6039
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 2.13s
                      Time elapsed: 00:42:25
                               ETA: 00:13:20

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 46489 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 65.7822
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.3202
                       Mean reward: 707.68
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 144.6430
        Episode_Reward/action_rate: -0.0823
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.11s
                      Time elapsed: 00:42:27
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 46074 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 67.0163
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.3464
                       Mean reward: 760.36
               Mean episode length: 241.45
    Episode_Reward/reaching_object: 1.2338
    Episode_Reward/rotating_object: 142.4664
        Episode_Reward/action_rate: -0.0817
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.13s
                      Time elapsed: 00:42:29
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 45969 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 3.68
          Mean value_function loss: 71.1069
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.3681
                       Mean reward: 742.51
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 143.3241
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.14s
                      Time elapsed: 00:42:31
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 46221 steps/s (collection: 2.016s, learning 0.111s)
             Mean action noise std: 3.69
          Mean value_function loss: 64.9234
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.3986
                       Mean reward: 718.77
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 1.2463
    Episode_Reward/rotating_object: 145.5898
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.13s
                      Time elapsed: 00:42:33
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 45578 steps/s (collection: 2.043s, learning 0.114s)
             Mean action noise std: 3.69
          Mean value_function loss: 65.2709
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.4290
                       Mean reward: 720.04
               Mean episode length: 239.52
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 141.4706
        Episode_Reward/action_rate: -0.0825
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.16s
                      Time elapsed: 00:42:35
                               ETA: 00:13:08

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 45964 steps/s (collection: 2.024s, learning 0.115s)
             Mean action noise std: 3.69
          Mean value_function loss: 74.2806
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 69.4439
                       Mean reward: 662.14
               Mean episode length: 233.17
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 138.4261
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.14s
                      Time elapsed: 00:42:37
                               ETA: 00:13:06

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 45514 steps/s (collection: 2.047s, learning 0.113s)
             Mean action noise std: 3.70
          Mean value_function loss: 69.9244
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 69.4558
                       Mean reward: 716.39
               Mean episode length: 232.01
    Episode_Reward/reaching_object: 1.2513
    Episode_Reward/rotating_object: 145.5822
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 2.16s
                      Time elapsed: 00:42:40
                               ETA: 00:13:04

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 45524 steps/s (collection: 2.046s, learning 0.113s)
             Mean action noise std: 3.70
          Mean value_function loss: 85.7677
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.4693
                       Mean reward: 683.70
               Mean episode length: 231.82
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 141.9288
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 2.16s
                      Time elapsed: 00:42:42
                               ETA: 00:13:02

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 45709 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 3.70
          Mean value_function loss: 71.3494
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.4814
                       Mean reward: 715.66
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 1.2403
    Episode_Reward/rotating_object: 142.3451
        Episode_Reward/action_rate: -0.0838
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 2.15s
                      Time elapsed: 00:42:44
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 45161 steps/s (collection: 2.060s, learning 0.117s)
             Mean action noise std: 3.70
          Mean value_function loss: 63.4957
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 69.4947
                       Mean reward: 710.24
               Mean episode length: 241.74
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 140.2256
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.18s
                      Time elapsed: 00:42:46
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 45511 steps/s (collection: 2.040s, learning 0.120s)
             Mean action noise std: 3.70
          Mean value_function loss: 72.3252
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 69.5069
                       Mean reward: 714.81
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.2243
    Episode_Reward/rotating_object: 139.9486
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.16s
                      Time elapsed: 00:42:48
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 45186 steps/s (collection: 2.058s, learning 0.117s)
             Mean action noise std: 3.71
          Mean value_function loss: 75.3137
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.5214
                       Mean reward: 689.55
               Mean episode length: 234.24
    Episode_Reward/reaching_object: 1.2345
    Episode_Reward/rotating_object: 139.8904
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.18s
                      Time elapsed: 00:42:50
                               ETA: 00:12:53

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 44479 steps/s (collection: 2.095s, learning 0.115s)
             Mean action noise std: 3.71
          Mean value_function loss: 78.8878
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.5411
                       Mean reward: 731.31
               Mean episode length: 240.20
    Episode_Reward/reaching_object: 1.2587
    Episode_Reward/rotating_object: 143.5184
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.21s
                      Time elapsed: 00:42:53
                               ETA: 00:12:50

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 45767 steps/s (collection: 2.035s, learning 0.112s)
             Mean action noise std: 3.71
          Mean value_function loss: 67.5367
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 69.5581
                       Mean reward: 695.97
               Mean episode length: 234.90
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 142.3989
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.15s
                      Time elapsed: 00:42:55
                               ETA: 00:12:48

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 44395 steps/s (collection: 2.104s, learning 0.111s)
             Mean action noise std: 3.72
          Mean value_function loss: 54.2609
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 69.5785
                       Mean reward: 713.02
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.2523
    Episode_Reward/rotating_object: 145.2188
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.21s
                      Time elapsed: 00:42:57
                               ETA: 00:12:46

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 43355 steps/s (collection: 2.155s, learning 0.113s)
             Mean action noise std: 3.72
          Mean value_function loss: 66.2587
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.6023
                       Mean reward: 688.26
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 140.5515
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.27s
                      Time elapsed: 00:42:59
                               ETA: 00:12:44

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 43061 steps/s (collection: 2.172s, learning 0.111s)
             Mean action noise std: 3.72
          Mean value_function loss: 73.6047
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 69.6225
                       Mean reward: 725.92
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 1.2471
    Episode_Reward/rotating_object: 143.5535
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.28s
                      Time elapsed: 00:43:02
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 45238 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 3.72
          Mean value_function loss: 72.8978
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.6350
                       Mean reward: 713.97
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.2512
    Episode_Reward/rotating_object: 147.3498
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.17s
                      Time elapsed: 00:43:04
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 42466 steps/s (collection: 2.187s, learning 0.128s)
             Mean action noise std: 3.73
          Mean value_function loss: 71.9522
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 69.6532
                       Mean reward: 721.35
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 142.5785
        Episode_Reward/action_rate: -0.0842
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.31s
                      Time elapsed: 00:43:06
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 41558 steps/s (collection: 2.239s, learning 0.126s)
             Mean action noise std: 3.73
          Mean value_function loss: 81.0353
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 69.6702
                       Mean reward: 734.85
               Mean episode length: 239.71
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 142.1580
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.37s
                      Time elapsed: 00:43:08
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 43086 steps/s (collection: 2.157s, learning 0.125s)
             Mean action noise std: 3.73
          Mean value_function loss: 74.3904
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 69.6810
                       Mean reward: 694.22
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 144.4631
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 2.28s
                      Time elapsed: 00:43:11
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 43331 steps/s (collection: 2.142s, learning 0.127s)
             Mean action noise std: 3.73
          Mean value_function loss: 71.5559
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.6919
                       Mean reward: 717.68
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 1.2429
    Episode_Reward/rotating_object: 143.7847
        Episode_Reward/action_rate: -0.0848
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.27s
                      Time elapsed: 00:43:13
                               ETA: 00:12:30

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 43069 steps/s (collection: 2.153s, learning 0.129s)
             Mean action noise std: 3.74
          Mean value_function loss: 76.4703
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.7084
                       Mean reward: 743.42
               Mean episode length: 242.62
    Episode_Reward/reaching_object: 1.2347
    Episode_Reward/rotating_object: 143.2441
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.28s
                      Time elapsed: 00:43:15
                               ETA: 00:12:28

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 43198 steps/s (collection: 2.152s, learning 0.124s)
             Mean action noise std: 3.74
          Mean value_function loss: 62.8530
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 69.7253
                       Mean reward: 728.45
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.2325
    Episode_Reward/rotating_object: 140.8193
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.28s
                      Time elapsed: 00:43:17
                               ETA: 00:12:26

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 46426 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 3.74
          Mean value_function loss: 68.3719
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.7382
                       Mean reward: 715.51
               Mean episode length: 237.09
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 141.7685
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.12s
                      Time elapsed: 00:43:20
                               ETA: 00:12:24

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 46437 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 3.74
          Mean value_function loss: 68.3067
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 69.7558
                       Mean reward: 726.45
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2191
    Episode_Reward/rotating_object: 139.9824
        Episode_Reward/action_rate: -0.0844
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.12s
                      Time elapsed: 00:43:22
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 46153 steps/s (collection: 2.016s, learning 0.114s)
             Mean action noise std: 3.75
          Mean value_function loss: 63.2832
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.7685
                       Mean reward: 720.80
               Mean episode length: 235.07
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 141.6585
        Episode_Reward/action_rate: -0.0847
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.13s
                      Time elapsed: 00:43:24
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 44693 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 3.75
          Mean value_function loss: 80.3830
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.7858
                       Mean reward: 680.31
               Mean episode length: 232.13
    Episode_Reward/reaching_object: 1.2264
    Episode_Reward/rotating_object: 138.8869
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.20s
                      Time elapsed: 00:43:26
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 45197 steps/s (collection: 2.050s, learning 0.125s)
             Mean action noise std: 3.75
          Mean value_function loss: 74.3940
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.8030
                       Mean reward: 756.83
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 1.2256
    Episode_Reward/rotating_object: 141.3963
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.18s
                      Time elapsed: 00:43:28
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 45154 steps/s (collection: 2.064s, learning 0.113s)
             Mean action noise std: 3.75
          Mean value_function loss: 87.7423
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 69.8204
                       Mean reward: 708.80
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.2321
    Episode_Reward/rotating_object: 143.3698
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.18s
                      Time elapsed: 00:43:30
                               ETA: 00:12:12

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 44944 steps/s (collection: 2.074s, learning 0.113s)
             Mean action noise std: 3.76
          Mean value_function loss: 76.5979
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 69.8335
                       Mean reward: 732.55
               Mean episode length: 235.52
    Episode_Reward/reaching_object: 1.1983
    Episode_Reward/rotating_object: 137.0381
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 2.19s
                      Time elapsed: 00:43:33
                               ETA: 00:12:10

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 45103 steps/s (collection: 2.068s, learning 0.112s)
             Mean action noise std: 3.76
          Mean value_function loss: 84.2644
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 69.8518
                       Mean reward: 683.74
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 140.0285
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.18s
                      Time elapsed: 00:43:35
                               ETA: 00:12:08

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 45667 steps/s (collection: 2.041s, learning 0.111s)
             Mean action noise std: 3.76
          Mean value_function loss: 82.6198
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 69.8659
                       Mean reward: 721.29
               Mean episode length: 239.81
    Episode_Reward/reaching_object: 1.2521
    Episode_Reward/rotating_object: 145.4550
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.15s
                      Time elapsed: 00:43:37
                               ETA: 00:12:06

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 45906 steps/s (collection: 2.028s, learning 0.113s)
             Mean action noise std: 3.76
          Mean value_function loss: 62.2226
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 69.8796
                       Mean reward: 737.29
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.2443
    Episode_Reward/rotating_object: 144.6779
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 2.14s
                      Time elapsed: 00:43:39
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 45636 steps/s (collection: 2.041s, learning 0.113s)
             Mean action noise std: 3.77
          Mean value_function loss: 66.8258
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.9029
                       Mean reward: 684.12
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 141.2640
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.15s
                      Time elapsed: 00:43:41
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 46054 steps/s (collection: 2.021s, learning 0.114s)
             Mean action noise std: 3.77
          Mean value_function loss: 57.7027
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 69.9264
                       Mean reward: 765.08
               Mean episode length: 241.43
    Episode_Reward/reaching_object: 1.2575
    Episode_Reward/rotating_object: 146.9207
        Episode_Reward/action_rate: -0.0879
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 2.13s
                      Time elapsed: 00:43:43
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 45804 steps/s (collection: 2.034s, learning 0.112s)
             Mean action noise std: 3.77
          Mean value_function loss: 66.6207
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 69.9397
                       Mean reward: 684.47
               Mean episode length: 231.80
    Episode_Reward/reaching_object: 1.2211
    Episode_Reward/rotating_object: 141.6835
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.15s
                      Time elapsed: 00:43:45
                               ETA: 00:11:57

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 45991 steps/s (collection: 2.020s, learning 0.117s)
             Mean action noise std: 3.77
          Mean value_function loss: 64.7435
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 69.9569
                       Mean reward: 743.88
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 141.7371
        Episode_Reward/action_rate: -0.0872
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 2.14s
                      Time elapsed: 00:43:48
                               ETA: 00:11:54

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 45468 steps/s (collection: 2.051s, learning 0.111s)
             Mean action noise std: 3.78
          Mean value_function loss: 83.0949
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 69.9805
                       Mean reward: 680.96
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.2112
    Episode_Reward/rotating_object: 139.5603
        Episode_Reward/action_rate: -0.0854
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.16s
                      Time elapsed: 00:43:50
                               ETA: 00:11:52

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 45328 steps/s (collection: 2.055s, learning 0.114s)
             Mean action noise std: 3.78
          Mean value_function loss: 74.7057
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 70.0011
                       Mean reward: 674.72
               Mean episode length: 228.69
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 138.9564
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.17s
                      Time elapsed: 00:43:52
                               ETA: 00:11:50

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 45070 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 3.78
          Mean value_function loss: 73.3138
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 70.0180
                       Mean reward: 699.40
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 142.3167
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.18s
                      Time elapsed: 00:43:54
                               ETA: 00:11:48

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 45615 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 3.79
          Mean value_function loss: 64.2554
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.0316
                       Mean reward: 750.87
               Mean episode length: 241.75
    Episode_Reward/reaching_object: 1.2174
    Episode_Reward/rotating_object: 142.1570
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.16s
                      Time elapsed: 00:43:56
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 45919 steps/s (collection: 2.029s, learning 0.111s)
             Mean action noise std: 3.79
          Mean value_function loss: 61.1202
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.0533
                       Mean reward: 768.61
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 145.1287
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 2.14s
                      Time elapsed: 00:43:58
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 46778 steps/s (collection: 1.991s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 71.5679
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.0755
                       Mean reward: 698.77
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.2439
    Episode_Reward/rotating_object: 144.1740
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 2.10s
                      Time elapsed: 00:44:01
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 46346 steps/s (collection: 2.011s, learning 0.110s)
             Mean action noise std: 3.79
          Mean value_function loss: 63.3735
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.0899
                       Mean reward: 732.27
               Mean episode length: 242.97
    Episode_Reward/reaching_object: 1.2529
    Episode_Reward/rotating_object: 147.5013
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.12s
                      Time elapsed: 00:44:03
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 46275 steps/s (collection: 2.014s, learning 0.111s)
             Mean action noise std: 3.80
          Mean value_function loss: 75.0884
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.1000
                       Mean reward: 745.00
               Mean episode length: 236.40
    Episode_Reward/reaching_object: 1.2111
    Episode_Reward/rotating_object: 139.4845
        Episode_Reward/action_rate: -0.0858
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 2.12s
                      Time elapsed: 00:44:05
                               ETA: 00:11:36

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 46427 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 3.80
          Mean value_function loss: 75.3464
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.1171
                       Mean reward: 752.90
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 147.1938
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 2.12s
                      Time elapsed: 00:44:07
                               ETA: 00:11:34

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 46538 steps/s (collection: 2.001s, learning 0.111s)
             Mean action noise std: 3.80
          Mean value_function loss: 75.5336
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 70.1346
                       Mean reward: 744.58
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 142.2599
        Episode_Reward/action_rate: -0.0871
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 2.11s
                      Time elapsed: 00:44:09
                               ETA: 00:11:32

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 46306 steps/s (collection: 2.009s, learning 0.114s)
             Mean action noise std: 3.81
          Mean value_function loss: 58.3410
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.1547
                       Mean reward: 758.96
               Mean episode length: 241.60
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 146.8730
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 2.12s
                      Time elapsed: 00:44:11
                               ETA: 00:11:30

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 45788 steps/s (collection: 2.033s, learning 0.114s)
             Mean action noise std: 3.81
          Mean value_function loss: 68.5458
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 70.1696
                       Mean reward: 735.84
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.2330
    Episode_Reward/rotating_object: 144.7165
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 2.15s
                      Time elapsed: 00:44:13
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 45800 steps/s (collection: 2.032s, learning 0.115s)
             Mean action noise std: 3.81
          Mean value_function loss: 75.8653
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 70.1817
                       Mean reward: 726.30
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 1.2320
    Episode_Reward/rotating_object: 143.9373
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 2.15s
                      Time elapsed: 00:44:15
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 43778 steps/s (collection: 2.117s, learning 0.129s)
             Mean action noise std: 3.81
          Mean value_function loss: 67.5130
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.1899
                       Mean reward: 718.59
               Mean episode length: 236.46
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 143.0908
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 2.25s
                      Time elapsed: 00:44:18
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 40121 steps/s (collection: 2.322s, learning 0.128s)
             Mean action noise std: 3.81
          Mean value_function loss: 70.5340
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 70.2091
                       Mean reward: 718.88
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 142.2504
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.45s
                      Time elapsed: 00:44:20
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 40733 steps/s (collection: 2.284s, learning 0.129s)
             Mean action noise std: 3.82
          Mean value_function loss: 68.4020
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.2310
                       Mean reward: 712.74
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.2157
    Episode_Reward/rotating_object: 143.2530
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 2.41s
                      Time elapsed: 00:44:23
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 42069 steps/s (collection: 2.207s, learning 0.130s)
             Mean action noise std: 3.82
          Mean value_function loss: 78.1413
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 70.2499
                       Mean reward: 716.28
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 140.5311
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.34s
                      Time elapsed: 00:44:25
                               ETA: 00:11:16

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 41323 steps/s (collection: 2.249s, learning 0.130s)
             Mean action noise std: 3.82
          Mean value_function loss: 58.3023
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.2683
                       Mean reward: 716.50
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.2249
    Episode_Reward/rotating_object: 143.9392
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 2.38s
                      Time elapsed: 00:44:27
                               ETA: 00:11:14

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 40424 steps/s (collection: 2.302s, learning 0.130s)
             Mean action noise std: 3.83
          Mean value_function loss: 76.0527
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.2882
                       Mean reward: 720.05
               Mean episode length: 238.37
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 137.7908
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 2.43s
                      Time elapsed: 00:44:30
                               ETA: 00:11:12

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 39211 steps/s (collection: 2.381s, learning 0.126s)
             Mean action noise std: 3.83
          Mean value_function loss: 76.1506
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.3070
                       Mean reward: 711.27
               Mean episode length: 237.69
    Episode_Reward/reaching_object: 1.2351
    Episode_Reward/rotating_object: 143.7443
        Episode_Reward/action_rate: -0.0896
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 2.51s
                      Time elapsed: 00:44:32
                               ETA: 00:11:10

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 39852 steps/s (collection: 2.345s, learning 0.121s)
             Mean action noise std: 3.83
          Mean value_function loss: 66.8755
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.3213
                       Mean reward: 734.44
               Mean episode length: 238.51
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 143.3611
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 2.47s
                      Time elapsed: 00:44:35
                               ETA: 00:11:08

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 43476 steps/s (collection: 2.142s, learning 0.119s)
             Mean action noise std: 3.83
          Mean value_function loss: 90.5785
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 70.3323
                       Mean reward: 719.68
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.2113
    Episode_Reward/rotating_object: 142.0213
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 2.26s
                      Time elapsed: 00:44:37
                               ETA: 00:11:06

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 43628 steps/s (collection: 2.142s, learning 0.112s)
             Mean action noise std: 3.83
          Mean value_function loss: 78.7843
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 70.3429
                       Mean reward: 733.74
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.2270
    Episode_Reward/rotating_object: 145.7697
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 2.25s
                      Time elapsed: 00:44:39
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 44355 steps/s (collection: 2.094s, learning 0.122s)
             Mean action noise std: 3.84
          Mean value_function loss: 79.1580
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.3576
                       Mean reward: 708.11
               Mean episode length: 234.13
    Episode_Reward/reaching_object: 1.2107
    Episode_Reward/rotating_object: 141.0554
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 2.22s
                      Time elapsed: 00:44:41
                               ETA: 00:11:01

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 42043 steps/s (collection: 2.211s, learning 0.128s)
             Mean action noise std: 3.84
          Mean value_function loss: 61.6168
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.3794
                       Mean reward: 727.85
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 1.2125
    Episode_Reward/rotating_object: 143.7501
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 2.34s
                      Time elapsed: 00:44:44
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 45389 steps/s (collection: 2.055s, learning 0.111s)
             Mean action noise std: 3.84
          Mean value_function loss: 84.4106
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 70.3997
                       Mean reward: 713.88
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.2098
    Episode_Reward/rotating_object: 144.0724
        Episode_Reward/action_rate: -0.0886
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 2.17s
                      Time elapsed: 00:44:46
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 45842 steps/s (collection: 2.034s, learning 0.111s)
             Mean action noise std: 3.85
          Mean value_function loss: 79.3616
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.4173
                       Mean reward: 712.75
               Mean episode length: 233.12
    Episode_Reward/reaching_object: 1.2029
    Episode_Reward/rotating_object: 141.2154
        Episode_Reward/action_rate: -0.0881
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 2.14s
                      Time elapsed: 00:44:48
                               ETA: 00:10:54

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 45451 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 3.85
          Mean value_function loss: 81.6561
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 70.4355
                       Mean reward: 692.67
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.2173
    Episode_Reward/rotating_object: 140.9135
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 2.16s
                      Time elapsed: 00:44:50
                               ETA: 00:10:52

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 46441 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 3.85
          Mean value_function loss: 69.2838
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.4528
                       Mean reward: 734.40
               Mean episode length: 243.72
    Episode_Reward/reaching_object: 1.2303
    Episode_Reward/rotating_object: 144.1197
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 2.12s
                      Time elapsed: 00:44:52
                               ETA: 00:10:50

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 46558 steps/s (collection: 1.999s, learning 0.112s)
             Mean action noise std: 3.85
          Mean value_function loss: 63.9660
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.4742
                       Mean reward: 714.10
               Mean episode length: 233.61
    Episode_Reward/reaching_object: 1.1921
    Episode_Reward/rotating_object: 137.3933
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 2.11s
                      Time elapsed: 00:44:54
                               ETA: 00:10:48

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 45871 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 3.86
          Mean value_function loss: 77.3041
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 70.4925
                       Mean reward: 699.13
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 1.2084
    Episode_Reward/rotating_object: 140.7627
        Episode_Reward/action_rate: -0.0898
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 2.14s
                      Time elapsed: 00:44:57
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 46162 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 3.86
          Mean value_function loss: 74.6747
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 70.5064
                       Mean reward: 718.80
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 1.2183
    Episode_Reward/rotating_object: 144.3724
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 2.13s
                      Time elapsed: 00:44:59
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 45658 steps/s (collection: 2.040s, learning 0.113s)
             Mean action noise std: 3.86
          Mean value_function loss: 67.6111
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 70.5170
                       Mean reward: 754.11
               Mean episode length: 237.15
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 141.2471
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 2.15s
                      Time elapsed: 00:45:01
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 43545 steps/s (collection: 2.145s, learning 0.113s)
             Mean action noise std: 3.86
          Mean value_function loss: 89.0008
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 70.5337
                       Mean reward: 717.25
               Mean episode length: 234.06
    Episode_Reward/reaching_object: 1.2051
    Episode_Reward/rotating_object: 143.2701
        Episode_Reward/action_rate: -0.0895
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 2.26s
                      Time elapsed: 00:45:03
                               ETA: 00:10:39

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 41177 steps/s (collection: 2.260s, learning 0.127s)
             Mean action noise std: 3.87
          Mean value_function loss: 78.0342
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 70.5503
                       Mean reward: 710.77
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.2037
    Episode_Reward/rotating_object: 141.4733
        Episode_Reward/action_rate: -0.0894
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 2.39s
                      Time elapsed: 00:45:05
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 42467 steps/s (collection: 2.201s, learning 0.114s)
             Mean action noise std: 3.87
          Mean value_function loss: 64.8923
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 70.5649
                       Mean reward: 711.02
               Mean episode length: 240.27
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 138.3472
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 2.31s
                      Time elapsed: 00:45:08
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 45047 steps/s (collection: 2.067s, learning 0.115s)
             Mean action noise std: 3.87
          Mean value_function loss: 65.2485
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.5805
                       Mean reward: 731.97
               Mean episode length: 241.15
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 145.2343
        Episode_Reward/action_rate: -0.0914
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.18s
                      Time elapsed: 00:45:10
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 44035 steps/s (collection: 2.116s, learning 0.116s)
             Mean action noise std: 3.87
          Mean value_function loss: 79.3060
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 70.5967
                       Mean reward: 717.53
               Mean episode length: 232.59
    Episode_Reward/reaching_object: 1.2208
    Episode_Reward/rotating_object: 143.4598
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.23s
                      Time elapsed: 00:45:12
                               ETA: 00:10:30

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 44438 steps/s (collection: 2.096s, learning 0.116s)
             Mean action noise std: 3.88
          Mean value_function loss: 64.1345
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 70.6128
                       Mean reward: 722.22
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 1.2225
    Episode_Reward/rotating_object: 142.4966
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.21s
                      Time elapsed: 00:45:14
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 44050 steps/s (collection: 2.106s, learning 0.126s)
             Mean action noise std: 3.88
          Mean value_function loss: 60.5035
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 70.6317
                       Mean reward: 738.72
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 144.1677
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.23s
                      Time elapsed: 00:45:17
                               ETA: 00:10:25

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 45042 steps/s (collection: 2.057s, learning 0.126s)
             Mean action noise std: 3.88
          Mean value_function loss: 61.6453
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 70.6412
                       Mean reward: 714.71
               Mean episode length: 236.44
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 138.0103
        Episode_Reward/action_rate: -0.0907
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.18s
                      Time elapsed: 00:45:19
                               ETA: 00:10:23

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 44481 steps/s (collection: 2.085s, learning 0.125s)
             Mean action noise std: 3.88
          Mean value_function loss: 69.6694
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 70.6556
                       Mean reward: 718.78
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 1.2061
    Episode_Reward/rotating_object: 140.1535
        Episode_Reward/action_rate: -0.0903
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.21s
                      Time elapsed: 00:45:21
                               ETA: 00:10:21

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 44848 steps/s (collection: 2.052s, learning 0.139s)
             Mean action noise std: 3.89
          Mean value_function loss: 78.1073
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.6762
                       Mean reward: 752.91
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.2338
    Episode_Reward/rotating_object: 145.9707
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.19s
                      Time elapsed: 00:45:23
                               ETA: 00:10:19

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 45399 steps/s (collection: 2.040s, learning 0.126s)
             Mean action noise std: 3.89
          Mean value_function loss: 82.6481
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.6921
                       Mean reward: 705.06
               Mean episode length: 230.12
    Episode_Reward/reaching_object: 1.2195
    Episode_Reward/rotating_object: 141.9043
        Episode_Reward/action_rate: -0.0909
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.17s
                      Time elapsed: 00:45:25
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 44023 steps/s (collection: 2.108s, learning 0.125s)
             Mean action noise std: 3.89
          Mean value_function loss: 71.8649
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.7064
                       Mean reward: 739.17
               Mean episode length: 236.41
    Episode_Reward/reaching_object: 1.1919
    Episode_Reward/rotating_object: 140.0679
        Episode_Reward/action_rate: -0.0900
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.23s
                      Time elapsed: 00:45:28
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 45465 steps/s (collection: 2.049s, learning 0.113s)
             Mean action noise std: 3.89
          Mean value_function loss: 84.3680
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 70.7209
                       Mean reward: 698.04
               Mean episode length: 226.95
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 143.9872
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.16s
                      Time elapsed: 00:45:30
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 43864 steps/s (collection: 2.128s, learning 0.113s)
             Mean action noise std: 3.90
          Mean value_function loss: 81.8499
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.7313
                       Mean reward: 702.68
               Mean episode length: 229.46
    Episode_Reward/reaching_object: 1.2104
    Episode_Reward/rotating_object: 142.0753
        Episode_Reward/action_rate: -0.0901
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.24s
                      Time elapsed: 00:45:32
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 45579 steps/s (collection: 2.046s, learning 0.110s)
             Mean action noise std: 3.90
          Mean value_function loss: 78.0698
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 70.7471
                       Mean reward: 702.61
               Mean episode length: 233.23
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 141.9659
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.16s
                      Time elapsed: 00:45:34
                               ETA: 00:10:07

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 46098 steps/s (collection: 2.022s, learning 0.110s)
             Mean action noise std: 3.90
          Mean value_function loss: 72.9882
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 70.7647
                       Mean reward: 724.70
               Mean episode length: 234.64
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 144.5178
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.13s
                      Time elapsed: 00:45:36
                               ETA: 00:10:05

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 46547 steps/s (collection: 2.002s, learning 0.110s)
             Mean action noise std: 3.91
          Mean value_function loss: 73.7171
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.7840
                       Mean reward: 755.52
               Mean episode length: 237.92
    Episode_Reward/reaching_object: 1.2318
    Episode_Reward/rotating_object: 149.0209
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.11s
                      Time elapsed: 00:45:38
                               ETA: 00:10:03

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 45862 steps/s (collection: 2.033s, learning 0.111s)
             Mean action noise std: 3.91
          Mean value_function loss: 87.0185
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.8056
                       Mean reward: 690.25
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 140.1698
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.14s
                      Time elapsed: 00:45:41
                               ETA: 00:10:01

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 46325 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 3.91
          Mean value_function loss: 67.6412
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.8288
                       Mean reward: 728.96
               Mean episode length: 240.84
    Episode_Reward/reaching_object: 1.2260
    Episode_Reward/rotating_object: 145.2154
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.12s
                      Time elapsed: 00:45:43
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 46506 steps/s (collection: 2.003s, learning 0.110s)
             Mean action noise std: 3.91
          Mean value_function loss: 69.6508
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 70.8488
                       Mean reward: 728.37
               Mean episode length: 236.12
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 141.9545
        Episode_Reward/action_rate: -0.0910
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.11s
                      Time elapsed: 00:45:45
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 46198 steps/s (collection: 2.017s, learning 0.110s)
             Mean action noise std: 3.92
          Mean value_function loss: 83.5511
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 70.8646
                       Mean reward: 723.43
               Mean episode length: 240.25
    Episode_Reward/reaching_object: 1.2182
    Episode_Reward/rotating_object: 141.2718
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.13s
                      Time elapsed: 00:45:47
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 43140 steps/s (collection: 2.154s, learning 0.125s)
             Mean action noise std: 3.92
          Mean value_function loss: 75.8273
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.8839
                       Mean reward: 727.04
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.2229
    Episode_Reward/rotating_object: 142.8771
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.28s
                      Time elapsed: 00:45:49
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 44152 steps/s (collection: 2.116s, learning 0.110s)
             Mean action noise std: 3.92
          Mean value_function loss: 91.0837
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 70.9047
                       Mean reward: 688.61
               Mean episode length: 222.09
    Episode_Reward/reaching_object: 1.1742
    Episode_Reward/rotating_object: 136.7443
        Episode_Reward/action_rate: -0.0885
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.23s
                      Time elapsed: 00:45:51
                               ETA: 00:09:50

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 43050 steps/s (collection: 2.171s, learning 0.113s)
             Mean action noise std: 3.92
          Mean value_function loss: 69.3119
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 70.9187
                       Mean reward: 712.82
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 142.6927
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.28s
                      Time elapsed: 00:45:54
                               ETA: 00:09:47

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 42031 steps/s (collection: 2.226s, learning 0.113s)
             Mean action noise std: 3.93
          Mean value_function loss: 82.4573
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 70.9357
                       Mean reward: 740.75
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 1.2308
    Episode_Reward/rotating_object: 145.9484
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.34s
                      Time elapsed: 00:45:56
                               ETA: 00:09:45

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 43041 steps/s (collection: 2.168s, learning 0.116s)
             Mean action noise std: 3.93
          Mean value_function loss: 79.4160
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 70.9577
                       Mean reward: 686.98
               Mean episode length: 233.86
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 141.2797
        Episode_Reward/action_rate: -0.0918
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.28s
                      Time elapsed: 00:45:58
                               ETA: 00:09:43

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 43431 steps/s (collection: 2.152s, learning 0.111s)
             Mean action noise std: 3.93
          Mean value_function loss: 75.5876
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 70.9730
                       Mean reward: 727.22
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 142.2354
        Episode_Reward/action_rate: -0.0915
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.26s
                      Time elapsed: 00:46:01
                               ETA: 00:09:41

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 45370 steps/s (collection: 2.046s, learning 0.121s)
             Mean action noise std: 3.94
          Mean value_function loss: 67.8172
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 70.9892
                       Mean reward: 736.15
               Mean episode length: 238.03
    Episode_Reward/reaching_object: 1.2003
    Episode_Reward/rotating_object: 141.9431
        Episode_Reward/action_rate: -0.0911
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.17s
                      Time elapsed: 00:46:03
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 45682 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 3.94
          Mean value_function loss: 89.8202
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.0018
                       Mean reward: 701.09
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 1.2093
    Episode_Reward/rotating_object: 140.9214
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.15s
                      Time elapsed: 00:46:05
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 45234 steps/s (collection: 2.043s, learning 0.130s)
             Mean action noise std: 3.94
          Mean value_function loss: 80.2688
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.0159
                       Mean reward: 732.06
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 141.4247
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.17s
                      Time elapsed: 00:46:07
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 45053 steps/s (collection: 2.046s, learning 0.136s)
             Mean action noise std: 3.94
          Mean value_function loss: 72.9864
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.0297
                       Mean reward: 739.62
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 141.5705
        Episode_Reward/action_rate: -0.0935
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.18s
                      Time elapsed: 00:46:09
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 44324 steps/s (collection: 2.090s, learning 0.128s)
             Mean action noise std: 3.95
          Mean value_function loss: 70.0506
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 71.0482
                       Mean reward: 718.91
               Mean episode length: 233.99
    Episode_Reward/reaching_object: 1.2506
    Episode_Reward/rotating_object: 144.3707
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.22s
                      Time elapsed: 00:46:12
                               ETA: 00:09:29

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 43504 steps/s (collection: 2.144s, learning 0.115s)
             Mean action noise std: 3.95
          Mean value_function loss: 83.2028
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.0684
                       Mean reward: 691.24
               Mean episode length: 232.83
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 143.0192
        Episode_Reward/action_rate: -0.0928
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.26s
                      Time elapsed: 00:46:14
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 44081 steps/s (collection: 2.118s, learning 0.112s)
             Mean action noise std: 3.95
          Mean value_function loss: 75.2795
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.0885
                       Mean reward: 673.86
               Mean episode length: 228.01
    Episode_Reward/reaching_object: 1.2137
    Episode_Reward/rotating_object: 140.0659
        Episode_Reward/action_rate: -0.0921
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.23s
                      Time elapsed: 00:46:16
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 43423 steps/s (collection: 2.149s, learning 0.115s)
             Mean action noise std: 3.95
          Mean value_function loss: 71.4670
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 71.1060
                       Mean reward: 746.72
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 142.7479
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.26s
                      Time elapsed: 00:46:18
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 45595 steps/s (collection: 2.041s, learning 0.115s)
             Mean action noise std: 3.96
          Mean value_function loss: 70.8798
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.1214
                       Mean reward: 664.00
               Mean episode length: 222.77
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 140.1159
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.16s
                      Time elapsed: 00:46:20
                               ETA: 00:09:21

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 44837 steps/s (collection: 2.082s, learning 0.111s)
             Mean action noise std: 3.96
          Mean value_function loss: 67.0694
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.1410
                       Mean reward: 742.22
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.2164
    Episode_Reward/rotating_object: 142.5301
        Episode_Reward/action_rate: -0.0927
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.19s
                      Time elapsed: 00:46:23
                               ETA: 00:09:18

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 46262 steps/s (collection: 2.013s, learning 0.112s)
             Mean action noise std: 3.96
          Mean value_function loss: 69.8724
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.1593
                       Mean reward: 729.51
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 143.3927
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.12s
                      Time elapsed: 00:46:25
                               ETA: 00:09:16

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 46446 steps/s (collection: 2.005s, learning 0.112s)
             Mean action noise std: 3.97
          Mean value_function loss: 61.9321
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 71.1842
                       Mean reward: 706.05
               Mean episode length: 229.75
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 139.8568
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.12s
                      Time elapsed: 00:46:27
                               ETA: 00:09:14

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 47145 steps/s (collection: 1.973s, learning 0.112s)
             Mean action noise std: 3.97
          Mean value_function loss: 65.9622
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 71.1995
                       Mean reward: 741.02
               Mean episode length: 240.05
    Episode_Reward/reaching_object: 1.2447
    Episode_Reward/rotating_object: 145.0251
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.09s
                      Time elapsed: 00:46:29
                               ETA: 00:09:12

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 46743 steps/s (collection: 1.991s, learning 0.112s)
             Mean action noise std: 3.97
          Mean value_function loss: 77.0005
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 71.2125
                       Mean reward: 691.19
               Mean episode length: 233.94
    Episode_Reward/reaching_object: 1.2143
    Episode_Reward/rotating_object: 141.2132
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.10s
                      Time elapsed: 00:46:31
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 46543 steps/s (collection: 1.996s, learning 0.116s)
             Mean action noise std: 3.97
          Mean value_function loss: 68.8619
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 71.2269
                       Mean reward: 730.04
               Mean episode length: 239.74
    Episode_Reward/reaching_object: 1.2358
    Episode_Reward/rotating_object: 144.2891
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.11s
                      Time elapsed: 00:46:33
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 46562 steps/s (collection: 2.000s, learning 0.112s)
             Mean action noise std: 3.98
          Mean value_function loss: 73.0662
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.2403
                       Mean reward: 710.28
               Mean episode length: 228.62
    Episode_Reward/reaching_object: 1.2215
    Episode_Reward/rotating_object: 144.8912
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.11s
                      Time elapsed: 00:46:35
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 46018 steps/s (collection: 2.023s, learning 0.113s)
             Mean action noise std: 3.98
          Mean value_function loss: 79.6651
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.2551
                       Mean reward: 684.56
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.2276
    Episode_Reward/rotating_object: 142.8724
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.14s
                      Time elapsed: 00:46:37
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 46027 steps/s (collection: 2.021s, learning 0.115s)
             Mean action noise std: 3.98
          Mean value_function loss: 90.8618
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.2756
                       Mean reward: 749.68
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 143.2197
        Episode_Reward/action_rate: -0.0946
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.14s
                      Time elapsed: 00:46:40
                               ETA: 00:09:00

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 45232 steps/s (collection: 2.058s, learning 0.115s)
             Mean action noise std: 3.98
          Mean value_function loss: 74.4462
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 71.2930
                       Mean reward: 733.62
               Mean episode length: 236.49
    Episode_Reward/reaching_object: 1.2109
    Episode_Reward/rotating_object: 144.0530
        Episode_Reward/action_rate: -0.0947
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.17s
                      Time elapsed: 00:46:42
                               ETA: 00:08:58

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 42355 steps/s (collection: 2.206s, learning 0.115s)
             Mean action noise std: 3.99
          Mean value_function loss: 66.3557
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 71.3099
                       Mean reward: 736.33
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.2057
    Episode_Reward/rotating_object: 142.9916
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.32s
                      Time elapsed: 00:46:44
                               ETA: 00:08:56

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 42568 steps/s (collection: 2.196s, learning 0.113s)
             Mean action noise std: 3.99
          Mean value_function loss: 70.8421
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.3277
                       Mean reward: 752.83
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.2118
    Episode_Reward/rotating_object: 144.3988
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.31s
                      Time elapsed: 00:46:46
                               ETA: 00:08:54

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 44126 steps/s (collection: 2.115s, learning 0.112s)
             Mean action noise std: 3.99
          Mean value_function loss: 72.1535
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.3421
                       Mean reward: 712.16
               Mean episode length: 232.28
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 140.5623
        Episode_Reward/action_rate: -0.0937
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.23s
                      Time elapsed: 00:46:49
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 44852 steps/s (collection: 2.079s, learning 0.113s)
             Mean action noise std: 3.99
          Mean value_function loss: 64.0750
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 71.3487
                       Mean reward: 746.54
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.2294
    Episode_Reward/rotating_object: 145.7191
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.19s
                      Time elapsed: 00:46:51
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 46072 steps/s (collection: 2.020s, learning 0.114s)
             Mean action noise std: 4.00
          Mean value_function loss: 73.9822
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.3603
                       Mean reward: 703.32
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 141.5194
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.13s
                      Time elapsed: 00:46:53
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 45800 steps/s (collection: 2.034s, learning 0.112s)
             Mean action noise std: 4.00
          Mean value_function loss: 71.4450
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.3765
                       Mean reward: 753.31
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 1.2105
    Episode_Reward/rotating_object: 144.0876
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.15s
                      Time elapsed: 00:46:55
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 44279 steps/s (collection: 2.108s, learning 0.112s)
             Mean action noise std: 4.00
          Mean value_function loss: 77.2639
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.3929
                       Mean reward: 764.27
               Mean episode length: 245.19
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 142.8453
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.22s
                      Time elapsed: 00:46:57
                               ETA: 00:08:43

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 45760 steps/s (collection: 2.033s, learning 0.115s)
             Mean action noise std: 4.00
          Mean value_function loss: 56.9595
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 71.4125
                       Mean reward: 718.17
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 1.2258
    Episode_Reward/rotating_object: 142.2132
        Episode_Reward/action_rate: -0.0971
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.15s
                      Time elapsed: 00:46:59
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 45733 steps/s (collection: 2.039s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 61.7135
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.4302
                       Mean reward: 755.84
               Mean episode length: 241.24
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 145.4617
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.15s
                      Time elapsed: 00:47:02
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 45319 steps/s (collection: 2.056s, learning 0.113s)
             Mean action noise std: 4.01
          Mean value_function loss: 79.2695
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.4430
                       Mean reward: 690.14
               Mean episode length: 227.19
    Episode_Reward/reaching_object: 1.2139
    Episode_Reward/rotating_object: 144.6129
        Episode_Reward/action_rate: -0.0962
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.17s
                      Time elapsed: 00:47:04
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 45796 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 73.7399
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 71.4544
                       Mean reward: 741.75
               Mean episode length: 242.95
    Episode_Reward/reaching_object: 1.2089
    Episode_Reward/rotating_object: 141.3852
        Episode_Reward/action_rate: -0.0955
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.15s
                      Time elapsed: 00:47:06
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 46106 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 72.6108
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.4640
                       Mean reward: 742.29
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.2062
    Episode_Reward/rotating_object: 143.9070
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.13s
                      Time elapsed: 00:47:08
                               ETA: 00:08:31

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 46396 steps/s (collection: 2.008s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 57.0998
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.4793
                       Mean reward: 723.57
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.2094
    Episode_Reward/rotating_object: 143.1891
        Episode_Reward/action_rate: -0.0959
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.12s
                      Time elapsed: 00:47:10
                               ETA: 00:08:29

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 46249 steps/s (collection: 2.015s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 73.1791
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 71.4911
                       Mean reward: 743.27
               Mean episode length: 239.96
    Episode_Reward/reaching_object: 1.2379
    Episode_Reward/rotating_object: 144.7470
        Episode_Reward/action_rate: -0.0982
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.13s
                      Time elapsed: 00:47:12
                               ETA: 00:08:27

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 46319 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 81.8865
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 71.5033
                       Mean reward: 708.16
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.1988
    Episode_Reward/rotating_object: 139.9913
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.12s
                      Time elapsed: 00:47:14
                               ETA: 00:08:25

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 46205 steps/s (collection: 2.017s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 64.1556
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.5223
                       Mean reward: 718.09
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.2123
    Episode_Reward/rotating_object: 143.8047
        Episode_Reward/action_rate: -0.0969
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.13s
                      Time elapsed: 00:47:17
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 46971 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 4.02
          Mean value_function loss: 64.4527
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.5338
                       Mean reward: 722.21
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.2041
    Episode_Reward/rotating_object: 143.7770
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.09s
                      Time elapsed: 00:47:19
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 46610 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 68.3207
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.5497
                       Mean reward: 707.87
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 142.6513
        Episode_Reward/action_rate: -0.0974
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.11s
                      Time elapsed: 00:47:21
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 47036 steps/s (collection: 1.979s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 68.9124
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.5673
                       Mean reward: 704.83
               Mean episode length: 229.73
    Episode_Reward/reaching_object: 1.2248
    Episode_Reward/rotating_object: 145.3935
        Episode_Reward/action_rate: -0.0980
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.09s
                      Time elapsed: 00:47:23
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 46849 steps/s (collection: 1.987s, learning 0.111s)
             Mean action noise std: 4.03
          Mean value_function loss: 70.4520
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 71.5792
                       Mean reward: 699.45
               Mean episode length: 231.66
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 143.9170
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.10s
                      Time elapsed: 00:47:25
                               ETA: 00:08:13

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 45549 steps/s (collection: 2.043s, learning 0.115s)
             Mean action noise std: 4.03
          Mean value_function loss: 69.5067
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.5936
                       Mean reward: 734.33
               Mean episode length: 241.08
    Episode_Reward/reaching_object: 1.2194
    Episode_Reward/rotating_object: 144.3683
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.16s
                      Time elapsed: 00:47:27
                               ETA: 00:08:11

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 45609 steps/s (collection: 2.042s, learning 0.114s)
             Mean action noise std: 4.03
          Mean value_function loss: 78.2507
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 71.6121
                       Mean reward: 748.56
               Mean episode length: 241.42
    Episode_Reward/reaching_object: 1.2101
    Episode_Reward/rotating_object: 143.7074
        Episode_Reward/action_rate: -0.0972
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.16s
                      Time elapsed: 00:47:29
                               ETA: 00:08:09

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 45867 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 4.04
          Mean value_function loss: 76.2385
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 71.6215
                       Mean reward: 685.34
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 136.8496
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.14s
                      Time elapsed: 00:47:31
                               ETA: 00:08:07

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 45853 steps/s (collection: 2.020s, learning 0.124s)
             Mean action noise std: 4.04
          Mean value_function loss: 69.0265
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.6396
                       Mean reward: 768.76
               Mean episode length: 242.72
    Episode_Reward/reaching_object: 1.2425
    Episode_Reward/rotating_object: 146.7516
        Episode_Reward/action_rate: -0.0998
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.14s
                      Time elapsed: 00:47:34
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 45797 steps/s (collection: 2.022s, learning 0.125s)
             Mean action noise std: 4.04
          Mean value_function loss: 72.2745
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.6572
                       Mean reward: 769.62
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 145.1679
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.15s
                      Time elapsed: 00:47:36
                               ETA: 00:08:02

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 45254 steps/s (collection: 2.049s, learning 0.124s)
             Mean action noise std: 4.05
          Mean value_function loss: 59.3959
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.6701
                       Mean reward: 773.87
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 146.7225
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.17s
                      Time elapsed: 00:47:38
                               ETA: 00:08:00

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 44233 steps/s (collection: 2.105s, learning 0.117s)
             Mean action noise std: 4.05
          Mean value_function loss: 75.7552
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.6806
                       Mean reward: 708.54
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 1.2300
    Episode_Reward/rotating_object: 143.4943
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.22s
                      Time elapsed: 00:47:40
                               ETA: 00:07:58

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 44551 steps/s (collection: 2.093s, learning 0.113s)
             Mean action noise std: 4.05
          Mean value_function loss: 63.8095
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.6918
                       Mean reward: 754.37
               Mean episode length: 239.46
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 148.3852
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.21s
                      Time elapsed: 00:47:42
                               ETA: 00:07:56

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 44506 steps/s (collection: 2.096s, learning 0.113s)
             Mean action noise std: 4.05
          Mean value_function loss: 71.7997
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 71.7072
                       Mean reward: 716.09
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.2161
    Episode_Reward/rotating_object: 143.5230
        Episode_Reward/action_rate: -0.0988
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.21s
                      Time elapsed: 00:47:44
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 44243 steps/s (collection: 2.106s, learning 0.116s)
             Mean action noise std: 4.05
          Mean value_function loss: 60.7057
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 71.7189
                       Mean reward: 762.66
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 1.2433
    Episode_Reward/rotating_object: 149.2752
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.22s
                      Time elapsed: 00:47:47
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 45589 steps/s (collection: 2.043s, learning 0.113s)
             Mean action noise std: 4.05
          Mean value_function loss: 74.7899
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 71.7370
                       Mean reward: 707.54
               Mean episode length: 238.14
    Episode_Reward/reaching_object: 1.2295
    Episode_Reward/rotating_object: 145.0515
        Episode_Reward/action_rate: -0.1001
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.16s
                      Time elapsed: 00:47:49
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 45153 steps/s (collection: 2.063s, learning 0.115s)
             Mean action noise std: 4.06
          Mean value_function loss: 75.6876
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 71.7523
                       Mean reward: 723.09
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 1.2151
    Episode_Reward/rotating_object: 144.5885
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.18s
                      Time elapsed: 00:47:51
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 45629 steps/s (collection: 2.041s, learning 0.114s)
             Mean action noise std: 4.06
          Mean value_function loss: 69.6339
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.7647
                       Mean reward: 693.79
               Mean episode length: 235.42
    Episode_Reward/reaching_object: 1.2218
    Episode_Reward/rotating_object: 143.6080
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.15s
                      Time elapsed: 00:47:53
                               ETA: 00:07:44

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 45710 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 4.06
          Mean value_function loss: 69.1710
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.7798
                       Mean reward: 694.48
               Mean episode length: 234.44
    Episode_Reward/reaching_object: 1.1914
    Episode_Reward/rotating_object: 138.2012
        Episode_Reward/action_rate: -0.0983
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.15s
                      Time elapsed: 00:47:55
                               ETA: 00:07:42

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 45393 steps/s (collection: 2.050s, learning 0.115s)
             Mean action noise std: 4.06
          Mean value_function loss: 50.2138
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 71.7971
                       Mean reward: 747.50
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 1.2365
    Episode_Reward/rotating_object: 145.5965
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.17s
                      Time elapsed: 00:47:57
                               ETA: 00:07:40

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 45829 steps/s (collection: 2.034s, learning 0.111s)
             Mean action noise std: 4.07
          Mean value_function loss: 52.1510
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.8122
                       Mean reward: 753.35
               Mean episode length: 244.90
    Episode_Reward/reaching_object: 1.2389
    Episode_Reward/rotating_object: 148.2589
        Episode_Reward/action_rate: -0.1015
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.15s
                      Time elapsed: 00:48:00
                               ETA: 00:07:38

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 46640 steps/s (collection: 1.996s, learning 0.112s)
             Mean action noise std: 4.07
          Mean value_function loss: 53.1004
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 71.8250
                       Mean reward: 728.42
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 1.2262
    Episode_Reward/rotating_object: 146.0917
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.11s
                      Time elapsed: 00:48:02
                               ETA: 00:07:35

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 46580 steps/s (collection: 1.999s, learning 0.111s)
             Mean action noise std: 4.07
          Mean value_function loss: 73.8852
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 71.8340
                       Mean reward: 737.44
               Mean episode length: 240.34
    Episode_Reward/reaching_object: 1.2420
    Episode_Reward/rotating_object: 146.8210
        Episode_Reward/action_rate: -0.1017
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.11s
                      Time elapsed: 00:48:04
                               ETA: 00:07:33

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 46236 steps/s (collection: 2.014s, learning 0.112s)
             Mean action noise std: 4.07
          Mean value_function loss: 72.5941
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.8482
                       Mean reward: 761.13
               Mean episode length: 240.83
    Episode_Reward/reaching_object: 1.2032
    Episode_Reward/rotating_object: 143.0771
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.13s
                      Time elapsed: 00:48:06
                               ETA: 00:07:31

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 46663 steps/s (collection: 1.995s, learning 0.112s)
             Mean action noise std: 4.08
          Mean value_function loss: 58.1470
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 71.8677
                       Mean reward: 722.89
               Mean episode length: 237.68
    Episode_Reward/reaching_object: 1.2485
    Episode_Reward/rotating_object: 147.4335
        Episode_Reward/action_rate: -0.1022
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.11s
                      Time elapsed: 00:48:08
                               ETA: 00:07:29

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 46660 steps/s (collection: 1.995s, learning 0.112s)
             Mean action noise std: 4.08
          Mean value_function loss: 58.0153
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 71.8834
                       Mean reward: 722.14
               Mean episode length: 239.91
    Episode_Reward/reaching_object: 1.2280
    Episode_Reward/rotating_object: 142.1925
        Episode_Reward/action_rate: -0.1014
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.11s
                      Time elapsed: 00:48:10
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 46416 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 4.08
          Mean value_function loss: 67.7841
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 71.8956
                       Mean reward: 730.35
               Mean episode length: 237.02
    Episode_Reward/reaching_object: 1.2164
    Episode_Reward/rotating_object: 143.9898
        Episode_Reward/action_rate: -0.1004
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.12s
                      Time elapsed: 00:48:12
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 45534 steps/s (collection: 2.045s, learning 0.114s)
             Mean action noise std: 4.08
          Mean value_function loss: 64.3117
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 71.9054
                       Mean reward: 720.51
               Mean episode length: 240.22
    Episode_Reward/reaching_object: 1.2467
    Episode_Reward/rotating_object: 144.8467
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.16s
                      Time elapsed: 00:48:14
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 45799 steps/s (collection: 2.033s, learning 0.114s)
             Mean action noise std: 4.08
          Mean value_function loss: 52.0082
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.9189
                       Mean reward: 751.61
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 147.6441
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.15s
                      Time elapsed: 00:48:17
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 45592 steps/s (collection: 2.042s, learning 0.114s)
             Mean action noise std: 4.09
          Mean value_function loss: 70.2373
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 71.9350
                       Mean reward: 735.85
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.2171
    Episode_Reward/rotating_object: 140.3365
        Episode_Reward/action_rate: -0.1005
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.16s
                      Time elapsed: 00:48:19
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 45183 steps/s (collection: 2.061s, learning 0.115s)
             Mean action noise std: 4.09
          Mean value_function loss: 78.0759
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 71.9466
                       Mean reward: 691.80
               Mean episode length: 230.78
    Episode_Reward/reaching_object: 1.2327
    Episode_Reward/rotating_object: 142.8420
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.18s
                      Time elapsed: 00:48:21
                               ETA: 00:07:15

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 45603 steps/s (collection: 2.044s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 82.0922
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 71.9544
                       Mean reward: 728.62
               Mean episode length: 237.93
    Episode_Reward/reaching_object: 1.2221
    Episode_Reward/rotating_object: 141.3783
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.16s
                      Time elapsed: 00:48:23
                               ETA: 00:07:13

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 45219 steps/s (collection: 2.059s, learning 0.115s)
             Mean action noise std: 4.09
          Mean value_function loss: 85.8808
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 71.9637
                       Mean reward: 677.87
               Mean episode length: 231.16
    Episode_Reward/reaching_object: 1.2137
    Episode_Reward/rotating_object: 139.5987
        Episode_Reward/action_rate: -0.0991
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.17s
                      Time elapsed: 00:48:25
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 45638 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 4.09
          Mean value_function loss: 72.3240
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 71.9795
                       Mean reward: 769.10
               Mean episode length: 246.38
    Episode_Reward/reaching_object: 1.2631
    Episode_Reward/rotating_object: 146.5989
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.15s
                      Time elapsed: 00:48:27
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 45783 steps/s (collection: 2.034s, learning 0.114s)
             Mean action noise std: 4.10
          Mean value_function loss: 66.7888
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 71.9999
                       Mean reward: 729.22
               Mean episode length: 237.47
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 145.3144
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.15s
                      Time elapsed: 00:48:30
                               ETA: 00:07:06

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 45576 steps/s (collection: 2.044s, learning 0.113s)
             Mean action noise std: 4.10
          Mean value_function loss: 77.8219
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.0156
                       Mean reward: 696.53
               Mean episode length: 227.97
    Episode_Reward/reaching_object: 1.2205
    Episode_Reward/rotating_object: 140.8123
        Episode_Reward/action_rate: -0.0999
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.16s
                      Time elapsed: 00:48:32
                               ETA: 00:07:04

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 45535 steps/s (collection: 2.045s, learning 0.114s)
             Mean action noise std: 4.10
          Mean value_function loss: 72.0470
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.0284
                       Mean reward: 731.70
               Mean episode length: 236.30
    Episode_Reward/reaching_object: 1.2633
    Episode_Reward/rotating_object: 146.4036
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.16s
                      Time elapsed: 00:48:34
                               ETA: 00:07:02

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 45154 steps/s (collection: 2.066s, learning 0.112s)
             Mean action noise std: 4.11
          Mean value_function loss: 77.3785
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.0454
                       Mean reward: 740.07
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 142.4805
        Episode_Reward/action_rate: -0.1009
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.18s
                      Time elapsed: 00:48:36
                               ETA: 00:07:00

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 45986 steps/s (collection: 2.025s, learning 0.113s)
             Mean action noise std: 4.11
          Mean value_function loss: 78.9815
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 72.0653
                       Mean reward: 705.52
               Mean episode length: 233.40
    Episode_Reward/reaching_object: 1.2519
    Episode_Reward/rotating_object: 146.9961
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.14s
                      Time elapsed: 00:48:38
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 45622 steps/s (collection: 2.041s, learning 0.114s)
             Mean action noise std: 4.11
          Mean value_function loss: 71.3911
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.0822
                       Mean reward: 748.82
               Mean episode length: 241.40
    Episode_Reward/reaching_object: 1.2410
    Episode_Reward/rotating_object: 146.0510
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.15s
                      Time elapsed: 00:48:40
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 45441 steps/s (collection: 2.052s, learning 0.111s)
             Mean action noise std: 4.11
          Mean value_function loss: 67.1090
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 72.0943
                       Mean reward: 728.67
               Mean episode length: 234.81
    Episode_Reward/reaching_object: 1.2035
    Episode_Reward/rotating_object: 141.4898
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.16s
                      Time elapsed: 00:48:43
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 45531 steps/s (collection: 2.044s, learning 0.115s)
             Mean action noise std: 4.12
          Mean value_function loss: 73.0644
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 72.1083
                       Mean reward: 706.74
               Mean episode length: 235.73
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 140.1889
        Episode_Reward/action_rate: -0.1012
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.16s
                      Time elapsed: 00:48:45
                               ETA: 00:06:51

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 44898 steps/s (collection: 2.076s, learning 0.113s)
             Mean action noise std: 4.12
          Mean value_function loss: 67.2722
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 72.1245
                       Mean reward: 757.39
               Mean episode length: 243.08
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 144.1985
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.19s
                      Time elapsed: 00:48:47
                               ETA: 00:06:48

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 43134 steps/s (collection: 2.168s, learning 0.111s)
             Mean action noise std: 4.12
          Mean value_function loss: 54.7250
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 72.1310
                       Mean reward: 759.84
               Mean episode length: 241.23
    Episode_Reward/reaching_object: 1.2698
    Episode_Reward/rotating_object: 151.3893
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.28s
                      Time elapsed: 00:48:49
                               ETA: 00:06:46

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 43089 steps/s (collection: 2.171s, learning 0.111s)
             Mean action noise std: 4.12
          Mean value_function loss: 87.7500
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 72.1383
                       Mean reward: 715.36
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.2029
    Episode_Reward/rotating_object: 139.1430
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.28s
                      Time elapsed: 00:48:51
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 44211 steps/s (collection: 2.113s, learning 0.111s)
             Mean action noise std: 4.12
          Mean value_function loss: 61.1342
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.1516
                       Mean reward: 721.03
               Mean episode length: 238.11
    Episode_Reward/reaching_object: 1.2361
    Episode_Reward/rotating_object: 145.5495
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.22s
                      Time elapsed: 00:48:54
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 46602 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 4.13
          Mean value_function loss: 71.8496
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 72.1661
                       Mean reward: 740.50
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.2354
    Episode_Reward/rotating_object: 143.9675
        Episode_Reward/action_rate: -0.1044
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.11s
                      Time elapsed: 00:48:56
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 45866 steps/s (collection: 2.032s, learning 0.111s)
             Mean action noise std: 4.13
          Mean value_function loss: 69.3702
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.1847
                       Mean reward: 736.16
               Mean episode length: 240.02
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 143.3838
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.14s
                      Time elapsed: 00:48:58
                               ETA: 00:06:37

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 45780 steps/s (collection: 2.036s, learning 0.111s)
             Mean action noise std: 4.13
          Mean value_function loss: 64.3167
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.2029
                       Mean reward: 776.59
               Mean episode length: 244.60
    Episode_Reward/reaching_object: 1.2477
    Episode_Reward/rotating_object: 144.7355
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.15s
                      Time elapsed: 00:49:00
                               ETA: 00:06:35

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 45281 steps/s (collection: 2.059s, learning 0.112s)
             Mean action noise std: 4.13
          Mean value_function loss: 66.9786
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 72.2160
                       Mean reward: 696.95
               Mean episode length: 233.90
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 144.4669
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.17s
                      Time elapsed: 00:49:02
                               ETA: 00:06:33

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 44568 steps/s (collection: 2.080s, learning 0.125s)
             Mean action noise std: 4.13
          Mean value_function loss: 76.2701
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.2229
                       Mean reward: 725.92
               Mean episode length: 235.65
    Episode_Reward/reaching_object: 1.2179
    Episode_Reward/rotating_object: 141.1117
        Episode_Reward/action_rate: -0.1030
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.21s
                      Time elapsed: 00:49:04
                               ETA: 00:06:31

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 45213 steps/s (collection: 2.060s, learning 0.114s)
             Mean action noise std: 4.14
          Mean value_function loss: 63.9793
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.2346
                       Mean reward: 734.85
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 1.2340
    Episode_Reward/rotating_object: 144.3952
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.17s
                      Time elapsed: 00:49:07
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 45678 steps/s (collection: 2.037s, learning 0.115s)
             Mean action noise std: 4.14
          Mean value_function loss: 66.8783
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.2521
                       Mean reward: 728.68
               Mean episode length: 237.26
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 143.2886
        Episode_Reward/action_rate: -0.1032
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.15s
                      Time elapsed: 00:49:09
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 45863 steps/s (collection: 2.030s, learning 0.113s)
             Mean action noise std: 4.14
          Mean value_function loss: 86.4204
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.2691
                       Mean reward: 695.38
               Mean episode length: 230.40
    Episode_Reward/reaching_object: 1.2278
    Episode_Reward/rotating_object: 143.3442
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.14s
                      Time elapsed: 00:49:11
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 45833 steps/s (collection: 2.031s, learning 0.113s)
             Mean action noise std: 4.14
          Mean value_function loss: 75.3660
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 72.2847
                       Mean reward: 754.27
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 1.2292
    Episode_Reward/rotating_object: 143.1472
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.14s
                      Time elapsed: 00:49:13
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 45717 steps/s (collection: 2.037s, learning 0.113s)
             Mean action noise std: 4.15
          Mean value_function loss: 65.5635
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.2903
                       Mean reward: 727.97
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.2173
    Episode_Reward/rotating_object: 142.4928
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.15s
                      Time elapsed: 00:49:15
                               ETA: 00:06:20

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 45208 steps/s (collection: 2.061s, learning 0.113s)
             Mean action noise std: 4.15
          Mean value_function loss: 73.2457
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.3020
                       Mean reward: 699.03
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.2329
    Episode_Reward/rotating_object: 143.8893
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.17s
                      Time elapsed: 00:49:17
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 45907 steps/s (collection: 2.031s, learning 0.111s)
             Mean action noise std: 4.15
          Mean value_function loss: 68.5210
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.3213
                       Mean reward: 774.17
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 1.2461
    Episode_Reward/rotating_object: 147.3055
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.14s
                      Time elapsed: 00:49:20
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 46030 steps/s (collection: 2.022s, learning 0.114s)
             Mean action noise std: 4.15
          Mean value_function loss: 85.3350
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.3330
                       Mean reward: 754.63
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.2211
    Episode_Reward/rotating_object: 142.2860
        Episode_Reward/action_rate: -0.1037
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.14s
                      Time elapsed: 00:49:22
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 45113 steps/s (collection: 2.069s, learning 0.111s)
             Mean action noise std: 4.16
          Mean value_function loss: 68.9932
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.3481
                       Mean reward: 787.70
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 1.2503
    Episode_Reward/rotating_object: 149.4233
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 2.18s
                      Time elapsed: 00:49:24
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 45965 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 4.16
          Mean value_function loss: 53.3884
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.3623
                       Mean reward: 736.11
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 1.2446
    Episode_Reward/rotating_object: 143.8573
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 2.14s
                      Time elapsed: 00:49:26
                               ETA: 00:06:08

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 46121 steps/s (collection: 2.020s, learning 0.111s)
             Mean action noise std: 4.16
          Mean value_function loss: 56.8085
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 72.3753
                       Mean reward: 736.09
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.2404
    Episode_Reward/rotating_object: 148.0775
        Episode_Reward/action_rate: -0.1053
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 2.13s
                      Time elapsed: 00:49:28
                               ETA: 00:06:06

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 45392 steps/s (collection: 2.036s, learning 0.130s)
             Mean action noise std: 4.16
          Mean value_function loss: 65.2221
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.3907
                       Mean reward: 724.24
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 1.2508
    Episode_Reward/rotating_object: 147.3959
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 2.17s
                      Time elapsed: 00:49:30
                               ETA: 00:06:04

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 45441 steps/s (collection: 2.048s, learning 0.115s)
             Mean action noise std: 4.17
          Mean value_function loss: 82.3765
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 72.4071
                       Mean reward: 755.27
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 144.9830
        Episode_Reward/action_rate: -0.1057
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 2.16s
                      Time elapsed: 00:49:32
                               ETA: 00:06:02

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 45254 steps/s (collection: 2.058s, learning 0.114s)
             Mean action noise std: 4.17
          Mean value_function loss: 73.7684
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 72.4184
                       Mean reward: 761.18
               Mean episode length: 243.81
    Episode_Reward/reaching_object: 1.2570
    Episode_Reward/rotating_object: 149.2344
        Episode_Reward/action_rate: -0.1074
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 2.17s
                      Time elapsed: 00:49:35
                               ETA: 00:05:59

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 45803 steps/s (collection: 2.035s, learning 0.112s)
             Mean action noise std: 4.17
          Mean value_function loss: 79.6183
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.4300
                       Mean reward: 684.01
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 1.2196
    Episode_Reward/rotating_object: 140.8912
        Episode_Reward/action_rate: -0.1048
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 2.15s
                      Time elapsed: 00:49:37
                               ETA: 00:05:57

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 46010 steps/s (collection: 2.026s, learning 0.111s)
             Mean action noise std: 4.17
          Mean value_function loss: 70.0393
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.4484
                       Mean reward: 718.66
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.2375
    Episode_Reward/rotating_object: 145.5265
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 2.14s
                      Time elapsed: 00:49:39
                               ETA: 00:05:55

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 46318 steps/s (collection: 2.011s, learning 0.111s)
             Mean action noise std: 4.18
          Mean value_function loss: 78.0210
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 72.4699
                       Mean reward: 746.55
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.2363
    Episode_Reward/rotating_object: 145.1016
        Episode_Reward/action_rate: -0.1070
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 2.12s
                      Time elapsed: 00:49:41
                               ETA: 00:05:53

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 45381 steps/s (collection: 2.056s, learning 0.111s)
             Mean action noise std: 4.18
          Mean value_function loss: 76.2818
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.4810
                       Mean reward: 695.73
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 1.2310
    Episode_Reward/rotating_object: 142.5047
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.17s
                      Time elapsed: 00:49:43
                               ETA: 00:05:51

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 43220 steps/s (collection: 2.164s, learning 0.111s)
             Mean action noise std: 4.18
          Mean value_function loss: 78.2838
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.4904
                       Mean reward: 759.15
               Mean episode length: 236.84
    Episode_Reward/reaching_object: 1.2302
    Episode_Reward/rotating_object: 144.2424
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 2.27s
                      Time elapsed: 00:49:45
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 45696 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 4.18
          Mean value_function loss: 72.8206
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.5015
                       Mean reward: 726.55
               Mean episode length: 232.67
    Episode_Reward/reaching_object: 1.2342
    Episode_Reward/rotating_object: 145.2572
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.15s
                      Time elapsed: 00:49:48
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 46074 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 4.19
          Mean value_function loss: 83.7674
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.5186
                       Mean reward: 706.62
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 141.5294
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 2.13s
                      Time elapsed: 00:49:50
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 45826 steps/s (collection: 2.022s, learning 0.123s)
             Mean action noise std: 4.19
          Mean value_function loss: 73.0075
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.5378
                       Mean reward: 739.82
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 1.2457
    Episode_Reward/rotating_object: 145.8108
        Episode_Reward/action_rate: -0.1070
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.15s
                      Time elapsed: 00:49:52
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 45635 steps/s (collection: 2.042s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 67.8389
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.5579
                       Mean reward: 744.21
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 1.2447
    Episode_Reward/rotating_object: 142.9733
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.15s
                      Time elapsed: 00:49:54
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 45550 steps/s (collection: 2.045s, learning 0.113s)
             Mean action noise std: 4.19
          Mean value_function loss: 76.8333
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 72.5722
                       Mean reward: 725.23
               Mean episode length: 231.74
    Episode_Reward/reaching_object: 1.2583
    Episode_Reward/rotating_object: 147.0667
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 2.16s
                      Time elapsed: 00:49:56
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 46290 steps/s (collection: 2.013s, learning 0.110s)
             Mean action noise std: 4.20
          Mean value_function loss: 81.8835
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 72.5815
                       Mean reward: 735.38
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 141.6722
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 2.12s
                      Time elapsed: 00:49:58
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 46044 steps/s (collection: 2.022s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 47.3003
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 72.5890
                       Mean reward: 777.27
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.2559
    Episode_Reward/rotating_object: 146.9535
        Episode_Reward/action_rate: -0.1086
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 2.13s
                      Time elapsed: 00:50:00
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 45358 steps/s (collection: 2.054s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 76.2414
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 72.5963
                       Mean reward: 748.74
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 1.2510
    Episode_Reward/rotating_object: 146.3879
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 2.17s
                      Time elapsed: 00:50:03
                               ETA: 00:05:30

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 44184 steps/s (collection: 2.112s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 59.1169
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 72.6125
                       Mean reward: 738.23
               Mean episode length: 240.89
    Episode_Reward/reaching_object: 1.2528
    Episode_Reward/rotating_object: 147.2464
        Episode_Reward/action_rate: -0.1085
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 2.22s
                      Time elapsed: 00:50:05
                               ETA: 00:05:28

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 43630 steps/s (collection: 2.141s, learning 0.112s)
             Mean action noise std: 4.20
          Mean value_function loss: 67.4677
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 72.6285
                       Mean reward: 756.01
               Mean episode length: 236.88
    Episode_Reward/reaching_object: 1.2238
    Episode_Reward/rotating_object: 143.9165
        Episode_Reward/action_rate: -0.1070
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 2.25s
                      Time elapsed: 00:50:07
                               ETA: 00:05:26

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 45349 steps/s (collection: 2.055s, learning 0.113s)
             Mean action noise std: 4.21
          Mean value_function loss: 63.1497
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.6418
                       Mean reward: 723.06
               Mean episode length: 238.86
    Episode_Reward/reaching_object: 1.2385
    Episode_Reward/rotating_object: 142.6534
        Episode_Reward/action_rate: -0.1078
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.17s
                      Time elapsed: 00:50:09
                               ETA: 00:05:24

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 46125 steps/s (collection: 2.019s, learning 0.113s)
             Mean action noise std: 4.21
          Mean value_function loss: 67.5714
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 72.6563
                       Mean reward: 717.49
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.2426
    Episode_Reward/rotating_object: 144.8959
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 2.13s
                      Time elapsed: 00:50:11
                               ETA: 00:05:22

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 44721 steps/s (collection: 2.084s, learning 0.115s)
             Mean action noise std: 4.21
          Mean value_function loss: 62.9536
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.6724
                       Mean reward: 697.72
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 1.2589
    Episode_Reward/rotating_object: 145.7091
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 2.20s
                      Time elapsed: 00:50:14
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 45264 steps/s (collection: 2.056s, learning 0.116s)
             Mean action noise std: 4.21
          Mean value_function loss: 65.0930
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 72.6869
                       Mean reward: 752.25
               Mean episode length: 244.54
    Episode_Reward/reaching_object: 1.2489
    Episode_Reward/rotating_object: 143.1675
        Episode_Reward/action_rate: -0.1095
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 2.17s
                      Time elapsed: 00:50:16
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 41880 steps/s (collection: 2.219s, learning 0.128s)
             Mean action noise std: 4.22
          Mean value_function loss: 72.7642
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.6986
                       Mean reward: 730.49
               Mean episode length: 236.76
    Episode_Reward/reaching_object: 1.2444
    Episode_Reward/rotating_object: 146.4120
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.35s
                      Time elapsed: 00:50:18
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 41535 steps/s (collection: 2.241s, learning 0.126s)
             Mean action noise std: 4.22
          Mean value_function loss: 73.4138
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.7106
                       Mean reward: 750.38
               Mean episode length: 235.87
    Episode_Reward/reaching_object: 1.2500
    Episode_Reward/rotating_object: 147.7614
        Episode_Reward/action_rate: -0.1088
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 2.37s
                      Time elapsed: 00:50:20
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 41886 steps/s (collection: 2.230s, learning 0.117s)
             Mean action noise std: 4.22
          Mean value_function loss: 75.0035
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 72.7272
                       Mean reward: 734.44
               Mean episode length: 237.95
    Episode_Reward/reaching_object: 1.2533
    Episode_Reward/rotating_object: 145.9283
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 2.35s
                      Time elapsed: 00:50:23
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 46145 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 4.22
          Mean value_function loss: 81.4844
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.7419
                       Mean reward: 698.48
               Mean episode length: 226.39
    Episode_Reward/reaching_object: 1.2317
    Episode_Reward/rotating_object: 142.9277
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 2.13s
                      Time elapsed: 00:50:25
                               ETA: 00:05:08

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 46671 steps/s (collection: 1.995s, learning 0.111s)
             Mean action noise std: 4.22
          Mean value_function loss: 71.4410
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.7553
                       Mean reward: 757.60
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.2556
    Episode_Reward/rotating_object: 148.8671
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 2.11s
                      Time elapsed: 00:50:27
                               ETA: 00:05:06

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 46506 steps/s (collection: 2.003s, learning 0.111s)
             Mean action noise std: 4.23
          Mean value_function loss: 75.7100
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.7688
                       Mean reward: 704.67
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 1.2436
    Episode_Reward/rotating_object: 143.6857
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 2.11s
                      Time elapsed: 00:50:29
                               ETA: 00:05:04

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 46598 steps/s (collection: 1.999s, learning 0.111s)
             Mean action noise std: 4.23
          Mean value_function loss: 61.9993
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.7827
                       Mean reward: 719.41
               Mean episode length: 231.06
    Episode_Reward/reaching_object: 1.2226
    Episode_Reward/rotating_object: 141.9147
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 2.11s
                      Time elapsed: 00:50:31
                               ETA: 00:05:02

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 46476 steps/s (collection: 2.002s, learning 0.113s)
             Mean action noise std: 4.23
          Mean value_function loss: 70.0650
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 72.7981
                       Mean reward: 751.47
               Mean episode length: 240.69
    Episode_Reward/reaching_object: 1.2545
    Episode_Reward/rotating_object: 146.7292
        Episode_Reward/action_rate: -0.1104
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 2.12s
                      Time elapsed: 00:50:33
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 46629 steps/s (collection: 1.997s, learning 0.112s)
             Mean action noise std: 4.23
          Mean value_function loss: 69.2349
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.8081
                       Mean reward: 732.94
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 144.2778
        Episode_Reward/action_rate: -0.1084
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 2.11s
                      Time elapsed: 00:50:36
                               ETA: 00:04:57

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 46619 steps/s (collection: 1.998s, learning 0.111s)
             Mean action noise std: 4.24
          Mean value_function loss: 62.0426
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 72.8190
                       Mean reward: 676.73
               Mean episode length: 226.02
    Episode_Reward/reaching_object: 1.2401
    Episode_Reward/rotating_object: 144.3234
        Episode_Reward/action_rate: -0.1095
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 2.11s
                      Time elapsed: 00:50:38
                               ETA: 00:04:55

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 45754 steps/s (collection: 2.032s, learning 0.116s)
             Mean action noise std: 4.24
          Mean value_function loss: 54.7950
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 72.8362
                       Mean reward: 741.98
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.2792
    Episode_Reward/rotating_object: 151.0641
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 18.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 2.15s
                      Time elapsed: 00:50:40
                               ETA: 00:04:53

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 45513 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 4.24
          Mean value_function loss: 57.8458
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.8471
                       Mean reward: 745.02
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 1.2564
    Episode_Reward/rotating_object: 143.4127
        Episode_Reward/action_rate: -0.1110
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 2.16s
                      Time elapsed: 00:50:42
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 44699 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 4.24
          Mean value_function loss: 76.2112
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.8599
                       Mean reward: 702.40
               Mean episode length: 225.70
    Episode_Reward/reaching_object: 1.2216
    Episode_Reward/rotating_object: 143.3784
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 2.20s
                      Time elapsed: 00:50:44
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 44959 steps/s (collection: 2.064s, learning 0.123s)
             Mean action noise std: 4.24
          Mean value_function loss: 66.4782
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.8713
                       Mean reward: 745.18
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2551
    Episode_Reward/rotating_object: 145.7331
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 2.19s
                      Time elapsed: 00:50:46
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 43606 steps/s (collection: 2.128s, learning 0.126s)
             Mean action noise std: 4.25
          Mean value_function loss: 64.9755
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 72.8823
                       Mean reward: 745.49
               Mean episode length: 241.47
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 144.2026
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 2.25s
                      Time elapsed: 00:50:49
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 44607 steps/s (collection: 2.088s, learning 0.116s)
             Mean action noise std: 4.25
          Mean value_function loss: 66.1857
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 72.8947
                       Mean reward: 742.91
               Mean episode length: 238.44
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 147.7131
        Episode_Reward/action_rate: -0.1107
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.20s
                      Time elapsed: 00:50:51
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 45474 steps/s (collection: 2.046s, learning 0.116s)
             Mean action noise std: 4.25
          Mean value_function loss: 71.0954
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.9090
                       Mean reward: 733.36
               Mean episode length: 239.94
    Episode_Reward/reaching_object: 1.2608
    Episode_Reward/rotating_object: 148.5273
        Episode_Reward/action_rate: -0.1116
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 2.16s
                      Time elapsed: 00:50:53
                               ETA: 00:04:39

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 45084 steps/s (collection: 2.066s, learning 0.114s)
             Mean action noise std: 4.25
          Mean value_function loss: 60.7954
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 72.9256
                       Mean reward: 719.61
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.2250
    Episode_Reward/rotating_object: 140.8959
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 2.18s
                      Time elapsed: 00:50:55
                               ETA: 00:04:37

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 46013 steps/s (collection: 2.021s, learning 0.115s)
             Mean action noise std: 4.26
          Mean value_function loss: 76.0477
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 72.9388
                       Mean reward: 752.36
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.2188
    Episode_Reward/rotating_object: 142.5751
        Episode_Reward/action_rate: -0.1093
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 2.14s
                      Time elapsed: 00:50:57
                               ETA: 00:04:35

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 45662 steps/s (collection: 2.039s, learning 0.114s)
             Mean action noise std: 4.26
          Mean value_function loss: 72.8966
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 72.9555
                       Mean reward: 732.27
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.2299
    Episode_Reward/rotating_object: 144.2172
        Episode_Reward/action_rate: -0.1097
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 2.15s
                      Time elapsed: 00:50:59
                               ETA: 00:04:33

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 45717 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 4.26
          Mean value_function loss: 70.4703
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 72.9721
                       Mean reward: 741.92
               Mean episode length: 237.18
    Episode_Reward/reaching_object: 1.2163
    Episode_Reward/rotating_object: 144.4237
        Episode_Reward/action_rate: -0.1092
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 2.15s
                      Time elapsed: 00:51:02
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 45275 steps/s (collection: 2.058s, learning 0.113s)
             Mean action noise std: 4.26
          Mean value_function loss: 82.7507
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 72.9779
                       Mean reward: 722.35
               Mean episode length: 231.25
    Episode_Reward/reaching_object: 1.1992
    Episode_Reward/rotating_object: 141.3340
        Episode_Reward/action_rate: -0.1082
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 2.17s
                      Time elapsed: 00:51:04
                               ETA: 00:04:28

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 45738 steps/s (collection: 2.035s, learning 0.114s)
             Mean action noise std: 4.26
          Mean value_function loss: 86.3932
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 72.9888
                       Mean reward: 716.79
               Mean episode length: 232.97
    Episode_Reward/reaching_object: 1.2209
    Episode_Reward/rotating_object: 143.9719
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 2.15s
                      Time elapsed: 00:51:06
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 45338 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 4.27
          Mean value_function loss: 75.7449
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.0091
                       Mean reward: 751.35
               Mean episode length: 241.96
    Episode_Reward/reaching_object: 1.2268
    Episode_Reward/rotating_object: 142.2294
        Episode_Reward/action_rate: -0.1103
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 2.17s
                      Time elapsed: 00:51:08
                               ETA: 00:04:24

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 45581 steps/s (collection: 2.046s, learning 0.111s)
             Mean action noise std: 4.27
          Mean value_function loss: 79.7958
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.0282
                       Mean reward: 727.96
               Mean episode length: 234.38
    Episode_Reward/reaching_object: 1.2152
    Episode_Reward/rotating_object: 143.4579
        Episode_Reward/action_rate: -0.1109
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.16s
                      Time elapsed: 00:51:10
                               ETA: 00:04:21

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 45403 steps/s (collection: 2.055s, learning 0.110s)
             Mean action noise std: 4.27
          Mean value_function loss: 97.4913
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.0457
                       Mean reward: 744.07
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.2183
    Episode_Reward/rotating_object: 141.2731
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 2.17s
                      Time elapsed: 00:51:12
                               ETA: 00:04:19

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 45968 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 4.28
          Mean value_function loss: 73.5072
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.0631
                       Mean reward: 712.36
               Mean episode length: 230.00
    Episode_Reward/reaching_object: 1.2142
    Episode_Reward/rotating_object: 142.7381
        Episode_Reward/action_rate: -0.1096
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 2.14s
                      Time elapsed: 00:51:15
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 46302 steps/s (collection: 2.013s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 84.1090
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 73.0756
                       Mean reward: 706.41
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 1.2098
    Episode_Reward/rotating_object: 139.3748
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 2.12s
                      Time elapsed: 00:51:17
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 45984 steps/s (collection: 2.027s, learning 0.111s)
             Mean action noise std: 4.28
          Mean value_function loss: 66.4434
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 73.0866
                       Mean reward: 716.49
               Mean episode length: 238.66
    Episode_Reward/reaching_object: 1.2149
    Episode_Reward/rotating_object: 142.7194
        Episode_Reward/action_rate: -0.1099
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 2.14s
                      Time elapsed: 00:51:19
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 45803 steps/s (collection: 2.036s, learning 0.110s)
             Mean action noise std: 4.28
          Mean value_function loss: 62.3502
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.0960
                       Mean reward: 764.51
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 1.2349
    Episode_Reward/rotating_object: 145.6890
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 2.15s
                      Time elapsed: 00:51:21
                               ETA: 00:04:10

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 46320 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 4.28
          Mean value_function loss: 79.6613
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 73.1067
                       Mean reward: 747.76
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.2422
    Episode_Reward/rotating_object: 144.4742
        Episode_Reward/action_rate: -0.1124
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 2.12s
                      Time elapsed: 00:51:23
                               ETA: 00:04:08

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 45659 steps/s (collection: 2.042s, learning 0.111s)
             Mean action noise std: 4.29
          Mean value_function loss: 73.5119
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.1174
                       Mean reward: 683.46
               Mean episode length: 224.83
    Episode_Reward/reaching_object: 1.2336
    Episode_Reward/rotating_object: 141.6452
        Episode_Reward/action_rate: -0.1115
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.15s
                      Time elapsed: 00:51:25
                               ETA: 00:04:06

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 46017 steps/s (collection: 2.010s, learning 0.126s)
             Mean action noise std: 4.29
          Mean value_function loss: 70.6182
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 73.1326
                       Mean reward: 721.11
               Mean episode length: 240.51
    Episode_Reward/reaching_object: 1.2417
    Episode_Reward/rotating_object: 143.6194
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 2.14s
                      Time elapsed: 00:51:27
                               ETA: 00:04:04

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 45231 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 4.29
          Mean value_function loss: 79.5888
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 73.1459
                       Mean reward: 706.01
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.2569
    Episode_Reward/rotating_object: 145.9633
        Episode_Reward/action_rate: -0.1133
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 2.17s
                      Time elapsed: 00:51:29
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 45195 steps/s (collection: 2.062s, learning 0.113s)
             Mean action noise std: 4.29
          Mean value_function loss: 67.3350
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 73.1591
                       Mean reward: 773.84
               Mean episode length: 242.94
    Episode_Reward/reaching_object: 1.2520
    Episode_Reward/rotating_object: 146.4153
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 2.18s
                      Time elapsed: 00:51:32
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 45490 steps/s (collection: 2.046s, learning 0.115s)
             Mean action noise std: 4.29
          Mean value_function loss: 60.1841
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 73.1672
                       Mean reward: 786.07
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 1.2831
    Episode_Reward/rotating_object: 151.5531
        Episode_Reward/action_rate: -0.1161
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 2.16s
                      Time elapsed: 00:51:34
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 44113 steps/s (collection: 2.115s, learning 0.113s)
             Mean action noise std: 4.30
          Mean value_function loss: 74.2725
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 73.1783
                       Mean reward: 694.94
               Mean episode length: 233.67
    Episode_Reward/reaching_object: 1.2427
    Episode_Reward/rotating_object: 141.4208
        Episode_Reward/action_rate: -0.1125
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 2.23s
                      Time elapsed: 00:51:36
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 45250 steps/s (collection: 2.058s, learning 0.114s)
             Mean action noise std: 4.30
          Mean value_function loss: 78.7074
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.1954
                       Mean reward: 709.18
               Mean episode length: 230.11
    Episode_Reward/reaching_object: 1.2459
    Episode_Reward/rotating_object: 146.1197
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 2.17s
                      Time elapsed: 00:51:38
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 45588 steps/s (collection: 2.042s, learning 0.114s)
             Mean action noise std: 4.30
          Mean value_function loss: 67.7854
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.2123
                       Mean reward: 722.21
               Mean episode length: 234.05
    Episode_Reward/reaching_object: 1.2388
    Episode_Reward/rotating_object: 143.7728
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 2.16s
                      Time elapsed: 00:51:40
                               ETA: 00:03:50

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 43773 steps/s (collection: 2.133s, learning 0.113s)
             Mean action noise std: 4.30
          Mean value_function loss: 84.2663
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.2234
                       Mean reward: 713.03
               Mean episode length: 230.86
    Episode_Reward/reaching_object: 1.2377
    Episode_Reward/rotating_object: 143.4918
        Episode_Reward/action_rate: -0.1121
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 2.25s
                      Time elapsed: 00:51:43
                               ETA: 00:03:48

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 42695 steps/s (collection: 2.192s, learning 0.111s)
             Mean action noise std: 4.30
          Mean value_function loss: 74.1707
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 73.2297
                       Mean reward: 699.06
               Mean episode length: 231.62
    Episode_Reward/reaching_object: 1.2360
    Episode_Reward/rotating_object: 143.6569
        Episode_Reward/action_rate: -0.1120
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.30s
                      Time elapsed: 00:51:45
                               ETA: 00:03:46

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 45561 steps/s (collection: 2.044s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 84.6389
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 73.2357
                       Mean reward: 719.99
               Mean episode length: 237.51
    Episode_Reward/reaching_object: 1.2254
    Episode_Reward/rotating_object: 141.9098
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 2.16s
                      Time elapsed: 00:51:47
                               ETA: 00:03:44

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 45643 steps/s (collection: 2.041s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 71.4428
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.2446
                       Mean reward: 742.62
               Mean episode length: 238.43
    Episode_Reward/reaching_object: 1.2468
    Episode_Reward/rotating_object: 144.9658
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.15s
                      Time elapsed: 00:51:49
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 46011 steps/s (collection: 2.026s, learning 0.110s)
             Mean action noise std: 4.31
          Mean value_function loss: 74.8481
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 73.2546
                       Mean reward: 712.30
               Mean episode length: 235.43
    Episode_Reward/reaching_object: 1.2200
    Episode_Reward/rotating_object: 140.6742
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 2.14s
                      Time elapsed: 00:51:51
                               ETA: 00:03:39

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 45590 steps/s (collection: 2.043s, learning 0.113s)
             Mean action noise std: 4.31
          Mean value_function loss: 73.2306
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.2746
                       Mean reward: 729.74
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 144.5197
        Episode_Reward/action_rate: -0.1130
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 2.16s
                      Time elapsed: 00:51:54
                               ETA: 00:03:37

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 45302 steps/s (collection: 2.056s, learning 0.114s)
             Mean action noise std: 4.32
          Mean value_function loss: 66.1412
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.2990
                       Mean reward: 737.96
               Mean episode length: 242.76
    Episode_Reward/reaching_object: 1.2364
    Episode_Reward/rotating_object: 142.8800
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.17s
                      Time elapsed: 00:51:56
                               ETA: 00:03:35

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 45410 steps/s (collection: 2.052s, learning 0.113s)
             Mean action noise std: 4.32
          Mean value_function loss: 70.6149
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.3229
                       Mean reward: 703.72
               Mean episode length: 233.08
    Episode_Reward/reaching_object: 1.2324
    Episode_Reward/rotating_object: 143.9081
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 2.16s
                      Time elapsed: 00:51:58
                               ETA: 00:03:33

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 45688 steps/s (collection: 2.039s, learning 0.112s)
             Mean action noise std: 4.32
          Mean value_function loss: 72.5989
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.3358
                       Mean reward: 712.23
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 142.3313
        Episode_Reward/action_rate: -0.1134
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 2.15s
                      Time elapsed: 00:52:00
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 46291 steps/s (collection: 2.013s, learning 0.110s)
             Mean action noise std: 4.33
          Mean value_function loss: 71.7034
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.3500
                       Mean reward: 706.54
               Mean episode length: 230.70
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 143.9242
        Episode_Reward/action_rate: -0.1135
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 2.12s
                      Time elapsed: 00:52:02
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 46538 steps/s (collection: 2.002s, learning 0.111s)
             Mean action noise std: 4.33
          Mean value_function loss: 63.6653
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.3647
                       Mean reward: 730.29
               Mean episode length: 237.54
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 143.1998
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.11s
                      Time elapsed: 00:52:04
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 46572 steps/s (collection: 2.000s, learning 0.111s)
             Mean action noise std: 4.33
          Mean value_function loss: 59.4053
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.3807
                       Mean reward: 696.76
               Mean episode length: 238.00
    Episode_Reward/reaching_object: 1.2241
    Episode_Reward/rotating_object: 143.3139
        Episode_Reward/action_rate: -0.1155
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 2.11s
                      Time elapsed: 00:52:06
                               ETA: 00:03:24

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 46701 steps/s (collection: 1.994s, learning 0.111s)
             Mean action noise std: 4.33
          Mean value_function loss: 73.2199
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 73.4003
                       Mean reward: 749.88
               Mean episode length: 241.03
    Episode_Reward/reaching_object: 1.2343
    Episode_Reward/rotating_object: 144.5685
        Episode_Reward/action_rate: -0.1152
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 2.10s
                      Time elapsed: 00:52:08
                               ETA: 00:03:21

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 46794 steps/s (collection: 1.990s, learning 0.111s)
             Mean action noise std: 4.34
          Mean value_function loss: 56.0661
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.4140
                       Mean reward: 756.72
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.2480
    Episode_Reward/rotating_object: 146.4066
        Episode_Reward/action_rate: -0.1163
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 2.10s
                      Time elapsed: 00:52:11
                               ETA: 00:03:19

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 46789 steps/s (collection: 1.991s, learning 0.110s)
             Mean action noise std: 4.34
          Mean value_function loss: 63.2287
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 73.4258
                       Mean reward: 733.96
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 1.2407
    Episode_Reward/rotating_object: 146.2208
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 2.10s
                      Time elapsed: 00:52:13
                               ETA: 00:03:17

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 46824 steps/s (collection: 1.989s, learning 0.110s)
             Mean action noise std: 4.34
          Mean value_function loss: 57.9594
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 73.4401
                       Mean reward: 743.82
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 1.2368
    Episode_Reward/rotating_object: 146.1129
        Episode_Reward/action_rate: -0.1165
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 2.10s
                      Time elapsed: 00:52:15
                               ETA: 00:03:15

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 43956 steps/s (collection: 2.123s, learning 0.113s)
             Mean action noise std: 4.34
          Mean value_function loss: 60.6033
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 73.4540
                       Mean reward: 723.83
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 144.1464
        Episode_Reward/action_rate: -0.1146
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 2.24s
                      Time elapsed: 00:52:17
                               ETA: 00:03:13

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 42682 steps/s (collection: 2.191s, learning 0.113s)
             Mean action noise std: 4.34
          Mean value_function loss: 65.8229
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.4625
                       Mean reward: 772.14
               Mean episode length: 241.70
    Episode_Reward/reaching_object: 1.2244
    Episode_Reward/rotating_object: 144.9655
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 2.30s
                      Time elapsed: 00:52:19
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 45339 steps/s (collection: 2.055s, learning 0.113s)
             Mean action noise std: 4.35
          Mean value_function loss: 72.5801
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.4751
                       Mean reward: 720.36
               Mean episode length: 235.91
    Episode_Reward/reaching_object: 1.2230
    Episode_Reward/rotating_object: 144.2877
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 2.17s
                      Time elapsed: 00:52:21
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 45294 steps/s (collection: 2.058s, learning 0.112s)
             Mean action noise std: 4.35
          Mean value_function loss: 73.0681
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.4922
                       Mean reward: 669.05
               Mean episode length: 219.43
    Episode_Reward/reaching_object: 1.1914
    Episode_Reward/rotating_object: 144.0143
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 2.17s
                      Time elapsed: 00:52:24
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 46062 steps/s (collection: 2.023s, learning 0.111s)
             Mean action noise std: 4.35
          Mean value_function loss: 61.1503
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 73.5080
                       Mean reward: 761.34
               Mean episode length: 239.89
    Episode_Reward/reaching_object: 1.2144
    Episode_Reward/rotating_object: 145.7743
        Episode_Reward/action_rate: -0.1157
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 2.13s
                      Time elapsed: 00:52:26
                               ETA: 00:03:04

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 42777 steps/s (collection: 2.169s, learning 0.129s)
             Mean action noise std: 4.36
          Mean value_function loss: 58.0365
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 73.5158
                       Mean reward: 745.69
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.1865
    Episode_Reward/rotating_object: 141.8855
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 2.30s
                      Time elapsed: 00:52:28
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 42906 steps/s (collection: 2.162s, learning 0.129s)
             Mean action noise std: 4.36
          Mean value_function loss: 71.3283
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.5333
                       Mean reward: 735.92
               Mean episode length: 232.47
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 145.7825
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 2.29s
                      Time elapsed: 00:52:30
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 42163 steps/s (collection: 2.200s, learning 0.131s)
             Mean action noise std: 4.36
          Mean value_function loss: 69.1218
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.5514
                       Mean reward: 733.12
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.2337
    Episode_Reward/rotating_object: 149.5075
        Episode_Reward/action_rate: -0.1178
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.33s
                      Time elapsed: 00:52:33
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 45769 steps/s (collection: 2.036s, learning 0.112s)
             Mean action noise std: 4.37
          Mean value_function loss: 77.7717
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.5666
                       Mean reward: 777.01
               Mean episode length: 243.62
    Episode_Reward/reaching_object: 1.2162
    Episode_Reward/rotating_object: 148.9011
        Episode_Reward/action_rate: -0.1163
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 2.15s
                      Time elapsed: 00:52:35
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 46398 steps/s (collection: 2.007s, learning 0.112s)
             Mean action noise std: 4.37
          Mean value_function loss: 60.2229
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 73.5818
                       Mean reward: 728.40
               Mean episode length: 234.29
    Episode_Reward/reaching_object: 1.1934
    Episode_Reward/rotating_object: 143.3522
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 2.12s
                      Time elapsed: 00:52:37
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 46218 steps/s (collection: 2.016s, learning 0.111s)
             Mean action noise std: 4.37
          Mean value_function loss: 64.3443
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.5900
                       Mean reward: 765.49
               Mean episode length: 241.56
    Episode_Reward/reaching_object: 1.2275
    Episode_Reward/rotating_object: 150.5125
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.13s
                      Time elapsed: 00:52:39
                               ETA: 00:02:50

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 46232 steps/s (collection: 2.014s, learning 0.112s)
             Mean action noise std: 4.37
          Mean value_function loss: 75.3199
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.6014
                       Mean reward: 730.99
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 145.7324
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 2.13s
                      Time elapsed: 00:52:41
                               ETA: 00:02:48

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 45834 steps/s (collection: 2.032s, learning 0.112s)
             Mean action noise std: 4.37
          Mean value_function loss: 68.4215
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 73.6110
                       Mean reward: 718.44
               Mean episode length: 228.12
    Episode_Reward/reaching_object: 1.1975
    Episode_Reward/rotating_object: 145.2510
        Episode_Reward/action_rate: -0.1150
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 2.14s
                      Time elapsed: 00:52:43
                               ETA: 00:02:46

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 45864 steps/s (collection: 2.029s, learning 0.115s)
             Mean action noise std: 4.38
          Mean value_function loss: 63.1500
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 73.6230
                       Mean reward: 759.71
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 1.2393
    Episode_Reward/rotating_object: 149.7727
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 2.14s
                      Time elapsed: 00:52:46
                               ETA: 00:02:44

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 45952 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 4.38
          Mean value_function loss: 74.9427
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 73.6382
                       Mean reward: 720.63
               Mean episode length: 233.83
    Episode_Reward/reaching_object: 1.1863
    Episode_Reward/rotating_object: 142.0916
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 2.14s
                      Time elapsed: 00:52:48
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 46499 steps/s (collection: 2.004s, learning 0.111s)
             Mean action noise std: 4.38
          Mean value_function loss: 70.5477
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.6500
                       Mean reward: 713.49
               Mean episode length: 229.49
    Episode_Reward/reaching_object: 1.1788
    Episode_Reward/rotating_object: 142.1885
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 2.11s
                      Time elapsed: 00:52:50
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 47417 steps/s (collection: 1.963s, learning 0.110s)
             Mean action noise std: 4.38
          Mean value_function loss: 64.0734
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.6633
                       Mean reward: 709.90
               Mean episode length: 230.31
    Episode_Reward/reaching_object: 1.1932
    Episode_Reward/rotating_object: 146.1329
        Episode_Reward/action_rate: -0.1156
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 2.07s
                      Time elapsed: 00:52:52
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 47251 steps/s (collection: 1.970s, learning 0.110s)
             Mean action noise std: 4.38
          Mean value_function loss: 73.9415
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.6767
                       Mean reward: 730.43
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 1.2018
    Episode_Reward/rotating_object: 145.3981
        Episode_Reward/action_rate: -0.1162
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 2.08s
                      Time elapsed: 00:52:54
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 46903 steps/s (collection: 1.985s, learning 0.111s)
             Mean action noise std: 4.39
          Mean value_function loss: 79.8523
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.6893
                       Mean reward: 750.00
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.1925
    Episode_Reward/rotating_object: 145.2791
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 2.10s
                      Time elapsed: 00:52:56
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 45925 steps/s (collection: 2.030s, learning 0.111s)
             Mean action noise std: 4.39
          Mean value_function loss: 84.8973
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 73.7071
                       Mean reward: 710.92
               Mean episode length: 232.34
    Episode_Reward/reaching_object: 1.1895
    Episode_Reward/rotating_object: 142.7881
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 2.14s
                      Time elapsed: 00:52:58
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 46425 steps/s (collection: 2.007s, learning 0.110s)
             Mean action noise std: 4.39
          Mean value_function loss: 69.4808
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 73.7260
                       Mean reward: 675.22
               Mean episode length: 232.55
    Episode_Reward/reaching_object: 1.1909
    Episode_Reward/rotating_object: 140.0729
        Episode_Reward/action_rate: -0.1159
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 2.12s
                      Time elapsed: 00:53:00
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 44931 steps/s (collection: 2.065s, learning 0.123s)
             Mean action noise std: 4.40
          Mean value_function loss: 67.7683
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.7414
                       Mean reward: 724.69
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.1838
    Episode_Reward/rotating_object: 144.7289
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 2.19s
                      Time elapsed: 00:53:02
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 44222 steps/s (collection: 2.111s, learning 0.112s)
             Mean action noise std: 4.40
          Mean value_function loss: 57.8101
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 73.7538
                       Mean reward: 754.43
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 1.2242
    Episode_Reward/rotating_object: 148.3928
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.22s
                      Time elapsed: 00:53:05
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 45027 steps/s (collection: 2.069s, learning 0.114s)
             Mean action noise std: 4.40
          Mean value_function loss: 63.0422
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 73.7633
                       Mean reward: 735.68
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.2307
    Episode_Reward/rotating_object: 148.3679
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.18s
                      Time elapsed: 00:53:07
                               ETA: 00:02:21

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 46101 steps/s (collection: 2.021s, learning 0.111s)
             Mean action noise std: 4.40
          Mean value_function loss: 74.9620
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 73.7729
                       Mean reward: 733.03
               Mean episode length: 236.32
    Episode_Reward/reaching_object: 1.1705
    Episode_Reward/rotating_object: 139.2087
        Episode_Reward/action_rate: -0.1141
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 2.13s
                      Time elapsed: 00:53:09
                               ETA: 00:02:19

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 45573 steps/s (collection: 2.046s, learning 0.112s)
             Mean action noise std: 4.41
          Mean value_function loss: 84.8661
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.7921
                       Mean reward: 711.51
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 1.2185
    Episode_Reward/rotating_object: 149.2848
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 2.16s
                      Time elapsed: 00:53:11
                               ETA: 00:02:17

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 45476 steps/s (collection: 2.050s, learning 0.112s)
             Mean action noise std: 4.41
          Mean value_function loss: 69.7415
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.8078
                       Mean reward: 726.46
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.2346
    Episode_Reward/rotating_object: 150.3302
        Episode_Reward/action_rate: -0.1197
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 2.16s
                      Time elapsed: 00:53:13
                               ETA: 00:02:15

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 46181 steps/s (collection: 2.016s, learning 0.113s)
             Mean action noise std: 4.41
          Mean value_function loss: 60.6539
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.8209
                       Mean reward: 756.46
               Mean episode length: 241.73
    Episode_Reward/reaching_object: 1.2148
    Episode_Reward/rotating_object: 146.3297
        Episode_Reward/action_rate: -0.1181
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 2.13s
                      Time elapsed: 00:53:15
                               ETA: 00:02:13

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 46260 steps/s (collection: 2.012s, learning 0.113s)
             Mean action noise std: 4.41
          Mean value_function loss: 59.6625
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 73.8347
                       Mean reward: 694.16
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.2189
    Episode_Reward/rotating_object: 145.7409
        Episode_Reward/action_rate: -0.1186
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 2.12s
                      Time elapsed: 00:53:18
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 46059 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 4.41
          Mean value_function loss: 64.8190
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 73.8450
                       Mean reward: 767.94
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 1.2259
    Episode_Reward/rotating_object: 146.6745
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.13s
                      Time elapsed: 00:53:20
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 46206 steps/s (collection: 2.014s, learning 0.114s)
             Mean action noise std: 4.42
          Mean value_function loss: 60.3531
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 73.8556
                       Mean reward: 753.04
               Mean episode length: 240.16
    Episode_Reward/reaching_object: 1.2288
    Episode_Reward/rotating_object: 149.1232
        Episode_Reward/action_rate: -0.1205
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 2.13s
                      Time elapsed: 00:53:22
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 45845 steps/s (collection: 2.031s, learning 0.113s)
             Mean action noise std: 4.42
          Mean value_function loss: 48.6457
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.8701
                       Mean reward: 742.67
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 1.2228
    Episode_Reward/rotating_object: 149.2648
        Episode_Reward/action_rate: -0.1198
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 2.14s
                      Time elapsed: 00:53:24
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 45842 steps/s (collection: 2.033s, learning 0.112s)
             Mean action noise std: 4.42
          Mean value_function loss: 72.6456
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.8901
                       Mean reward: 742.81
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2168
    Episode_Reward/rotating_object: 146.9931
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 2.14s
                      Time elapsed: 00:53:26
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 46430 steps/s (collection: 2.006s, learning 0.111s)
             Mean action noise std: 4.43
          Mean value_function loss: 62.1909
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 73.9031
                       Mean reward: 696.81
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.2139
    Episode_Reward/rotating_object: 142.8959
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 2.12s
                      Time elapsed: 00:53:28
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 45403 steps/s (collection: 2.054s, learning 0.111s)
             Mean action noise std: 4.43
          Mean value_function loss: 63.1670
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.9160
                       Mean reward: 727.80
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 145.2760
        Episode_Reward/action_rate: -0.1201
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 2.17s
                      Time elapsed: 00:53:30
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 43211 steps/s (collection: 2.163s, learning 0.112s)
             Mean action noise std: 4.43
          Mean value_function loss: 73.6592
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 73.9290
                       Mean reward: 690.32
               Mean episode length: 228.60
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 140.1438
        Episode_Reward/action_rate: -0.1182
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 2.27s
                      Time elapsed: 00:53:33
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 43232 steps/s (collection: 2.156s, learning 0.118s)
             Mean action noise std: 4.43
          Mean value_function loss: 73.6789
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 73.9411
                       Mean reward: 687.81
               Mean episode length: 228.98
    Episode_Reward/reaching_object: 1.1915
    Episode_Reward/rotating_object: 143.2573
        Episode_Reward/action_rate: -0.1182
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 2.27s
                      Time elapsed: 00:53:35
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 43181 steps/s (collection: 2.164s, learning 0.113s)
             Mean action noise std: 4.43
          Mean value_function loss: 57.7538
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 73.9543
                       Mean reward: 731.69
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.1912
    Episode_Reward/rotating_object: 142.6013
        Episode_Reward/action_rate: -0.1179
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.28s
                      Time elapsed: 00:53:37
                               ETA: 00:01:50

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 46627 steps/s (collection: 1.997s, learning 0.111s)
             Mean action noise std: 4.44
          Mean value_function loss: 64.7170
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 73.9711
                       Mean reward: 719.55
               Mean episode length: 238.13
    Episode_Reward/reaching_object: 1.2031
    Episode_Reward/rotating_object: 144.2867
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.11s
                      Time elapsed: 00:53:39
                               ETA: 00:01:48

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 47123 steps/s (collection: 1.975s, learning 0.111s)
             Mean action noise std: 4.44
          Mean value_function loss: 51.4037
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 73.9877
                       Mean reward: 777.54
               Mean episode length: 242.46
    Episode_Reward/reaching_object: 1.2273
    Episode_Reward/rotating_object: 150.9056
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.09s
                      Time elapsed: 00:53:41
                               ETA: 00:01:46

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 46463 steps/s (collection: 2.005s, learning 0.111s)
             Mean action noise std: 4.44
          Mean value_function loss: 55.3707
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 73.9981
                       Mean reward: 773.44
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.2120
    Episode_Reward/rotating_object: 145.3824
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.12s
                      Time elapsed: 00:53:44
                               ETA: 00:01:44

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 46694 steps/s (collection: 1.994s, learning 0.112s)
             Mean action noise std: 4.45
          Mean value_function loss: 64.6364
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.0098
                       Mean reward: 748.39
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 1.2220
    Episode_Reward/rotating_object: 147.1346
        Episode_Reward/action_rate: -0.1222
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.11s
                      Time elapsed: 00:53:46
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 47476 steps/s (collection: 1.958s, learning 0.112s)
             Mean action noise std: 4.45
          Mean value_function loss: 73.2705
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.0277
                       Mean reward: 738.35
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.1913
    Episode_Reward/rotating_object: 145.2563
        Episode_Reward/action_rate: -0.1183
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.07s
                      Time elapsed: 00:53:48
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 47052 steps/s (collection: 1.977s, learning 0.112s)
             Mean action noise std: 4.45
          Mean value_function loss: 52.0933
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 74.0455
                       Mean reward: 755.14
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.2143
    Episode_Reward/rotating_object: 149.2000
        Episode_Reward/action_rate: -0.1206
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.09s
                      Time elapsed: 00:53:50
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 47364 steps/s (collection: 1.962s, learning 0.113s)
             Mean action noise std: 4.45
          Mean value_function loss: 60.5202
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 74.0658
                       Mean reward: 700.48
               Mean episode length: 232.20
    Episode_Reward/reaching_object: 1.1999
    Episode_Reward/rotating_object: 145.6679
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.08s
                      Time elapsed: 00:53:52
                               ETA: 00:01:35

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 46121 steps/s (collection: 2.015s, learning 0.116s)
             Mean action noise std: 4.46
          Mean value_function loss: 67.1927
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.0814
                       Mean reward: 738.05
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.2119
    Episode_Reward/rotating_object: 147.3886
        Episode_Reward/action_rate: -0.1207
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.13s
                      Time elapsed: 00:53:54
                               ETA: 00:01:33

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 46528 steps/s (collection: 1.997s, learning 0.116s)
             Mean action noise std: 4.46
          Mean value_function loss: 64.4659
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.0933
                       Mean reward: 712.36
               Mean episode length: 235.09
    Episode_Reward/reaching_object: 1.1758
    Episode_Reward/rotating_object: 142.0186
        Episode_Reward/action_rate: -0.1173
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.11s
                      Time elapsed: 00:53:56
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 46424 steps/s (collection: 2.005s, learning 0.113s)
             Mean action noise std: 4.46
          Mean value_function loss: 59.9456
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.1084
                       Mean reward: 749.18
               Mean episode length: 236.11
    Episode_Reward/reaching_object: 1.2169
    Episode_Reward/rotating_object: 148.8857
        Episode_Reward/action_rate: -0.1218
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.12s
                      Time elapsed: 00:53:58
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 46115 steps/s (collection: 2.018s, learning 0.114s)
             Mean action noise std: 4.47
          Mean value_function loss: 59.4051
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 74.1252
                       Mean reward: 762.00
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.2134
    Episode_Reward/rotating_object: 148.4927
        Episode_Reward/action_rate: -0.1212
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.13s
                      Time elapsed: 00:54:00
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 46414 steps/s (collection: 2.003s, learning 0.115s)
             Mean action noise std: 4.47
          Mean value_function loss: 55.9773
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 74.1445
                       Mean reward: 749.75
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 152.0135
        Episode_Reward/action_rate: -0.1226
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 2.12s
                      Time elapsed: 00:54:03
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 46523 steps/s (collection: 1.999s, learning 0.114s)
             Mean action noise std: 4.47
          Mean value_function loss: 66.5545
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 74.1568
                       Mean reward: 769.96
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 1.1883
    Episode_Reward/rotating_object: 142.8118
        Episode_Reward/action_rate: -0.1198
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 2.11s
                      Time elapsed: 00:54:05
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 45900 steps/s (collection: 2.018s, learning 0.123s)
             Mean action noise std: 4.47
          Mean value_function loss: 70.3383
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.1698
                       Mean reward: 748.58
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 151.5722
        Episode_Reward/action_rate: -0.1230
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 2.14s
                      Time elapsed: 00:54:07
                               ETA: 00:01:19

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 42437 steps/s (collection: 2.188s, learning 0.129s)
             Mean action noise std: 4.48
          Mean value_function loss: 56.2422
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.1843
                       Mean reward: 745.52
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 1.2169
    Episode_Reward/rotating_object: 148.3782
        Episode_Reward/action_rate: -0.1221
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 2.32s
                      Time elapsed: 00:54:09
                               ETA: 00:01:17

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 43234 steps/s (collection: 2.145s, learning 0.128s)
             Mean action noise std: 4.48
          Mean value_function loss: 60.3044
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 74.2005
                       Mean reward: 713.26
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.1963
    Episode_Reward/rotating_object: 146.1987
        Episode_Reward/action_rate: -0.1212
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.27s
                      Time elapsed: 00:54:11
                               ETA: 00:01:15

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 42667 steps/s (collection: 2.178s, learning 0.126s)
             Mean action noise std: 4.48
          Mean value_function loss: 71.1935
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 74.2145
                       Mean reward: 708.73
               Mean episode length: 234.36
    Episode_Reward/reaching_object: 1.1939
    Episode_Reward/rotating_object: 143.1456
        Episode_Reward/action_rate: -0.1208
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 2.30s
                      Time elapsed: 00:54:14
                               ETA: 00:01:13

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 42730 steps/s (collection: 2.172s, learning 0.128s)
             Mean action noise std: 4.48
          Mean value_function loss: 41.3215
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.2259
                       Mean reward: 769.98
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 1.2009
    Episode_Reward/rotating_object: 147.4942
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.30s
                      Time elapsed: 00:54:16
                               ETA: 00:01:10

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 42545 steps/s (collection: 2.183s, learning 0.128s)
             Mean action noise std: 4.48
          Mean value_function loss: 63.2592
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.2362
                       Mean reward: 709.83
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.2074
    Episode_Reward/rotating_object: 144.7907
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.31s
                      Time elapsed: 00:54:18
                               ETA: 00:01:08

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 42227 steps/s (collection: 2.195s, learning 0.133s)
             Mean action noise std: 4.49
          Mean value_function loss: 61.2065
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 74.2542
                       Mean reward: 739.28
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.2304
    Episode_Reward/rotating_object: 153.6773
        Episode_Reward/action_rate: -0.1244
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 2.33s
                      Time elapsed: 00:54:21
                               ETA: 00:01:06

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 44242 steps/s (collection: 2.107s, learning 0.115s)
             Mean action noise std: 4.49
          Mean value_function loss: 50.9488
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 74.2710
                       Mean reward: 771.08
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 1.2219
    Episode_Reward/rotating_object: 150.5035
        Episode_Reward/action_rate: -0.1235
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 2.22s
                      Time elapsed: 00:54:23
                               ETA: 00:01:04

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 44704 steps/s (collection: 2.088s, learning 0.111s)
             Mean action noise std: 4.49
          Mean value_function loss: 62.0018
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.2876
                       Mean reward: 695.18
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.2088
    Episode_Reward/rotating_object: 148.4523
        Episode_Reward/action_rate: -0.1229
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 2.20s
                      Time elapsed: 00:54:25
                               ETA: 00:01:02

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 45717 steps/s (collection: 2.040s, learning 0.111s)
             Mean action noise std: 4.50
          Mean value_function loss: 71.4789
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.3073
                       Mean reward: 725.12
               Mean episode length: 234.09
    Episode_Reward/reaching_object: 1.1994
    Episode_Reward/rotating_object: 146.8794
        Episode_Reward/action_rate: -0.1220
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 2.15s
                      Time elapsed: 00:54:27
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 46970 steps/s (collection: 1.982s, learning 0.111s)
             Mean action noise std: 4.50
          Mean value_function loss: 52.7129
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.3217
                       Mean reward: 735.07
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.2245
    Episode_Reward/rotating_object: 149.4103
        Episode_Reward/action_rate: -0.1244
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 2.09s
                      Time elapsed: 00:54:29
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 46828 steps/s (collection: 1.988s, learning 0.111s)
             Mean action noise std: 4.50
          Mean value_function loss: 84.6908
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.3369
                       Mean reward: 702.14
               Mean episode length: 223.82
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 147.1051
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 2.10s
                      Time elapsed: 00:54:31
                               ETA: 00:00:55

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 47128 steps/s (collection: 1.975s, learning 0.111s)
             Mean action noise std: 4.50
          Mean value_function loss: 49.8053
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.3476
                       Mean reward: 755.78
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.2260
    Episode_Reward/rotating_object: 147.5129
        Episode_Reward/action_rate: -0.1253
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 2.09s
                      Time elapsed: 00:54:33
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 47127 steps/s (collection: 1.976s, learning 0.110s)
             Mean action noise std: 4.51
          Mean value_function loss: 65.9445
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.3595
                       Mean reward: 751.10
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.2116
    Episode_Reward/rotating_object: 149.2993
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 2.09s
                      Time elapsed: 00:54:36
                               ETA: 00:00:50

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 47269 steps/s (collection: 1.969s, learning 0.110s)
             Mean action noise std: 4.51
          Mean value_function loss: 60.7413
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.3704
                       Mean reward: 753.42
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.1995
    Episode_Reward/rotating_object: 146.6533
        Episode_Reward/action_rate: -0.1235
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 2.08s
                      Time elapsed: 00:54:38
                               ETA: 00:00:48

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 46948 steps/s (collection: 1.983s, learning 0.111s)
             Mean action noise std: 4.51
          Mean value_function loss: 86.0687
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.3812
                       Mean reward: 726.67
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.1808
    Episode_Reward/rotating_object: 141.6602
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.09s
                      Time elapsed: 00:54:40
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 46481 steps/s (collection: 2.001s, learning 0.114s)
             Mean action noise std: 4.51
          Mean value_function loss: 73.3530
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 74.3926
                       Mean reward: 736.79
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 1.2127
    Episode_Reward/rotating_object: 145.8463
        Episode_Reward/action_rate: -0.1246
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 2.11s
                      Time elapsed: 00:54:42
                               ETA: 00:00:44

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 45665 steps/s (collection: 2.040s, learning 0.113s)
             Mean action noise std: 4.52
          Mean value_function loss: 60.4980
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.4108
                       Mean reward: 771.79
               Mean episode length: 244.44
    Episode_Reward/reaching_object: 1.2154
    Episode_Reward/rotating_object: 148.7805
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 2.15s
                      Time elapsed: 00:54:44
                               ETA: 00:00:42

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 45646 steps/s (collection: 2.040s, learning 0.113s)
             Mean action noise std: 4.52
          Mean value_function loss: 57.2697
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 74.4260
                       Mean reward: 764.99
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 1.2265
    Episode_Reward/rotating_object: 150.6255
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.15s
                      Time elapsed: 00:54:46
                               ETA: 00:00:39

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 45834 steps/s (collection: 2.033s, learning 0.111s)
             Mean action noise std: 4.52
          Mean value_function loss: 60.4985
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.4399
                       Mean reward: 755.97
               Mean episode length: 238.63
    Episode_Reward/reaching_object: 1.2316
    Episode_Reward/rotating_object: 151.1991
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.14s
                      Time elapsed: 00:54:48
                               ETA: 00:00:37

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 45218 steps/s (collection: 2.061s, learning 0.113s)
             Mean action noise std: 4.53
          Mean value_function loss: 83.2146
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 74.4553
                       Mean reward: 722.72
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.1945
    Episode_Reward/rotating_object: 140.6094
        Episode_Reward/action_rate: -0.1228
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.17s
                      Time elapsed: 00:54:50
                               ETA: 00:00:35

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 46079 steps/s (collection: 2.021s, learning 0.113s)
             Mean action noise std: 4.53
          Mean value_function loss: 67.1051
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.4696
                       Mean reward: 744.34
               Mean episode length: 240.53
    Episode_Reward/reaching_object: 1.2231
    Episode_Reward/rotating_object: 147.0753
        Episode_Reward/action_rate: -0.1259
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 2.13s
                      Time elapsed: 00:54:53
                               ETA: 00:00:33

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 45241 steps/s (collection: 2.062s, learning 0.111s)
             Mean action noise std: 4.53
          Mean value_function loss: 71.6558
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.4864
                       Mean reward: 750.20
               Mean episode length: 238.09
    Episode_Reward/reaching_object: 1.2175
    Episode_Reward/rotating_object: 149.9664
        Episode_Reward/action_rate: -0.1250
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 2.17s
                      Time elapsed: 00:54:55
                               ETA: 00:00:31

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 45935 steps/s (collection: 2.025s, learning 0.115s)
             Mean action noise std: 4.53
          Mean value_function loss: 80.0382
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 74.5040
                       Mean reward: 712.63
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.1886
    Episode_Reward/rotating_object: 145.0759
        Episode_Reward/action_rate: -0.1233
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 2.14s
                      Time elapsed: 00:54:57
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 46127 steps/s (collection: 2.019s, learning 0.112s)
             Mean action noise std: 4.54
          Mean value_function loss: 60.2818
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 74.5223
                       Mean reward: 744.58
               Mean episode length: 244.79
    Episode_Reward/reaching_object: 1.1946
    Episode_Reward/rotating_object: 146.2218
        Episode_Reward/action_rate: -0.1240
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 2.13s
                      Time elapsed: 00:54:59
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 46172 steps/s (collection: 2.018s, learning 0.111s)
             Mean action noise std: 4.54
          Mean value_function loss: 65.2042
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 74.5342
                       Mean reward: 707.10
               Mean episode length: 230.17
    Episode_Reward/reaching_object: 1.2080
    Episode_Reward/rotating_object: 142.8506
        Episode_Reward/action_rate: -0.1262
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 2.13s
                      Time elapsed: 00:55:01
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 45926 steps/s (collection: 2.028s, learning 0.113s)
             Mean action noise std: 4.54
          Mean value_function loss: 66.2047
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 74.5483
                       Mean reward: 739.84
               Mean episode length: 238.39
    Episode_Reward/reaching_object: 1.2089
    Episode_Reward/rotating_object: 144.3841
        Episode_Reward/action_rate: -0.1258
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.14s
                      Time elapsed: 00:55:03
                               ETA: 00:00:22

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 45643 steps/s (collection: 2.043s, learning 0.111s)
             Mean action noise std: 4.54
          Mean value_function loss: 66.7042
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 74.5608
                       Mean reward: 732.59
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 1.1954
    Episode_Reward/rotating_object: 147.3371
        Episode_Reward/action_rate: -0.1253
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 2.15s
                      Time elapsed: 00:55:05
                               ETA: 00:00:19

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 45962 steps/s (collection: 2.025s, learning 0.114s)
             Mean action noise std: 4.55
          Mean value_function loss: 66.4129
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 74.5761
                       Mean reward: 757.49
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 1.2064
    Episode_Reward/rotating_object: 148.7283
        Episode_Reward/action_rate: -0.1270
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 2.14s
                      Time elapsed: 00:55:08
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 46303 steps/s (collection: 2.010s, learning 0.113s)
             Mean action noise std: 4.55
          Mean value_function loss: 66.6324
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.5929
                       Mean reward: 730.28
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.1905
    Episode_Reward/rotating_object: 142.6548
        Episode_Reward/action_rate: -0.1256
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 2.12s
                      Time elapsed: 00:55:10
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 46412 steps/s (collection: 2.007s, learning 0.111s)
             Mean action noise std: 4.55
          Mean value_function loss: 75.7052
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 74.6033
                       Mean reward: 750.19
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.2086
    Episode_Reward/rotating_object: 149.7037
        Episode_Reward/action_rate: -0.1271
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 2.12s
                      Time elapsed: 00:55:12
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 46088 steps/s (collection: 2.022s, learning 0.111s)
             Mean action noise std: 4.55
          Mean value_function loss: 68.7309
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 74.6125
                       Mean reward: 711.35
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.2047
    Episode_Reward/rotating_object: 147.1757
        Episode_Reward/action_rate: -0.1274
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 2.13s
                      Time elapsed: 00:55:14
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 46654 steps/s (collection: 1.997s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 75.9549
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 74.6296
                       Mean reward: 709.17
               Mean episode length: 230.47
    Episode_Reward/reaching_object: 1.2030
    Episode_Reward/rotating_object: 144.8493
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 2.11s
                      Time elapsed: 00:55:16
                               ETA: 00:00:08

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 47012 steps/s (collection: 1.980s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 59.0878
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 74.6484
                       Mean reward: 752.73
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 1.2055
    Episode_Reward/rotating_object: 148.6694
        Episode_Reward/action_rate: -0.1271
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 2.09s
                      Time elapsed: 00:55:18
                               ETA: 00:00:06

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 46884 steps/s (collection: 1.986s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 70.3588
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 74.6675
                       Mean reward: 725.00
               Mean episode length: 233.84
    Episode_Reward/reaching_object: 1.1857
    Episode_Reward/rotating_object: 142.8539
        Episode_Reward/action_rate: -0.1261
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 2.10s
                      Time elapsed: 00:55:20
                               ETA: 00:00:04

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 47010 steps/s (collection: 1.980s, learning 0.111s)
             Mean action noise std: 4.56
          Mean value_function loss: 68.1648
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 74.6808
                       Mean reward: 705.22
               Mean episode length: 235.26
    Episode_Reward/reaching_object: 1.1962
    Episode_Reward/rotating_object: 145.7793
        Episode_Reward/action_rate: -0.1262
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 2.09s
                      Time elapsed: 00:55:22
                               ETA: 00:00:02

